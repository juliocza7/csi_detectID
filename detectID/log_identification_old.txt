Usando dispositivo: cpu
Usando dispositivo: cpu
Ejecutando solo la tarea de Identificación con modelo: 1

Grupos generados:  10
grupo  1 :  ['095', '065', '013', '063', '070', '040']
grupo  2 :  ['102', '020', '125', '011', '021', '008']
grupo  3 :  ['036', '024', '100', '090', '091', '019']
grupo  4 :  ['064', '060', '028', '033', '026', '110']
grupo  5 :  ['104', '093', '088', '055', '045', '022']
grupo  6 :  ['062', '035', '002', '043', '073', '109']
grupo  7 :  ['098', '025', '059', '121', '107', '086']
grupo  8 :  ['031', '051', '096', '034', '014', '092']
grupo  9 :  ['007', '111', '001', '082', '103', '117']
grupo  10 :  ['067', '124', '010', '009', '118', '032']

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  095  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  095  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6886, Acc: 0.5399, Val Loss: 0.6908, Val Acc: 0.5548
Mejor modelo guardado con Val Loss: 0.6908
Epoch 2/100, Loss: 0.6928, Acc: 0.5025, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 3/100, Loss: 0.6934, Acc: 0.4937, Val Loss: 0.6932, Val Acc: 0.5011
Epoch 4/100, Loss: 0.6934, Acc: 0.4943, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 5/100, Loss: 0.6936, Acc: 0.4893, Val Loss: 0.6931, Val Acc: 0.4989
Epoch 6/100, Loss: 0.6935, Acc: 0.4895, Val Loss: 0.6938, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6933, Acc: 0.5017, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 8/100, Loss: 0.6932, Acc: 0.5045, Val Loss: 0.6945, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6933, Acc: 0.4993, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 10/100, Loss: 0.6935, Acc: 0.4904, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 11/100, Loss: 0.6935, Acc: 0.4940, Val Loss: 0.6932, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6932, Acc: 0.5051, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6934, Acc: 0.4983, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6933, Acc: 0.4968, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6934, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 16/100, Loss: 0.6933, Acc: 0.4943, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6933, Acc: 0.4991, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 18/100, Loss: 0.6932, Acc: 0.5018, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 19/100, Loss: 0.6933, Acc: 0.4956, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 20/100, Loss: 0.6934, Acc: 0.4941, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 21/100, Loss: 0.6932, Acc: 0.4968, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4965, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 23/100, Loss: 0.6933, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 24/100, Loss: 0.6932, Acc: 0.4932, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 25/100, Loss: 0.6925, Acc: 0.5074, Val Loss: 0.6903, Val Acc: 0.5555
Mejor modelo guardado con Val Loss: 0.6903
Epoch 26/100, Loss: 0.6900, Acc: 0.5624, Val Loss: 0.6896, Val Acc: 0.5706
Mejor modelo guardado con Val Loss: 0.6896
Epoch 27/100, Loss: 0.6891, Acc: 0.5693, Val Loss: 0.6892, Val Acc: 0.5610
Mejor modelo guardado con Val Loss: 0.6892
Epoch 28/100, Loss: 0.6883, Acc: 0.5801, Val Loss: 0.6875, Val Acc: 0.5886
Mejor modelo guardado con Val Loss: 0.6875
Epoch 29/100, Loss: 0.6878, Acc: 0.5775, Val Loss: 0.6869, Val Acc: 0.5912
Mejor modelo guardado con Val Loss: 0.6869
Epoch 30/100, Loss: 0.6874, Acc: 0.5764, Val Loss: 0.6863, Val Acc: 0.5813
Mejor modelo guardado con Val Loss: 0.6863
Epoch 31/100, Loss: 0.6870, Acc: 0.5736, Val Loss: 0.6847, Val Acc: 0.6000
Mejor modelo guardado con Val Loss: 0.6847
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6861, Acc: 0.5844, Val Loss: 0.6844, Val Acc: 0.5923
Mejor modelo guardado con Val Loss: 0.6844
Epoch 33/100, Loss: 0.6857, Acc: 0.5821, Val Loss: 0.6837, Val Acc: 0.6066
Mejor modelo guardado con Val Loss: 0.6837
Epoch 34/100, Loss: 0.6852, Acc: 0.5832, Val Loss: 0.6832, Val Acc: 0.6033
Mejor modelo guardado con Val Loss: 0.6832
Epoch 35/100, Loss: 0.6850, Acc: 0.5851, Val Loss: 0.6829, Val Acc: 0.6096
Mejor modelo guardado con Val Loss: 0.6829
Epoch 36/100, Loss: 0.6849, Acc: 0.5843, Val Loss: 0.6824, Val Acc: 0.6026
Mejor modelo guardado con Val Loss: 0.6824
Epoch 37/100, Loss: 0.6842, Acc: 0.5889, Val Loss: 0.6820, Val Acc: 0.6040
Mejor modelo guardado con Val Loss: 0.6820
Epoch 38/100, Loss: 0.6840, Acc: 0.5876, Val Loss: 0.6812, Val Acc: 0.6096
Mejor modelo guardado con Val Loss: 0.6812
Epoch 39/100, Loss: 0.6838, Acc: 0.5832, Val Loss: 0.6809, Val Acc: 0.6074
Mejor modelo guardado con Val Loss: 0.6809
Epoch 40/100, Loss: 0.6831, Acc: 0.5886, Val Loss: 0.6815, Val Acc: 0.5930
Epoch 41/100, Loss: 0.6832, Acc: 0.5863, Val Loss: 0.6796, Val Acc: 0.6188
Mejor modelo guardado con Val Loss: 0.6796
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6827, Acc: 0.5863, Val Loss: 0.6794, Val Acc: 0.6154
Mejor modelo guardado con Val Loss: 0.6794
Epoch 43/100, Loss: 0.6825, Acc: 0.5881, Val Loss: 0.6790, Val Acc: 0.6169
Mejor modelo guardado con Val Loss: 0.6790
Epoch 44/100, Loss: 0.6824, Acc: 0.5885, Val Loss: 0.6788, Val Acc: 0.6206
Mejor modelo guardado con Val Loss: 0.6788
Epoch 45/100, Loss: 0.6822, Acc: 0.5903, Val Loss: 0.6786, Val Acc: 0.6169
Mejor modelo guardado con Val Loss: 0.6786
Epoch 46/100, Loss: 0.6820, Acc: 0.5885, Val Loss: 0.6783, Val Acc: 0.6176
Mejor modelo guardado con Val Loss: 0.6783
Epoch 47/100, Loss: 0.6819, Acc: 0.5893, Val Loss: 0.6780, Val Acc: 0.6210
Mejor modelo guardado con Val Loss: 0.6780
Epoch 48/100, Loss: 0.6817, Acc: 0.5892, Val Loss: 0.6781, Val Acc: 0.6099
Epoch 49/100, Loss: 0.6817, Acc: 0.5878, Val Loss: 0.6775, Val Acc: 0.6202
Mejor modelo guardado con Val Loss: 0.6775
Epoch 50/100, Loss: 0.6809, Acc: 0.5877, Val Loss: 0.6779, Val Acc: 0.6062
Epoch 51/100, Loss: 0.6797, Acc: 0.5862, Val Loss: 0.6770, Val Acc: 0.6103
Mejor modelo guardado con Val Loss: 0.6770
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6793, Acc: 0.5897, Val Loss: 0.6767, Val Acc: 0.6044
Mejor modelo guardado con Val Loss: 0.6767
Epoch 53/100, Loss: 0.6793, Acc: 0.5891, Val Loss: 0.6762, Val Acc: 0.6074
Mejor modelo guardado con Val Loss: 0.6762
Epoch 54/100, Loss: 0.6784, Acc: 0.5892, Val Loss: 0.6742, Val Acc: 0.6143
Mejor modelo guardado con Val Loss: 0.6742
Epoch 55/100, Loss: 0.6779, Acc: 0.5909, Val Loss: 0.6736, Val Acc: 0.6151
Mejor modelo guardado con Val Loss: 0.6736
Epoch 56/100, Loss: 0.6778, Acc: 0.5921, Val Loss: 0.6740, Val Acc: 0.6099
Epoch 57/100, Loss: 0.6775, Acc: 0.5915, Val Loss: 0.6730, Val Acc: 0.6154
Mejor modelo guardado con Val Loss: 0.6730
Epoch 58/100, Loss: 0.6773, Acc: 0.5948, Val Loss: 0.6732, Val Acc: 0.6132
Epoch 59/100, Loss: 0.6772, Acc: 0.5892, Val Loss: 0.6726, Val Acc: 0.6180
Mejor modelo guardado con Val Loss: 0.6726
Epoch 60/100, Loss: 0.6771, Acc: 0.5898, Val Loss: 0.6725, Val Acc: 0.6162
Mejor modelo guardado con Val Loss: 0.6725
Epoch 61/100, Loss: 0.6769, Acc: 0.5909, Val Loss: 0.6723, Val Acc: 0.6158
Mejor modelo guardado con Val Loss: 0.6723
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6768, Acc: 0.5907, Val Loss: 0.6724, Val Acc: 0.6184
Epoch 63/100, Loss: 0.6767, Acc: 0.5936, Val Loss: 0.6720, Val Acc: 0.6195
Mejor modelo guardado con Val Loss: 0.6720
Epoch 64/100, Loss: 0.6766, Acc: 0.5893, Val Loss: 0.6719, Val Acc: 0.6195
Mejor modelo guardado con Val Loss: 0.6719
Epoch 65/100, Loss: 0.6766, Acc: 0.5905, Val Loss: 0.6718, Val Acc: 0.6176
Mejor modelo guardado con Val Loss: 0.6718
Epoch 66/100, Loss: 0.6765, Acc: 0.5921, Val Loss: 0.6719, Val Acc: 0.6188
Epoch 67/100, Loss: 0.6764, Acc: 0.5922, Val Loss: 0.6716, Val Acc: 0.6188
Mejor modelo guardado con Val Loss: 0.6716
Epoch 68/100, Loss: 0.6763, Acc: 0.5912, Val Loss: 0.6715, Val Acc: 0.6202
Mejor modelo guardado con Val Loss: 0.6715
Epoch 69/100, Loss: 0.6763, Acc: 0.5929, Val Loss: 0.6716, Val Acc: 0.6184
Epoch 70/100, Loss: 0.6762, Acc: 0.5934, Val Loss: 0.6716, Val Acc: 0.6195
Epoch 71/100, Loss: 0.6761, Acc: 0.5912, Val Loss: 0.6715, Val Acc: 0.6180
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6761, Acc: 0.5924, Val Loss: 0.6712, Val Acc: 0.6176
Mejor modelo guardado con Val Loss: 0.6712
Epoch 73/100, Loss: 0.6760, Acc: 0.5895, Val Loss: 0.6712, Val Acc: 0.6199
Mejor modelo guardado con Val Loss: 0.6712
Epoch 74/100, Loss: 0.6760, Acc: 0.5917, Val Loss: 0.6710, Val Acc: 0.6202
Mejor modelo guardado con Val Loss: 0.6710
Epoch 75/100, Loss: 0.6759, Acc: 0.5921, Val Loss: 0.6710, Val Acc: 0.6180
Epoch 76/100, Loss: 0.6759, Acc: 0.5926, Val Loss: 0.6710, Val Acc: 0.6195
Mejor modelo guardado con Val Loss: 0.6710
Epoch 77/100, Loss: 0.6759, Acc: 0.5916, Val Loss: 0.6709, Val Acc: 0.6191
Mejor modelo guardado con Val Loss: 0.6709
Epoch 78/100, Loss: 0.6758, Acc: 0.5917, Val Loss: 0.6709, Val Acc: 0.6195
Epoch 79/100, Loss: 0.6758, Acc: 0.5913, Val Loss: 0.6707, Val Acc: 0.6213
Mejor modelo guardado con Val Loss: 0.6707
Epoch 80/100, Loss: 0.6757, Acc: 0.5926, Val Loss: 0.6708, Val Acc: 0.6188
Epoch 81/100, Loss: 0.6757, Acc: 0.5926, Val Loss: 0.6707, Val Acc: 0.6188
Mejor modelo guardado con Val Loss: 0.6707
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6756, Acc: 0.5924, Val Loss: 0.6706, Val Acc: 0.6191
Mejor modelo guardado con Val Loss: 0.6706
Epoch 83/100, Loss: 0.6756, Acc: 0.5915, Val Loss: 0.6704, Val Acc: 0.6221
Mejor modelo guardado con Val Loss: 0.6704
Epoch 84/100, Loss: 0.6755, Acc: 0.5919, Val Loss: 0.6705, Val Acc: 0.6199
Epoch 85/100, Loss: 0.6755, Acc: 0.5924, Val Loss: 0.6704, Val Acc: 0.6195
Epoch 86/100, Loss: 0.6755, Acc: 0.5934, Val Loss: 0.6704, Val Acc: 0.6199
Mejor modelo guardado con Val Loss: 0.6704
Epoch 87/100, Loss: 0.6754, Acc: 0.5925, Val Loss: 0.6702, Val Acc: 0.6206
Mejor modelo guardado con Val Loss: 0.6702
Epoch 88/100, Loss: 0.6754, Acc: 0.5926, Val Loss: 0.6702, Val Acc: 0.6191
Epoch 89/100, Loss: 0.6753, Acc: 0.5920, Val Loss: 0.6701, Val Acc: 0.6202
Mejor modelo guardado con Val Loss: 0.6701
Epoch 90/100, Loss: 0.6753, Acc: 0.5917, Val Loss: 0.6700, Val Acc: 0.6213
Mejor modelo guardado con Val Loss: 0.6700
Epoch 91/100, Loss: 0.6753, Acc: 0.5915, Val Loss: 0.6701, Val Acc: 0.6195
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6752, Acc: 0.5938, Val Loss: 0.6698, Val Acc: 0.6210
Mejor modelo guardado con Val Loss: 0.6698
Epoch 93/100, Loss: 0.6752, Acc: 0.5917, Val Loss: 0.6698, Val Acc: 0.6210
Mejor modelo guardado con Val Loss: 0.6698
Epoch 94/100, Loss: 0.6751, Acc: 0.5929, Val Loss: 0.6698, Val Acc: 0.6210
Mejor modelo guardado con Val Loss: 0.6698
Epoch 95/100, Loss: 0.6751, Acc: 0.5932, Val Loss: 0.6697, Val Acc: 0.6210
Mejor modelo guardado con Val Loss: 0.6697
Epoch 96/100, Loss: 0.6750, Acc: 0.5924, Val Loss: 0.6696, Val Acc: 0.6202
Mejor modelo guardado con Val Loss: 0.6696
Epoch 97/100, Loss: 0.6750, Acc: 0.5933, Val Loss: 0.6695, Val Acc: 0.6202
Mejor modelo guardado con Val Loss: 0.6695
Epoch 98/100, Loss: 0.6750, Acc: 0.5937, Val Loss: 0.6694, Val Acc: 0.6221
Mejor modelo guardado con Val Loss: 0.6694
Epoch 99/100, Loss: 0.6749, Acc: 0.5933, Val Loss: 0.6693, Val Acc: 0.6221
Mejor modelo guardado con Val Loss: 0.6693
Epoch 100/100, Loss: 0.6749, Acc: 0.5929, Val Loss: 0.6693, Val Acc: 0.6221
Mejor modelo guardado con Val Loss: 0.6693

##############################
Resultados para principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1 
 {'training': [0.6748934037545148, 0.592922794117647, 0.5797192871786785, 0.6757352941176471, 0.6240556828792123], 'validate': [0.669317131818727, 0.6220588235294118, 0.6182336182336182, 0.638235294117647, 0.6280752532561505], 'test': [0.6676005003628908, 0.6258823529411764, 0.6203599550056242, 0.6488235294117647, 0.6342725704427832]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  065  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  065  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6935, Acc: 0.5010, Val Loss: 0.6932, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6932
Epoch 2/100, Loss: 0.6934, Acc: 0.4959, Val Loss: 0.6939, Val Acc: 0.5000
Epoch 3/100, Loss: 0.6935, Acc: 0.4961, Val Loss: 0.6931, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6931
Epoch 4/100, Loss: 0.6933, Acc: 0.5000, Val Loss: 0.6937, Val Acc: 0.5000
Epoch 5/100, Loss: 0.6932, Acc: 0.5064, Val Loss: 0.6931, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6931
Epoch 6/100, Loss: 0.6935, Acc: 0.4911, Val Loss: 0.6935, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6935, Acc: 0.4956, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 8/100, Loss: 0.6935, Acc: 0.4965, Val Loss: 0.6931, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6931
Epoch 9/100, Loss: 0.6935, Acc: 0.4917, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 10/100, Loss: 0.6935, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 11/100, Loss: 0.6933, Acc: 0.4998, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6932, Acc: 0.5046, Val Loss: 0.6931, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6931
Epoch 13/100, Loss: 0.6934, Acc: 0.4961, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6933, Acc: 0.5031, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6933, Acc: 0.4972, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 16/100, Loss: 0.6933, Acc: 0.4892, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6933, Acc: 0.4991, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 18/100, Loss: 0.6933, Acc: 0.4954, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 19/100, Loss: 0.6933, Acc: 0.4998, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 20/100, Loss: 0.6933, Acc: 0.4928, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 21/100, Loss: 0.6933, Acc: 0.4966, Val Loss: 0.6934, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4961, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 23/100, Loss: 0.6932, Acc: 0.4934, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 24/100, Loss: 0.6932, Acc: 0.4997, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 25/100, Loss: 0.6932, Acc: 0.4906, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 26/100, Loss: 0.6932, Acc: 0.4989, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 27/100, Loss: 0.6932, Acc: 0.4982, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 28/100, Loss: 0.6932, Acc: 0.4987, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 29/100, Loss: 0.6932, Acc: 0.4952, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 30/100, Loss: 0.6931, Acc: 0.5093, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 31/100, Loss: 0.6932, Acc: 0.5006, Val Loss: 0.6932, Val Acc: 0.5000
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 33/100, Loss: 0.6932, Acc: 0.4919, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 34/100, Loss: 0.6932, Acc: 0.4908, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 35/100, Loss: 0.6932, Acc: 0.4887, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 36/100, Loss: 0.6932, Acc: 0.4917, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 37/100, Loss: 0.6932, Acc: 0.4950, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 38/100, Loss: 0.6932, Acc: 0.5013, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 39/100, Loss: 0.6932, Acc: 0.4998, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 40/100, Loss: 0.6932, Acc: 0.4975, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 41/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.4929, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 43/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 44/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 45/100, Loss: 0.6932, Acc: 0.4929, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 46/100, Loss: 0.6932, Acc: 0.4992, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 47/100, Loss: 0.6932, Acc: 0.4959, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 48/100, Loss: 0.6932, Acc: 0.4964, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 49/100, Loss: 0.6932, Acc: 0.4972, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 50/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 51/100, Loss: 0.6932, Acc: 0.4968, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6932, Acc: 0.4949, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 53/100, Loss: 0.6932, Acc: 0.4999, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 54/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 55/100, Loss: 0.6932, Acc: 0.4939, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 56/100, Loss: 0.6932, Acc: 0.4963, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 57/100, Loss: 0.6932, Acc: 0.4998, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 58/100, Loss: 0.6932, Acc: 0.4992, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 59/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 60/100, Loss: 0.6932, Acc: 0.4974, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 61/100, Loss: 0.6932, Acc: 0.4863, Val Loss: 0.6931, Val Acc: 0.4993
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6932, Acc: 0.4904, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 63/100, Loss: 0.6932, Acc: 0.4916, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 64/100, Loss: 0.6932, Acc: 0.4934, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 65/100, Loss: 0.6932, Acc: 0.4994, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 66/100, Loss: 0.6932, Acc: 0.4915, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 67/100, Loss: 0.6932, Acc: 0.4918, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 68/100, Loss: 0.6932, Acc: 0.4947, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 69/100, Loss: 0.6931, Acc: 0.4910, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 70/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 71/100, Loss: 0.6931, Acc: 0.4972, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6931, Acc: 0.4962, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 73/100, Loss: 0.6932, Acc: 0.4966, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 74/100, Loss: 0.6931, Acc: 0.4940, Val Loss: 0.6931, Val Acc: 0.5015
Epoch 75/100, Loss: 0.6932, Acc: 0.4971, Val Loss: 0.6931, Val Acc: 0.5011
Epoch 76/100, Loss: 0.6931, Acc: 0.4928, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 77/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 78/100, Loss: 0.6931, Acc: 0.5002, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 79/100, Loss: 0.6931, Acc: 0.4976, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 80/100, Loss: 0.6932, Acc: 0.4978, Val Loss: 0.6931, Val Acc: 0.5011
Epoch 81/100, Loss: 0.6931, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.5096
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6931, Acc: 0.4950, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 83/100, Loss: 0.6931, Acc: 0.4939, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 84/100, Loss: 0.6932, Acc: 0.4922, Val Loss: 0.6931, Val Acc: 0.4967
Epoch 85/100, Loss: 0.6931, Acc: 0.5015, Val Loss: 0.6931, Val Acc: 0.5015
Epoch 86/100, Loss: 0.6931, Acc: 0.4993, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 87/100, Loss: 0.6931, Acc: 0.5022, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 88/100, Loss: 0.6931, Acc: 0.4932, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 89/100, Loss: 0.6931, Acc: 0.4994, Val Loss: 0.6931, Val Acc: 0.4985
Epoch 90/100, Loss: 0.6931, Acc: 0.4986, Val Loss: 0.6931, Val Acc: 0.5022
Epoch 91/100, Loss: 0.6931, Acc: 0.4953, Val Loss: 0.6931, Val Acc: 0.5059
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6931, Acc: 0.4953, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 93/100, Loss: 0.6931, Acc: 0.5022, Val Loss: 0.6931, Val Acc: 0.4982
Epoch 94/100, Loss: 0.6931, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.4901
Epoch 95/100, Loss: 0.6930, Acc: 0.4987, Val Loss: 0.6935, Val Acc: 0.4357
Epoch 96/100, Loss: 0.6927, Acc: 0.4873, Val Loss: 0.6938, Val Acc: 0.4331
Epoch 97/100, Loss: 0.6926, Acc: 0.4913, Val Loss: 0.6939, Val Acc: 0.4419
Epoch 98/100, Loss: 0.6926, Acc: 0.4962, Val Loss: 0.6939, Val Acc: 0.4478
Epoch 99/100, Loss: 0.6926, Acc: 0.5058, Val Loss: 0.6940, Val Acc: 0.4518
Epoch 100/100, Loss: 0.6926, Acc: 0.5056, Val Loss: 0.6940, Val Acc: 0.4526

##############################
Resultados para principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1 
 {'training': [0.6925777775399825, 0.5056066176470588, 0.504832831563936, 0.5856617647058824, 0.5422517232575951], 'validate': [0.6940497381742611, 0.4525735294117647, 0.46422628951747086, 0.6154411764705883, 0.5292443882390135], 'test': [0.6930230767638595, 0.5, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  013  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  013  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6872, Acc: 0.5624, Val Loss: 0.6678, Val Acc: 0.6732
Mejor modelo guardado con Val Loss: 0.6678
Epoch 2/100, Loss: 0.6831, Acc: 0.5756, Val Loss: 0.6762, Val Acc: 0.6482
Epoch 3/100, Loss: 0.6759, Acc: 0.5989, Val Loss: 0.6460, Val Acc: 0.6750
Mejor modelo guardado con Val Loss: 0.6460
Epoch 4/100, Loss: 0.6660, Acc: 0.6147, Val Loss: 0.6220, Val Acc: 0.7018
Mejor modelo guardado con Val Loss: 0.6220
Epoch 5/100, Loss: 0.6612, Acc: 0.6171, Val Loss: 0.6136, Val Acc: 0.7022
Mejor modelo guardado con Val Loss: 0.6136
Epoch 6/100, Loss: 0.6577, Acc: 0.6195, Val Loss: 0.6219, Val Acc: 0.6404
Epoch 7/100, Loss: 0.6515, Acc: 0.6269, Val Loss: 0.6282, Val Acc: 0.6522
Epoch 8/100, Loss: 0.6552, Acc: 0.6165, Val Loss: 0.6278, Val Acc: 0.6577
Epoch 9/100, Loss: 0.6514, Acc: 0.6262, Val Loss: 0.6109, Val Acc: 0.6544
Mejor modelo guardado con Val Loss: 0.6109
Epoch 10/100, Loss: 0.6500, Acc: 0.6220, Val Loss: 0.6044, Val Acc: 0.6412
Mejor modelo guardado con Val Loss: 0.6044
Epoch 11/100, Loss: 0.6452, Acc: 0.6244, Val Loss: 0.6049, Val Acc: 0.6607
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6424, Acc: 0.6332, Val Loss: 0.5824, Val Acc: 0.7007
Mejor modelo guardado con Val Loss: 0.5824
Epoch 13/100, Loss: 0.6428, Acc: 0.6316, Val Loss: 0.5921, Val Acc: 0.6846
Epoch 14/100, Loss: 0.6408, Acc: 0.6355, Val Loss: 0.5845, Val Acc: 0.6846
Epoch 15/100, Loss: 0.6398, Acc: 0.6351, Val Loss: 0.5830, Val Acc: 0.6904
Epoch 16/100, Loss: 0.6397, Acc: 0.6348, Val Loss: 0.5821, Val Acc: 0.6739
Mejor modelo guardado con Val Loss: 0.5821
Epoch 17/100, Loss: 0.6405, Acc: 0.6365, Val Loss: 0.5807, Val Acc: 0.7040
Mejor modelo guardado con Val Loss: 0.5807
Epoch 18/100, Loss: 0.6400, Acc: 0.6370, Val Loss: 0.5982, Val Acc: 0.6559
Epoch 19/100, Loss: 0.6391, Acc: 0.6359, Val Loss: 0.5789, Val Acc: 0.6882
Mejor modelo guardado con Val Loss: 0.5789
Epoch 20/100, Loss: 0.6386, Acc: 0.6342, Val Loss: 0.6096, Val Acc: 0.6195
Epoch 21/100, Loss: 0.6385, Acc: 0.6379, Val Loss: 0.5933, Val Acc: 0.6592
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6352, Acc: 0.6386, Val Loss: 0.5976, Val Acc: 0.6695
Epoch 23/100, Loss: 0.6349, Acc: 0.6383, Val Loss: 0.5866, Val Acc: 0.6548
Epoch 24/100, Loss: 0.6360, Acc: 0.6415, Val Loss: 0.5788, Val Acc: 0.6790
Mejor modelo guardado con Val Loss: 0.5788
Epoch 25/100, Loss: 0.6349, Acc: 0.6392, Val Loss: 0.5916, Val Acc: 0.6585
Epoch 26/100, Loss: 0.6352, Acc: 0.6415, Val Loss: 0.5886, Val Acc: 0.6673
Epoch 27/100, Loss: 0.6359, Acc: 0.6350, Val Loss: 0.5745, Val Acc: 0.7055
Mejor modelo guardado con Val Loss: 0.5745
Epoch 28/100, Loss: 0.6351, Acc: 0.6380, Val Loss: 0.5834, Val Acc: 0.6732
Epoch 29/100, Loss: 0.6342, Acc: 0.6423, Val Loss: 0.5941, Val Acc: 0.6511
Epoch 30/100, Loss: 0.6340, Acc: 0.6427, Val Loss: 0.5793, Val Acc: 0.6754
Epoch 31/100, Loss: 0.6339, Acc: 0.6414, Val Loss: 0.5935, Val Acc: 0.6779
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6331, Acc: 0.6421, Val Loss: 0.5828, Val Acc: 0.6662
Epoch 33/100, Loss: 0.6327, Acc: 0.6446, Val Loss: 0.5772, Val Acc: 0.6710
Epoch 34/100, Loss: 0.6328, Acc: 0.6429, Val Loss: 0.5864, Val Acc: 0.6548
Epoch 35/100, Loss: 0.6326, Acc: 0.6416, Val Loss: 0.5761, Val Acc: 0.6787
Epoch 36/100, Loss: 0.6325, Acc: 0.6416, Val Loss: 0.5798, Val Acc: 0.6820
Epoch 37/100, Loss: 0.6328, Acc: 0.6383, Val Loss: 0.5751, Val Acc: 0.6982
Epoch 38/100, Loss: 0.6321, Acc: 0.6414, Val Loss: 0.5785, Val Acc: 0.6724
Epoch 39/100, Loss: 0.6326, Acc: 0.6399, Val Loss: 0.5892, Val Acc: 0.6768
Epoch 40/100, Loss: 0.6323, Acc: 0.6421, Val Loss: 0.5766, Val Acc: 0.6757
Epoch 41/100, Loss: 0.6322, Acc: 0.6410, Val Loss: 0.5815, Val Acc: 0.6724
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6314, Acc: 0.6426, Val Loss: 0.5754, Val Acc: 0.6787
Epoch 43/100, Loss: 0.6315, Acc: 0.6434, Val Loss: 0.5799, Val Acc: 0.6713
Epoch 44/100, Loss: 0.6317, Acc: 0.6431, Val Loss: 0.5769, Val Acc: 0.6772
Epoch 45/100, Loss: 0.6314, Acc: 0.6425, Val Loss: 0.5803, Val Acc: 0.6676
Epoch 46/100, Loss: 0.6312, Acc: 0.6432, Val Loss: 0.5776, Val Acc: 0.6779
Epoch 47/100, Loss: 0.6312, Acc: 0.6410, Val Loss: 0.5782, Val Acc: 0.6702
Epoch 48/100, Loss: 0.6310, Acc: 0.6433, Val Loss: 0.5845, Val Acc: 0.6695
Epoch 49/100, Loss: 0.6312, Acc: 0.6434, Val Loss: 0.5782, Val Acc: 0.6779
Epoch 50/100, Loss: 0.6308, Acc: 0.6432, Val Loss: 0.5767, Val Acc: 0.6746
Epoch 51/100, Loss: 0.6313, Acc: 0.6416, Val Loss: 0.5818, Val Acc: 0.6647
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6307, Acc: 0.6415, Val Loss: 0.5792, Val Acc: 0.6684
Epoch 53/100, Loss: 0.6306, Acc: 0.6431, Val Loss: 0.5803, Val Acc: 0.6713
Epoch 54/100, Loss: 0.6304, Acc: 0.6438, Val Loss: 0.5754, Val Acc: 0.6772
Epoch 55/100, Loss: 0.6307, Acc: 0.6437, Val Loss: 0.5763, Val Acc: 0.6746
Epoch 56/100, Loss: 0.6306, Acc: 0.6426, Val Loss: 0.5791, Val Acc: 0.6735
Epoch 57/100, Loss: 0.6305, Acc: 0.6441, Val Loss: 0.5796, Val Acc: 0.6684
Epoch 58/100, Loss: 0.6301, Acc: 0.6429, Val Loss: 0.5775, Val Acc: 0.6757
Epoch 59/100, Loss: 0.6296, Acc: 0.6454, Val Loss: 0.5797, Val Acc: 0.6691
Epoch 60/100, Loss: 0.6294, Acc: 0.6460, Val Loss: 0.5828, Val Acc: 0.6669
Epoch 61/100, Loss: 0.6295, Acc: 0.6468, Val Loss: 0.5806, Val Acc: 0.6702
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6293, Acc: 0.6462, Val Loss: 0.5811, Val Acc: 0.6710
Epoch 63/100, Loss: 0.6292, Acc: 0.6464, Val Loss: 0.5793, Val Acc: 0.6702
Epoch 64/100, Loss: 0.6291, Acc: 0.6462, Val Loss: 0.5813, Val Acc: 0.6706
Epoch 65/100, Loss: 0.6291, Acc: 0.6460, Val Loss: 0.5809, Val Acc: 0.6695
Epoch 66/100, Loss: 0.6291, Acc: 0.6457, Val Loss: 0.5795, Val Acc: 0.6721
Epoch 67/100, Loss: 0.6291, Acc: 0.6468, Val Loss: 0.5812, Val Acc: 0.6713
Epoch 68/100, Loss: 0.6291, Acc: 0.6454, Val Loss: 0.5797, Val Acc: 0.6710
Epoch 69/100, Loss: 0.6291, Acc: 0.6460, Val Loss: 0.5791, Val Acc: 0.6743
Epoch 70/100, Loss: 0.6290, Acc: 0.6459, Val Loss: 0.5806, Val Acc: 0.6717
Epoch 71/100, Loss: 0.6290, Acc: 0.6450, Val Loss: 0.5811, Val Acc: 0.6706
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6289, Acc: 0.6461, Val Loss: 0.5804, Val Acc: 0.6713
Epoch 73/100, Loss: 0.6289, Acc: 0.6466, Val Loss: 0.5799, Val Acc: 0.6721
Epoch 74/100, Loss: 0.6289, Acc: 0.6458, Val Loss: 0.5802, Val Acc: 0.6713
Epoch 75/100, Loss: 0.6289, Acc: 0.6461, Val Loss: 0.5807, Val Acc: 0.6702
Epoch 76/100, Loss: 0.6289, Acc: 0.6465, Val Loss: 0.5803, Val Acc: 0.6721
Epoch 77/100, Loss: 0.6289, Acc: 0.6465, Val Loss: 0.5794, Val Acc: 0.6728
Epoch 78/100, Loss: 0.6288, Acc: 0.6463, Val Loss: 0.5808, Val Acc: 0.6713
Epoch 79/100, Loss: 0.6288, Acc: 0.6470, Val Loss: 0.5801, Val Acc: 0.6713
Epoch 80/100, Loss: 0.6288, Acc: 0.6447, Val Loss: 0.5798, Val Acc: 0.6717
Epoch 81/100, Loss: 0.6288, Acc: 0.6467, Val Loss: 0.5793, Val Acc: 0.6728
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6288, Acc: 0.6456, Val Loss: 0.5792, Val Acc: 0.6728
Epoch 83/100, Loss: 0.6288, Acc: 0.6466, Val Loss: 0.5801, Val Acc: 0.6710
Epoch 84/100, Loss: 0.6287, Acc: 0.6470, Val Loss: 0.5797, Val Acc: 0.6724
Epoch 85/100, Loss: 0.6287, Acc: 0.6466, Val Loss: 0.5803, Val Acc: 0.6713
Epoch 86/100, Loss: 0.6287, Acc: 0.6461, Val Loss: 0.5803, Val Acc: 0.6710
Epoch 87/100, Loss: 0.6287, Acc: 0.6466, Val Loss: 0.5804, Val Acc: 0.6710
Epoch 88/100, Loss: 0.6287, Acc: 0.6464, Val Loss: 0.5811, Val Acc: 0.6713
Epoch 89/100, Loss: 0.6287, Acc: 0.6462, Val Loss: 0.5796, Val Acc: 0.6728
Epoch 90/100, Loss: 0.6286, Acc: 0.6462, Val Loss: 0.5800, Val Acc: 0.6713
Epoch 91/100, Loss: 0.6286, Acc: 0.6469, Val Loss: 0.5812, Val Acc: 0.6691
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6286, Acc: 0.6466, Val Loss: 0.5794, Val Acc: 0.6728
Epoch 93/100, Loss: 0.6286, Acc: 0.6469, Val Loss: 0.5800, Val Acc: 0.6713
Epoch 94/100, Loss: 0.6286, Acc: 0.6460, Val Loss: 0.5803, Val Acc: 0.6713
Epoch 95/100, Loss: 0.6286, Acc: 0.6458, Val Loss: 0.5802, Val Acc: 0.6713
Epoch 96/100, Loss: 0.6285, Acc: 0.6459, Val Loss: 0.5792, Val Acc: 0.6735
Epoch 97/100, Loss: 0.6285, Acc: 0.6472, Val Loss: 0.5793, Val Acc: 0.6728
Epoch 98/100, Loss: 0.6286, Acc: 0.6463, Val Loss: 0.5794, Val Acc: 0.6732
Epoch 99/100, Loss: 0.6285, Acc: 0.6464, Val Loss: 0.5796, Val Acc: 0.6721
Epoch 100/100, Loss: 0.6285, Acc: 0.6458, Val Loss: 0.5790, Val Acc: 0.6739

##############################
Resultados para principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1 
 {'training': [0.6284972397720112, 0.6457720588235294, 0.6875591296121097, 0.534375, 0.6013653289201489], 'validate': [0.579025998711586, 0.6738970588235295, 0.6336913510457886, 0.8242647058823529, 0.7165228507510387], 'test': [0.7271682575896934, 0.5223529411764706, 0.5311475409836065, 0.3811764705882353, 0.4438356164383562]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  063  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  063  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6878, Acc: 0.5489, Val Loss: 0.7001, Val Acc: 0.4239
Mejor modelo guardado con Val Loss: 0.7001
Epoch 2/100, Loss: 0.6829, Acc: 0.5777, Val Loss: 0.7000, Val Acc: 0.4882
Mejor modelo guardado con Val Loss: 0.7000
Epoch 3/100, Loss: 0.6802, Acc: 0.5848, Val Loss: 0.7024, Val Acc: 0.4835
Epoch 4/100, Loss: 0.6771, Acc: 0.5879, Val Loss: 0.7047, Val Acc: 0.4316
Epoch 5/100, Loss: 0.6726, Acc: 0.5909, Val Loss: 0.7244, Val Acc: 0.4173
Epoch 6/100, Loss: 0.6801, Acc: 0.5799, Val Loss: 0.7012, Val Acc: 0.4915
Epoch 7/100, Loss: 0.6726, Acc: 0.5931, Val Loss: 0.7091, Val Acc: 0.4540
Epoch 8/100, Loss: 0.6701, Acc: 0.5965, Val Loss: 0.7304, Val Acc: 0.4246
Epoch 9/100, Loss: 0.6690, Acc: 0.5944, Val Loss: 0.7051, Val Acc: 0.4728
Epoch 10/100, Loss: 0.6662, Acc: 0.6000, Val Loss: 0.7392, Val Acc: 0.4235
Epoch 11/100, Loss: 0.6696, Acc: 0.5839, Val Loss: 0.7148, Val Acc: 0.4761
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6622, Acc: 0.6056, Val Loss: 0.6979, Val Acc: 0.4967
Mejor modelo guardado con Val Loss: 0.6979
Epoch 13/100, Loss: 0.6587, Acc: 0.6047, Val Loss: 0.7304, Val Acc: 0.4430
Epoch 14/100, Loss: 0.6572, Acc: 0.6063, Val Loss: 0.7046, Val Acc: 0.4813
Epoch 15/100, Loss: 0.6585, Acc: 0.6008, Val Loss: 0.7073, Val Acc: 0.4805
Epoch 16/100, Loss: 0.6547, Acc: 0.6064, Val Loss: 0.7100, Val Acc: 0.4603
Epoch 17/100, Loss: 0.6569, Acc: 0.6042, Val Loss: 0.7236, Val Acc: 0.4493
Epoch 18/100, Loss: 0.6531, Acc: 0.6109, Val Loss: 0.7097, Val Acc: 0.4779
Epoch 19/100, Loss: 0.6513, Acc: 0.6123, Val Loss: 0.7182, Val Acc: 0.4768
Epoch 20/100, Loss: 0.6533, Acc: 0.6054, Val Loss: 0.7156, Val Acc: 0.4779
Epoch 21/100, Loss: 0.6513, Acc: 0.6060, Val Loss: 0.6937, Val Acc: 0.4989
Mejor modelo guardado con Val Loss: 0.6937
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6493, Acc: 0.6097, Val Loss: 0.7141, Val Acc: 0.4768
Epoch 23/100, Loss: 0.6494, Acc: 0.6083, Val Loss: 0.7166, Val Acc: 0.4688
Epoch 24/100, Loss: 0.6487, Acc: 0.6094, Val Loss: 0.7286, Val Acc: 0.4621
Epoch 25/100, Loss: 0.6495, Acc: 0.6085, Val Loss: 0.7081, Val Acc: 0.4772
Epoch 26/100, Loss: 0.6480, Acc: 0.6107, Val Loss: 0.7062, Val Acc: 0.4882
Epoch 27/100, Loss: 0.6477, Acc: 0.6113, Val Loss: 0.7032, Val Acc: 0.4849
Epoch 28/100, Loss: 0.6471, Acc: 0.6121, Val Loss: 0.7071, Val Acc: 0.4783
Epoch 29/100, Loss: 0.6470, Acc: 0.6104, Val Loss: 0.7112, Val Acc: 0.4827
Epoch 30/100, Loss: 0.6470, Acc: 0.6125, Val Loss: 0.7141, Val Acc: 0.4761
Epoch 31/100, Loss: 0.6469, Acc: 0.6123, Val Loss: 0.7013, Val Acc: 0.4938
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6453, Acc: 0.6118, Val Loss: 0.7004, Val Acc: 0.4919
Epoch 33/100, Loss: 0.6451, Acc: 0.6137, Val Loss: 0.7089, Val Acc: 0.4761
Epoch 34/100, Loss: 0.6449, Acc: 0.6139, Val Loss: 0.7082, Val Acc: 0.4842
Epoch 35/100, Loss: 0.6444, Acc: 0.6125, Val Loss: 0.7117, Val Acc: 0.4732
Epoch 36/100, Loss: 0.6451, Acc: 0.6126, Val Loss: 0.7033, Val Acc: 0.4893
Epoch 37/100, Loss: 0.6443, Acc: 0.6200, Val Loss: 0.7089, Val Acc: 0.4901
Epoch 38/100, Loss: 0.6450, Acc: 0.6228, Val Loss: 0.6917, Val Acc: 0.5081
Mejor modelo guardado con Val Loss: 0.6917
Epoch 39/100, Loss: 0.6442, Acc: 0.6304, Val Loss: 0.7046, Val Acc: 0.5430
Epoch 40/100, Loss: 0.6440, Acc: 0.6394, Val Loss: 0.7102, Val Acc: 0.5430
Epoch 41/100, Loss: 0.6437, Acc: 0.6429, Val Loss: 0.7000, Val Acc: 0.5371
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6434, Acc: 0.6415, Val Loss: 0.7027, Val Acc: 0.5585
Epoch 43/100, Loss: 0.6433, Acc: 0.6425, Val Loss: 0.7027, Val Acc: 0.5610
Epoch 44/100, Loss: 0.6432, Acc: 0.6443, Val Loss: 0.7018, Val Acc: 0.5632
Epoch 45/100, Loss: 0.6432, Acc: 0.6438, Val Loss: 0.7092, Val Acc: 0.5574
Epoch 46/100, Loss: 0.6429, Acc: 0.6461, Val Loss: 0.6979, Val Acc: 0.5676
Epoch 47/100, Loss: 0.6430, Acc: 0.6470, Val Loss: 0.7059, Val Acc: 0.5585
Epoch 48/100, Loss: 0.6429, Acc: 0.6448, Val Loss: 0.7033, Val Acc: 0.5599
Epoch 49/100, Loss: 0.6429, Acc: 0.6436, Val Loss: 0.7035, Val Acc: 0.5695
Epoch 50/100, Loss: 0.6427, Acc: 0.6469, Val Loss: 0.7089, Val Acc: 0.5614
Epoch 51/100, Loss: 0.6425, Acc: 0.6432, Val Loss: 0.6962, Val Acc: 0.5794
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6424, Acc: 0.6480, Val Loss: 0.6998, Val Acc: 0.5699
Epoch 53/100, Loss: 0.6422, Acc: 0.6487, Val Loss: 0.7089, Val Acc: 0.5570
Epoch 54/100, Loss: 0.6424, Acc: 0.6467, Val Loss: 0.7039, Val Acc: 0.5680
Epoch 55/100, Loss: 0.6423, Acc: 0.6491, Val Loss: 0.7011, Val Acc: 0.5746
Epoch 56/100, Loss: 0.6421, Acc: 0.6467, Val Loss: 0.7018, Val Acc: 0.5735
Epoch 57/100, Loss: 0.6421, Acc: 0.6462, Val Loss: 0.7057, Val Acc: 0.5684
Epoch 58/100, Loss: 0.6421, Acc: 0.6469, Val Loss: 0.7053, Val Acc: 0.5603
Epoch 59/100, Loss: 0.6421, Acc: 0.6474, Val Loss: 0.7069, Val Acc: 0.5614
Epoch 60/100, Loss: 0.6421, Acc: 0.6460, Val Loss: 0.7023, Val Acc: 0.5629
Epoch 61/100, Loss: 0.6420, Acc: 0.6472, Val Loss: 0.7057, Val Acc: 0.5614
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6418, Acc: 0.6484, Val Loss: 0.7036, Val Acc: 0.5621
Epoch 63/100, Loss: 0.6417, Acc: 0.6483, Val Loss: 0.7052, Val Acc: 0.5665
Epoch 64/100, Loss: 0.6418, Acc: 0.6484, Val Loss: 0.7057, Val Acc: 0.5625
Epoch 65/100, Loss: 0.6417, Acc: 0.6484, Val Loss: 0.7038, Val Acc: 0.5621
Epoch 66/100, Loss: 0.6417, Acc: 0.6470, Val Loss: 0.7054, Val Acc: 0.5610
Epoch 67/100, Loss: 0.6417, Acc: 0.6475, Val Loss: 0.7025, Val Acc: 0.5643
Epoch 68/100, Loss: 0.6417, Acc: 0.6479, Val Loss: 0.7044, Val Acc: 0.5603
Epoch 69/100, Loss: 0.6416, Acc: 0.6473, Val Loss: 0.7034, Val Acc: 0.5647
Epoch 70/100, Loss: 0.6416, Acc: 0.6487, Val Loss: 0.7024, Val Acc: 0.5658
Epoch 71/100, Loss: 0.6417, Acc: 0.6479, Val Loss: 0.7034, Val Acc: 0.5643
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6415, Acc: 0.6484, Val Loss: 0.7061, Val Acc: 0.5640
Epoch 73/100, Loss: 0.6415, Acc: 0.6485, Val Loss: 0.7036, Val Acc: 0.5629
Epoch 74/100, Loss: 0.6415, Acc: 0.6490, Val Loss: 0.7039, Val Acc: 0.5603
Epoch 75/100, Loss: 0.6414, Acc: 0.6482, Val Loss: 0.7062, Val Acc: 0.5603
Epoch 76/100, Loss: 0.6414, Acc: 0.6474, Val Loss: 0.7051, Val Acc: 0.5581
Epoch 77/100, Loss: 0.6414, Acc: 0.6478, Val Loss: 0.7045, Val Acc: 0.5585
Epoch 78/100, Loss: 0.6414, Acc: 0.6483, Val Loss: 0.7048, Val Acc: 0.5559
Epoch 79/100, Loss: 0.6413, Acc: 0.6479, Val Loss: 0.7054, Val Acc: 0.5540
Epoch 80/100, Loss: 0.6412, Acc: 0.6471, Val Loss: 0.7038, Val Acc: 0.5526
Epoch 81/100, Loss: 0.6412, Acc: 0.6471, Val Loss: 0.7037, Val Acc: 0.5518
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6409, Acc: 0.6444, Val Loss: 0.7057, Val Acc: 0.5474
Epoch 83/100, Loss: 0.6408, Acc: 0.6448, Val Loss: 0.7053, Val Acc: 0.5419
Epoch 84/100, Loss: 0.6407, Acc: 0.6443, Val Loss: 0.7071, Val Acc: 0.5382
Epoch 85/100, Loss: 0.6406, Acc: 0.6432, Val Loss: 0.7065, Val Acc: 0.5324
Epoch 86/100, Loss: 0.6406, Acc: 0.6421, Val Loss: 0.7064, Val Acc: 0.5309
Epoch 87/100, Loss: 0.6405, Acc: 0.6415, Val Loss: 0.7062, Val Acc: 0.5290
Epoch 88/100, Loss: 0.6405, Acc: 0.6407, Val Loss: 0.7057, Val Acc: 0.5287
Epoch 89/100, Loss: 0.6405, Acc: 0.6399, Val Loss: 0.7059, Val Acc: 0.5287
Epoch 90/100, Loss: 0.6404, Acc: 0.6415, Val Loss: 0.7065, Val Acc: 0.5265
Epoch 91/100, Loss: 0.6404, Acc: 0.6417, Val Loss: 0.7082, Val Acc: 0.5265
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6404, Acc: 0.6428, Val Loss: 0.7070, Val Acc: 0.5287
Epoch 93/100, Loss: 0.6403, Acc: 0.6416, Val Loss: 0.7058, Val Acc: 0.5301
Epoch 94/100, Loss: 0.6403, Acc: 0.6426, Val Loss: 0.7047, Val Acc: 0.5316
Epoch 95/100, Loss: 0.6403, Acc: 0.6440, Val Loss: 0.7059, Val Acc: 0.5294
Epoch 96/100, Loss: 0.6402, Acc: 0.6425, Val Loss: 0.7059, Val Acc: 0.5287
Epoch 97/100, Loss: 0.6402, Acc: 0.6423, Val Loss: 0.7060, Val Acc: 0.5298
Epoch 98/100, Loss: 0.6401, Acc: 0.6438, Val Loss: 0.7054, Val Acc: 0.5301
Epoch 99/100, Loss: 0.6400, Acc: 0.6442, Val Loss: 0.7073, Val Acc: 0.5290
Epoch 100/100, Loss: 0.6400, Acc: 0.6428, Val Loss: 0.7072, Val Acc: 0.5276

##############################
Resultados para principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1 
 {'training': [0.6400152062668519, 0.6428308823529412, 0.6141975308641975, 0.7681985294117647, 0.6826200588043123], 'validate': [0.7071969453678575, 0.5275735294117647, 0.521713954834974, 0.6625, 0.5837382572076449], 'test': [0.7032825825390993, 0.4802941176470588, 0.4888741281966124, 0.8658823529411764, 0.6249203990660157]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  070  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  070  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6896, Acc: 0.5464, Val Loss: 0.6965, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6965
Epoch 2/100, Loss: 0.6894, Acc: 0.5359, Val Loss: 0.7020, Val Acc: 0.4996
Epoch 3/100, Loss: 0.6897, Acc: 0.5356, Val Loss: 0.7007, Val Acc: 0.4640
Epoch 4/100, Loss: 0.6917, Acc: 0.5213, Val Loss: 0.6939, Val Acc: 0.4585
Mejor modelo guardado con Val Loss: 0.6939
Epoch 5/100, Loss: 0.6933, Acc: 0.5119, Val Loss: 0.6948, Val Acc: 0.4996
Epoch 6/100, Loss: 0.6898, Acc: 0.5431, Val Loss: 0.7046, Val Acc: 0.3912
Epoch 7/100, Loss: 0.6877, Acc: 0.5627, Val Loss: 0.6960, Val Acc: 0.4908
Epoch 8/100, Loss: 0.6873, Acc: 0.5563, Val Loss: 0.7087, Val Acc: 0.3971
Epoch 9/100, Loss: 0.6861, Acc: 0.5529, Val Loss: 0.7022, Val Acc: 0.4750
Epoch 10/100, Loss: 0.6822, Acc: 0.5753, Val Loss: 0.7234, Val Acc: 0.3812
Epoch 11/100, Loss: 0.6803, Acc: 0.5795, Val Loss: 0.7291, Val Acc: 0.3816
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6765, Acc: 0.5877, Val Loss: 0.7252, Val Acc: 0.4000
Epoch 13/100, Loss: 0.6749, Acc: 0.5893, Val Loss: 0.7171, Val Acc: 0.4386
Epoch 14/100, Loss: 0.6746, Acc: 0.5884, Val Loss: 0.7394, Val Acc: 0.3621
Epoch 15/100, Loss: 0.6736, Acc: 0.5915, Val Loss: 0.7334, Val Acc: 0.3897
Epoch 16/100, Loss: 0.6721, Acc: 0.5931, Val Loss: 0.7503, Val Acc: 0.3555
Epoch 17/100, Loss: 0.6723, Acc: 0.5926, Val Loss: 0.7376, Val Acc: 0.3596
Epoch 18/100, Loss: 0.6723, Acc: 0.5909, Val Loss: 0.7458, Val Acc: 0.3757
Epoch 19/100, Loss: 0.6717, Acc: 0.5919, Val Loss: 0.7510, Val Acc: 0.3746
Epoch 20/100, Loss: 0.6701, Acc: 0.5954, Val Loss: 0.7317, Val Acc: 0.3853
Epoch 21/100, Loss: 0.6696, Acc: 0.5991, Val Loss: 0.7518, Val Acc: 0.3886
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6692, Acc: 0.5975, Val Loss: 0.7379, Val Acc: 0.4228
Epoch 23/100, Loss: 0.6690, Acc: 0.5997, Val Loss: 0.7521, Val Acc: 0.3904
Epoch 24/100, Loss: 0.6679, Acc: 0.6006, Val Loss: 0.7605, Val Acc: 0.3732
Epoch 25/100, Loss: 0.6677, Acc: 0.5999, Val Loss: 0.7621, Val Acc: 0.3724
Epoch 26/100, Loss: 0.6684, Acc: 0.5959, Val Loss: 0.7565, Val Acc: 0.3754
Epoch 27/100, Loss: 0.6666, Acc: 0.6066, Val Loss: 0.7362, Val Acc: 0.4371
Epoch 28/100, Loss: 0.6672, Acc: 0.6003, Val Loss: 0.7508, Val Acc: 0.3945
Epoch 29/100, Loss: 0.6669, Acc: 0.6008, Val Loss: 0.7544, Val Acc: 0.3923
Epoch 30/100, Loss: 0.6663, Acc: 0.5998, Val Loss: 0.7582, Val Acc: 0.3879
Epoch 31/100, Loss: 0.6652, Acc: 0.6042, Val Loss: 0.7636, Val Acc: 0.3482
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6648, Acc: 0.6030, Val Loss: 0.7600, Val Acc: 0.3842
Epoch 33/100, Loss: 0.6648, Acc: 0.6027, Val Loss: 0.7657, Val Acc: 0.3695
Epoch 34/100, Loss: 0.6645, Acc: 0.6059, Val Loss: 0.7572, Val Acc: 0.3812
Epoch 35/100, Loss: 0.6644, Acc: 0.6031, Val Loss: 0.7603, Val Acc: 0.3974
Epoch 36/100, Loss: 0.6642, Acc: 0.6069, Val Loss: 0.7620, Val Acc: 0.3779
Epoch 37/100, Loss: 0.6641, Acc: 0.6054, Val Loss: 0.7583, Val Acc: 0.3827
Epoch 38/100, Loss: 0.6641, Acc: 0.6043, Val Loss: 0.7539, Val Acc: 0.4140
Epoch 39/100, Loss: 0.6637, Acc: 0.6051, Val Loss: 0.7638, Val Acc: 0.3849
Epoch 40/100, Loss: 0.6634, Acc: 0.6056, Val Loss: 0.7569, Val Acc: 0.3996
Epoch 41/100, Loss: 0.6635, Acc: 0.6048, Val Loss: 0.7558, Val Acc: 0.3967
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6633, Acc: 0.6041, Val Loss: 0.7684, Val Acc: 0.3772
Epoch 43/100, Loss: 0.6630, Acc: 0.6074, Val Loss: 0.7597, Val Acc: 0.3974
Epoch 44/100, Loss: 0.6631, Acc: 0.6040, Val Loss: 0.7602, Val Acc: 0.3930
Epoch 45/100, Loss: 0.6628, Acc: 0.6090, Val Loss: 0.7747, Val Acc: 0.3691
Epoch 46/100, Loss: 0.6634, Acc: 0.6051, Val Loss: 0.7675, Val Acc: 0.3750
Epoch 47/100, Loss: 0.6628, Acc: 0.6083, Val Loss: 0.7668, Val Acc: 0.3787
Epoch 48/100, Loss: 0.6627, Acc: 0.6063, Val Loss: 0.7742, Val Acc: 0.3643
Epoch 49/100, Loss: 0.6628, Acc: 0.6079, Val Loss: 0.7667, Val Acc: 0.3890
Epoch 50/100, Loss: 0.6627, Acc: 0.6079, Val Loss: 0.7690, Val Acc: 0.3835
Epoch 51/100, Loss: 0.6628, Acc: 0.6060, Val Loss: 0.7649, Val Acc: 0.3886
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6625, Acc: 0.6086, Val Loss: 0.7659, Val Acc: 0.3849
Epoch 53/100, Loss: 0.6624, Acc: 0.6098, Val Loss: 0.7695, Val Acc: 0.3776
Epoch 54/100, Loss: 0.6625, Acc: 0.6072, Val Loss: 0.7644, Val Acc: 0.3886
Epoch 55/100, Loss: 0.6624, Acc: 0.6085, Val Loss: 0.7692, Val Acc: 0.3772
Epoch 56/100, Loss: 0.6623, Acc: 0.6088, Val Loss: 0.7611, Val Acc: 0.3890
Epoch 57/100, Loss: 0.6625, Acc: 0.6089, Val Loss: 0.7638, Val Acc: 0.3893
Epoch 58/100, Loss: 0.6623, Acc: 0.6082, Val Loss: 0.7663, Val Acc: 0.3857
Epoch 59/100, Loss: 0.6623, Acc: 0.6081, Val Loss: 0.7672, Val Acc: 0.3820
Epoch 60/100, Loss: 0.6622, Acc: 0.6071, Val Loss: 0.7677, Val Acc: 0.3812
Epoch 61/100, Loss: 0.6622, Acc: 0.6077, Val Loss: 0.7695, Val Acc: 0.3768
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6622, Acc: 0.6074, Val Loss: 0.7671, Val Acc: 0.3816
Epoch 63/100, Loss: 0.6621, Acc: 0.6086, Val Loss: 0.7656, Val Acc: 0.3871
Epoch 64/100, Loss: 0.6621, Acc: 0.6079, Val Loss: 0.7680, Val Acc: 0.3820
Epoch 65/100, Loss: 0.6622, Acc: 0.6092, Val Loss: 0.7665, Val Acc: 0.3838
Epoch 66/100, Loss: 0.6620, Acc: 0.6091, Val Loss: 0.7673, Val Acc: 0.3809
Epoch 67/100, Loss: 0.6620, Acc: 0.6091, Val Loss: 0.7659, Val Acc: 0.3879
Epoch 68/100, Loss: 0.6620, Acc: 0.6085, Val Loss: 0.7680, Val Acc: 0.3820
Epoch 69/100, Loss: 0.6620, Acc: 0.6087, Val Loss: 0.7667, Val Acc: 0.3849
Epoch 70/100, Loss: 0.6620, Acc: 0.6088, Val Loss: 0.7673, Val Acc: 0.3816
Epoch 71/100, Loss: 0.6620, Acc: 0.6085, Val Loss: 0.7648, Val Acc: 0.3901
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6620, Acc: 0.6096, Val Loss: 0.7666, Val Acc: 0.3849
Epoch 73/100, Loss: 0.6619, Acc: 0.6094, Val Loss: 0.7678, Val Acc: 0.3812
Epoch 74/100, Loss: 0.6620, Acc: 0.6086, Val Loss: 0.7659, Val Acc: 0.3879
Epoch 75/100, Loss: 0.6619, Acc: 0.6096, Val Loss: 0.7665, Val Acc: 0.3849
Epoch 76/100, Loss: 0.6619, Acc: 0.6100, Val Loss: 0.7670, Val Acc: 0.3849
Epoch 77/100, Loss: 0.6619, Acc: 0.6102, Val Loss: 0.7665, Val Acc: 0.3838
Epoch 78/100, Loss: 0.6619, Acc: 0.6087, Val Loss: 0.7667, Val Acc: 0.3853
Epoch 79/100, Loss: 0.6619, Acc: 0.6092, Val Loss: 0.7668, Val Acc: 0.3853
Epoch 80/100, Loss: 0.6619, Acc: 0.6087, Val Loss: 0.7672, Val Acc: 0.3831
Epoch 81/100, Loss: 0.6619, Acc: 0.6086, Val Loss: 0.7657, Val Acc: 0.3879
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6619, Acc: 0.6097, Val Loss: 0.7678, Val Acc: 0.3812
Epoch 83/100, Loss: 0.6619, Acc: 0.6098, Val Loss: 0.7674, Val Acc: 0.3831
Epoch 84/100, Loss: 0.6618, Acc: 0.6101, Val Loss: 0.7669, Val Acc: 0.3853
Epoch 85/100, Loss: 0.6619, Acc: 0.6085, Val Loss: 0.7664, Val Acc: 0.3875
Epoch 86/100, Loss: 0.6618, Acc: 0.6096, Val Loss: 0.7672, Val Acc: 0.3849
Epoch 87/100, Loss: 0.6618, Acc: 0.6093, Val Loss: 0.7673, Val Acc: 0.3831
Epoch 88/100, Loss: 0.6618, Acc: 0.6082, Val Loss: 0.7668, Val Acc: 0.3842
Epoch 89/100, Loss: 0.6618, Acc: 0.6097, Val Loss: 0.7680, Val Acc: 0.3816
Epoch 90/100, Loss: 0.6618, Acc: 0.6085, Val Loss: 0.7683, Val Acc: 0.3812
Epoch 91/100, Loss: 0.6618, Acc: 0.6100, Val Loss: 0.7685, Val Acc: 0.3812
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6618, Acc: 0.6086, Val Loss: 0.7678, Val Acc: 0.3816
Epoch 93/100, Loss: 0.6618, Acc: 0.6093, Val Loss: 0.7678, Val Acc: 0.3820
Epoch 94/100, Loss: 0.6618, Acc: 0.6085, Val Loss: 0.7672, Val Acc: 0.3835
Epoch 95/100, Loss: 0.6618, Acc: 0.6092, Val Loss: 0.7682, Val Acc: 0.3812
Epoch 96/100, Loss: 0.6618, Acc: 0.6080, Val Loss: 0.7683, Val Acc: 0.3809
Epoch 97/100, Loss: 0.6617, Acc: 0.6090, Val Loss: 0.7679, Val Acc: 0.3835
Epoch 98/100, Loss: 0.6618, Acc: 0.6093, Val Loss: 0.7682, Val Acc: 0.3816
Epoch 99/100, Loss: 0.6617, Acc: 0.6089, Val Loss: 0.7681, Val Acc: 0.3824
Epoch 100/100, Loss: 0.6617, Acc: 0.6090, Val Loss: 0.7681, Val Acc: 0.3816

##############################
Resultados para principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1 
 {'training': [0.6617366387563594, 0.6090073529411765, 0.6301009214567793, 0.5279411764705882, 0.5745149029805962], 'validate': [0.7681273083354152, 0.3816176470588235, 0.3475378787878788, 0.2698529411764706, 0.3038079470198676], 'test': [0.692205074760649, 0.4938235294117647, 0.4967642526964561, 0.9482352941176471, 0.6519716885743175]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  040  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  040  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6902, Acc: 0.5338, Val Loss: 0.6866, Val Acc: 0.5691
Mejor modelo guardado con Val Loss: 0.6866
Epoch 2/100, Loss: 0.6925, Acc: 0.5090, Val Loss: 0.6909, Val Acc: 0.5570
Epoch 3/100, Loss: 0.6931, Acc: 0.5034, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 4/100, Loss: 0.6934, Acc: 0.4932, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 5/100, Loss: 0.6935, Acc: 0.4958, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 6/100, Loss: 0.6935, Acc: 0.4969, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6935, Acc: 0.4973, Val Loss: 0.6931, Val Acc: 0.5099
Epoch 8/100, Loss: 0.6934, Acc: 0.4926, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6939, Acc: 0.4912, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 10/100, Loss: 0.6934, Acc: 0.5013, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 11/100, Loss: 0.6933, Acc: 0.4969, Val Loss: 0.6936, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4978, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6933, Acc: 0.5022, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6933, Acc: 0.4902, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6932, Acc: 0.5033, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 16/100, Loss: 0.6933, Acc: 0.4910, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6933, Acc: 0.4938, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 18/100, Loss: 0.6933, Acc: 0.4986, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 19/100, Loss: 0.6933, Acc: 0.4989, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 20/100, Loss: 0.6932, Acc: 0.5015, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 21/100, Loss: 0.6932, Acc: 0.4996, Val Loss: 0.6932, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4983, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 23/100, Loss: 0.6932, Acc: 0.4968, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 24/100, Loss: 0.6932, Acc: 0.4956, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 25/100, Loss: 0.6932, Acc: 0.4921, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 26/100, Loss: 0.6932, Acc: 0.4956, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 27/100, Loss: 0.6932, Acc: 0.4987, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 28/100, Loss: 0.6932, Acc: 0.4917, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 29/100, Loss: 0.6932, Acc: 0.4994, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 30/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 31/100, Loss: 0.6933, Acc: 0.4993, Val Loss: 0.6933, Val Acc: 0.5000
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4943, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 33/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 34/100, Loss: 0.6932, Acc: 0.4980, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 35/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 36/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 37/100, Loss: 0.6932, Acc: 0.4974, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 38/100, Loss: 0.6932, Acc: 0.4955, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 39/100, Loss: 0.6932, Acc: 0.4890, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 40/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 41/100, Loss: 0.6932, Acc: 0.4963, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.4969, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 43/100, Loss: 0.6932, Acc: 0.4922, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 44/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 45/100, Loss: 0.6931, Acc: 0.4991, Val Loss: 0.6920, Val Acc: 0.5000
Epoch 46/100, Loss: 0.6929, Acc: 0.5207, Val Loss: 0.6920, Val Acc: 0.5886
Epoch 47/100, Loss: 0.6927, Acc: 0.5318, Val Loss: 0.6918, Val Acc: 0.5960
Epoch 48/100, Loss: 0.6927, Acc: 0.5293, Val Loss: 0.6917, Val Acc: 0.5985
Epoch 49/100, Loss: 0.6926, Acc: 0.5381, Val Loss: 0.6916, Val Acc: 0.5993
Epoch 50/100, Loss: 0.6925, Acc: 0.5403, Val Loss: 0.6914, Val Acc: 0.6059
Epoch 51/100, Loss: 0.6924, Acc: 0.5467, Val Loss: 0.6912, Val Acc: 0.6018
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6923, Acc: 0.5494, Val Loss: 0.6911, Val Acc: 0.6081
Epoch 53/100, Loss: 0.6922, Acc: 0.5512, Val Loss: 0.6911, Val Acc: 0.6026
Epoch 54/100, Loss: 0.6922, Acc: 0.5518, Val Loss: 0.6910, Val Acc: 0.6081
Epoch 55/100, Loss: 0.6921, Acc: 0.5510, Val Loss: 0.6909, Val Acc: 0.6044
Epoch 56/100, Loss: 0.6921, Acc: 0.5513, Val Loss: 0.6908, Val Acc: 0.6077
Epoch 57/100, Loss: 0.6920, Acc: 0.5540, Val Loss: 0.6907, Val Acc: 0.6074
Epoch 58/100, Loss: 0.6920, Acc: 0.5535, Val Loss: 0.6906, Val Acc: 0.6096
Epoch 59/100, Loss: 0.6919, Acc: 0.5551, Val Loss: 0.6905, Val Acc: 0.6096
Epoch 60/100, Loss: 0.6919, Acc: 0.5529, Val Loss: 0.6904, Val Acc: 0.6074
Epoch 61/100, Loss: 0.6917, Acc: 0.5600, Val Loss: 0.6902, Val Acc: 0.6070
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6915, Acc: 0.5590, Val Loss: 0.6900, Val Acc: 0.6085
Epoch 63/100, Loss: 0.6914, Acc: 0.5598, Val Loss: 0.6899, Val Acc: 0.6022
Epoch 64/100, Loss: 0.6914, Acc: 0.5601, Val Loss: 0.6899, Val Acc: 0.6018
Epoch 65/100, Loss: 0.6913, Acc: 0.5633, Val Loss: 0.6898, Val Acc: 0.6066
Epoch 66/100, Loss: 0.6913, Acc: 0.5630, Val Loss: 0.6898, Val Acc: 0.6051
Epoch 67/100, Loss: 0.6913, Acc: 0.5623, Val Loss: 0.6897, Val Acc: 0.6066
Epoch 68/100, Loss: 0.6912, Acc: 0.5619, Val Loss: 0.6895, Val Acc: 0.6059
Epoch 69/100, Loss: 0.6912, Acc: 0.5610, Val Loss: 0.6895, Val Acc: 0.6066
Epoch 70/100, Loss: 0.6911, Acc: 0.5644, Val Loss: 0.6894, Val Acc: 0.6081
Epoch 71/100, Loss: 0.6911, Acc: 0.5626, Val Loss: 0.6892, Val Acc: 0.6096
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6910, Acc: 0.5641, Val Loss: 0.6892, Val Acc: 0.6096
Epoch 73/100, Loss: 0.6909, Acc: 0.5642, Val Loss: 0.6890, Val Acc: 0.6140
Epoch 74/100, Loss: 0.6908, Acc: 0.5625, Val Loss: 0.6889, Val Acc: 0.6096
Epoch 75/100, Loss: 0.6907, Acc: 0.5595, Val Loss: 0.6889, Val Acc: 0.5860
Epoch 76/100, Loss: 0.6906, Acc: 0.5477, Val Loss: 0.6888, Val Acc: 0.5801
Epoch 77/100, Loss: 0.6905, Acc: 0.5497, Val Loss: 0.6887, Val Acc: 0.5779
Epoch 78/100, Loss: 0.6904, Acc: 0.5519, Val Loss: 0.6885, Val Acc: 0.5842
Epoch 79/100, Loss: 0.6904, Acc: 0.5496, Val Loss: 0.6885, Val Acc: 0.5757
Epoch 80/100, Loss: 0.6903, Acc: 0.5506, Val Loss: 0.6884, Val Acc: 0.5864
Epoch 81/100, Loss: 0.6903, Acc: 0.5535, Val Loss: 0.6882, Val Acc: 0.5926
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6902, Acc: 0.5591, Val Loss: 0.6882, Val Acc: 0.5875
Epoch 83/100, Loss: 0.6900, Acc: 0.5630, Val Loss: 0.6881, Val Acc: 0.5941
Epoch 84/100, Loss: 0.6899, Acc: 0.5601, Val Loss: 0.6880, Val Acc: 0.5996
Epoch 85/100, Loss: 0.6898, Acc: 0.5648, Val Loss: 0.6879, Val Acc: 0.5974
Epoch 86/100, Loss: 0.6897, Acc: 0.5623, Val Loss: 0.6879, Val Acc: 0.5949
Epoch 87/100, Loss: 0.6897, Acc: 0.5671, Val Loss: 0.6879, Val Acc: 0.5901
Epoch 88/100, Loss: 0.6896, Acc: 0.5628, Val Loss: 0.6877, Val Acc: 0.5941
Epoch 89/100, Loss: 0.6896, Acc: 0.5612, Val Loss: 0.6876, Val Acc: 0.5934
Epoch 90/100, Loss: 0.6896, Acc: 0.5648, Val Loss: 0.6875, Val Acc: 0.5934
Epoch 91/100, Loss: 0.6895, Acc: 0.5636, Val Loss: 0.6874, Val Acc: 0.5982
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6894, Acc: 0.5640, Val Loss: 0.6873, Val Acc: 0.5956
Epoch 93/100, Loss: 0.6894, Acc: 0.5657, Val Loss: 0.6871, Val Acc: 0.5996
Epoch 94/100, Loss: 0.6887, Acc: 0.5731, Val Loss: 0.6871, Val Acc: 0.5967
Epoch 95/100, Loss: 0.6879, Acc: 0.5769, Val Loss: 0.6870, Val Acc: 0.5926
Epoch 96/100, Loss: 0.6878, Acc: 0.5785, Val Loss: 0.6869, Val Acc: 0.5952
Epoch 97/100, Loss: 0.6877, Acc: 0.5778, Val Loss: 0.6868, Val Acc: 0.5960
Epoch 98/100, Loss: 0.6876, Acc: 0.5781, Val Loss: 0.6867, Val Acc: 0.5960
Epoch 99/100, Loss: 0.6875, Acc: 0.5774, Val Loss: 0.6866, Val Acc: 0.5963
Mejor modelo guardado con Val Loss: 0.6866
Epoch 100/100, Loss: 0.6874, Acc: 0.5772, Val Loss: 0.6865, Val Acc: 0.5967
Mejor modelo guardado con Val Loss: 0.6865

##############################
Resultados para principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  1 
 {'training': [0.6874182445161483, 0.5772058823529411, 0.5828729281767956, 0.5430147058823529, 0.5622382946326608], 'validate': [0.6864619296650554, 0.5966911764705882, 0.604117181314331, 0.5610294117647059, 0.5817765916889058], 'test': [0.6870031180205168, 0.5935294117647059, 0.5865070729053319, 0.6341176470588236, 0.609383832673827]}

##############################
Resultados para window:  1 
 {'095:065:013:063:070:040': {'training': [0.6748934037545148, 0.592922794117647, 0.5797192871786785, 0.6757352941176471, 0.6240556828792123], 'validate': [0.669317131818727, 0.6220588235294118, 0.6182336182336182, 0.638235294117647, 0.6280752532561505], 'test': [0.6676005003628908, 0.6258823529411764, 0.6203599550056242, 0.6488235294117647, 0.6342725704427832]}, '065:095:013:063:070:040': {'training': [0.6925777775399825, 0.5056066176470588, 0.504832831563936, 0.5856617647058824, 0.5422517232575951], 'validate': [0.6940497381742611, 0.4525735294117647, 0.46422628951747086, 0.6154411764705883, 0.5292443882390135], 'test': [0.6930230767638595, 0.5, 0.0, 0.0, 0.0]}, '013:095:065:063:070:040': {'training': [0.6284972397720112, 0.6457720588235294, 0.6875591296121097, 0.534375, 0.6013653289201489], 'validate': [0.579025998711586, 0.6738970588235295, 0.6336913510457886, 0.8242647058823529, 0.7165228507510387], 'test': [0.7271682575896934, 0.5223529411764706, 0.5311475409836065, 0.3811764705882353, 0.4438356164383562]}, '063:095:065:013:070:040': {'training': [0.6400152062668519, 0.6428308823529412, 0.6141975308641975, 0.7681985294117647, 0.6826200588043123], 'validate': [0.7071969453678575, 0.5275735294117647, 0.521713954834974, 0.6625, 0.5837382572076449], 'test': [0.7032825825390993, 0.4802941176470588, 0.4888741281966124, 0.8658823529411764, 0.6249203990660157]}, '070:095:065:013:063:040': {'training': [0.6617366387563594, 0.6090073529411765, 0.6301009214567793, 0.5279411764705882, 0.5745149029805962], 'validate': [0.7681273083354152, 0.3816176470588235, 0.3475378787878788, 0.2698529411764706, 0.3038079470198676], 'test': [0.692205074760649, 0.4938235294117647, 0.4967642526964561, 0.9482352941176471, 0.6519716885743175]}, '040:095:065:013:063:070': {'training': [0.6874182445161483, 0.5772058823529411, 0.5828729281767956, 0.5430147058823529, 0.5622382946326608], 'validate': [0.6864619296650554, 0.5966911764705882, 0.604117181314331, 0.5610294117647059, 0.5817765916889058], 'test': [0.6870031180205168, 0.5935294117647059, 0.5865070729053319, 0.6341176470588236, 0.609383832673827]}}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  102  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  102  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6209, Acc: 0.6790, Val Loss: 0.3960, Val Acc: 0.9511
Mejor modelo guardado con Val Loss: 0.3960
Epoch 2/100, Loss: 0.5698, Acc: 0.7195, Val Loss: 0.3386, Val Acc: 0.9426
Mejor modelo guardado con Val Loss: 0.3386
Epoch 3/100, Loss: 0.5537, Acc: 0.7217, Val Loss: 0.3006, Val Acc: 0.9404
Mejor modelo guardado con Val Loss: 0.3006
Epoch 4/100, Loss: 0.5486, Acc: 0.7253, Val Loss: 0.2945, Val Acc: 0.9419
Mejor modelo guardado con Val Loss: 0.2945
Epoch 5/100, Loss: 0.5460, Acc: 0.7257, Val Loss: 0.2929, Val Acc: 0.9121
Mejor modelo guardado con Val Loss: 0.2929
Epoch 6/100, Loss: 0.5419, Acc: 0.7283, Val Loss: 0.2685, Val Acc: 0.9393
Mejor modelo guardado con Val Loss: 0.2685
Epoch 7/100, Loss: 0.5372, Acc: 0.7332, Val Loss: 0.2437, Val Acc: 0.9419
Mejor modelo guardado con Val Loss: 0.2437
Epoch 8/100, Loss: 0.5438, Acc: 0.7272, Val Loss: 0.2644, Val Acc: 0.9290
Epoch 9/100, Loss: 0.5396, Acc: 0.7305, Val Loss: 0.2729, Val Acc: 0.9187
Epoch 10/100, Loss: 0.5395, Acc: 0.7301, Val Loss: 0.2237, Val Acc: 0.9449
Mejor modelo guardado con Val Loss: 0.2237
Epoch 11/100, Loss: 0.5358, Acc: 0.7341, Val Loss: 0.2467, Val Acc: 0.9368
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5297, Acc: 0.7395, Val Loss: 0.2380, Val Acc: 0.9335
Epoch 13/100, Loss: 0.5266, Acc: 0.7406, Val Loss: 0.2465, Val Acc: 0.9254
Epoch 14/100, Loss: 0.5247, Acc: 0.7406, Val Loss: 0.2439, Val Acc: 0.9346
Epoch 15/100, Loss: 0.5246, Acc: 0.7400, Val Loss: 0.2476, Val Acc: 0.9195
Epoch 16/100, Loss: 0.5248, Acc: 0.7420, Val Loss: 0.2314, Val Acc: 0.9316
Epoch 17/100, Loss: 0.5244, Acc: 0.7394, Val Loss: 0.2380, Val Acc: 0.9298
Epoch 18/100, Loss: 0.5236, Acc: 0.7445, Val Loss: 0.2653, Val Acc: 0.9169
Epoch 19/100, Loss: 0.5229, Acc: 0.7429, Val Loss: 0.2447, Val Acc: 0.9301
Epoch 20/100, Loss: 0.5203, Acc: 0.7403, Val Loss: 0.2748, Val Acc: 0.9107
Epoch 21/100, Loss: 0.5217, Acc: 0.7443, Val Loss: 0.2380, Val Acc: 0.9290
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5193, Acc: 0.7424, Val Loss: 0.2299, Val Acc: 0.9287
Epoch 23/100, Loss: 0.5177, Acc: 0.7449, Val Loss: 0.2403, Val Acc: 0.9309
Epoch 24/100, Loss: 0.5167, Acc: 0.7459, Val Loss: 0.2347, Val Acc: 0.9331
Epoch 25/100, Loss: 0.5155, Acc: 0.7497, Val Loss: 0.2271, Val Acc: 0.9283
Epoch 26/100, Loss: 0.5137, Acc: 0.7486, Val Loss: 0.2187, Val Acc: 0.9290
Mejor modelo guardado con Val Loss: 0.2187
Epoch 27/100, Loss: 0.5134, Acc: 0.7469, Val Loss: 0.2403, Val Acc: 0.9320
Epoch 28/100, Loss: 0.5116, Acc: 0.7517, Val Loss: 0.2509, Val Acc: 0.9239
Epoch 29/100, Loss: 0.5118, Acc: 0.7505, Val Loss: 0.2306, Val Acc: 0.9235
Epoch 30/100, Loss: 0.5111, Acc: 0.7512, Val Loss: 0.2397, Val Acc: 0.9272
Epoch 31/100, Loss: 0.5099, Acc: 0.7497, Val Loss: 0.2247, Val Acc: 0.9283
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5078, Acc: 0.7542, Val Loss: 0.2441, Val Acc: 0.9199
Epoch 33/100, Loss: 0.5070, Acc: 0.7517, Val Loss: 0.2314, Val Acc: 0.9235
Epoch 34/100, Loss: 0.5073, Acc: 0.7506, Val Loss: 0.2265, Val Acc: 0.9217
Epoch 35/100, Loss: 0.5064, Acc: 0.7516, Val Loss: 0.2285, Val Acc: 0.9243
Epoch 36/100, Loss: 0.5056, Acc: 0.7533, Val Loss: 0.2302, Val Acc: 0.9276
Epoch 37/100, Loss: 0.5048, Acc: 0.7519, Val Loss: 0.2305, Val Acc: 0.9202
Epoch 38/100, Loss: 0.5052, Acc: 0.7546, Val Loss: 0.2302, Val Acc: 0.9224
Epoch 39/100, Loss: 0.5048, Acc: 0.7538, Val Loss: 0.2423, Val Acc: 0.9158
Epoch 40/100, Loss: 0.5035, Acc: 0.7562, Val Loss: 0.2264, Val Acc: 0.9210
Epoch 41/100, Loss: 0.5037, Acc: 0.7551, Val Loss: 0.2243, Val Acc: 0.9235
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5018, Acc: 0.7562, Val Loss: 0.2339, Val Acc: 0.9187
Epoch 43/100, Loss: 0.5016, Acc: 0.7558, Val Loss: 0.2323, Val Acc: 0.9199
Epoch 44/100, Loss: 0.5015, Acc: 0.7560, Val Loss: 0.2321, Val Acc: 0.9199
Epoch 45/100, Loss: 0.5014, Acc: 0.7572, Val Loss: 0.2273, Val Acc: 0.9254
Epoch 46/100, Loss: 0.5012, Acc: 0.7567, Val Loss: 0.2318, Val Acc: 0.9195
Epoch 47/100, Loss: 0.5006, Acc: 0.7569, Val Loss: 0.2311, Val Acc: 0.9206
Epoch 48/100, Loss: 0.5004, Acc: 0.7569, Val Loss: 0.2393, Val Acc: 0.9187
Epoch 49/100, Loss: 0.5001, Acc: 0.7586, Val Loss: 0.2366, Val Acc: 0.9187
Epoch 50/100, Loss: 0.4999, Acc: 0.7570, Val Loss: 0.2394, Val Acc: 0.9165
Epoch 51/100, Loss: 0.4996, Acc: 0.7582, Val Loss: 0.2362, Val Acc: 0.9195
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4989, Acc: 0.7581, Val Loss: 0.2310, Val Acc: 0.9199
Epoch 53/100, Loss: 0.4987, Acc: 0.7575, Val Loss: 0.2388, Val Acc: 0.9184
Epoch 54/100, Loss: 0.4986, Acc: 0.7591, Val Loss: 0.2303, Val Acc: 0.9187
Epoch 55/100, Loss: 0.4983, Acc: 0.7594, Val Loss: 0.2307, Val Acc: 0.9195
Epoch 56/100, Loss: 0.4980, Acc: 0.7586, Val Loss: 0.2385, Val Acc: 0.9180
Epoch 57/100, Loss: 0.4982, Acc: 0.7583, Val Loss: 0.2325, Val Acc: 0.9191
Epoch 58/100, Loss: 0.4980, Acc: 0.7579, Val Loss: 0.2327, Val Acc: 0.9184
Epoch 59/100, Loss: 0.4981, Acc: 0.7580, Val Loss: 0.2355, Val Acc: 0.9184
Epoch 60/100, Loss: 0.4978, Acc: 0.7582, Val Loss: 0.2295, Val Acc: 0.9195
Epoch 61/100, Loss: 0.4978, Acc: 0.7580, Val Loss: 0.2308, Val Acc: 0.9195
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4973, Acc: 0.7583, Val Loss: 0.2307, Val Acc: 0.9184
Epoch 63/100, Loss: 0.4971, Acc: 0.7585, Val Loss: 0.2303, Val Acc: 0.9195
Epoch 64/100, Loss: 0.4970, Acc: 0.7587, Val Loss: 0.2291, Val Acc: 0.9213
Epoch 65/100, Loss: 0.4971, Acc: 0.7577, Val Loss: 0.2307, Val Acc: 0.9180
Epoch 66/100, Loss: 0.4968, Acc: 0.7590, Val Loss: 0.2339, Val Acc: 0.9187
Epoch 67/100, Loss: 0.4968, Acc: 0.7594, Val Loss: 0.2288, Val Acc: 0.9187
Epoch 68/100, Loss: 0.4967, Acc: 0.7594, Val Loss: 0.2286, Val Acc: 0.9235
Epoch 69/100, Loss: 0.4967, Acc: 0.7588, Val Loss: 0.2309, Val Acc: 0.9187
Epoch 70/100, Loss: 0.4965, Acc: 0.7589, Val Loss: 0.2340, Val Acc: 0.9191
Epoch 71/100, Loss: 0.4965, Acc: 0.7598, Val Loss: 0.2298, Val Acc: 0.9187
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4962, Acc: 0.7592, Val Loss: 0.2318, Val Acc: 0.9195
Epoch 73/100, Loss: 0.4962, Acc: 0.7597, Val Loss: 0.2295, Val Acc: 0.9191
Epoch 74/100, Loss: 0.4961, Acc: 0.7592, Val Loss: 0.2322, Val Acc: 0.9195
Epoch 75/100, Loss: 0.4961, Acc: 0.7586, Val Loss: 0.2306, Val Acc: 0.9199
Epoch 76/100, Loss: 0.4961, Acc: 0.7585, Val Loss: 0.2314, Val Acc: 0.9191
Epoch 77/100, Loss: 0.4961, Acc: 0.7591, Val Loss: 0.2302, Val Acc: 0.9187
Epoch 78/100, Loss: 0.4960, Acc: 0.7598, Val Loss: 0.2305, Val Acc: 0.9184
Epoch 79/100, Loss: 0.4960, Acc: 0.7592, Val Loss: 0.2312, Val Acc: 0.9195
Epoch 80/100, Loss: 0.4960, Acc: 0.7590, Val Loss: 0.2322, Val Acc: 0.9187
Epoch 81/100, Loss: 0.4959, Acc: 0.7599, Val Loss: 0.2320, Val Acc: 0.9191
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4959, Acc: 0.7603, Val Loss: 0.2312, Val Acc: 0.9195
Epoch 83/100, Loss: 0.4958, Acc: 0.7590, Val Loss: 0.2304, Val Acc: 0.9195
Epoch 84/100, Loss: 0.4957, Acc: 0.7590, Val Loss: 0.2303, Val Acc: 0.9199
Epoch 85/100, Loss: 0.4957, Acc: 0.7597, Val Loss: 0.2310, Val Acc: 0.9195
Epoch 86/100, Loss: 0.4957, Acc: 0.7587, Val Loss: 0.2312, Val Acc: 0.9187
Epoch 87/100, Loss: 0.4956, Acc: 0.7597, Val Loss: 0.2315, Val Acc: 0.9191
Epoch 88/100, Loss: 0.4956, Acc: 0.7586, Val Loss: 0.2313, Val Acc: 0.9187
Epoch 89/100, Loss: 0.4955, Acc: 0.7585, Val Loss: 0.2320, Val Acc: 0.9187
Epoch 90/100, Loss: 0.4954, Acc: 0.7597, Val Loss: 0.2332, Val Acc: 0.9191
Epoch 91/100, Loss: 0.4953, Acc: 0.7593, Val Loss: 0.2325, Val Acc: 0.9184
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4953, Acc: 0.7608, Val Loss: 0.2313, Val Acc: 0.9199
Epoch 93/100, Loss: 0.4952, Acc: 0.7596, Val Loss: 0.2325, Val Acc: 0.9180
Epoch 94/100, Loss: 0.4951, Acc: 0.7593, Val Loss: 0.2329, Val Acc: 0.9184
Epoch 95/100, Loss: 0.4950, Acc: 0.7608, Val Loss: 0.2314, Val Acc: 0.9191
Epoch 96/100, Loss: 0.4949, Acc: 0.7599, Val Loss: 0.2340, Val Acc: 0.9176
Epoch 97/100, Loss: 0.4948, Acc: 0.7603, Val Loss: 0.2340, Val Acc: 0.9173
Epoch 98/100, Loss: 0.4949, Acc: 0.7610, Val Loss: 0.2341, Val Acc: 0.9176
Epoch 99/100, Loss: 0.4947, Acc: 0.7601, Val Loss: 0.2333, Val Acc: 0.9184
Epoch 100/100, Loss: 0.4947, Acc: 0.7608, Val Loss: 0.2331, Val Acc: 0.9187

##############################
Resultados para principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1 
 {'training': [0.4947081397561466, 0.7608455882352941, 0.7841409691629956, 0.7198529411764706, 0.7506229633889209], 'validate': [0.23306136353071347, 0.91875, 0.971830985915493, 0.8625, 0.9139072847682119], 'test': [0.8019277061577197, 0.5497058823529412, 0.5402189433603046, 0.6676470588235294, 0.5972112601946856]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  020  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  020  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6152, Acc: 0.7045, Val Loss: 0.8235, Val Acc: 0.4537
Mejor modelo guardado con Val Loss: 0.8235
Epoch 2/100, Loss: 0.5530, Acc: 0.7368, Val Loss: 0.8271, Val Acc: 0.4673
Epoch 3/100, Loss: 0.5377, Acc: 0.7456, Val Loss: 0.8131, Val Acc: 0.4430
Mejor modelo guardado con Val Loss: 0.8131
Epoch 4/100, Loss: 0.5240, Acc: 0.7551, Val Loss: 0.8496, Val Acc: 0.4581
Epoch 5/100, Loss: 0.5232, Acc: 0.7533, Val Loss: 0.8969, Val Acc: 0.4688
Epoch 6/100, Loss: 0.5177, Acc: 0.7567, Val Loss: 0.8946, Val Acc: 0.4713
Epoch 7/100, Loss: 0.5148, Acc: 0.7570, Val Loss: 0.8919, Val Acc: 0.4710
Epoch 8/100, Loss: 0.5152, Acc: 0.7556, Val Loss: 0.8559, Val Acc: 0.4871
Epoch 9/100, Loss: 0.5145, Acc: 0.7546, Val Loss: 0.7962, Val Acc: 0.4838
Mejor modelo guardado con Val Loss: 0.7962
Epoch 10/100, Loss: 0.5189, Acc: 0.7563, Val Loss: 0.8989, Val Acc: 0.4518
Epoch 11/100, Loss: 0.5088, Acc: 0.7564, Val Loss: 0.9062, Val Acc: 0.4871
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5035, Acc: 0.7631, Val Loss: 0.9242, Val Acc: 0.4437
Epoch 13/100, Loss: 0.5021, Acc: 0.7624, Val Loss: 0.8932, Val Acc: 0.4746
Epoch 14/100, Loss: 0.5024, Acc: 0.7653, Val Loss: 0.9070, Val Acc: 0.4798
Epoch 15/100, Loss: 0.5003, Acc: 0.7619, Val Loss: 0.9390, Val Acc: 0.4548
Epoch 16/100, Loss: 0.5020, Acc: 0.7647, Val Loss: 0.9143, Val Acc: 0.4662
Epoch 17/100, Loss: 0.4984, Acc: 0.7627, Val Loss: 0.9164, Val Acc: 0.4474
Epoch 18/100, Loss: 0.4987, Acc: 0.7659, Val Loss: 0.9314, Val Acc: 0.4610
Epoch 19/100, Loss: 0.4993, Acc: 0.7645, Val Loss: 0.9388, Val Acc: 0.4482
Epoch 20/100, Loss: 0.4999, Acc: 0.7623, Val Loss: 0.9353, Val Acc: 0.4636
Epoch 21/100, Loss: 0.4967, Acc: 0.7642, Val Loss: 0.9373, Val Acc: 0.4504
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4923, Acc: 0.7681, Val Loss: 0.9165, Val Acc: 0.4783
Epoch 23/100, Loss: 0.4925, Acc: 0.7673, Val Loss: 0.9090, Val Acc: 0.4669
Epoch 24/100, Loss: 0.4931, Acc: 0.7691, Val Loss: 0.9063, Val Acc: 0.4765
Epoch 25/100, Loss: 0.4910, Acc: 0.7718, Val Loss: 0.9105, Val Acc: 0.4625
Epoch 26/100, Loss: 0.4900, Acc: 0.7702, Val Loss: 0.9189, Val Acc: 0.4618
Epoch 27/100, Loss: 0.4909, Acc: 0.7703, Val Loss: 0.9191, Val Acc: 0.4669
Epoch 28/100, Loss: 0.4906, Acc: 0.7683, Val Loss: 0.9003, Val Acc: 0.4779
Epoch 29/100, Loss: 0.4900, Acc: 0.7699, Val Loss: 0.9160, Val Acc: 0.4625
Epoch 30/100, Loss: 0.4904, Acc: 0.7693, Val Loss: 0.9080, Val Acc: 0.4702
Epoch 31/100, Loss: 0.4894, Acc: 0.7704, Val Loss: 0.9082, Val Acc: 0.4654
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4862, Acc: 0.7739, Val Loss: 0.9189, Val Acc: 0.4732
Epoch 33/100, Loss: 0.4862, Acc: 0.7732, Val Loss: 0.9203, Val Acc: 0.4750
Epoch 34/100, Loss: 0.4862, Acc: 0.7728, Val Loss: 0.9219, Val Acc: 0.4743
Epoch 35/100, Loss: 0.4855, Acc: 0.7735, Val Loss: 0.9409, Val Acc: 0.4577
Epoch 36/100, Loss: 0.4859, Acc: 0.7728, Val Loss: 0.9269, Val Acc: 0.4706
Epoch 37/100, Loss: 0.4856, Acc: 0.7732, Val Loss: 0.9321, Val Acc: 0.4684
Epoch 38/100, Loss: 0.4849, Acc: 0.7744, Val Loss: 0.9332, Val Acc: 0.4585
Epoch 39/100, Loss: 0.4861, Acc: 0.7736, Val Loss: 0.9385, Val Acc: 0.4581
Epoch 40/100, Loss: 0.4855, Acc: 0.7712, Val Loss: 0.9273, Val Acc: 0.4721
Epoch 41/100, Loss: 0.4846, Acc: 0.7730, Val Loss: 0.9351, Val Acc: 0.4717
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4839, Acc: 0.7730, Val Loss: 0.9316, Val Acc: 0.4706
Epoch 43/100, Loss: 0.4836, Acc: 0.7739, Val Loss: 0.9293, Val Acc: 0.4728
Epoch 44/100, Loss: 0.4836, Acc: 0.7722, Val Loss: 0.9286, Val Acc: 0.4717
Epoch 45/100, Loss: 0.4840, Acc: 0.7717, Val Loss: 0.9274, Val Acc: 0.4757
Epoch 46/100, Loss: 0.4841, Acc: 0.7740, Val Loss: 0.9323, Val Acc: 0.4702
Epoch 47/100, Loss: 0.4835, Acc: 0.7749, Val Loss: 0.9292, Val Acc: 0.4746
Epoch 48/100, Loss: 0.4831, Acc: 0.7736, Val Loss: 0.9346, Val Acc: 0.4673
Epoch 49/100, Loss: 0.4831, Acc: 0.7734, Val Loss: 0.9331, Val Acc: 0.4658
Epoch 50/100, Loss: 0.4831, Acc: 0.7734, Val Loss: 0.9257, Val Acc: 0.4688
Epoch 51/100, Loss: 0.4827, Acc: 0.7725, Val Loss: 0.9243, Val Acc: 0.4717
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4819, Acc: 0.7726, Val Loss: 0.9282, Val Acc: 0.4713
Epoch 53/100, Loss: 0.4814, Acc: 0.7732, Val Loss: 0.9301, Val Acc: 0.4662
Epoch 54/100, Loss: 0.4813, Acc: 0.7748, Val Loss: 0.9253, Val Acc: 0.4702
Epoch 55/100, Loss: 0.4813, Acc: 0.7741, Val Loss: 0.9208, Val Acc: 0.4713
Epoch 56/100, Loss: 0.4812, Acc: 0.7734, Val Loss: 0.9255, Val Acc: 0.4699
Epoch 57/100, Loss: 0.4811, Acc: 0.7737, Val Loss: 0.9217, Val Acc: 0.4717
Epoch 58/100, Loss: 0.4810, Acc: 0.7748, Val Loss: 0.9264, Val Acc: 0.4728
Epoch 59/100, Loss: 0.4810, Acc: 0.7745, Val Loss: 0.9240, Val Acc: 0.4713
Epoch 60/100, Loss: 0.4808, Acc: 0.7744, Val Loss: 0.9271, Val Acc: 0.4713
Epoch 61/100, Loss: 0.4807, Acc: 0.7741, Val Loss: 0.9240, Val Acc: 0.4721
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4803, Acc: 0.7736, Val Loss: 0.9250, Val Acc: 0.4713
Epoch 63/100, Loss: 0.4803, Acc: 0.7737, Val Loss: 0.9244, Val Acc: 0.4713
Epoch 64/100, Loss: 0.4803, Acc: 0.7740, Val Loss: 0.9247, Val Acc: 0.4699
Epoch 65/100, Loss: 0.4804, Acc: 0.7736, Val Loss: 0.9252, Val Acc: 0.4706
Epoch 66/100, Loss: 0.4803, Acc: 0.7747, Val Loss: 0.9250, Val Acc: 0.4710
Epoch 67/100, Loss: 0.4801, Acc: 0.7747, Val Loss: 0.9239, Val Acc: 0.4717
Epoch 68/100, Loss: 0.4800, Acc: 0.7740, Val Loss: 0.9252, Val Acc: 0.4702
Epoch 69/100, Loss: 0.4800, Acc: 0.7746, Val Loss: 0.9245, Val Acc: 0.4724
Epoch 70/100, Loss: 0.4801, Acc: 0.7741, Val Loss: 0.9275, Val Acc: 0.4695
Epoch 71/100, Loss: 0.4800, Acc: 0.7759, Val Loss: 0.9251, Val Acc: 0.4713
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4798, Acc: 0.7743, Val Loss: 0.9245, Val Acc: 0.4713
Epoch 73/100, Loss: 0.4797, Acc: 0.7741, Val Loss: 0.9251, Val Acc: 0.4706
Epoch 74/100, Loss: 0.4798, Acc: 0.7750, Val Loss: 0.9242, Val Acc: 0.4713
Epoch 75/100, Loss: 0.4797, Acc: 0.7743, Val Loss: 0.9240, Val Acc: 0.4713
Epoch 76/100, Loss: 0.4796, Acc: 0.7752, Val Loss: 0.9242, Val Acc: 0.4717
Epoch 77/100, Loss: 0.4796, Acc: 0.7752, Val Loss: 0.9240, Val Acc: 0.4717
Epoch 78/100, Loss: 0.4797, Acc: 0.7748, Val Loss: 0.9242, Val Acc: 0.4713
Epoch 79/100, Loss: 0.4795, Acc: 0.7744, Val Loss: 0.9241, Val Acc: 0.4721
Epoch 80/100, Loss: 0.4796, Acc: 0.7737, Val Loss: 0.9247, Val Acc: 0.4706
Epoch 81/100, Loss: 0.4796, Acc: 0.7758, Val Loss: 0.9247, Val Acc: 0.4717
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4796, Acc: 0.7742, Val Loss: 0.9247, Val Acc: 0.4713
Epoch 83/100, Loss: 0.4795, Acc: 0.7746, Val Loss: 0.9247, Val Acc: 0.4717
Epoch 84/100, Loss: 0.4794, Acc: 0.7744, Val Loss: 0.9248, Val Acc: 0.4713
Epoch 85/100, Loss: 0.4794, Acc: 0.7755, Val Loss: 0.9246, Val Acc: 0.4717
Epoch 86/100, Loss: 0.4794, Acc: 0.7747, Val Loss: 0.9247, Val Acc: 0.4713
Epoch 87/100, Loss: 0.4794, Acc: 0.7755, Val Loss: 0.9258, Val Acc: 0.4706
Epoch 88/100, Loss: 0.4793, Acc: 0.7745, Val Loss: 0.9252, Val Acc: 0.4710
Epoch 89/100, Loss: 0.4794, Acc: 0.7755, Val Loss: 0.9248, Val Acc: 0.4713
Epoch 90/100, Loss: 0.4793, Acc: 0.7756, Val Loss: 0.9249, Val Acc: 0.4713
Epoch 91/100, Loss: 0.4793, Acc: 0.7749, Val Loss: 0.9263, Val Acc: 0.4710
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4793, Acc: 0.7752, Val Loss: 0.9246, Val Acc: 0.4713
Epoch 93/100, Loss: 0.4792, Acc: 0.7743, Val Loss: 0.9261, Val Acc: 0.4706
Epoch 94/100, Loss: 0.4792, Acc: 0.7753, Val Loss: 0.9264, Val Acc: 0.4710
Epoch 95/100, Loss: 0.4792, Acc: 0.7757, Val Loss: 0.9267, Val Acc: 0.4710
Epoch 96/100, Loss: 0.4793, Acc: 0.7749, Val Loss: 0.9267, Val Acc: 0.4710
Epoch 97/100, Loss: 0.4792, Acc: 0.7754, Val Loss: 0.9262, Val Acc: 0.4706
Epoch 98/100, Loss: 0.4791, Acc: 0.7754, Val Loss: 0.9264, Val Acc: 0.4713
Epoch 99/100, Loss: 0.4791, Acc: 0.7756, Val Loss: 0.9265, Val Acc: 0.4710
Epoch 100/100, Loss: 0.4791, Acc: 0.7744, Val Loss: 0.9267, Val Acc: 0.4710

##############################
Resultados para principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1 
 {'training': [0.47912590275792516, 0.7744485294117647, 0.7328446662507798, 0.8637867647058823, 0.7929463381707729], 'validate': [0.9266594759253568, 0.47095588235294117, 0.4845522096206492, 0.9110294117647059, 0.6326270104671943], 'test': [0.5402078360871032, 0.7402941176470588, 0.6728734659331358, 0.9352941176470588, 0.7826729017967019]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  125  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  125  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6885, Acc: 0.5428, Val Loss: 0.6820, Val Acc: 0.6210
Mejor modelo guardado con Val Loss: 0.6820
Epoch 2/100, Loss: 0.6888, Acc: 0.5436, Val Loss: 0.6848, Val Acc: 0.5132
Epoch 3/100, Loss: 0.6862, Acc: 0.5584, Val Loss: 0.6854, Val Acc: 0.5801
Epoch 4/100, Loss: 0.6830, Acc: 0.5759, Val Loss: 0.6808, Val Acc: 0.5695
Mejor modelo guardado con Val Loss: 0.6808
Epoch 5/100, Loss: 0.6788, Acc: 0.5853, Val Loss: 0.6638, Val Acc: 0.6360
Mejor modelo guardado con Val Loss: 0.6638
Epoch 6/100, Loss: 0.6738, Acc: 0.5962, Val Loss: 0.6573, Val Acc: 0.6566
Mejor modelo guardado con Val Loss: 0.6573
Epoch 7/100, Loss: 0.6707, Acc: 0.6018, Val Loss: 0.6636, Val Acc: 0.6033
Epoch 8/100, Loss: 0.6699, Acc: 0.6003, Val Loss: 0.6412, Val Acc: 0.6732
Mejor modelo guardado con Val Loss: 0.6412
Epoch 9/100, Loss: 0.6675, Acc: 0.5987, Val Loss: 0.6514, Val Acc: 0.6537
Epoch 10/100, Loss: 0.6666, Acc: 0.6038, Val Loss: 0.6486, Val Acc: 0.6783
Epoch 11/100, Loss: 0.6651, Acc: 0.6025, Val Loss: 0.6311, Val Acc: 0.6757
Mejor modelo guardado con Val Loss: 0.6311
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6594, Acc: 0.6157, Val Loss: 0.6259, Val Acc: 0.6772
Mejor modelo guardado con Val Loss: 0.6259
Epoch 13/100, Loss: 0.6595, Acc: 0.6121, Val Loss: 0.6360, Val Acc: 0.6375
Epoch 14/100, Loss: 0.6578, Acc: 0.6110, Val Loss: 0.6285, Val Acc: 0.6691
Epoch 15/100, Loss: 0.6567, Acc: 0.6175, Val Loss: 0.6194, Val Acc: 0.6813
Mejor modelo guardado con Val Loss: 0.6194
Epoch 16/100, Loss: 0.6566, Acc: 0.6178, Val Loss: 0.6207, Val Acc: 0.6816
Epoch 17/100, Loss: 0.6565, Acc: 0.6150, Val Loss: 0.6260, Val Acc: 0.6548
Epoch 18/100, Loss: 0.6572, Acc: 0.6155, Val Loss: 0.6296, Val Acc: 0.6732
Epoch 19/100, Loss: 0.6560, Acc: 0.6210, Val Loss: 0.6320, Val Acc: 0.6460
Epoch 20/100, Loss: 0.6565, Acc: 0.6162, Val Loss: 0.6171, Val Acc: 0.6809
Mejor modelo guardado con Val Loss: 0.6171
Epoch 21/100, Loss: 0.6579, Acc: 0.6117, Val Loss: 0.6136, Val Acc: 0.6827
Mejor modelo guardado con Val Loss: 0.6136
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6546, Acc: 0.6210, Val Loss: 0.6156, Val Acc: 0.6864
Epoch 23/100, Loss: 0.6536, Acc: 0.6230, Val Loss: 0.6129, Val Acc: 0.6868
Mejor modelo guardado con Val Loss: 0.6129
Epoch 24/100, Loss: 0.6541, Acc: 0.6222, Val Loss: 0.6119, Val Acc: 0.6871
Mejor modelo guardado con Val Loss: 0.6119
Epoch 25/100, Loss: 0.6532, Acc: 0.6250, Val Loss: 0.6166, Val Acc: 0.6879
Epoch 26/100, Loss: 0.6541, Acc: 0.6238, Val Loss: 0.6166, Val Acc: 0.6897
Epoch 27/100, Loss: 0.6534, Acc: 0.6231, Val Loss: 0.6174, Val Acc: 0.6853
Epoch 28/100, Loss: 0.6529, Acc: 0.6205, Val Loss: 0.6294, Val Acc: 0.6449
Epoch 29/100, Loss: 0.6531, Acc: 0.6183, Val Loss: 0.6201, Val Acc: 0.6713
Epoch 30/100, Loss: 0.6523, Acc: 0.6199, Val Loss: 0.6148, Val Acc: 0.6904
Epoch 31/100, Loss: 0.6525, Acc: 0.6219, Val Loss: 0.6180, Val Acc: 0.6757
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6518, Acc: 0.6239, Val Loss: 0.6118, Val Acc: 0.6904
Mejor modelo guardado con Val Loss: 0.6118
Epoch 33/100, Loss: 0.6521, Acc: 0.6227, Val Loss: 0.6180, Val Acc: 0.6757
Epoch 34/100, Loss: 0.6520, Acc: 0.6252, Val Loss: 0.6144, Val Acc: 0.6919
Epoch 35/100, Loss: 0.6515, Acc: 0.6244, Val Loss: 0.6174, Val Acc: 0.6890
Epoch 36/100, Loss: 0.6522, Acc: 0.6221, Val Loss: 0.6136, Val Acc: 0.6904
Epoch 37/100, Loss: 0.6522, Acc: 0.6232, Val Loss: 0.6114, Val Acc: 0.6908
Mejor modelo guardado con Val Loss: 0.6114
Epoch 38/100, Loss: 0.6516, Acc: 0.6233, Val Loss: 0.6152, Val Acc: 0.6886
Epoch 39/100, Loss: 0.6516, Acc: 0.6207, Val Loss: 0.6131, Val Acc: 0.6890
Epoch 40/100, Loss: 0.6511, Acc: 0.6244, Val Loss: 0.6162, Val Acc: 0.6838
Epoch 41/100, Loss: 0.6514, Acc: 0.6244, Val Loss: 0.6140, Val Acc: 0.6904
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6510, Acc: 0.6249, Val Loss: 0.6143, Val Acc: 0.6912
Epoch 43/100, Loss: 0.6507, Acc: 0.6272, Val Loss: 0.6157, Val Acc: 0.6824
Epoch 44/100, Loss: 0.6509, Acc: 0.6235, Val Loss: 0.6168, Val Acc: 0.6772
Epoch 45/100, Loss: 0.6509, Acc: 0.6242, Val Loss: 0.6129, Val Acc: 0.6930
Epoch 46/100, Loss: 0.6507, Acc: 0.6253, Val Loss: 0.6132, Val Acc: 0.6912
Epoch 47/100, Loss: 0.6511, Acc: 0.6251, Val Loss: 0.6124, Val Acc: 0.6945
Epoch 48/100, Loss: 0.6505, Acc: 0.6278, Val Loss: 0.6144, Val Acc: 0.6897
Epoch 49/100, Loss: 0.6507, Acc: 0.6242, Val Loss: 0.6139, Val Acc: 0.6912
Epoch 50/100, Loss: 0.6505, Acc: 0.6256, Val Loss: 0.6180, Val Acc: 0.6754
Epoch 51/100, Loss: 0.6507, Acc: 0.6252, Val Loss: 0.6128, Val Acc: 0.6941
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6505, Acc: 0.6248, Val Loss: 0.6131, Val Acc: 0.6926
Epoch 53/100, Loss: 0.6503, Acc: 0.6234, Val Loss: 0.6141, Val Acc: 0.6897
Epoch 54/100, Loss: 0.6496, Acc: 0.6280, Val Loss: 0.6161, Val Acc: 0.6930
Epoch 55/100, Loss: 0.6492, Acc: 0.6263, Val Loss: 0.6149, Val Acc: 0.6949
Epoch 56/100, Loss: 0.6493, Acc: 0.6273, Val Loss: 0.6156, Val Acc: 0.6912
Epoch 57/100, Loss: 0.6492, Acc: 0.6267, Val Loss: 0.6177, Val Acc: 0.6853
Epoch 58/100, Loss: 0.6493, Acc: 0.6277, Val Loss: 0.6168, Val Acc: 0.6882
Epoch 59/100, Loss: 0.6491, Acc: 0.6270, Val Loss: 0.6134, Val Acc: 0.6912
Epoch 60/100, Loss: 0.6492, Acc: 0.6279, Val Loss: 0.6140, Val Acc: 0.6949
Epoch 61/100, Loss: 0.6491, Acc: 0.6277, Val Loss: 0.6162, Val Acc: 0.6919
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6488, Acc: 0.6270, Val Loss: 0.6156, Val Acc: 0.6926
Epoch 63/100, Loss: 0.6489, Acc: 0.6272, Val Loss: 0.6161, Val Acc: 0.6893
Epoch 64/100, Loss: 0.6489, Acc: 0.6257, Val Loss: 0.6151, Val Acc: 0.6934
Epoch 65/100, Loss: 0.6490, Acc: 0.6278, Val Loss: 0.6147, Val Acc: 0.6949
Epoch 66/100, Loss: 0.6489, Acc: 0.6259, Val Loss: 0.6156, Val Acc: 0.6934
Epoch 67/100, Loss: 0.6488, Acc: 0.6278, Val Loss: 0.6169, Val Acc: 0.6890
Epoch 68/100, Loss: 0.6488, Acc: 0.6256, Val Loss: 0.6159, Val Acc: 0.6937
Epoch 69/100, Loss: 0.6489, Acc: 0.6279, Val Loss: 0.6165, Val Acc: 0.6915
Epoch 70/100, Loss: 0.6488, Acc: 0.6266, Val Loss: 0.6170, Val Acc: 0.6901
Epoch 71/100, Loss: 0.6486, Acc: 0.6286, Val Loss: 0.6180, Val Acc: 0.6857
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6487, Acc: 0.6260, Val Loss: 0.6163, Val Acc: 0.6919
Epoch 73/100, Loss: 0.6487, Acc: 0.6273, Val Loss: 0.6167, Val Acc: 0.6915
Epoch 74/100, Loss: 0.6486, Acc: 0.6263, Val Loss: 0.6165, Val Acc: 0.6919
Epoch 75/100, Loss: 0.6486, Acc: 0.6273, Val Loss: 0.6168, Val Acc: 0.6912
Epoch 76/100, Loss: 0.6486, Acc: 0.6270, Val Loss: 0.6165, Val Acc: 0.6912
Epoch 77/100, Loss: 0.6486, Acc: 0.6263, Val Loss: 0.6170, Val Acc: 0.6897
Epoch 78/100, Loss: 0.6487, Acc: 0.6257, Val Loss: 0.6163, Val Acc: 0.6934
Epoch 79/100, Loss: 0.6486, Acc: 0.6282, Val Loss: 0.6172, Val Acc: 0.6912
Epoch 80/100, Loss: 0.6486, Acc: 0.6277, Val Loss: 0.6174, Val Acc: 0.6897
Epoch 81/100, Loss: 0.6485, Acc: 0.6256, Val Loss: 0.6167, Val Acc: 0.6923
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6485, Acc: 0.6282, Val Loss: 0.6169, Val Acc: 0.6915
Epoch 83/100, Loss: 0.6485, Acc: 0.6271, Val Loss: 0.6167, Val Acc: 0.6915
Epoch 84/100, Loss: 0.6485, Acc: 0.6276, Val Loss: 0.6167, Val Acc: 0.6923
Epoch 85/100, Loss: 0.6485, Acc: 0.6276, Val Loss: 0.6175, Val Acc: 0.6912
Epoch 86/100, Loss: 0.6485, Acc: 0.6286, Val Loss: 0.6181, Val Acc: 0.6875
Epoch 87/100, Loss: 0.6485, Acc: 0.6263, Val Loss: 0.6173, Val Acc: 0.6908
Epoch 88/100, Loss: 0.6484, Acc: 0.6285, Val Loss: 0.6182, Val Acc: 0.6864
Epoch 89/100, Loss: 0.6485, Acc: 0.6286, Val Loss: 0.6177, Val Acc: 0.6901
Epoch 90/100, Loss: 0.6485, Acc: 0.6256, Val Loss: 0.6170, Val Acc: 0.6915
Epoch 91/100, Loss: 0.6484, Acc: 0.6270, Val Loss: 0.6171, Val Acc: 0.6912
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6484, Acc: 0.6282, Val Loss: 0.6183, Val Acc: 0.6871
Epoch 93/100, Loss: 0.6484, Acc: 0.6277, Val Loss: 0.6174, Val Acc: 0.6908
Epoch 94/100, Loss: 0.6484, Acc: 0.6257, Val Loss: 0.6170, Val Acc: 0.6923
Epoch 95/100, Loss: 0.6484, Acc: 0.6285, Val Loss: 0.6171, Val Acc: 0.6912
Epoch 96/100, Loss: 0.6484, Acc: 0.6270, Val Loss: 0.6172, Val Acc: 0.6912
Epoch 97/100, Loss: 0.6484, Acc: 0.6281, Val Loss: 0.6177, Val Acc: 0.6912
Epoch 98/100, Loss: 0.6483, Acc: 0.6285, Val Loss: 0.6177, Val Acc: 0.6882
Epoch 99/100, Loss: 0.6483, Acc: 0.6269, Val Loss: 0.6171, Val Acc: 0.6908
Epoch 100/100, Loss: 0.6483, Acc: 0.6282, Val Loss: 0.6171, Val Acc: 0.6912

##############################
Resultados para principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1 
 {'training': [0.6483071565628051, 0.6282169117647058, 0.6107670319199618, 0.7069852941176471, 0.6553633807616938], 'validate': [0.6171403790629187, 0.6911764705882353, 0.7006172839506173, 0.6676470588235294, 0.6837349397590361], 'test': [0.7239753824693186, 0.4958823529411765, 0.4970034246575342, 0.6829411764705883, 0.5753221010901883]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  011  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  011  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6936, Acc: 0.4986, Val Loss: 0.6932, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6932
Epoch 2/100, Loss: 0.6935, Acc: 0.5006, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 3/100, Loss: 0.6935, Acc: 0.4947, Val Loss: 0.6931, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6931
Epoch 4/100, Loss: 0.6933, Acc: 0.4987, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 5/100, Loss: 0.6935, Acc: 0.4941, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 6/100, Loss: 0.6933, Acc: 0.4987, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6933, Acc: 0.5013, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 8/100, Loss: 0.6934, Acc: 0.4991, Val Loss: 0.6935, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6933, Acc: 0.5028, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 10/100, Loss: 0.6934, Acc: 0.4914, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 11/100, Loss: 0.6933, Acc: 0.5013, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4916, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6932, Acc: 0.4955, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6933, Acc: 0.4994, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 16/100, Loss: 0.6933, Acc: 0.4958, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6932, Acc: 0.5042, Val Loss: 0.6937, Val Acc: 0.5000
Epoch 18/100, Loss: 0.6932, Acc: 0.5017, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 19/100, Loss: 0.6931, Acc: 0.5057, Val Loss: 0.6937, Val Acc: 0.5000
Epoch 20/100, Loss: 0.6932, Acc: 0.5026, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 21/100, Loss: 0.6932, Acc: 0.5044, Val Loss: 0.6935, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4972, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 23/100, Loss: 0.6933, Acc: 0.5046, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 24/100, Loss: 0.6934, Acc: 0.4917, Val Loss: 0.6936, Val Acc: 0.5000
Epoch 25/100, Loss: 0.6932, Acc: 0.4950, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 26/100, Loss: 0.6932, Acc: 0.4981, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 27/100, Loss: 0.6932, Acc: 0.4971, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 28/100, Loss: 0.6932, Acc: 0.4955, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 29/100, Loss: 0.6932, Acc: 0.4954, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 30/100, Loss: 0.6932, Acc: 0.4990, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 31/100, Loss: 0.6932, Acc: 0.4965, Val Loss: 0.6931, Val Acc: 0.5004
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4907, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 33/100, Loss: 0.6932, Acc: 0.4972, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 34/100, Loss: 0.6932, Acc: 0.4926, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 35/100, Loss: 0.6932, Acc: 0.4951, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 36/100, Loss: 0.6932, Acc: 0.4981, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 37/100, Loss: 0.6932, Acc: 0.5001, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 38/100, Loss: 0.6929, Acc: 0.5114, Val Loss: 0.6904, Val Acc: 0.6103
Mejor modelo guardado con Val Loss: 0.6904
Epoch 39/100, Loss: 0.6932, Acc: 0.5078, Val Loss: 0.6914, Val Acc: 0.5000
Epoch 40/100, Loss: 0.6924, Acc: 0.5000, Val Loss: 0.6901, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6901
Epoch 41/100, Loss: 0.6920, Acc: 0.5346, Val Loss: 0.6884, Val Acc: 0.6250
Mejor modelo guardado con Val Loss: 0.6884
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6918, Acc: 0.5488, Val Loss: 0.6884, Val Acc: 0.6445
Epoch 43/100, Loss: 0.6916, Acc: 0.5573, Val Loss: 0.6875, Val Acc: 0.6684
Mejor modelo guardado con Val Loss: 0.6875
Epoch 44/100, Loss: 0.6915, Acc: 0.5548, Val Loss: 0.6886, Val Acc: 0.6364
Epoch 45/100, Loss: 0.6913, Acc: 0.5576, Val Loss: 0.6883, Val Acc: 0.6438
Epoch 46/100, Loss: 0.6912, Acc: 0.5638, Val Loss: 0.6883, Val Acc: 0.6342
Epoch 47/100, Loss: 0.6910, Acc: 0.5647, Val Loss: 0.6880, Val Acc: 0.6305
Epoch 48/100, Loss: 0.6909, Acc: 0.5693, Val Loss: 0.6875, Val Acc: 0.6511
Mejor modelo guardado con Val Loss: 0.6875
Epoch 49/100, Loss: 0.6907, Acc: 0.5737, Val Loss: 0.6873, Val Acc: 0.6511
Mejor modelo guardado con Val Loss: 0.6873
Epoch 50/100, Loss: 0.6906, Acc: 0.5746, Val Loss: 0.6878, Val Acc: 0.6338
Epoch 51/100, Loss: 0.6905, Acc: 0.5744, Val Loss: 0.6864, Val Acc: 0.6687
Mejor modelo guardado con Val Loss: 0.6864
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6903, Acc: 0.5740, Val Loss: 0.6868, Val Acc: 0.6551
Epoch 53/100, Loss: 0.6902, Acc: 0.5780, Val Loss: 0.6876, Val Acc: 0.6235
Epoch 54/100, Loss: 0.6901, Acc: 0.5788, Val Loss: 0.6872, Val Acc: 0.6346
Epoch 55/100, Loss: 0.6900, Acc: 0.5794, Val Loss: 0.6873, Val Acc: 0.6287
Epoch 56/100, Loss: 0.6899, Acc: 0.5789, Val Loss: 0.6876, Val Acc: 0.6176
Epoch 57/100, Loss: 0.6898, Acc: 0.5790, Val Loss: 0.6882, Val Acc: 0.6110
Epoch 58/100, Loss: 0.6897, Acc: 0.5787, Val Loss: 0.6870, Val Acc: 0.6346
Epoch 59/100, Loss: 0.6896, Acc: 0.5802, Val Loss: 0.6869, Val Acc: 0.6338
Epoch 60/100, Loss: 0.6895, Acc: 0.5813, Val Loss: 0.6867, Val Acc: 0.6375
Epoch 61/100, Loss: 0.6894, Acc: 0.5821, Val Loss: 0.6871, Val Acc: 0.6305
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6894, Acc: 0.5849, Val Loss: 0.6868, Val Acc: 0.6276
Epoch 63/100, Loss: 0.6893, Acc: 0.5838, Val Loss: 0.6868, Val Acc: 0.6305
Epoch 64/100, Loss: 0.6893, Acc: 0.5864, Val Loss: 0.6865, Val Acc: 0.6349
Epoch 65/100, Loss: 0.6892, Acc: 0.5854, Val Loss: 0.6867, Val Acc: 0.6290
Epoch 66/100, Loss: 0.6892, Acc: 0.5851, Val Loss: 0.6868, Val Acc: 0.6276
Epoch 67/100, Loss: 0.6891, Acc: 0.5854, Val Loss: 0.6871, Val Acc: 0.6239
Epoch 68/100, Loss: 0.6891, Acc: 0.5855, Val Loss: 0.6871, Val Acc: 0.6147
Epoch 69/100, Loss: 0.6890, Acc: 0.5863, Val Loss: 0.6871, Val Acc: 0.6140
Epoch 70/100, Loss: 0.6890, Acc: 0.5859, Val Loss: 0.6869, Val Acc: 0.6287
Epoch 71/100, Loss: 0.6887, Acc: 0.5843, Val Loss: 0.6903, Val Acc: 0.5673
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6880, Acc: 0.5780, Val Loss: 0.6907, Val Acc: 0.5577
Epoch 73/100, Loss: 0.6880, Acc: 0.5784, Val Loss: 0.6904, Val Acc: 0.5551
Epoch 74/100, Loss: 0.6879, Acc: 0.5810, Val Loss: 0.6902, Val Acc: 0.5599
Epoch 75/100, Loss: 0.6878, Acc: 0.5824, Val Loss: 0.6904, Val Acc: 0.5566
Epoch 76/100, Loss: 0.6878, Acc: 0.5836, Val Loss: 0.6902, Val Acc: 0.5625
Epoch 77/100, Loss: 0.6877, Acc: 0.5834, Val Loss: 0.6902, Val Acc: 0.5640
Epoch 78/100, Loss: 0.6877, Acc: 0.5857, Val Loss: 0.6899, Val Acc: 0.5710
Epoch 79/100, Loss: 0.6876, Acc: 0.5871, Val Loss: 0.6901, Val Acc: 0.5728
Epoch 80/100, Loss: 0.6876, Acc: 0.5870, Val Loss: 0.6900, Val Acc: 0.5790
Epoch 81/100, Loss: 0.6875, Acc: 0.5890, Val Loss: 0.6902, Val Acc: 0.5768
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6875, Acc: 0.5882, Val Loss: 0.6902, Val Acc: 0.5794
Epoch 83/100, Loss: 0.6874, Acc: 0.5905, Val Loss: 0.6900, Val Acc: 0.5827
Epoch 84/100, Loss: 0.6874, Acc: 0.5897, Val Loss: 0.6899, Val Acc: 0.5824
Epoch 85/100, Loss: 0.6873, Acc: 0.5904, Val Loss: 0.6898, Val Acc: 0.5787
Epoch 86/100, Loss: 0.6873, Acc: 0.5920, Val Loss: 0.6898, Val Acc: 0.5805
Epoch 87/100, Loss: 0.6872, Acc: 0.5918, Val Loss: 0.6897, Val Acc: 0.5813
Epoch 88/100, Loss: 0.6872, Acc: 0.5930, Val Loss: 0.6897, Val Acc: 0.5827
Epoch 89/100, Loss: 0.6872, Acc: 0.5941, Val Loss: 0.6893, Val Acc: 0.5882
Epoch 90/100, Loss: 0.6871, Acc: 0.5941, Val Loss: 0.6894, Val Acc: 0.5875
Epoch 91/100, Loss: 0.6871, Acc: 0.5935, Val Loss: 0.6893, Val Acc: 0.5893
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6867, Acc: 0.5919, Val Loss: 0.6929, Val Acc: 0.5489
Epoch 93/100, Loss: 0.6865, Acc: 0.5946, Val Loss: 0.6935, Val Acc: 0.5393
Epoch 94/100, Loss: 0.6864, Acc: 0.5904, Val Loss: 0.6932, Val Acc: 0.5474
Epoch 95/100, Loss: 0.6864, Acc: 0.5942, Val Loss: 0.6931, Val Acc: 0.5489
Epoch 96/100, Loss: 0.6863, Acc: 0.5937, Val Loss: 0.6929, Val Acc: 0.5504
Epoch 97/100, Loss: 0.6862, Acc: 0.5934, Val Loss: 0.6915, Val Acc: 0.5518
Epoch 98/100, Loss: 0.6861, Acc: 0.5922, Val Loss: 0.6899, Val Acc: 0.5684
Epoch 99/100, Loss: 0.6860, Acc: 0.5925, Val Loss: 0.6888, Val Acc: 0.5761
Epoch 100/100, Loss: 0.6858, Acc: 0.5941, Val Loss: 0.6886, Val Acc: 0.5750

##############################
Resultados para principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1 
 {'training': [0.6858121261877173, 0.5941176470588235, 0.5914285714285714, 0.6088235294117647, 0.6], 'validate': [0.6885624167531036, 0.575, 0.5860033726812817, 0.5110294117647058, 0.5459544383346425], 'test': [0.6945759146301834, 0.46647058823529414, 0.4756825938566553, 0.6558823529411765, 0.5514342235410484]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  021  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  021  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5764, Acc: 0.7292, Val Loss: 0.4973, Val Acc: 0.8162
Mejor modelo guardado con Val Loss: 0.4973
Epoch 2/100, Loss: 0.5259, Acc: 0.7496, Val Loss: 0.4390, Val Acc: 0.8228
Mejor modelo guardado con Val Loss: 0.4390
Epoch 3/100, Loss: 0.5214, Acc: 0.7482, Val Loss: 0.4631, Val Acc: 0.8268
Epoch 4/100, Loss: 0.5124, Acc: 0.7504, Val Loss: 0.4557, Val Acc: 0.8107
Epoch 5/100, Loss: 0.5093, Acc: 0.7564, Val Loss: 0.4490, Val Acc: 0.8180
Epoch 6/100, Loss: 0.5061, Acc: 0.7556, Val Loss: 0.5322, Val Acc: 0.7037
Epoch 7/100, Loss: 0.5056, Acc: 0.7520, Val Loss: 0.4575, Val Acc: 0.8040
Epoch 8/100, Loss: 0.5040, Acc: 0.7550, Val Loss: 0.4249, Val Acc: 0.8390
Mejor modelo guardado con Val Loss: 0.4249
Epoch 9/100, Loss: 0.5062, Acc: 0.7542, Val Loss: 0.4518, Val Acc: 0.8125
Epoch 10/100, Loss: 0.5074, Acc: 0.7524, Val Loss: 0.4163, Val Acc: 0.8268
Mejor modelo guardado con Val Loss: 0.4163
Epoch 11/100, Loss: 0.5028, Acc: 0.7536, Val Loss: 0.4497, Val Acc: 0.7996
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4970, Acc: 0.7542, Val Loss: 0.4344, Val Acc: 0.8268
Epoch 13/100, Loss: 0.4998, Acc: 0.7555, Val Loss: 0.4699, Val Acc: 0.7820
Epoch 14/100, Loss: 0.4975, Acc: 0.7563, Val Loss: 0.4004, Val Acc: 0.8379
Mejor modelo guardado con Val Loss: 0.4004
Epoch 15/100, Loss: 0.4967, Acc: 0.7588, Val Loss: 0.4583, Val Acc: 0.7919
Epoch 16/100, Loss: 0.4960, Acc: 0.7572, Val Loss: 0.4757, Val Acc: 0.7614
Epoch 17/100, Loss: 0.4962, Acc: 0.7573, Val Loss: 0.4081, Val Acc: 0.8283
Epoch 18/100, Loss: 0.4942, Acc: 0.7606, Val Loss: 0.4189, Val Acc: 0.8305
Epoch 19/100, Loss: 0.4979, Acc: 0.7549, Val Loss: 0.4408, Val Acc: 0.8081
Epoch 20/100, Loss: 0.4949, Acc: 0.7612, Val Loss: 0.4425, Val Acc: 0.7978
Epoch 21/100, Loss: 0.4938, Acc: 0.7581, Val Loss: 0.4141, Val Acc: 0.8290
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4938, Acc: 0.7574, Val Loss: 0.4292, Val Acc: 0.8217
Epoch 23/100, Loss: 0.4914, Acc: 0.7597, Val Loss: 0.4304, Val Acc: 0.8298
Epoch 24/100, Loss: 0.4893, Acc: 0.7597, Val Loss: 0.4105, Val Acc: 0.8246
Epoch 25/100, Loss: 0.4892, Acc: 0.7648, Val Loss: 0.4327, Val Acc: 0.8143
Epoch 26/100, Loss: 0.4898, Acc: 0.7619, Val Loss: 0.4427, Val Acc: 0.8235
Epoch 27/100, Loss: 0.4904, Acc: 0.7595, Val Loss: 0.4146, Val Acc: 0.8283
Epoch 28/100, Loss: 0.4879, Acc: 0.7619, Val Loss: 0.4153, Val Acc: 0.8250
Epoch 29/100, Loss: 0.4884, Acc: 0.7607, Val Loss: 0.4259, Val Acc: 0.8147
Epoch 30/100, Loss: 0.4878, Acc: 0.7608, Val Loss: 0.4202, Val Acc: 0.8243
Epoch 31/100, Loss: 0.4885, Acc: 0.7630, Val Loss: 0.4055, Val Acc: 0.8331
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4860, Acc: 0.7622, Val Loss: 0.4155, Val Acc: 0.8320
Epoch 33/100, Loss: 0.4857, Acc: 0.7624, Val Loss: 0.4173, Val Acc: 0.8313
Epoch 34/100, Loss: 0.4854, Acc: 0.7656, Val Loss: 0.4190, Val Acc: 0.8290
Epoch 35/100, Loss: 0.4860, Acc: 0.7656, Val Loss: 0.4253, Val Acc: 0.8213
Epoch 36/100, Loss: 0.4852, Acc: 0.7633, Val Loss: 0.4124, Val Acc: 0.8379
Epoch 37/100, Loss: 0.4864, Acc: 0.7619, Val Loss: 0.4133, Val Acc: 0.8313
Epoch 38/100, Loss: 0.4850, Acc: 0.7638, Val Loss: 0.4212, Val Acc: 0.8239
Epoch 39/100, Loss: 0.4849, Acc: 0.7647, Val Loss: 0.4153, Val Acc: 0.8287
Epoch 40/100, Loss: 0.4851, Acc: 0.7642, Val Loss: 0.4140, Val Acc: 0.8287
Epoch 41/100, Loss: 0.4840, Acc: 0.7646, Val Loss: 0.4300, Val Acc: 0.8081
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4843, Acc: 0.7621, Val Loss: 0.4126, Val Acc: 0.8298
Epoch 43/100, Loss: 0.4835, Acc: 0.7622, Val Loss: 0.4176, Val Acc: 0.8228
Epoch 44/100, Loss: 0.4836, Acc: 0.7627, Val Loss: 0.4088, Val Acc: 0.8331
Epoch 45/100, Loss: 0.4831, Acc: 0.7651, Val Loss: 0.4108, Val Acc: 0.8239
Epoch 46/100, Loss: 0.4833, Acc: 0.7635, Val Loss: 0.4110, Val Acc: 0.8346
Epoch 47/100, Loss: 0.4836, Acc: 0.7618, Val Loss: 0.4142, Val Acc: 0.8239
Epoch 48/100, Loss: 0.4831, Acc: 0.7618, Val Loss: 0.4202, Val Acc: 0.8202
Epoch 49/100, Loss: 0.4837, Acc: 0.7627, Val Loss: 0.4200, Val Acc: 0.8206
Epoch 50/100, Loss: 0.4829, Acc: 0.7638, Val Loss: 0.4128, Val Acc: 0.8228
Epoch 51/100, Loss: 0.4831, Acc: 0.7634, Val Loss: 0.4140, Val Acc: 0.8243
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4823, Acc: 0.7636, Val Loss: 0.4151, Val Acc: 0.8235
Epoch 53/100, Loss: 0.4822, Acc: 0.7646, Val Loss: 0.4087, Val Acc: 0.8327
Epoch 54/100, Loss: 0.4822, Acc: 0.7637, Val Loss: 0.4123, Val Acc: 0.8268
Epoch 55/100, Loss: 0.4822, Acc: 0.7644, Val Loss: 0.4154, Val Acc: 0.8239
Epoch 56/100, Loss: 0.4820, Acc: 0.7628, Val Loss: 0.4134, Val Acc: 0.8272
Epoch 57/100, Loss: 0.4818, Acc: 0.7641, Val Loss: 0.4161, Val Acc: 0.8276
Epoch 58/100, Loss: 0.4818, Acc: 0.7635, Val Loss: 0.4154, Val Acc: 0.8272
Epoch 59/100, Loss: 0.4816, Acc: 0.7640, Val Loss: 0.4134, Val Acc: 0.8287
Epoch 60/100, Loss: 0.4814, Acc: 0.7634, Val Loss: 0.4145, Val Acc: 0.8290
Epoch 61/100, Loss: 0.4814, Acc: 0.7626, Val Loss: 0.4159, Val Acc: 0.8257
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4810, Acc: 0.7641, Val Loss: 0.4153, Val Acc: 0.8279
Epoch 63/100, Loss: 0.4810, Acc: 0.7641, Val Loss: 0.4147, Val Acc: 0.8283
Epoch 64/100, Loss: 0.4809, Acc: 0.7649, Val Loss: 0.4137, Val Acc: 0.8283
Epoch 65/100, Loss: 0.4808, Acc: 0.7642, Val Loss: 0.4126, Val Acc: 0.8294
Epoch 66/100, Loss: 0.4809, Acc: 0.7634, Val Loss: 0.4147, Val Acc: 0.8261
Epoch 67/100, Loss: 0.4809, Acc: 0.7643, Val Loss: 0.4177, Val Acc: 0.8254
Epoch 68/100, Loss: 0.4809, Acc: 0.7640, Val Loss: 0.4156, Val Acc: 0.8265
Epoch 69/100, Loss: 0.4809, Acc: 0.7643, Val Loss: 0.4143, Val Acc: 0.8276
Epoch 70/100, Loss: 0.4808, Acc: 0.7640, Val Loss: 0.4159, Val Acc: 0.8257
Epoch 71/100, Loss: 0.4808, Acc: 0.7640, Val Loss: 0.4136, Val Acc: 0.8283
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4806, Acc: 0.7650, Val Loss: 0.4138, Val Acc: 0.8283
Epoch 73/100, Loss: 0.4806, Acc: 0.7638, Val Loss: 0.4151, Val Acc: 0.8276
Epoch 74/100, Loss: 0.4806, Acc: 0.7646, Val Loss: 0.4127, Val Acc: 0.8287
Epoch 75/100, Loss: 0.4805, Acc: 0.7642, Val Loss: 0.4159, Val Acc: 0.8268
Epoch 76/100, Loss: 0.4805, Acc: 0.7640, Val Loss: 0.4155, Val Acc: 0.8268
Epoch 77/100, Loss: 0.4805, Acc: 0.7645, Val Loss: 0.4149, Val Acc: 0.8279
Epoch 78/100, Loss: 0.4805, Acc: 0.7641, Val Loss: 0.4148, Val Acc: 0.8268
Epoch 79/100, Loss: 0.4805, Acc: 0.7639, Val Loss: 0.4143, Val Acc: 0.8276
Epoch 80/100, Loss: 0.4806, Acc: 0.7653, Val Loss: 0.4146, Val Acc: 0.8268
Epoch 81/100, Loss: 0.4805, Acc: 0.7633, Val Loss: 0.4137, Val Acc: 0.8276
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4805, Acc: 0.7639, Val Loss: 0.4171, Val Acc: 0.8261
Epoch 83/100, Loss: 0.4803, Acc: 0.7645, Val Loss: 0.4115, Val Acc: 0.8290
Epoch 84/100, Loss: 0.4804, Acc: 0.7643, Val Loss: 0.4156, Val Acc: 0.8268
Epoch 85/100, Loss: 0.4805, Acc: 0.7643, Val Loss: 0.4159, Val Acc: 0.8265
Epoch 86/100, Loss: 0.4804, Acc: 0.7642, Val Loss: 0.4136, Val Acc: 0.8276
Epoch 87/100, Loss: 0.4804, Acc: 0.7633, Val Loss: 0.4154, Val Acc: 0.8272
Epoch 88/100, Loss: 0.4804, Acc: 0.7638, Val Loss: 0.4130, Val Acc: 0.8276
Epoch 89/100, Loss: 0.4803, Acc: 0.7637, Val Loss: 0.4156, Val Acc: 0.8268
Epoch 90/100, Loss: 0.4804, Acc: 0.7642, Val Loss: 0.4141, Val Acc: 0.8272
Epoch 91/100, Loss: 0.4804, Acc: 0.7645, Val Loss: 0.4126, Val Acc: 0.8268
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4803, Acc: 0.7642, Val Loss: 0.4131, Val Acc: 0.8272
Epoch 93/100, Loss: 0.4803, Acc: 0.7638, Val Loss: 0.4137, Val Acc: 0.8272
Epoch 94/100, Loss: 0.4803, Acc: 0.7643, Val Loss: 0.4144, Val Acc: 0.8276
Epoch 95/100, Loss: 0.4803, Acc: 0.7639, Val Loss: 0.4143, Val Acc: 0.8272
Epoch 96/100, Loss: 0.4803, Acc: 0.7638, Val Loss: 0.4133, Val Acc: 0.8272
Epoch 97/100, Loss: 0.4802, Acc: 0.7645, Val Loss: 0.4157, Val Acc: 0.8268
Epoch 98/100, Loss: 0.4802, Acc: 0.7645, Val Loss: 0.4147, Val Acc: 0.8268
Epoch 99/100, Loss: 0.4802, Acc: 0.7649, Val Loss: 0.4141, Val Acc: 0.8272
Epoch 100/100, Loss: 0.4802, Acc: 0.7653, Val Loss: 0.4129, Val Acc: 0.8276

##############################
Resultados para principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1 
 {'training': [0.4801541400306365, 0.7653492647058824, 0.7624068351208871, 0.7709558823529412, 0.7666575267343022], 'validate': [0.41286668320034825, 0.8275735294117647, 0.7728107777097367, 0.9279411764705883, 0.8433010357500835], 'test': [0.42975381375462923, 0.8014705882352942, 0.8169449598021027, 0.7770588235294118, 0.7965028640337655]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  008  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  008  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6901, Acc: 0.5449, Val Loss: 0.6860, Val Acc: 0.5673
Mejor modelo guardado con Val Loss: 0.6860
Epoch 2/100, Loss: 0.6814, Acc: 0.5924, Val Loss: 0.6810, Val Acc: 0.5625
Mejor modelo guardado con Val Loss: 0.6810
Epoch 3/100, Loss: 0.6722, Acc: 0.6112, Val Loss: 0.6781, Val Acc: 0.6085
Mejor modelo guardado con Val Loss: 0.6781
Epoch 4/100, Loss: 0.6666, Acc: 0.6205, Val Loss: 0.6774, Val Acc: 0.5904
Mejor modelo guardado con Val Loss: 0.6774
Epoch 5/100, Loss: 0.6592, Acc: 0.6239, Val Loss: 0.6692, Val Acc: 0.6430
Mejor modelo guardado con Val Loss: 0.6692
Epoch 6/100, Loss: 0.6661, Acc: 0.6153, Val Loss: 0.6636, Val Acc: 0.6471
Mejor modelo guardado con Val Loss: 0.6636
Epoch 7/100, Loss: 0.6589, Acc: 0.6224, Val Loss: 0.6721, Val Acc: 0.6037
Epoch 8/100, Loss: 0.6563, Acc: 0.6306, Val Loss: 0.6701, Val Acc: 0.6077
Epoch 9/100, Loss: 0.6496, Acc: 0.6362, Val Loss: 0.6663, Val Acc: 0.6217
Epoch 10/100, Loss: 0.6475, Acc: 0.6330, Val Loss: 0.6797, Val Acc: 0.6004
Epoch 11/100, Loss: 0.6532, Acc: 0.6246, Val Loss: 0.6897, Val Acc: 0.5739
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6463, Acc: 0.6359, Val Loss: 0.6780, Val Acc: 0.6000
Epoch 13/100, Loss: 0.6435, Acc: 0.6408, Val Loss: 0.6875, Val Acc: 0.5923
Epoch 14/100, Loss: 0.6428, Acc: 0.6393, Val Loss: 0.6948, Val Acc: 0.5699
Epoch 15/100, Loss: 0.6428, Acc: 0.6381, Val Loss: 0.6921, Val Acc: 0.5816
Epoch 16/100, Loss: 0.6419, Acc: 0.6416, Val Loss: 0.6978, Val Acc: 0.5658
Epoch 17/100, Loss: 0.6408, Acc: 0.6413, Val Loss: 0.7032, Val Acc: 0.5592
Epoch 18/100, Loss: 0.6424, Acc: 0.6415, Val Loss: 0.7135, Val Acc: 0.5338
Epoch 19/100, Loss: 0.6421, Acc: 0.6393, Val Loss: 0.6860, Val Acc: 0.5798
Epoch 20/100, Loss: 0.6425, Acc: 0.6338, Val Loss: 0.6788, Val Acc: 0.6165
Epoch 21/100, Loss: 0.6425, Acc: 0.6389, Val Loss: 0.7003, Val Acc: 0.5787
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6388, Acc: 0.6434, Val Loss: 0.6878, Val Acc: 0.5974
Epoch 23/100, Loss: 0.6384, Acc: 0.6449, Val Loss: 0.7082, Val Acc: 0.5529
Epoch 24/100, Loss: 0.6403, Acc: 0.6407, Val Loss: 0.7031, Val Acc: 0.5607
Epoch 25/100, Loss: 0.6395, Acc: 0.6442, Val Loss: 0.6976, Val Acc: 0.5868
Epoch 26/100, Loss: 0.6393, Acc: 0.6430, Val Loss: 0.6997, Val Acc: 0.5710
Epoch 27/100, Loss: 0.6388, Acc: 0.6459, Val Loss: 0.6792, Val Acc: 0.6165
Epoch 28/100, Loss: 0.6403, Acc: 0.6398, Val Loss: 0.7092, Val Acc: 0.5544
Epoch 29/100, Loss: 0.6385, Acc: 0.6450, Val Loss: 0.7077, Val Acc: 0.5625
Epoch 30/100, Loss: 0.6386, Acc: 0.6431, Val Loss: 0.7082, Val Acc: 0.5625
Epoch 31/100, Loss: 0.6384, Acc: 0.6441, Val Loss: 0.6949, Val Acc: 0.5934
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6386, Acc: 0.6414, Val Loss: 0.7008, Val Acc: 0.5801
Epoch 33/100, Loss: 0.6375, Acc: 0.6452, Val Loss: 0.7051, Val Acc: 0.5603
Epoch 34/100, Loss: 0.6373, Acc: 0.6466, Val Loss: 0.6935, Val Acc: 0.5838
Epoch 35/100, Loss: 0.6370, Acc: 0.6450, Val Loss: 0.6995, Val Acc: 0.5849
Epoch 36/100, Loss: 0.6369, Acc: 0.6440, Val Loss: 0.6932, Val Acc: 0.5835
Epoch 37/100, Loss: 0.6374, Acc: 0.6428, Val Loss: 0.7047, Val Acc: 0.5662
Epoch 38/100, Loss: 0.6372, Acc: 0.6458, Val Loss: 0.7032, Val Acc: 0.5732
Epoch 39/100, Loss: 0.6371, Acc: 0.6465, Val Loss: 0.7064, Val Acc: 0.5548
Epoch 40/100, Loss: 0.6373, Acc: 0.6444, Val Loss: 0.7044, Val Acc: 0.5801
Epoch 41/100, Loss: 0.6369, Acc: 0.6447, Val Loss: 0.7026, Val Acc: 0.5662
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6361, Acc: 0.6445, Val Loss: 0.7009, Val Acc: 0.5816
Epoch 43/100, Loss: 0.6354, Acc: 0.6466, Val Loss: 0.7028, Val Acc: 0.5739
Epoch 44/100, Loss: 0.6354, Acc: 0.6452, Val Loss: 0.7000, Val Acc: 0.5790
Epoch 45/100, Loss: 0.6350, Acc: 0.6464, Val Loss: 0.7005, Val Acc: 0.5886
Epoch 46/100, Loss: 0.6355, Acc: 0.6434, Val Loss: 0.6987, Val Acc: 0.5809
Epoch 47/100, Loss: 0.6353, Acc: 0.6458, Val Loss: 0.7036, Val Acc: 0.5754
Epoch 48/100, Loss: 0.6352, Acc: 0.6444, Val Loss: 0.7071, Val Acc: 0.5632
Epoch 49/100, Loss: 0.6351, Acc: 0.6437, Val Loss: 0.7040, Val Acc: 0.5728
Epoch 50/100, Loss: 0.6345, Acc: 0.6457, Val Loss: 0.7081, Val Acc: 0.5643
Epoch 51/100, Loss: 0.6342, Acc: 0.6451, Val Loss: 0.7050, Val Acc: 0.5783
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6333, Acc: 0.6452, Val Loss: 0.7058, Val Acc: 0.5757
Epoch 53/100, Loss: 0.6333, Acc: 0.6460, Val Loss: 0.7035, Val Acc: 0.5813
Epoch 54/100, Loss: 0.6329, Acc: 0.6460, Val Loss: 0.7040, Val Acc: 0.5838
Epoch 55/100, Loss: 0.6330, Acc: 0.6464, Val Loss: 0.7043, Val Acc: 0.5754
Epoch 56/100, Loss: 0.6328, Acc: 0.6467, Val Loss: 0.7033, Val Acc: 0.5776
Epoch 57/100, Loss: 0.6326, Acc: 0.6467, Val Loss: 0.7034, Val Acc: 0.5813
Epoch 58/100, Loss: 0.6325, Acc: 0.6468, Val Loss: 0.7037, Val Acc: 0.5805
Epoch 59/100, Loss: 0.6323, Acc: 0.6445, Val Loss: 0.7046, Val Acc: 0.5838
Epoch 60/100, Loss: 0.6322, Acc: 0.6439, Val Loss: 0.7079, Val Acc: 0.5772
Epoch 61/100, Loss: 0.6321, Acc: 0.6463, Val Loss: 0.7067, Val Acc: 0.5743
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6317, Acc: 0.6465, Val Loss: 0.7072, Val Acc: 0.5754
Epoch 63/100, Loss: 0.6314, Acc: 0.6459, Val Loss: 0.7094, Val Acc: 0.5746
Epoch 64/100, Loss: 0.6313, Acc: 0.6464, Val Loss: 0.7091, Val Acc: 0.5768
Epoch 65/100, Loss: 0.6311, Acc: 0.6461, Val Loss: 0.7102, Val Acc: 0.5746
Epoch 66/100, Loss: 0.6310, Acc: 0.6462, Val Loss: 0.7099, Val Acc: 0.5754
Epoch 67/100, Loss: 0.6310, Acc: 0.6477, Val Loss: 0.7094, Val Acc: 0.5790
Epoch 68/100, Loss: 0.6309, Acc: 0.6461, Val Loss: 0.7098, Val Acc: 0.5801
Epoch 69/100, Loss: 0.6309, Acc: 0.6461, Val Loss: 0.7096, Val Acc: 0.5794
Epoch 70/100, Loss: 0.6309, Acc: 0.6466, Val Loss: 0.7101, Val Acc: 0.5750
Epoch 71/100, Loss: 0.6307, Acc: 0.6460, Val Loss: 0.7106, Val Acc: 0.5746
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6306, Acc: 0.6464, Val Loss: 0.7105, Val Acc: 0.5754
Epoch 73/100, Loss: 0.6305, Acc: 0.6462, Val Loss: 0.7109, Val Acc: 0.5757
Epoch 74/100, Loss: 0.6304, Acc: 0.6470, Val Loss: 0.7103, Val Acc: 0.5776
Epoch 75/100, Loss: 0.6304, Acc: 0.6458, Val Loss: 0.7109, Val Acc: 0.5750
Epoch 76/100, Loss: 0.6304, Acc: 0.6456, Val Loss: 0.7111, Val Acc: 0.5750
Epoch 77/100, Loss: 0.6304, Acc: 0.6461, Val Loss: 0.7110, Val Acc: 0.5746
Epoch 78/100, Loss: 0.6303, Acc: 0.6464, Val Loss: 0.7114, Val Acc: 0.5746
Epoch 79/100, Loss: 0.6303, Acc: 0.6459, Val Loss: 0.7115, Val Acc: 0.5743
Epoch 80/100, Loss: 0.6302, Acc: 0.6464, Val Loss: 0.7113, Val Acc: 0.5750
Epoch 81/100, Loss: 0.6302, Acc: 0.6460, Val Loss: 0.7110, Val Acc: 0.5750
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6301, Acc: 0.6463, Val Loss: 0.7115, Val Acc: 0.5743
Epoch 83/100, Loss: 0.6301, Acc: 0.6470, Val Loss: 0.7109, Val Acc: 0.5746
Epoch 84/100, Loss: 0.6300, Acc: 0.6463, Val Loss: 0.7109, Val Acc: 0.5783
Epoch 85/100, Loss: 0.6300, Acc: 0.6464, Val Loss: 0.7111, Val Acc: 0.5746
Epoch 86/100, Loss: 0.6300, Acc: 0.6469, Val Loss: 0.7115, Val Acc: 0.5750
Epoch 87/100, Loss: 0.6299, Acc: 0.6476, Val Loss: 0.7118, Val Acc: 0.5750
Epoch 88/100, Loss: 0.6299, Acc: 0.6463, Val Loss: 0.7120, Val Acc: 0.5754
Epoch 89/100, Loss: 0.6298, Acc: 0.6468, Val Loss: 0.7116, Val Acc: 0.5750
Epoch 90/100, Loss: 0.6298, Acc: 0.6461, Val Loss: 0.7120, Val Acc: 0.5750
Epoch 91/100, Loss: 0.6298, Acc: 0.6465, Val Loss: 0.7123, Val Acc: 0.5732
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6297, Acc: 0.6467, Val Loss: 0.7115, Val Acc: 0.5776
Epoch 93/100, Loss: 0.6296, Acc: 0.6468, Val Loss: 0.7114, Val Acc: 0.5772
Epoch 94/100, Loss: 0.6294, Acc: 0.6469, Val Loss: 0.7131, Val Acc: 0.5732
Epoch 95/100, Loss: 0.6292, Acc: 0.6472, Val Loss: 0.7132, Val Acc: 0.5735
Epoch 96/100, Loss: 0.6292, Acc: 0.6466, Val Loss: 0.7131, Val Acc: 0.5732
Epoch 97/100, Loss: 0.6291, Acc: 0.6472, Val Loss: 0.7135, Val Acc: 0.5717
Epoch 98/100, Loss: 0.6291, Acc: 0.6472, Val Loss: 0.7135, Val Acc: 0.5724
Epoch 99/100, Loss: 0.6290, Acc: 0.6467, Val Loss: 0.7133, Val Acc: 0.5750
Epoch 100/100, Loss: 0.6289, Acc: 0.6476, Val Loss: 0.7136, Val Acc: 0.5721

##############################
Resultados para principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  1 
 {'training': [0.6289230108261108, 0.647610294117647, 0.6228580171358629, 0.7483455882352941, 0.6798597194388778], 'validate': [0.7136313028113787, 0.5720588235294117, 0.5675862068965517, 0.6051470588235294, 0.5857651245551602], 'test': [0.5834296378824446, 0.7841176470588235, 0.9149484536082474, 0.6264705882352941, 0.7437150837988827]}

##############################
Resultados para window:  1 
 {'102:020:125:011:021:008': {'training': [0.4947081397561466, 0.7608455882352941, 0.7841409691629956, 0.7198529411764706, 0.7506229633889209], 'validate': [0.23306136353071347, 0.91875, 0.971830985915493, 0.8625, 0.9139072847682119], 'test': [0.8019277061577197, 0.5497058823529412, 0.5402189433603046, 0.6676470588235294, 0.5972112601946856]}, '020:102:125:011:021:008': {'training': [0.47912590275792516, 0.7744485294117647, 0.7328446662507798, 0.8637867647058823, 0.7929463381707729], 'validate': [0.9266594759253568, 0.47095588235294117, 0.4845522096206492, 0.9110294117647059, 0.6326270104671943], 'test': [0.5402078360871032, 0.7402941176470588, 0.6728734659331358, 0.9352941176470588, 0.7826729017967019]}, '125:102:020:011:021:008': {'training': [0.6483071565628051, 0.6282169117647058, 0.6107670319199618, 0.7069852941176471, 0.6553633807616938], 'validate': [0.6171403790629187, 0.6911764705882353, 0.7006172839506173, 0.6676470588235294, 0.6837349397590361], 'test': [0.7239753824693186, 0.4958823529411765, 0.4970034246575342, 0.6829411764705883, 0.5753221010901883]}, '011:102:020:125:021:008': {'training': [0.6858121261877173, 0.5941176470588235, 0.5914285714285714, 0.6088235294117647, 0.6], 'validate': [0.6885624167531036, 0.575, 0.5860033726812817, 0.5110294117647058, 0.5459544383346425], 'test': [0.6945759146301834, 0.46647058823529414, 0.4756825938566553, 0.6558823529411765, 0.5514342235410484]}, '021:102:020:125:011:008': {'training': [0.4801541400306365, 0.7653492647058824, 0.7624068351208871, 0.7709558823529412, 0.7666575267343022], 'validate': [0.41286668320034825, 0.8275735294117647, 0.7728107777097367, 0.9279411764705883, 0.8433010357500835], 'test': [0.42975381375462923, 0.8014705882352942, 0.8169449598021027, 0.7770588235294118, 0.7965028640337655]}, '008:102:020:125:011:021': {'training': [0.6289230108261108, 0.647610294117647, 0.6228580171358629, 0.7483455882352941, 0.6798597194388778], 'validate': [0.7136313028113787, 0.5720588235294117, 0.5675862068965517, 0.6051470588235294, 0.5857651245551602], 'test': [0.5834296378824446, 0.7841176470588235, 0.9149484536082474, 0.6264705882352941, 0.7437150837988827]}}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  036  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  036  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  036  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6897, Acc: 0.5362, Val Loss: 0.6661, Val Acc: 0.7077
Mejor modelo guardado con Val Loss: 0.6661
Epoch 2/100, Loss: 0.6893, Acc: 0.5419, Val Loss: 0.6808, Val Acc: 0.7371
Epoch 3/100, Loss: 0.6930, Acc: 0.5113, Val Loss: 0.6936, Val Acc: 0.5000
Epoch 4/100, Loss: 0.6935, Acc: 0.5020, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 5/100, Loss: 0.6934, Acc: 0.4954, Val Loss: 0.6936, Val Acc: 0.5000
Epoch 6/100, Loss: 0.6934, Acc: 0.4962, Val Loss: 0.6937, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6933, Acc: 0.5007, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 8/100, Loss: 0.6933, Acc: 0.5016, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6934, Acc: 0.5013, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 10/100, Loss: 0.6933, Acc: 0.4971, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 11/100, Loss: 0.6932, Acc: 0.5094, Val Loss: 0.6934, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6932, Acc: 0.5020, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6933, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6933, Acc: 0.4984, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6932, Acc: 0.4995, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 16/100, Loss: 0.6933, Acc: 0.4936, Val Loss: 0.6925, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6940, Acc: 0.5035, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 18/100, Loss: 0.6933, Acc: 0.4932, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 19/100, Loss: 0.6934, Acc: 0.4972, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 20/100, Loss: 0.6933, Acc: 0.4934, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 21/100, Loss: 0.6932, Acc: 0.5018, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.5044, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 23/100, Loss: 0.6932, Acc: 0.4932, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 24/100, Loss: 0.6932, Acc: 0.4959, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 25/100, Loss: 0.6932, Acc: 0.5008, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 26/100, Loss: 0.6932, Acc: 0.4903, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 27/100, Loss: 0.6932, Acc: 0.4991, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 28/100, Loss: 0.6932, Acc: 0.4963, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 29/100, Loss: 0.6932, Acc: 0.4914, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 30/100, Loss: 0.6932, Acc: 0.4955, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 31/100, Loss: 0.6933, Acc: 0.4922, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4968, Val Loss: 0.6932, Val Acc: 0.4989
Epoch 33/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6933, Val Acc: 0.4952
Epoch 34/100, Loss: 0.6932, Acc: 0.4982, Val Loss: 0.6932, Val Acc: 0.4985
Epoch 35/100, Loss: 0.6932, Acc: 0.4978, Val Loss: 0.6935, Val Acc: 0.4761
Epoch 36/100, Loss: 0.6932, Acc: 0.4940, Val Loss: 0.6932, Val Acc: 0.4989
Epoch 37/100, Loss: 0.6932, Acc: 0.4947, Val Loss: 0.6934, Val Acc: 0.4776
Epoch 38/100, Loss: 0.6932, Acc: 0.4947, Val Loss: 0.6928, Val Acc: 0.5658
Epoch 39/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6938, Val Acc: 0.5000
Epoch 40/100, Loss: 0.6931, Acc: 0.4976, Val Loss: 0.6931, Val Acc: 0.5456
Epoch 41/100, Loss: 0.6931, Acc: 0.5075, Val Loss: 0.6929, Val Acc: 0.5566
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6931, Acc: 0.5133, Val Loss: 0.6926, Val Acc: 0.6202
Epoch 43/100, Loss: 0.6931, Acc: 0.5204, Val Loss: 0.6924, Val Acc: 0.6474
Epoch 44/100, Loss: 0.6930, Acc: 0.5217, Val Loss: 0.6924, Val Acc: 0.6368
Epoch 45/100, Loss: 0.6930, Acc: 0.5312, Val Loss: 0.6920, Val Acc: 0.6625
Epoch 46/100, Loss: 0.6929, Acc: 0.5287, Val Loss: 0.6920, Val Acc: 0.6695
Epoch 47/100, Loss: 0.6929, Acc: 0.5288, Val Loss: 0.6918, Val Acc: 0.6669
Epoch 48/100, Loss: 0.6928, Acc: 0.5337, Val Loss: 0.6913, Val Acc: 0.6849
Epoch 49/100, Loss: 0.6928, Acc: 0.5311, Val Loss: 0.6916, Val Acc: 0.6632
Epoch 50/100, Loss: 0.6928, Acc: 0.5376, Val Loss: 0.6936, Val Acc: 0.5857
Epoch 51/100, Loss: 0.6927, Acc: 0.5371, Val Loss: 0.6916, Val Acc: 0.6500
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6926, Acc: 0.5426, Val Loss: 0.6914, Val Acc: 0.6592
Epoch 53/100, Loss: 0.6925, Acc: 0.5356, Val Loss: 0.6901, Val Acc: 0.6713
Epoch 54/100, Loss: 0.6922, Acc: 0.5412, Val Loss: 0.6891, Val Acc: 0.6801
Epoch 55/100, Loss: 0.6922, Acc: 0.5430, Val Loss: 0.6889, Val Acc: 0.6680
Epoch 56/100, Loss: 0.6921, Acc: 0.5429, Val Loss: 0.6883, Val Acc: 0.6930
Epoch 57/100, Loss: 0.6920, Acc: 0.5443, Val Loss: 0.6881, Val Acc: 0.6971
Epoch 58/100, Loss: 0.6919, Acc: 0.5487, Val Loss: 0.6879, Val Acc: 0.7029
Epoch 59/100, Loss: 0.6919, Acc: 0.5446, Val Loss: 0.6879, Val Acc: 0.6890
Epoch 60/100, Loss: 0.6918, Acc: 0.5454, Val Loss: 0.6873, Val Acc: 0.7107
Epoch 61/100, Loss: 0.6917, Acc: 0.5442, Val Loss: 0.6870, Val Acc: 0.7074
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6916, Acc: 0.5481, Val Loss: 0.6869, Val Acc: 0.7081
Epoch 63/100, Loss: 0.6916, Acc: 0.5476, Val Loss: 0.6866, Val Acc: 0.7125
Epoch 64/100, Loss: 0.6915, Acc: 0.5503, Val Loss: 0.6865, Val Acc: 0.7110
Epoch 65/100, Loss: 0.6915, Acc: 0.5510, Val Loss: 0.6864, Val Acc: 0.7110
Epoch 66/100, Loss: 0.6914, Acc: 0.5508, Val Loss: 0.6861, Val Acc: 0.7151
Epoch 67/100, Loss: 0.6914, Acc: 0.5517, Val Loss: 0.6859, Val Acc: 0.7162
Epoch 68/100, Loss: 0.6913, Acc: 0.5513, Val Loss: 0.6857, Val Acc: 0.7206
Epoch 69/100, Loss: 0.6913, Acc: 0.5526, Val Loss: 0.6857, Val Acc: 0.7180
Epoch 70/100, Loss: 0.6913, Acc: 0.5504, Val Loss: 0.6855, Val Acc: 0.7195
Epoch 71/100, Loss: 0.6912, Acc: 0.5506, Val Loss: 0.6855, Val Acc: 0.7162
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6912, Acc: 0.5545, Val Loss: 0.6853, Val Acc: 0.7154
Epoch 73/100, Loss: 0.6911, Acc: 0.5529, Val Loss: 0.6852, Val Acc: 0.7169
Epoch 74/100, Loss: 0.6911, Acc: 0.5543, Val Loss: 0.6850, Val Acc: 0.7195
Epoch 75/100, Loss: 0.6911, Acc: 0.5545, Val Loss: 0.6850, Val Acc: 0.7202
Epoch 76/100, Loss: 0.6911, Acc: 0.5517, Val Loss: 0.6847, Val Acc: 0.7239
Epoch 77/100, Loss: 0.6910, Acc: 0.5524, Val Loss: 0.6847, Val Acc: 0.7224
Epoch 78/100, Loss: 0.6910, Acc: 0.5545, Val Loss: 0.6847, Val Acc: 0.7232
Epoch 79/100, Loss: 0.6910, Acc: 0.5540, Val Loss: 0.6843, Val Acc: 0.7235
Epoch 80/100, Loss: 0.6910, Acc: 0.5542, Val Loss: 0.6843, Val Acc: 0.7254
Epoch 81/100, Loss: 0.6909, Acc: 0.5527, Val Loss: 0.6842, Val Acc: 0.7243
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6909, Acc: 0.5557, Val Loss: 0.6840, Val Acc: 0.7276
Epoch 83/100, Loss: 0.6909, Acc: 0.5519, Val Loss: 0.6840, Val Acc: 0.7283
Epoch 84/100, Loss: 0.6908, Acc: 0.5563, Val Loss: 0.6838, Val Acc: 0.7294
Epoch 85/100, Loss: 0.6908, Acc: 0.5539, Val Loss: 0.6836, Val Acc: 0.7298
Epoch 86/100, Loss: 0.6908, Acc: 0.5540, Val Loss: 0.6836, Val Acc: 0.7294
Epoch 87/100, Loss: 0.6907, Acc: 0.5534, Val Loss: 0.6834, Val Acc: 0.7316
Epoch 88/100, Loss: 0.6907, Acc: 0.5535, Val Loss: 0.6833, Val Acc: 0.7327
Epoch 89/100, Loss: 0.6907, Acc: 0.5556, Val Loss: 0.6832, Val Acc: 0.7331
Epoch 90/100, Loss: 0.6906, Acc: 0.5538, Val Loss: 0.6831, Val Acc: 0.7324
Epoch 91/100, Loss: 0.6906, Acc: 0.5534, Val Loss: 0.6829, Val Acc: 0.7349
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6906, Acc: 0.5528, Val Loss: 0.6828, Val Acc: 0.7346
Epoch 93/100, Loss: 0.6906, Acc: 0.5528, Val Loss: 0.6827, Val Acc: 0.7382
Epoch 94/100, Loss: 0.6905, Acc: 0.5556, Val Loss: 0.6826, Val Acc: 0.7412
Epoch 95/100, Loss: 0.6905, Acc: 0.5552, Val Loss: 0.6824, Val Acc: 0.7397
Epoch 96/100, Loss: 0.6904, Acc: 0.5556, Val Loss: 0.6823, Val Acc: 0.7404
Epoch 97/100, Loss: 0.6904, Acc: 0.5551, Val Loss: 0.6822, Val Acc: 0.7360
Epoch 98/100, Loss: 0.6903, Acc: 0.5546, Val Loss: 0.6818, Val Acc: 0.7390
Epoch 99/100, Loss: 0.6903, Acc: 0.5552, Val Loss: 0.6815, Val Acc: 0.7430
Epoch 100/100, Loss: 0.6902, Acc: 0.5548, Val Loss: 0.6812, Val Acc: 0.7449

##############################
Resultados para principal:  036  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1 
 {'training': [0.6902135698234334, 0.5547794117647059, 0.5505598914149983, 0.5965073529411765, 0.5726133756837833], 'validate': [0.6812007635138756, 0.7448529411764706, 0.7694174757281553, 0.6992647058823529, 0.7326656394453005], 'test': [0.6895691730357982, 0.5323529411764706, 0.5184687709872398, 0.908235294117647, 0.6601111586147926]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  024  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  024  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  024  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6237, Acc: 0.6705, Val Loss: 0.7178, Val Acc: 0.6033
Mejor modelo guardado con Val Loss: 0.7178
Epoch 2/100, Loss: 0.5697, Acc: 0.7095, Val Loss: 0.7464, Val Acc: 0.4849
Epoch 3/100, Loss: 0.5547, Acc: 0.7192, Val Loss: 0.7622, Val Acc: 0.5335
Epoch 4/100, Loss: 0.5400, Acc: 0.7243, Val Loss: 0.7804, Val Acc: 0.5702
Epoch 5/100, Loss: 0.5445, Acc: 0.7217, Val Loss: 0.7530, Val Acc: 0.5669
Epoch 6/100, Loss: 0.5358, Acc: 0.7286, Val Loss: 0.7301, Val Acc: 0.5408
Epoch 7/100, Loss: 0.5352, Acc: 0.7294, Val Loss: 0.7612, Val Acc: 0.5496
Epoch 8/100, Loss: 0.5313, Acc: 0.7264, Val Loss: 0.7718, Val Acc: 0.5544
Epoch 9/100, Loss: 0.5344, Acc: 0.7250, Val Loss: 0.7694, Val Acc: 0.5504
Epoch 10/100, Loss: 0.5273, Acc: 0.7251, Val Loss: 0.7927, Val Acc: 0.5338
Epoch 11/100, Loss: 0.5324, Acc: 0.7205, Val Loss: 0.7882, Val Acc: 0.5658
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5235, Acc: 0.7312, Val Loss: 0.7506, Val Acc: 0.5735
Epoch 13/100, Loss: 0.5212, Acc: 0.7291, Val Loss: 0.7164, Val Acc: 0.5945
Mejor modelo guardado con Val Loss: 0.7164
Epoch 14/100, Loss: 0.5270, Acc: 0.7290, Val Loss: 0.7446, Val Acc: 0.5857
Epoch 15/100, Loss: 0.5229, Acc: 0.7302, Val Loss: 0.7432, Val Acc: 0.5820
Epoch 16/100, Loss: 0.5231, Acc: 0.7325, Val Loss: 0.7629, Val Acc: 0.5496
Epoch 17/100, Loss: 0.5201, Acc: 0.7303, Val Loss: 0.7354, Val Acc: 0.5643
Epoch 18/100, Loss: 0.5221, Acc: 0.7320, Val Loss: 0.7980, Val Acc: 0.5235
Epoch 19/100, Loss: 0.5223, Acc: 0.7308, Val Loss: 0.7442, Val Acc: 0.5886
Epoch 20/100, Loss: 0.5208, Acc: 0.7282, Val Loss: 0.8165, Val Acc: 0.5213
Epoch 21/100, Loss: 0.5218, Acc: 0.7343, Val Loss: 0.7376, Val Acc: 0.5831
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5181, Acc: 0.7333, Val Loss: 0.7810, Val Acc: 0.5309
Epoch 23/100, Loss: 0.5172, Acc: 0.7361, Val Loss: 0.7591, Val Acc: 0.5816
Epoch 24/100, Loss: 0.5155, Acc: 0.7348, Val Loss: 0.7508, Val Acc: 0.5570
Epoch 25/100, Loss: 0.5142, Acc: 0.7300, Val Loss: 0.7800, Val Acc: 0.5548
Epoch 26/100, Loss: 0.5148, Acc: 0.7341, Val Loss: 0.7571, Val Acc: 0.5790
Epoch 27/100, Loss: 0.5142, Acc: 0.7324, Val Loss: 0.7482, Val Acc: 0.5853
Epoch 28/100, Loss: 0.5139, Acc: 0.7360, Val Loss: 0.7663, Val Acc: 0.5489
Epoch 29/100, Loss: 0.5141, Acc: 0.7357, Val Loss: 0.7464, Val Acc: 0.5735
Epoch 30/100, Loss: 0.5125, Acc: 0.7366, Val Loss: 0.7296, Val Acc: 0.5724
Epoch 31/100, Loss: 0.5121, Acc: 0.7366, Val Loss: 0.7538, Val Acc: 0.5603
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5109, Acc: 0.7388, Val Loss: 0.7507, Val Acc: 0.5581
Epoch 33/100, Loss: 0.5104, Acc: 0.7381, Val Loss: 0.7668, Val Acc: 0.5607
Epoch 34/100, Loss: 0.5103, Acc: 0.7393, Val Loss: 0.7689, Val Acc: 0.5735
Epoch 35/100, Loss: 0.5098, Acc: 0.7391, Val Loss: 0.7478, Val Acc: 0.5783
Epoch 36/100, Loss: 0.5114, Acc: 0.7355, Val Loss: 0.8018, Val Acc: 0.5426
Epoch 37/100, Loss: 0.5099, Acc: 0.7394, Val Loss: 0.7667, Val Acc: 0.5801
Epoch 38/100, Loss: 0.5097, Acc: 0.7392, Val Loss: 0.7643, Val Acc: 0.5647
Epoch 39/100, Loss: 0.5101, Acc: 0.7378, Val Loss: 0.7751, Val Acc: 0.5654
Epoch 40/100, Loss: 0.5101, Acc: 0.7384, Val Loss: 0.7452, Val Acc: 0.5783
Epoch 41/100, Loss: 0.5103, Acc: 0.7364, Val Loss: 0.7575, Val Acc: 0.5636
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5087, Acc: 0.7403, Val Loss: 0.7606, Val Acc: 0.5665
Epoch 43/100, Loss: 0.5083, Acc: 0.7380, Val Loss: 0.7708, Val Acc: 0.5724
Epoch 44/100, Loss: 0.5083, Acc: 0.7391, Val Loss: 0.7801, Val Acc: 0.5581
Epoch 45/100, Loss: 0.5086, Acc: 0.7396, Val Loss: 0.7910, Val Acc: 0.5581
Epoch 46/100, Loss: 0.5081, Acc: 0.7402, Val Loss: 0.7862, Val Acc: 0.5603
Epoch 47/100, Loss: 0.5081, Acc: 0.7392, Val Loss: 0.7822, Val Acc: 0.5676
Epoch 48/100, Loss: 0.5080, Acc: 0.7416, Val Loss: 0.7791, Val Acc: 0.5563
Epoch 49/100, Loss: 0.5081, Acc: 0.7393, Val Loss: 0.7853, Val Acc: 0.5643
Epoch 50/100, Loss: 0.5077, Acc: 0.7410, Val Loss: 0.7804, Val Acc: 0.5529
Epoch 51/100, Loss: 0.5083, Acc: 0.7414, Val Loss: 0.7703, Val Acc: 0.5621
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5073, Acc: 0.7401, Val Loss: 0.7686, Val Acc: 0.5680
Epoch 53/100, Loss: 0.5072, Acc: 0.7401, Val Loss: 0.7797, Val Acc: 0.5544
Epoch 54/100, Loss: 0.5070, Acc: 0.7398, Val Loss: 0.7879, Val Acc: 0.5687
Epoch 55/100, Loss: 0.5072, Acc: 0.7408, Val Loss: 0.7843, Val Acc: 0.5570
Epoch 56/100, Loss: 0.5068, Acc: 0.7421, Val Loss: 0.7813, Val Acc: 0.5607
Epoch 57/100, Loss: 0.5069, Acc: 0.7414, Val Loss: 0.7881, Val Acc: 0.5721
Epoch 58/100, Loss: 0.5068, Acc: 0.7417, Val Loss: 0.7733, Val Acc: 0.5746
Epoch 59/100, Loss: 0.5069, Acc: 0.7408, Val Loss: 0.7673, Val Acc: 0.5669
Epoch 60/100, Loss: 0.5070, Acc: 0.7408, Val Loss: 0.7785, Val Acc: 0.5632
Epoch 61/100, Loss: 0.5070, Acc: 0.7420, Val Loss: 0.7803, Val Acc: 0.5728
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5066, Acc: 0.7406, Val Loss: 0.7766, Val Acc: 0.5658
Epoch 63/100, Loss: 0.5064, Acc: 0.7425, Val Loss: 0.7803, Val Acc: 0.5632
Epoch 64/100, Loss: 0.5063, Acc: 0.7418, Val Loss: 0.7795, Val Acc: 0.5721
Epoch 65/100, Loss: 0.5064, Acc: 0.7409, Val Loss: 0.7778, Val Acc: 0.5640
Epoch 66/100, Loss: 0.5064, Acc: 0.7411, Val Loss: 0.7813, Val Acc: 0.5651
Epoch 67/100, Loss: 0.5063, Acc: 0.7417, Val Loss: 0.7772, Val Acc: 0.5662
Epoch 68/100, Loss: 0.5064, Acc: 0.7416, Val Loss: 0.7798, Val Acc: 0.5577
Epoch 69/100, Loss: 0.5062, Acc: 0.7414, Val Loss: 0.7763, Val Acc: 0.5717
Epoch 70/100, Loss: 0.5062, Acc: 0.7420, Val Loss: 0.7795, Val Acc: 0.5669
Epoch 71/100, Loss: 0.5063, Acc: 0.7418, Val Loss: 0.7758, Val Acc: 0.5684
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5060, Acc: 0.7424, Val Loss: 0.7797, Val Acc: 0.5651
Epoch 73/100, Loss: 0.5060, Acc: 0.7426, Val Loss: 0.7806, Val Acc: 0.5654
Epoch 74/100, Loss: 0.5060, Acc: 0.7415, Val Loss: 0.7792, Val Acc: 0.5658
Epoch 75/100, Loss: 0.5060, Acc: 0.7416, Val Loss: 0.7798, Val Acc: 0.5647
Epoch 76/100, Loss: 0.5060, Acc: 0.7425, Val Loss: 0.7784, Val Acc: 0.5643
Epoch 77/100, Loss: 0.5060, Acc: 0.7426, Val Loss: 0.7790, Val Acc: 0.5658
Epoch 78/100, Loss: 0.5059, Acc: 0.7425, Val Loss: 0.7774, Val Acc: 0.5654
Epoch 79/100, Loss: 0.5060, Acc: 0.7427, Val Loss: 0.7792, Val Acc: 0.5581
Epoch 80/100, Loss: 0.5060, Acc: 0.7415, Val Loss: 0.7803, Val Acc: 0.5632
Epoch 81/100, Loss: 0.5059, Acc: 0.7421, Val Loss: 0.7785, Val Acc: 0.5662
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5059, Acc: 0.7414, Val Loss: 0.7781, Val Acc: 0.5658
Epoch 83/100, Loss: 0.5059, Acc: 0.7417, Val Loss: 0.7785, Val Acc: 0.5647
Epoch 84/100, Loss: 0.5060, Acc: 0.7414, Val Loss: 0.7771, Val Acc: 0.5647
Epoch 85/100, Loss: 0.5059, Acc: 0.7418, Val Loss: 0.7756, Val Acc: 0.5680
Epoch 86/100, Loss: 0.5059, Acc: 0.7416, Val Loss: 0.7759, Val Acc: 0.5651
Epoch 87/100, Loss: 0.5059, Acc: 0.7424, Val Loss: 0.7788, Val Acc: 0.5654
Epoch 88/100, Loss: 0.5058, Acc: 0.7428, Val Loss: 0.7804, Val Acc: 0.5687
Epoch 89/100, Loss: 0.5058, Acc: 0.7417, Val Loss: 0.7788, Val Acc: 0.5643
Epoch 90/100, Loss: 0.5058, Acc: 0.7412, Val Loss: 0.7782, Val Acc: 0.5658
Epoch 91/100, Loss: 0.5057, Acc: 0.7432, Val Loss: 0.7761, Val Acc: 0.5669
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5054, Acc: 0.7423, Val Loss: 0.7781, Val Acc: 0.5665
Epoch 93/100, Loss: 0.5052, Acc: 0.7414, Val Loss: 0.7786, Val Acc: 0.5702
Epoch 94/100, Loss: 0.5051, Acc: 0.7420, Val Loss: 0.7791, Val Acc: 0.5691
Epoch 95/100, Loss: 0.5051, Acc: 0.7425, Val Loss: 0.7785, Val Acc: 0.5676
Epoch 96/100, Loss: 0.5050, Acc: 0.7426, Val Loss: 0.7772, Val Acc: 0.5702
Epoch 97/100, Loss: 0.5050, Acc: 0.7426, Val Loss: 0.7786, Val Acc: 0.5669
Epoch 98/100, Loss: 0.5049, Acc: 0.7409, Val Loss: 0.7778, Val Acc: 0.5665
Epoch 99/100, Loss: 0.5049, Acc: 0.7421, Val Loss: 0.7759, Val Acc: 0.5673
Epoch 100/100, Loss: 0.5050, Acc: 0.7426, Val Loss: 0.7774, Val Acc: 0.5665

##############################
Resultados para principal:  024  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1 
 {'training': [0.504967048588921, 0.7425551470588235, 0.750047375402691, 0.7275735294117647, 0.738639544648689], 'validate': [0.7774183582081351, 0.5665441176470588, 0.5628908964558721, 0.5955882352941176, 0.5787781350482315], 'test': [0.6216058885609662, 0.6485294117647059, 0.6099259904222899, 0.8241176470588235, 0.7010257693269952]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  100  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  100  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  100  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6075, Acc: 0.7071, Val Loss: 0.7710, Val Acc: 0.4794
Mejor modelo guardado con Val Loss: 0.7710
Epoch 2/100, Loss: 0.5620, Acc: 0.7256, Val Loss: 0.8296, Val Acc: 0.4768
Epoch 3/100, Loss: 0.5442, Acc: 0.7306, Val Loss: 0.8110, Val Acc: 0.4849
Epoch 4/100, Loss: 0.5395, Acc: 0.7311, Val Loss: 0.8002, Val Acc: 0.4768
Epoch 5/100, Loss: 0.5367, Acc: 0.7341, Val Loss: 0.8425, Val Acc: 0.4827
Epoch 6/100, Loss: 0.5399, Acc: 0.7296, Val Loss: 0.8075, Val Acc: 0.4757
Epoch 7/100, Loss: 0.5350, Acc: 0.7320, Val Loss: 0.8649, Val Acc: 0.4809
Epoch 8/100, Loss: 0.5330, Acc: 0.7332, Val Loss: 0.7982, Val Acc: 0.4827
Epoch 9/100, Loss: 0.5361, Acc: 0.7340, Val Loss: 0.8533, Val Acc: 0.4790
Epoch 10/100, Loss: 0.5318, Acc: 0.7327, Val Loss: 0.8317, Val Acc: 0.4765
Epoch 11/100, Loss: 0.5292, Acc: 0.7369, Val Loss: 0.8759, Val Acc: 0.4813
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5275, Acc: 0.7385, Val Loss: 0.9437, Val Acc: 0.4816
Epoch 13/100, Loss: 0.5216, Acc: 0.7408, Val Loss: 0.8907, Val Acc: 0.4820
Epoch 14/100, Loss: 0.5207, Acc: 0.7392, Val Loss: 0.8441, Val Acc: 0.4768
Epoch 15/100, Loss: 0.5173, Acc: 0.7411, Val Loss: 0.9772, Val Acc: 0.4813
Epoch 16/100, Loss: 0.5169, Acc: 0.7405, Val Loss: 0.8899, Val Acc: 0.4835
Epoch 17/100, Loss: 0.5195, Acc: 0.7353, Val Loss: 0.8780, Val Acc: 0.4783
Epoch 18/100, Loss: 0.5196, Acc: 0.7393, Val Loss: 0.8863, Val Acc: 0.4875
Epoch 19/100, Loss: 0.5180, Acc: 0.7375, Val Loss: 0.8910, Val Acc: 0.4857
Epoch 20/100, Loss: 0.5168, Acc: 0.7381, Val Loss: 0.9220, Val Acc: 0.4890
Epoch 21/100, Loss: 0.5198, Acc: 0.7384, Val Loss: 0.9141, Val Acc: 0.4783
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5163, Acc: 0.7371, Val Loss: 0.9560, Val Acc: 0.4816
Epoch 23/100, Loss: 0.5142, Acc: 0.7390, Val Loss: 0.9096, Val Acc: 0.4882
Epoch 24/100, Loss: 0.5116, Acc: 0.7449, Val Loss: 0.9145, Val Acc: 0.4926
Epoch 25/100, Loss: 0.5100, Acc: 0.7436, Val Loss: 0.8660, Val Acc: 0.4816
Epoch 26/100, Loss: 0.5104, Acc: 0.7413, Val Loss: 0.8775, Val Acc: 0.4849
Epoch 27/100, Loss: 0.5101, Acc: 0.7444, Val Loss: 0.9260, Val Acc: 0.4897
Epoch 28/100, Loss: 0.5107, Acc: 0.7425, Val Loss: 0.9043, Val Acc: 0.4853
Epoch 29/100, Loss: 0.5098, Acc: 0.7415, Val Loss: 0.8935, Val Acc: 0.4813
Epoch 30/100, Loss: 0.5093, Acc: 0.7407, Val Loss: 0.9233, Val Acc: 0.4842
Epoch 31/100, Loss: 0.5083, Acc: 0.7422, Val Loss: 0.8904, Val Acc: 0.4824
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5066, Acc: 0.7439, Val Loss: 0.8977, Val Acc: 0.4853
Epoch 33/100, Loss: 0.5062, Acc: 0.7432, Val Loss: 0.9194, Val Acc: 0.4879
Epoch 34/100, Loss: 0.5064, Acc: 0.7452, Val Loss: 0.9116, Val Acc: 0.4871
Epoch 35/100, Loss: 0.5058, Acc: 0.7448, Val Loss: 0.9098, Val Acc: 0.4868
Epoch 36/100, Loss: 0.5060, Acc: 0.7437, Val Loss: 0.8869, Val Acc: 0.4846
Epoch 37/100, Loss: 0.5059, Acc: 0.7421, Val Loss: 0.8983, Val Acc: 0.4886
Epoch 38/100, Loss: 0.5053, Acc: 0.7415, Val Loss: 0.9289, Val Acc: 0.4860
Epoch 39/100, Loss: 0.5059, Acc: 0.7428, Val Loss: 0.9078, Val Acc: 0.4890
Epoch 40/100, Loss: 0.5054, Acc: 0.7433, Val Loss: 0.8784, Val Acc: 0.4857
Epoch 41/100, Loss: 0.5045, Acc: 0.7455, Val Loss: 0.9338, Val Acc: 0.4864
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5040, Acc: 0.7440, Val Loss: 0.9126, Val Acc: 0.4857
Epoch 43/100, Loss: 0.5034, Acc: 0.7445, Val Loss: 0.9205, Val Acc: 0.4842
Epoch 44/100, Loss: 0.5032, Acc: 0.7447, Val Loss: 0.9005, Val Acc: 0.4849
Epoch 45/100, Loss: 0.5033, Acc: 0.7451, Val Loss: 0.9189, Val Acc: 0.4871
Epoch 46/100, Loss: 0.5035, Acc: 0.7454, Val Loss: 0.9143, Val Acc: 0.4868
Epoch 47/100, Loss: 0.5030, Acc: 0.7447, Val Loss: 0.9176, Val Acc: 0.4846
Epoch 48/100, Loss: 0.5034, Acc: 0.7447, Val Loss: 0.9133, Val Acc: 0.4871
Epoch 49/100, Loss: 0.5026, Acc: 0.7453, Val Loss: 0.9066, Val Acc: 0.4871
Epoch 50/100, Loss: 0.5024, Acc: 0.7451, Val Loss: 0.9267, Val Acc: 0.4860
Epoch 51/100, Loss: 0.5027, Acc: 0.7444, Val Loss: 0.9195, Val Acc: 0.4853
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5021, Acc: 0.7454, Val Loss: 0.9136, Val Acc: 0.4864
Epoch 53/100, Loss: 0.5017, Acc: 0.7454, Val Loss: 0.9258, Val Acc: 0.4879
Epoch 54/100, Loss: 0.5018, Acc: 0.7460, Val Loss: 0.9189, Val Acc: 0.4864
Epoch 55/100, Loss: 0.5018, Acc: 0.7459, Val Loss: 0.9164, Val Acc: 0.4871
Epoch 56/100, Loss: 0.5014, Acc: 0.7461, Val Loss: 0.9237, Val Acc: 0.4879
Epoch 57/100, Loss: 0.5014, Acc: 0.7441, Val Loss: 0.9234, Val Acc: 0.4879
Epoch 58/100, Loss: 0.5015, Acc: 0.7452, Val Loss: 0.9275, Val Acc: 0.4868
Epoch 59/100, Loss: 0.5015, Acc: 0.7469, Val Loss: 0.9208, Val Acc: 0.4846
Epoch 60/100, Loss: 0.5014, Acc: 0.7466, Val Loss: 0.9248, Val Acc: 0.4864
Epoch 61/100, Loss: 0.5013, Acc: 0.7448, Val Loss: 0.9297, Val Acc: 0.4868
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5012, Acc: 0.7460, Val Loss: 0.9256, Val Acc: 0.4875
Epoch 63/100, Loss: 0.5010, Acc: 0.7463, Val Loss: 0.9237, Val Acc: 0.4871
Epoch 64/100, Loss: 0.5010, Acc: 0.7460, Val Loss: 0.9227, Val Acc: 0.4875
Epoch 65/100, Loss: 0.5009, Acc: 0.7464, Val Loss: 0.9168, Val Acc: 0.4875
Epoch 66/100, Loss: 0.5008, Acc: 0.7464, Val Loss: 0.9230, Val Acc: 0.4864
Epoch 67/100, Loss: 0.5009, Acc: 0.7468, Val Loss: 0.9221, Val Acc: 0.4882
Epoch 68/100, Loss: 0.5007, Acc: 0.7472, Val Loss: 0.9199, Val Acc: 0.4875
Epoch 69/100, Loss: 0.5008, Acc: 0.7460, Val Loss: 0.9253, Val Acc: 0.4879
Epoch 70/100, Loss: 0.5007, Acc: 0.7462, Val Loss: 0.9203, Val Acc: 0.4890
Epoch 71/100, Loss: 0.5007, Acc: 0.7462, Val Loss: 0.9202, Val Acc: 0.4882
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5006, Acc: 0.7464, Val Loss: 0.9229, Val Acc: 0.4882
Epoch 73/100, Loss: 0.5005, Acc: 0.7463, Val Loss: 0.9192, Val Acc: 0.4882
Epoch 74/100, Loss: 0.5005, Acc: 0.7466, Val Loss: 0.9224, Val Acc: 0.4882
Epoch 75/100, Loss: 0.5004, Acc: 0.7473, Val Loss: 0.9227, Val Acc: 0.4879
Epoch 76/100, Loss: 0.5004, Acc: 0.7461, Val Loss: 0.9224, Val Acc: 0.4886
Epoch 77/100, Loss: 0.5004, Acc: 0.7468, Val Loss: 0.9243, Val Acc: 0.4882
Epoch 78/100, Loss: 0.5004, Acc: 0.7460, Val Loss: 0.9235, Val Acc: 0.4882
Epoch 79/100, Loss: 0.5004, Acc: 0.7453, Val Loss: 0.9262, Val Acc: 0.4871
Epoch 80/100, Loss: 0.5003, Acc: 0.7482, Val Loss: 0.9221, Val Acc: 0.4882
Epoch 81/100, Loss: 0.5003, Acc: 0.7469, Val Loss: 0.9221, Val Acc: 0.4875
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5003, Acc: 0.7470, Val Loss: 0.9238, Val Acc: 0.4882
Epoch 83/100, Loss: 0.5002, Acc: 0.7476, Val Loss: 0.9211, Val Acc: 0.4879
Epoch 84/100, Loss: 0.5003, Acc: 0.7452, Val Loss: 0.9254, Val Acc: 0.4882
Epoch 85/100, Loss: 0.5003, Acc: 0.7473, Val Loss: 0.9229, Val Acc: 0.4882
Epoch 86/100, Loss: 0.5002, Acc: 0.7475, Val Loss: 0.9200, Val Acc: 0.4875
Epoch 87/100, Loss: 0.5003, Acc: 0.7466, Val Loss: 0.9229, Val Acc: 0.4879
Epoch 88/100, Loss: 0.5003, Acc: 0.7471, Val Loss: 0.9216, Val Acc: 0.4882
Epoch 89/100, Loss: 0.5002, Acc: 0.7472, Val Loss: 0.9235, Val Acc: 0.4879
Epoch 90/100, Loss: 0.5002, Acc: 0.7466, Val Loss: 0.9223, Val Acc: 0.4882
Epoch 91/100, Loss: 0.5001, Acc: 0.7470, Val Loss: 0.9216, Val Acc: 0.4875
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5002, Acc: 0.7475, Val Loss: 0.9211, Val Acc: 0.4879
Epoch 93/100, Loss: 0.5001, Acc: 0.7473, Val Loss: 0.9199, Val Acc: 0.4875
Epoch 94/100, Loss: 0.5001, Acc: 0.7467, Val Loss: 0.9208, Val Acc: 0.4879
Epoch 95/100, Loss: 0.5001, Acc: 0.7469, Val Loss: 0.9242, Val Acc: 0.4879
Epoch 96/100, Loss: 0.5001, Acc: 0.7480, Val Loss: 0.9245, Val Acc: 0.4882
Epoch 97/100, Loss: 0.5001, Acc: 0.7466, Val Loss: 0.9249, Val Acc: 0.4882
Epoch 98/100, Loss: 0.5000, Acc: 0.7468, Val Loss: 0.9241, Val Acc: 0.4879
Epoch 99/100, Loss: 0.4999, Acc: 0.7467, Val Loss: 0.9254, Val Acc: 0.4879
Epoch 100/100, Loss: 0.4999, Acc: 0.7477, Val Loss: 0.9229, Val Acc: 0.4882

##############################
Resultados para principal:  100  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1 
 {'training': [0.49985529955695657, 0.7477022058823529, 0.793381232310037, 0.6698529411764705, 0.72640287052726], 'validate': [0.9228542090155357, 0.48823529411764705, 0.46261682242990654, 0.14558823529411766, 0.2214765100671141], 'test': [0.601868807165711, 0.691764705882353, 0.75115562403698, 0.5735294117647058, 0.6504336224149433]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  090  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  090  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  090  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6770, Acc: 0.5783, Val Loss: 0.6961, Val Acc: 0.4548
Mejor modelo guardado con Val Loss: 0.6961
Epoch 2/100, Loss: 0.6663, Acc: 0.5987, Val Loss: 0.6982, Val Acc: 0.4743
Epoch 3/100, Loss: 0.6508, Acc: 0.6138, Val Loss: 0.7209, Val Acc: 0.4426
Epoch 4/100, Loss: 0.6509, Acc: 0.6104, Val Loss: 0.7029, Val Acc: 0.5074
Epoch 5/100, Loss: 0.6439, Acc: 0.6105, Val Loss: 0.6665, Val Acc: 0.5559
Mejor modelo guardado con Val Loss: 0.6665
Epoch 6/100, Loss: 0.6331, Acc: 0.6233, Val Loss: 0.7341, Val Acc: 0.4526
Epoch 7/100, Loss: 0.6273, Acc: 0.6248, Val Loss: 0.6906, Val Acc: 0.4853
Epoch 8/100, Loss: 0.6272, Acc: 0.6264, Val Loss: 0.6921, Val Acc: 0.5040
Epoch 9/100, Loss: 0.6250, Acc: 0.6274, Val Loss: 0.6774, Val Acc: 0.5393
Epoch 10/100, Loss: 0.6211, Acc: 0.6297, Val Loss: 0.7537, Val Acc: 0.4129
Epoch 11/100, Loss: 0.6197, Acc: 0.6335, Val Loss: 0.7156, Val Acc: 0.5103
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6143, Acc: 0.6404, Val Loss: 0.6881, Val Acc: 0.5239
Epoch 13/100, Loss: 0.6116, Acc: 0.6431, Val Loss: 0.6728, Val Acc: 0.5485
Epoch 14/100, Loss: 0.6084, Acc: 0.6587, Val Loss: 0.6772, Val Acc: 0.5298
Epoch 15/100, Loss: 0.6097, Acc: 0.6442, Val Loss: 0.6734, Val Acc: 0.5566
Epoch 16/100, Loss: 0.6061, Acc: 0.6452, Val Loss: 0.6919, Val Acc: 0.5375
Epoch 17/100, Loss: 0.6041, Acc: 0.6509, Val Loss: 0.6848, Val Acc: 0.5232
Epoch 18/100, Loss: 0.6037, Acc: 0.6684, Val Loss: 0.7317, Val Acc: 0.5294
Epoch 19/100, Loss: 0.6022, Acc: 0.6608, Val Loss: 0.6777, Val Acc: 0.6268
Epoch 20/100, Loss: 0.6046, Acc: 0.6763, Val Loss: 0.6979, Val Acc: 0.5665
Epoch 21/100, Loss: 0.6017, Acc: 0.6778, Val Loss: 0.6673, Val Acc: 0.6272
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5982, Acc: 0.6857, Val Loss: 0.6871, Val Acc: 0.6125
Epoch 23/100, Loss: 0.5970, Acc: 0.6881, Val Loss: 0.6847, Val Acc: 0.6151
Epoch 24/100, Loss: 0.5979, Acc: 0.6848, Val Loss: 0.6830, Val Acc: 0.6224
Epoch 25/100, Loss: 0.5971, Acc: 0.6842, Val Loss: 0.6768, Val Acc: 0.6121
Epoch 26/100, Loss: 0.5960, Acc: 0.6875, Val Loss: 0.6927, Val Acc: 0.6040
Epoch 27/100, Loss: 0.5966, Acc: 0.6863, Val Loss: 0.6818, Val Acc: 0.6055
Epoch 28/100, Loss: 0.5964, Acc: 0.6851, Val Loss: 0.6778, Val Acc: 0.6147
Epoch 29/100, Loss: 0.5959, Acc: 0.6852, Val Loss: 0.6675, Val Acc: 0.6210
Epoch 30/100, Loss: 0.5956, Acc: 0.6852, Val Loss: 0.6914, Val Acc: 0.5930
Epoch 31/100, Loss: 0.5949, Acc: 0.6855, Val Loss: 0.6976, Val Acc: 0.5945
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5934, Acc: 0.6888, Val Loss: 0.6756, Val Acc: 0.6232
Epoch 33/100, Loss: 0.5930, Acc: 0.6894, Val Loss: 0.7035, Val Acc: 0.5993
Epoch 34/100, Loss: 0.5925, Acc: 0.6896, Val Loss: 0.6895, Val Acc: 0.6110
Epoch 35/100, Loss: 0.5921, Acc: 0.6892, Val Loss: 0.6802, Val Acc: 0.6151
Epoch 36/100, Loss: 0.5918, Acc: 0.6871, Val Loss: 0.6834, Val Acc: 0.6191
Epoch 37/100, Loss: 0.5919, Acc: 0.6896, Val Loss: 0.6909, Val Acc: 0.6033
Epoch 38/100, Loss: 0.5915, Acc: 0.6888, Val Loss: 0.6712, Val Acc: 0.6239
Epoch 39/100, Loss: 0.5914, Acc: 0.6892, Val Loss: 0.6949, Val Acc: 0.5915
Epoch 40/100, Loss: 0.5913, Acc: 0.6901, Val Loss: 0.6946, Val Acc: 0.6107
Epoch 41/100, Loss: 0.5915, Acc: 0.6873, Val Loss: 0.6955, Val Acc: 0.6007
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5907, Acc: 0.6884, Val Loss: 0.6956, Val Acc: 0.6048
Epoch 43/100, Loss: 0.5897, Acc: 0.6937, Val Loss: 0.6984, Val Acc: 0.6026
Epoch 44/100, Loss: 0.5897, Acc: 0.6896, Val Loss: 0.6964, Val Acc: 0.6029
Epoch 45/100, Loss: 0.5899, Acc: 0.6898, Val Loss: 0.6923, Val Acc: 0.6026
Epoch 46/100, Loss: 0.5895, Acc: 0.6891, Val Loss: 0.6775, Val Acc: 0.6199
Epoch 47/100, Loss: 0.5893, Acc: 0.6925, Val Loss: 0.6937, Val Acc: 0.6114
Epoch 48/100, Loss: 0.5897, Acc: 0.6912, Val Loss: 0.6929, Val Acc: 0.6055
Epoch 49/100, Loss: 0.5891, Acc: 0.6905, Val Loss: 0.6848, Val Acc: 0.6191
Epoch 50/100, Loss: 0.5891, Acc: 0.6940, Val Loss: 0.6886, Val Acc: 0.5963
Epoch 51/100, Loss: 0.5893, Acc: 0.6912, Val Loss: 0.6853, Val Acc: 0.6132
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5886, Acc: 0.6904, Val Loss: 0.6910, Val Acc: 0.6092
Epoch 53/100, Loss: 0.5885, Acc: 0.6923, Val Loss: 0.6865, Val Acc: 0.6110
Epoch 54/100, Loss: 0.5884, Acc: 0.6929, Val Loss: 0.6803, Val Acc: 0.6132
Epoch 55/100, Loss: 0.5888, Acc: 0.6913, Val Loss: 0.6850, Val Acc: 0.6129
Epoch 56/100, Loss: 0.5884, Acc: 0.6916, Val Loss: 0.6875, Val Acc: 0.6125
Epoch 57/100, Loss: 0.5883, Acc: 0.6906, Val Loss: 0.6911, Val Acc: 0.6096
Epoch 58/100, Loss: 0.5885, Acc: 0.6899, Val Loss: 0.6895, Val Acc: 0.6077
Epoch 59/100, Loss: 0.5883, Acc: 0.6905, Val Loss: 0.6894, Val Acc: 0.6074
Epoch 60/100, Loss: 0.5881, Acc: 0.6924, Val Loss: 0.6850, Val Acc: 0.6191
Epoch 61/100, Loss: 0.5882, Acc: 0.6908, Val Loss: 0.6929, Val Acc: 0.6066
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5878, Acc: 0.6918, Val Loss: 0.6879, Val Acc: 0.6118
Epoch 63/100, Loss: 0.5878, Acc: 0.6922, Val Loss: 0.6910, Val Acc: 0.6099
Epoch 64/100, Loss: 0.5878, Acc: 0.6923, Val Loss: 0.6851, Val Acc: 0.6162
Epoch 65/100, Loss: 0.5877, Acc: 0.6914, Val Loss: 0.6883, Val Acc: 0.6121
Epoch 66/100, Loss: 0.5878, Acc: 0.6918, Val Loss: 0.6842, Val Acc: 0.6180
Epoch 67/100, Loss: 0.5877, Acc: 0.6913, Val Loss: 0.6893, Val Acc: 0.6121
Epoch 68/100, Loss: 0.5876, Acc: 0.6918, Val Loss: 0.6883, Val Acc: 0.6118
Epoch 69/100, Loss: 0.5877, Acc: 0.6917, Val Loss: 0.6865, Val Acc: 0.6132
Epoch 70/100, Loss: 0.5876, Acc: 0.6915, Val Loss: 0.6899, Val Acc: 0.6107
Epoch 71/100, Loss: 0.5875, Acc: 0.6915, Val Loss: 0.6896, Val Acc: 0.6136
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5875, Acc: 0.6917, Val Loss: 0.6878, Val Acc: 0.6129
Epoch 73/100, Loss: 0.5874, Acc: 0.6907, Val Loss: 0.6881, Val Acc: 0.6136
Epoch 74/100, Loss: 0.5874, Acc: 0.6913, Val Loss: 0.6908, Val Acc: 0.6099
Epoch 75/100, Loss: 0.5874, Acc: 0.6912, Val Loss: 0.6887, Val Acc: 0.6114
Epoch 76/100, Loss: 0.5874, Acc: 0.6910, Val Loss: 0.6876, Val Acc: 0.6151
Epoch 77/100, Loss: 0.5873, Acc: 0.6910, Val Loss: 0.6870, Val Acc: 0.6125
Epoch 78/100, Loss: 0.5873, Acc: 0.6917, Val Loss: 0.6883, Val Acc: 0.6129
Epoch 79/100, Loss: 0.5874, Acc: 0.6926, Val Loss: 0.6904, Val Acc: 0.6103
Epoch 80/100, Loss: 0.5873, Acc: 0.6915, Val Loss: 0.6888, Val Acc: 0.6118
Epoch 81/100, Loss: 0.5873, Acc: 0.6921, Val Loss: 0.6870, Val Acc: 0.6147
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5873, Acc: 0.6912, Val Loss: 0.6883, Val Acc: 0.6129
Epoch 83/100, Loss: 0.5873, Acc: 0.6910, Val Loss: 0.6863, Val Acc: 0.6132
Epoch 84/100, Loss: 0.5872, Acc: 0.6918, Val Loss: 0.6881, Val Acc: 0.6118
Epoch 85/100, Loss: 0.5872, Acc: 0.6920, Val Loss: 0.6885, Val Acc: 0.6125
Epoch 86/100, Loss: 0.5872, Acc: 0.6919, Val Loss: 0.6886, Val Acc: 0.6125
Epoch 87/100, Loss: 0.5872, Acc: 0.6918, Val Loss: 0.6868, Val Acc: 0.6143
Epoch 88/100, Loss: 0.5872, Acc: 0.6912, Val Loss: 0.6874, Val Acc: 0.6118
Epoch 89/100, Loss: 0.5871, Acc: 0.6909, Val Loss: 0.6864, Val Acc: 0.6151
Epoch 90/100, Loss: 0.5872, Acc: 0.6904, Val Loss: 0.6867, Val Acc: 0.6136
Epoch 91/100, Loss: 0.5871, Acc: 0.6927, Val Loss: 0.6885, Val Acc: 0.6121
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5871, Acc: 0.6925, Val Loss: 0.6895, Val Acc: 0.6114
Epoch 93/100, Loss: 0.5871, Acc: 0.6910, Val Loss: 0.6880, Val Acc: 0.6132
Epoch 94/100, Loss: 0.5871, Acc: 0.6921, Val Loss: 0.6887, Val Acc: 0.6110
Epoch 95/100, Loss: 0.5870, Acc: 0.6922, Val Loss: 0.6873, Val Acc: 0.6125
Epoch 96/100, Loss: 0.5870, Acc: 0.6917, Val Loss: 0.6876, Val Acc: 0.6136
Epoch 97/100, Loss: 0.5870, Acc: 0.6923, Val Loss: 0.6869, Val Acc: 0.6140
Epoch 98/100, Loss: 0.5871, Acc: 0.6918, Val Loss: 0.6873, Val Acc: 0.6121
Epoch 99/100, Loss: 0.5870, Acc: 0.6915, Val Loss: 0.6879, Val Acc: 0.6143
Epoch 100/100, Loss: 0.5870, Acc: 0.6918, Val Loss: 0.6888, Val Acc: 0.6121

##############################
Resultados para principal:  090  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1 
 {'training': [0.5869515010539224, 0.6918198529411764, 0.6635323616987933, 0.7783088235294118, 0.7163522544623975], 'validate': [0.6888372073339861, 0.6121323529411765, 0.598705501618123, 0.6801470588235294, 0.6368330464716007], 'test': [0.7220989929305183, 0.45294117647058824, 0.475, 0.8941176470588236, 0.6204081632653061]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  091  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  091  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  091  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6722, Acc: 0.6385, Val Loss: 0.6786, Val Acc: 0.5934
Mejor modelo guardado con Val Loss: 0.6786
Epoch 2/100, Loss: 0.6402, Acc: 0.7005, Val Loss: 0.6660, Val Acc: 0.5993
Mejor modelo guardado con Val Loss: 0.6660
Epoch 3/100, Loss: 0.6118, Acc: 0.7119, Val Loss: 0.6624, Val Acc: 0.6066
Mejor modelo guardado con Val Loss: 0.6624
Epoch 4/100, Loss: 0.5950, Acc: 0.7139, Val Loss: 0.6784, Val Acc: 0.5835
Epoch 5/100, Loss: 0.5821, Acc: 0.7181, Val Loss: 0.6652, Val Acc: 0.5996
Epoch 6/100, Loss: 0.5744, Acc: 0.7186, Val Loss: 0.6592, Val Acc: 0.6129
Mejor modelo guardado con Val Loss: 0.6592
Epoch 7/100, Loss: 0.5690, Acc: 0.7248, Val Loss: 0.6650, Val Acc: 0.6074
Epoch 8/100, Loss: 0.5665, Acc: 0.7236, Val Loss: 0.6722, Val Acc: 0.6070
Epoch 9/100, Loss: 0.5618, Acc: 0.7234, Val Loss: 0.6870, Val Acc: 0.5945
Epoch 10/100, Loss: 0.5613, Acc: 0.7196, Val Loss: 0.6669, Val Acc: 0.6048
Epoch 11/100, Loss: 0.5588, Acc: 0.7250, Val Loss: 0.6732, Val Acc: 0.6004
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5559, Acc: 0.7262, Val Loss: 0.6814, Val Acc: 0.6062
Epoch 13/100, Loss: 0.5544, Acc: 0.7290, Val Loss: 0.6697, Val Acc: 0.6140
Epoch 14/100, Loss: 0.5532, Acc: 0.7258, Val Loss: 0.6796, Val Acc: 0.6070
Epoch 15/100, Loss: 0.5539, Acc: 0.7288, Val Loss: 0.6808, Val Acc: 0.6085
Epoch 16/100, Loss: 0.5512, Acc: 0.7320, Val Loss: 0.7122, Val Acc: 0.5853
Epoch 17/100, Loss: 0.5539, Acc: 0.7263, Val Loss: 0.6771, Val Acc: 0.6018
Epoch 18/100, Loss: 0.5513, Acc: 0.7313, Val Loss: 0.6843, Val Acc: 0.6191
Epoch 19/100, Loss: 0.5534, Acc: 0.7275, Val Loss: 0.6953, Val Acc: 0.6195
Epoch 20/100, Loss: 0.5530, Acc: 0.7304, Val Loss: 0.6942, Val Acc: 0.5960
Epoch 21/100, Loss: 0.5526, Acc: 0.7244, Val Loss: 0.6937, Val Acc: 0.6055
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5511, Acc: 0.7297, Val Loss: 0.6863, Val Acc: 0.6015
Epoch 23/100, Loss: 0.5481, Acc: 0.7326, Val Loss: 0.6785, Val Acc: 0.6011
Epoch 24/100, Loss: 0.5512, Acc: 0.7311, Val Loss: 0.6913, Val Acc: 0.6029
Epoch 25/100, Loss: 0.5505, Acc: 0.7300, Val Loss: 0.6875, Val Acc: 0.6062
Epoch 26/100, Loss: 0.5489, Acc: 0.7324, Val Loss: 0.6754, Val Acc: 0.6048
Epoch 27/100, Loss: 0.5483, Acc: 0.7329, Val Loss: 0.6858, Val Acc: 0.6029
Epoch 28/100, Loss: 0.5492, Acc: 0.7314, Val Loss: 0.6762, Val Acc: 0.5949
Epoch 29/100, Loss: 0.5499, Acc: 0.7301, Val Loss: 0.6776, Val Acc: 0.6221
Epoch 30/100, Loss: 0.5485, Acc: 0.7333, Val Loss: 0.6719, Val Acc: 0.6176
Epoch 31/100, Loss: 0.5468, Acc: 0.7321, Val Loss: 0.7072, Val Acc: 0.5960
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5477, Acc: 0.7318, Val Loss: 0.6822, Val Acc: 0.6154
Epoch 33/100, Loss: 0.5465, Acc: 0.7314, Val Loss: 0.6789, Val Acc: 0.6037
Epoch 34/100, Loss: 0.5471, Acc: 0.7341, Val Loss: 0.6802, Val Acc: 0.6004
Epoch 35/100, Loss: 0.5468, Acc: 0.7339, Val Loss: 0.6764, Val Acc: 0.6224
Epoch 36/100, Loss: 0.5464, Acc: 0.7324, Val Loss: 0.6782, Val Acc: 0.5985
Epoch 37/100, Loss: 0.5466, Acc: 0.7317, Val Loss: 0.6801, Val Acc: 0.6169
Epoch 38/100, Loss: 0.5465, Acc: 0.7324, Val Loss: 0.6789, Val Acc: 0.6221
Epoch 39/100, Loss: 0.5467, Acc: 0.7317, Val Loss: 0.6740, Val Acc: 0.6154
Epoch 40/100, Loss: 0.5462, Acc: 0.7341, Val Loss: 0.6820, Val Acc: 0.6191
Epoch 41/100, Loss: 0.5456, Acc: 0.7318, Val Loss: 0.6706, Val Acc: 0.6140
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5452, Acc: 0.7344, Val Loss: 0.6745, Val Acc: 0.6151
Epoch 43/100, Loss: 0.5450, Acc: 0.7333, Val Loss: 0.6764, Val Acc: 0.6125
Epoch 44/100, Loss: 0.5446, Acc: 0.7333, Val Loss: 0.6820, Val Acc: 0.6018
Epoch 45/100, Loss: 0.5450, Acc: 0.7326, Val Loss: 0.6770, Val Acc: 0.6096
Epoch 46/100, Loss: 0.5447, Acc: 0.7315, Val Loss: 0.6731, Val Acc: 0.6184
Epoch 47/100, Loss: 0.5445, Acc: 0.7314, Val Loss: 0.6775, Val Acc: 0.6125
Epoch 48/100, Loss: 0.5445, Acc: 0.7330, Val Loss: 0.6798, Val Acc: 0.6074
Epoch 49/100, Loss: 0.5445, Acc: 0.7333, Val Loss: 0.6823, Val Acc: 0.6048
Epoch 50/100, Loss: 0.5447, Acc: 0.7356, Val Loss: 0.6779, Val Acc: 0.6206
Epoch 51/100, Loss: 0.5442, Acc: 0.7326, Val Loss: 0.6765, Val Acc: 0.6051
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5439, Acc: 0.7335, Val Loss: 0.6756, Val Acc: 0.6184
Epoch 53/100, Loss: 0.5438, Acc: 0.7338, Val Loss: 0.6764, Val Acc: 0.6162
Epoch 54/100, Loss: 0.5439, Acc: 0.7343, Val Loss: 0.6758, Val Acc: 0.6103
Epoch 55/100, Loss: 0.5439, Acc: 0.7327, Val Loss: 0.6794, Val Acc: 0.6096
Epoch 56/100, Loss: 0.5438, Acc: 0.7340, Val Loss: 0.6769, Val Acc: 0.6143
Epoch 57/100, Loss: 0.5437, Acc: 0.7331, Val Loss: 0.6807, Val Acc: 0.6074
Epoch 58/100, Loss: 0.5439, Acc: 0.7330, Val Loss: 0.6741, Val Acc: 0.6188
Epoch 59/100, Loss: 0.5438, Acc: 0.7324, Val Loss: 0.6751, Val Acc: 0.6147
Epoch 60/100, Loss: 0.5438, Acc: 0.7320, Val Loss: 0.6756, Val Acc: 0.6154
Epoch 61/100, Loss: 0.5434, Acc: 0.7341, Val Loss: 0.6749, Val Acc: 0.6210
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5436, Acc: 0.7318, Val Loss: 0.6770, Val Acc: 0.6140
Epoch 63/100, Loss: 0.5433, Acc: 0.7324, Val Loss: 0.6759, Val Acc: 0.6154
Epoch 64/100, Loss: 0.5434, Acc: 0.7312, Val Loss: 0.6773, Val Acc: 0.6151
Epoch 65/100, Loss: 0.5432, Acc: 0.7339, Val Loss: 0.6798, Val Acc: 0.6059
Epoch 66/100, Loss: 0.5434, Acc: 0.7347, Val Loss: 0.6784, Val Acc: 0.6114
Epoch 67/100, Loss: 0.5433, Acc: 0.7329, Val Loss: 0.6775, Val Acc: 0.6107
Epoch 68/100, Loss: 0.5434, Acc: 0.7317, Val Loss: 0.6769, Val Acc: 0.6140
Epoch 69/100, Loss: 0.5433, Acc: 0.7331, Val Loss: 0.6769, Val Acc: 0.6158
Epoch 70/100, Loss: 0.5432, Acc: 0.7326, Val Loss: 0.6784, Val Acc: 0.6099
Epoch 71/100, Loss: 0.5432, Acc: 0.7320, Val Loss: 0.6781, Val Acc: 0.6162
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5431, Acc: 0.7322, Val Loss: 0.6768, Val Acc: 0.6158
Epoch 73/100, Loss: 0.5431, Acc: 0.7338, Val Loss: 0.6779, Val Acc: 0.6107
Epoch 74/100, Loss: 0.5433, Acc: 0.7332, Val Loss: 0.6773, Val Acc: 0.6107
Epoch 75/100, Loss: 0.5430, Acc: 0.7323, Val Loss: 0.6764, Val Acc: 0.6151
Epoch 76/100, Loss: 0.5432, Acc: 0.7334, Val Loss: 0.6771, Val Acc: 0.6140
Epoch 77/100, Loss: 0.5431, Acc: 0.7322, Val Loss: 0.6773, Val Acc: 0.6151
Epoch 78/100, Loss: 0.5430, Acc: 0.7324, Val Loss: 0.6778, Val Acc: 0.6110
Epoch 79/100, Loss: 0.5431, Acc: 0.7324, Val Loss: 0.6781, Val Acc: 0.6110
Epoch 80/100, Loss: 0.5431, Acc: 0.7328, Val Loss: 0.6779, Val Acc: 0.6151
Epoch 81/100, Loss: 0.5430, Acc: 0.7332, Val Loss: 0.6776, Val Acc: 0.6129
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5431, Acc: 0.7326, Val Loss: 0.6776, Val Acc: 0.6118
Epoch 83/100, Loss: 0.5430, Acc: 0.7332, Val Loss: 0.6777, Val Acc: 0.6114
Epoch 84/100, Loss: 0.5430, Acc: 0.7329, Val Loss: 0.6769, Val Acc: 0.6140
Epoch 85/100, Loss: 0.5430, Acc: 0.7335, Val Loss: 0.6779, Val Acc: 0.6147
Epoch 86/100, Loss: 0.5430, Acc: 0.7324, Val Loss: 0.6774, Val Acc: 0.6132
Epoch 87/100, Loss: 0.5429, Acc: 0.7325, Val Loss: 0.6763, Val Acc: 0.6158
Epoch 88/100, Loss: 0.5429, Acc: 0.7340, Val Loss: 0.6775, Val Acc: 0.6114
Epoch 89/100, Loss: 0.5430, Acc: 0.7335, Val Loss: 0.6775, Val Acc: 0.6151
Epoch 90/100, Loss: 0.5429, Acc: 0.7326, Val Loss: 0.6771, Val Acc: 0.6125
Epoch 91/100, Loss: 0.5429, Acc: 0.7325, Val Loss: 0.6779, Val Acc: 0.6140
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5429, Acc: 0.7325, Val Loss: 0.6779, Val Acc: 0.6125
Epoch 93/100, Loss: 0.5429, Acc: 0.7336, Val Loss: 0.6780, Val Acc: 0.6143
Epoch 94/100, Loss: 0.5428, Acc: 0.7326, Val Loss: 0.6783, Val Acc: 0.6121
Epoch 95/100, Loss: 0.5429, Acc: 0.7341, Val Loss: 0.6777, Val Acc: 0.6129
Epoch 96/100, Loss: 0.5428, Acc: 0.7331, Val Loss: 0.6788, Val Acc: 0.6110
Epoch 97/100, Loss: 0.5428, Acc: 0.7335, Val Loss: 0.6781, Val Acc: 0.6140
Epoch 98/100, Loss: 0.5429, Acc: 0.7321, Val Loss: 0.6777, Val Acc: 0.6143
Epoch 99/100, Loss: 0.5428, Acc: 0.7329, Val Loss: 0.6775, Val Acc: 0.6151
Epoch 100/100, Loss: 0.5429, Acc: 0.7326, Val Loss: 0.6776, Val Acc: 0.6136

##############################
Resultados para principal:  091  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1 
 {'training': [0.5428531055941301, 0.7326286764705883, 0.7648043523749738, 0.671875, 0.7153341814267541], 'validate': [0.6776005913351857, 0.6136029411764706, 0.6437209302325582, 0.5088235294117647, 0.5683778234086242], 'test': [0.7208687078069758, 0.5523529411764706, 0.5405651777575206, 0.6976470588235294, 0.6091422701592193]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  019  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  019  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  019  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6665, Acc: 0.6169, Val Loss: 0.6712, Val Acc: 0.5794
Mejor modelo guardado con Val Loss: 0.6712
Epoch 2/100, Loss: 0.6419, Acc: 0.6534, Val Loss: 0.6294, Val Acc: 0.6717
Mejor modelo guardado con Val Loss: 0.6294
Epoch 3/100, Loss: 0.6250, Acc: 0.6735, Val Loss: 0.6651, Val Acc: 0.6706
Epoch 4/100, Loss: 0.6212, Acc: 0.6830, Val Loss: 0.6228, Val Acc: 0.6813
Mejor modelo guardado con Val Loss: 0.6228
Epoch 5/100, Loss: 0.6079, Acc: 0.6941, Val Loss: 0.6238, Val Acc: 0.6687
Epoch 6/100, Loss: 0.5983, Acc: 0.6972, Val Loss: 0.6204, Val Acc: 0.6695
Mejor modelo guardado con Val Loss: 0.6204
Epoch 7/100, Loss: 0.5939, Acc: 0.6964, Val Loss: 0.5978, Val Acc: 0.6996
Mejor modelo guardado con Val Loss: 0.5978
Epoch 8/100, Loss: 0.5927, Acc: 0.6942, Val Loss: 0.5949, Val Acc: 0.6923
Mejor modelo guardado con Val Loss: 0.5949
Epoch 9/100, Loss: 0.5863, Acc: 0.7011, Val Loss: 0.5874, Val Acc: 0.7026
Mejor modelo guardado con Val Loss: 0.5874
Epoch 10/100, Loss: 0.5925, Acc: 0.6958, Val Loss: 0.6057, Val Acc: 0.6813
Epoch 11/100, Loss: 0.5910, Acc: 0.6943, Val Loss: 0.6039, Val Acc: 0.6816
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5843, Acc: 0.7022, Val Loss: 0.6068, Val Acc: 0.6765
Epoch 13/100, Loss: 0.5798, Acc: 0.7033, Val Loss: 0.5986, Val Acc: 0.6886
Epoch 14/100, Loss: 0.5787, Acc: 0.7034, Val Loss: 0.6004, Val Acc: 0.6849
Epoch 15/100, Loss: 0.5754, Acc: 0.7075, Val Loss: 0.5915, Val Acc: 0.6952
Epoch 16/100, Loss: 0.5759, Acc: 0.7037, Val Loss: 0.6082, Val Acc: 0.6776
Epoch 17/100, Loss: 0.5747, Acc: 0.7083, Val Loss: 0.5989, Val Acc: 0.6820
Epoch 18/100, Loss: 0.5719, Acc: 0.7082, Val Loss: 0.6115, Val Acc: 0.6805
Epoch 19/100, Loss: 0.5729, Acc: 0.7056, Val Loss: 0.6232, Val Acc: 0.6463
Epoch 20/100, Loss: 0.5734, Acc: 0.7072, Val Loss: 0.6429, Val Acc: 0.6393
Epoch 21/100, Loss: 0.5701, Acc: 0.7090, Val Loss: 0.6068, Val Acc: 0.6813
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5671, Acc: 0.7116, Val Loss: 0.5996, Val Acc: 0.6835
Epoch 23/100, Loss: 0.5667, Acc: 0.7124, Val Loss: 0.6172, Val Acc: 0.6710
Epoch 24/100, Loss: 0.5657, Acc: 0.7119, Val Loss: 0.6190, Val Acc: 0.6676
Epoch 25/100, Loss: 0.5652, Acc: 0.7117, Val Loss: 0.6518, Val Acc: 0.6301
Epoch 26/100, Loss: 0.5654, Acc: 0.7139, Val Loss: 0.6128, Val Acc: 0.6761
Epoch 27/100, Loss: 0.5635, Acc: 0.7150, Val Loss: 0.5981, Val Acc: 0.6879
Epoch 28/100, Loss: 0.5642, Acc: 0.7131, Val Loss: 0.5916, Val Acc: 0.6945
Epoch 29/100, Loss: 0.5639, Acc: 0.7147, Val Loss: 0.5986, Val Acc: 0.6827
Epoch 30/100, Loss: 0.5636, Acc: 0.7174, Val Loss: 0.6108, Val Acc: 0.6790
Epoch 31/100, Loss: 0.5620, Acc: 0.7143, Val Loss: 0.6175, Val Acc: 0.6687
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5600, Acc: 0.7192, Val Loss: 0.5995, Val Acc: 0.6857
Epoch 33/100, Loss: 0.5594, Acc: 0.7190, Val Loss: 0.5875, Val Acc: 0.6949
Epoch 34/100, Loss: 0.5597, Acc: 0.7157, Val Loss: 0.6004, Val Acc: 0.6868
Epoch 35/100, Loss: 0.5594, Acc: 0.7179, Val Loss: 0.5998, Val Acc: 0.6860
Epoch 36/100, Loss: 0.5595, Acc: 0.7179, Val Loss: 0.5915, Val Acc: 0.6919
Epoch 37/100, Loss: 0.5587, Acc: 0.7184, Val Loss: 0.6125, Val Acc: 0.6776
Epoch 38/100, Loss: 0.5583, Acc: 0.7171, Val Loss: 0.6001, Val Acc: 0.6864
Epoch 39/100, Loss: 0.5585, Acc: 0.7161, Val Loss: 0.5918, Val Acc: 0.6886
Epoch 40/100, Loss: 0.5579, Acc: 0.7177, Val Loss: 0.5948, Val Acc: 0.6930
Epoch 41/100, Loss: 0.5578, Acc: 0.7180, Val Loss: 0.5940, Val Acc: 0.6919
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5567, Acc: 0.7179, Val Loss: 0.6084, Val Acc: 0.6794
Epoch 43/100, Loss: 0.5569, Acc: 0.7187, Val Loss: 0.5988, Val Acc: 0.6846
Epoch 44/100, Loss: 0.5572, Acc: 0.7203, Val Loss: 0.6036, Val Acc: 0.6838
Epoch 45/100, Loss: 0.5566, Acc: 0.7189, Val Loss: 0.6018, Val Acc: 0.6820
Epoch 46/100, Loss: 0.5561, Acc: 0.7190, Val Loss: 0.6115, Val Acc: 0.6798
Epoch 47/100, Loss: 0.5562, Acc: 0.7192, Val Loss: 0.6043, Val Acc: 0.6820
Epoch 48/100, Loss: 0.5565, Acc: 0.7187, Val Loss: 0.6018, Val Acc: 0.6846
Epoch 49/100, Loss: 0.5559, Acc: 0.7196, Val Loss: 0.5990, Val Acc: 0.6846
Epoch 50/100, Loss: 0.5558, Acc: 0.7198, Val Loss: 0.6003, Val Acc: 0.6824
Epoch 51/100, Loss: 0.5559, Acc: 0.7160, Val Loss: 0.5950, Val Acc: 0.6868
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5554, Acc: 0.7205, Val Loss: 0.6039, Val Acc: 0.6827
Epoch 53/100, Loss: 0.5552, Acc: 0.7204, Val Loss: 0.5970, Val Acc: 0.6849
Epoch 54/100, Loss: 0.5551, Acc: 0.7203, Val Loss: 0.5962, Val Acc: 0.6857
Epoch 55/100, Loss: 0.5551, Acc: 0.7203, Val Loss: 0.6008, Val Acc: 0.6820
Epoch 56/100, Loss: 0.5549, Acc: 0.7201, Val Loss: 0.5974, Val Acc: 0.6849
Epoch 57/100, Loss: 0.5548, Acc: 0.7208, Val Loss: 0.5969, Val Acc: 0.6853
Epoch 58/100, Loss: 0.5548, Acc: 0.7204, Val Loss: 0.5980, Val Acc: 0.6849
Epoch 59/100, Loss: 0.5546, Acc: 0.7210, Val Loss: 0.5969, Val Acc: 0.6846
Epoch 60/100, Loss: 0.5546, Acc: 0.7226, Val Loss: 0.5988, Val Acc: 0.6831
Epoch 61/100, Loss: 0.5542, Acc: 0.7202, Val Loss: 0.5993, Val Acc: 0.6853
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5539, Acc: 0.7199, Val Loss: 0.6011, Val Acc: 0.6816
Epoch 63/100, Loss: 0.5539, Acc: 0.7220, Val Loss: 0.6002, Val Acc: 0.6824
Epoch 64/100, Loss: 0.5539, Acc: 0.7213, Val Loss: 0.5996, Val Acc: 0.6842
Epoch 65/100, Loss: 0.5538, Acc: 0.7218, Val Loss: 0.5998, Val Acc: 0.6827
Epoch 66/100, Loss: 0.5538, Acc: 0.7217, Val Loss: 0.5968, Val Acc: 0.6864
Epoch 67/100, Loss: 0.5538, Acc: 0.7213, Val Loss: 0.5989, Val Acc: 0.6853
Epoch 68/100, Loss: 0.5537, Acc: 0.7210, Val Loss: 0.6029, Val Acc: 0.6816
Epoch 69/100, Loss: 0.5536, Acc: 0.7214, Val Loss: 0.6014, Val Acc: 0.6820
Epoch 70/100, Loss: 0.5536, Acc: 0.7228, Val Loss: 0.6028, Val Acc: 0.6827
Epoch 71/100, Loss: 0.5536, Acc: 0.7215, Val Loss: 0.5996, Val Acc: 0.6835
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5535, Acc: 0.7220, Val Loss: 0.6009, Val Acc: 0.6820
Epoch 73/100, Loss: 0.5534, Acc: 0.7213, Val Loss: 0.5987, Val Acc: 0.6857
Epoch 74/100, Loss: 0.5534, Acc: 0.7221, Val Loss: 0.5982, Val Acc: 0.6860
Epoch 75/100, Loss: 0.5533, Acc: 0.7219, Val Loss: 0.5988, Val Acc: 0.6857
Epoch 76/100, Loss: 0.5534, Acc: 0.7210, Val Loss: 0.5979, Val Acc: 0.6868
Epoch 77/100, Loss: 0.5534, Acc: 0.7215, Val Loss: 0.5984, Val Acc: 0.6857
Epoch 78/100, Loss: 0.5532, Acc: 0.7222, Val Loss: 0.6012, Val Acc: 0.6813
Epoch 79/100, Loss: 0.5533, Acc: 0.7217, Val Loss: 0.6004, Val Acc: 0.6831
Epoch 80/100, Loss: 0.5532, Acc: 0.7222, Val Loss: 0.5985, Val Acc: 0.6860
Epoch 81/100, Loss: 0.5532, Acc: 0.7216, Val Loss: 0.5999, Val Acc: 0.6835
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5532, Acc: 0.7222, Val Loss: 0.6012, Val Acc: 0.6816
Epoch 83/100, Loss: 0.5531, Acc: 0.7227, Val Loss: 0.6037, Val Acc: 0.6820
Epoch 84/100, Loss: 0.5533, Acc: 0.7210, Val Loss: 0.6020, Val Acc: 0.6820
Epoch 85/100, Loss: 0.5531, Acc: 0.7222, Val Loss: 0.6013, Val Acc: 0.6824
Epoch 86/100, Loss: 0.5531, Acc: 0.7217, Val Loss: 0.5994, Val Acc: 0.6838
Epoch 87/100, Loss: 0.5531, Acc: 0.7222, Val Loss: 0.5976, Val Acc: 0.6857
Epoch 88/100, Loss: 0.5531, Acc: 0.7227, Val Loss: 0.5996, Val Acc: 0.6835
Epoch 89/100, Loss: 0.5531, Acc: 0.7219, Val Loss: 0.6004, Val Acc: 0.6835
Epoch 90/100, Loss: 0.5530, Acc: 0.7211, Val Loss: 0.5988, Val Acc: 0.6853
Epoch 91/100, Loss: 0.5531, Acc: 0.7227, Val Loss: 0.6003, Val Acc: 0.6838
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5530, Acc: 0.7219, Val Loss: 0.5991, Val Acc: 0.6853
Epoch 93/100, Loss: 0.5530, Acc: 0.7222, Val Loss: 0.5996, Val Acc: 0.6849
Epoch 94/100, Loss: 0.5530, Acc: 0.7220, Val Loss: 0.6006, Val Acc: 0.6835
Epoch 95/100, Loss: 0.5529, Acc: 0.7213, Val Loss: 0.5992, Val Acc: 0.6846
Epoch 96/100, Loss: 0.5529, Acc: 0.7234, Val Loss: 0.6007, Val Acc: 0.6835
Epoch 97/100, Loss: 0.5528, Acc: 0.7225, Val Loss: 0.6027, Val Acc: 0.6824
Epoch 98/100, Loss: 0.5529, Acc: 0.7225, Val Loss: 0.6025, Val Acc: 0.6816
Epoch 99/100, Loss: 0.5528, Acc: 0.7226, Val Loss: 0.6012, Val Acc: 0.6827
Epoch 100/100, Loss: 0.5528, Acc: 0.7214, Val Loss: 0.5997, Val Acc: 0.6838

##############################
Resultados para principal:  019  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  1 
 {'training': [0.5527808827512405, 0.7214154411764706, 0.7048817826160911, 0.7617647058823529, 0.7322201607915894], 'validate': [0.5997053419434747, 0.6838235294117647, 0.643184421534937, 0.825735294117647, 0.7231165486155827], 'test': [0.8945032678268574, 0.3941176470588235, 0.3953488372093023, 0.4, 0.39766081871345027]}

##############################
Resultados para window:  1 
 {'036:024:100:090:091:019': {'training': [0.6902135698234334, 0.5547794117647059, 0.5505598914149983, 0.5965073529411765, 0.5726133756837833], 'validate': [0.6812007635138756, 0.7448529411764706, 0.7694174757281553, 0.6992647058823529, 0.7326656394453005], 'test': [0.6895691730357982, 0.5323529411764706, 0.5184687709872398, 0.908235294117647, 0.6601111586147926]}, '024:036:100:090:091:019': {'training': [0.504967048588921, 0.7425551470588235, 0.750047375402691, 0.7275735294117647, 0.738639544648689], 'validate': [0.7774183582081351, 0.5665441176470588, 0.5628908964558721, 0.5955882352941176, 0.5787781350482315], 'test': [0.6216058885609662, 0.6485294117647059, 0.6099259904222899, 0.8241176470588235, 0.7010257693269952]}, '100:036:024:090:091:019': {'training': [0.49985529955695657, 0.7477022058823529, 0.793381232310037, 0.6698529411764705, 0.72640287052726], 'validate': [0.9228542090155357, 0.48823529411764705, 0.46261682242990654, 0.14558823529411766, 0.2214765100671141], 'test': [0.601868807165711, 0.691764705882353, 0.75115562403698, 0.5735294117647058, 0.6504336224149433]}, '090:036:024:100:091:019': {'training': [0.5869515010539224, 0.6918198529411764, 0.6635323616987933, 0.7783088235294118, 0.7163522544623975], 'validate': [0.6888372073339861, 0.6121323529411765, 0.598705501618123, 0.6801470588235294, 0.6368330464716007], 'test': [0.7220989929305183, 0.45294117647058824, 0.475, 0.8941176470588236, 0.6204081632653061]}, '091:036:024:100:090:019': {'training': [0.5428531055941301, 0.7326286764705883, 0.7648043523749738, 0.671875, 0.7153341814267541], 'validate': [0.6776005913351857, 0.6136029411764706, 0.6437209302325582, 0.5088235294117647, 0.5683778234086242], 'test': [0.7208687078069758, 0.5523529411764706, 0.5405651777575206, 0.6976470588235294, 0.6091422701592193]}, '019:036:024:100:090:091': {'training': [0.5527808827512405, 0.7214154411764706, 0.7048817826160911, 0.7617647058823529, 0.7322201607915894], 'validate': [0.5997053419434747, 0.6838235294117647, 0.643184421534937, 0.825735294117647, 0.7231165486155827], 'test': [0.8945032678268574, 0.3941176470588235, 0.3953488372093023, 0.4, 0.39766081871345027]}}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  064  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  064  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  064  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6191, Acc: 0.6909, Val Loss: 0.6911, Val Acc: 0.5449
Mejor modelo guardado con Val Loss: 0.6911
Epoch 2/100, Loss: 0.5724, Acc: 0.7080, Val Loss: 0.7169, Val Acc: 0.5463
Epoch 3/100, Loss: 0.5580, Acc: 0.7181, Val Loss: 0.7103, Val Acc: 0.5636
Epoch 4/100, Loss: 0.5542, Acc: 0.7117, Val Loss: 0.7175, Val Acc: 0.5437
Epoch 5/100, Loss: 0.5520, Acc: 0.7192, Val Loss: 0.7067, Val Acc: 0.5621
Epoch 6/100, Loss: 0.5524, Acc: 0.7170, Val Loss: 0.7152, Val Acc: 0.5390
Epoch 7/100, Loss: 0.5522, Acc: 0.7172, Val Loss: 0.7163, Val Acc: 0.5518
Epoch 8/100, Loss: 0.5477, Acc: 0.7143, Val Loss: 0.7373, Val Acc: 0.5401
Epoch 9/100, Loss: 0.5537, Acc: 0.7175, Val Loss: 0.7223, Val Acc: 0.5360
Epoch 10/100, Loss: 0.5492, Acc: 0.7187, Val Loss: 0.7249, Val Acc: 0.5559
Epoch 11/100, Loss: 0.5490, Acc: 0.7152, Val Loss: 0.7635, Val Acc: 0.5217
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5430, Acc: 0.7235, Val Loss: 0.7442, Val Acc: 0.5426
Epoch 13/100, Loss: 0.5419, Acc: 0.7215, Val Loss: 0.7334, Val Acc: 0.5342
Epoch 14/100, Loss: 0.5423, Acc: 0.7232, Val Loss: 0.7415, Val Acc: 0.5456
Epoch 15/100, Loss: 0.5414, Acc: 0.7212, Val Loss: 0.7187, Val Acc: 0.5563
Epoch 16/100, Loss: 0.5417, Acc: 0.7215, Val Loss: 0.7303, Val Acc: 0.5364
Epoch 17/100, Loss: 0.5406, Acc: 0.7207, Val Loss: 0.7448, Val Acc: 0.5415
Epoch 18/100, Loss: 0.5443, Acc: 0.7206, Val Loss: 0.7507, Val Acc: 0.5441
Epoch 19/100, Loss: 0.5394, Acc: 0.7234, Val Loss: 0.7304, Val Acc: 0.5577
Epoch 20/100, Loss: 0.5392, Acc: 0.7252, Val Loss: 0.7495, Val Acc: 0.5346
Epoch 21/100, Loss: 0.5400, Acc: 0.7234, Val Loss: 0.7307, Val Acc: 0.5173
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5375, Acc: 0.7234, Val Loss: 0.7640, Val Acc: 0.5202
Epoch 23/100, Loss: 0.5364, Acc: 0.7257, Val Loss: 0.7453, Val Acc: 0.5305
Epoch 24/100, Loss: 0.5360, Acc: 0.7268, Val Loss: 0.7496, Val Acc: 0.5371
Epoch 25/100, Loss: 0.5350, Acc: 0.7264, Val Loss: 0.7408, Val Acc: 0.5309
Epoch 26/100, Loss: 0.5344, Acc: 0.7286, Val Loss: 0.7389, Val Acc: 0.5335
Epoch 27/100, Loss: 0.5350, Acc: 0.7272, Val Loss: 0.7522, Val Acc: 0.5382
Epoch 28/100, Loss: 0.5337, Acc: 0.7292, Val Loss: 0.7535, Val Acc: 0.5368
Epoch 29/100, Loss: 0.5367, Acc: 0.7232, Val Loss: 0.7255, Val Acc: 0.5463
Epoch 30/100, Loss: 0.5354, Acc: 0.7266, Val Loss: 0.7533, Val Acc: 0.5412
Epoch 31/100, Loss: 0.5348, Acc: 0.7264, Val Loss: 0.7612, Val Acc: 0.5312
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5335, Acc: 0.7296, Val Loss: 0.7571, Val Acc: 0.5353
Epoch 33/100, Loss: 0.5324, Acc: 0.7287, Val Loss: 0.7562, Val Acc: 0.5309
Epoch 34/100, Loss: 0.5326, Acc: 0.7297, Val Loss: 0.7492, Val Acc: 0.5368
Epoch 35/100, Loss: 0.5319, Acc: 0.7301, Val Loss: 0.7583, Val Acc: 0.5349
Epoch 36/100, Loss: 0.5323, Acc: 0.7296, Val Loss: 0.7445, Val Acc: 0.5342
Epoch 37/100, Loss: 0.5314, Acc: 0.7319, Val Loss: 0.7553, Val Acc: 0.5338
Epoch 38/100, Loss: 0.5313, Acc: 0.7317, Val Loss: 0.7543, Val Acc: 0.5346
Epoch 39/100, Loss: 0.5317, Acc: 0.7302, Val Loss: 0.7473, Val Acc: 0.5382
Epoch 40/100, Loss: 0.5320, Acc: 0.7316, Val Loss: 0.7470, Val Acc: 0.5423
Epoch 41/100, Loss: 0.5317, Acc: 0.7296, Val Loss: 0.7466, Val Acc: 0.5261
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5307, Acc: 0.7321, Val Loss: 0.7461, Val Acc: 0.5324
Epoch 43/100, Loss: 0.5303, Acc: 0.7291, Val Loss: 0.7480, Val Acc: 0.5283
Epoch 44/100, Loss: 0.5302, Acc: 0.7335, Val Loss: 0.7551, Val Acc: 0.5346
Epoch 45/100, Loss: 0.5304, Acc: 0.7316, Val Loss: 0.7517, Val Acc: 0.5331
Epoch 46/100, Loss: 0.5306, Acc: 0.7319, Val Loss: 0.7436, Val Acc: 0.5338
Epoch 47/100, Loss: 0.5304, Acc: 0.7309, Val Loss: 0.7502, Val Acc: 0.5346
Epoch 48/100, Loss: 0.5305, Acc: 0.7321, Val Loss: 0.7530, Val Acc: 0.5349
Epoch 49/100, Loss: 0.5302, Acc: 0.7342, Val Loss: 0.7532, Val Acc: 0.5335
Epoch 50/100, Loss: 0.5307, Acc: 0.7319, Val Loss: 0.7471, Val Acc: 0.5360
Epoch 51/100, Loss: 0.5298, Acc: 0.7337, Val Loss: 0.7505, Val Acc: 0.5349
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5299, Acc: 0.7323, Val Loss: 0.7493, Val Acc: 0.5349
Epoch 53/100, Loss: 0.5295, Acc: 0.7344, Val Loss: 0.7511, Val Acc: 0.5349
Epoch 54/100, Loss: 0.5295, Acc: 0.7332, Val Loss: 0.7464, Val Acc: 0.5346
Epoch 55/100, Loss: 0.5295, Acc: 0.7335, Val Loss: 0.7514, Val Acc: 0.5346
Epoch 56/100, Loss: 0.5295, Acc: 0.7313, Val Loss: 0.7462, Val Acc: 0.5342
Epoch 57/100, Loss: 0.5296, Acc: 0.7325, Val Loss: 0.7480, Val Acc: 0.5346
Epoch 58/100, Loss: 0.5296, Acc: 0.7327, Val Loss: 0.7500, Val Acc: 0.5353
Epoch 59/100, Loss: 0.5294, Acc: 0.7317, Val Loss: 0.7441, Val Acc: 0.5349
Epoch 60/100, Loss: 0.5292, Acc: 0.7343, Val Loss: 0.7525, Val Acc: 0.5349
Epoch 61/100, Loss: 0.5295, Acc: 0.7323, Val Loss: 0.7480, Val Acc: 0.5349
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5291, Acc: 0.7325, Val Loss: 0.7493, Val Acc: 0.5349
Epoch 63/100, Loss: 0.5291, Acc: 0.7323, Val Loss: 0.7503, Val Acc: 0.5338
Epoch 64/100, Loss: 0.5290, Acc: 0.7327, Val Loss: 0.7502, Val Acc: 0.5353
Epoch 65/100, Loss: 0.5290, Acc: 0.7329, Val Loss: 0.7496, Val Acc: 0.5353
Epoch 66/100, Loss: 0.5290, Acc: 0.7321, Val Loss: 0.7529, Val Acc: 0.5342
Epoch 67/100, Loss: 0.5289, Acc: 0.7330, Val Loss: 0.7512, Val Acc: 0.5353
Epoch 68/100, Loss: 0.5290, Acc: 0.7338, Val Loss: 0.7501, Val Acc: 0.5342
Epoch 69/100, Loss: 0.5290, Acc: 0.7329, Val Loss: 0.7508, Val Acc: 0.5346
Epoch 70/100, Loss: 0.5289, Acc: 0.7340, Val Loss: 0.7519, Val Acc: 0.5338
Epoch 71/100, Loss: 0.5289, Acc: 0.7323, Val Loss: 0.7518, Val Acc: 0.5357
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5288, Acc: 0.7338, Val Loss: 0.7508, Val Acc: 0.5342
Epoch 73/100, Loss: 0.5288, Acc: 0.7342, Val Loss: 0.7510, Val Acc: 0.5353
Epoch 74/100, Loss: 0.5288, Acc: 0.7332, Val Loss: 0.7524, Val Acc: 0.5353
Epoch 75/100, Loss: 0.5288, Acc: 0.7330, Val Loss: 0.7508, Val Acc: 0.5349
Epoch 76/100, Loss: 0.5287, Acc: 0.7324, Val Loss: 0.7520, Val Acc: 0.5342
Epoch 77/100, Loss: 0.5287, Acc: 0.7335, Val Loss: 0.7518, Val Acc: 0.5346
Epoch 78/100, Loss: 0.5288, Acc: 0.7341, Val Loss: 0.7518, Val Acc: 0.5349
Epoch 79/100, Loss: 0.5287, Acc: 0.7339, Val Loss: 0.7497, Val Acc: 0.5353
Epoch 80/100, Loss: 0.5287, Acc: 0.7332, Val Loss: 0.7502, Val Acc: 0.5346
Epoch 81/100, Loss: 0.5287, Acc: 0.7332, Val Loss: 0.7512, Val Acc: 0.5349
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5287, Acc: 0.7340, Val Loss: 0.7516, Val Acc: 0.5349
Epoch 83/100, Loss: 0.5287, Acc: 0.7326, Val Loss: 0.7514, Val Acc: 0.5342
Epoch 84/100, Loss: 0.5287, Acc: 0.7340, Val Loss: 0.7512, Val Acc: 0.5349
Epoch 85/100, Loss: 0.5287, Acc: 0.7327, Val Loss: 0.7512, Val Acc: 0.5349
Epoch 86/100, Loss: 0.5286, Acc: 0.7331, Val Loss: 0.7523, Val Acc: 0.5349
Epoch 87/100, Loss: 0.5287, Acc: 0.7338, Val Loss: 0.7516, Val Acc: 0.5349
Epoch 88/100, Loss: 0.5286, Acc: 0.7335, Val Loss: 0.7509, Val Acc: 0.5357
Epoch 89/100, Loss: 0.5287, Acc: 0.7328, Val Loss: 0.7507, Val Acc: 0.5342
Epoch 90/100, Loss: 0.5286, Acc: 0.7332, Val Loss: 0.7502, Val Acc: 0.5360
Epoch 91/100, Loss: 0.5286, Acc: 0.7339, Val Loss: 0.7505, Val Acc: 0.5342
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5287, Acc: 0.7331, Val Loss: 0.7508, Val Acc: 0.5346
Epoch 93/100, Loss: 0.5286, Acc: 0.7336, Val Loss: 0.7508, Val Acc: 0.5353
Epoch 94/100, Loss: 0.5286, Acc: 0.7339, Val Loss: 0.7514, Val Acc: 0.5346
Epoch 95/100, Loss: 0.5286, Acc: 0.7337, Val Loss: 0.7515, Val Acc: 0.5349
Epoch 96/100, Loss: 0.5286, Acc: 0.7335, Val Loss: 0.7517, Val Acc: 0.5349
Epoch 97/100, Loss: 0.5286, Acc: 0.7333, Val Loss: 0.7523, Val Acc: 0.5338
Epoch 98/100, Loss: 0.5286, Acc: 0.7344, Val Loss: 0.7517, Val Acc: 0.5346
Epoch 99/100, Loss: 0.5286, Acc: 0.7331, Val Loss: 0.7521, Val Acc: 0.5353
Epoch 100/100, Loss: 0.5286, Acc: 0.7340, Val Loss: 0.7523, Val Acc: 0.5353

##############################
Resultados para principal:  064  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1 
 {'training': [0.5285794599967845, 0.7340073529411765, 0.6862200117027502, 0.8623161764705882, 0.7642554578038449], 'validate': [0.7522558708523595, 0.5352941176470588, 0.5215633423180593, 0.8536764705882353, 0.6475181260457334], 'test': [0.8075944935833966, 0.37, 0.40806988352745427, 0.5770588235294117, 0.4780701754385965]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  060  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  060  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  060  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6547, Acc: 0.6345, Val Loss: 0.8187, Val Acc: 0.2930
Mejor modelo guardado con Val Loss: 0.8187
Epoch 2/100, Loss: 0.6171, Acc: 0.6744, Val Loss: 0.9246, Val Acc: 0.2434
Epoch 3/100, Loss: 0.6007, Acc: 0.6850, Val Loss: 0.9580, Val Acc: 0.2239
Epoch 4/100, Loss: 0.5955, Acc: 0.6858, Val Loss: 0.8786, Val Acc: 0.2772
Epoch 5/100, Loss: 0.5995, Acc: 0.6814, Val Loss: 0.9414, Val Acc: 0.2581
Epoch 6/100, Loss: 0.5923, Acc: 0.6864, Val Loss: 1.0837, Val Acc: 0.2496
Epoch 7/100, Loss: 0.5896, Acc: 0.6842, Val Loss: 1.0320, Val Acc: 0.2353
Epoch 8/100, Loss: 0.5875, Acc: 0.6880, Val Loss: 0.9325, Val Acc: 0.3107
Epoch 9/100, Loss: 0.5917, Acc: 0.6861, Val Loss: 0.9339, Val Acc: 0.2945
Epoch 10/100, Loss: 0.5931, Acc: 0.6868, Val Loss: 1.0448, Val Acc: 0.2629
Epoch 11/100, Loss: 0.5853, Acc: 0.6890, Val Loss: 1.0613, Val Acc: 0.2463
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5848, Acc: 0.6907, Val Loss: 1.0264, Val Acc: 0.2485
Epoch 13/100, Loss: 0.5807, Acc: 0.6906, Val Loss: 1.0255, Val Acc: 0.2522
Epoch 14/100, Loss: 0.5797, Acc: 0.6942, Val Loss: 1.0838, Val Acc: 0.2467
Epoch 15/100, Loss: 0.5799, Acc: 0.6972, Val Loss: 1.1013, Val Acc: 0.2680
Epoch 16/100, Loss: 0.5784, Acc: 0.6948, Val Loss: 1.0468, Val Acc: 0.2691
Epoch 17/100, Loss: 0.5755, Acc: 0.6985, Val Loss: 1.1173, Val Acc: 0.2320
Epoch 18/100, Loss: 0.5783, Acc: 0.6929, Val Loss: 1.1220, Val Acc: 0.2529
Epoch 19/100, Loss: 0.5801, Acc: 0.6969, Val Loss: 0.9818, Val Acc: 0.2732
Epoch 20/100, Loss: 0.5781, Acc: 0.6938, Val Loss: 1.0529, Val Acc: 0.2864
Epoch 21/100, Loss: 0.5793, Acc: 0.6915, Val Loss: 1.0662, Val Acc: 0.2695
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5760, Acc: 0.6964, Val Loss: 1.1124, Val Acc: 0.2761
Epoch 23/100, Loss: 0.5740, Acc: 0.6985, Val Loss: 1.0093, Val Acc: 0.2592
Epoch 24/100, Loss: 0.5744, Acc: 0.6947, Val Loss: 1.0592, Val Acc: 0.2397
Epoch 25/100, Loss: 0.5746, Acc: 0.6999, Val Loss: 1.0499, Val Acc: 0.2518
Epoch 26/100, Loss: 0.5736, Acc: 0.6957, Val Loss: 1.0551, Val Acc: 0.2787
Epoch 27/100, Loss: 0.5739, Acc: 0.6944, Val Loss: 1.0549, Val Acc: 0.2680
Epoch 28/100, Loss: 0.5726, Acc: 0.6976, Val Loss: 1.0832, Val Acc: 0.2493
Epoch 29/100, Loss: 0.5740, Acc: 0.6927, Val Loss: 1.1000, Val Acc: 0.2728
Epoch 30/100, Loss: 0.5741, Acc: 0.6979, Val Loss: 1.0680, Val Acc: 0.2551
Epoch 31/100, Loss: 0.5743, Acc: 0.6945, Val Loss: 1.0790, Val Acc: 0.2599
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5725, Acc: 0.6991, Val Loss: 1.0700, Val Acc: 0.2529
Epoch 33/100, Loss: 0.5726, Acc: 0.6977, Val Loss: 1.0910, Val Acc: 0.2474
Epoch 34/100, Loss: 0.5725, Acc: 0.6966, Val Loss: 1.0285, Val Acc: 0.2842
Epoch 35/100, Loss: 0.5717, Acc: 0.7022, Val Loss: 1.0754, Val Acc: 0.2548
Epoch 36/100, Loss: 0.5715, Acc: 0.6999, Val Loss: 1.0558, Val Acc: 0.2658
Epoch 37/100, Loss: 0.5721, Acc: 0.6957, Val Loss: 1.0709, Val Acc: 0.2537
Epoch 38/100, Loss: 0.5711, Acc: 0.6978, Val Loss: 1.0673, Val Acc: 0.2721
Epoch 39/100, Loss: 0.5702, Acc: 0.6992, Val Loss: 1.0634, Val Acc: 0.2603
Epoch 40/100, Loss: 0.5707, Acc: 0.6969, Val Loss: 1.0608, Val Acc: 0.2570
Epoch 41/100, Loss: 0.5707, Acc: 0.6984, Val Loss: 1.0696, Val Acc: 0.2489
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5694, Acc: 0.7004, Val Loss: 1.0707, Val Acc: 0.2599
Epoch 43/100, Loss: 0.5690, Acc: 0.6976, Val Loss: 1.0617, Val Acc: 0.2596
Epoch 44/100, Loss: 0.5692, Acc: 0.6996, Val Loss: 1.0631, Val Acc: 0.2585
Epoch 45/100, Loss: 0.5692, Acc: 0.6991, Val Loss: 1.0512, Val Acc: 0.2632
Epoch 46/100, Loss: 0.5692, Acc: 0.6996, Val Loss: 1.0641, Val Acc: 0.2533
Epoch 47/100, Loss: 0.5688, Acc: 0.7002, Val Loss: 1.0642, Val Acc: 0.2596
Epoch 48/100, Loss: 0.5691, Acc: 0.6976, Val Loss: 1.0832, Val Acc: 0.2577
Epoch 49/100, Loss: 0.5688, Acc: 0.7010, Val Loss: 1.0692, Val Acc: 0.2673
Epoch 50/100, Loss: 0.5689, Acc: 0.6983, Val Loss: 1.0844, Val Acc: 0.2599
Epoch 51/100, Loss: 0.5689, Acc: 0.6967, Val Loss: 1.0425, Val Acc: 0.2592
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5686, Acc: 0.6977, Val Loss: 1.0687, Val Acc: 0.2629
Epoch 53/100, Loss: 0.5682, Acc: 0.6978, Val Loss: 1.0709, Val Acc: 0.2607
Epoch 54/100, Loss: 0.5684, Acc: 0.6974, Val Loss: 1.0732, Val Acc: 0.2625
Epoch 55/100, Loss: 0.5683, Acc: 0.6964, Val Loss: 1.0673, Val Acc: 0.2618
Epoch 56/100, Loss: 0.5682, Acc: 0.6984, Val Loss: 1.0804, Val Acc: 0.2596
Epoch 57/100, Loss: 0.5682, Acc: 0.6983, Val Loss: 1.0637, Val Acc: 0.2614
Epoch 58/100, Loss: 0.5680, Acc: 0.6985, Val Loss: 1.0685, Val Acc: 0.2621
Epoch 59/100, Loss: 0.5682, Acc: 0.6995, Val Loss: 1.0641, Val Acc: 0.2625
Epoch 60/100, Loss: 0.5681, Acc: 0.6994, Val Loss: 1.0707, Val Acc: 0.2566
Epoch 61/100, Loss: 0.5681, Acc: 0.6983, Val Loss: 1.0590, Val Acc: 0.2640
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5679, Acc: 0.6977, Val Loss: 1.0653, Val Acc: 0.2636
Epoch 63/100, Loss: 0.5678, Acc: 0.6981, Val Loss: 1.0727, Val Acc: 0.2618
Epoch 64/100, Loss: 0.5677, Acc: 0.6988, Val Loss: 1.0674, Val Acc: 0.2610
Epoch 65/100, Loss: 0.5677, Acc: 0.6971, Val Loss: 1.0719, Val Acc: 0.2599
Epoch 66/100, Loss: 0.5676, Acc: 0.6972, Val Loss: 1.0676, Val Acc: 0.2640
Epoch 67/100, Loss: 0.5676, Acc: 0.6977, Val Loss: 1.0708, Val Acc: 0.2629
Epoch 68/100, Loss: 0.5676, Acc: 0.6983, Val Loss: 1.0727, Val Acc: 0.2621
Epoch 69/100, Loss: 0.5676, Acc: 0.6978, Val Loss: 1.0746, Val Acc: 0.2621
Epoch 70/100, Loss: 0.5676, Acc: 0.6983, Val Loss: 1.0714, Val Acc: 0.2592
Epoch 71/100, Loss: 0.5675, Acc: 0.6978, Val Loss: 1.0715, Val Acc: 0.2599
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5674, Acc: 0.6979, Val Loss: 1.0698, Val Acc: 0.2632
Epoch 73/100, Loss: 0.5674, Acc: 0.6976, Val Loss: 1.0687, Val Acc: 0.2618
Epoch 74/100, Loss: 0.5674, Acc: 0.6975, Val Loss: 1.0689, Val Acc: 0.2618
Epoch 75/100, Loss: 0.5674, Acc: 0.6977, Val Loss: 1.0686, Val Acc: 0.2610
Epoch 76/100, Loss: 0.5674, Acc: 0.6970, Val Loss: 1.0702, Val Acc: 0.2621
Epoch 77/100, Loss: 0.5674, Acc: 0.6981, Val Loss: 1.0694, Val Acc: 0.2629
Epoch 78/100, Loss: 0.5674, Acc: 0.6982, Val Loss: 1.0697, Val Acc: 0.2636
Epoch 79/100, Loss: 0.5674, Acc: 0.6987, Val Loss: 1.0699, Val Acc: 0.2629
Epoch 80/100, Loss: 0.5673, Acc: 0.6983, Val Loss: 1.0689, Val Acc: 0.2625
Epoch 81/100, Loss: 0.5673, Acc: 0.6980, Val Loss: 1.0703, Val Acc: 0.2632
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5673, Acc: 0.6982, Val Loss: 1.0693, Val Acc: 0.2636
Epoch 83/100, Loss: 0.5674, Acc: 0.6980, Val Loss: 1.0716, Val Acc: 0.2614
Epoch 84/100, Loss: 0.5673, Acc: 0.6977, Val Loss: 1.0707, Val Acc: 0.2629
Epoch 85/100, Loss: 0.5674, Acc: 0.6980, Val Loss: 1.0701, Val Acc: 0.2621
Epoch 86/100, Loss: 0.5673, Acc: 0.6975, Val Loss: 1.0706, Val Acc: 0.2636
Epoch 87/100, Loss: 0.5673, Acc: 0.6981, Val Loss: 1.0705, Val Acc: 0.2625
Epoch 88/100, Loss: 0.5673, Acc: 0.6979, Val Loss: 1.0704, Val Acc: 0.2621
Epoch 89/100, Loss: 0.5673, Acc: 0.6982, Val Loss: 1.0712, Val Acc: 0.2625
Epoch 90/100, Loss: 0.5673, Acc: 0.6978, Val Loss: 1.0682, Val Acc: 0.2636
Epoch 91/100, Loss: 0.5672, Acc: 0.6980, Val Loss: 1.0719, Val Acc: 0.2618
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5672, Acc: 0.6978, Val Loss: 1.0697, Val Acc: 0.2651
Epoch 93/100, Loss: 0.5672, Acc: 0.6983, Val Loss: 1.0719, Val Acc: 0.2640
Epoch 94/100, Loss: 0.5672, Acc: 0.6984, Val Loss: 1.0719, Val Acc: 0.2629
Epoch 95/100, Loss: 0.5672, Acc: 0.6981, Val Loss: 1.0701, Val Acc: 0.2640
Epoch 96/100, Loss: 0.5671, Acc: 0.6990, Val Loss: 1.0725, Val Acc: 0.2607
Epoch 97/100, Loss: 0.5672, Acc: 0.6983, Val Loss: 1.0698, Val Acc: 0.2647
Epoch 98/100, Loss: 0.5671, Acc: 0.6981, Val Loss: 1.0726, Val Acc: 0.2632
Epoch 99/100, Loss: 0.5672, Acc: 0.6985, Val Loss: 1.0683, Val Acc: 0.2625
Epoch 100/100, Loss: 0.5672, Acc: 0.6984, Val Loss: 1.0693, Val Acc: 0.2640

##############################
Resultados para principal:  060  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1 
 {'training': [0.5671535302610958, 0.6984375, 0.7469686570578815, 0.6001838235294118, 0.6655794516359189], 'validate': [1.0692541668581408, 0.2639705882352941, 0.1907514450867052, 0.14558823529411766, 0.1651376146788991], 'test': [0.7840908953437099, 0.3764705882352941, 0.35517241379310344, 0.3029411764705882, 0.326984126984127]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  028  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  028  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  028  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5492, Acc: 0.8298, Val Loss: 0.5215, Val Acc: 0.7893
Mejor modelo guardado con Val Loss: 0.5215
Epoch 2/100, Loss: 0.4036, Acc: 0.8525, Val Loss: 0.4936, Val Acc: 0.7886
Mejor modelo guardado con Val Loss: 0.4936
Epoch 3/100, Loss: 0.3612, Acc: 0.8601, Val Loss: 0.4894, Val Acc: 0.7798
Mejor modelo guardado con Val Loss: 0.4894
Epoch 4/100, Loss: 0.3500, Acc: 0.8582, Val Loss: 0.4835, Val Acc: 0.7919
Mejor modelo guardado con Val Loss: 0.4835
Epoch 5/100, Loss: 0.3434, Acc: 0.8594, Val Loss: 0.5463, Val Acc: 0.7176
Epoch 6/100, Loss: 0.3384, Acc: 0.8569, Val Loss: 0.4787, Val Acc: 0.8051
Mejor modelo guardado con Val Loss: 0.4787
Epoch 7/100, Loss: 0.3331, Acc: 0.8589, Val Loss: 0.5017, Val Acc: 0.7904
Epoch 8/100, Loss: 0.3317, Acc: 0.8594, Val Loss: 0.5619, Val Acc: 0.7408
Epoch 9/100, Loss: 0.3370, Acc: 0.8553, Val Loss: 0.4943, Val Acc: 0.7798
Epoch 10/100, Loss: 0.3314, Acc: 0.8597, Val Loss: 0.4902, Val Acc: 0.7926
Epoch 11/100, Loss: 0.3326, Acc: 0.8577, Val Loss: 0.4774, Val Acc: 0.8037
Mejor modelo guardado con Val Loss: 0.4774
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3272, Acc: 0.8599, Val Loss: 0.5051, Val Acc: 0.7860
Epoch 13/100, Loss: 0.3246, Acc: 0.8622, Val Loss: 0.4900, Val Acc: 0.7934
Epoch 14/100, Loss: 0.3231, Acc: 0.8613, Val Loss: 0.4952, Val Acc: 0.7904
Epoch 15/100, Loss: 0.3281, Acc: 0.8577, Val Loss: 0.4685, Val Acc: 0.8037
Mejor modelo guardado con Val Loss: 0.4685
Epoch 16/100, Loss: 0.3260, Acc: 0.8604, Val Loss: 0.4880, Val Acc: 0.8004
Epoch 17/100, Loss: 0.3244, Acc: 0.8617, Val Loss: 0.5086, Val Acc: 0.7783
Epoch 18/100, Loss: 0.3277, Acc: 0.8601, Val Loss: 0.4882, Val Acc: 0.8040
Epoch 19/100, Loss: 0.3260, Acc: 0.8587, Val Loss: 0.4984, Val Acc: 0.7996
Epoch 20/100, Loss: 0.3232, Acc: 0.8637, Val Loss: 0.5070, Val Acc: 0.7919
Epoch 21/100, Loss: 0.3218, Acc: 0.8645, Val Loss: 0.4778, Val Acc: 0.7952
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3218, Acc: 0.8606, Val Loss: 0.5142, Val Acc: 0.7838
Epoch 23/100, Loss: 0.3204, Acc: 0.8617, Val Loss: 0.5257, Val Acc: 0.7838
Epoch 24/100, Loss: 0.3195, Acc: 0.8652, Val Loss: 0.5236, Val Acc: 0.7824
Epoch 25/100, Loss: 0.3193, Acc: 0.8621, Val Loss: 0.4848, Val Acc: 0.8051
Epoch 26/100, Loss: 0.3188, Acc: 0.8646, Val Loss: 0.4948, Val Acc: 0.8077
Epoch 27/100, Loss: 0.3211, Acc: 0.8647, Val Loss: 0.5135, Val Acc: 0.8011
Epoch 28/100, Loss: 0.3200, Acc: 0.8639, Val Loss: 0.5142, Val Acc: 0.7868
Epoch 29/100, Loss: 0.3217, Acc: 0.8619, Val Loss: 0.5058, Val Acc: 0.7982
Epoch 30/100, Loss: 0.3204, Acc: 0.8631, Val Loss: 0.5104, Val Acc: 0.7864
Epoch 31/100, Loss: 0.3187, Acc: 0.8646, Val Loss: 0.5175, Val Acc: 0.7838
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3163, Acc: 0.8653, Val Loss: 0.5177, Val Acc: 0.7886
Epoch 33/100, Loss: 0.3166, Acc: 0.8655, Val Loss: 0.5114, Val Acc: 0.7890
Epoch 34/100, Loss: 0.3158, Acc: 0.8664, Val Loss: 0.5028, Val Acc: 0.8015
Epoch 35/100, Loss: 0.3160, Acc: 0.8662, Val Loss: 0.5163, Val Acc: 0.7835
Epoch 36/100, Loss: 0.3160, Acc: 0.8664, Val Loss: 0.5083, Val Acc: 0.7912
Epoch 37/100, Loss: 0.3160, Acc: 0.8649, Val Loss: 0.5110, Val Acc: 0.7912
Epoch 38/100, Loss: 0.3165, Acc: 0.8647, Val Loss: 0.5190, Val Acc: 0.7846
Epoch 39/100, Loss: 0.3154, Acc: 0.8649, Val Loss: 0.5098, Val Acc: 0.7904
Epoch 40/100, Loss: 0.3170, Acc: 0.8655, Val Loss: 0.5104, Val Acc: 0.7930
Epoch 41/100, Loss: 0.3168, Acc: 0.8633, Val Loss: 0.4965, Val Acc: 0.7974
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3150, Acc: 0.8653, Val Loss: 0.5096, Val Acc: 0.7949
Epoch 43/100, Loss: 0.3147, Acc: 0.8653, Val Loss: 0.5051, Val Acc: 0.7974
Epoch 44/100, Loss: 0.3147, Acc: 0.8661, Val Loss: 0.5012, Val Acc: 0.7971
Epoch 45/100, Loss: 0.3145, Acc: 0.8653, Val Loss: 0.5032, Val Acc: 0.8044
Epoch 46/100, Loss: 0.3144, Acc: 0.8649, Val Loss: 0.5105, Val Acc: 0.7978
Epoch 47/100, Loss: 0.3145, Acc: 0.8665, Val Loss: 0.5122, Val Acc: 0.7963
Epoch 48/100, Loss: 0.3148, Acc: 0.8664, Val Loss: 0.5012, Val Acc: 0.8007
Epoch 49/100, Loss: 0.3143, Acc: 0.8650, Val Loss: 0.5103, Val Acc: 0.7971
Epoch 50/100, Loss: 0.3144, Acc: 0.8661, Val Loss: 0.5146, Val Acc: 0.7949
Epoch 51/100, Loss: 0.3148, Acc: 0.8645, Val Loss: 0.5083, Val Acc: 0.7963
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3138, Acc: 0.8654, Val Loss: 0.5096, Val Acc: 0.7960
Epoch 53/100, Loss: 0.3135, Acc: 0.8659, Val Loss: 0.5052, Val Acc: 0.7993
Epoch 54/100, Loss: 0.3133, Acc: 0.8659, Val Loss: 0.5065, Val Acc: 0.8004
Epoch 55/100, Loss: 0.3134, Acc: 0.8660, Val Loss: 0.5057, Val Acc: 0.7989
Epoch 56/100, Loss: 0.3136, Acc: 0.8650, Val Loss: 0.5079, Val Acc: 0.7967
Epoch 57/100, Loss: 0.3134, Acc: 0.8661, Val Loss: 0.5020, Val Acc: 0.8011
Epoch 58/100, Loss: 0.3133, Acc: 0.8667, Val Loss: 0.5082, Val Acc: 0.7985
Epoch 59/100, Loss: 0.3132, Acc: 0.8654, Val Loss: 0.5084, Val Acc: 0.7989
Epoch 60/100, Loss: 0.3131, Acc: 0.8666, Val Loss: 0.5083, Val Acc: 0.7974
Epoch 61/100, Loss: 0.3133, Acc: 0.8666, Val Loss: 0.5078, Val Acc: 0.7989
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3129, Acc: 0.8663, Val Loss: 0.5080, Val Acc: 0.7982
Epoch 63/100, Loss: 0.3128, Acc: 0.8667, Val Loss: 0.5058, Val Acc: 0.7996
Epoch 64/100, Loss: 0.3128, Acc: 0.8663, Val Loss: 0.5075, Val Acc: 0.7985
Epoch 65/100, Loss: 0.3128, Acc: 0.8653, Val Loss: 0.5066, Val Acc: 0.8000
Epoch 66/100, Loss: 0.3128, Acc: 0.8657, Val Loss: 0.5076, Val Acc: 0.7978
Epoch 67/100, Loss: 0.3128, Acc: 0.8666, Val Loss: 0.5062, Val Acc: 0.8007
Epoch 68/100, Loss: 0.3128, Acc: 0.8662, Val Loss: 0.5055, Val Acc: 0.8004
Epoch 69/100, Loss: 0.3128, Acc: 0.8657, Val Loss: 0.5058, Val Acc: 0.7996
Epoch 70/100, Loss: 0.3129, Acc: 0.8668, Val Loss: 0.5066, Val Acc: 0.8004
Epoch 71/100, Loss: 0.3128, Acc: 0.8668, Val Loss: 0.5085, Val Acc: 0.7989
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3127, Acc: 0.8658, Val Loss: 0.5081, Val Acc: 0.7978
Epoch 73/100, Loss: 0.3126, Acc: 0.8662, Val Loss: 0.5065, Val Acc: 0.7996
Epoch 74/100, Loss: 0.3125, Acc: 0.8662, Val Loss: 0.5077, Val Acc: 0.7974
Epoch 75/100, Loss: 0.3125, Acc: 0.8663, Val Loss: 0.5071, Val Acc: 0.7978
Epoch 76/100, Loss: 0.3126, Acc: 0.8659, Val Loss: 0.5077, Val Acc: 0.7985
Epoch 77/100, Loss: 0.3125, Acc: 0.8665, Val Loss: 0.5068, Val Acc: 0.8000
Epoch 78/100, Loss: 0.3125, Acc: 0.8661, Val Loss: 0.5071, Val Acc: 0.8000
Epoch 79/100, Loss: 0.3125, Acc: 0.8665, Val Loss: 0.5073, Val Acc: 0.7993
Epoch 80/100, Loss: 0.3126, Acc: 0.8660, Val Loss: 0.5080, Val Acc: 0.7985
Epoch 81/100, Loss: 0.3125, Acc: 0.8663, Val Loss: 0.5070, Val Acc: 0.7996
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3125, Acc: 0.8664, Val Loss: 0.5082, Val Acc: 0.7978
Epoch 83/100, Loss: 0.3124, Acc: 0.8658, Val Loss: 0.5078, Val Acc: 0.7985
Epoch 84/100, Loss: 0.3125, Acc: 0.8663, Val Loss: 0.5079, Val Acc: 0.7982
Epoch 85/100, Loss: 0.3124, Acc: 0.8665, Val Loss: 0.5072, Val Acc: 0.7985
Epoch 86/100, Loss: 0.3124, Acc: 0.8670, Val Loss: 0.5085, Val Acc: 0.7978
Epoch 87/100, Loss: 0.3125, Acc: 0.8662, Val Loss: 0.5077, Val Acc: 0.7974
Epoch 88/100, Loss: 0.3124, Acc: 0.8661, Val Loss: 0.5055, Val Acc: 0.8007
Epoch 89/100, Loss: 0.3124, Acc: 0.8661, Val Loss: 0.5074, Val Acc: 0.7978
Epoch 90/100, Loss: 0.3123, Acc: 0.8660, Val Loss: 0.5086, Val Acc: 0.7978
Epoch 91/100, Loss: 0.3124, Acc: 0.8672, Val Loss: 0.5085, Val Acc: 0.7982
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3124, Acc: 0.8662, Val Loss: 0.5079, Val Acc: 0.7982
Epoch 93/100, Loss: 0.3123, Acc: 0.8667, Val Loss: 0.5078, Val Acc: 0.7985
Epoch 94/100, Loss: 0.3124, Acc: 0.8661, Val Loss: 0.5075, Val Acc: 0.7985
Epoch 95/100, Loss: 0.3123, Acc: 0.8669, Val Loss: 0.5084, Val Acc: 0.7985
Epoch 96/100, Loss: 0.3123, Acc: 0.8665, Val Loss: 0.5073, Val Acc: 0.7985
Epoch 97/100, Loss: 0.3124, Acc: 0.8671, Val Loss: 0.5077, Val Acc: 0.7978
Epoch 98/100, Loss: 0.3123, Acc: 0.8664, Val Loss: 0.5078, Val Acc: 0.7982
Epoch 99/100, Loss: 0.3123, Acc: 0.8665, Val Loss: 0.5074, Val Acc: 0.7993
Epoch 100/100, Loss: 0.3123, Acc: 0.8665, Val Loss: 0.5087, Val Acc: 0.7985

##############################
Resultados para principal:  028  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1 
 {'training': [0.31231615008676755, 0.8664522058823529, 0.8805115480053445, 0.8479779411764706, 0.8639385710272497], 'validate': [0.5086882856436247, 0.7985294117647059, 0.8237639553429027, 0.7595588235294117, 0.7903596021423106], 'test': [0.7350447876723828, 0.6232352941176471, 0.9686800894854586, 0.25470588235294117, 0.4033535165346996]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  033  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  033  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  033  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6928, Acc: 0.5140, Val Loss: 0.6923, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6923
Epoch 2/100, Loss: 0.6932, Acc: 0.5034, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 3/100, Loss: 0.6935, Acc: 0.4984, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 4/100, Loss: 0.6933, Acc: 0.5006, Val Loss: 0.6935, Val Acc: 0.5000
Epoch 5/100, Loss: 0.6934, Acc: 0.4877, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 6/100, Loss: 0.6932, Acc: 0.5070, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6935, Acc: 0.4933, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 8/100, Loss: 0.6935, Acc: 0.4967, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6934, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 10/100, Loss: 0.6935, Acc: 0.5006, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 11/100, Loss: 0.6935, Acc: 0.4949, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6932, Acc: 0.4991, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6933, Acc: 0.4980, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6933, Acc: 0.4967, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6934, Acc: 0.4982, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 16/100, Loss: 0.6933, Acc: 0.4890, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6932, Acc: 0.5004, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 18/100, Loss: 0.6933, Acc: 0.5022, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 19/100, Loss: 0.6934, Acc: 0.4908, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 20/100, Loss: 0.6933, Acc: 0.4978, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 21/100, Loss: 0.6931, Acc: 0.5078, Val Loss: 0.6939, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6930, Acc: 0.5019, Val Loss: 0.6934, Val Acc: 0.4915
Epoch 23/100, Loss: 0.6925, Acc: 0.5104, Val Loss: 0.6928, Val Acc: 0.5029
Epoch 24/100, Loss: 0.6923, Acc: 0.5119, Val Loss: 0.6925, Val Acc: 0.5221
Epoch 25/100, Loss: 0.6921, Acc: 0.5164, Val Loss: 0.6921, Val Acc: 0.5250
Mejor modelo guardado con Val Loss: 0.6921
Epoch 26/100, Loss: 0.6921, Acc: 0.5117, Val Loss: 0.6919, Val Acc: 0.5305
Mejor modelo guardado con Val Loss: 0.6919
Epoch 27/100, Loss: 0.6918, Acc: 0.5130, Val Loss: 0.6913, Val Acc: 0.5364
Mejor modelo guardado con Val Loss: 0.6913
Epoch 28/100, Loss: 0.6915, Acc: 0.5141, Val Loss: 0.6906, Val Acc: 0.5368
Mejor modelo guardado con Val Loss: 0.6906
Epoch 29/100, Loss: 0.6913, Acc: 0.5216, Val Loss: 0.6903, Val Acc: 0.5437
Mejor modelo guardado con Val Loss: 0.6903
Epoch 30/100, Loss: 0.6912, Acc: 0.5212, Val Loss: 0.6901, Val Acc: 0.5426
Mejor modelo guardado con Val Loss: 0.6901
Epoch 31/100, Loss: 0.6910, Acc: 0.5244, Val Loss: 0.6900, Val Acc: 0.5456
Mejor modelo guardado con Val Loss: 0.6900
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6906, Acc: 0.5243, Val Loss: 0.6896, Val Acc: 0.5482
Mejor modelo guardado con Val Loss: 0.6896
Epoch 33/100, Loss: 0.6903, Acc: 0.5266, Val Loss: 0.6893, Val Acc: 0.5529
Mejor modelo guardado con Val Loss: 0.6893
Epoch 34/100, Loss: 0.6904, Acc: 0.5277, Val Loss: 0.6890, Val Acc: 0.5518
Mejor modelo guardado con Val Loss: 0.6890
Epoch 35/100, Loss: 0.6902, Acc: 0.5270, Val Loss: 0.6887, Val Acc: 0.5548
Mejor modelo guardado con Val Loss: 0.6887
Epoch 36/100, Loss: 0.6900, Acc: 0.5296, Val Loss: 0.6883, Val Acc: 0.5570
Mejor modelo guardado con Val Loss: 0.6883
Epoch 37/100, Loss: 0.6902, Acc: 0.5240, Val Loss: 0.6892, Val Acc: 0.5467
Epoch 38/100, Loss: 0.6899, Acc: 0.5324, Val Loss: 0.6883, Val Acc: 0.5574
Epoch 39/100, Loss: 0.6899, Acc: 0.5291, Val Loss: 0.6884, Val Acc: 0.5548
Epoch 40/100, Loss: 0.6897, Acc: 0.5300, Val Loss: 0.6886, Val Acc: 0.5504
Epoch 41/100, Loss: 0.6896, Acc: 0.5319, Val Loss: 0.6875, Val Acc: 0.5618
Mejor modelo guardado con Val Loss: 0.6875
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6894, Acc: 0.5341, Val Loss: 0.6881, Val Acc: 0.5559
Epoch 43/100, Loss: 0.6893, Acc: 0.5340, Val Loss: 0.6874, Val Acc: 0.5647
Mejor modelo guardado con Val Loss: 0.6874
Epoch 44/100, Loss: 0.6893, Acc: 0.5330, Val Loss: 0.6871, Val Acc: 0.5625
Mejor modelo guardado con Val Loss: 0.6871
Epoch 45/100, Loss: 0.6892, Acc: 0.5335, Val Loss: 0.6871, Val Acc: 0.5647
Epoch 46/100, Loss: 0.6891, Acc: 0.5343, Val Loss: 0.6867, Val Acc: 0.5496
Mejor modelo guardado con Val Loss: 0.6867
Epoch 47/100, Loss: 0.6892, Acc: 0.5294, Val Loss: 0.6870, Val Acc: 0.5669
Epoch 48/100, Loss: 0.6891, Acc: 0.5336, Val Loss: 0.6873, Val Acc: 0.5618
Epoch 49/100, Loss: 0.6889, Acc: 0.5347, Val Loss: 0.6874, Val Acc: 0.5599
Epoch 50/100, Loss: 0.6889, Acc: 0.5321, Val Loss: 0.6870, Val Acc: 0.5629
Epoch 51/100, Loss: 0.6889, Acc: 0.5353, Val Loss: 0.6864, Val Acc: 0.5643
Mejor modelo guardado con Val Loss: 0.6864
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6888, Acc: 0.5335, Val Loss: 0.6869, Val Acc: 0.5632
Epoch 53/100, Loss: 0.6888, Acc: 0.5372, Val Loss: 0.6865, Val Acc: 0.5665
Epoch 54/100, Loss: 0.6888, Acc: 0.5351, Val Loss: 0.6865, Val Acc: 0.5665
Epoch 55/100, Loss: 0.6887, Acc: 0.5365, Val Loss: 0.6862, Val Acc: 0.5651
Mejor modelo guardado con Val Loss: 0.6862
Epoch 56/100, Loss: 0.6887, Acc: 0.5352, Val Loss: 0.6871, Val Acc: 0.5599
Epoch 57/100, Loss: 0.6887, Acc: 0.5346, Val Loss: 0.6865, Val Acc: 0.5640
Epoch 58/100, Loss: 0.6886, Acc: 0.5364, Val Loss: 0.6862, Val Acc: 0.5684
Epoch 59/100, Loss: 0.6885, Acc: 0.5345, Val Loss: 0.6894, Val Acc: 0.5132
Epoch 60/100, Loss: 0.6882, Acc: 0.5411, Val Loss: 0.6901, Val Acc: 0.5074
Epoch 61/100, Loss: 0.6880, Acc: 0.5408, Val Loss: 0.6910, Val Acc: 0.4893
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6878, Acc: 0.5332, Val Loss: 0.6919, Val Acc: 0.4636
Epoch 63/100, Loss: 0.6878, Acc: 0.5349, Val Loss: 0.6918, Val Acc: 0.4629
Epoch 64/100, Loss: 0.6877, Acc: 0.5331, Val Loss: 0.6923, Val Acc: 0.4529
Epoch 65/100, Loss: 0.6877, Acc: 0.5343, Val Loss: 0.6922, Val Acc: 0.4493
Epoch 66/100, Loss: 0.6876, Acc: 0.5354, Val Loss: 0.6922, Val Acc: 0.4485
Epoch 67/100, Loss: 0.6876, Acc: 0.5338, Val Loss: 0.6921, Val Acc: 0.4437
Epoch 68/100, Loss: 0.6875, Acc: 0.5361, Val Loss: 0.6920, Val Acc: 0.4441
Epoch 69/100, Loss: 0.6875, Acc: 0.5369, Val Loss: 0.6918, Val Acc: 0.4423
Epoch 70/100, Loss: 0.6874, Acc: 0.5345, Val Loss: 0.6916, Val Acc: 0.4437
Epoch 71/100, Loss: 0.6873, Acc: 0.5345, Val Loss: 0.6916, Val Acc: 0.4401
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6873, Acc: 0.5350, Val Loss: 0.6915, Val Acc: 0.4408
Epoch 73/100, Loss: 0.6873, Acc: 0.5345, Val Loss: 0.6914, Val Acc: 0.4434
Epoch 74/100, Loss: 0.6872, Acc: 0.5358, Val Loss: 0.6915, Val Acc: 0.4441
Epoch 75/100, Loss: 0.6872, Acc: 0.5362, Val Loss: 0.6916, Val Acc: 0.4419
Epoch 76/100, Loss: 0.6872, Acc: 0.5319, Val Loss: 0.6916, Val Acc: 0.4397
Epoch 77/100, Loss: 0.6871, Acc: 0.5325, Val Loss: 0.6913, Val Acc: 0.4478
Epoch 78/100, Loss: 0.6871, Acc: 0.5301, Val Loss: 0.6914, Val Acc: 0.4467
Epoch 79/100, Loss: 0.6871, Acc: 0.5290, Val Loss: 0.6913, Val Acc: 0.4507
Epoch 80/100, Loss: 0.6870, Acc: 0.5293, Val Loss: 0.6913, Val Acc: 0.4662
Epoch 81/100, Loss: 0.6870, Acc: 0.5264, Val Loss: 0.6912, Val Acc: 0.4761
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6870, Acc: 0.5246, Val Loss: 0.6912, Val Acc: 0.4967
Epoch 83/100, Loss: 0.6870, Acc: 0.5299, Val Loss: 0.6913, Val Acc: 0.5026
Epoch 84/100, Loss: 0.6869, Acc: 0.5284, Val Loss: 0.6910, Val Acc: 0.5110
Epoch 85/100, Loss: 0.6864, Acc: 0.5287, Val Loss: 0.6901, Val Acc: 0.5228
Epoch 86/100, Loss: 0.6863, Acc: 0.5306, Val Loss: 0.6902, Val Acc: 0.5254
Epoch 87/100, Loss: 0.6863, Acc: 0.5315, Val Loss: 0.6900, Val Acc: 0.5290
Epoch 88/100, Loss: 0.6863, Acc: 0.5346, Val Loss: 0.6898, Val Acc: 0.5301
Epoch 89/100, Loss: 0.6863, Acc: 0.5324, Val Loss: 0.6900, Val Acc: 0.5287
Epoch 90/100, Loss: 0.6862, Acc: 0.5331, Val Loss: 0.6903, Val Acc: 0.5360
Epoch 91/100, Loss: 0.6862, Acc: 0.5347, Val Loss: 0.6900, Val Acc: 0.5364
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6862, Acc: 0.5340, Val Loss: 0.6901, Val Acc: 0.5368
Epoch 93/100, Loss: 0.6862, Acc: 0.5359, Val Loss: 0.6903, Val Acc: 0.5401
Epoch 94/100, Loss: 0.6862, Acc: 0.5365, Val Loss: 0.6900, Val Acc: 0.5368
Epoch 95/100, Loss: 0.6861, Acc: 0.5339, Val Loss: 0.6904, Val Acc: 0.5401
Epoch 96/100, Loss: 0.6861, Acc: 0.5343, Val Loss: 0.6899, Val Acc: 0.5386
Epoch 97/100, Loss: 0.6861, Acc: 0.5360, Val Loss: 0.6898, Val Acc: 0.5375
Epoch 98/100, Loss: 0.6860, Acc: 0.5354, Val Loss: 0.6900, Val Acc: 0.5342
Epoch 99/100, Loss: 0.6860, Acc: 0.5353, Val Loss: 0.6902, Val Acc: 0.5324
Epoch 100/100, Loss: 0.6859, Acc: 0.5354, Val Loss: 0.6915, Val Acc: 0.4978

##############################
Resultados para principal:  033  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1 
 {'training': [0.6859400577404919, 0.5353860294117647, 0.5512104283054003, 0.38088235294117645, 0.4504837482335036], 'validate': [0.6914648247319598, 0.49779411764705883, 0.4974704890387858, 0.4338235294117647, 0.4634721131186174], 'test': [0.6806480465111909, 0.6144117647058823, 0.7222857142857143, 0.37176470588235294, 0.49087378640776697]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  026  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  026  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  026  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6641, Acc: 0.6225, Val Loss: 0.6495, Val Acc: 0.6467
Mejor modelo guardado con Val Loss: 0.6495
Epoch 2/100, Loss: 0.6423, Acc: 0.6389, Val Loss: 0.6764, Val Acc: 0.5934
Epoch 3/100, Loss: 0.6287, Acc: 0.6467, Val Loss: 0.6598, Val Acc: 0.5614
Epoch 4/100, Loss: 0.6117, Acc: 0.6619, Val Loss: 0.6799, Val Acc: 0.4982
Epoch 5/100, Loss: 0.6130, Acc: 0.6727, Val Loss: 0.6609, Val Acc: 0.5665
Epoch 6/100, Loss: 0.6044, Acc: 0.6754, Val Loss: 0.6672, Val Acc: 0.5290
Epoch 7/100, Loss: 0.6033, Acc: 0.6786, Val Loss: 0.6833, Val Acc: 0.5202
Epoch 8/100, Loss: 0.5963, Acc: 0.6830, Val Loss: 0.7007, Val Acc: 0.4820
Epoch 9/100, Loss: 0.5862, Acc: 0.6915, Val Loss: 0.6652, Val Acc: 0.5971
Epoch 10/100, Loss: 0.5831, Acc: 0.6912, Val Loss: 0.6776, Val Acc: 0.5283
Epoch 11/100, Loss: 0.5801, Acc: 0.6935, Val Loss: 0.7084, Val Acc: 0.4658
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5751, Acc: 0.6979, Val Loss: 0.7521, Val Acc: 0.4239
Epoch 13/100, Loss: 0.5715, Acc: 0.6989, Val Loss: 0.6806, Val Acc: 0.5147
Epoch 14/100, Loss: 0.5739, Acc: 0.6978, Val Loss: 0.6290, Val Acc: 0.6074
Mejor modelo guardado con Val Loss: 0.6290
Epoch 15/100, Loss: 0.5707, Acc: 0.6975, Val Loss: 0.7258, Val Acc: 0.4721
Epoch 16/100, Loss: 0.5679, Acc: 0.7028, Val Loss: 0.7394, Val Acc: 0.4548
Epoch 17/100, Loss: 0.5691, Acc: 0.7025, Val Loss: 0.7529, Val Acc: 0.4294
Epoch 18/100, Loss: 0.5677, Acc: 0.7050, Val Loss: 0.7083, Val Acc: 0.4886
Epoch 19/100, Loss: 0.5658, Acc: 0.7046, Val Loss: 0.7468, Val Acc: 0.4607
Epoch 20/100, Loss: 0.5644, Acc: 0.7027, Val Loss: 0.7246, Val Acc: 0.4949
Epoch 21/100, Loss: 0.5620, Acc: 0.7055, Val Loss: 0.7382, Val Acc: 0.4507
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5614, Acc: 0.7054, Val Loss: 0.7667, Val Acc: 0.4386
Epoch 23/100, Loss: 0.5594, Acc: 0.7101, Val Loss: 0.7697, Val Acc: 0.4301
Epoch 24/100, Loss: 0.5586, Acc: 0.7082, Val Loss: 0.7392, Val Acc: 0.4581
Epoch 25/100, Loss: 0.5596, Acc: 0.7066, Val Loss: 0.7600, Val Acc: 0.4665
Epoch 26/100, Loss: 0.5577, Acc: 0.7071, Val Loss: 0.7576, Val Acc: 0.4662
Epoch 27/100, Loss: 0.5570, Acc: 0.7082, Val Loss: 0.7764, Val Acc: 0.4390
Epoch 28/100, Loss: 0.5598, Acc: 0.7087, Val Loss: 0.7447, Val Acc: 0.4938
Epoch 29/100, Loss: 0.5559, Acc: 0.7104, Val Loss: 0.7577, Val Acc: 0.4599
Epoch 30/100, Loss: 0.5562, Acc: 0.7070, Val Loss: 0.7703, Val Acc: 0.4746
Epoch 31/100, Loss: 0.5569, Acc: 0.7078, Val Loss: 0.7668, Val Acc: 0.4588
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5534, Acc: 0.7125, Val Loss: 0.7548, Val Acc: 0.4783
Epoch 33/100, Loss: 0.5540, Acc: 0.7098, Val Loss: 0.7595, Val Acc: 0.4761
Epoch 34/100, Loss: 0.5538, Acc: 0.7108, Val Loss: 0.7613, Val Acc: 0.4669
Epoch 35/100, Loss: 0.5532, Acc: 0.7107, Val Loss: 0.7845, Val Acc: 0.4283
Epoch 36/100, Loss: 0.5538, Acc: 0.7115, Val Loss: 0.7763, Val Acc: 0.4585
Epoch 37/100, Loss: 0.5529, Acc: 0.7119, Val Loss: 0.7833, Val Acc: 0.4533
Epoch 38/100, Loss: 0.5529, Acc: 0.7121, Val Loss: 0.7736, Val Acc: 0.4562
Epoch 39/100, Loss: 0.5531, Acc: 0.7097, Val Loss: 0.7587, Val Acc: 0.4761
Epoch 40/100, Loss: 0.5533, Acc: 0.7108, Val Loss: 0.7975, Val Acc: 0.4489
Epoch 41/100, Loss: 0.5521, Acc: 0.7134, Val Loss: 0.7793, Val Acc: 0.4596
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5517, Acc: 0.7108, Val Loss: 0.7777, Val Acc: 0.4658
Epoch 43/100, Loss: 0.5517, Acc: 0.7123, Val Loss: 0.7724, Val Acc: 0.4684
Epoch 44/100, Loss: 0.5514, Acc: 0.7134, Val Loss: 0.7844, Val Acc: 0.4529
Epoch 45/100, Loss: 0.5517, Acc: 0.7108, Val Loss: 0.7837, Val Acc: 0.4555
Epoch 46/100, Loss: 0.5512, Acc: 0.7123, Val Loss: 0.7888, Val Acc: 0.4515
Epoch 47/100, Loss: 0.5517, Acc: 0.7122, Val Loss: 0.7800, Val Acc: 0.4636
Epoch 48/100, Loss: 0.5515, Acc: 0.7113, Val Loss: 0.7827, Val Acc: 0.4636
Epoch 49/100, Loss: 0.5512, Acc: 0.7124, Val Loss: 0.7724, Val Acc: 0.4699
Epoch 50/100, Loss: 0.5513, Acc: 0.7098, Val Loss: 0.7903, Val Acc: 0.4489
Epoch 51/100, Loss: 0.5512, Acc: 0.7120, Val Loss: 0.7875, Val Acc: 0.4467
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5508, Acc: 0.7122, Val Loss: 0.7818, Val Acc: 0.4596
Epoch 53/100, Loss: 0.5505, Acc: 0.7119, Val Loss: 0.7751, Val Acc: 0.4695
Epoch 54/100, Loss: 0.5507, Acc: 0.7100, Val Loss: 0.7811, Val Acc: 0.4651
Epoch 55/100, Loss: 0.5505, Acc: 0.7122, Val Loss: 0.7818, Val Acc: 0.4621
Epoch 56/100, Loss: 0.5504, Acc: 0.7117, Val Loss: 0.7790, Val Acc: 0.4662
Epoch 57/100, Loss: 0.5503, Acc: 0.7125, Val Loss: 0.7903, Val Acc: 0.4574
Epoch 58/100, Loss: 0.5505, Acc: 0.7112, Val Loss: 0.7832, Val Acc: 0.4632
Epoch 59/100, Loss: 0.5502, Acc: 0.7133, Val Loss: 0.7868, Val Acc: 0.4618
Epoch 60/100, Loss: 0.5504, Acc: 0.7129, Val Loss: 0.7753, Val Acc: 0.4721
Epoch 61/100, Loss: 0.5502, Acc: 0.7139, Val Loss: 0.7854, Val Acc: 0.4640
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5499, Acc: 0.7129, Val Loss: 0.7860, Val Acc: 0.4632
Epoch 63/100, Loss: 0.5500, Acc: 0.7131, Val Loss: 0.7851, Val Acc: 0.4632
Epoch 64/100, Loss: 0.5498, Acc: 0.7139, Val Loss: 0.7838, Val Acc: 0.4625
Epoch 65/100, Loss: 0.5500, Acc: 0.7120, Val Loss: 0.7847, Val Acc: 0.4621
Epoch 66/100, Loss: 0.5498, Acc: 0.7127, Val Loss: 0.7849, Val Acc: 0.4621
Epoch 67/100, Loss: 0.5499, Acc: 0.7132, Val Loss: 0.7835, Val Acc: 0.4640
Epoch 68/100, Loss: 0.5498, Acc: 0.7134, Val Loss: 0.7846, Val Acc: 0.4640
Epoch 69/100, Loss: 0.5499, Acc: 0.7115, Val Loss: 0.7815, Val Acc: 0.4662
Epoch 70/100, Loss: 0.5499, Acc: 0.7134, Val Loss: 0.7858, Val Acc: 0.4632
Epoch 71/100, Loss: 0.5498, Acc: 0.7119, Val Loss: 0.7855, Val Acc: 0.4610
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5496, Acc: 0.7122, Val Loss: 0.7857, Val Acc: 0.4629
Epoch 73/100, Loss: 0.5494, Acc: 0.7129, Val Loss: 0.7865, Val Acc: 0.4654
Epoch 74/100, Loss: 0.5491, Acc: 0.7133, Val Loss: 0.7919, Val Acc: 0.4610
Epoch 75/100, Loss: 0.5489, Acc: 0.7131, Val Loss: 0.7924, Val Acc: 0.4647
Epoch 76/100, Loss: 0.5488, Acc: 0.7132, Val Loss: 0.7913, Val Acc: 0.4640
Epoch 77/100, Loss: 0.5488, Acc: 0.7136, Val Loss: 0.7926, Val Acc: 0.4643
Epoch 78/100, Loss: 0.5488, Acc: 0.7120, Val Loss: 0.7933, Val Acc: 0.4651
Epoch 79/100, Loss: 0.5487, Acc: 0.7128, Val Loss: 0.7933, Val Acc: 0.4632
Epoch 80/100, Loss: 0.5487, Acc: 0.7122, Val Loss: 0.7933, Val Acc: 0.4651
Epoch 81/100, Loss: 0.5487, Acc: 0.7130, Val Loss: 0.7933, Val Acc: 0.4676
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5487, Acc: 0.7120, Val Loss: 0.7975, Val Acc: 0.4614
Epoch 83/100, Loss: 0.5486, Acc: 0.7131, Val Loss: 0.7945, Val Acc: 0.4643
Epoch 84/100, Loss: 0.5486, Acc: 0.7126, Val Loss: 0.7962, Val Acc: 0.4618
Epoch 85/100, Loss: 0.5486, Acc: 0.7127, Val Loss: 0.7969, Val Acc: 0.4618
Epoch 86/100, Loss: 0.5485, Acc: 0.7129, Val Loss: 0.7989, Val Acc: 0.4614
Epoch 87/100, Loss: 0.5481, Acc: 0.7131, Val Loss: 0.8010, Val Acc: 0.4629
Epoch 88/100, Loss: 0.5479, Acc: 0.7127, Val Loss: 0.8039, Val Acc: 0.4614
Epoch 89/100, Loss: 0.5479, Acc: 0.7134, Val Loss: 0.8031, Val Acc: 0.4607
Epoch 90/100, Loss: 0.5479, Acc: 0.7133, Val Loss: 0.8015, Val Acc: 0.4614
Epoch 91/100, Loss: 0.5479, Acc: 0.7145, Val Loss: 0.8034, Val Acc: 0.4603
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5478, Acc: 0.7131, Val Loss: 0.8033, Val Acc: 0.4614
Epoch 93/100, Loss: 0.5478, Acc: 0.7141, Val Loss: 0.8075, Val Acc: 0.4566
Epoch 94/100, Loss: 0.5478, Acc: 0.7122, Val Loss: 0.8042, Val Acc: 0.4596
Epoch 95/100, Loss: 0.5478, Acc: 0.7124, Val Loss: 0.8004, Val Acc: 0.4618
Epoch 96/100, Loss: 0.5478, Acc: 0.7135, Val Loss: 0.8036, Val Acc: 0.4588
Epoch 97/100, Loss: 0.5477, Acc: 0.7148, Val Loss: 0.8057, Val Acc: 0.4592
Epoch 98/100, Loss: 0.5476, Acc: 0.7131, Val Loss: 0.8049, Val Acc: 0.4599
Epoch 99/100, Loss: 0.5477, Acc: 0.7125, Val Loss: 0.8026, Val Acc: 0.4614
Epoch 100/100, Loss: 0.5477, Acc: 0.7152, Val Loss: 0.8039, Val Acc: 0.4610

##############################
Resultados para principal:  026  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1 
 {'training': [0.5476726274279987, 0.7151654411764706, 0.6737420216713671, 0.834375, 0.7455038186745504], 'validate': [0.8038735375847927, 0.4610294117647059, 0.4657622739018088, 0.5301470588235294, 0.4958734525447043], 'test': [0.7284350025433081, 0.5491176470588235, 0.5363834422657952, 0.7241176470588235, 0.616270337922403]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  110  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  110  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  110  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6069, Acc: 0.7009, Val Loss: 0.5725, Val Acc: 0.7537
Mejor modelo guardado con Val Loss: 0.5725
Epoch 2/100, Loss: 0.5653, Acc: 0.7107, Val Loss: 0.5755, Val Acc: 0.7018
Epoch 3/100, Loss: 0.5422, Acc: 0.7209, Val Loss: 0.5615, Val Acc: 0.6952
Mejor modelo guardado con Val Loss: 0.5615
Epoch 4/100, Loss: 0.5305, Acc: 0.7291, Val Loss: 0.5580, Val Acc: 0.7096
Mejor modelo guardado con Val Loss: 0.5580
Epoch 5/100, Loss: 0.5223, Acc: 0.7381, Val Loss: 0.6064, Val Acc: 0.5757
Epoch 6/100, Loss: 0.5176, Acc: 0.7397, Val Loss: 0.5864, Val Acc: 0.6651
Epoch 7/100, Loss: 0.5160, Acc: 0.7400, Val Loss: 0.5870, Val Acc: 0.6603
Epoch 8/100, Loss: 0.5142, Acc: 0.7444, Val Loss: 0.5956, Val Acc: 0.6279
Epoch 9/100, Loss: 0.5155, Acc: 0.7378, Val Loss: 0.5330, Val Acc: 0.7654
Mejor modelo guardado con Val Loss: 0.5330
Epoch 10/100, Loss: 0.5178, Acc: 0.7430, Val Loss: 0.5798, Val Acc: 0.6728
Epoch 11/100, Loss: 0.5194, Acc: 0.7335, Val Loss: 0.5549, Val Acc: 0.7018
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5073, Acc: 0.7488, Val Loss: 0.5504, Val Acc: 0.7169
Epoch 13/100, Loss: 0.5049, Acc: 0.7469, Val Loss: 0.5586, Val Acc: 0.6912
Epoch 14/100, Loss: 0.5036, Acc: 0.7494, Val Loss: 0.5688, Val Acc: 0.6952
Epoch 15/100, Loss: 0.5001, Acc: 0.7532, Val Loss: 0.5674, Val Acc: 0.7051
Epoch 16/100, Loss: 0.4986, Acc: 0.7583, Val Loss: 0.5578, Val Acc: 0.6956
Epoch 17/100, Loss: 0.4978, Acc: 0.7553, Val Loss: 0.5580, Val Acc: 0.7143
Epoch 18/100, Loss: 0.4982, Acc: 0.7543, Val Loss: 0.5344, Val Acc: 0.7305
Epoch 19/100, Loss: 0.4964, Acc: 0.7546, Val Loss: 0.5658, Val Acc: 0.7029
Epoch 20/100, Loss: 0.4950, Acc: 0.7586, Val Loss: 0.5820, Val Acc: 0.6772
Epoch 21/100, Loss: 0.5020, Acc: 0.7524, Val Loss: 0.5826, Val Acc: 0.6706
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4977, Acc: 0.7567, Val Loss: 0.5644, Val Acc: 0.7007
Epoch 23/100, Loss: 0.4928, Acc: 0.7575, Val Loss: 0.5618, Val Acc: 0.7000
Epoch 24/100, Loss: 0.4921, Acc: 0.7619, Val Loss: 0.5743, Val Acc: 0.7081
Epoch 25/100, Loss: 0.4913, Acc: 0.7595, Val Loss: 0.5450, Val Acc: 0.7272
Epoch 26/100, Loss: 0.4913, Acc: 0.7589, Val Loss: 0.5794, Val Acc: 0.6941
Epoch 27/100, Loss: 0.4917, Acc: 0.7595, Val Loss: 0.5516, Val Acc: 0.7121
Epoch 28/100, Loss: 0.4894, Acc: 0.7583, Val Loss: 0.5578, Val Acc: 0.6934
Epoch 29/100, Loss: 0.4899, Acc: 0.7604, Val Loss: 0.5608, Val Acc: 0.7129
Epoch 30/100, Loss: 0.4885, Acc: 0.7587, Val Loss: 0.5326, Val Acc: 0.7419
Mejor modelo guardado con Val Loss: 0.5326
Epoch 31/100, Loss: 0.4897, Acc: 0.7597, Val Loss: 0.5692, Val Acc: 0.7110
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4873, Acc: 0.7616, Val Loss: 0.5624, Val Acc: 0.7129
Epoch 33/100, Loss: 0.4860, Acc: 0.7612, Val Loss: 0.5511, Val Acc: 0.7092
Epoch 34/100, Loss: 0.4855, Acc: 0.7626, Val Loss: 0.5471, Val Acc: 0.7154
Epoch 35/100, Loss: 0.4858, Acc: 0.7620, Val Loss: 0.5505, Val Acc: 0.7118
Epoch 36/100, Loss: 0.4850, Acc: 0.7617, Val Loss: 0.5562, Val Acc: 0.7040
Epoch 37/100, Loss: 0.4843, Acc: 0.7638, Val Loss: 0.5745, Val Acc: 0.6849
Epoch 38/100, Loss: 0.4849, Acc: 0.7607, Val Loss: 0.5485, Val Acc: 0.7088
Epoch 39/100, Loss: 0.4845, Acc: 0.7622, Val Loss: 0.5542, Val Acc: 0.7048
Epoch 40/100, Loss: 0.4846, Acc: 0.7626, Val Loss: 0.5389, Val Acc: 0.7188
Epoch 41/100, Loss: 0.4844, Acc: 0.7609, Val Loss: 0.5370, Val Acc: 0.7294
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4831, Acc: 0.7640, Val Loss: 0.5589, Val Acc: 0.7099
Epoch 43/100, Loss: 0.4828, Acc: 0.7627, Val Loss: 0.5363, Val Acc: 0.7279
Epoch 44/100, Loss: 0.4827, Acc: 0.7599, Val Loss: 0.5616, Val Acc: 0.6982
Epoch 45/100, Loss: 0.4822, Acc: 0.7636, Val Loss: 0.5366, Val Acc: 0.7239
Epoch 46/100, Loss: 0.4823, Acc: 0.7630, Val Loss: 0.5524, Val Acc: 0.7132
Epoch 47/100, Loss: 0.4822, Acc: 0.7646, Val Loss: 0.5596, Val Acc: 0.7048
Epoch 48/100, Loss: 0.4817, Acc: 0.7646, Val Loss: 0.5395, Val Acc: 0.7257
Epoch 49/100, Loss: 0.4820, Acc: 0.7628, Val Loss: 0.5446, Val Acc: 0.7121
Epoch 50/100, Loss: 0.4819, Acc: 0.7611, Val Loss: 0.5519, Val Acc: 0.7051
Epoch 51/100, Loss: 0.4822, Acc: 0.7648, Val Loss: 0.5431, Val Acc: 0.7158
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4810, Acc: 0.7642, Val Loss: 0.5455, Val Acc: 0.7099
Epoch 53/100, Loss: 0.4811, Acc: 0.7640, Val Loss: 0.5476, Val Acc: 0.7132
Epoch 54/100, Loss: 0.4808, Acc: 0.7641, Val Loss: 0.5469, Val Acc: 0.7081
Epoch 55/100, Loss: 0.4809, Acc: 0.7649, Val Loss: 0.5458, Val Acc: 0.7140
Epoch 56/100, Loss: 0.4807, Acc: 0.7628, Val Loss: 0.5495, Val Acc: 0.7107
Epoch 57/100, Loss: 0.4801, Acc: 0.7641, Val Loss: 0.5438, Val Acc: 0.7180
Epoch 58/100, Loss: 0.4803, Acc: 0.7642, Val Loss: 0.5499, Val Acc: 0.7099
Epoch 59/100, Loss: 0.4798, Acc: 0.7652, Val Loss: 0.5434, Val Acc: 0.7154
Epoch 60/100, Loss: 0.4799, Acc: 0.7644, Val Loss: 0.5444, Val Acc: 0.7151
Epoch 61/100, Loss: 0.4801, Acc: 0.7632, Val Loss: 0.5446, Val Acc: 0.7151
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4795, Acc: 0.7646, Val Loss: 0.5460, Val Acc: 0.7140
Epoch 63/100, Loss: 0.4795, Acc: 0.7642, Val Loss: 0.5465, Val Acc: 0.7140
Epoch 64/100, Loss: 0.4794, Acc: 0.7648, Val Loss: 0.5472, Val Acc: 0.7143
Epoch 65/100, Loss: 0.4794, Acc: 0.7648, Val Loss: 0.5473, Val Acc: 0.7129
Epoch 66/100, Loss: 0.4794, Acc: 0.7646, Val Loss: 0.5481, Val Acc: 0.7121
Epoch 67/100, Loss: 0.4794, Acc: 0.7643, Val Loss: 0.5471, Val Acc: 0.7129
Epoch 68/100, Loss: 0.4793, Acc: 0.7652, Val Loss: 0.5461, Val Acc: 0.7136
Epoch 69/100, Loss: 0.4793, Acc: 0.7650, Val Loss: 0.5446, Val Acc: 0.7140
Epoch 70/100, Loss: 0.4793, Acc: 0.7637, Val Loss: 0.5467, Val Acc: 0.7125
Epoch 71/100, Loss: 0.4792, Acc: 0.7658, Val Loss: 0.5435, Val Acc: 0.7154
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4791, Acc: 0.7654, Val Loss: 0.5456, Val Acc: 0.7140
Epoch 73/100, Loss: 0.4790, Acc: 0.7652, Val Loss: 0.5458, Val Acc: 0.7132
Epoch 74/100, Loss: 0.4791, Acc: 0.7646, Val Loss: 0.5455, Val Acc: 0.7147
Epoch 75/100, Loss: 0.4790, Acc: 0.7659, Val Loss: 0.5436, Val Acc: 0.7147
Epoch 76/100, Loss: 0.4790, Acc: 0.7649, Val Loss: 0.5450, Val Acc: 0.7140
Epoch 77/100, Loss: 0.4789, Acc: 0.7664, Val Loss: 0.5440, Val Acc: 0.7151
Epoch 78/100, Loss: 0.4790, Acc: 0.7647, Val Loss: 0.5442, Val Acc: 0.7147
Epoch 79/100, Loss: 0.4790, Acc: 0.7653, Val Loss: 0.5442, Val Acc: 0.7154
Epoch 80/100, Loss: 0.4789, Acc: 0.7658, Val Loss: 0.5449, Val Acc: 0.7140
Epoch 81/100, Loss: 0.4789, Acc: 0.7661, Val Loss: 0.5446, Val Acc: 0.7154
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4789, Acc: 0.7649, Val Loss: 0.5459, Val Acc: 0.7129
Epoch 83/100, Loss: 0.4788, Acc: 0.7650, Val Loss: 0.5460, Val Acc: 0.7136
Epoch 84/100, Loss: 0.4789, Acc: 0.7649, Val Loss: 0.5446, Val Acc: 0.7143
Epoch 85/100, Loss: 0.4789, Acc: 0.7653, Val Loss: 0.5445, Val Acc: 0.7151
Epoch 86/100, Loss: 0.4788, Acc: 0.7649, Val Loss: 0.5467, Val Acc: 0.7147
Epoch 87/100, Loss: 0.4788, Acc: 0.7645, Val Loss: 0.5456, Val Acc: 0.7140
Epoch 88/100, Loss: 0.4788, Acc: 0.7651, Val Loss: 0.5449, Val Acc: 0.7140
Epoch 89/100, Loss: 0.4788, Acc: 0.7653, Val Loss: 0.5446, Val Acc: 0.7136
Epoch 90/100, Loss: 0.4787, Acc: 0.7647, Val Loss: 0.5466, Val Acc: 0.7136
Epoch 91/100, Loss: 0.4786, Acc: 0.7653, Val Loss: 0.5473, Val Acc: 0.7136
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4784, Acc: 0.7656, Val Loss: 0.5447, Val Acc: 0.7162
Epoch 93/100, Loss: 0.4784, Acc: 0.7652, Val Loss: 0.5468, Val Acc: 0.7136
Epoch 94/100, Loss: 0.4783, Acc: 0.7655, Val Loss: 0.5463, Val Acc: 0.7132
Epoch 95/100, Loss: 0.4784, Acc: 0.7648, Val Loss: 0.5458, Val Acc: 0.7151
Epoch 96/100, Loss: 0.4783, Acc: 0.7659, Val Loss: 0.5459, Val Acc: 0.7147
Epoch 97/100, Loss: 0.4783, Acc: 0.7653, Val Loss: 0.5466, Val Acc: 0.7162
Epoch 98/100, Loss: 0.4782, Acc: 0.7648, Val Loss: 0.5467, Val Acc: 0.7154
Epoch 99/100, Loss: 0.4783, Acc: 0.7640, Val Loss: 0.5473, Val Acc: 0.7154
Epoch 100/100, Loss: 0.4781, Acc: 0.7653, Val Loss: 0.5481, Val Acc: 0.7136

##############################
Resultados para principal:  110  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  1 
 {'training': [0.4781492429621079, 0.7653492647058824, 0.7368334700574242, 0.8255514705882353, 0.7786736020806242], 'validate': [0.5480665045595446, 0.7136029411764706, 0.7289204097714737, 0.6801470588235294, 0.7036896158235071], 'test': [0.572244664033254, 0.7041176470588235, 0.6788659793814433, 0.7747058823529411, 0.7236263736263736]}

##############################
Resultados para window:  1 
 {'064:060:028:033:026:110': {'training': [0.5285794599967845, 0.7340073529411765, 0.6862200117027502, 0.8623161764705882, 0.7642554578038449], 'validate': [0.7522558708523595, 0.5352941176470588, 0.5215633423180593, 0.8536764705882353, 0.6475181260457334], 'test': [0.8075944935833966, 0.37, 0.40806988352745427, 0.5770588235294117, 0.4780701754385965]}, '060:064:028:033:026:110': {'training': [0.5671535302610958, 0.6984375, 0.7469686570578815, 0.6001838235294118, 0.6655794516359189], 'validate': [1.0692541668581408, 0.2639705882352941, 0.1907514450867052, 0.14558823529411766, 0.1651376146788991], 'test': [0.7840908953437099, 0.3764705882352941, 0.35517241379310344, 0.3029411764705882, 0.326984126984127]}, '028:064:060:033:026:110': {'training': [0.31231615008676755, 0.8664522058823529, 0.8805115480053445, 0.8479779411764706, 0.8639385710272497], 'validate': [0.5086882856436247, 0.7985294117647059, 0.8237639553429027, 0.7595588235294117, 0.7903596021423106], 'test': [0.7350447876723828, 0.6232352941176471, 0.9686800894854586, 0.25470588235294117, 0.4033535165346996]}, '033:064:060:028:026:110': {'training': [0.6859400577404919, 0.5353860294117647, 0.5512104283054003, 0.38088235294117645, 0.4504837482335036], 'validate': [0.6914648247319598, 0.49779411764705883, 0.4974704890387858, 0.4338235294117647, 0.4634721131186174], 'test': [0.6806480465111909, 0.6144117647058823, 0.7222857142857143, 0.37176470588235294, 0.49087378640776697]}, '026:064:060:028:033:110': {'training': [0.5476726274279987, 0.7151654411764706, 0.6737420216713671, 0.834375, 0.7455038186745504], 'validate': [0.8038735375847927, 0.4610294117647059, 0.4657622739018088, 0.5301470588235294, 0.4958734525447043], 'test': [0.7284350025433081, 0.5491176470588235, 0.5363834422657952, 0.7241176470588235, 0.616270337922403]}, '110:064:060:028:033:026': {'training': [0.4781492429621079, 0.7653492647058824, 0.7368334700574242, 0.8255514705882353, 0.7786736020806242], 'validate': [0.5480665045595446, 0.7136029411764706, 0.7289204097714737, 0.6801470588235294, 0.7036896158235071], 'test': [0.572244664033254, 0.7041176470588235, 0.6788659793814433, 0.7747058823529411, 0.7236263736263736]}}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  104  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  104  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  104  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6922, Acc: 0.5172, Val Loss: 0.6919, Val Acc: 0.6217
Mejor modelo guardado con Val Loss: 0.6919
Epoch 2/100, Loss: 0.6934, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.5029
Epoch 3/100, Loss: 0.6929, Acc: 0.5150, Val Loss: 0.6855, Val Acc: 0.6974
Mejor modelo guardado con Val Loss: 0.6855
Epoch 4/100, Loss: 0.6931, Acc: 0.5028, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 5/100, Loss: 0.6934, Acc: 0.4989, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 6/100, Loss: 0.6934, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.5007
Epoch 7/100, Loss: 0.6932, Acc: 0.5040, Val Loss: 0.6938, Val Acc: 0.5000
Epoch 8/100, Loss: 0.6934, Acc: 0.4976, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6932, Acc: 0.5024, Val Loss: 0.6932, Val Acc: 0.5011
Epoch 10/100, Loss: 0.6933, Acc: 0.4999, Val Loss: 0.6828, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6828
Epoch 11/100, Loss: 0.6931, Acc: 0.5031, Val Loss: 0.6937, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.5004, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6933, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6933, Acc: 0.4964, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6933, Acc: 0.4967, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 16/100, Loss: 0.6937, Acc: 0.4965, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6933, Acc: 0.4943, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 18/100, Loss: 0.6933, Acc: 0.4934, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 19/100, Loss: 0.6932, Acc: 0.4950, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 20/100, Loss: 0.6933, Acc: 0.4949, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 21/100, Loss: 0.6933, Acc: 0.4988, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 23/100, Loss: 0.6932, Acc: 0.5028, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 24/100, Loss: 0.6933, Acc: 0.4930, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 25/100, Loss: 0.6932, Acc: 0.4918, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 26/100, Loss: 0.6932, Acc: 0.4989, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 27/100, Loss: 0.6933, Acc: 0.4898, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 28/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 29/100, Loss: 0.6932, Acc: 0.4976, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 30/100, Loss: 0.6932, Acc: 0.4991, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 31/100, Loss: 0.6932, Acc: 0.4996, Val Loss: 0.6931, Val Acc: 0.4996
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4993, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 33/100, Loss: 0.6932, Acc: 0.4930, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 34/100, Loss: 0.6932, Acc: 0.4961, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 35/100, Loss: 0.6930, Acc: 0.5047, Val Loss: 0.6925, Val Acc: 0.5382
Epoch 36/100, Loss: 0.6929, Acc: 0.5108, Val Loss: 0.6922, Val Acc: 0.5581
Epoch 37/100, Loss: 0.6927, Acc: 0.5217, Val Loss: 0.6924, Val Acc: 0.5261
Epoch 38/100, Loss: 0.6925, Acc: 0.5245, Val Loss: 0.6914, Val Acc: 0.5757
Epoch 39/100, Loss: 0.6924, Acc: 0.5236, Val Loss: 0.6920, Val Acc: 0.5331
Epoch 40/100, Loss: 0.6924, Acc: 0.5271, Val Loss: 0.6907, Val Acc: 0.5794
Epoch 41/100, Loss: 0.6921, Acc: 0.5313, Val Loss: 0.6903, Val Acc: 0.5868
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6920, Acc: 0.5307, Val Loss: 0.6902, Val Acc: 0.5831
Epoch 43/100, Loss: 0.6920, Acc: 0.5336, Val Loss: 0.6902, Val Acc: 0.5717
Epoch 44/100, Loss: 0.6919, Acc: 0.5390, Val Loss: 0.6905, Val Acc: 0.5680
Epoch 45/100, Loss: 0.6918, Acc: 0.5365, Val Loss: 0.6896, Val Acc: 0.5967
Epoch 46/100, Loss: 0.6918, Acc: 0.5320, Val Loss: 0.6899, Val Acc: 0.5754
Epoch 47/100, Loss: 0.6918, Acc: 0.5378, Val Loss: 0.6895, Val Acc: 0.5820
Epoch 48/100, Loss: 0.6916, Acc: 0.5371, Val Loss: 0.6894, Val Acc: 0.5960
Epoch 49/100, Loss: 0.6915, Acc: 0.5380, Val Loss: 0.6895, Val Acc: 0.5904
Epoch 50/100, Loss: 0.6914, Acc: 0.5380, Val Loss: 0.6893, Val Acc: 0.5779
Epoch 51/100, Loss: 0.6914, Acc: 0.5395, Val Loss: 0.6894, Val Acc: 0.5860
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6913, Acc: 0.5348, Val Loss: 0.6891, Val Acc: 0.5801
Epoch 53/100, Loss: 0.6912, Acc: 0.5388, Val Loss: 0.6889, Val Acc: 0.5915
Epoch 54/100, Loss: 0.6912, Acc: 0.5393, Val Loss: 0.6888, Val Acc: 0.5912
Epoch 55/100, Loss: 0.6912, Acc: 0.5375, Val Loss: 0.6887, Val Acc: 0.5934
Epoch 56/100, Loss: 0.6911, Acc: 0.5402, Val Loss: 0.6887, Val Acc: 0.5849
Epoch 57/100, Loss: 0.6911, Acc: 0.5442, Val Loss: 0.6883, Val Acc: 0.5974
Epoch 58/100, Loss: 0.6910, Acc: 0.5407, Val Loss: 0.6882, Val Acc: 0.5989
Epoch 59/100, Loss: 0.6910, Acc: 0.5404, Val Loss: 0.6882, Val Acc: 0.5967
Epoch 60/100, Loss: 0.6910, Acc: 0.5405, Val Loss: 0.6881, Val Acc: 0.5971
Epoch 61/100, Loss: 0.6909, Acc: 0.5412, Val Loss: 0.6880, Val Acc: 0.5982
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6909, Acc: 0.5432, Val Loss: 0.6881, Val Acc: 0.5934
Epoch 63/100, Loss: 0.6909, Acc: 0.5434, Val Loss: 0.6880, Val Acc: 0.5974
Epoch 64/100, Loss: 0.6908, Acc: 0.5410, Val Loss: 0.6880, Val Acc: 0.5956
Epoch 65/100, Loss: 0.6908, Acc: 0.5430, Val Loss: 0.6879, Val Acc: 0.5982
Epoch 66/100, Loss: 0.6908, Acc: 0.5426, Val Loss: 0.6878, Val Acc: 0.5974
Epoch 67/100, Loss: 0.6908, Acc: 0.5422, Val Loss: 0.6878, Val Acc: 0.5974
Epoch 68/100, Loss: 0.6908, Acc: 0.5435, Val Loss: 0.6878, Val Acc: 0.5982
Epoch 69/100, Loss: 0.6908, Acc: 0.5453, Val Loss: 0.6877, Val Acc: 0.6000
Epoch 70/100, Loss: 0.6907, Acc: 0.5428, Val Loss: 0.6877, Val Acc: 0.6011
Epoch 71/100, Loss: 0.6907, Acc: 0.5419, Val Loss: 0.6876, Val Acc: 0.6018
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6907, Acc: 0.5427, Val Loss: 0.6875, Val Acc: 0.6011
Epoch 73/100, Loss: 0.6907, Acc: 0.5437, Val Loss: 0.6875, Val Acc: 0.6015
Epoch 74/100, Loss: 0.6907, Acc: 0.5420, Val Loss: 0.6875, Val Acc: 0.6018
Epoch 75/100, Loss: 0.6906, Acc: 0.5430, Val Loss: 0.6875, Val Acc: 0.6029
Epoch 76/100, Loss: 0.6906, Acc: 0.5440, Val Loss: 0.6874, Val Acc: 0.6033
Epoch 77/100, Loss: 0.6906, Acc: 0.5435, Val Loss: 0.6874, Val Acc: 0.6026
Epoch 78/100, Loss: 0.6906, Acc: 0.5440, Val Loss: 0.6873, Val Acc: 0.6051
Epoch 79/100, Loss: 0.6906, Acc: 0.5439, Val Loss: 0.6874, Val Acc: 0.6026
Epoch 80/100, Loss: 0.6906, Acc: 0.5453, Val Loss: 0.6873, Val Acc: 0.6037
Epoch 81/100, Loss: 0.6906, Acc: 0.5437, Val Loss: 0.6873, Val Acc: 0.6037
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6906, Acc: 0.5455, Val Loss: 0.6873, Val Acc: 0.6033
Epoch 83/100, Loss: 0.6905, Acc: 0.5434, Val Loss: 0.6872, Val Acc: 0.6037
Epoch 84/100, Loss: 0.6905, Acc: 0.5441, Val Loss: 0.6872, Val Acc: 0.6048
Epoch 85/100, Loss: 0.6905, Acc: 0.5432, Val Loss: 0.6871, Val Acc: 0.6074
Epoch 86/100, Loss: 0.6905, Acc: 0.5463, Val Loss: 0.6871, Val Acc: 0.6033
Epoch 87/100, Loss: 0.6905, Acc: 0.5451, Val Loss: 0.6870, Val Acc: 0.6074
Epoch 88/100, Loss: 0.6905, Acc: 0.5453, Val Loss: 0.6869, Val Acc: 0.6070
Epoch 89/100, Loss: 0.6904, Acc: 0.5455, Val Loss: 0.6866, Val Acc: 0.6096
Epoch 90/100, Loss: 0.6904, Acc: 0.5464, Val Loss: 0.6861, Val Acc: 0.6118
Epoch 91/100, Loss: 0.6903, Acc: 0.5457, Val Loss: 0.6859, Val Acc: 0.6118
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6902, Acc: 0.5460, Val Loss: 0.6859, Val Acc: 0.6118
Epoch 93/100, Loss: 0.6902, Acc: 0.5475, Val Loss: 0.6858, Val Acc: 0.6110
Epoch 94/100, Loss: 0.6902, Acc: 0.5485, Val Loss: 0.6858, Val Acc: 0.6114
Epoch 95/100, Loss: 0.6902, Acc: 0.5474, Val Loss: 0.6857, Val Acc: 0.6114
Epoch 96/100, Loss: 0.6901, Acc: 0.5487, Val Loss: 0.6857, Val Acc: 0.6103
Epoch 97/100, Loss: 0.6901, Acc: 0.5477, Val Loss: 0.6856, Val Acc: 0.6129
Epoch 98/100, Loss: 0.6901, Acc: 0.5485, Val Loss: 0.6856, Val Acc: 0.6151
Epoch 99/100, Loss: 0.6901, Acc: 0.5486, Val Loss: 0.6855, Val Acc: 0.6151
Epoch 100/100, Loss: 0.6901, Acc: 0.5476, Val Loss: 0.6855, Val Acc: 0.6143

##############################
Resultados para principal:  104  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1 
 {'training': [0.6900769812219283, 0.5476102941176471, 0.5465659834591874, 0.5588235294117647, 0.5526267951281585], 'validate': [0.6854562537614689, 0.6143382352941177, 0.6288318144159072, 0.5580882352941177, 0.5913517724970783], 'test': [0.6796457138326433, 0.5, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  093  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  093  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  093  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6680, Acc: 0.6183, Val Loss: 0.7395, Val Acc: 0.4485
Mejor modelo guardado con Val Loss: 0.7395
Epoch 2/100, Loss: 0.6523, Acc: 0.6480, Val Loss: 0.8023, Val Acc: 0.2860
Epoch 3/100, Loss: 0.6358, Acc: 0.6634, Val Loss: 0.8129, Val Acc: 0.3798
Epoch 4/100, Loss: 0.6324, Acc: 0.6551, Val Loss: 0.8647, Val Acc: 0.3662
Epoch 5/100, Loss: 0.6220, Acc: 0.6668, Val Loss: 0.8705, Val Acc: 0.3849
Epoch 6/100, Loss: 0.6198, Acc: 0.6682, Val Loss: 0.9492, Val Acc: 0.2923
Epoch 7/100, Loss: 0.6224, Acc: 0.6680, Val Loss: 0.9199, Val Acc: 0.3272
Epoch 8/100, Loss: 0.6140, Acc: 0.6734, Val Loss: 0.9441, Val Acc: 0.3710
Epoch 9/100, Loss: 0.6208, Acc: 0.6670, Val Loss: 0.8797, Val Acc: 0.3158
Epoch 10/100, Loss: 0.6172, Acc: 0.6710, Val Loss: 0.8765, Val Acc: 0.3184
Epoch 11/100, Loss: 0.6250, Acc: 0.6630, Val Loss: 0.9012, Val Acc: 0.2540
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6183, Acc: 0.6743, Val Loss: 0.8923, Val Acc: 0.3434
Epoch 13/100, Loss: 0.6148, Acc: 0.6757, Val Loss: 0.8979, Val Acc: 0.2783
Epoch 14/100, Loss: 0.6151, Acc: 0.6749, Val Loss: 0.8517, Val Acc: 0.4165
Epoch 15/100, Loss: 0.6203, Acc: 0.6682, Val Loss: 0.8821, Val Acc: 0.3169
Epoch 16/100, Loss: 0.6149, Acc: 0.6676, Val Loss: 0.8457, Val Acc: 0.4261
Epoch 17/100, Loss: 0.6123, Acc: 0.6770, Val Loss: 0.9284, Val Acc: 0.3140
Epoch 18/100, Loss: 0.6127, Acc: 0.6752, Val Loss: 0.9340, Val Acc: 0.3309
Epoch 19/100, Loss: 0.6121, Acc: 0.6767, Val Loss: 0.8931, Val Acc: 0.3890
Epoch 20/100, Loss: 0.6108, Acc: 0.6766, Val Loss: 0.9098, Val Acc: 0.3335
Epoch 21/100, Loss: 0.6119, Acc: 0.6771, Val Loss: 0.9089, Val Acc: 0.3735
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6073, Acc: 0.6819, Val Loss: 0.9215, Val Acc: 0.3640
Epoch 23/100, Loss: 0.6067, Acc: 0.6797, Val Loss: 0.9035, Val Acc: 0.3761
Epoch 24/100, Loss: 0.6075, Acc: 0.6834, Val Loss: 0.8978, Val Acc: 0.3860
Epoch 25/100, Loss: 0.6079, Acc: 0.6760, Val Loss: 0.9101, Val Acc: 0.3790
Epoch 26/100, Loss: 0.6079, Acc: 0.6804, Val Loss: 0.9159, Val Acc: 0.3790
Epoch 27/100, Loss: 0.6060, Acc: 0.6810, Val Loss: 0.9310, Val Acc: 0.3563
Epoch 28/100, Loss: 0.6066, Acc: 0.6862, Val Loss: 0.9044, Val Acc: 0.3871
Epoch 29/100, Loss: 0.6051, Acc: 0.6800, Val Loss: 0.9292, Val Acc: 0.3496
Epoch 30/100, Loss: 0.6066, Acc: 0.6804, Val Loss: 0.9337, Val Acc: 0.3415
Epoch 31/100, Loss: 0.6051, Acc: 0.6825, Val Loss: 0.9359, Val Acc: 0.3467
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6047, Acc: 0.6833, Val Loss: 0.9181, Val Acc: 0.3702
Epoch 33/100, Loss: 0.6055, Acc: 0.6841, Val Loss: 0.9060, Val Acc: 0.3875
Epoch 34/100, Loss: 0.6048, Acc: 0.6835, Val Loss: 0.9207, Val Acc: 0.3695
Epoch 35/100, Loss: 0.6049, Acc: 0.6858, Val Loss: 0.9141, Val Acc: 0.3809
Epoch 36/100, Loss: 0.6047, Acc: 0.6845, Val Loss: 0.9313, Val Acc: 0.3724
Epoch 37/100, Loss: 0.6044, Acc: 0.6835, Val Loss: 0.9222, Val Acc: 0.3790
Epoch 38/100, Loss: 0.6036, Acc: 0.6859, Val Loss: 0.9453, Val Acc: 0.3496
Epoch 39/100, Loss: 0.6037, Acc: 0.6835, Val Loss: 0.9329, Val Acc: 0.3647
Epoch 40/100, Loss: 0.6036, Acc: 0.6846, Val Loss: 0.9334, Val Acc: 0.3607
Epoch 41/100, Loss: 0.6038, Acc: 0.6849, Val Loss: 0.9215, Val Acc: 0.3787
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6031, Acc: 0.6852, Val Loss: 0.9413, Val Acc: 0.3540
Epoch 43/100, Loss: 0.6030, Acc: 0.6841, Val Loss: 0.9248, Val Acc: 0.3739
Epoch 44/100, Loss: 0.6034, Acc: 0.6850, Val Loss: 0.9290, Val Acc: 0.3721
Epoch 45/100, Loss: 0.6028, Acc: 0.6860, Val Loss: 0.9122, Val Acc: 0.3893
Epoch 46/100, Loss: 0.6028, Acc: 0.6847, Val Loss: 0.9195, Val Acc: 0.3842
Epoch 47/100, Loss: 0.6030, Acc: 0.6853, Val Loss: 0.9346, Val Acc: 0.3585
Epoch 48/100, Loss: 0.6027, Acc: 0.6868, Val Loss: 0.9283, Val Acc: 0.3676
Epoch 49/100, Loss: 0.6026, Acc: 0.6873, Val Loss: 0.9327, Val Acc: 0.3743
Epoch 50/100, Loss: 0.6023, Acc: 0.6849, Val Loss: 0.9131, Val Acc: 0.3904
Epoch 51/100, Loss: 0.6029, Acc: 0.6870, Val Loss: 0.9254, Val Acc: 0.3838
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6021, Acc: 0.6867, Val Loss: 0.9353, Val Acc: 0.3665
Epoch 53/100, Loss: 0.6022, Acc: 0.6876, Val Loss: 0.9262, Val Acc: 0.3812
Epoch 54/100, Loss: 0.6024, Acc: 0.6845, Val Loss: 0.9269, Val Acc: 0.3761
Epoch 55/100, Loss: 0.6020, Acc: 0.6871, Val Loss: 0.9237, Val Acc: 0.3820
Epoch 56/100, Loss: 0.6019, Acc: 0.6881, Val Loss: 0.9191, Val Acc: 0.3849
Epoch 57/100, Loss: 0.6023, Acc: 0.6864, Val Loss: 0.9228, Val Acc: 0.3805
Epoch 58/100, Loss: 0.6019, Acc: 0.6858, Val Loss: 0.9323, Val Acc: 0.3673
Epoch 59/100, Loss: 0.6020, Acc: 0.6878, Val Loss: 0.9296, Val Acc: 0.3728
Epoch 60/100, Loss: 0.6016, Acc: 0.6868, Val Loss: 0.9144, Val Acc: 0.3897
Epoch 61/100, Loss: 0.6016, Acc: 0.6857, Val Loss: 0.9317, Val Acc: 0.3688
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6016, Acc: 0.6873, Val Loss: 0.9227, Val Acc: 0.3824
Epoch 63/100, Loss: 0.6017, Acc: 0.6869, Val Loss: 0.9273, Val Acc: 0.3772
Epoch 64/100, Loss: 0.6016, Acc: 0.6879, Val Loss: 0.9246, Val Acc: 0.3801
Epoch 65/100, Loss: 0.6015, Acc: 0.6878, Val Loss: 0.9276, Val Acc: 0.3776
Epoch 66/100, Loss: 0.6016, Acc: 0.6879, Val Loss: 0.9235, Val Acc: 0.3812
Epoch 67/100, Loss: 0.6015, Acc: 0.6870, Val Loss: 0.9248, Val Acc: 0.3798
Epoch 68/100, Loss: 0.6017, Acc: 0.6853, Val Loss: 0.9265, Val Acc: 0.3776
Epoch 69/100, Loss: 0.6015, Acc: 0.6876, Val Loss: 0.9275, Val Acc: 0.3772
Epoch 70/100, Loss: 0.6015, Acc: 0.6872, Val Loss: 0.9306, Val Acc: 0.3691
Epoch 71/100, Loss: 0.6014, Acc: 0.6874, Val Loss: 0.9231, Val Acc: 0.3812
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6014, Acc: 0.6873, Val Loss: 0.9274, Val Acc: 0.3776
Epoch 73/100, Loss: 0.6013, Acc: 0.6887, Val Loss: 0.9249, Val Acc: 0.3794
Epoch 74/100, Loss: 0.6014, Acc: 0.6884, Val Loss: 0.9247, Val Acc: 0.3801
Epoch 75/100, Loss: 0.6014, Acc: 0.6881, Val Loss: 0.9233, Val Acc: 0.3816
Epoch 76/100, Loss: 0.6014, Acc: 0.6883, Val Loss: 0.9235, Val Acc: 0.3816
Epoch 77/100, Loss: 0.6014, Acc: 0.6886, Val Loss: 0.9253, Val Acc: 0.3787
Epoch 78/100, Loss: 0.6013, Acc: 0.6882, Val Loss: 0.9253, Val Acc: 0.3787
Epoch 79/100, Loss: 0.6013, Acc: 0.6880, Val Loss: 0.9242, Val Acc: 0.3801
Epoch 80/100, Loss: 0.6013, Acc: 0.6885, Val Loss: 0.9288, Val Acc: 0.3739
Epoch 81/100, Loss: 0.6013, Acc: 0.6871, Val Loss: 0.9261, Val Acc: 0.3783
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6013, Acc: 0.6870, Val Loss: 0.9253, Val Acc: 0.3790
Epoch 83/100, Loss: 0.6014, Acc: 0.6874, Val Loss: 0.9263, Val Acc: 0.3783
Epoch 84/100, Loss: 0.6014, Acc: 0.6877, Val Loss: 0.9247, Val Acc: 0.3798
Epoch 85/100, Loss: 0.6014, Acc: 0.6876, Val Loss: 0.9247, Val Acc: 0.3798
Epoch 86/100, Loss: 0.6012, Acc: 0.6881, Val Loss: 0.9262, Val Acc: 0.3787
Epoch 87/100, Loss: 0.6013, Acc: 0.6880, Val Loss: 0.9266, Val Acc: 0.3783
Epoch 88/100, Loss: 0.6013, Acc: 0.6880, Val Loss: 0.9266, Val Acc: 0.3783
Epoch 89/100, Loss: 0.6013, Acc: 0.6883, Val Loss: 0.9265, Val Acc: 0.3787
Epoch 90/100, Loss: 0.6012, Acc: 0.6878, Val Loss: 0.9249, Val Acc: 0.3805
Epoch 91/100, Loss: 0.6013, Acc: 0.6881, Val Loss: 0.9264, Val Acc: 0.3787
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6012, Acc: 0.6876, Val Loss: 0.9265, Val Acc: 0.3779
Epoch 93/100, Loss: 0.6012, Acc: 0.6875, Val Loss: 0.9300, Val Acc: 0.3710
Epoch 94/100, Loss: 0.6012, Acc: 0.6888, Val Loss: 0.9300, Val Acc: 0.3713
Epoch 95/100, Loss: 0.6013, Acc: 0.6875, Val Loss: 0.9294, Val Acc: 0.3750
Epoch 96/100, Loss: 0.6012, Acc: 0.6880, Val Loss: 0.9273, Val Acc: 0.3779
Epoch 97/100, Loss: 0.6012, Acc: 0.6879, Val Loss: 0.9255, Val Acc: 0.3798
Epoch 98/100, Loss: 0.6012, Acc: 0.6886, Val Loss: 0.9283, Val Acc: 0.3765
Epoch 99/100, Loss: 0.6012, Acc: 0.6869, Val Loss: 0.9282, Val Acc: 0.3768
Epoch 100/100, Loss: 0.6012, Acc: 0.6882, Val Loss: 0.9268, Val Acc: 0.3790

##############################
Resultados para principal:  093  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1 
 {'training': [0.601217349136577, 0.6882352941176471, 0.663317384370016, 0.7645220588235294, 0.7103330486763451], 'validate': [0.9267875545246657, 0.3790441176470588, 0.42724458204334365, 0.7102941176470589, 0.5335542667771334], 'test': [0.7314841537563889, 0.47705882352941176, 0.4875239923224568, 0.8964705882352941, 0.631578947368421]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  088  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  088  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  088  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6915, Acc: 0.5155, Val Loss: 0.6726, Val Acc: 0.6265
Mejor modelo guardado con Val Loss: 0.6726
Epoch 2/100, Loss: 0.6921, Acc: 0.5040, Val Loss: 0.6890, Val Acc: 0.5897
Epoch 3/100, Loss: 0.6901, Acc: 0.5165, Val Loss: 0.6759, Val Acc: 0.5000
Epoch 4/100, Loss: 0.6861, Acc: 0.5395, Val Loss: 0.6654, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6654
Epoch 5/100, Loss: 0.6810, Acc: 0.5358, Val Loss: 0.6514, Val Acc: 0.6691
Mejor modelo guardado con Val Loss: 0.6514
Epoch 6/100, Loss: 0.6789, Acc: 0.5409, Val Loss: 0.6493, Val Acc: 0.6886
Mejor modelo guardado con Val Loss: 0.6493
Epoch 7/100, Loss: 0.6776, Acc: 0.5575, Val Loss: 0.6451, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6451
Epoch 8/100, Loss: 0.6759, Acc: 0.5481, Val Loss: 0.6259, Val Acc: 0.7188
Mejor modelo guardado con Val Loss: 0.6259
Epoch 9/100, Loss: 0.6747, Acc: 0.5546, Val Loss: 0.6186, Val Acc: 0.7217
Mejor modelo guardado con Val Loss: 0.6186
Epoch 10/100, Loss: 0.6729, Acc: 0.5572, Val Loss: 0.5980, Val Acc: 0.7500
Mejor modelo guardado con Val Loss: 0.5980
Epoch 11/100, Loss: 0.6711, Acc: 0.5606, Val Loss: 0.6277, Val Acc: 0.6989
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6687, Acc: 0.5617, Val Loss: 0.6001, Val Acc: 0.7412
Epoch 13/100, Loss: 0.6679, Acc: 0.5611, Val Loss: 0.5848, Val Acc: 0.7540
Mejor modelo guardado con Val Loss: 0.5848
Epoch 14/100, Loss: 0.6679, Acc: 0.5616, Val Loss: 0.6058, Val Acc: 0.7250
Epoch 15/100, Loss: 0.6670, Acc: 0.5627, Val Loss: 0.5833, Val Acc: 0.7471
Mejor modelo guardado con Val Loss: 0.5833
Epoch 16/100, Loss: 0.6661, Acc: 0.5631, Val Loss: 0.5901, Val Acc: 0.7408
Epoch 17/100, Loss: 0.6648, Acc: 0.5646, Val Loss: 0.5789, Val Acc: 0.7493
Mejor modelo guardado con Val Loss: 0.5789
Epoch 18/100, Loss: 0.6647, Acc: 0.5635, Val Loss: 0.5770, Val Acc: 0.7504
Mejor modelo guardado con Val Loss: 0.5770
Epoch 19/100, Loss: 0.6650, Acc: 0.5623, Val Loss: 0.5758, Val Acc: 0.7482
Mejor modelo guardado con Val Loss: 0.5758
Epoch 20/100, Loss: 0.6646, Acc: 0.5632, Val Loss: 0.5796, Val Acc: 0.7441
Epoch 21/100, Loss: 0.6638, Acc: 0.5626, Val Loss: 0.5675, Val Acc: 0.7533
Mejor modelo guardado con Val Loss: 0.5675
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6625, Acc: 0.5631, Val Loss: 0.5696, Val Acc: 0.7500
Epoch 23/100, Loss: 0.6623, Acc: 0.5633, Val Loss: 0.5641, Val Acc: 0.7570
Mejor modelo guardado con Val Loss: 0.5641
Epoch 24/100, Loss: 0.6621, Acc: 0.5648, Val Loss: 0.5695, Val Acc: 0.7493
Epoch 25/100, Loss: 0.6616, Acc: 0.5635, Val Loss: 0.5692, Val Acc: 0.7485
Epoch 26/100, Loss: 0.6620, Acc: 0.5631, Val Loss: 0.5744, Val Acc: 0.7449
Epoch 27/100, Loss: 0.6613, Acc: 0.5637, Val Loss: 0.5644, Val Acc: 0.7522
Epoch 28/100, Loss: 0.6616, Acc: 0.5636, Val Loss: 0.5673, Val Acc: 0.7482
Epoch 29/100, Loss: 0.6608, Acc: 0.5634, Val Loss: 0.5632, Val Acc: 0.7489
Mejor modelo guardado con Val Loss: 0.5632
Epoch 30/100, Loss: 0.6605, Acc: 0.5642, Val Loss: 0.5574, Val Acc: 0.7585
Mejor modelo guardado con Val Loss: 0.5574
Epoch 31/100, Loss: 0.6606, Acc: 0.5642, Val Loss: 0.5651, Val Acc: 0.7485
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6602, Acc: 0.5639, Val Loss: 0.5613, Val Acc: 0.7500
Epoch 33/100, Loss: 0.6603, Acc: 0.5647, Val Loss: 0.5606, Val Acc: 0.7500
Epoch 34/100, Loss: 0.6600, Acc: 0.5641, Val Loss: 0.5589, Val Acc: 0.7507
Epoch 35/100, Loss: 0.6599, Acc: 0.5642, Val Loss: 0.5571, Val Acc: 0.7540
Mejor modelo guardado con Val Loss: 0.5571
Epoch 36/100, Loss: 0.6599, Acc: 0.5638, Val Loss: 0.5587, Val Acc: 0.7515
Epoch 37/100, Loss: 0.6597, Acc: 0.5644, Val Loss: 0.5538, Val Acc: 0.7603
Mejor modelo guardado con Val Loss: 0.5538
Epoch 38/100, Loss: 0.6596, Acc: 0.5649, Val Loss: 0.5606, Val Acc: 0.7496
Epoch 39/100, Loss: 0.6596, Acc: 0.5635, Val Loss: 0.5562, Val Acc: 0.7511
Epoch 40/100, Loss: 0.6594, Acc: 0.5648, Val Loss: 0.5514, Val Acc: 0.7618
Mejor modelo guardado con Val Loss: 0.5514
Epoch 41/100, Loss: 0.6593, Acc: 0.5648, Val Loss: 0.5562, Val Acc: 0.7511
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6590, Acc: 0.5641, Val Loss: 0.5517, Val Acc: 0.7599
Epoch 43/100, Loss: 0.6591, Acc: 0.5644, Val Loss: 0.5521, Val Acc: 0.7592
Epoch 44/100, Loss: 0.6591, Acc: 0.5640, Val Loss: 0.5540, Val Acc: 0.7529
Epoch 45/100, Loss: 0.6589, Acc: 0.5638, Val Loss: 0.5531, Val Acc: 0.7544
Epoch 46/100, Loss: 0.6588, Acc: 0.5642, Val Loss: 0.5519, Val Acc: 0.7562
Epoch 47/100, Loss: 0.6588, Acc: 0.5645, Val Loss: 0.5528, Val Acc: 0.7540
Epoch 48/100, Loss: 0.6588, Acc: 0.5638, Val Loss: 0.5539, Val Acc: 0.7515
Epoch 49/100, Loss: 0.6588, Acc: 0.5642, Val Loss: 0.5549, Val Acc: 0.7537
Epoch 50/100, Loss: 0.6587, Acc: 0.5644, Val Loss: 0.5509, Val Acc: 0.7596
Mejor modelo guardado con Val Loss: 0.5509
Epoch 51/100, Loss: 0.6587, Acc: 0.5634, Val Loss: 0.5512, Val Acc: 0.7562
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6585, Acc: 0.5639, Val Loss: 0.5522, Val Acc: 0.7544
Epoch 53/100, Loss: 0.6585, Acc: 0.5644, Val Loss: 0.5515, Val Acc: 0.7562
Epoch 54/100, Loss: 0.6585, Acc: 0.5640, Val Loss: 0.5516, Val Acc: 0.7548
Epoch 55/100, Loss: 0.6585, Acc: 0.5651, Val Loss: 0.5531, Val Acc: 0.7518
Epoch 56/100, Loss: 0.6584, Acc: 0.5645, Val Loss: 0.5510, Val Acc: 0.7570
Epoch 57/100, Loss: 0.6584, Acc: 0.5645, Val Loss: 0.5503, Val Acc: 0.7581
Mejor modelo guardado con Val Loss: 0.5503
Epoch 58/100, Loss: 0.6584, Acc: 0.5641, Val Loss: 0.5529, Val Acc: 0.7511
Epoch 59/100, Loss: 0.6584, Acc: 0.5642, Val Loss: 0.5500, Val Acc: 0.7581
Mejor modelo guardado con Val Loss: 0.5500
Epoch 60/100, Loss: 0.6584, Acc: 0.5646, Val Loss: 0.5503, Val Acc: 0.7574
Epoch 61/100, Loss: 0.6583, Acc: 0.5647, Val Loss: 0.5518, Val Acc: 0.7529
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6583, Acc: 0.5645, Val Loss: 0.5512, Val Acc: 0.7533
Epoch 63/100, Loss: 0.6583, Acc: 0.5645, Val Loss: 0.5508, Val Acc: 0.7540
Epoch 64/100, Loss: 0.6583, Acc: 0.5637, Val Loss: 0.5505, Val Acc: 0.7551
Epoch 65/100, Loss: 0.6582, Acc: 0.5645, Val Loss: 0.5517, Val Acc: 0.7529
Epoch 66/100, Loss: 0.6582, Acc: 0.5644, Val Loss: 0.5507, Val Acc: 0.7544
Epoch 67/100, Loss: 0.6582, Acc: 0.5644, Val Loss: 0.5495, Val Acc: 0.7581
Mejor modelo guardado con Val Loss: 0.5495
Epoch 68/100, Loss: 0.6582, Acc: 0.5642, Val Loss: 0.5502, Val Acc: 0.7559
Epoch 69/100, Loss: 0.6582, Acc: 0.5644, Val Loss: 0.5498, Val Acc: 0.7574
Epoch 70/100, Loss: 0.6581, Acc: 0.5649, Val Loss: 0.5503, Val Acc: 0.7544
Epoch 71/100, Loss: 0.6582, Acc: 0.5645, Val Loss: 0.5494, Val Acc: 0.7581
Mejor modelo guardado con Val Loss: 0.5494
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6581, Acc: 0.5643, Val Loss: 0.5501, Val Acc: 0.7551
Epoch 73/100, Loss: 0.6581, Acc: 0.5647, Val Loss: 0.5499, Val Acc: 0.7566
Epoch 74/100, Loss: 0.6581, Acc: 0.5642, Val Loss: 0.5502, Val Acc: 0.7544
Epoch 75/100, Loss: 0.6581, Acc: 0.5646, Val Loss: 0.5500, Val Acc: 0.7551
Epoch 76/100, Loss: 0.6581, Acc: 0.5642, Val Loss: 0.5501, Val Acc: 0.7544
Epoch 77/100, Loss: 0.6581, Acc: 0.5646, Val Loss: 0.5498, Val Acc: 0.7555
Epoch 78/100, Loss: 0.6581, Acc: 0.5645, Val Loss: 0.5500, Val Acc: 0.7544
Epoch 79/100, Loss: 0.6581, Acc: 0.5642, Val Loss: 0.5505, Val Acc: 0.7526
Epoch 80/100, Loss: 0.6581, Acc: 0.5644, Val Loss: 0.5502, Val Acc: 0.7537
Epoch 81/100, Loss: 0.6581, Acc: 0.5648, Val Loss: 0.5499, Val Acc: 0.7544
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6580, Acc: 0.5646, Val Loss: 0.5501, Val Acc: 0.7537
Epoch 83/100, Loss: 0.6580, Acc: 0.5642, Val Loss: 0.5499, Val Acc: 0.7544
Epoch 84/100, Loss: 0.6580, Acc: 0.5645, Val Loss: 0.5500, Val Acc: 0.7544
Epoch 85/100, Loss: 0.6580, Acc: 0.5646, Val Loss: 0.5496, Val Acc: 0.7555
Epoch 86/100, Loss: 0.6580, Acc: 0.5646, Val Loss: 0.5497, Val Acc: 0.7548
Epoch 87/100, Loss: 0.6580, Acc: 0.5648, Val Loss: 0.5494, Val Acc: 0.7566
Mejor modelo guardado con Val Loss: 0.5494
Epoch 88/100, Loss: 0.6580, Acc: 0.5646, Val Loss: 0.5495, Val Acc: 0.7559
Epoch 89/100, Loss: 0.6580, Acc: 0.5645, Val Loss: 0.5495, Val Acc: 0.7559
Epoch 90/100, Loss: 0.6580, Acc: 0.5645, Val Loss: 0.5495, Val Acc: 0.7559
Epoch 91/100, Loss: 0.6580, Acc: 0.5647, Val Loss: 0.5496, Val Acc: 0.7544
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6580, Acc: 0.5648, Val Loss: 0.5497, Val Acc: 0.7544
Epoch 93/100, Loss: 0.6580, Acc: 0.5644, Val Loss: 0.5496, Val Acc: 0.7544
Epoch 94/100, Loss: 0.6580, Acc: 0.5644, Val Loss: 0.5496, Val Acc: 0.7544
Epoch 95/100, Loss: 0.6580, Acc: 0.5651, Val Loss: 0.5497, Val Acc: 0.7537
Epoch 96/100, Loss: 0.6579, Acc: 0.5643, Val Loss: 0.5495, Val Acc: 0.7544
Epoch 97/100, Loss: 0.6574, Acc: 0.5641, Val Loss: 0.5494, Val Acc: 0.7566
Epoch 98/100, Loss: 0.6572, Acc: 0.5646, Val Loss: 0.5494, Val Acc: 0.7562
Epoch 99/100, Loss: 0.6572, Acc: 0.5646, Val Loss: 0.5495, Val Acc: 0.7562
Epoch 100/100, Loss: 0.6571, Acc: 0.5645, Val Loss: 0.5495, Val Acc: 0.7559

##############################
Resultados para principal:  088  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1 
 {'training': [0.6571336819845087, 0.5645220588235295, 0.5352834740651388, 0.9788602941176471, 0.6920977384975305], 'validate': [0.5494790929694509, 0.7558823529411764, 0.6827731092436975, 0.9558823529411765, 0.7965686274509803], 'test': [0.5106303062703874, 0.8473529411764706, 0.7770999530736743, 0.9741176470588235, 0.8645262333594361]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  055  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  055  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  055  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6894, Acc: 0.5439, Val Loss: 0.6798, Val Acc: 0.5033
Mejor modelo guardado con Val Loss: 0.6798
Epoch 2/100, Loss: 0.6861, Acc: 0.5642, Val Loss: 0.6432, Val Acc: 0.8243
Mejor modelo guardado con Val Loss: 0.6432
Epoch 3/100, Loss: 0.6798, Acc: 0.5848, Val Loss: 0.6160, Val Acc: 0.8805
Mejor modelo guardado con Val Loss: 0.6160
Epoch 4/100, Loss: 0.6787, Acc: 0.5825, Val Loss: 0.5995, Val Acc: 0.8993
Mejor modelo guardado con Val Loss: 0.5995
Epoch 5/100, Loss: 0.6766, Acc: 0.5916, Val Loss: 0.6033, Val Acc: 0.7610
Epoch 6/100, Loss: 0.6717, Acc: 0.5952, Val Loss: 0.5987, Val Acc: 0.7452
Mejor modelo guardado con Val Loss: 0.5987
Epoch 7/100, Loss: 0.6716, Acc: 0.5838, Val Loss: 0.5748, Val Acc: 0.8077
Mejor modelo guardado con Val Loss: 0.5748
Epoch 8/100, Loss: 0.6693, Acc: 0.5953, Val Loss: 0.5685, Val Acc: 0.8066
Mejor modelo guardado con Val Loss: 0.5685
Epoch 9/100, Loss: 0.6671, Acc: 0.5931, Val Loss: 0.5453, Val Acc: 0.8846
Mejor modelo guardado con Val Loss: 0.5453
Epoch 10/100, Loss: 0.6684, Acc: 0.5969, Val Loss: 0.5960, Val Acc: 0.7154
Epoch 11/100, Loss: 0.6676, Acc: 0.5960, Val Loss: 0.5305, Val Acc: 0.8290
Mejor modelo guardado con Val Loss: 0.5305
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6617, Acc: 0.6112, Val Loss: 0.5225, Val Acc: 0.8570
Mejor modelo guardado con Val Loss: 0.5225
Epoch 13/100, Loss: 0.6629, Acc: 0.5965, Val Loss: 0.5381, Val Acc: 0.8051
Epoch 14/100, Loss: 0.6635, Acc: 0.6033, Val Loss: 0.5359, Val Acc: 0.8085
Epoch 15/100, Loss: 0.6614, Acc: 0.6044, Val Loss: 0.5292, Val Acc: 0.7923
Epoch 16/100, Loss: 0.6592, Acc: 0.6133, Val Loss: 0.5234, Val Acc: 0.8265
Epoch 17/100, Loss: 0.6619, Acc: 0.6047, Val Loss: 0.5520, Val Acc: 0.7574
Epoch 18/100, Loss: 0.6610, Acc: 0.6116, Val Loss: 0.5190, Val Acc: 0.8301
Mejor modelo guardado con Val Loss: 0.5190
Epoch 19/100, Loss: 0.6596, Acc: 0.6099, Val Loss: 0.5405, Val Acc: 0.7915
Epoch 20/100, Loss: 0.6596, Acc: 0.6082, Val Loss: 0.5251, Val Acc: 0.7956
Epoch 21/100, Loss: 0.6620, Acc: 0.6055, Val Loss: 0.4856, Val Acc: 0.8934
Mejor modelo guardado con Val Loss: 0.4856
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6592, Acc: 0.6128, Val Loss: 0.5137, Val Acc: 0.8195
Epoch 23/100, Loss: 0.6580, Acc: 0.6121, Val Loss: 0.4970, Val Acc: 0.8614
Epoch 24/100, Loss: 0.6573, Acc: 0.6132, Val Loss: 0.5017, Val Acc: 0.8529
Epoch 25/100, Loss: 0.6580, Acc: 0.6101, Val Loss: 0.5182, Val Acc: 0.8103
Epoch 26/100, Loss: 0.6571, Acc: 0.6161, Val Loss: 0.5009, Val Acc: 0.8482
Epoch 27/100, Loss: 0.6582, Acc: 0.6045, Val Loss: 0.4902, Val Acc: 0.8757
Epoch 28/100, Loss: 0.6594, Acc: 0.6093, Val Loss: 0.5028, Val Acc: 0.8482
Epoch 29/100, Loss: 0.6578, Acc: 0.6107, Val Loss: 0.4860, Val Acc: 0.8746
Epoch 30/100, Loss: 0.6569, Acc: 0.6151, Val Loss: 0.4990, Val Acc: 0.8438
Epoch 31/100, Loss: 0.6563, Acc: 0.6196, Val Loss: 0.5085, Val Acc: 0.8199
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6555, Acc: 0.6166, Val Loss: 0.5298, Val Acc: 0.7684
Epoch 33/100, Loss: 0.6557, Acc: 0.6191, Val Loss: 0.5057, Val Acc: 0.8221
Epoch 34/100, Loss: 0.6558, Acc: 0.6147, Val Loss: 0.4956, Val Acc: 0.8456
Epoch 35/100, Loss: 0.6558, Acc: 0.6179, Val Loss: 0.5049, Val Acc: 0.8217
Epoch 36/100, Loss: 0.6558, Acc: 0.6169, Val Loss: 0.5087, Val Acc: 0.8107
Epoch 37/100, Loss: 0.6557, Acc: 0.6172, Val Loss: 0.5066, Val Acc: 0.8173
Epoch 38/100, Loss: 0.6552, Acc: 0.6204, Val Loss: 0.4992, Val Acc: 0.8298
Epoch 39/100, Loss: 0.6560, Acc: 0.6173, Val Loss: 0.5092, Val Acc: 0.7974
Epoch 40/100, Loss: 0.6554, Acc: 0.6171, Val Loss: 0.5003, Val Acc: 0.8265
Epoch 41/100, Loss: 0.6551, Acc: 0.6172, Val Loss: 0.4954, Val Acc: 0.8276
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6541, Acc: 0.6215, Val Loss: 0.5132, Val Acc: 0.7904
Epoch 43/100, Loss: 0.6543, Acc: 0.6188, Val Loss: 0.4911, Val Acc: 0.8441
Epoch 44/100, Loss: 0.6546, Acc: 0.6182, Val Loss: 0.5081, Val Acc: 0.8048
Epoch 45/100, Loss: 0.6543, Acc: 0.6185, Val Loss: 0.5024, Val Acc: 0.8151
Epoch 46/100, Loss: 0.6543, Acc: 0.6208, Val Loss: 0.5020, Val Acc: 0.8176
Epoch 47/100, Loss: 0.6546, Acc: 0.6184, Val Loss: 0.4893, Val Acc: 0.8404
Epoch 48/100, Loss: 0.6542, Acc: 0.6189, Val Loss: 0.5035, Val Acc: 0.8143
Epoch 49/100, Loss: 0.6541, Acc: 0.6197, Val Loss: 0.4978, Val Acc: 0.8243
Epoch 50/100, Loss: 0.6544, Acc: 0.6171, Val Loss: 0.5076, Val Acc: 0.8029
Epoch 51/100, Loss: 0.6541, Acc: 0.6196, Val Loss: 0.4971, Val Acc: 0.8235
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6537, Acc: 0.6194, Val Loss: 0.4958, Val Acc: 0.8257
Epoch 53/100, Loss: 0.6538, Acc: 0.6205, Val Loss: 0.5004, Val Acc: 0.8165
Epoch 54/100, Loss: 0.6538, Acc: 0.6198, Val Loss: 0.4969, Val Acc: 0.8235
Epoch 55/100, Loss: 0.6538, Acc: 0.6203, Val Loss: 0.4970, Val Acc: 0.8243
Epoch 56/100, Loss: 0.6537, Acc: 0.6191, Val Loss: 0.4956, Val Acc: 0.8254
Epoch 57/100, Loss: 0.6537, Acc: 0.6189, Val Loss: 0.5065, Val Acc: 0.8018
Epoch 58/100, Loss: 0.6536, Acc: 0.6202, Val Loss: 0.4937, Val Acc: 0.8283
Epoch 59/100, Loss: 0.6537, Acc: 0.6192, Val Loss: 0.5009, Val Acc: 0.8096
Epoch 60/100, Loss: 0.6536, Acc: 0.6189, Val Loss: 0.4947, Val Acc: 0.8257
Epoch 61/100, Loss: 0.6536, Acc: 0.6200, Val Loss: 0.4933, Val Acc: 0.8276
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6535, Acc: 0.6200, Val Loss: 0.4971, Val Acc: 0.8221
Epoch 63/100, Loss: 0.6535, Acc: 0.6210, Val Loss: 0.4961, Val Acc: 0.8239
Epoch 64/100, Loss: 0.6535, Acc: 0.6199, Val Loss: 0.4971, Val Acc: 0.8221
Epoch 65/100, Loss: 0.6535, Acc: 0.6205, Val Loss: 0.4973, Val Acc: 0.8210
Epoch 66/100, Loss: 0.6534, Acc: 0.6198, Val Loss: 0.4966, Val Acc: 0.8232
Epoch 67/100, Loss: 0.6535, Acc: 0.6192, Val Loss: 0.4981, Val Acc: 0.8202
Epoch 68/100, Loss: 0.6535, Acc: 0.6206, Val Loss: 0.4964, Val Acc: 0.8224
Epoch 69/100, Loss: 0.6534, Acc: 0.6207, Val Loss: 0.5042, Val Acc: 0.8033
Epoch 70/100, Loss: 0.6534, Acc: 0.6191, Val Loss: 0.4949, Val Acc: 0.8243
Epoch 71/100, Loss: 0.6534, Acc: 0.6210, Val Loss: 0.5003, Val Acc: 0.8132
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6533, Acc: 0.6189, Val Loss: 0.4983, Val Acc: 0.8195
Epoch 73/100, Loss: 0.6533, Acc: 0.6206, Val Loss: 0.4967, Val Acc: 0.8213
Epoch 74/100, Loss: 0.6533, Acc: 0.6210, Val Loss: 0.4984, Val Acc: 0.8195
Epoch 75/100, Loss: 0.6533, Acc: 0.6205, Val Loss: 0.4985, Val Acc: 0.8187
Epoch 76/100, Loss: 0.6533, Acc: 0.6205, Val Loss: 0.4984, Val Acc: 0.8187
Epoch 77/100, Loss: 0.6533, Acc: 0.6206, Val Loss: 0.4970, Val Acc: 0.8210
Epoch 78/100, Loss: 0.6533, Acc: 0.6199, Val Loss: 0.4952, Val Acc: 0.8239
Epoch 79/100, Loss: 0.6533, Acc: 0.6202, Val Loss: 0.4955, Val Acc: 0.8235
Epoch 80/100, Loss: 0.6533, Acc: 0.6199, Val Loss: 0.4972, Val Acc: 0.8206
Epoch 81/100, Loss: 0.6532, Acc: 0.6206, Val Loss: 0.4974, Val Acc: 0.8202
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6533, Acc: 0.6199, Val Loss: 0.4956, Val Acc: 0.8232
Epoch 83/100, Loss: 0.6532, Acc: 0.6214, Val Loss: 0.4972, Val Acc: 0.8202
Epoch 84/100, Loss: 0.6532, Acc: 0.6189, Val Loss: 0.4981, Val Acc: 0.8191
Epoch 85/100, Loss: 0.6532, Acc: 0.6194, Val Loss: 0.4991, Val Acc: 0.8147
Epoch 86/100, Loss: 0.6533, Acc: 0.6198, Val Loss: 0.4969, Val Acc: 0.8206
Epoch 87/100, Loss: 0.6532, Acc: 0.6211, Val Loss: 0.4975, Val Acc: 0.8199
Epoch 88/100, Loss: 0.6532, Acc: 0.6199, Val Loss: 0.4997, Val Acc: 0.8118
Epoch 89/100, Loss: 0.6532, Acc: 0.6199, Val Loss: 0.4958, Val Acc: 0.8221
Epoch 90/100, Loss: 0.6532, Acc: 0.6214, Val Loss: 0.4995, Val Acc: 0.8140
Epoch 91/100, Loss: 0.6532, Acc: 0.6194, Val Loss: 0.4983, Val Acc: 0.8173
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6531, Acc: 0.6211, Val Loss: 0.4979, Val Acc: 0.8195
Epoch 93/100, Loss: 0.6531, Acc: 0.6203, Val Loss: 0.4956, Val Acc: 0.8232
Epoch 94/100, Loss: 0.6531, Acc: 0.6200, Val Loss: 0.4970, Val Acc: 0.8199
Epoch 95/100, Loss: 0.6530, Acc: 0.6203, Val Loss: 0.4960, Val Acc: 0.8224
Epoch 96/100, Loss: 0.6529, Acc: 0.6220, Val Loss: 0.4983, Val Acc: 0.8191
Epoch 97/100, Loss: 0.6530, Acc: 0.6210, Val Loss: 0.4963, Val Acc: 0.8217
Epoch 98/100, Loss: 0.6530, Acc: 0.6208, Val Loss: 0.4967, Val Acc: 0.8202
Epoch 99/100, Loss: 0.6529, Acc: 0.6205, Val Loss: 0.4947, Val Acc: 0.8235
Epoch 100/100, Loss: 0.6529, Acc: 0.6207, Val Loss: 0.4965, Val Acc: 0.8210

##############################
Resultados para principal:  055  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1 
 {'training': [0.6529459087287679, 0.6206801470588236, 0.6049224868147675, 0.6957720588235294, 0.6471744891852612], 'validate': [0.49652927351552384, 0.8209558823529411, 0.9678456591639871, 0.6639705882352941, 0.7876144788486699], 'test': [0.5457988359310009, 0.793235294117647, 0.78965717606043, 0.7994117647058824, 0.794504530838936]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  045  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  045  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  045  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5597, Acc: 0.7676, Val Loss: 0.3714, Val Acc: 0.9213
Mejor modelo guardado con Val Loss: 0.3714
Epoch 2/100, Loss: 0.4711, Acc: 0.7923, Val Loss: 0.2950, Val Acc: 0.9195
Mejor modelo guardado con Val Loss: 0.2950
Epoch 3/100, Loss: 0.4477, Acc: 0.8017, Val Loss: 0.3108, Val Acc: 0.9110
Epoch 4/100, Loss: 0.4374, Acc: 0.7991, Val Loss: 0.2643, Val Acc: 0.9305
Mejor modelo guardado con Val Loss: 0.2643
Epoch 5/100, Loss: 0.4390, Acc: 0.7984, Val Loss: 0.2521, Val Acc: 0.9232
Mejor modelo guardado con Val Loss: 0.2521
Epoch 6/100, Loss: 0.4336, Acc: 0.8046, Val Loss: 0.2402, Val Acc: 0.9279
Mejor modelo guardado con Val Loss: 0.2402
Epoch 7/100, Loss: 0.4335, Acc: 0.7993, Val Loss: 0.2432, Val Acc: 0.9187
Epoch 8/100, Loss: 0.4296, Acc: 0.8013, Val Loss: 0.2466, Val Acc: 0.9232
Epoch 9/100, Loss: 0.4253, Acc: 0.8055, Val Loss: 0.2338, Val Acc: 0.9301
Mejor modelo guardado con Val Loss: 0.2338
Epoch 10/100, Loss: 0.4212, Acc: 0.8064, Val Loss: 0.2407, Val Acc: 0.9279
Epoch 11/100, Loss: 0.4250, Acc: 0.8073, Val Loss: 0.2521, Val Acc: 0.9279
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4231, Acc: 0.8051, Val Loss: 0.2363, Val Acc: 0.9305
Epoch 13/100, Loss: 0.4194, Acc: 0.8064, Val Loss: 0.2191, Val Acc: 0.9235
Mejor modelo guardado con Val Loss: 0.2191
Epoch 14/100, Loss: 0.4163, Acc: 0.8048, Val Loss: 0.2241, Val Acc: 0.9298
Epoch 15/100, Loss: 0.4175, Acc: 0.8061, Val Loss: 0.2255, Val Acc: 0.9158
Epoch 16/100, Loss: 0.4161, Acc: 0.8097, Val Loss: 0.2369, Val Acc: 0.9217
Epoch 17/100, Loss: 0.4171, Acc: 0.8105, Val Loss: 0.2249, Val Acc: 0.9261
Epoch 18/100, Loss: 0.4176, Acc: 0.8061, Val Loss: 0.2216, Val Acc: 0.9246
Epoch 19/100, Loss: 0.4161, Acc: 0.8093, Val Loss: 0.2302, Val Acc: 0.9184
Epoch 20/100, Loss: 0.4172, Acc: 0.8073, Val Loss: 0.2304, Val Acc: 0.9224
Epoch 21/100, Loss: 0.4159, Acc: 0.8065, Val Loss: 0.2262, Val Acc: 0.9268
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4084, Acc: 0.8128, Val Loss: 0.2231, Val Acc: 0.9210
Epoch 23/100, Loss: 0.4081, Acc: 0.8128, Val Loss: 0.2128, Val Acc: 0.9239
Mejor modelo guardado con Val Loss: 0.2128
Epoch 24/100, Loss: 0.4087, Acc: 0.8131, Val Loss: 0.2207, Val Acc: 0.9235
Epoch 25/100, Loss: 0.4064, Acc: 0.8147, Val Loss: 0.2140, Val Acc: 0.9261
Epoch 26/100, Loss: 0.4080, Acc: 0.8119, Val Loss: 0.2177, Val Acc: 0.9235
Epoch 27/100, Loss: 0.4074, Acc: 0.8135, Val Loss: 0.2213, Val Acc: 0.9239
Epoch 28/100, Loss: 0.4074, Acc: 0.8155, Val Loss: 0.2184, Val Acc: 0.9261
Epoch 29/100, Loss: 0.4063, Acc: 0.8131, Val Loss: 0.2196, Val Acc: 0.9221
Epoch 30/100, Loss: 0.4075, Acc: 0.8142, Val Loss: 0.2403, Val Acc: 0.9257
Epoch 31/100, Loss: 0.4052, Acc: 0.8148, Val Loss: 0.2192, Val Acc: 0.9250
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4044, Acc: 0.8187, Val Loss: 0.2202, Val Acc: 0.9246
Epoch 33/100, Loss: 0.4031, Acc: 0.8178, Val Loss: 0.2183, Val Acc: 0.9272
Epoch 34/100, Loss: 0.4022, Acc: 0.8195, Val Loss: 0.2258, Val Acc: 0.9250
Epoch 35/100, Loss: 0.4025, Acc: 0.8176, Val Loss: 0.2211, Val Acc: 0.9243
Epoch 36/100, Loss: 0.4019, Acc: 0.8174, Val Loss: 0.2221, Val Acc: 0.9232
Epoch 37/100, Loss: 0.4014, Acc: 0.8168, Val Loss: 0.2164, Val Acc: 0.9279
Epoch 38/100, Loss: 0.4013, Acc: 0.8190, Val Loss: 0.2129, Val Acc: 0.9265
Epoch 39/100, Loss: 0.4005, Acc: 0.8185, Val Loss: 0.2202, Val Acc: 0.9254
Epoch 40/100, Loss: 0.4006, Acc: 0.8178, Val Loss: 0.2112, Val Acc: 0.9272
Mejor modelo guardado con Val Loss: 0.2112
Epoch 41/100, Loss: 0.4007, Acc: 0.8187, Val Loss: 0.2148, Val Acc: 0.9246
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3994, Acc: 0.8211, Val Loss: 0.2146, Val Acc: 0.9265
Epoch 43/100, Loss: 0.3993, Acc: 0.8197, Val Loss: 0.2169, Val Acc: 0.9276
Epoch 44/100, Loss: 0.3987, Acc: 0.8199, Val Loss: 0.2164, Val Acc: 0.9235
Epoch 45/100, Loss: 0.3985, Acc: 0.8190, Val Loss: 0.2181, Val Acc: 0.9290
Epoch 46/100, Loss: 0.3987, Acc: 0.8201, Val Loss: 0.2155, Val Acc: 0.9250
Epoch 47/100, Loss: 0.3985, Acc: 0.8190, Val Loss: 0.2121, Val Acc: 0.9250
Epoch 48/100, Loss: 0.3983, Acc: 0.8208, Val Loss: 0.2215, Val Acc: 0.9232
Epoch 49/100, Loss: 0.3979, Acc: 0.8199, Val Loss: 0.2166, Val Acc: 0.9228
Epoch 50/100, Loss: 0.3983, Acc: 0.8213, Val Loss: 0.2062, Val Acc: 0.9257
Mejor modelo guardado con Val Loss: 0.2062
Epoch 51/100, Loss: 0.3981, Acc: 0.8214, Val Loss: 0.2106, Val Acc: 0.9265
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3969, Acc: 0.8214, Val Loss: 0.2131, Val Acc: 0.9246
Epoch 53/100, Loss: 0.3971, Acc: 0.8209, Val Loss: 0.2149, Val Acc: 0.9239
Epoch 54/100, Loss: 0.3971, Acc: 0.8203, Val Loss: 0.2131, Val Acc: 0.9265
Epoch 55/100, Loss: 0.3968, Acc: 0.8213, Val Loss: 0.2108, Val Acc: 0.9268
Epoch 56/100, Loss: 0.3971, Acc: 0.8214, Val Loss: 0.2143, Val Acc: 0.9243
Epoch 57/100, Loss: 0.3967, Acc: 0.8222, Val Loss: 0.2126, Val Acc: 0.9268
Epoch 58/100, Loss: 0.3968, Acc: 0.8222, Val Loss: 0.2137, Val Acc: 0.9261
Epoch 59/100, Loss: 0.3968, Acc: 0.8230, Val Loss: 0.2124, Val Acc: 0.9272
Epoch 60/100, Loss: 0.3967, Acc: 0.8209, Val Loss: 0.2147, Val Acc: 0.9261
Epoch 61/100, Loss: 0.3962, Acc: 0.8222, Val Loss: 0.2119, Val Acc: 0.9272
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3963, Acc: 0.8212, Val Loss: 0.2127, Val Acc: 0.9276
Epoch 63/100, Loss: 0.3963, Acc: 0.8225, Val Loss: 0.2136, Val Acc: 0.9254
Epoch 64/100, Loss: 0.3960, Acc: 0.8206, Val Loss: 0.2131, Val Acc: 0.9276
Epoch 65/100, Loss: 0.3960, Acc: 0.8226, Val Loss: 0.2137, Val Acc: 0.9239
Epoch 66/100, Loss: 0.3960, Acc: 0.8221, Val Loss: 0.2129, Val Acc: 0.9246
Epoch 67/100, Loss: 0.3960, Acc: 0.8222, Val Loss: 0.2123, Val Acc: 0.9265
Epoch 68/100, Loss: 0.3959, Acc: 0.8215, Val Loss: 0.2127, Val Acc: 0.9243
Epoch 69/100, Loss: 0.3959, Acc: 0.8212, Val Loss: 0.2142, Val Acc: 0.9279
Epoch 70/100, Loss: 0.3959, Acc: 0.8221, Val Loss: 0.2119, Val Acc: 0.9261
Epoch 71/100, Loss: 0.3958, Acc: 0.8223, Val Loss: 0.2134, Val Acc: 0.9246
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3957, Acc: 0.8223, Val Loss: 0.2126, Val Acc: 0.9250
Epoch 73/100, Loss: 0.3956, Acc: 0.8226, Val Loss: 0.2126, Val Acc: 0.9261
Epoch 74/100, Loss: 0.3956, Acc: 0.8224, Val Loss: 0.2128, Val Acc: 0.9254
Epoch 75/100, Loss: 0.3955, Acc: 0.8224, Val Loss: 0.2134, Val Acc: 0.9254
Epoch 76/100, Loss: 0.3955, Acc: 0.8221, Val Loss: 0.2125, Val Acc: 0.9261
Epoch 77/100, Loss: 0.3953, Acc: 0.8221, Val Loss: 0.2124, Val Acc: 0.9261
Epoch 78/100, Loss: 0.3952, Acc: 0.8223, Val Loss: 0.2125, Val Acc: 0.9265
Epoch 79/100, Loss: 0.3952, Acc: 0.8216, Val Loss: 0.2128, Val Acc: 0.9261
Epoch 80/100, Loss: 0.3952, Acc: 0.8223, Val Loss: 0.2122, Val Acc: 0.9261
Epoch 81/100, Loss: 0.3952, Acc: 0.8218, Val Loss: 0.2129, Val Acc: 0.9257
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3952, Acc: 0.8217, Val Loss: 0.2123, Val Acc: 0.9261
Epoch 83/100, Loss: 0.3951, Acc: 0.8220, Val Loss: 0.2128, Val Acc: 0.9257
Epoch 84/100, Loss: 0.3951, Acc: 0.8221, Val Loss: 0.2121, Val Acc: 0.9265
Epoch 85/100, Loss: 0.3952, Acc: 0.8223, Val Loss: 0.2135, Val Acc: 0.9265
Epoch 86/100, Loss: 0.3951, Acc: 0.8222, Val Loss: 0.2131, Val Acc: 0.9265
Epoch 87/100, Loss: 0.3951, Acc: 0.8216, Val Loss: 0.2124, Val Acc: 0.9265
Epoch 88/100, Loss: 0.3949, Acc: 0.8225, Val Loss: 0.2133, Val Acc: 0.9246
Epoch 89/100, Loss: 0.3951, Acc: 0.8202, Val Loss: 0.2129, Val Acc: 0.9261
Epoch 90/100, Loss: 0.3950, Acc: 0.8224, Val Loss: 0.2129, Val Acc: 0.9265
Epoch 91/100, Loss: 0.3951, Acc: 0.8229, Val Loss: 0.2118, Val Acc: 0.9261
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3949, Acc: 0.8209, Val Loss: 0.2126, Val Acc: 0.9272
Epoch 93/100, Loss: 0.3950, Acc: 0.8223, Val Loss: 0.2128, Val Acc: 0.9261
Epoch 94/100, Loss: 0.3950, Acc: 0.8231, Val Loss: 0.2126, Val Acc: 0.9261
Epoch 95/100, Loss: 0.3950, Acc: 0.8216, Val Loss: 0.2126, Val Acc: 0.9257
Epoch 96/100, Loss: 0.3949, Acc: 0.8222, Val Loss: 0.2131, Val Acc: 0.9250
Epoch 97/100, Loss: 0.3949, Acc: 0.8218, Val Loss: 0.2131, Val Acc: 0.9261
Epoch 98/100, Loss: 0.3949, Acc: 0.8222, Val Loss: 0.2129, Val Acc: 0.9254
Epoch 99/100, Loss: 0.3949, Acc: 0.8219, Val Loss: 0.2120, Val Acc: 0.9261
Epoch 100/100, Loss: 0.3948, Acc: 0.8223, Val Loss: 0.2123, Val Acc: 0.9265

##############################
Resultados para principal:  045  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1 
 {'training': [0.3948373755987953, 0.8223345588235295, 0.8485390578413834, 0.7847426470588236, 0.8153949002005539], 'validate': [0.21233289268647515, 0.9264705882352942, 0.941400304414003, 0.9095588235294118, 0.925205684367988], 'test': [1.3402379998178393, 0.4461764705882353, 0.46524876566654005, 0.7205882352941176, 0.5654281098546042]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  022  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  022  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  022  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6339, Acc: 0.6825, Val Loss: 0.4550, Val Acc: 0.9169
Mejor modelo guardado con Val Loss: 0.4550
Epoch 2/100, Loss: 0.5713, Acc: 0.7296, Val Loss: 0.3751, Val Acc: 0.9382
Mejor modelo guardado con Val Loss: 0.3751
Epoch 3/100, Loss: 0.5465, Acc: 0.7330, Val Loss: 0.3322, Val Acc: 0.9265
Mejor modelo guardado con Val Loss: 0.3322
Epoch 4/100, Loss: 0.5351, Acc: 0.7426, Val Loss: 0.3267, Val Acc: 0.8978
Mejor modelo guardado con Val Loss: 0.3267
Epoch 5/100, Loss: 0.5413, Acc: 0.7291, Val Loss: 0.3262, Val Acc: 0.9298
Mejor modelo guardado con Val Loss: 0.3262
Epoch 6/100, Loss: 0.5326, Acc: 0.7350, Val Loss: 0.2985, Val Acc: 0.9371
Mejor modelo guardado con Val Loss: 0.2985
Epoch 7/100, Loss: 0.5301, Acc: 0.7386, Val Loss: 0.3087, Val Acc: 0.9346
Epoch 8/100, Loss: 0.5349, Acc: 0.7366, Val Loss: 0.3306, Val Acc: 0.9265
Epoch 9/100, Loss: 0.5252, Acc: 0.7445, Val Loss: 0.3442, Val Acc: 0.9353
Epoch 10/100, Loss: 0.5255, Acc: 0.7423, Val Loss: 0.3091, Val Acc: 0.9309
Epoch 11/100, Loss: 0.5227, Acc: 0.7482, Val Loss: 0.2730, Val Acc: 0.9279
Mejor modelo guardado con Val Loss: 0.2730
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5175, Acc: 0.7440, Val Loss: 0.2836, Val Acc: 0.9257
Epoch 13/100, Loss: 0.5137, Acc: 0.7487, Val Loss: 0.2353, Val Acc: 0.9379
Mejor modelo guardado con Val Loss: 0.2353
Epoch 14/100, Loss: 0.5138, Acc: 0.7478, Val Loss: 0.2387, Val Acc: 0.9364
Epoch 15/100, Loss: 0.5138, Acc: 0.7470, Val Loss: 0.2738, Val Acc: 0.9235
Epoch 16/100, Loss: 0.5116, Acc: 0.7515, Val Loss: 0.2600, Val Acc: 0.9279
Epoch 17/100, Loss: 0.5111, Acc: 0.7485, Val Loss: 0.2786, Val Acc: 0.9257
Epoch 18/100, Loss: 0.5112, Acc: 0.7530, Val Loss: 0.2628, Val Acc: 0.9140
Epoch 19/100, Loss: 0.5140, Acc: 0.7517, Val Loss: 0.2666, Val Acc: 0.9338
Epoch 20/100, Loss: 0.5130, Acc: 0.7485, Val Loss: 0.2477, Val Acc: 0.9298
Epoch 21/100, Loss: 0.5119, Acc: 0.7486, Val Loss: 0.2595, Val Acc: 0.9316
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5088, Acc: 0.7488, Val Loss: 0.2371, Val Acc: 0.9360
Epoch 23/100, Loss: 0.5069, Acc: 0.7540, Val Loss: 0.2442, Val Acc: 0.9313
Epoch 24/100, Loss: 0.5051, Acc: 0.7538, Val Loss: 0.2507, Val Acc: 0.9316
Epoch 25/100, Loss: 0.5061, Acc: 0.7546, Val Loss: 0.2388, Val Acc: 0.9316
Epoch 26/100, Loss: 0.5064, Acc: 0.7528, Val Loss: 0.2260, Val Acc: 0.9360
Mejor modelo guardado con Val Loss: 0.2260
Epoch 27/100, Loss: 0.5079, Acc: 0.7520, Val Loss: 0.2503, Val Acc: 0.9313
Epoch 28/100, Loss: 0.5049, Acc: 0.7517, Val Loss: 0.2478, Val Acc: 0.9243
Epoch 29/100, Loss: 0.5070, Acc: 0.7513, Val Loss: 0.2477, Val Acc: 0.9368
Epoch 30/100, Loss: 0.5045, Acc: 0.7535, Val Loss: 0.2519, Val Acc: 0.9324
Epoch 31/100, Loss: 0.5065, Acc: 0.7504, Val Loss: 0.2507, Val Acc: 0.9309
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5037, Acc: 0.7556, Val Loss: 0.2367, Val Acc: 0.9331
Epoch 33/100, Loss: 0.5025, Acc: 0.7558, Val Loss: 0.2427, Val Acc: 0.9279
Epoch 34/100, Loss: 0.5027, Acc: 0.7568, Val Loss: 0.2402, Val Acc: 0.9294
Epoch 35/100, Loss: 0.5025, Acc: 0.7564, Val Loss: 0.2459, Val Acc: 0.9298
Epoch 36/100, Loss: 0.5022, Acc: 0.7574, Val Loss: 0.2276, Val Acc: 0.9357
Epoch 37/100, Loss: 0.5014, Acc: 0.7578, Val Loss: 0.2430, Val Acc: 0.9254
Epoch 38/100, Loss: 0.5015, Acc: 0.7574, Val Loss: 0.2499, Val Acc: 0.9316
Epoch 39/100, Loss: 0.5014, Acc: 0.7594, Val Loss: 0.2356, Val Acc: 0.9320
Epoch 40/100, Loss: 0.5015, Acc: 0.7566, Val Loss: 0.2424, Val Acc: 0.9298
Epoch 41/100, Loss: 0.5011, Acc: 0.7571, Val Loss: 0.2310, Val Acc: 0.9305
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4998, Acc: 0.7581, Val Loss: 0.2301, Val Acc: 0.9298
Epoch 43/100, Loss: 0.4995, Acc: 0.7595, Val Loss: 0.2336, Val Acc: 0.9290
Epoch 44/100, Loss: 0.5001, Acc: 0.7587, Val Loss: 0.2336, Val Acc: 0.9327
Epoch 45/100, Loss: 0.4995, Acc: 0.7591, Val Loss: 0.2382, Val Acc: 0.9287
Epoch 46/100, Loss: 0.4993, Acc: 0.7597, Val Loss: 0.2390, Val Acc: 0.9309
Epoch 47/100, Loss: 0.4995, Acc: 0.7585, Val Loss: 0.2349, Val Acc: 0.9301
Epoch 48/100, Loss: 0.4996, Acc: 0.7600, Val Loss: 0.2368, Val Acc: 0.9294
Epoch 49/100, Loss: 0.4995, Acc: 0.7577, Val Loss: 0.2302, Val Acc: 0.9305
Epoch 50/100, Loss: 0.4993, Acc: 0.7602, Val Loss: 0.2379, Val Acc: 0.9313
Epoch 51/100, Loss: 0.4989, Acc: 0.7598, Val Loss: 0.2341, Val Acc: 0.9290
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4982, Acc: 0.7591, Val Loss: 0.2352, Val Acc: 0.9301
Epoch 53/100, Loss: 0.4981, Acc: 0.7595, Val Loss: 0.2412, Val Acc: 0.9298
Epoch 54/100, Loss: 0.4983, Acc: 0.7600, Val Loss: 0.2321, Val Acc: 0.9305
Epoch 55/100, Loss: 0.4983, Acc: 0.7607, Val Loss: 0.2341, Val Acc: 0.9309
Epoch 56/100, Loss: 0.4979, Acc: 0.7593, Val Loss: 0.2341, Val Acc: 0.9313
Epoch 57/100, Loss: 0.4980, Acc: 0.7605, Val Loss: 0.2314, Val Acc: 0.9301
Epoch 58/100, Loss: 0.4979, Acc: 0.7607, Val Loss: 0.2389, Val Acc: 0.9301
Epoch 59/100, Loss: 0.4979, Acc: 0.7608, Val Loss: 0.2373, Val Acc: 0.9309
Epoch 60/100, Loss: 0.4979, Acc: 0.7594, Val Loss: 0.2324, Val Acc: 0.9316
Epoch 61/100, Loss: 0.4975, Acc: 0.7605, Val Loss: 0.2340, Val Acc: 0.9316
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4976, Acc: 0.7610, Val Loss: 0.2327, Val Acc: 0.9313
Epoch 63/100, Loss: 0.4974, Acc: 0.7602, Val Loss: 0.2348, Val Acc: 0.9309
Epoch 64/100, Loss: 0.4974, Acc: 0.7599, Val Loss: 0.2343, Val Acc: 0.9298
Epoch 65/100, Loss: 0.4973, Acc: 0.7591, Val Loss: 0.2326, Val Acc: 0.9301
Epoch 66/100, Loss: 0.4972, Acc: 0.7604, Val Loss: 0.2341, Val Acc: 0.9301
Epoch 67/100, Loss: 0.4972, Acc: 0.7610, Val Loss: 0.2336, Val Acc: 0.9313
Epoch 68/100, Loss: 0.4974, Acc: 0.7594, Val Loss: 0.2325, Val Acc: 0.9309
Epoch 69/100, Loss: 0.4973, Acc: 0.7599, Val Loss: 0.2346, Val Acc: 0.9305
Epoch 70/100, Loss: 0.4972, Acc: 0.7621, Val Loss: 0.2351, Val Acc: 0.9309
Epoch 71/100, Loss: 0.4971, Acc: 0.7608, Val Loss: 0.2364, Val Acc: 0.9305
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4970, Acc: 0.7608, Val Loss: 0.2340, Val Acc: 0.9316
Epoch 73/100, Loss: 0.4970, Acc: 0.7609, Val Loss: 0.2337, Val Acc: 0.9313
Epoch 74/100, Loss: 0.4971, Acc: 0.7608, Val Loss: 0.2339, Val Acc: 0.9309
Epoch 75/100, Loss: 0.4969, Acc: 0.7613, Val Loss: 0.2343, Val Acc: 0.9301
Epoch 76/100, Loss: 0.4969, Acc: 0.7609, Val Loss: 0.2339, Val Acc: 0.9316
Epoch 77/100, Loss: 0.4969, Acc: 0.7597, Val Loss: 0.2340, Val Acc: 0.9305
Epoch 78/100, Loss: 0.4969, Acc: 0.7608, Val Loss: 0.2337, Val Acc: 0.9313
Epoch 79/100, Loss: 0.4968, Acc: 0.7612, Val Loss: 0.2331, Val Acc: 0.9316
Epoch 80/100, Loss: 0.4969, Acc: 0.7598, Val Loss: 0.2328, Val Acc: 0.9305
Epoch 81/100, Loss: 0.4968, Acc: 0.7608, Val Loss: 0.2328, Val Acc: 0.9309
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4968, Acc: 0.7609, Val Loss: 0.2334, Val Acc: 0.9294
Epoch 83/100, Loss: 0.4968, Acc: 0.7612, Val Loss: 0.2334, Val Acc: 0.9305
Epoch 84/100, Loss: 0.4969, Acc: 0.7609, Val Loss: 0.2335, Val Acc: 0.9305
Epoch 85/100, Loss: 0.4968, Acc: 0.7610, Val Loss: 0.2334, Val Acc: 0.9316
Epoch 86/100, Loss: 0.4968, Acc: 0.7606, Val Loss: 0.2323, Val Acc: 0.9301
Epoch 87/100, Loss: 0.4967, Acc: 0.7619, Val Loss: 0.2336, Val Acc: 0.9320
Epoch 88/100, Loss: 0.4968, Acc: 0.7610, Val Loss: 0.2336, Val Acc: 0.9313
Epoch 89/100, Loss: 0.4967, Acc: 0.7600, Val Loss: 0.2343, Val Acc: 0.9305
Epoch 90/100, Loss: 0.4968, Acc: 0.7609, Val Loss: 0.2327, Val Acc: 0.9313
Epoch 91/100, Loss: 0.4967, Acc: 0.7598, Val Loss: 0.2344, Val Acc: 0.9305
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4967, Acc: 0.7605, Val Loss: 0.2322, Val Acc: 0.9309
Epoch 93/100, Loss: 0.4967, Acc: 0.7608, Val Loss: 0.2332, Val Acc: 0.9305
Epoch 94/100, Loss: 0.4967, Acc: 0.7608, Val Loss: 0.2343, Val Acc: 0.9305
Epoch 95/100, Loss: 0.4967, Acc: 0.7602, Val Loss: 0.2330, Val Acc: 0.9309
Epoch 96/100, Loss: 0.4967, Acc: 0.7603, Val Loss: 0.2330, Val Acc: 0.9301
Epoch 97/100, Loss: 0.4967, Acc: 0.7608, Val Loss: 0.2332, Val Acc: 0.9301
Epoch 98/100, Loss: 0.4966, Acc: 0.7605, Val Loss: 0.2334, Val Acc: 0.9309
Epoch 99/100, Loss: 0.4968, Acc: 0.7605, Val Loss: 0.2342, Val Acc: 0.9305
Epoch 100/100, Loss: 0.4966, Acc: 0.7602, Val Loss: 0.2336, Val Acc: 0.9309

##############################
Resultados para principal:  022  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  1 
 {'training': [0.4966065399787005, 0.760202205882353, 0.7925191155197355, 0.7049632352941176, 0.7461815351687907], 'validate': [0.23361847151157467, 0.9308823529411765, 0.9334319526627219, 0.9279411764705883, 0.9306784660766961], 'test': [1.3051249172400545, 0.3688235294117647, 0.3934034416826004, 0.48411764705882354, 0.4340717299578059]}

##############################
Resultados para window:  1 
 {'104:093:088:055:045:022': {'training': [0.6900769812219283, 0.5476102941176471, 0.5465659834591874, 0.5588235294117647, 0.5526267951281585], 'validate': [0.6854562537614689, 0.6143382352941177, 0.6288318144159072, 0.5580882352941177, 0.5913517724970783], 'test': [0.6796457138326433, 0.5, 0.0, 0.0, 0.0]}, '093:104:088:055:045:022': {'training': [0.601217349136577, 0.6882352941176471, 0.663317384370016, 0.7645220588235294, 0.7103330486763451], 'validate': [0.9267875545246657, 0.3790441176470588, 0.42724458204334365, 0.7102941176470589, 0.5335542667771334], 'test': [0.7314841537563889, 0.47705882352941176, 0.4875239923224568, 0.8964705882352941, 0.631578947368421]}, '088:104:093:055:045:022': {'training': [0.6571336819845087, 0.5645220588235295, 0.5352834740651388, 0.9788602941176471, 0.6920977384975305], 'validate': [0.5494790929694509, 0.7558823529411764, 0.6827731092436975, 0.9558823529411765, 0.7965686274509803], 'test': [0.5106303062703874, 0.8473529411764706, 0.7770999530736743, 0.9741176470588235, 0.8645262333594361]}, '055:104:093:088:045:022': {'training': [0.6529459087287679, 0.6206801470588236, 0.6049224868147675, 0.6957720588235294, 0.6471744891852612], 'validate': [0.49652927351552384, 0.8209558823529411, 0.9678456591639871, 0.6639705882352941, 0.7876144788486699], 'test': [0.5457988359310009, 0.793235294117647, 0.78965717606043, 0.7994117647058824, 0.794504530838936]}, '045:104:093:088:055:022': {'training': [0.3948373755987953, 0.8223345588235295, 0.8485390578413834, 0.7847426470588236, 0.8153949002005539], 'validate': [0.21233289268647515, 0.9264705882352942, 0.941400304414003, 0.9095588235294118, 0.925205684367988], 'test': [1.3402379998178393, 0.4461764705882353, 0.46524876566654005, 0.7205882352941176, 0.5654281098546042]}, '022:104:093:088:055:045': {'training': [0.4966065399787005, 0.760202205882353, 0.7925191155197355, 0.7049632352941176, 0.7461815351687907], 'validate': [0.23361847151157467, 0.9308823529411765, 0.9334319526627219, 0.9279411764705883, 0.9306784660766961], 'test': [1.3051249172400545, 0.3688235294117647, 0.3934034416826004, 0.48411764705882354, 0.4340717299578059]}}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  062  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  062  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  062  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4833, Acc: 0.8443, Val Loss: 0.6661, Val Acc: 0.6305
Mejor modelo guardado con Val Loss: 0.6661
Epoch 2/100, Loss: 0.3591, Acc: 0.8576, Val Loss: 0.6701, Val Acc: 0.6570
Epoch 3/100, Loss: 0.3320, Acc: 0.8639, Val Loss: 0.6392, Val Acc: 0.6768
Mejor modelo guardado con Val Loss: 0.6392
Epoch 4/100, Loss: 0.3283, Acc: 0.8631, Val Loss: 0.7126, Val Acc: 0.6438
Epoch 5/100, Loss: 0.3205, Acc: 0.8658, Val Loss: 0.7243, Val Acc: 0.6555
Epoch 6/100, Loss: 0.3241, Acc: 0.8663, Val Loss: 0.6569, Val Acc: 0.6761
Epoch 7/100, Loss: 0.3227, Acc: 0.8659, Val Loss: 0.7392, Val Acc: 0.6353
Epoch 8/100, Loss: 0.3210, Acc: 0.8642, Val Loss: 0.6771, Val Acc: 0.6574
Epoch 9/100, Loss: 0.3169, Acc: 0.8671, Val Loss: 0.6745, Val Acc: 0.6544
Epoch 10/100, Loss: 0.3129, Acc: 0.8710, Val Loss: 0.7104, Val Acc: 0.6614
Epoch 11/100, Loss: 0.3173, Acc: 0.8672, Val Loss: 0.6764, Val Acc: 0.6504
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3107, Acc: 0.8706, Val Loss: 0.6964, Val Acc: 0.6507
Epoch 13/100, Loss: 0.3137, Acc: 0.8673, Val Loss: 0.7123, Val Acc: 0.6665
Epoch 14/100, Loss: 0.3109, Acc: 0.8685, Val Loss: 0.7134, Val Acc: 0.6574
Epoch 15/100, Loss: 0.3103, Acc: 0.8677, Val Loss: 0.6992, Val Acc: 0.6673
Epoch 16/100, Loss: 0.3086, Acc: 0.8719, Val Loss: 0.7237, Val Acc: 0.6629
Epoch 17/100, Loss: 0.3075, Acc: 0.8701, Val Loss: 0.7203, Val Acc: 0.6548
Epoch 18/100, Loss: 0.3073, Acc: 0.8694, Val Loss: 0.7514, Val Acc: 0.6544
Epoch 19/100, Loss: 0.3072, Acc: 0.8711, Val Loss: 0.7646, Val Acc: 0.6482
Epoch 20/100, Loss: 0.3075, Acc: 0.8716, Val Loss: 0.7068, Val Acc: 0.6684
Epoch 21/100, Loss: 0.3076, Acc: 0.8679, Val Loss: 0.7225, Val Acc: 0.6438
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3030, Acc: 0.8741, Val Loss: 0.7366, Val Acc: 0.6467
Epoch 23/100, Loss: 0.3030, Acc: 0.8726, Val Loss: 0.7407, Val Acc: 0.6540
Epoch 24/100, Loss: 0.3034, Acc: 0.8716, Val Loss: 0.7560, Val Acc: 0.6522
Epoch 25/100, Loss: 0.3034, Acc: 0.8721, Val Loss: 0.7382, Val Acc: 0.6581
Epoch 26/100, Loss: 0.3014, Acc: 0.8725, Val Loss: 0.7376, Val Acc: 0.6540
Epoch 27/100, Loss: 0.3000, Acc: 0.8751, Val Loss: 0.7558, Val Acc: 0.6548
Epoch 28/100, Loss: 0.3005, Acc: 0.8731, Val Loss: 0.7891, Val Acc: 0.6489
Epoch 29/100, Loss: 0.3034, Acc: 0.8715, Val Loss: 0.7500, Val Acc: 0.6551
Epoch 30/100, Loss: 0.2999, Acc: 0.8757, Val Loss: 0.7506, Val Acc: 0.6551
Epoch 31/100, Loss: 0.2994, Acc: 0.8740, Val Loss: 0.7552, Val Acc: 0.6540
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2987, Acc: 0.8756, Val Loss: 0.7973, Val Acc: 0.6493
Epoch 33/100, Loss: 0.2989, Acc: 0.8747, Val Loss: 0.7550, Val Acc: 0.6603
Epoch 34/100, Loss: 0.2979, Acc: 0.8750, Val Loss: 0.7763, Val Acc: 0.6596
Epoch 35/100, Loss: 0.2988, Acc: 0.8758, Val Loss: 0.7062, Val Acc: 0.6706
Epoch 36/100, Loss: 0.2972, Acc: 0.8756, Val Loss: 0.7556, Val Acc: 0.6621
Epoch 37/100, Loss: 0.2974, Acc: 0.8758, Val Loss: 0.7538, Val Acc: 0.6625
Epoch 38/100, Loss: 0.2967, Acc: 0.8748, Val Loss: 0.7536, Val Acc: 0.6570
Epoch 39/100, Loss: 0.2964, Acc: 0.8756, Val Loss: 0.7549, Val Acc: 0.6551
Epoch 40/100, Loss: 0.2966, Acc: 0.8758, Val Loss: 0.8019, Val Acc: 0.6463
Epoch 41/100, Loss: 0.2960, Acc: 0.8774, Val Loss: 0.7379, Val Acc: 0.6610
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2947, Acc: 0.8761, Val Loss: 0.7500, Val Acc: 0.6449
Epoch 43/100, Loss: 0.2947, Acc: 0.8769, Val Loss: 0.7418, Val Acc: 0.6585
Epoch 44/100, Loss: 0.2945, Acc: 0.8775, Val Loss: 0.7778, Val Acc: 0.6526
Epoch 45/100, Loss: 0.2950, Acc: 0.8757, Val Loss: 0.7540, Val Acc: 0.6548
Epoch 46/100, Loss: 0.2944, Acc: 0.8787, Val Loss: 0.7336, Val Acc: 0.6618
Epoch 47/100, Loss: 0.2943, Acc: 0.8761, Val Loss: 0.7607, Val Acc: 0.6548
Epoch 48/100, Loss: 0.2944, Acc: 0.8774, Val Loss: 0.7619, Val Acc: 0.6452
Epoch 49/100, Loss: 0.2945, Acc: 0.8769, Val Loss: 0.7694, Val Acc: 0.6493
Epoch 50/100, Loss: 0.2943, Acc: 0.8769, Val Loss: 0.7400, Val Acc: 0.6610
Epoch 51/100, Loss: 0.2941, Acc: 0.8757, Val Loss: 0.7592, Val Acc: 0.6526
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2934, Acc: 0.8781, Val Loss: 0.7621, Val Acc: 0.6493
Epoch 53/100, Loss: 0.2934, Acc: 0.8781, Val Loss: 0.7479, Val Acc: 0.6574
Epoch 54/100, Loss: 0.2934, Acc: 0.8778, Val Loss: 0.7509, Val Acc: 0.6566
Epoch 55/100, Loss: 0.2931, Acc: 0.8767, Val Loss: 0.7509, Val Acc: 0.6625
Epoch 56/100, Loss: 0.2934, Acc: 0.8778, Val Loss: 0.7383, Val Acc: 0.6625
Epoch 57/100, Loss: 0.2929, Acc: 0.8772, Val Loss: 0.7584, Val Acc: 0.6577
Epoch 58/100, Loss: 0.2930, Acc: 0.8769, Val Loss: 0.7600, Val Acc: 0.6485
Epoch 59/100, Loss: 0.2933, Acc: 0.8769, Val Loss: 0.7646, Val Acc: 0.6485
Epoch 60/100, Loss: 0.2929, Acc: 0.8781, Val Loss: 0.7448, Val Acc: 0.6607
Epoch 61/100, Loss: 0.2927, Acc: 0.8770, Val Loss: 0.7334, Val Acc: 0.6621
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2924, Acc: 0.8785, Val Loss: 0.7480, Val Acc: 0.6581
Epoch 63/100, Loss: 0.2925, Acc: 0.8779, Val Loss: 0.7494, Val Acc: 0.6529
Epoch 64/100, Loss: 0.2924, Acc: 0.8774, Val Loss: 0.7557, Val Acc: 0.6533
Epoch 65/100, Loss: 0.2925, Acc: 0.8766, Val Loss: 0.7500, Val Acc: 0.6570
Epoch 66/100, Loss: 0.2925, Acc: 0.8781, Val Loss: 0.7562, Val Acc: 0.6581
Epoch 67/100, Loss: 0.2924, Acc: 0.8776, Val Loss: 0.7541, Val Acc: 0.6526
Epoch 68/100, Loss: 0.2922, Acc: 0.8777, Val Loss: 0.7449, Val Acc: 0.6577
Epoch 69/100, Loss: 0.2923, Acc: 0.8780, Val Loss: 0.7539, Val Acc: 0.6592
Epoch 70/100, Loss: 0.2924, Acc: 0.8787, Val Loss: 0.7503, Val Acc: 0.6581
Epoch 71/100, Loss: 0.2923, Acc: 0.8781, Val Loss: 0.7522, Val Acc: 0.6544
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2921, Acc: 0.8781, Val Loss: 0.7538, Val Acc: 0.6533
Epoch 73/100, Loss: 0.2920, Acc: 0.8781, Val Loss: 0.7469, Val Acc: 0.6585
Epoch 74/100, Loss: 0.2921, Acc: 0.8789, Val Loss: 0.7571, Val Acc: 0.6522
Epoch 75/100, Loss: 0.2920, Acc: 0.8779, Val Loss: 0.7597, Val Acc: 0.6518
Epoch 76/100, Loss: 0.2919, Acc: 0.8784, Val Loss: 0.7556, Val Acc: 0.6537
Epoch 77/100, Loss: 0.2920, Acc: 0.8784, Val Loss: 0.7507, Val Acc: 0.6570
Epoch 78/100, Loss: 0.2920, Acc: 0.8786, Val Loss: 0.7549, Val Acc: 0.6544
Epoch 79/100, Loss: 0.2919, Acc: 0.8784, Val Loss: 0.7502, Val Acc: 0.6551
Epoch 80/100, Loss: 0.2920, Acc: 0.8788, Val Loss: 0.7576, Val Acc: 0.6515
Epoch 81/100, Loss: 0.2920, Acc: 0.8782, Val Loss: 0.7570, Val Acc: 0.6515
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2919, Acc: 0.8779, Val Loss: 0.7595, Val Acc: 0.6511
Epoch 83/100, Loss: 0.2921, Acc: 0.8780, Val Loss: 0.7556, Val Acc: 0.6540
Epoch 84/100, Loss: 0.2919, Acc: 0.8782, Val Loss: 0.7584, Val Acc: 0.6518
Epoch 85/100, Loss: 0.2919, Acc: 0.8778, Val Loss: 0.7562, Val Acc: 0.6537
Epoch 86/100, Loss: 0.2919, Acc: 0.8785, Val Loss: 0.7542, Val Acc: 0.6540
Epoch 87/100, Loss: 0.2919, Acc: 0.8784, Val Loss: 0.7580, Val Acc: 0.6548
Epoch 88/100, Loss: 0.2918, Acc: 0.8778, Val Loss: 0.7599, Val Acc: 0.6511
Epoch 89/100, Loss: 0.2918, Acc: 0.8784, Val Loss: 0.7529, Val Acc: 0.6566
Epoch 90/100, Loss: 0.2918, Acc: 0.8781, Val Loss: 0.7545, Val Acc: 0.6540
Epoch 91/100, Loss: 0.2918, Acc: 0.8777, Val Loss: 0.7594, Val Acc: 0.6515
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2919, Acc: 0.8778, Val Loss: 0.7521, Val Acc: 0.6574
Epoch 93/100, Loss: 0.2918, Acc: 0.8783, Val Loss: 0.7547, Val Acc: 0.6544
Epoch 94/100, Loss: 0.2918, Acc: 0.8786, Val Loss: 0.7573, Val Acc: 0.6540
Epoch 95/100, Loss: 0.2918, Acc: 0.8782, Val Loss: 0.7525, Val Acc: 0.6581
Epoch 96/100, Loss: 0.2916, Acc: 0.8778, Val Loss: 0.7588, Val Acc: 0.6511
Epoch 97/100, Loss: 0.2917, Acc: 0.8788, Val Loss: 0.7499, Val Acc: 0.6570
Epoch 98/100, Loss: 0.2916, Acc: 0.8775, Val Loss: 0.7629, Val Acc: 0.6500
Epoch 99/100, Loss: 0.2915, Acc: 0.8783, Val Loss: 0.7593, Val Acc: 0.6515
Epoch 100/100, Loss: 0.2916, Acc: 0.8790, Val Loss: 0.7566, Val Acc: 0.6551

##############################
Resultados para principal:  062  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1 
 {'training': [0.2916217440191437, 0.8789522058823529, 0.8836776474967429, 0.8727941176470588, 0.8782021640617775], 'validate': [0.7566020655077558, 0.6551470588235294, 0.734966592427617, 0.4852941176470588, 0.5845881310894597], 'test': [0.3375696268070627, 0.8661764705882353, 0.8579643473260494, 0.8776470588235294, 0.8676940971212562]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  035  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  035  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  035  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6219, Acc: 0.6938, Val Loss: 0.6802, Val Acc: 0.5588
Mejor modelo guardado con Val Loss: 0.6802
Epoch 2/100, Loss: 0.5693, Acc: 0.7214, Val Loss: 0.5948, Val Acc: 0.6941
Mejor modelo guardado con Val Loss: 0.5948
Epoch 3/100, Loss: 0.5301, Acc: 0.7483, Val Loss: 0.5785, Val Acc: 0.7011
Mejor modelo guardado con Val Loss: 0.5785
Epoch 4/100, Loss: 0.5262, Acc: 0.7405, Val Loss: 0.5472, Val Acc: 0.7213
Mejor modelo guardado con Val Loss: 0.5472
Epoch 5/100, Loss: 0.5077, Acc: 0.7573, Val Loss: 0.5626, Val Acc: 0.7188
Epoch 6/100, Loss: 0.5045, Acc: 0.7608, Val Loss: 0.5760, Val Acc: 0.7136
Epoch 7/100, Loss: 0.5018, Acc: 0.7594, Val Loss: 0.5365, Val Acc: 0.7309
Mejor modelo guardado con Val Loss: 0.5365
Epoch 8/100, Loss: 0.5038, Acc: 0.7607, Val Loss: 0.6031, Val Acc: 0.6724
Epoch 9/100, Loss: 0.5026, Acc: 0.7676, Val Loss: 0.5764, Val Acc: 0.6901
Epoch 10/100, Loss: 0.4910, Acc: 0.7665, Val Loss: 0.5278, Val Acc: 0.7438
Mejor modelo guardado con Val Loss: 0.5278
Epoch 11/100, Loss: 0.4866, Acc: 0.7694, Val Loss: 0.5633, Val Acc: 0.7213
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4795, Acc: 0.7726, Val Loss: 0.5862, Val Acc: 0.6805
Epoch 13/100, Loss: 0.4781, Acc: 0.7765, Val Loss: 0.5705, Val Acc: 0.7026
Epoch 14/100, Loss: 0.4747, Acc: 0.7773, Val Loss: 0.6105, Val Acc: 0.6776
Epoch 15/100, Loss: 0.4759, Acc: 0.7781, Val Loss: 0.5907, Val Acc: 0.6989
Epoch 16/100, Loss: 0.4760, Acc: 0.7765, Val Loss: 0.5742, Val Acc: 0.6985
Epoch 17/100, Loss: 0.4744, Acc: 0.7777, Val Loss: 0.5741, Val Acc: 0.6993
Epoch 18/100, Loss: 0.4728, Acc: 0.7765, Val Loss: 0.5576, Val Acc: 0.7202
Epoch 19/100, Loss: 0.4734, Acc: 0.7756, Val Loss: 0.5840, Val Acc: 0.6879
Epoch 20/100, Loss: 0.4737, Acc: 0.7765, Val Loss: 0.6079, Val Acc: 0.6728
Epoch 21/100, Loss: 0.4721, Acc: 0.7755, Val Loss: 0.5511, Val Acc: 0.7338
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4656, Acc: 0.7787, Val Loss: 0.5772, Val Acc: 0.7011
Epoch 23/100, Loss: 0.4647, Acc: 0.7827, Val Loss: 0.5495, Val Acc: 0.7232
Epoch 24/100, Loss: 0.4640, Acc: 0.7815, Val Loss: 0.5461, Val Acc: 0.7331
Epoch 25/100, Loss: 0.4647, Acc: 0.7815, Val Loss: 0.5545, Val Acc: 0.7272
Epoch 26/100, Loss: 0.4672, Acc: 0.7772, Val Loss: 0.5688, Val Acc: 0.6937
Epoch 27/100, Loss: 0.4653, Acc: 0.7785, Val Loss: 0.5585, Val Acc: 0.7125
Epoch 28/100, Loss: 0.4628, Acc: 0.7812, Val Loss: 0.5733, Val Acc: 0.6952
Epoch 29/100, Loss: 0.4626, Acc: 0.7793, Val Loss: 0.5905, Val Acc: 0.6926
Epoch 30/100, Loss: 0.4626, Acc: 0.7817, Val Loss: 0.5501, Val Acc: 0.7213
Epoch 31/100, Loss: 0.4628, Acc: 0.7790, Val Loss: 0.5776, Val Acc: 0.7059
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4602, Acc: 0.7810, Val Loss: 0.5853, Val Acc: 0.6801
Epoch 33/100, Loss: 0.4596, Acc: 0.7819, Val Loss: 0.5724, Val Acc: 0.7048
Epoch 34/100, Loss: 0.4592, Acc: 0.7821, Val Loss: 0.5550, Val Acc: 0.7125
Epoch 35/100, Loss: 0.4588, Acc: 0.7837, Val Loss: 0.5867, Val Acc: 0.6934
Epoch 36/100, Loss: 0.4579, Acc: 0.7831, Val Loss: 0.5647, Val Acc: 0.7107
Epoch 37/100, Loss: 0.4589, Acc: 0.7811, Val Loss: 0.5704, Val Acc: 0.7121
Epoch 38/100, Loss: 0.4584, Acc: 0.7820, Val Loss: 0.5771, Val Acc: 0.6971
Epoch 39/100, Loss: 0.4583, Acc: 0.7827, Val Loss: 0.5961, Val Acc: 0.6901
Epoch 40/100, Loss: 0.4576, Acc: 0.7832, Val Loss: 0.5698, Val Acc: 0.7158
Epoch 41/100, Loss: 0.4578, Acc: 0.7828, Val Loss: 0.5658, Val Acc: 0.7165
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4562, Acc: 0.7856, Val Loss: 0.5577, Val Acc: 0.7202
Epoch 43/100, Loss: 0.4558, Acc: 0.7837, Val Loss: 0.5908, Val Acc: 0.6882
Epoch 44/100, Loss: 0.4556, Acc: 0.7847, Val Loss: 0.5659, Val Acc: 0.7029
Epoch 45/100, Loss: 0.4556, Acc: 0.7829, Val Loss: 0.5694, Val Acc: 0.7015
Epoch 46/100, Loss: 0.4551, Acc: 0.7855, Val Loss: 0.5603, Val Acc: 0.7147
Epoch 47/100, Loss: 0.4547, Acc: 0.7847, Val Loss: 0.5698, Val Acc: 0.7059
Epoch 48/100, Loss: 0.4549, Acc: 0.7861, Val Loss: 0.5605, Val Acc: 0.7154
Epoch 49/100, Loss: 0.4544, Acc: 0.7861, Val Loss: 0.5629, Val Acc: 0.7085
Epoch 50/100, Loss: 0.4540, Acc: 0.7858, Val Loss: 0.5567, Val Acc: 0.7210
Epoch 51/100, Loss: 0.4545, Acc: 0.7853, Val Loss: 0.5714, Val Acc: 0.6996
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4533, Acc: 0.7859, Val Loss: 0.5751, Val Acc: 0.6989
Epoch 53/100, Loss: 0.4532, Acc: 0.7854, Val Loss: 0.5618, Val Acc: 0.7110
Epoch 54/100, Loss: 0.4531, Acc: 0.7865, Val Loss: 0.5636, Val Acc: 0.7081
Epoch 55/100, Loss: 0.4531, Acc: 0.7852, Val Loss: 0.5665, Val Acc: 0.7040
Epoch 56/100, Loss: 0.4529, Acc: 0.7843, Val Loss: 0.5609, Val Acc: 0.7110
Epoch 57/100, Loss: 0.4528, Acc: 0.7864, Val Loss: 0.5726, Val Acc: 0.7000
Epoch 58/100, Loss: 0.4528, Acc: 0.7860, Val Loss: 0.5672, Val Acc: 0.7074
Epoch 59/100, Loss: 0.4523, Acc: 0.7849, Val Loss: 0.5570, Val Acc: 0.7188
Epoch 60/100, Loss: 0.4524, Acc: 0.7861, Val Loss: 0.5565, Val Acc: 0.7158
Epoch 61/100, Loss: 0.4527, Acc: 0.7850, Val Loss: 0.5597, Val Acc: 0.7132
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4519, Acc: 0.7852, Val Loss: 0.5669, Val Acc: 0.7074
Epoch 63/100, Loss: 0.4521, Acc: 0.7853, Val Loss: 0.5723, Val Acc: 0.7004
Epoch 64/100, Loss: 0.4518, Acc: 0.7872, Val Loss: 0.5584, Val Acc: 0.7151
Epoch 65/100, Loss: 0.4519, Acc: 0.7865, Val Loss: 0.5635, Val Acc: 0.7110
Epoch 66/100, Loss: 0.4519, Acc: 0.7858, Val Loss: 0.5632, Val Acc: 0.7107
Epoch 67/100, Loss: 0.4517, Acc: 0.7858, Val Loss: 0.5607, Val Acc: 0.7110
Epoch 68/100, Loss: 0.4517, Acc: 0.7862, Val Loss: 0.5698, Val Acc: 0.7044
Epoch 69/100, Loss: 0.4518, Acc: 0.7865, Val Loss: 0.5637, Val Acc: 0.7096
Epoch 70/100, Loss: 0.4516, Acc: 0.7854, Val Loss: 0.5706, Val Acc: 0.7011
Epoch 71/100, Loss: 0.4517, Acc: 0.7854, Val Loss: 0.5674, Val Acc: 0.7063
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4515, Acc: 0.7853, Val Loss: 0.5693, Val Acc: 0.7040
Epoch 73/100, Loss: 0.4515, Acc: 0.7863, Val Loss: 0.5703, Val Acc: 0.7029
Epoch 74/100, Loss: 0.4514, Acc: 0.7858, Val Loss: 0.5660, Val Acc: 0.7066
Epoch 75/100, Loss: 0.4514, Acc: 0.7862, Val Loss: 0.5687, Val Acc: 0.7048
Epoch 76/100, Loss: 0.4512, Acc: 0.7863, Val Loss: 0.5635, Val Acc: 0.7099
Epoch 77/100, Loss: 0.4513, Acc: 0.7855, Val Loss: 0.5684, Val Acc: 0.7040
Epoch 78/100, Loss: 0.4513, Acc: 0.7860, Val Loss: 0.5662, Val Acc: 0.7059
Epoch 79/100, Loss: 0.4513, Acc: 0.7858, Val Loss: 0.5675, Val Acc: 0.7063
Epoch 80/100, Loss: 0.4513, Acc: 0.7867, Val Loss: 0.5672, Val Acc: 0.7066
Epoch 81/100, Loss: 0.4512, Acc: 0.7863, Val Loss: 0.5687, Val Acc: 0.7055
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4512, Acc: 0.7862, Val Loss: 0.5669, Val Acc: 0.7055
Epoch 83/100, Loss: 0.4511, Acc: 0.7865, Val Loss: 0.5646, Val Acc: 0.7077
Epoch 84/100, Loss: 0.4512, Acc: 0.7858, Val Loss: 0.5642, Val Acc: 0.7081
Epoch 85/100, Loss: 0.4511, Acc: 0.7862, Val Loss: 0.5640, Val Acc: 0.7092
Epoch 86/100, Loss: 0.4511, Acc: 0.7876, Val Loss: 0.5696, Val Acc: 0.7048
Epoch 87/100, Loss: 0.4510, Acc: 0.7860, Val Loss: 0.5668, Val Acc: 0.7070
Epoch 88/100, Loss: 0.4511, Acc: 0.7857, Val Loss: 0.5700, Val Acc: 0.7033
Epoch 89/100, Loss: 0.4510, Acc: 0.7860, Val Loss: 0.5681, Val Acc: 0.7048
Epoch 90/100, Loss: 0.4509, Acc: 0.7860, Val Loss: 0.5666, Val Acc: 0.7059
Epoch 91/100, Loss: 0.4509, Acc: 0.7857, Val Loss: 0.5686, Val Acc: 0.7048
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4509, Acc: 0.7871, Val Loss: 0.5632, Val Acc: 0.7099
Epoch 93/100, Loss: 0.4509, Acc: 0.7862, Val Loss: 0.5629, Val Acc: 0.7110
Epoch 94/100, Loss: 0.4508, Acc: 0.7858, Val Loss: 0.5697, Val Acc: 0.7033
Epoch 95/100, Loss: 0.4509, Acc: 0.7859, Val Loss: 0.5667, Val Acc: 0.7044
Epoch 96/100, Loss: 0.4508, Acc: 0.7864, Val Loss: 0.5675, Val Acc: 0.7048
Epoch 97/100, Loss: 0.4508, Acc: 0.7859, Val Loss: 0.5689, Val Acc: 0.7044
Epoch 98/100, Loss: 0.4507, Acc: 0.7863, Val Loss: 0.5688, Val Acc: 0.7044
Epoch 99/100, Loss: 0.4508, Acc: 0.7860, Val Loss: 0.5642, Val Acc: 0.7077
Epoch 100/100, Loss: 0.4507, Acc: 0.7858, Val Loss: 0.5679, Val Acc: 0.7055

##############################
Resultados para principal:  035  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1 
 {'training': [0.4506832678528393, 0.7858455882352942, 0.7588215712383488, 0.8380514705882353, 0.796470999301188], 'validate': [0.5679353943397832, 0.705514705882353, 0.6456487754038561, 0.9110294117647059, 0.7557182067703568], 'test': [0.5796618395381503, 0.7047058823529412, 0.6750503018108652, 0.7894117647058824, 0.7277657266811279]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  002  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  002  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  002  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6732, Acc: 0.5738, Val Loss: 0.6976, Val Acc: 0.4945
Mejor modelo guardado con Val Loss: 0.6976
Epoch 2/100, Loss: 0.6600, Acc: 0.6029, Val Loss: 0.6936, Val Acc: 0.5059
Mejor modelo guardado con Val Loss: 0.6936
Epoch 3/100, Loss: 0.6452, Acc: 0.6224, Val Loss: 0.6919, Val Acc: 0.5375
Mejor modelo guardado con Val Loss: 0.6919
Epoch 4/100, Loss: 0.6297, Acc: 0.6432, Val Loss: 0.6844, Val Acc: 0.5349
Mejor modelo guardado con Val Loss: 0.6844
Epoch 5/100, Loss: 0.6281, Acc: 0.6640, Val Loss: 0.6897, Val Acc: 0.5482
Epoch 6/100, Loss: 0.6149, Acc: 0.6594, Val Loss: 0.7047, Val Acc: 0.5140
Epoch 7/100, Loss: 0.6050, Acc: 0.6763, Val Loss: 0.6975, Val Acc: 0.5360
Epoch 8/100, Loss: 0.5981, Acc: 0.6866, Val Loss: 0.7014, Val Acc: 0.5327
Epoch 9/100, Loss: 0.5945, Acc: 0.6875, Val Loss: 0.6826, Val Acc: 0.5816
Mejor modelo guardado con Val Loss: 0.6826
Epoch 10/100, Loss: 0.5882, Acc: 0.6969, Val Loss: 0.6980, Val Acc: 0.5511
Epoch 11/100, Loss: 0.5835, Acc: 0.7016, Val Loss: 0.7260, Val Acc: 0.5338
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5749, Acc: 0.7095, Val Loss: 0.7131, Val Acc: 0.5441
Epoch 13/100, Loss: 0.5765, Acc: 0.7072, Val Loss: 0.7137, Val Acc: 0.5449
Epoch 14/100, Loss: 0.5721, Acc: 0.7082, Val Loss: 0.7129, Val Acc: 0.5437
Epoch 15/100, Loss: 0.5729, Acc: 0.7080, Val Loss: 0.7110, Val Acc: 0.5489
Epoch 16/100, Loss: 0.5706, Acc: 0.7084, Val Loss: 0.7299, Val Acc: 0.5346
Epoch 17/100, Loss: 0.5692, Acc: 0.7126, Val Loss: 0.6975, Val Acc: 0.5610
Epoch 18/100, Loss: 0.5697, Acc: 0.7125, Val Loss: 0.7108, Val Acc: 0.5555
Epoch 19/100, Loss: 0.5671, Acc: 0.7107, Val Loss: 0.7153, Val Acc: 0.5445
Epoch 20/100, Loss: 0.5665, Acc: 0.7106, Val Loss: 0.7184, Val Acc: 0.5474
Epoch 21/100, Loss: 0.5672, Acc: 0.7115, Val Loss: 0.7123, Val Acc: 0.5511
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5628, Acc: 0.7121, Val Loss: 0.7093, Val Acc: 0.5588
Epoch 23/100, Loss: 0.5605, Acc: 0.7183, Val Loss: 0.7288, Val Acc: 0.5397
Epoch 24/100, Loss: 0.5616, Acc: 0.7155, Val Loss: 0.7371, Val Acc: 0.5360
Epoch 25/100, Loss: 0.5607, Acc: 0.7192, Val Loss: 0.7319, Val Acc: 0.5397
Epoch 26/100, Loss: 0.5594, Acc: 0.7166, Val Loss: 0.7450, Val Acc: 0.5327
Epoch 27/100, Loss: 0.5594, Acc: 0.7181, Val Loss: 0.7221, Val Acc: 0.5471
Epoch 28/100, Loss: 0.5582, Acc: 0.7180, Val Loss: 0.7370, Val Acc: 0.5371
Epoch 29/100, Loss: 0.5581, Acc: 0.7154, Val Loss: 0.7349, Val Acc: 0.5423
Epoch 30/100, Loss: 0.5581, Acc: 0.7192, Val Loss: 0.7464, Val Acc: 0.5346
Epoch 31/100, Loss: 0.5582, Acc: 0.7185, Val Loss: 0.7093, Val Acc: 0.5647
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5567, Acc: 0.7193, Val Loss: 0.7318, Val Acc: 0.5445
Epoch 33/100, Loss: 0.5560, Acc: 0.7204, Val Loss: 0.7098, Val Acc: 0.5680
Epoch 34/100, Loss: 0.5557, Acc: 0.7188, Val Loss: 0.7229, Val Acc: 0.5526
Epoch 35/100, Loss: 0.5550, Acc: 0.7198, Val Loss: 0.7293, Val Acc: 0.5496
Epoch 36/100, Loss: 0.5561, Acc: 0.7212, Val Loss: 0.7389, Val Acc: 0.5393
Epoch 37/100, Loss: 0.5556, Acc: 0.7244, Val Loss: 0.7292, Val Acc: 0.5460
Epoch 38/100, Loss: 0.5556, Acc: 0.7214, Val Loss: 0.7423, Val Acc: 0.5360
Epoch 39/100, Loss: 0.5548, Acc: 0.7217, Val Loss: 0.7276, Val Acc: 0.5551
Epoch 40/100, Loss: 0.5549, Acc: 0.7225, Val Loss: 0.7377, Val Acc: 0.5393
Epoch 41/100, Loss: 0.5540, Acc: 0.7225, Val Loss: 0.7337, Val Acc: 0.5449
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5534, Acc: 0.7220, Val Loss: 0.7243, Val Acc: 0.5570
Epoch 43/100, Loss: 0.5532, Acc: 0.7210, Val Loss: 0.7444, Val Acc: 0.5379
Epoch 44/100, Loss: 0.5532, Acc: 0.7218, Val Loss: 0.7377, Val Acc: 0.5437
Epoch 45/100, Loss: 0.5530, Acc: 0.7219, Val Loss: 0.7237, Val Acc: 0.5544
Epoch 46/100, Loss: 0.5534, Acc: 0.7199, Val Loss: 0.7258, Val Acc: 0.5555
Epoch 47/100, Loss: 0.5532, Acc: 0.7210, Val Loss: 0.7448, Val Acc: 0.5382
Epoch 48/100, Loss: 0.5532, Acc: 0.7209, Val Loss: 0.7314, Val Acc: 0.5485
Epoch 49/100, Loss: 0.5530, Acc: 0.7210, Val Loss: 0.7455, Val Acc: 0.5364
Epoch 50/100, Loss: 0.5523, Acc: 0.7235, Val Loss: 0.7317, Val Acc: 0.5452
Epoch 51/100, Loss: 0.5536, Acc: 0.7199, Val Loss: 0.7350, Val Acc: 0.5460
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5518, Acc: 0.7210, Val Loss: 0.7343, Val Acc: 0.5426
Epoch 53/100, Loss: 0.5507, Acc: 0.7222, Val Loss: 0.7383, Val Acc: 0.5445
Epoch 54/100, Loss: 0.5506, Acc: 0.7239, Val Loss: 0.7358, Val Acc: 0.5493
Epoch 55/100, Loss: 0.5507, Acc: 0.7215, Val Loss: 0.7366, Val Acc: 0.5449
Epoch 56/100, Loss: 0.5506, Acc: 0.7222, Val Loss: 0.7373, Val Acc: 0.5460
Epoch 57/100, Loss: 0.5505, Acc: 0.7228, Val Loss: 0.7382, Val Acc: 0.5456
Epoch 58/100, Loss: 0.5505, Acc: 0.7228, Val Loss: 0.7374, Val Acc: 0.5474
Epoch 59/100, Loss: 0.5502, Acc: 0.7218, Val Loss: 0.7397, Val Acc: 0.5423
Epoch 60/100, Loss: 0.5501, Acc: 0.7213, Val Loss: 0.7432, Val Acc: 0.5397
Epoch 61/100, Loss: 0.5502, Acc: 0.7219, Val Loss: 0.7421, Val Acc: 0.5415
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5499, Acc: 0.7224, Val Loss: 0.7406, Val Acc: 0.5426
Epoch 63/100, Loss: 0.5499, Acc: 0.7226, Val Loss: 0.7393, Val Acc: 0.5445
Epoch 64/100, Loss: 0.5498, Acc: 0.7229, Val Loss: 0.7368, Val Acc: 0.5471
Epoch 65/100, Loss: 0.5498, Acc: 0.7232, Val Loss: 0.7360, Val Acc: 0.5463
Epoch 66/100, Loss: 0.5497, Acc: 0.7237, Val Loss: 0.7450, Val Acc: 0.5379
Epoch 67/100, Loss: 0.5498, Acc: 0.7215, Val Loss: 0.7361, Val Acc: 0.5474
Epoch 68/100, Loss: 0.5497, Acc: 0.7220, Val Loss: 0.7392, Val Acc: 0.5449
Epoch 69/100, Loss: 0.5497, Acc: 0.7233, Val Loss: 0.7396, Val Acc: 0.5449
Epoch 70/100, Loss: 0.5497, Acc: 0.7225, Val Loss: 0.7380, Val Acc: 0.5482
Epoch 71/100, Loss: 0.5497, Acc: 0.7219, Val Loss: 0.7422, Val Acc: 0.5423
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5495, Acc: 0.7229, Val Loss: 0.7375, Val Acc: 0.5482
Epoch 73/100, Loss: 0.5496, Acc: 0.7221, Val Loss: 0.7384, Val Acc: 0.5474
Epoch 74/100, Loss: 0.5495, Acc: 0.7221, Val Loss: 0.7390, Val Acc: 0.5460
Epoch 75/100, Loss: 0.5495, Acc: 0.7219, Val Loss: 0.7386, Val Acc: 0.5474
Epoch 76/100, Loss: 0.5495, Acc: 0.7218, Val Loss: 0.7385, Val Acc: 0.5474
Epoch 77/100, Loss: 0.5495, Acc: 0.7228, Val Loss: 0.7384, Val Acc: 0.5474
Epoch 78/100, Loss: 0.5494, Acc: 0.7225, Val Loss: 0.7379, Val Acc: 0.5474
Epoch 79/100, Loss: 0.5494, Acc: 0.7222, Val Loss: 0.7387, Val Acc: 0.5471
Epoch 80/100, Loss: 0.5493, Acc: 0.7226, Val Loss: 0.7392, Val Acc: 0.5456
Epoch 81/100, Loss: 0.5495, Acc: 0.7216, Val Loss: 0.7385, Val Acc: 0.5471
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5494, Acc: 0.7222, Val Loss: 0.7384, Val Acc: 0.5474
Epoch 83/100, Loss: 0.5495, Acc: 0.7220, Val Loss: 0.7390, Val Acc: 0.5467
Epoch 84/100, Loss: 0.5493, Acc: 0.7229, Val Loss: 0.7383, Val Acc: 0.5474
Epoch 85/100, Loss: 0.5494, Acc: 0.7225, Val Loss: 0.7395, Val Acc: 0.5463
Epoch 86/100, Loss: 0.5493, Acc: 0.7220, Val Loss: 0.7375, Val Acc: 0.5474
Epoch 87/100, Loss: 0.5493, Acc: 0.7221, Val Loss: 0.7378, Val Acc: 0.5474
Epoch 88/100, Loss: 0.5493, Acc: 0.7222, Val Loss: 0.7392, Val Acc: 0.5474
Epoch 89/100, Loss: 0.5493, Acc: 0.7225, Val Loss: 0.7383, Val Acc: 0.5478
Epoch 90/100, Loss: 0.5493, Acc: 0.7226, Val Loss: 0.7393, Val Acc: 0.5482
Epoch 91/100, Loss: 0.5492, Acc: 0.7227, Val Loss: 0.7398, Val Acc: 0.5460
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5493, Acc: 0.7219, Val Loss: 0.7400, Val Acc: 0.5456
Epoch 93/100, Loss: 0.5492, Acc: 0.7219, Val Loss: 0.7388, Val Acc: 0.5474
Epoch 94/100, Loss: 0.5492, Acc: 0.7232, Val Loss: 0.7377, Val Acc: 0.5478
Epoch 95/100, Loss: 0.5491, Acc: 0.7224, Val Loss: 0.7388, Val Acc: 0.5482
Epoch 96/100, Loss: 0.5492, Acc: 0.7224, Val Loss: 0.7393, Val Acc: 0.5474
Epoch 97/100, Loss: 0.5492, Acc: 0.7222, Val Loss: 0.7376, Val Acc: 0.5474
Epoch 98/100, Loss: 0.5491, Acc: 0.7222, Val Loss: 0.7383, Val Acc: 0.5474
Epoch 99/100, Loss: 0.5491, Acc: 0.7215, Val Loss: 0.7380, Val Acc: 0.5474
Epoch 100/100, Loss: 0.5491, Acc: 0.7226, Val Loss: 0.7394, Val Acc: 0.5474

##############################
Resultados para principal:  002  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1 
 {'training': [0.5491432354730719, 0.7226102941176471, 0.7189081706435285, 0.7310661764705882, 0.7249362012395187], 'validate': [0.7393857517907786, 0.5474264705882353, 0.5361749859786876, 0.7029411764705882, 0.6083359847279669], 'test': [0.6866019897990756, 0.5579411764705883, 0.5586658725431805, 0.5517647058823529, 0.5551938443326427]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  043  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  043  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  043  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5425, Acc: 0.7692, Val Loss: 0.7309, Val Acc: 0.5335
Mejor modelo guardado con Val Loss: 0.7309
Epoch 2/100, Loss: 0.4547, Acc: 0.7954, Val Loss: 0.7149, Val Acc: 0.5835
Mejor modelo guardado con Val Loss: 0.7149
Epoch 3/100, Loss: 0.4277, Acc: 0.8007, Val Loss: 0.7164, Val Acc: 0.5724
Epoch 4/100, Loss: 0.4216, Acc: 0.8032, Val Loss: 0.7135, Val Acc: 0.5849
Mejor modelo guardado con Val Loss: 0.7135
Epoch 5/100, Loss: 0.4140, Acc: 0.8037, Val Loss: 0.7124, Val Acc: 0.5938
Mejor modelo guardado con Val Loss: 0.7124
Epoch 6/100, Loss: 0.4176, Acc: 0.8028, Val Loss: 0.7113, Val Acc: 0.5849
Mejor modelo guardado con Val Loss: 0.7113
Epoch 7/100, Loss: 0.4220, Acc: 0.8009, Val Loss: 0.7072, Val Acc: 0.5779
Mejor modelo guardado con Val Loss: 0.7072
Epoch 8/100, Loss: 0.4152, Acc: 0.8068, Val Loss: 0.7233, Val Acc: 0.5952
Epoch 9/100, Loss: 0.4109, Acc: 0.8042, Val Loss: 0.7212, Val Acc: 0.6059
Epoch 10/100, Loss: 0.4109, Acc: 0.8094, Val Loss: 0.7337, Val Acc: 0.5629
Epoch 11/100, Loss: 0.4172, Acc: 0.8052, Val Loss: 0.7308, Val Acc: 0.6022
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3998, Acc: 0.8119, Val Loss: 0.7208, Val Acc: 0.6037
Epoch 13/100, Loss: 0.3996, Acc: 0.8141, Val Loss: 0.7304, Val Acc: 0.5761
Epoch 14/100, Loss: 0.4007, Acc: 0.8105, Val Loss: 0.7365, Val Acc: 0.6066
Epoch 15/100, Loss: 0.3978, Acc: 0.8156, Val Loss: 0.7338, Val Acc: 0.5993
Epoch 16/100, Loss: 0.3992, Acc: 0.8097, Val Loss: 0.7233, Val Acc: 0.6040
Epoch 17/100, Loss: 0.3968, Acc: 0.8128, Val Loss: 0.7773, Val Acc: 0.5926
Epoch 18/100, Loss: 0.3971, Acc: 0.8127, Val Loss: 0.7071, Val Acc: 0.6037
Mejor modelo guardado con Val Loss: 0.7071
Epoch 19/100, Loss: 0.3980, Acc: 0.8123, Val Loss: 0.7629, Val Acc: 0.5893
Epoch 20/100, Loss: 0.3975, Acc: 0.8104, Val Loss: 0.7189, Val Acc: 0.6099
Epoch 21/100, Loss: 0.3922, Acc: 0.8132, Val Loss: 0.7346, Val Acc: 0.6037
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3907, Acc: 0.8130, Val Loss: 0.7719, Val Acc: 0.5989
Epoch 23/100, Loss: 0.3920, Acc: 0.8175, Val Loss: 0.7650, Val Acc: 0.5989
Epoch 24/100, Loss: 0.3891, Acc: 0.8166, Val Loss: 0.7357, Val Acc: 0.5993
Epoch 25/100, Loss: 0.3899, Acc: 0.8178, Val Loss: 0.7646, Val Acc: 0.6121
Epoch 26/100, Loss: 0.3905, Acc: 0.8167, Val Loss: 0.7614, Val Acc: 0.6070
Epoch 27/100, Loss: 0.3911, Acc: 0.8130, Val Loss: 0.7431, Val Acc: 0.6018
Epoch 28/100, Loss: 0.3887, Acc: 0.8150, Val Loss: 0.7847, Val Acc: 0.5941
Epoch 29/100, Loss: 0.3881, Acc: 0.8183, Val Loss: 0.7732, Val Acc: 0.5923
Epoch 30/100, Loss: 0.3921, Acc: 0.8119, Val Loss: 0.7591, Val Acc: 0.5860
Epoch 31/100, Loss: 0.3872, Acc: 0.8166, Val Loss: 0.7398, Val Acc: 0.6029
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3856, Acc: 0.8193, Val Loss: 0.7560, Val Acc: 0.6022
Epoch 33/100, Loss: 0.3850, Acc: 0.8197, Val Loss: 0.7510, Val Acc: 0.6074
Epoch 34/100, Loss: 0.3841, Acc: 0.8211, Val Loss: 0.7279, Val Acc: 0.6143
Epoch 35/100, Loss: 0.3842, Acc: 0.8193, Val Loss: 0.7376, Val Acc: 0.6118
Epoch 36/100, Loss: 0.3836, Acc: 0.8223, Val Loss: 0.7362, Val Acc: 0.6158
Epoch 37/100, Loss: 0.3841, Acc: 0.8206, Val Loss: 0.7514, Val Acc: 0.6007
Epoch 38/100, Loss: 0.3837, Acc: 0.8227, Val Loss: 0.7488, Val Acc: 0.6085
Epoch 39/100, Loss: 0.3840, Acc: 0.8210, Val Loss: 0.7600, Val Acc: 0.5963
Epoch 40/100, Loss: 0.3838, Acc: 0.8205, Val Loss: 0.7510, Val Acc: 0.6136
Epoch 41/100, Loss: 0.3831, Acc: 0.8196, Val Loss: 0.7412, Val Acc: 0.6070
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3820, Acc: 0.8238, Val Loss: 0.7464, Val Acc: 0.5982
Epoch 43/100, Loss: 0.3817, Acc: 0.8210, Val Loss: 0.7500, Val Acc: 0.6026
Epoch 44/100, Loss: 0.3821, Acc: 0.8207, Val Loss: 0.7514, Val Acc: 0.5967
Epoch 45/100, Loss: 0.3811, Acc: 0.8237, Val Loss: 0.7459, Val Acc: 0.6066
Epoch 46/100, Loss: 0.3812, Acc: 0.8217, Val Loss: 0.7547, Val Acc: 0.6033
Epoch 47/100, Loss: 0.3813, Acc: 0.8213, Val Loss: 0.7644, Val Acc: 0.6051
Epoch 48/100, Loss: 0.3808, Acc: 0.8243, Val Loss: 0.7548, Val Acc: 0.6048
Epoch 49/100, Loss: 0.3809, Acc: 0.8244, Val Loss: 0.7369, Val Acc: 0.6044
Epoch 50/100, Loss: 0.3809, Acc: 0.8236, Val Loss: 0.7397, Val Acc: 0.6062
Epoch 51/100, Loss: 0.3810, Acc: 0.8235, Val Loss: 0.7517, Val Acc: 0.6033
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3800, Acc: 0.8252, Val Loss: 0.7502, Val Acc: 0.6110
Epoch 53/100, Loss: 0.3800, Acc: 0.8248, Val Loss: 0.7483, Val Acc: 0.6114
Epoch 54/100, Loss: 0.3800, Acc: 0.8229, Val Loss: 0.7509, Val Acc: 0.6055
Epoch 55/100, Loss: 0.3801, Acc: 0.8236, Val Loss: 0.7477, Val Acc: 0.6132
Epoch 56/100, Loss: 0.3799, Acc: 0.8234, Val Loss: 0.7534, Val Acc: 0.6129
Epoch 57/100, Loss: 0.3793, Acc: 0.8240, Val Loss: 0.7699, Val Acc: 0.5985
Epoch 58/100, Loss: 0.3801, Acc: 0.8238, Val Loss: 0.7567, Val Acc: 0.6018
Epoch 59/100, Loss: 0.3797, Acc: 0.8254, Val Loss: 0.7587, Val Acc: 0.6062
Epoch 60/100, Loss: 0.3797, Acc: 0.8252, Val Loss: 0.7492, Val Acc: 0.6044
Epoch 61/100, Loss: 0.3794, Acc: 0.8236, Val Loss: 0.7544, Val Acc: 0.6004
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3792, Acc: 0.8255, Val Loss: 0.7604, Val Acc: 0.6059
Epoch 63/100, Loss: 0.3791, Acc: 0.8247, Val Loss: 0.7555, Val Acc: 0.6037
Epoch 64/100, Loss: 0.3792, Acc: 0.8247, Val Loss: 0.7559, Val Acc: 0.6051
Epoch 65/100, Loss: 0.3792, Acc: 0.8250, Val Loss: 0.7569, Val Acc: 0.6051
Epoch 66/100, Loss: 0.3793, Acc: 0.8255, Val Loss: 0.7570, Val Acc: 0.6044
Epoch 67/100, Loss: 0.3792, Acc: 0.8246, Val Loss: 0.7560, Val Acc: 0.6085
Epoch 68/100, Loss: 0.3791, Acc: 0.8261, Val Loss: 0.7559, Val Acc: 0.6088
Epoch 69/100, Loss: 0.3792, Acc: 0.8245, Val Loss: 0.7534, Val Acc: 0.6074
Epoch 70/100, Loss: 0.3791, Acc: 0.8252, Val Loss: 0.7518, Val Acc: 0.6040
Epoch 71/100, Loss: 0.3790, Acc: 0.8244, Val Loss: 0.7534, Val Acc: 0.6092
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3790, Acc: 0.8238, Val Loss: 0.7565, Val Acc: 0.6048
Epoch 73/100, Loss: 0.3789, Acc: 0.8254, Val Loss: 0.7560, Val Acc: 0.6059
Epoch 74/100, Loss: 0.3789, Acc: 0.8247, Val Loss: 0.7559, Val Acc: 0.6074
Epoch 75/100, Loss: 0.3788, Acc: 0.8259, Val Loss: 0.7534, Val Acc: 0.6040
Epoch 76/100, Loss: 0.3789, Acc: 0.8257, Val Loss: 0.7550, Val Acc: 0.6088
Epoch 77/100, Loss: 0.3789, Acc: 0.8253, Val Loss: 0.7563, Val Acc: 0.6088
Epoch 78/100, Loss: 0.3788, Acc: 0.8251, Val Loss: 0.7565, Val Acc: 0.6092
Epoch 79/100, Loss: 0.3787, Acc: 0.8248, Val Loss: 0.7560, Val Acc: 0.6044
Epoch 80/100, Loss: 0.3788, Acc: 0.8252, Val Loss: 0.7557, Val Acc: 0.6062
Epoch 81/100, Loss: 0.3787, Acc: 0.8255, Val Loss: 0.7566, Val Acc: 0.6062
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3787, Acc: 0.8256, Val Loss: 0.7569, Val Acc: 0.6051
Epoch 83/100, Loss: 0.3787, Acc: 0.8252, Val Loss: 0.7560, Val Acc: 0.6074
Epoch 84/100, Loss: 0.3787, Acc: 0.8247, Val Loss: 0.7576, Val Acc: 0.6059
Epoch 85/100, Loss: 0.3786, Acc: 0.8253, Val Loss: 0.7532, Val Acc: 0.6055
Epoch 86/100, Loss: 0.3787, Acc: 0.8250, Val Loss: 0.7558, Val Acc: 0.6037
Epoch 87/100, Loss: 0.3786, Acc: 0.8254, Val Loss: 0.7567, Val Acc: 0.6055
Epoch 88/100, Loss: 0.3786, Acc: 0.8244, Val Loss: 0.7556, Val Acc: 0.6033
Epoch 89/100, Loss: 0.3787, Acc: 0.8244, Val Loss: 0.7567, Val Acc: 0.6044
Epoch 90/100, Loss: 0.3787, Acc: 0.8244, Val Loss: 0.7577, Val Acc: 0.6044
Epoch 91/100, Loss: 0.3787, Acc: 0.8256, Val Loss: 0.7579, Val Acc: 0.6051
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3785, Acc: 0.8254, Val Loss: 0.7594, Val Acc: 0.6044
Epoch 93/100, Loss: 0.3786, Acc: 0.8255, Val Loss: 0.7547, Val Acc: 0.6081
Epoch 94/100, Loss: 0.3785, Acc: 0.8250, Val Loss: 0.7605, Val Acc: 0.6051
Epoch 95/100, Loss: 0.3786, Acc: 0.8252, Val Loss: 0.7578, Val Acc: 0.6040
Epoch 96/100, Loss: 0.3785, Acc: 0.8257, Val Loss: 0.7544, Val Acc: 0.6048
Epoch 97/100, Loss: 0.3785, Acc: 0.8251, Val Loss: 0.7543, Val Acc: 0.6059
Epoch 98/100, Loss: 0.3785, Acc: 0.8255, Val Loss: 0.7597, Val Acc: 0.6040
Epoch 99/100, Loss: 0.3785, Acc: 0.8252, Val Loss: 0.7610, Val Acc: 0.6040
Epoch 100/100, Loss: 0.3785, Acc: 0.8250, Val Loss: 0.7588, Val Acc: 0.6044

##############################
Resultados para principal:  043  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1 
 {'training': [0.378475761588882, 0.825, 0.8327060594655626, 0.8134191176470589, 0.8229496001487818], 'validate': [0.7587504248286403, 0.6044117647058823, 0.6324626865671642, 0.4985294117647059, 0.5575657894736842], 'test': [0.4809294425778919, 0.77, 0.7208854667949952, 0.8811764705882353, 0.7930121757543674]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  073  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  073  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  073  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6902, Acc: 0.5320, Val Loss: 0.7074, Val Acc: 0.3779
Mejor modelo guardado con Val Loss: 0.7074
Epoch 2/100, Loss: 0.6875, Acc: 0.5514, Val Loss: 0.7059, Val Acc: 0.3974
Mejor modelo guardado con Val Loss: 0.7059
Epoch 3/100, Loss: 0.6829, Acc: 0.5675, Val Loss: 0.7094, Val Acc: 0.3654
Epoch 4/100, Loss: 0.6776, Acc: 0.5752, Val Loss: 0.7289, Val Acc: 0.3206
Epoch 5/100, Loss: 0.6747, Acc: 0.5768, Val Loss: 0.7143, Val Acc: 0.4011
Epoch 6/100, Loss: 0.6702, Acc: 0.5818, Val Loss: 0.7114, Val Acc: 0.4243
Epoch 7/100, Loss: 0.6690, Acc: 0.5813, Val Loss: 0.7645, Val Acc: 0.3257
Epoch 8/100, Loss: 0.6715, Acc: 0.5760, Val Loss: 0.7556, Val Acc: 0.3540
Epoch 9/100, Loss: 0.6655, Acc: 0.5840, Val Loss: 0.7389, Val Acc: 0.3805
Epoch 10/100, Loss: 0.6638, Acc: 0.5863, Val Loss: 0.7478, Val Acc: 0.3790
Epoch 11/100, Loss: 0.6625, Acc: 0.5840, Val Loss: 0.7123, Val Acc: 0.4393
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6589, Acc: 0.5893, Val Loss: 0.7315, Val Acc: 0.4265
Epoch 13/100, Loss: 0.6581, Acc: 0.5905, Val Loss: 0.7255, Val Acc: 0.4316
Epoch 14/100, Loss: 0.6579, Acc: 0.5897, Val Loss: 0.7114, Val Acc: 0.4776
Epoch 15/100, Loss: 0.6569, Acc: 0.5893, Val Loss: 0.7238, Val Acc: 0.4375
Epoch 16/100, Loss: 0.6561, Acc: 0.5926, Val Loss: 0.7456, Val Acc: 0.3676
Epoch 17/100, Loss: 0.6566, Acc: 0.5925, Val Loss: 0.7171, Val Acc: 0.4658
Epoch 18/100, Loss: 0.6561, Acc: 0.5895, Val Loss: 0.7521, Val Acc: 0.4007
Epoch 19/100, Loss: 0.6558, Acc: 0.5895, Val Loss: 0.7218, Val Acc: 0.4551
Epoch 20/100, Loss: 0.6567, Acc: 0.5908, Val Loss: 0.7130, Val Acc: 0.4783
Epoch 21/100, Loss: 0.6550, Acc: 0.5908, Val Loss: 0.7265, Val Acc: 0.4463
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6543, Acc: 0.5908, Val Loss: 0.7363, Val Acc: 0.4298
Epoch 23/100, Loss: 0.6532, Acc: 0.5920, Val Loss: 0.7434, Val Acc: 0.4176
Epoch 24/100, Loss: 0.6537, Acc: 0.5922, Val Loss: 0.7325, Val Acc: 0.4434
Epoch 25/100, Loss: 0.6529, Acc: 0.5913, Val Loss: 0.7269, Val Acc: 0.4504
Epoch 26/100, Loss: 0.6531, Acc: 0.5931, Val Loss: 0.7292, Val Acc: 0.4463
Epoch 27/100, Loss: 0.6534, Acc: 0.5899, Val Loss: 0.7430, Val Acc: 0.4279
Epoch 28/100, Loss: 0.6536, Acc: 0.5910, Val Loss: 0.7431, Val Acc: 0.4246
Epoch 29/100, Loss: 0.6532, Acc: 0.5908, Val Loss: 0.7195, Val Acc: 0.4684
Epoch 30/100, Loss: 0.6534, Acc: 0.5911, Val Loss: 0.7362, Val Acc: 0.4397
Epoch 31/100, Loss: 0.6526, Acc: 0.5914, Val Loss: 0.7202, Val Acc: 0.4658
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6531, Acc: 0.5926, Val Loss: 0.7349, Val Acc: 0.4415
Epoch 33/100, Loss: 0.6525, Acc: 0.5923, Val Loss: 0.7475, Val Acc: 0.4221
Epoch 34/100, Loss: 0.6528, Acc: 0.5931, Val Loss: 0.7413, Val Acc: 0.4316
Epoch 35/100, Loss: 0.6520, Acc: 0.5917, Val Loss: 0.7292, Val Acc: 0.4482
Epoch 36/100, Loss: 0.6519, Acc: 0.5919, Val Loss: 0.7210, Val Acc: 0.4673
Epoch 37/100, Loss: 0.6519, Acc: 0.5912, Val Loss: 0.7369, Val Acc: 0.4353
Epoch 38/100, Loss: 0.6516, Acc: 0.5917, Val Loss: 0.7271, Val Acc: 0.4526
Epoch 39/100, Loss: 0.6519, Acc: 0.5917, Val Loss: 0.7285, Val Acc: 0.4518
Epoch 40/100, Loss: 0.6521, Acc: 0.5915, Val Loss: 0.7388, Val Acc: 0.4346
Epoch 41/100, Loss: 0.6518, Acc: 0.5905, Val Loss: 0.7300, Val Acc: 0.4478
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6514, Acc: 0.5936, Val Loss: 0.7271, Val Acc: 0.4559
Epoch 43/100, Loss: 0.6509, Acc: 0.5936, Val Loss: 0.7374, Val Acc: 0.4393
Epoch 44/100, Loss: 0.6517, Acc: 0.5920, Val Loss: 0.7324, Val Acc: 0.4449
Epoch 45/100, Loss: 0.6513, Acc: 0.5930, Val Loss: 0.7320, Val Acc: 0.4467
Epoch 46/100, Loss: 0.6511, Acc: 0.5919, Val Loss: 0.7345, Val Acc: 0.4305
Epoch 47/100, Loss: 0.6509, Acc: 0.5920, Val Loss: 0.7266, Val Acc: 0.4426
Epoch 48/100, Loss: 0.6509, Acc: 0.5916, Val Loss: 0.7200, Val Acc: 0.4544
Epoch 49/100, Loss: 0.6509, Acc: 0.5917, Val Loss: 0.7217, Val Acc: 0.4496
Epoch 50/100, Loss: 0.6504, Acc: 0.5925, Val Loss: 0.7244, Val Acc: 0.4474
Epoch 51/100, Loss: 0.6505, Acc: 0.5921, Val Loss: 0.7199, Val Acc: 0.4544
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6503, Acc: 0.5922, Val Loss: 0.7293, Val Acc: 0.4408
Epoch 53/100, Loss: 0.6503, Acc: 0.5922, Val Loss: 0.7250, Val Acc: 0.4471
Epoch 54/100, Loss: 0.6502, Acc: 0.5923, Val Loss: 0.7208, Val Acc: 0.4548
Epoch 55/100, Loss: 0.6502, Acc: 0.5916, Val Loss: 0.7249, Val Acc: 0.4463
Epoch 56/100, Loss: 0.6502, Acc: 0.5931, Val Loss: 0.7230, Val Acc: 0.4504
Epoch 57/100, Loss: 0.6501, Acc: 0.5932, Val Loss: 0.7231, Val Acc: 0.4504
Epoch 58/100, Loss: 0.6501, Acc: 0.5925, Val Loss: 0.7247, Val Acc: 0.4471
Epoch 59/100, Loss: 0.6501, Acc: 0.5919, Val Loss: 0.7243, Val Acc: 0.4489
Epoch 60/100, Loss: 0.6500, Acc: 0.5920, Val Loss: 0.7261, Val Acc: 0.4456
Epoch 61/100, Loss: 0.6500, Acc: 0.5923, Val Loss: 0.7228, Val Acc: 0.4504
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6498, Acc: 0.5923, Val Loss: 0.7238, Val Acc: 0.4485
Epoch 63/100, Loss: 0.6498, Acc: 0.5916, Val Loss: 0.7239, Val Acc: 0.4489
Epoch 64/100, Loss: 0.6498, Acc: 0.5925, Val Loss: 0.7244, Val Acc: 0.4482
Epoch 65/100, Loss: 0.6498, Acc: 0.5928, Val Loss: 0.7245, Val Acc: 0.4467
Epoch 66/100, Loss: 0.6498, Acc: 0.5929, Val Loss: 0.7223, Val Acc: 0.4515
Epoch 67/100, Loss: 0.6498, Acc: 0.5929, Val Loss: 0.7227, Val Acc: 0.4507
Epoch 68/100, Loss: 0.6498, Acc: 0.5932, Val Loss: 0.7219, Val Acc: 0.4518
Epoch 69/100, Loss: 0.6498, Acc: 0.5919, Val Loss: 0.7259, Val Acc: 0.4460
Epoch 70/100, Loss: 0.6497, Acc: 0.5924, Val Loss: 0.7252, Val Acc: 0.4467
Epoch 71/100, Loss: 0.6498, Acc: 0.5930, Val Loss: 0.7236, Val Acc: 0.4493
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6496, Acc: 0.5927, Val Loss: 0.7231, Val Acc: 0.4504
Epoch 73/100, Loss: 0.6496, Acc: 0.5923, Val Loss: 0.7239, Val Acc: 0.4489
Epoch 74/100, Loss: 0.6496, Acc: 0.5927, Val Loss: 0.7247, Val Acc: 0.4467
Epoch 75/100, Loss: 0.6496, Acc: 0.5929, Val Loss: 0.7238, Val Acc: 0.4485
Epoch 76/100, Loss: 0.6496, Acc: 0.5931, Val Loss: 0.7244, Val Acc: 0.4471
Epoch 77/100, Loss: 0.6496, Acc: 0.5931, Val Loss: 0.7233, Val Acc: 0.4496
Epoch 78/100, Loss: 0.6496, Acc: 0.5930, Val Loss: 0.7248, Val Acc: 0.4467
Epoch 79/100, Loss: 0.6495, Acc: 0.5929, Val Loss: 0.7238, Val Acc: 0.4489
Epoch 80/100, Loss: 0.6495, Acc: 0.5926, Val Loss: 0.7245, Val Acc: 0.4474
Epoch 81/100, Loss: 0.6495, Acc: 0.5924, Val Loss: 0.7254, Val Acc: 0.4460
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6495, Acc: 0.5927, Val Loss: 0.7254, Val Acc: 0.4460
Epoch 83/100, Loss: 0.6495, Acc: 0.5933, Val Loss: 0.7249, Val Acc: 0.4467
Epoch 84/100, Loss: 0.6495, Acc: 0.5931, Val Loss: 0.7234, Val Acc: 0.4493
Epoch 85/100, Loss: 0.6495, Acc: 0.5929, Val Loss: 0.7232, Val Acc: 0.4496
Epoch 86/100, Loss: 0.6495, Acc: 0.5921, Val Loss: 0.7248, Val Acc: 0.4467
Epoch 87/100, Loss: 0.6495, Acc: 0.5928, Val Loss: 0.7251, Val Acc: 0.4467
Epoch 88/100, Loss: 0.6495, Acc: 0.5928, Val Loss: 0.7230, Val Acc: 0.4496
Epoch 89/100, Loss: 0.6494, Acc: 0.5926, Val Loss: 0.7244, Val Acc: 0.4471
Epoch 90/100, Loss: 0.6495, Acc: 0.5932, Val Loss: 0.7236, Val Acc: 0.4493
Epoch 91/100, Loss: 0.6493, Acc: 0.5932, Val Loss: 0.7230, Val Acc: 0.4500
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6493, Acc: 0.5930, Val Loss: 0.7236, Val Acc: 0.4500
Epoch 93/100, Loss: 0.6492, Acc: 0.5927, Val Loss: 0.7246, Val Acc: 0.4478
Epoch 94/100, Loss: 0.6492, Acc: 0.5930, Val Loss: 0.7241, Val Acc: 0.4493
Epoch 95/100, Loss: 0.6492, Acc: 0.5928, Val Loss: 0.7237, Val Acc: 0.4500
Epoch 96/100, Loss: 0.6491, Acc: 0.5929, Val Loss: 0.7239, Val Acc: 0.4500
Epoch 97/100, Loss: 0.6491, Acc: 0.5925, Val Loss: 0.7250, Val Acc: 0.4485
Epoch 98/100, Loss: 0.6491, Acc: 0.5924, Val Loss: 0.7240, Val Acc: 0.4496
Epoch 99/100, Loss: 0.6491, Acc: 0.5925, Val Loss: 0.7245, Val Acc: 0.4493
Epoch 100/100, Loss: 0.6491, Acc: 0.5919, Val Loss: 0.7258, Val Acc: 0.4460

##############################
Resultados para principal:  073  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1 
 {'training': [0.6491016268730163, 0.5919117647058824, 0.5552852720035383, 0.9231617647058824, 0.6934548467274234], 'validate': [0.7258389328801355, 0.4459558823529412, 0.4713896457765668, 0.8904411764705882, 0.6164418427080682], 'test': [0.7005633446905348, 0.44441176470588234, 0.46751460983155724, 0.8, 0.5901497070948145]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  109  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  109  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  109  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6855, Acc: 0.5611, Val Loss: 0.7030, Val Acc: 0.4581
Mejor modelo guardado con Val Loss: 0.7030
Epoch 2/100, Loss: 0.6787, Acc: 0.5967, Val Loss: 0.7091, Val Acc: 0.4364
Epoch 3/100, Loss: 0.6730, Acc: 0.5920, Val Loss: 0.7144, Val Acc: 0.4489
Epoch 4/100, Loss: 0.6744, Acc: 0.5739, Val Loss: 0.7242, Val Acc: 0.4110
Epoch 5/100, Loss: 0.6668, Acc: 0.5976, Val Loss: 0.7318, Val Acc: 0.4327
Epoch 6/100, Loss: 0.6596, Acc: 0.6054, Val Loss: 0.7261, Val Acc: 0.4437
Epoch 7/100, Loss: 0.6608, Acc: 0.5969, Val Loss: 0.7191, Val Acc: 0.4665
Epoch 8/100, Loss: 0.6566, Acc: 0.6050, Val Loss: 0.7254, Val Acc: 0.4423
Epoch 9/100, Loss: 0.6523, Acc: 0.6099, Val Loss: 0.7287, Val Acc: 0.4632
Epoch 10/100, Loss: 0.6529, Acc: 0.6017, Val Loss: 0.7338, Val Acc: 0.4515
Epoch 11/100, Loss: 0.6514, Acc: 0.6067, Val Loss: 0.7314, Val Acc: 0.4445
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6485, Acc: 0.6131, Val Loss: 0.7339, Val Acc: 0.4562
Epoch 13/100, Loss: 0.6467, Acc: 0.6148, Val Loss: 0.7364, Val Acc: 0.4562
Epoch 14/100, Loss: 0.6464, Acc: 0.6126, Val Loss: 0.7356, Val Acc: 0.4599
Epoch 15/100, Loss: 0.6475, Acc: 0.6124, Val Loss: 0.7411, Val Acc: 0.4463
Epoch 16/100, Loss: 0.6465, Acc: 0.6117, Val Loss: 0.7293, Val Acc: 0.4632
Epoch 17/100, Loss: 0.6462, Acc: 0.6108, Val Loss: 0.7297, Val Acc: 0.4544
Epoch 18/100, Loss: 0.6480, Acc: 0.6105, Val Loss: 0.7424, Val Acc: 0.4533
Epoch 19/100, Loss: 0.6460, Acc: 0.6131, Val Loss: 0.7295, Val Acc: 0.4618
Epoch 20/100, Loss: 0.6443, Acc: 0.6124, Val Loss: 0.7399, Val Acc: 0.4533
Epoch 21/100, Loss: 0.6436, Acc: 0.6184, Val Loss: 0.7389, Val Acc: 0.4603
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6435, Acc: 0.6152, Val Loss: 0.7414, Val Acc: 0.4511
Epoch 23/100, Loss: 0.6431, Acc: 0.6151, Val Loss: 0.7466, Val Acc: 0.4474
Epoch 24/100, Loss: 0.6431, Acc: 0.6166, Val Loss: 0.7300, Val Acc: 0.4691
Epoch 25/100, Loss: 0.6437, Acc: 0.6131, Val Loss: 0.7355, Val Acc: 0.4566
Epoch 26/100, Loss: 0.6427, Acc: 0.6145, Val Loss: 0.7277, Val Acc: 0.4643
Epoch 27/100, Loss: 0.6437, Acc: 0.6149, Val Loss: 0.7414, Val Acc: 0.4588
Epoch 28/100, Loss: 0.6436, Acc: 0.6121, Val Loss: 0.7370, Val Acc: 0.4581
Epoch 29/100, Loss: 0.6428, Acc: 0.6165, Val Loss: 0.7293, Val Acc: 0.4651
Epoch 30/100, Loss: 0.6435, Acc: 0.6149, Val Loss: 0.7346, Val Acc: 0.4390
Epoch 31/100, Loss: 0.6441, Acc: 0.6131, Val Loss: 0.7403, Val Acc: 0.4570
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6415, Acc: 0.6166, Val Loss: 0.7417, Val Acc: 0.4544
Epoch 33/100, Loss: 0.6413, Acc: 0.6160, Val Loss: 0.7398, Val Acc: 0.4548
Epoch 34/100, Loss: 0.6417, Acc: 0.6165, Val Loss: 0.7428, Val Acc: 0.4540
Epoch 35/100, Loss: 0.6417, Acc: 0.6177, Val Loss: 0.7416, Val Acc: 0.4596
Epoch 36/100, Loss: 0.6413, Acc: 0.6171, Val Loss: 0.7414, Val Acc: 0.4522
Epoch 37/100, Loss: 0.6416, Acc: 0.6150, Val Loss: 0.7380, Val Acc: 0.4548
Epoch 38/100, Loss: 0.6412, Acc: 0.6168, Val Loss: 0.7424, Val Acc: 0.4511
Epoch 39/100, Loss: 0.6414, Acc: 0.6150, Val Loss: 0.7331, Val Acc: 0.4500
Epoch 40/100, Loss: 0.6411, Acc: 0.6164, Val Loss: 0.7325, Val Acc: 0.4647
Epoch 41/100, Loss: 0.6415, Acc: 0.6164, Val Loss: 0.7306, Val Acc: 0.4699
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6410, Acc: 0.6160, Val Loss: 0.7355, Val Acc: 0.4599
Epoch 43/100, Loss: 0.6408, Acc: 0.6158, Val Loss: 0.7409, Val Acc: 0.4562
Epoch 44/100, Loss: 0.6404, Acc: 0.6189, Val Loss: 0.7338, Val Acc: 0.4632
Epoch 45/100, Loss: 0.6404, Acc: 0.6170, Val Loss: 0.7382, Val Acc: 0.4537
Epoch 46/100, Loss: 0.6404, Acc: 0.6178, Val Loss: 0.7363, Val Acc: 0.4592
Epoch 47/100, Loss: 0.6401, Acc: 0.6170, Val Loss: 0.7387, Val Acc: 0.4511
Epoch 48/100, Loss: 0.6403, Acc: 0.6174, Val Loss: 0.7359, Val Acc: 0.4588
Epoch 49/100, Loss: 0.6405, Acc: 0.6183, Val Loss: 0.7346, Val Acc: 0.4585
Epoch 50/100, Loss: 0.6404, Acc: 0.6200, Val Loss: 0.7350, Val Acc: 0.4585
Epoch 51/100, Loss: 0.6403, Acc: 0.6175, Val Loss: 0.7365, Val Acc: 0.4566
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6401, Acc: 0.6170, Val Loss: 0.7383, Val Acc: 0.4559
Epoch 53/100, Loss: 0.6398, Acc: 0.6199, Val Loss: 0.7366, Val Acc: 0.4592
Epoch 54/100, Loss: 0.6401, Acc: 0.6161, Val Loss: 0.7377, Val Acc: 0.4555
Epoch 55/100, Loss: 0.6400, Acc: 0.6193, Val Loss: 0.7380, Val Acc: 0.4562
Epoch 56/100, Loss: 0.6399, Acc: 0.6185, Val Loss: 0.7390, Val Acc: 0.4562
Epoch 57/100, Loss: 0.6397, Acc: 0.6195, Val Loss: 0.7421, Val Acc: 0.4540
Epoch 58/100, Loss: 0.6399, Acc: 0.6188, Val Loss: 0.7394, Val Acc: 0.4559
Epoch 59/100, Loss: 0.6398, Acc: 0.6189, Val Loss: 0.7389, Val Acc: 0.4562
Epoch 60/100, Loss: 0.6399, Acc: 0.6181, Val Loss: 0.7382, Val Acc: 0.4562
Epoch 61/100, Loss: 0.6400, Acc: 0.6191, Val Loss: 0.7394, Val Acc: 0.4537
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6396, Acc: 0.6188, Val Loss: 0.7399, Val Acc: 0.4544
Epoch 63/100, Loss: 0.6397, Acc: 0.6182, Val Loss: 0.7393, Val Acc: 0.4555
Epoch 64/100, Loss: 0.6396, Acc: 0.6182, Val Loss: 0.7376, Val Acc: 0.4566
Epoch 65/100, Loss: 0.6395, Acc: 0.6188, Val Loss: 0.7376, Val Acc: 0.4562
Epoch 66/100, Loss: 0.6394, Acc: 0.6184, Val Loss: 0.7374, Val Acc: 0.4566
Epoch 67/100, Loss: 0.6394, Acc: 0.6185, Val Loss: 0.7377, Val Acc: 0.4562
Epoch 68/100, Loss: 0.6394, Acc: 0.6184, Val Loss: 0.7379, Val Acc: 0.4559
Epoch 69/100, Loss: 0.6394, Acc: 0.6195, Val Loss: 0.7373, Val Acc: 0.4562
Epoch 70/100, Loss: 0.6394, Acc: 0.6185, Val Loss: 0.7385, Val Acc: 0.4570
Epoch 71/100, Loss: 0.6393, Acc: 0.6190, Val Loss: 0.7373, Val Acc: 0.4559
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6393, Acc: 0.6182, Val Loss: 0.7378, Val Acc: 0.4562
Epoch 73/100, Loss: 0.6393, Acc: 0.6184, Val Loss: 0.7379, Val Acc: 0.4566
Epoch 74/100, Loss: 0.6393, Acc: 0.6188, Val Loss: 0.7379, Val Acc: 0.4566
Epoch 75/100, Loss: 0.6393, Acc: 0.6188, Val Loss: 0.7382, Val Acc: 0.4562
Epoch 76/100, Loss: 0.6393, Acc: 0.6192, Val Loss: 0.7381, Val Acc: 0.4562
Epoch 77/100, Loss: 0.6393, Acc: 0.6188, Val Loss: 0.7385, Val Acc: 0.4566
Epoch 78/100, Loss: 0.6392, Acc: 0.6188, Val Loss: 0.7377, Val Acc: 0.4566
Epoch 79/100, Loss: 0.6393, Acc: 0.6190, Val Loss: 0.7378, Val Acc: 0.4562
Epoch 80/100, Loss: 0.6393, Acc: 0.6185, Val Loss: 0.7381, Val Acc: 0.4559
Epoch 81/100, Loss: 0.6393, Acc: 0.6186, Val Loss: 0.7385, Val Acc: 0.4559
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6392, Acc: 0.6186, Val Loss: 0.7386, Val Acc: 0.4562
Epoch 83/100, Loss: 0.6392, Acc: 0.6184, Val Loss: 0.7389, Val Acc: 0.4562
Epoch 84/100, Loss: 0.6391, Acc: 0.6188, Val Loss: 0.7398, Val Acc: 0.4570
Epoch 85/100, Loss: 0.6389, Acc: 0.6188, Val Loss: 0.7412, Val Acc: 0.4562
Epoch 86/100, Loss: 0.6388, Acc: 0.6183, Val Loss: 0.7422, Val Acc: 0.4562
Epoch 87/100, Loss: 0.6388, Acc: 0.6188, Val Loss: 0.7426, Val Acc: 0.4555
Epoch 88/100, Loss: 0.6387, Acc: 0.6188, Val Loss: 0.7425, Val Acc: 0.4559
Epoch 89/100, Loss: 0.6387, Acc: 0.6183, Val Loss: 0.7426, Val Acc: 0.4562
Epoch 90/100, Loss: 0.6387, Acc: 0.6189, Val Loss: 0.7427, Val Acc: 0.4559
Epoch 91/100, Loss: 0.6387, Acc: 0.6187, Val Loss: 0.7426, Val Acc: 0.4562
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6387, Acc: 0.6189, Val Loss: 0.7417, Val Acc: 0.4555
Epoch 93/100, Loss: 0.6386, Acc: 0.6179, Val Loss: 0.7420, Val Acc: 0.4566
Epoch 94/100, Loss: 0.6386, Acc: 0.6190, Val Loss: 0.7417, Val Acc: 0.4562
Epoch 95/100, Loss: 0.6386, Acc: 0.6195, Val Loss: 0.7421, Val Acc: 0.4562
Epoch 96/100, Loss: 0.6385, Acc: 0.6195, Val Loss: 0.7419, Val Acc: 0.4562
Epoch 97/100, Loss: 0.6386, Acc: 0.6195, Val Loss: 0.7423, Val Acc: 0.4562
Epoch 98/100, Loss: 0.6385, Acc: 0.6192, Val Loss: 0.7421, Val Acc: 0.4559
Epoch 99/100, Loss: 0.6385, Acc: 0.6180, Val Loss: 0.7424, Val Acc: 0.4548
Epoch 100/100, Loss: 0.6385, Acc: 0.6190, Val Loss: 0.7425, Val Acc: 0.4555

##############################
Resultados para principal:  109  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  1 
 {'training': [0.6385201552334954, 0.6190257352941176, 0.5820971218460759, 0.8439338235294118, 0.6889772642004952], 'validate': [0.7425002400265184, 0.45551470588235293, 0.475925189017111, 0.8794117647058823, 0.6176090885618384], 'test': [0.6854040931772303, 0.57, 0.544973544973545, 0.8482352941176471, 0.6635987114588127]}

##############################
Resultados para window:  1 
 {'062:035:002:043:073:109': {'training': [0.2916217440191437, 0.8789522058823529, 0.8836776474967429, 0.8727941176470588, 0.8782021640617775], 'validate': [0.7566020655077558, 0.6551470588235294, 0.734966592427617, 0.4852941176470588, 0.5845881310894597], 'test': [0.3375696268070627, 0.8661764705882353, 0.8579643473260494, 0.8776470588235294, 0.8676940971212562]}, '035:062:002:043:073:109': {'training': [0.4506832678528393, 0.7858455882352942, 0.7588215712383488, 0.8380514705882353, 0.796470999301188], 'validate': [0.5679353943397832, 0.705514705882353, 0.6456487754038561, 0.9110294117647059, 0.7557182067703568], 'test': [0.5796618395381503, 0.7047058823529412, 0.6750503018108652, 0.7894117647058824, 0.7277657266811279]}, '002:062:035:043:073:109': {'training': [0.5491432354730719, 0.7226102941176471, 0.7189081706435285, 0.7310661764705882, 0.7249362012395187], 'validate': [0.7393857517907786, 0.5474264705882353, 0.5361749859786876, 0.7029411764705882, 0.6083359847279669], 'test': [0.6866019897990756, 0.5579411764705883, 0.5586658725431805, 0.5517647058823529, 0.5551938443326427]}, '043:062:035:002:073:109': {'training': [0.378475761588882, 0.825, 0.8327060594655626, 0.8134191176470589, 0.8229496001487818], 'validate': [0.7587504248286403, 0.6044117647058823, 0.6324626865671642, 0.4985294117647059, 0.5575657894736842], 'test': [0.4809294425778919, 0.77, 0.7208854667949952, 0.8811764705882353, 0.7930121757543674]}, '073:062:035:002:043:109': {'training': [0.6491016268730163, 0.5919117647058824, 0.5552852720035383, 0.9231617647058824, 0.6934548467274234], 'validate': [0.7258389328801355, 0.4459558823529412, 0.4713896457765668, 0.8904411764705882, 0.6164418427080682], 'test': [0.7005633446905348, 0.44441176470588234, 0.46751460983155724, 0.8, 0.5901497070948145]}, '109:062:035:002:043:073': {'training': [0.6385201552334954, 0.6190257352941176, 0.5820971218460759, 0.8439338235294118, 0.6889772642004952], 'validate': [0.7425002400265184, 0.45551470588235293, 0.475925189017111, 0.8794117647058823, 0.6176090885618384], 'test': [0.6854040931772303, 0.57, 0.544973544973545, 0.8482352941176471, 0.6635987114588127]}}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  098  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  098  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  098  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6623, Acc: 0.6181, Val Loss: 0.5974, Val Acc: 0.7945
Mejor modelo guardado con Val Loss: 0.5974
Epoch 2/100, Loss: 0.6327, Acc: 0.6467, Val Loss: 0.5489, Val Acc: 0.7963
Mejor modelo guardado con Val Loss: 0.5489
Epoch 3/100, Loss: 0.6120, Acc: 0.6574, Val Loss: 0.5463, Val Acc: 0.8007
Mejor modelo guardado con Val Loss: 0.5463
Epoch 4/100, Loss: 0.6085, Acc: 0.6579, Val Loss: 0.5256, Val Acc: 0.7989
Mejor modelo guardado con Val Loss: 0.5256
Epoch 5/100, Loss: 0.6016, Acc: 0.6608, Val Loss: 0.5073, Val Acc: 0.8026
Mejor modelo guardado con Val Loss: 0.5073
Epoch 6/100, Loss: 0.6008, Acc: 0.6630, Val Loss: 0.5227, Val Acc: 0.7923
Epoch 7/100, Loss: 0.5948, Acc: 0.6635, Val Loss: 0.4986, Val Acc: 0.8059
Mejor modelo guardado con Val Loss: 0.4986
Epoch 8/100, Loss: 0.5938, Acc: 0.6643, Val Loss: 0.5095, Val Acc: 0.7960
Epoch 9/100, Loss: 0.5926, Acc: 0.6655, Val Loss: 0.5005, Val Acc: 0.8059
Epoch 10/100, Loss: 0.5914, Acc: 0.6653, Val Loss: 0.5151, Val Acc: 0.7805
Epoch 11/100, Loss: 0.5895, Acc: 0.6645, Val Loss: 0.5220, Val Acc: 0.7739
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5874, Acc: 0.6641, Val Loss: 0.5008, Val Acc: 0.8033
Epoch 13/100, Loss: 0.5851, Acc: 0.6708, Val Loss: 0.4973, Val Acc: 0.8088
Mejor modelo guardado con Val Loss: 0.4973
Epoch 14/100, Loss: 0.5858, Acc: 0.6681, Val Loss: 0.4903, Val Acc: 0.8063
Mejor modelo guardado con Val Loss: 0.4903
Epoch 15/100, Loss: 0.5871, Acc: 0.6671, Val Loss: 0.5167, Val Acc: 0.7794
Epoch 16/100, Loss: 0.5856, Acc: 0.6696, Val Loss: 0.5053, Val Acc: 0.7956
Epoch 17/100, Loss: 0.5857, Acc: 0.6691, Val Loss: 0.5014, Val Acc: 0.8015
Epoch 18/100, Loss: 0.5857, Acc: 0.6685, Val Loss: 0.5180, Val Acc: 0.7860
Epoch 19/100, Loss: 0.5849, Acc: 0.6684, Val Loss: 0.5138, Val Acc: 0.7798
Epoch 20/100, Loss: 0.5848, Acc: 0.6696, Val Loss: 0.4924, Val Acc: 0.8063
Epoch 21/100, Loss: 0.5850, Acc: 0.6690, Val Loss: 0.5053, Val Acc: 0.7897
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5838, Acc: 0.6694, Val Loss: 0.5147, Val Acc: 0.7809
Epoch 23/100, Loss: 0.5825, Acc: 0.6726, Val Loss: 0.4993, Val Acc: 0.7893
Epoch 24/100, Loss: 0.5828, Acc: 0.6697, Val Loss: 0.5024, Val Acc: 0.7919
Epoch 25/100, Loss: 0.5822, Acc: 0.6707, Val Loss: 0.5098, Val Acc: 0.7787
Epoch 26/100, Loss: 0.5824, Acc: 0.6701, Val Loss: 0.5037, Val Acc: 0.7934
Epoch 27/100, Loss: 0.5831, Acc: 0.6707, Val Loss: 0.4981, Val Acc: 0.7967
Epoch 28/100, Loss: 0.5828, Acc: 0.6718, Val Loss: 0.5046, Val Acc: 0.7827
Epoch 29/100, Loss: 0.5818, Acc: 0.6710, Val Loss: 0.5091, Val Acc: 0.7890
Epoch 30/100, Loss: 0.5831, Acc: 0.6722, Val Loss: 0.5067, Val Acc: 0.7901
Epoch 31/100, Loss: 0.5826, Acc: 0.6708, Val Loss: 0.5287, Val Acc: 0.7577
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5820, Acc: 0.6730, Val Loss: 0.5046, Val Acc: 0.7897
Epoch 33/100, Loss: 0.5809, Acc: 0.6728, Val Loss: 0.5012, Val Acc: 0.7945
Epoch 34/100, Loss: 0.5807, Acc: 0.6726, Val Loss: 0.5015, Val Acc: 0.7901
Epoch 35/100, Loss: 0.5809, Acc: 0.6725, Val Loss: 0.5028, Val Acc: 0.7904
Epoch 36/100, Loss: 0.5809, Acc: 0.6728, Val Loss: 0.5077, Val Acc: 0.7816
Epoch 37/100, Loss: 0.5808, Acc: 0.6725, Val Loss: 0.5040, Val Acc: 0.7934
Epoch 38/100, Loss: 0.5806, Acc: 0.6733, Val Loss: 0.5094, Val Acc: 0.7824
Epoch 39/100, Loss: 0.5801, Acc: 0.6724, Val Loss: 0.5072, Val Acc: 0.7937
Epoch 40/100, Loss: 0.5789, Acc: 0.6721, Val Loss: 0.5096, Val Acc: 0.7875
Epoch 41/100, Loss: 0.5794, Acc: 0.6720, Val Loss: 0.5134, Val Acc: 0.7798
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5786, Acc: 0.6744, Val Loss: 0.5088, Val Acc: 0.7853
Epoch 43/100, Loss: 0.5774, Acc: 0.6734, Val Loss: 0.5042, Val Acc: 0.7842
Epoch 44/100, Loss: 0.5771, Acc: 0.6729, Val Loss: 0.5031, Val Acc: 0.7901
Epoch 45/100, Loss: 0.5769, Acc: 0.6733, Val Loss: 0.4989, Val Acc: 0.7960
Epoch 46/100, Loss: 0.5768, Acc: 0.6742, Val Loss: 0.5024, Val Acc: 0.7956
Epoch 47/100, Loss: 0.5765, Acc: 0.6729, Val Loss: 0.5083, Val Acc: 0.7868
Epoch 48/100, Loss: 0.5761, Acc: 0.6733, Val Loss: 0.5095, Val Acc: 0.7879
Epoch 49/100, Loss: 0.5761, Acc: 0.6730, Val Loss: 0.5156, Val Acc: 0.7713
Epoch 50/100, Loss: 0.5762, Acc: 0.6733, Val Loss: 0.5060, Val Acc: 0.7860
Epoch 51/100, Loss: 0.5755, Acc: 0.6726, Val Loss: 0.5001, Val Acc: 0.7923
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5751, Acc: 0.6730, Val Loss: 0.5047, Val Acc: 0.7882
Epoch 53/100, Loss: 0.5751, Acc: 0.6744, Val Loss: 0.5051, Val Acc: 0.7871
Epoch 54/100, Loss: 0.5750, Acc: 0.6731, Val Loss: 0.5066, Val Acc: 0.7857
Epoch 55/100, Loss: 0.5749, Acc: 0.6736, Val Loss: 0.5098, Val Acc: 0.7831
Epoch 56/100, Loss: 0.5748, Acc: 0.6740, Val Loss: 0.5059, Val Acc: 0.7890
Epoch 57/100, Loss: 0.5746, Acc: 0.6739, Val Loss: 0.5035, Val Acc: 0.7930
Epoch 58/100, Loss: 0.5745, Acc: 0.6742, Val Loss: 0.5014, Val Acc: 0.7919
Epoch 59/100, Loss: 0.5746, Acc: 0.6742, Val Loss: 0.5022, Val Acc: 0.7919
Epoch 60/100, Loss: 0.5743, Acc: 0.6744, Val Loss: 0.5075, Val Acc: 0.7886
Epoch 61/100, Loss: 0.5744, Acc: 0.6733, Val Loss: 0.5084, Val Acc: 0.7860
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5740, Acc: 0.6736, Val Loss: 0.5052, Val Acc: 0.7901
Epoch 63/100, Loss: 0.5739, Acc: 0.6742, Val Loss: 0.5062, Val Acc: 0.7890
Epoch 64/100, Loss: 0.5739, Acc: 0.6741, Val Loss: 0.5081, Val Acc: 0.7868
Epoch 65/100, Loss: 0.5738, Acc: 0.6734, Val Loss: 0.5066, Val Acc: 0.7882
Epoch 66/100, Loss: 0.5738, Acc: 0.6730, Val Loss: 0.5040, Val Acc: 0.7904
Epoch 67/100, Loss: 0.5737, Acc: 0.6737, Val Loss: 0.5074, Val Acc: 0.7860
Epoch 68/100, Loss: 0.5736, Acc: 0.6744, Val Loss: 0.5052, Val Acc: 0.7901
Epoch 69/100, Loss: 0.5737, Acc: 0.6741, Val Loss: 0.5068, Val Acc: 0.7875
Epoch 70/100, Loss: 0.5734, Acc: 0.6745, Val Loss: 0.5109, Val Acc: 0.7827
Epoch 71/100, Loss: 0.5737, Acc: 0.6738, Val Loss: 0.5107, Val Acc: 0.7853
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5734, Acc: 0.6740, Val Loss: 0.5068, Val Acc: 0.7890
Epoch 73/100, Loss: 0.5734, Acc: 0.6731, Val Loss: 0.5061, Val Acc: 0.7901
Epoch 74/100, Loss: 0.5733, Acc: 0.6738, Val Loss: 0.5061, Val Acc: 0.7901
Epoch 75/100, Loss: 0.5733, Acc: 0.6732, Val Loss: 0.5069, Val Acc: 0.7890
Epoch 76/100, Loss: 0.5731, Acc: 0.6737, Val Loss: 0.5079, Val Acc: 0.7890
Epoch 77/100, Loss: 0.5727, Acc: 0.6742, Val Loss: 0.5078, Val Acc: 0.7886
Epoch 78/100, Loss: 0.5722, Acc: 0.6762, Val Loss: 0.5088, Val Acc: 0.7864
Epoch 79/100, Loss: 0.5721, Acc: 0.6768, Val Loss: 0.5103, Val Acc: 0.7849
Epoch 80/100, Loss: 0.5720, Acc: 0.6765, Val Loss: 0.5077, Val Acc: 0.7886
Epoch 81/100, Loss: 0.5720, Acc: 0.6777, Val Loss: 0.5081, Val Acc: 0.7882
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5719, Acc: 0.6772, Val Loss: 0.5090, Val Acc: 0.7864
Epoch 83/100, Loss: 0.5719, Acc: 0.6784, Val Loss: 0.5103, Val Acc: 0.7835
Epoch 84/100, Loss: 0.5717, Acc: 0.6777, Val Loss: 0.5084, Val Acc: 0.7846
Epoch 85/100, Loss: 0.5717, Acc: 0.6784, Val Loss: 0.5080, Val Acc: 0.7871
Epoch 86/100, Loss: 0.5716, Acc: 0.6781, Val Loss: 0.5083, Val Acc: 0.7868
Epoch 87/100, Loss: 0.5716, Acc: 0.6770, Val Loss: 0.5089, Val Acc: 0.7853
Epoch 88/100, Loss: 0.5715, Acc: 0.6788, Val Loss: 0.5093, Val Acc: 0.7853
Epoch 89/100, Loss: 0.5715, Acc: 0.6780, Val Loss: 0.5095, Val Acc: 0.7849
Epoch 90/100, Loss: 0.5714, Acc: 0.6794, Val Loss: 0.5101, Val Acc: 0.7820
Epoch 91/100, Loss: 0.5714, Acc: 0.6789, Val Loss: 0.5087, Val Acc: 0.7849
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5694, Acc: 0.6858, Val Loss: 0.5115, Val Acc: 0.7761
Epoch 93/100, Loss: 0.5682, Acc: 0.6903, Val Loss: 0.5095, Val Acc: 0.7783
Epoch 94/100, Loss: 0.5683, Acc: 0.6881, Val Loss: 0.5099, Val Acc: 0.7794
Epoch 95/100, Loss: 0.5681, Acc: 0.6886, Val Loss: 0.5097, Val Acc: 0.7787
Epoch 96/100, Loss: 0.5681, Acc: 0.6894, Val Loss: 0.5101, Val Acc: 0.7783
Epoch 97/100, Loss: 0.5680, Acc: 0.6887, Val Loss: 0.5088, Val Acc: 0.7798
Epoch 98/100, Loss: 0.5680, Acc: 0.6887, Val Loss: 0.5083, Val Acc: 0.7805
Epoch 99/100, Loss: 0.5679, Acc: 0.6884, Val Loss: 0.5090, Val Acc: 0.7790
Epoch 100/100, Loss: 0.5677, Acc: 0.6890, Val Loss: 0.5079, Val Acc: 0.7805

##############################
Resultados para principal:  098  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1 
 {'training': [0.567741519037415, 0.6889705882352941, 0.6313234542667348, 0.9084558823529412, 0.7449502562556527], 'validate': [0.5079038482765819, 0.7805147058823529, 0.7347692307692307, 0.8779411764705882, 0.8], 'test': [0.6342776798539691, 0.6485294117647059, 0.6084156290253327, 0.8335294117647059, 0.7034003474807644]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  025  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  025  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  025  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6804, Acc: 0.5814, Val Loss: 0.6556, Val Acc: 0.7849
Mejor modelo guardado con Val Loss: 0.6556
Epoch 2/100, Loss: 0.6653, Acc: 0.6355, Val Loss: 0.6251, Val Acc: 0.6529
Mejor modelo guardado con Val Loss: 0.6251
Epoch 3/100, Loss: 0.6510, Acc: 0.6348, Val Loss: 0.5798, Val Acc: 0.8412
Mejor modelo guardado con Val Loss: 0.5798
Epoch 4/100, Loss: 0.6390, Acc: 0.6414, Val Loss: 0.5617, Val Acc: 0.8471
Mejor modelo guardado con Val Loss: 0.5617
Epoch 5/100, Loss: 0.6286, Acc: 0.6472, Val Loss: 0.5580, Val Acc: 0.8184
Mejor modelo guardado con Val Loss: 0.5580
Epoch 6/100, Loss: 0.6246, Acc: 0.6465, Val Loss: 0.5579, Val Acc: 0.8176
Mejor modelo guardado con Val Loss: 0.5579
Epoch 7/100, Loss: 0.6183, Acc: 0.6483, Val Loss: 0.5190, Val Acc: 0.8364
Mejor modelo guardado con Val Loss: 0.5190
Epoch 8/100, Loss: 0.6163, Acc: 0.6477, Val Loss: 0.5380, Val Acc: 0.7688
Epoch 9/100, Loss: 0.6129, Acc: 0.6482, Val Loss: 0.5042, Val Acc: 0.8371
Mejor modelo guardado con Val Loss: 0.5042
Epoch 10/100, Loss: 0.6137, Acc: 0.6484, Val Loss: 0.5104, Val Acc: 0.8430
Epoch 11/100, Loss: 0.6092, Acc: 0.6511, Val Loss: 0.4970, Val Acc: 0.8441
Mejor modelo guardado con Val Loss: 0.4970
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6070, Acc: 0.6504, Val Loss: 0.5155, Val Acc: 0.8033
Epoch 13/100, Loss: 0.6080, Acc: 0.6513, Val Loss: 0.4932, Val Acc: 0.8268
Mejor modelo guardado con Val Loss: 0.4932
Epoch 14/100, Loss: 0.6062, Acc: 0.6511, Val Loss: 0.4870, Val Acc: 0.8257
Mejor modelo guardado con Val Loss: 0.4870
Epoch 15/100, Loss: 0.6048, Acc: 0.6529, Val Loss: 0.5058, Val Acc: 0.8202
Epoch 16/100, Loss: 0.6037, Acc: 0.6562, Val Loss: 0.5178, Val Acc: 0.8007
Epoch 17/100, Loss: 0.6040, Acc: 0.6531, Val Loss: 0.4883, Val Acc: 0.8140
Epoch 18/100, Loss: 0.6030, Acc: 0.6525, Val Loss: 0.4846, Val Acc: 0.8305
Mejor modelo guardado con Val Loss: 0.4846
Epoch 19/100, Loss: 0.6027, Acc: 0.6543, Val Loss: 0.4936, Val Acc: 0.8250
Epoch 20/100, Loss: 0.6045, Acc: 0.6505, Val Loss: 0.4952, Val Acc: 0.8235
Epoch 21/100, Loss: 0.6023, Acc: 0.6540, Val Loss: 0.5218, Val Acc: 0.7901
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6017, Acc: 0.6542, Val Loss: 0.4910, Val Acc: 0.8169
Epoch 23/100, Loss: 0.6009, Acc: 0.6542, Val Loss: 0.4882, Val Acc: 0.8187
Epoch 24/100, Loss: 0.6006, Acc: 0.6551, Val Loss: 0.4992, Val Acc: 0.8037
Epoch 25/100, Loss: 0.6007, Acc: 0.6537, Val Loss: 0.4967, Val Acc: 0.8048
Epoch 26/100, Loss: 0.6004, Acc: 0.6551, Val Loss: 0.5040, Val Acc: 0.8048
Epoch 27/100, Loss: 0.6005, Acc: 0.6562, Val Loss: 0.5161, Val Acc: 0.7904
Epoch 28/100, Loss: 0.6009, Acc: 0.6554, Val Loss: 0.4943, Val Acc: 0.8114
Epoch 29/100, Loss: 0.6000, Acc: 0.6547, Val Loss: 0.4897, Val Acc: 0.8143
Epoch 30/100, Loss: 0.5997, Acc: 0.6571, Val Loss: 0.5078, Val Acc: 0.8015
Epoch 31/100, Loss: 0.5992, Acc: 0.6579, Val Loss: 0.4794, Val Acc: 0.8246
Mejor modelo guardado con Val Loss: 0.4794
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5992, Acc: 0.6559, Val Loss: 0.4936, Val Acc: 0.8081
Epoch 33/100, Loss: 0.5982, Acc: 0.6559, Val Loss: 0.4978, Val Acc: 0.8059
Epoch 34/100, Loss: 0.5974, Acc: 0.6566, Val Loss: 0.4964, Val Acc: 0.8063
Epoch 35/100, Loss: 0.5969, Acc: 0.6553, Val Loss: 0.4997, Val Acc: 0.8033
Epoch 36/100, Loss: 0.5961, Acc: 0.6562, Val Loss: 0.5129, Val Acc: 0.7882
Epoch 37/100, Loss: 0.5967, Acc: 0.6553, Val Loss: 0.4974, Val Acc: 0.8040
Epoch 38/100, Loss: 0.5958, Acc: 0.6577, Val Loss: 0.5138, Val Acc: 0.7857
Epoch 39/100, Loss: 0.5959, Acc: 0.6556, Val Loss: 0.4932, Val Acc: 0.8059
Epoch 40/100, Loss: 0.5948, Acc: 0.6581, Val Loss: 0.5194, Val Acc: 0.7824
Epoch 41/100, Loss: 0.5948, Acc: 0.6563, Val Loss: 0.4989, Val Acc: 0.8026
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5943, Acc: 0.6563, Val Loss: 0.4988, Val Acc: 0.8007
Epoch 43/100, Loss: 0.5945, Acc: 0.6566, Val Loss: 0.4981, Val Acc: 0.8022
Epoch 44/100, Loss: 0.5940, Acc: 0.6561, Val Loss: 0.4950, Val Acc: 0.8055
Epoch 45/100, Loss: 0.5937, Acc: 0.6564, Val Loss: 0.5027, Val Acc: 0.7993
Epoch 46/100, Loss: 0.5937, Acc: 0.6572, Val Loss: 0.5000, Val Acc: 0.8007
Epoch 47/100, Loss: 0.5931, Acc: 0.6573, Val Loss: 0.4988, Val Acc: 0.8000
Epoch 48/100, Loss: 0.5931, Acc: 0.6574, Val Loss: 0.5014, Val Acc: 0.7993
Epoch 49/100, Loss: 0.5925, Acc: 0.6569, Val Loss: 0.5080, Val Acc: 0.7989
Epoch 50/100, Loss: 0.5921, Acc: 0.6568, Val Loss: 0.5047, Val Acc: 0.7982
Epoch 51/100, Loss: 0.5919, Acc: 0.6567, Val Loss: 0.5099, Val Acc: 0.7949
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5913, Acc: 0.6575, Val Loss: 0.5056, Val Acc: 0.7963
Epoch 53/100, Loss: 0.5913, Acc: 0.6567, Val Loss: 0.4999, Val Acc: 0.8015
Epoch 54/100, Loss: 0.5911, Acc: 0.6572, Val Loss: 0.5063, Val Acc: 0.7967
Epoch 55/100, Loss: 0.5909, Acc: 0.6563, Val Loss: 0.5051, Val Acc: 0.7956
Epoch 56/100, Loss: 0.5908, Acc: 0.6576, Val Loss: 0.5009, Val Acc: 0.7996
Epoch 57/100, Loss: 0.5908, Acc: 0.6579, Val Loss: 0.5006, Val Acc: 0.8007
Epoch 58/100, Loss: 0.5907, Acc: 0.6567, Val Loss: 0.5086, Val Acc: 0.7952
Epoch 59/100, Loss: 0.5904, Acc: 0.6583, Val Loss: 0.5054, Val Acc: 0.7967
Epoch 60/100, Loss: 0.5904, Acc: 0.6564, Val Loss: 0.5133, Val Acc: 0.7926
Epoch 61/100, Loss: 0.5903, Acc: 0.6584, Val Loss: 0.5030, Val Acc: 0.7960
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5900, Acc: 0.6575, Val Loss: 0.5056, Val Acc: 0.7952
Epoch 63/100, Loss: 0.5899, Acc: 0.6563, Val Loss: 0.5031, Val Acc: 0.7982
Epoch 64/100, Loss: 0.5899, Acc: 0.6576, Val Loss: 0.5031, Val Acc: 0.7982
Epoch 65/100, Loss: 0.5899, Acc: 0.6573, Val Loss: 0.5053, Val Acc: 0.7960
Epoch 66/100, Loss: 0.5898, Acc: 0.6577, Val Loss: 0.5032, Val Acc: 0.7971
Epoch 67/100, Loss: 0.5898, Acc: 0.6578, Val Loss: 0.5048, Val Acc: 0.7960
Epoch 68/100, Loss: 0.5897, Acc: 0.6583, Val Loss: 0.5055, Val Acc: 0.7956
Epoch 69/100, Loss: 0.5897, Acc: 0.6580, Val Loss: 0.5058, Val Acc: 0.7949
Epoch 70/100, Loss: 0.5895, Acc: 0.6578, Val Loss: 0.5036, Val Acc: 0.7963
Epoch 71/100, Loss: 0.5895, Acc: 0.6583, Val Loss: 0.5036, Val Acc: 0.7971
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5894, Acc: 0.6580, Val Loss: 0.5056, Val Acc: 0.7956
Epoch 73/100, Loss: 0.5894, Acc: 0.6579, Val Loss: 0.5046, Val Acc: 0.7952
Epoch 74/100, Loss: 0.5893, Acc: 0.6580, Val Loss: 0.5041, Val Acc: 0.7971
Epoch 75/100, Loss: 0.5893, Acc: 0.6580, Val Loss: 0.5044, Val Acc: 0.7967
Epoch 76/100, Loss: 0.5892, Acc: 0.6580, Val Loss: 0.5043, Val Acc: 0.7960
Epoch 77/100, Loss: 0.5892, Acc: 0.6576, Val Loss: 0.5035, Val Acc: 0.7967
Epoch 78/100, Loss: 0.5892, Acc: 0.6583, Val Loss: 0.5042, Val Acc: 0.7960
Epoch 79/100, Loss: 0.5891, Acc: 0.6577, Val Loss: 0.5053, Val Acc: 0.7956
Epoch 80/100, Loss: 0.5890, Acc: 0.6583, Val Loss: 0.5059, Val Acc: 0.7956
Epoch 81/100, Loss: 0.5890, Acc: 0.6574, Val Loss: 0.5047, Val Acc: 0.7956
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5890, Acc: 0.6576, Val Loss: 0.5050, Val Acc: 0.7963
Epoch 83/100, Loss: 0.5889, Acc: 0.6578, Val Loss: 0.5045, Val Acc: 0.7960
Epoch 84/100, Loss: 0.5889, Acc: 0.6577, Val Loss: 0.5042, Val Acc: 0.7960
Epoch 85/100, Loss: 0.5889, Acc: 0.6578, Val Loss: 0.5056, Val Acc: 0.7960
Epoch 86/100, Loss: 0.5888, Acc: 0.6576, Val Loss: 0.5052, Val Acc: 0.7956
Epoch 87/100, Loss: 0.5888, Acc: 0.6575, Val Loss: 0.5046, Val Acc: 0.7967
Epoch 88/100, Loss: 0.5888, Acc: 0.6577, Val Loss: 0.5043, Val Acc: 0.7949
Epoch 89/100, Loss: 0.5887, Acc: 0.6578, Val Loss: 0.5050, Val Acc: 0.7952
Epoch 90/100, Loss: 0.5886, Acc: 0.6574, Val Loss: 0.5041, Val Acc: 0.7967
Epoch 91/100, Loss: 0.5887, Acc: 0.6571, Val Loss: 0.5047, Val Acc: 0.7945
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5886, Acc: 0.6576, Val Loss: 0.5060, Val Acc: 0.7960
Epoch 93/100, Loss: 0.5886, Acc: 0.6580, Val Loss: 0.5060, Val Acc: 0.7949
Epoch 94/100, Loss: 0.5885, Acc: 0.6576, Val Loss: 0.5053, Val Acc: 0.7945
Epoch 95/100, Loss: 0.5885, Acc: 0.6576, Val Loss: 0.5047, Val Acc: 0.7949
Epoch 96/100, Loss: 0.5884, Acc: 0.6581, Val Loss: 0.5041, Val Acc: 0.7949
Epoch 97/100, Loss: 0.5885, Acc: 0.6576, Val Loss: 0.5045, Val Acc: 0.7956
Epoch 98/100, Loss: 0.5884, Acc: 0.6585, Val Loss: 0.5059, Val Acc: 0.7960
Epoch 99/100, Loss: 0.5884, Acc: 0.6579, Val Loss: 0.5060, Val Acc: 0.7960
Epoch 100/100, Loss: 0.5883, Acc: 0.6579, Val Loss: 0.5062, Val Acc: 0.7956

##############################
Resultados para principal:  025  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1 
 {'training': [0.5882952413138222, 0.6579044117647059, 0.6051922605927015, 0.9084558823529412, 0.7264442157871527], 'validate': [0.5061746080254399, 0.7955882352941176, 0.7620599739243807, 0.8595588235294118, 0.8078783690393918], 'test': [0.6516661450818733, 0.611764705882353, 0.5725190839694656, 0.8823529411764706, 0.6944444444444444]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  059  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  059  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  059  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6161, Acc: 0.6870, Val Loss: 0.4109, Val Acc: 0.9187
Mejor modelo guardado con Val Loss: 0.4109
Epoch 2/100, Loss: 0.5721, Acc: 0.6993, Val Loss: 0.3480, Val Acc: 0.9246
Mejor modelo guardado con Val Loss: 0.3480
Epoch 3/100, Loss: 0.5483, Acc: 0.7086, Val Loss: 0.3059, Val Acc: 0.9213
Mejor modelo guardado con Val Loss: 0.3059
Epoch 4/100, Loss: 0.5404, Acc: 0.7095, Val Loss: 0.2897, Val Acc: 0.9290
Mejor modelo guardado con Val Loss: 0.2897
Epoch 5/100, Loss: 0.5419, Acc: 0.7121, Val Loss: 0.3425, Val Acc: 0.8923
Epoch 6/100, Loss: 0.5363, Acc: 0.7132, Val Loss: 0.2946, Val Acc: 0.9199
Epoch 7/100, Loss: 0.5406, Acc: 0.7128, Val Loss: 0.2824, Val Acc: 0.9287
Mejor modelo guardado con Val Loss: 0.2824
Epoch 8/100, Loss: 0.5332, Acc: 0.7137, Val Loss: 0.2871, Val Acc: 0.9074
Epoch 9/100, Loss: 0.5289, Acc: 0.7148, Val Loss: 0.2587, Val Acc: 0.9309
Mejor modelo guardado con Val Loss: 0.2587
Epoch 10/100, Loss: 0.5286, Acc: 0.7131, Val Loss: 0.2861, Val Acc: 0.9169
Epoch 11/100, Loss: 0.5292, Acc: 0.7136, Val Loss: 0.2958, Val Acc: 0.9265
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5216, Acc: 0.7217, Val Loss: 0.2602, Val Acc: 0.9243
Epoch 13/100, Loss: 0.5205, Acc: 0.7144, Val Loss: 0.2579, Val Acc: 0.9154
Mejor modelo guardado con Val Loss: 0.2579
Epoch 14/100, Loss: 0.5163, Acc: 0.7237, Val Loss: 0.2753, Val Acc: 0.8963
Epoch 15/100, Loss: 0.5165, Acc: 0.7205, Val Loss: 0.2544, Val Acc: 0.9246
Mejor modelo guardado con Val Loss: 0.2544
Epoch 16/100, Loss: 0.5186, Acc: 0.7170, Val Loss: 0.2442, Val Acc: 0.9184
Mejor modelo guardado con Val Loss: 0.2442
Epoch 17/100, Loss: 0.5169, Acc: 0.7203, Val Loss: 0.2659, Val Acc: 0.9029
Epoch 18/100, Loss: 0.5169, Acc: 0.7241, Val Loss: 0.2554, Val Acc: 0.9055
Epoch 19/100, Loss: 0.5169, Acc: 0.7165, Val Loss: 0.2529, Val Acc: 0.9107
Epoch 20/100, Loss: 0.5157, Acc: 0.7179, Val Loss: 0.2427, Val Acc: 0.9228
Mejor modelo guardado con Val Loss: 0.2427
Epoch 21/100, Loss: 0.5154, Acc: 0.7208, Val Loss: 0.2539, Val Acc: 0.9066
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5121, Acc: 0.7213, Val Loss: 0.2452, Val Acc: 0.9165
Epoch 23/100, Loss: 0.5112, Acc: 0.7225, Val Loss: 0.2493, Val Acc: 0.9096
Epoch 24/100, Loss: 0.5097, Acc: 0.7251, Val Loss: 0.2525, Val Acc: 0.9062
Epoch 25/100, Loss: 0.5112, Acc: 0.7213, Val Loss: 0.2310, Val Acc: 0.9228
Mejor modelo guardado con Val Loss: 0.2310
Epoch 26/100, Loss: 0.5098, Acc: 0.7222, Val Loss: 0.2336, Val Acc: 0.9081
Epoch 27/100, Loss: 0.5114, Acc: 0.7205, Val Loss: 0.2389, Val Acc: 0.9118
Epoch 28/100, Loss: 0.5106, Acc: 0.7215, Val Loss: 0.2158, Val Acc: 0.9254
Mejor modelo guardado con Val Loss: 0.2158
Epoch 29/100, Loss: 0.5104, Acc: 0.7216, Val Loss: 0.2426, Val Acc: 0.9048
Epoch 30/100, Loss: 0.5103, Acc: 0.7218, Val Loss: 0.2587, Val Acc: 0.8956
Epoch 31/100, Loss: 0.5090, Acc: 0.7216, Val Loss: 0.2328, Val Acc: 0.9235
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5075, Acc: 0.7238, Val Loss: 0.2298, Val Acc: 0.9092
Epoch 33/100, Loss: 0.5068, Acc: 0.7249, Val Loss: 0.2338, Val Acc: 0.9077
Epoch 34/100, Loss: 0.5070, Acc: 0.7249, Val Loss: 0.2267, Val Acc: 0.9287
Epoch 35/100, Loss: 0.5063, Acc: 0.7255, Val Loss: 0.2341, Val Acc: 0.9250
Epoch 36/100, Loss: 0.5067, Acc: 0.7243, Val Loss: 0.2282, Val Acc: 0.9165
Epoch 37/100, Loss: 0.5062, Acc: 0.7247, Val Loss: 0.2277, Val Acc: 0.9246
Epoch 38/100, Loss: 0.5063, Acc: 0.7241, Val Loss: 0.2288, Val Acc: 0.9136
Epoch 39/100, Loss: 0.5053, Acc: 0.7243, Val Loss: 0.2361, Val Acc: 0.9129
Epoch 40/100, Loss: 0.5048, Acc: 0.7265, Val Loss: 0.2391, Val Acc: 0.9085
Epoch 41/100, Loss: 0.5051, Acc: 0.7244, Val Loss: 0.2274, Val Acc: 0.9184
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5041, Acc: 0.7264, Val Loss: 0.2357, Val Acc: 0.9092
Epoch 43/100, Loss: 0.5035, Acc: 0.7259, Val Loss: 0.2357, Val Acc: 0.9103
Epoch 44/100, Loss: 0.5041, Acc: 0.7256, Val Loss: 0.2334, Val Acc: 0.9140
Epoch 45/100, Loss: 0.5037, Acc: 0.7256, Val Loss: 0.2364, Val Acc: 0.9081
Epoch 46/100, Loss: 0.5035, Acc: 0.7242, Val Loss: 0.2313, Val Acc: 0.9136
Epoch 47/100, Loss: 0.5031, Acc: 0.7262, Val Loss: 0.2371, Val Acc: 0.9110
Epoch 48/100, Loss: 0.5032, Acc: 0.7292, Val Loss: 0.2311, Val Acc: 0.9180
Epoch 49/100, Loss: 0.5027, Acc: 0.7259, Val Loss: 0.2370, Val Acc: 0.9118
Epoch 50/100, Loss: 0.5028, Acc: 0.7265, Val Loss: 0.2304, Val Acc: 0.9151
Epoch 51/100, Loss: 0.5027, Acc: 0.7271, Val Loss: 0.2326, Val Acc: 0.9129
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5016, Acc: 0.7278, Val Loss: 0.2243, Val Acc: 0.9199
Epoch 53/100, Loss: 0.5019, Acc: 0.7267, Val Loss: 0.2353, Val Acc: 0.9129
Epoch 54/100, Loss: 0.5018, Acc: 0.7274, Val Loss: 0.2292, Val Acc: 0.9173
Epoch 55/100, Loss: 0.5019, Acc: 0.7279, Val Loss: 0.2323, Val Acc: 0.9140
Epoch 56/100, Loss: 0.5018, Acc: 0.7265, Val Loss: 0.2275, Val Acc: 0.9173
Epoch 57/100, Loss: 0.5019, Acc: 0.7268, Val Loss: 0.2316, Val Acc: 0.9151
Epoch 58/100, Loss: 0.5015, Acc: 0.7276, Val Loss: 0.2306, Val Acc: 0.9147
Epoch 59/100, Loss: 0.5016, Acc: 0.7277, Val Loss: 0.2311, Val Acc: 0.9132
Epoch 60/100, Loss: 0.5014, Acc: 0.7267, Val Loss: 0.2312, Val Acc: 0.9147
Epoch 61/100, Loss: 0.5012, Acc: 0.7268, Val Loss: 0.2271, Val Acc: 0.9180
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5012, Acc: 0.7257, Val Loss: 0.2306, Val Acc: 0.9147
Epoch 63/100, Loss: 0.5010, Acc: 0.7258, Val Loss: 0.2290, Val Acc: 0.9151
Epoch 64/100, Loss: 0.5009, Acc: 0.7267, Val Loss: 0.2295, Val Acc: 0.9165
Epoch 65/100, Loss: 0.5009, Acc: 0.7267, Val Loss: 0.2318, Val Acc: 0.9140
Epoch 66/100, Loss: 0.5010, Acc: 0.7278, Val Loss: 0.2314, Val Acc: 0.9147
Epoch 67/100, Loss: 0.5010, Acc: 0.7266, Val Loss: 0.2309, Val Acc: 0.9140
Epoch 68/100, Loss: 0.5008, Acc: 0.7262, Val Loss: 0.2293, Val Acc: 0.9158
Epoch 69/100, Loss: 0.5008, Acc: 0.7271, Val Loss: 0.2313, Val Acc: 0.9151
Epoch 70/100, Loss: 0.5008, Acc: 0.7277, Val Loss: 0.2305, Val Acc: 0.9151
Epoch 71/100, Loss: 0.5008, Acc: 0.7266, Val Loss: 0.2304, Val Acc: 0.9143
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5007, Acc: 0.7273, Val Loss: 0.2296, Val Acc: 0.9151
Epoch 73/100, Loss: 0.5006, Acc: 0.7269, Val Loss: 0.2298, Val Acc: 0.9151
Epoch 74/100, Loss: 0.5006, Acc: 0.7263, Val Loss: 0.2297, Val Acc: 0.9151
Epoch 75/100, Loss: 0.5006, Acc: 0.7267, Val Loss: 0.2302, Val Acc: 0.9143
Epoch 76/100, Loss: 0.5006, Acc: 0.7264, Val Loss: 0.2311, Val Acc: 0.9147
Epoch 77/100, Loss: 0.5006, Acc: 0.7268, Val Loss: 0.2306, Val Acc: 0.9147
Epoch 78/100, Loss: 0.5005, Acc: 0.7260, Val Loss: 0.2293, Val Acc: 0.9154
Epoch 79/100, Loss: 0.5006, Acc: 0.7273, Val Loss: 0.2314, Val Acc: 0.9143
Epoch 80/100, Loss: 0.5006, Acc: 0.7269, Val Loss: 0.2312, Val Acc: 0.9147
Epoch 81/100, Loss: 0.5004, Acc: 0.7263, Val Loss: 0.2297, Val Acc: 0.9154
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5006, Acc: 0.7270, Val Loss: 0.2293, Val Acc: 0.9151
Epoch 83/100, Loss: 0.5005, Acc: 0.7266, Val Loss: 0.2295, Val Acc: 0.9151
Epoch 84/100, Loss: 0.5005, Acc: 0.7268, Val Loss: 0.2291, Val Acc: 0.9151
Epoch 85/100, Loss: 0.5004, Acc: 0.7265, Val Loss: 0.2315, Val Acc: 0.9132
Epoch 86/100, Loss: 0.5004, Acc: 0.7261, Val Loss: 0.2297, Val Acc: 0.9151
Epoch 87/100, Loss: 0.5005, Acc: 0.7268, Val Loss: 0.2290, Val Acc: 0.9154
Epoch 88/100, Loss: 0.5005, Acc: 0.7267, Val Loss: 0.2304, Val Acc: 0.9147
Epoch 89/100, Loss: 0.5005, Acc: 0.7266, Val Loss: 0.2317, Val Acc: 0.9136
Epoch 90/100, Loss: 0.5004, Acc: 0.7265, Val Loss: 0.2311, Val Acc: 0.9136
Epoch 91/100, Loss: 0.5004, Acc: 0.7273, Val Loss: 0.2301, Val Acc: 0.9151
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5003, Acc: 0.7265, Val Loss: 0.2290, Val Acc: 0.9158
Epoch 93/100, Loss: 0.5004, Acc: 0.7265, Val Loss: 0.2288, Val Acc: 0.9173
Epoch 94/100, Loss: 0.5003, Acc: 0.7265, Val Loss: 0.2296, Val Acc: 0.9154
Epoch 95/100, Loss: 0.5003, Acc: 0.7271, Val Loss: 0.2307, Val Acc: 0.9143
Epoch 96/100, Loss: 0.5003, Acc: 0.7266, Val Loss: 0.2307, Val Acc: 0.9136
Epoch 97/100, Loss: 0.5003, Acc: 0.7269, Val Loss: 0.2310, Val Acc: 0.9140
Epoch 98/100, Loss: 0.5002, Acc: 0.7267, Val Loss: 0.2313, Val Acc: 0.9132
Epoch 99/100, Loss: 0.5002, Acc: 0.7284, Val Loss: 0.2271, Val Acc: 0.9173
Epoch 100/100, Loss: 0.5002, Acc: 0.7276, Val Loss: 0.2294, Val Acc: 0.9162

##############################
Resultados para principal:  059  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1 
 {'training': [0.5002394888330909, 0.7275735294117647, 0.7411375146084924, 0.6994485294117647, 0.7196898051825231], 'validate': [0.22943367796062036, 0.9161764705882353, 0.9956217162872154, 0.8360294117647059, 0.9088729016786571], 'test': [0.545316674505119, 0.7205882352941176, 0.6729704797047971, 0.8582352941176471, 0.7543950361944157]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  121  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  121  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  121  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4955, Acc: 0.8256, Val Loss: 0.7527, Val Acc: 0.5522
Mejor modelo guardado con Val Loss: 0.7527
Epoch 2/100, Loss: 0.3598, Acc: 0.8627, Val Loss: 0.8909, Val Acc: 0.5445
Epoch 3/100, Loss: 0.3166, Acc: 0.8757, Val Loss: 1.0451, Val Acc: 0.5445
Epoch 4/100, Loss: 0.3112, Acc: 0.8720, Val Loss: 1.0324, Val Acc: 0.5246
Epoch 5/100, Loss: 0.3071, Acc: 0.8733, Val Loss: 1.0328, Val Acc: 0.5735
Epoch 6/100, Loss: 0.3063, Acc: 0.8758, Val Loss: 1.1618, Val Acc: 0.5210
Epoch 7/100, Loss: 0.3076, Acc: 0.8750, Val Loss: 1.0576, Val Acc: 0.5335
Epoch 8/100, Loss: 0.3044, Acc: 0.8715, Val Loss: 0.9937, Val Acc: 0.5835
Epoch 9/100, Loss: 0.3021, Acc: 0.8744, Val Loss: 1.0351, Val Acc: 0.5540
Epoch 10/100, Loss: 0.3104, Acc: 0.8724, Val Loss: 1.1050, Val Acc: 0.5368
Epoch 11/100, Loss: 0.3062, Acc: 0.8736, Val Loss: 0.9899, Val Acc: 0.5566
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2967, Acc: 0.8750, Val Loss: 1.0564, Val Acc: 0.5467
Epoch 13/100, Loss: 0.2958, Acc: 0.8783, Val Loss: 1.1220, Val Acc: 0.5526
Epoch 14/100, Loss: 0.2945, Acc: 0.8778, Val Loss: 1.1692, Val Acc: 0.5426
Epoch 15/100, Loss: 0.2993, Acc: 0.8755, Val Loss: 1.0374, Val Acc: 0.5647
Epoch 16/100, Loss: 0.2982, Acc: 0.8758, Val Loss: 1.0846, Val Acc: 0.5309
Epoch 17/100, Loss: 0.2938, Acc: 0.8803, Val Loss: 1.1761, Val Acc: 0.5522
Epoch 18/100, Loss: 0.2956, Acc: 0.8757, Val Loss: 1.1492, Val Acc: 0.5401
Epoch 19/100, Loss: 0.2970, Acc: 0.8757, Val Loss: 1.0736, Val Acc: 0.5393
Epoch 20/100, Loss: 0.2993, Acc: 0.8744, Val Loss: 0.9897, Val Acc: 0.5658
Epoch 21/100, Loss: 0.2965, Acc: 0.8772, Val Loss: 0.9878, Val Acc: 0.5676
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2938, Acc: 0.8783, Val Loss: 1.1021, Val Acc: 0.5496
Epoch 23/100, Loss: 0.2917, Acc: 0.8789, Val Loss: 1.0617, Val Acc: 0.5577
Epoch 24/100, Loss: 0.2926, Acc: 0.8756, Val Loss: 1.1663, Val Acc: 0.5276
Epoch 25/100, Loss: 0.2924, Acc: 0.8801, Val Loss: 1.0159, Val Acc: 0.5456
Epoch 26/100, Loss: 0.2913, Acc: 0.8783, Val Loss: 1.2073, Val Acc: 0.5471
Epoch 27/100, Loss: 0.2909, Acc: 0.8792, Val Loss: 1.0603, Val Acc: 0.5533
Epoch 28/100, Loss: 0.2906, Acc: 0.8803, Val Loss: 1.1167, Val Acc: 0.5555
Epoch 29/100, Loss: 0.2905, Acc: 0.8784, Val Loss: 1.0477, Val Acc: 0.5651
Epoch 30/100, Loss: 0.2924, Acc: 0.8790, Val Loss: 1.1845, Val Acc: 0.5397
Epoch 31/100, Loss: 0.2925, Acc: 0.8755, Val Loss: 1.1344, Val Acc: 0.5437
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2877, Acc: 0.8801, Val Loss: 1.2070, Val Acc: 0.5419
Epoch 33/100, Loss: 0.2881, Acc: 0.8794, Val Loss: 1.0932, Val Acc: 0.5327
Epoch 34/100, Loss: 0.2889, Acc: 0.8803, Val Loss: 1.0632, Val Acc: 0.5504
Epoch 35/100, Loss: 0.2882, Acc: 0.8798, Val Loss: 1.1027, Val Acc: 0.5504
Epoch 36/100, Loss: 0.2886, Acc: 0.8792, Val Loss: 1.0443, Val Acc: 0.5390
Epoch 37/100, Loss: 0.2887, Acc: 0.8798, Val Loss: 1.1747, Val Acc: 0.5452
Epoch 38/100, Loss: 0.2879, Acc: 0.8812, Val Loss: 1.0691, Val Acc: 0.5478
Epoch 39/100, Loss: 0.2879, Acc: 0.8797, Val Loss: 1.1110, Val Acc: 0.5478
Epoch 40/100, Loss: 0.2871, Acc: 0.8802, Val Loss: 1.0751, Val Acc: 0.5482
Epoch 41/100, Loss: 0.2864, Acc: 0.8790, Val Loss: 1.0894, Val Acc: 0.5441
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2854, Acc: 0.8812, Val Loss: 1.1524, Val Acc: 0.5412
Epoch 43/100, Loss: 0.2847, Acc: 0.8804, Val Loss: 1.1406, Val Acc: 0.5360
Epoch 44/100, Loss: 0.2852, Acc: 0.8809, Val Loss: 1.0950, Val Acc: 0.5474
Epoch 45/100, Loss: 0.2851, Acc: 0.8804, Val Loss: 1.1307, Val Acc: 0.5386
Epoch 46/100, Loss: 0.2848, Acc: 0.8807, Val Loss: 1.0620, Val Acc: 0.5522
Epoch 47/100, Loss: 0.2848, Acc: 0.8821, Val Loss: 1.0959, Val Acc: 0.5386
Epoch 48/100, Loss: 0.2851, Acc: 0.8798, Val Loss: 1.0926, Val Acc: 0.5456
Epoch 49/100, Loss: 0.2850, Acc: 0.8801, Val Loss: 1.1259, Val Acc: 0.5390
Epoch 50/100, Loss: 0.2841, Acc: 0.8812, Val Loss: 1.1393, Val Acc: 0.5515
Epoch 51/100, Loss: 0.2851, Acc: 0.8805, Val Loss: 1.1383, Val Acc: 0.5456
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2838, Acc: 0.8810, Val Loss: 1.1371, Val Acc: 0.5415
Epoch 53/100, Loss: 0.2838, Acc: 0.8809, Val Loss: 1.1169, Val Acc: 0.5426
Epoch 54/100, Loss: 0.2839, Acc: 0.8813, Val Loss: 1.1030, Val Acc: 0.5423
Epoch 55/100, Loss: 0.2836, Acc: 0.8811, Val Loss: 1.1005, Val Acc: 0.5390
Epoch 56/100, Loss: 0.2837, Acc: 0.8815, Val Loss: 1.0981, Val Acc: 0.5426
Epoch 57/100, Loss: 0.2835, Acc: 0.8813, Val Loss: 1.1028, Val Acc: 0.5426
Epoch 58/100, Loss: 0.2836, Acc: 0.8814, Val Loss: 1.1102, Val Acc: 0.5434
Epoch 59/100, Loss: 0.2837, Acc: 0.8809, Val Loss: 1.1427, Val Acc: 0.5379
Epoch 60/100, Loss: 0.2837, Acc: 0.8804, Val Loss: 1.1088, Val Acc: 0.5430
Epoch 61/100, Loss: 0.2832, Acc: 0.8801, Val Loss: 1.1044, Val Acc: 0.5496
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2830, Acc: 0.8815, Val Loss: 1.1442, Val Acc: 0.5393
Epoch 63/100, Loss: 0.2830, Acc: 0.8819, Val Loss: 1.1264, Val Acc: 0.5412
Epoch 64/100, Loss: 0.2829, Acc: 0.8810, Val Loss: 1.1037, Val Acc: 0.5445
Epoch 65/100, Loss: 0.2829, Acc: 0.8815, Val Loss: 1.1219, Val Acc: 0.5408
Epoch 66/100, Loss: 0.2830, Acc: 0.8817, Val Loss: 1.1034, Val Acc: 0.5441
Epoch 67/100, Loss: 0.2828, Acc: 0.8816, Val Loss: 1.1192, Val Acc: 0.5426
Epoch 68/100, Loss: 0.2828, Acc: 0.8822, Val Loss: 1.1228, Val Acc: 0.5430
Epoch 69/100, Loss: 0.2828, Acc: 0.8810, Val Loss: 1.1041, Val Acc: 0.5423
Epoch 70/100, Loss: 0.2829, Acc: 0.8817, Val Loss: 1.1177, Val Acc: 0.5423
Epoch 71/100, Loss: 0.2828, Acc: 0.8806, Val Loss: 1.1244, Val Acc: 0.5441
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2827, Acc: 0.8813, Val Loss: 1.1246, Val Acc: 0.5437
Epoch 73/100, Loss: 0.2827, Acc: 0.8821, Val Loss: 1.1056, Val Acc: 0.5437
Epoch 74/100, Loss: 0.2826, Acc: 0.8813, Val Loss: 1.1159, Val Acc: 0.5445
Epoch 75/100, Loss: 0.2826, Acc: 0.8818, Val Loss: 1.1224, Val Acc: 0.5426
Epoch 76/100, Loss: 0.2826, Acc: 0.8810, Val Loss: 1.1282, Val Acc: 0.5415
Epoch 77/100, Loss: 0.2826, Acc: 0.8812, Val Loss: 1.1162, Val Acc: 0.5426
Epoch 78/100, Loss: 0.2825, Acc: 0.8823, Val Loss: 1.1143, Val Acc: 0.5426
Epoch 79/100, Loss: 0.2826, Acc: 0.8814, Val Loss: 1.1177, Val Acc: 0.5426
Epoch 80/100, Loss: 0.2826, Acc: 0.8817, Val Loss: 1.1229, Val Acc: 0.5434
Epoch 81/100, Loss: 0.2825, Acc: 0.8824, Val Loss: 1.1220, Val Acc: 0.5415
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2825, Acc: 0.8810, Val Loss: 1.1244, Val Acc: 0.5390
Epoch 83/100, Loss: 0.2825, Acc: 0.8811, Val Loss: 1.1097, Val Acc: 0.5434
Epoch 84/100, Loss: 0.2825, Acc: 0.8812, Val Loss: 1.1177, Val Acc: 0.5430
Epoch 85/100, Loss: 0.2826, Acc: 0.8812, Val Loss: 1.1159, Val Acc: 0.5419
Epoch 86/100, Loss: 0.2826, Acc: 0.8812, Val Loss: 1.1217, Val Acc: 0.5415
Epoch 87/100, Loss: 0.2825, Acc: 0.8804, Val Loss: 1.1241, Val Acc: 0.5419
Epoch 88/100, Loss: 0.2826, Acc: 0.8813, Val Loss: 1.1123, Val Acc: 0.5430
Epoch 89/100, Loss: 0.2825, Acc: 0.8819, Val Loss: 1.1125, Val Acc: 0.5434
Epoch 90/100, Loss: 0.2825, Acc: 0.8819, Val Loss: 1.1241, Val Acc: 0.5412
Epoch 91/100, Loss: 0.2824, Acc: 0.8818, Val Loss: 1.1183, Val Acc: 0.5426
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2824, Acc: 0.8819, Val Loss: 1.1207, Val Acc: 0.5404
Epoch 93/100, Loss: 0.2825, Acc: 0.8816, Val Loss: 1.1214, Val Acc: 0.5426
Epoch 94/100, Loss: 0.2824, Acc: 0.8816, Val Loss: 1.1176, Val Acc: 0.5430
Epoch 95/100, Loss: 0.2824, Acc: 0.8818, Val Loss: 1.1125, Val Acc: 0.5426
Epoch 96/100, Loss: 0.2824, Acc: 0.8814, Val Loss: 1.1133, Val Acc: 0.5434
Epoch 97/100, Loss: 0.2823, Acc: 0.8811, Val Loss: 1.1273, Val Acc: 0.5412
Epoch 98/100, Loss: 0.2823, Acc: 0.8813, Val Loss: 1.1171, Val Acc: 0.5430
Epoch 99/100, Loss: 0.2824, Acc: 0.8812, Val Loss: 1.1214, Val Acc: 0.5437
Epoch 100/100, Loss: 0.2823, Acc: 0.8810, Val Loss: 1.1179, Val Acc: 0.5426

##############################
Resultados para principal:  121  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1 
 {'training': [0.2823474044308943, 0.8809742647058824, 0.8757932910244787, 0.8878676470588235, 0.8817891373801917], 'validate': [1.117939796905185, 0.5426470588235294, 0.5251517779705117, 0.8904411764705882, 0.6606655755591926], 'test': [0.4701758998411673, 0.7947058823529412, 0.8058608058608059, 0.7764705882352941, 0.7908927501497903]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  107  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  107  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  107  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4856, Acc: 0.8289, Val Loss: 1.0900, Val Acc: 0.4121
Mejor modelo guardado con Val Loss: 1.0900
Epoch 2/100, Loss: 0.3418, Acc: 0.8723, Val Loss: 1.3524, Val Acc: 0.4077
Epoch 3/100, Loss: 0.3153, Acc: 0.8752, Val Loss: 1.3218, Val Acc: 0.4320
Epoch 4/100, Loss: 0.3133, Acc: 0.8742, Val Loss: 1.2764, Val Acc: 0.4184
Epoch 5/100, Loss: 0.3134, Acc: 0.8731, Val Loss: 1.3440, Val Acc: 0.4099
Epoch 6/100, Loss: 0.3076, Acc: 0.8748, Val Loss: 1.4038, Val Acc: 0.4243
Epoch 7/100, Loss: 0.3037, Acc: 0.8752, Val Loss: 1.3979, Val Acc: 0.3956
Epoch 8/100, Loss: 0.3005, Acc: 0.8768, Val Loss: 1.4895, Val Acc: 0.4235
Epoch 9/100, Loss: 0.3029, Acc: 0.8764, Val Loss: 1.2978, Val Acc: 0.4419
Epoch 10/100, Loss: 0.3014, Acc: 0.8763, Val Loss: 1.5895, Val Acc: 0.4132
Epoch 11/100, Loss: 0.3009, Acc: 0.8778, Val Loss: 1.5340, Val Acc: 0.4254
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2948, Acc: 0.8795, Val Loss: 1.5055, Val Acc: 0.4485
Epoch 13/100, Loss: 0.2920, Acc: 0.8782, Val Loss: 1.5618, Val Acc: 0.4257
Epoch 14/100, Loss: 0.2935, Acc: 0.8808, Val Loss: 1.5169, Val Acc: 0.4279
Epoch 15/100, Loss: 0.2901, Acc: 0.8805, Val Loss: 1.6057, Val Acc: 0.4349
Epoch 16/100, Loss: 0.2904, Acc: 0.8797, Val Loss: 1.5852, Val Acc: 0.4423
Epoch 17/100, Loss: 0.2877, Acc: 0.8810, Val Loss: 1.5417, Val Acc: 0.4327
Epoch 18/100, Loss: 0.2909, Acc: 0.8819, Val Loss: 1.5083, Val Acc: 0.4316
Epoch 19/100, Loss: 0.2918, Acc: 0.8779, Val Loss: 1.5161, Val Acc: 0.4419
Epoch 20/100, Loss: 0.2892, Acc: 0.8824, Val Loss: 1.6181, Val Acc: 0.4239
Epoch 21/100, Loss: 0.2945, Acc: 0.8761, Val Loss: 1.5675, Val Acc: 0.4176
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2868, Acc: 0.8806, Val Loss: 1.5292, Val Acc: 0.4360
Epoch 23/100, Loss: 0.2874, Acc: 0.8800, Val Loss: 1.5742, Val Acc: 0.4279
Epoch 24/100, Loss: 0.2851, Acc: 0.8833, Val Loss: 1.5156, Val Acc: 0.4246
Epoch 25/100, Loss: 0.2859, Acc: 0.8804, Val Loss: 1.5810, Val Acc: 0.4529
Epoch 26/100, Loss: 0.2858, Acc: 0.8812, Val Loss: 1.5996, Val Acc: 0.4434
Epoch 27/100, Loss: 0.2859, Acc: 0.8817, Val Loss: 1.6621, Val Acc: 0.4147
Epoch 28/100, Loss: 0.2839, Acc: 0.8827, Val Loss: 1.6324, Val Acc: 0.4294
Epoch 29/100, Loss: 0.2845, Acc: 0.8825, Val Loss: 1.6594, Val Acc: 0.4305
Epoch 30/100, Loss: 0.2840, Acc: 0.8813, Val Loss: 1.6167, Val Acc: 0.4261
Epoch 31/100, Loss: 0.2835, Acc: 0.8836, Val Loss: 1.6641, Val Acc: 0.4390
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2829, Acc: 0.8817, Val Loss: 1.6253, Val Acc: 0.4349
Epoch 33/100, Loss: 0.2814, Acc: 0.8833, Val Loss: 1.6978, Val Acc: 0.4320
Epoch 34/100, Loss: 0.2802, Acc: 0.8855, Val Loss: 1.6705, Val Acc: 0.4324
Epoch 35/100, Loss: 0.2804, Acc: 0.8835, Val Loss: 1.6852, Val Acc: 0.4379
Epoch 36/100, Loss: 0.2799, Acc: 0.8844, Val Loss: 1.6683, Val Acc: 0.4357
Epoch 37/100, Loss: 0.2796, Acc: 0.8823, Val Loss: 1.6548, Val Acc: 0.4379
Epoch 38/100, Loss: 0.2793, Acc: 0.8834, Val Loss: 1.6230, Val Acc: 0.4423
Epoch 39/100, Loss: 0.2794, Acc: 0.8843, Val Loss: 1.6579, Val Acc: 0.4357
Epoch 40/100, Loss: 0.2793, Acc: 0.8838, Val Loss: 1.7083, Val Acc: 0.4353
Epoch 41/100, Loss: 0.2802, Acc: 0.8843, Val Loss: 1.6260, Val Acc: 0.4404
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2782, Acc: 0.8841, Val Loss: 1.6676, Val Acc: 0.4313
Epoch 43/100, Loss: 0.2774, Acc: 0.8845, Val Loss: 1.7486, Val Acc: 0.4246
Epoch 44/100, Loss: 0.2784, Acc: 0.8846, Val Loss: 1.6793, Val Acc: 0.4364
Epoch 45/100, Loss: 0.2781, Acc: 0.8832, Val Loss: 1.6864, Val Acc: 0.4353
Epoch 46/100, Loss: 0.2775, Acc: 0.8847, Val Loss: 1.6564, Val Acc: 0.4408
Epoch 47/100, Loss: 0.2776, Acc: 0.8856, Val Loss: 1.6458, Val Acc: 0.4423
Epoch 48/100, Loss: 0.2769, Acc: 0.8849, Val Loss: 1.7167, Val Acc: 0.4316
Epoch 49/100, Loss: 0.2780, Acc: 0.8834, Val Loss: 1.6954, Val Acc: 0.4386
Epoch 50/100, Loss: 0.2771, Acc: 0.8846, Val Loss: 1.6795, Val Acc: 0.4382
Epoch 51/100, Loss: 0.2773, Acc: 0.8854, Val Loss: 1.6934, Val Acc: 0.4357
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2765, Acc: 0.8856, Val Loss: 1.6679, Val Acc: 0.4379
Epoch 53/100, Loss: 0.2763, Acc: 0.8853, Val Loss: 1.6862, Val Acc: 0.4313
Epoch 54/100, Loss: 0.2763, Acc: 0.8849, Val Loss: 1.6753, Val Acc: 0.4357
Epoch 55/100, Loss: 0.2764, Acc: 0.8843, Val Loss: 1.6915, Val Acc: 0.4327
Epoch 56/100, Loss: 0.2763, Acc: 0.8838, Val Loss: 1.6757, Val Acc: 0.4335
Epoch 57/100, Loss: 0.2761, Acc: 0.8843, Val Loss: 1.7075, Val Acc: 0.4309
Epoch 58/100, Loss: 0.2758, Acc: 0.8863, Val Loss: 1.6760, Val Acc: 0.4357
Epoch 59/100, Loss: 0.2760, Acc: 0.8838, Val Loss: 1.6550, Val Acc: 0.4353
Epoch 60/100, Loss: 0.2762, Acc: 0.8849, Val Loss: 1.6768, Val Acc: 0.4305
Epoch 61/100, Loss: 0.2759, Acc: 0.8856, Val Loss: 1.6857, Val Acc: 0.4301
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2755, Acc: 0.8858, Val Loss: 1.7023, Val Acc: 0.4335
Epoch 63/100, Loss: 0.2756, Acc: 0.8844, Val Loss: 1.6923, Val Acc: 0.4320
Epoch 64/100, Loss: 0.2755, Acc: 0.8858, Val Loss: 1.6852, Val Acc: 0.4298
Epoch 65/100, Loss: 0.2755, Acc: 0.8847, Val Loss: 1.6903, Val Acc: 0.4349
Epoch 66/100, Loss: 0.2754, Acc: 0.8853, Val Loss: 1.7002, Val Acc: 0.4309
Epoch 67/100, Loss: 0.2756, Acc: 0.8847, Val Loss: 1.7040, Val Acc: 0.4324
Epoch 68/100, Loss: 0.2754, Acc: 0.8849, Val Loss: 1.6965, Val Acc: 0.4338
Epoch 69/100, Loss: 0.2753, Acc: 0.8840, Val Loss: 1.6883, Val Acc: 0.4301
Epoch 70/100, Loss: 0.2753, Acc: 0.8856, Val Loss: 1.6895, Val Acc: 0.4301
Epoch 71/100, Loss: 0.2752, Acc: 0.8852, Val Loss: 1.6982, Val Acc: 0.4327
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2752, Acc: 0.8843, Val Loss: 1.6897, Val Acc: 0.4313
Epoch 73/100, Loss: 0.2752, Acc: 0.8845, Val Loss: 1.6910, Val Acc: 0.4346
Epoch 74/100, Loss: 0.2751, Acc: 0.8850, Val Loss: 1.6949, Val Acc: 0.4309
Epoch 75/100, Loss: 0.2751, Acc: 0.8846, Val Loss: 1.6954, Val Acc: 0.4316
Epoch 76/100, Loss: 0.2750, Acc: 0.8844, Val Loss: 1.6924, Val Acc: 0.4338
Epoch 77/100, Loss: 0.2751, Acc: 0.8850, Val Loss: 1.6934, Val Acc: 0.4309
Epoch 78/100, Loss: 0.2750, Acc: 0.8847, Val Loss: 1.6905, Val Acc: 0.4338
Epoch 79/100, Loss: 0.2751, Acc: 0.8847, Val Loss: 1.6935, Val Acc: 0.4305
Epoch 80/100, Loss: 0.2751, Acc: 0.8839, Val Loss: 1.6998, Val Acc: 0.4309
Epoch 81/100, Loss: 0.2750, Acc: 0.8851, Val Loss: 1.6961, Val Acc: 0.4338
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2749, Acc: 0.8847, Val Loss: 1.6945, Val Acc: 0.4305
Epoch 83/100, Loss: 0.2751, Acc: 0.8843, Val Loss: 1.6952, Val Acc: 0.4316
Epoch 84/100, Loss: 0.2750, Acc: 0.8845, Val Loss: 1.6991, Val Acc: 0.4320
Epoch 85/100, Loss: 0.2749, Acc: 0.8851, Val Loss: 1.6932, Val Acc: 0.4301
Epoch 86/100, Loss: 0.2751, Acc: 0.8854, Val Loss: 1.6913, Val Acc: 0.4294
Epoch 87/100, Loss: 0.2749, Acc: 0.8850, Val Loss: 1.6947, Val Acc: 0.4301
Epoch 88/100, Loss: 0.2750, Acc: 0.8839, Val Loss: 1.6928, Val Acc: 0.4305
Epoch 89/100, Loss: 0.2749, Acc: 0.8847, Val Loss: 1.6986, Val Acc: 0.4320
Epoch 90/100, Loss: 0.2749, Acc: 0.8851, Val Loss: 1.6958, Val Acc: 0.4324
Epoch 91/100, Loss: 0.2749, Acc: 0.8850, Val Loss: 1.6950, Val Acc: 0.4301
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2750, Acc: 0.8850, Val Loss: 1.6957, Val Acc: 0.4309
Epoch 93/100, Loss: 0.2749, Acc: 0.8850, Val Loss: 1.6906, Val Acc: 0.4320
Epoch 94/100, Loss: 0.2749, Acc: 0.8854, Val Loss: 1.6937, Val Acc: 0.4338
Epoch 95/100, Loss: 0.2748, Acc: 0.8849, Val Loss: 1.6942, Val Acc: 0.4342
Epoch 96/100, Loss: 0.2748, Acc: 0.8849, Val Loss: 1.6946, Val Acc: 0.4316
Epoch 97/100, Loss: 0.2749, Acc: 0.8842, Val Loss: 1.6985, Val Acc: 0.4309
Epoch 98/100, Loss: 0.2748, Acc: 0.8850, Val Loss: 1.6939, Val Acc: 0.4327
Epoch 99/100, Loss: 0.2747, Acc: 0.8847, Val Loss: 1.6977, Val Acc: 0.4360
Epoch 100/100, Loss: 0.2748, Acc: 0.8856, Val Loss: 1.6978, Val Acc: 0.4316

##############################
Resultados para principal:  107  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1 
 {'training': [0.27480398705777, 0.8855698529411765, 0.8726239118848819, 0.9029411764705882, 0.8875237148793929], 'validate': [1.697760640188705, 0.43161764705882355, 0.4593531468531469, 0.7727941176470589, 0.5762061403508771], 'test': [0.47991389670857676, 0.7914705882352941, 0.7427731504164625, 0.8917647058823529, 0.8104784816893879]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  086  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  086  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  086  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6501, Acc: 0.6565, Val Loss: 0.7911, Val Acc: 0.3118
Mejor modelo guardado con Val Loss: 0.7911
Epoch 2/100, Loss: 0.6017, Acc: 0.6994, Val Loss: 0.8887, Val Acc: 0.3368
Epoch 3/100, Loss: 0.5862, Acc: 0.6959, Val Loss: 0.9540, Val Acc: 0.2610
Epoch 4/100, Loss: 0.5843, Acc: 0.6998, Val Loss: 0.9249, Val Acc: 0.3154
Epoch 5/100, Loss: 0.5710, Acc: 0.7096, Val Loss: 0.9150, Val Acc: 0.3596
Epoch 6/100, Loss: 0.5688, Acc: 0.7102, Val Loss: 0.9463, Val Acc: 0.3463
Epoch 7/100, Loss: 0.5637, Acc: 0.7150, Val Loss: 0.9764, Val Acc: 0.3772
Epoch 8/100, Loss: 0.5649, Acc: 0.7127, Val Loss: 0.9535, Val Acc: 0.3232
Epoch 9/100, Loss: 0.5731, Acc: 0.7040, Val Loss: 0.8744, Val Acc: 0.3636
Epoch 10/100, Loss: 0.5646, Acc: 0.7155, Val Loss: 0.9395, Val Acc: 0.4048
Epoch 11/100, Loss: 0.5689, Acc: 0.7088, Val Loss: 0.8976, Val Acc: 0.3143
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5635, Acc: 0.7148, Val Loss: 0.8961, Val Acc: 0.4040
Epoch 13/100, Loss: 0.5596, Acc: 0.7153, Val Loss: 0.9925, Val Acc: 0.3129
Epoch 14/100, Loss: 0.5617, Acc: 0.7118, Val Loss: 0.9554, Val Acc: 0.3912
Epoch 15/100, Loss: 0.5597, Acc: 0.7140, Val Loss: 0.9105, Val Acc: 0.3555
Epoch 16/100, Loss: 0.5580, Acc: 0.7178, Val Loss: 1.0011, Val Acc: 0.3673
Epoch 17/100, Loss: 0.5576, Acc: 0.7163, Val Loss: 0.9688, Val Acc: 0.3257
Epoch 18/100, Loss: 0.5570, Acc: 0.7155, Val Loss: 0.9660, Val Acc: 0.3596
Epoch 19/100, Loss: 0.5574, Acc: 0.7156, Val Loss: 0.9090, Val Acc: 0.3985
Epoch 20/100, Loss: 0.5565, Acc: 0.7172, Val Loss: 0.9738, Val Acc: 0.3658
Epoch 21/100, Loss: 0.5589, Acc: 0.7149, Val Loss: 0.9462, Val Acc: 0.3735
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5524, Acc: 0.7199, Val Loss: 0.9687, Val Acc: 0.3460
Epoch 23/100, Loss: 0.5525, Acc: 0.7216, Val Loss: 0.9357, Val Acc: 0.3551
Epoch 24/100, Loss: 0.5525, Acc: 0.7210, Val Loss: 0.9652, Val Acc: 0.3603
Epoch 25/100, Loss: 0.5522, Acc: 0.7187, Val Loss: 0.9906, Val Acc: 0.3460
Epoch 26/100, Loss: 0.5535, Acc: 0.7194, Val Loss: 0.9644, Val Acc: 0.3555
Epoch 27/100, Loss: 0.5503, Acc: 0.7195, Val Loss: 0.9563, Val Acc: 0.3614
Epoch 28/100, Loss: 0.5527, Acc: 0.7195, Val Loss: 0.9349, Val Acc: 0.3768
Epoch 29/100, Loss: 0.5511, Acc: 0.7188, Val Loss: 0.9604, Val Acc: 0.3853
Epoch 30/100, Loss: 0.5515, Acc: 0.7193, Val Loss: 0.9484, Val Acc: 0.3739
Epoch 31/100, Loss: 0.5507, Acc: 0.7203, Val Loss: 0.9230, Val Acc: 0.4103
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5492, Acc: 0.7233, Val Loss: 0.9391, Val Acc: 0.3798
Epoch 33/100, Loss: 0.5484, Acc: 0.7210, Val Loss: 0.9493, Val Acc: 0.3794
Epoch 34/100, Loss: 0.5481, Acc: 0.7229, Val Loss: 0.9312, Val Acc: 0.3651
Epoch 35/100, Loss: 0.5476, Acc: 0.7215, Val Loss: 0.9430, Val Acc: 0.3879
Epoch 36/100, Loss: 0.5479, Acc: 0.7217, Val Loss: 0.9582, Val Acc: 0.3783
Epoch 37/100, Loss: 0.5476, Acc: 0.7227, Val Loss: 0.9532, Val Acc: 0.3754
Epoch 38/100, Loss: 0.5475, Acc: 0.7213, Val Loss: 0.9317, Val Acc: 0.3794
Epoch 39/100, Loss: 0.5474, Acc: 0.7231, Val Loss: 0.9778, Val Acc: 0.3827
Epoch 40/100, Loss: 0.5486, Acc: 0.7203, Val Loss: 0.9567, Val Acc: 0.3710
Epoch 41/100, Loss: 0.5471, Acc: 0.7225, Val Loss: 0.9354, Val Acc: 0.3779
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5458, Acc: 0.7256, Val Loss: 0.9447, Val Acc: 0.3871
Epoch 43/100, Loss: 0.5454, Acc: 0.7242, Val Loss: 0.9413, Val Acc: 0.3809
Epoch 44/100, Loss: 0.5451, Acc: 0.7226, Val Loss: 0.9462, Val Acc: 0.3809
Epoch 45/100, Loss: 0.5452, Acc: 0.7238, Val Loss: 0.9554, Val Acc: 0.3662
Epoch 46/100, Loss: 0.5448, Acc: 0.7242, Val Loss: 0.9468, Val Acc: 0.3838
Epoch 47/100, Loss: 0.5448, Acc: 0.7238, Val Loss: 0.9642, Val Acc: 0.3710
Epoch 48/100, Loss: 0.5445, Acc: 0.7240, Val Loss: 0.9433, Val Acc: 0.3901
Epoch 49/100, Loss: 0.5445, Acc: 0.7229, Val Loss: 0.9512, Val Acc: 0.3787
Epoch 50/100, Loss: 0.5445, Acc: 0.7272, Val Loss: 0.9436, Val Acc: 0.3816
Epoch 51/100, Loss: 0.5441, Acc: 0.7230, Val Loss: 0.9542, Val Acc: 0.3868
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5440, Acc: 0.7260, Val Loss: 0.9553, Val Acc: 0.3684
Epoch 53/100, Loss: 0.5433, Acc: 0.7218, Val Loss: 0.9336, Val Acc: 0.3776
Epoch 54/100, Loss: 0.5433, Acc: 0.7252, Val Loss: 0.9336, Val Acc: 0.3798
Epoch 55/100, Loss: 0.5435, Acc: 0.7236, Val Loss: 0.9374, Val Acc: 0.3794
Epoch 56/100, Loss: 0.5430, Acc: 0.7250, Val Loss: 0.9393, Val Acc: 0.3761
Epoch 57/100, Loss: 0.5431, Acc: 0.7252, Val Loss: 0.9345, Val Acc: 0.3816
Epoch 58/100, Loss: 0.5428, Acc: 0.7267, Val Loss: 0.9264, Val Acc: 0.3893
Epoch 59/100, Loss: 0.5429, Acc: 0.7247, Val Loss: 0.9346, Val Acc: 0.3816
Epoch 60/100, Loss: 0.5427, Acc: 0.7244, Val Loss: 0.9321, Val Acc: 0.3871
Epoch 61/100, Loss: 0.5428, Acc: 0.7256, Val Loss: 0.9365, Val Acc: 0.3798
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5423, Acc: 0.7250, Val Loss: 0.9343, Val Acc: 0.3794
Epoch 63/100, Loss: 0.5424, Acc: 0.7250, Val Loss: 0.9335, Val Acc: 0.3824
Epoch 64/100, Loss: 0.5422, Acc: 0.7259, Val Loss: 0.9323, Val Acc: 0.3812
Epoch 65/100, Loss: 0.5422, Acc: 0.7251, Val Loss: 0.9315, Val Acc: 0.3809
Epoch 66/100, Loss: 0.5421, Acc: 0.7247, Val Loss: 0.9347, Val Acc: 0.3798
Epoch 67/100, Loss: 0.5421, Acc: 0.7255, Val Loss: 0.9320, Val Acc: 0.3757
Epoch 68/100, Loss: 0.5421, Acc: 0.7255, Val Loss: 0.9331, Val Acc: 0.3801
Epoch 69/100, Loss: 0.5421, Acc: 0.7255, Val Loss: 0.9353, Val Acc: 0.3794
Epoch 70/100, Loss: 0.5420, Acc: 0.7247, Val Loss: 0.9370, Val Acc: 0.3776
Epoch 71/100, Loss: 0.5419, Acc: 0.7251, Val Loss: 0.9325, Val Acc: 0.3798
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5414, Acc: 0.7257, Val Loss: 0.9301, Val Acc: 0.3812
Epoch 73/100, Loss: 0.5404, Acc: 0.7266, Val Loss: 0.9178, Val Acc: 0.3871
Epoch 74/100, Loss: 0.5397, Acc: 0.7270, Val Loss: 0.9075, Val Acc: 0.3949
Epoch 75/100, Loss: 0.5396, Acc: 0.7269, Val Loss: 0.9025, Val Acc: 0.3982
Epoch 76/100, Loss: 0.5396, Acc: 0.7280, Val Loss: 0.9079, Val Acc: 0.3941
Epoch 77/100, Loss: 0.5394, Acc: 0.7265, Val Loss: 0.9047, Val Acc: 0.3967
Epoch 78/100, Loss: 0.5394, Acc: 0.7274, Val Loss: 0.9068, Val Acc: 0.3945
Epoch 79/100, Loss: 0.5395, Acc: 0.7279, Val Loss: 0.9072, Val Acc: 0.3949
Epoch 80/100, Loss: 0.5393, Acc: 0.7281, Val Loss: 0.9055, Val Acc: 0.3978
Epoch 81/100, Loss: 0.5393, Acc: 0.7275, Val Loss: 0.9079, Val Acc: 0.3952
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5393, Acc: 0.7276, Val Loss: 0.9055, Val Acc: 0.3971
Epoch 83/100, Loss: 0.5392, Acc: 0.7287, Val Loss: 0.9029, Val Acc: 0.4011
Epoch 84/100, Loss: 0.5392, Acc: 0.7283, Val Loss: 0.9072, Val Acc: 0.3963
Epoch 85/100, Loss: 0.5392, Acc: 0.7286, Val Loss: 0.9086, Val Acc: 0.3952
Epoch 86/100, Loss: 0.5391, Acc: 0.7282, Val Loss: 0.9057, Val Acc: 0.3982
Epoch 87/100, Loss: 0.5391, Acc: 0.7287, Val Loss: 0.9058, Val Acc: 0.3985
Epoch 88/100, Loss: 0.5390, Acc: 0.7275, Val Loss: 0.9056, Val Acc: 0.3974
Epoch 89/100, Loss: 0.5390, Acc: 0.7274, Val Loss: 0.9047, Val Acc: 0.3985
Epoch 90/100, Loss: 0.5390, Acc: 0.7273, Val Loss: 0.9045, Val Acc: 0.3982
Epoch 91/100, Loss: 0.5389, Acc: 0.7281, Val Loss: 0.9096, Val Acc: 0.3963
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5388, Acc: 0.7287, Val Loss: 0.9092, Val Acc: 0.3971
Epoch 93/100, Loss: 0.5388, Acc: 0.7279, Val Loss: 0.9042, Val Acc: 0.3993
Epoch 94/100, Loss: 0.5388, Acc: 0.7281, Val Loss: 0.9043, Val Acc: 0.3993
Epoch 95/100, Loss: 0.5388, Acc: 0.7274, Val Loss: 0.9044, Val Acc: 0.3985
Epoch 96/100, Loss: 0.5386, Acc: 0.7287, Val Loss: 0.9032, Val Acc: 0.3996
Epoch 97/100, Loss: 0.5387, Acc: 0.7278, Val Loss: 0.9021, Val Acc: 0.4004
Epoch 98/100, Loss: 0.5387, Acc: 0.7276, Val Loss: 0.9049, Val Acc: 0.3985
Epoch 99/100, Loss: 0.5386, Acc: 0.7289, Val Loss: 0.9017, Val Acc: 0.4022
Epoch 100/100, Loss: 0.5386, Acc: 0.7286, Val Loss: 0.9062, Val Acc: 0.3989

##############################
Resultados para principal:  086  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  1 
 {'training': [0.5385909748428008, 0.7285845588235295, 0.6993746993746994, 0.8018382352941177, 0.7471097028346322], 'validate': [0.9062379633271417, 0.39889705882352944, 0.43386243386243384, 0.663235294117647, 0.5245710962489095], 'test': [0.7754005359278785, 0.33176470588235296, 0.3843977364591754, 0.5594117647058824, 0.4556780067081936]}

##############################
Resultados para window:  1 
 {'098:025:059:121:107:086': {'training': [0.567741519037415, 0.6889705882352941, 0.6313234542667348, 0.9084558823529412, 0.7449502562556527], 'validate': [0.5079038482765819, 0.7805147058823529, 0.7347692307692307, 0.8779411764705882, 0.8], 'test': [0.6342776798539691, 0.6485294117647059, 0.6084156290253327, 0.8335294117647059, 0.7034003474807644]}, '025:098:059:121:107:086': {'training': [0.5882952413138222, 0.6579044117647059, 0.6051922605927015, 0.9084558823529412, 0.7264442157871527], 'validate': [0.5061746080254399, 0.7955882352941176, 0.7620599739243807, 0.8595588235294118, 0.8078783690393918], 'test': [0.6516661450818733, 0.611764705882353, 0.5725190839694656, 0.8823529411764706, 0.6944444444444444]}, '059:098:025:121:107:086': {'training': [0.5002394888330909, 0.7275735294117647, 0.7411375146084924, 0.6994485294117647, 0.7196898051825231], 'validate': [0.22943367796062036, 0.9161764705882353, 0.9956217162872154, 0.8360294117647059, 0.9088729016786571], 'test': [0.545316674505119, 0.7205882352941176, 0.6729704797047971, 0.8582352941176471, 0.7543950361944157]}, '121:098:025:059:107:086': {'training': [0.2823474044308943, 0.8809742647058824, 0.8757932910244787, 0.8878676470588235, 0.8817891373801917], 'validate': [1.117939796905185, 0.5426470588235294, 0.5251517779705117, 0.8904411764705882, 0.6606655755591926], 'test': [0.4701758998411673, 0.7947058823529412, 0.8058608058608059, 0.7764705882352941, 0.7908927501497903]}, '107:098:025:059:121:086': {'training': [0.27480398705777, 0.8855698529411765, 0.8726239118848819, 0.9029411764705882, 0.8875237148793929], 'validate': [1.697760640188705, 0.43161764705882355, 0.4593531468531469, 0.7727941176470589, 0.5762061403508771], 'test': [0.47991389670857676, 0.7914705882352941, 0.7427731504164625, 0.8917647058823529, 0.8104784816893879]}, '086:098:025:059:121:107': {'training': [0.5385909748428008, 0.7285845588235295, 0.6993746993746994, 0.8018382352941177, 0.7471097028346322], 'validate': [0.9062379633271417, 0.39889705882352944, 0.43386243386243384, 0.663235294117647, 0.5245710962489095], 'test': [0.7754005359278785, 0.33176470588235296, 0.3843977364591754, 0.5594117647058824, 0.4556780067081936]}}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  031  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  031  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  031  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6930, Acc: 0.5085, Val Loss: 0.6926, Val Acc: 0.5298
Mejor modelo guardado con Val Loss: 0.6926
Epoch 2/100, Loss: 0.6934, Acc: 0.5038, Val Loss: 0.6933, Val Acc: 0.5026
Epoch 3/100, Loss: 0.6935, Acc: 0.4965, Val Loss: 0.6904, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6904
Epoch 4/100, Loss: 0.6935, Acc: 0.4976, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 5/100, Loss: 0.6933, Acc: 0.5031, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 6/100, Loss: 0.6933, Acc: 0.5068, Val Loss: 0.6948, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6937, Acc: 0.4987, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 8/100, Loss: 0.6936, Acc: 0.4922, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6933, Acc: 0.4971, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 10/100, Loss: 0.6934, Acc: 0.5051, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 11/100, Loss: 0.6934, Acc: 0.4965, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6932, Acc: 0.5044, Val Loss: 0.6935, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6931, Acc: 0.5066, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6930, Acc: 0.5085, Val Loss: 0.6938, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6934, Acc: 0.4969, Val Loss: 0.6931, Val Acc: 0.4982
Epoch 16/100, Loss: 0.6933, Acc: 0.4995, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6922, Acc: 0.5267, Val Loss: 0.6899, Val Acc: 0.5794
Mejor modelo guardado con Val Loss: 0.6899
Epoch 18/100, Loss: 0.6916, Acc: 0.5342, Val Loss: 0.6902, Val Acc: 0.5585
Epoch 19/100, Loss: 0.6925, Acc: 0.5116, Val Loss: 0.6931, Val Acc: 0.5029
Epoch 20/100, Loss: 0.6933, Acc: 0.4912, Val Loss: 0.6934, Val Acc: 0.5000
Epoch 21/100, Loss: 0.6933, Acc: 0.4990, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4919, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 23/100, Loss: 0.6931, Acc: 0.5045, Val Loss: 0.6932, Val Acc: 0.5029
Epoch 24/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 25/100, Loss: 0.6934, Acc: 0.4985, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 26/100, Loss: 0.6933, Acc: 0.4908, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 27/100, Loss: 0.6931, Acc: 0.5010, Val Loss: 0.6932, Val Acc: 0.5074
Epoch 28/100, Loss: 0.6927, Acc: 0.5146, Val Loss: 0.6927, Val Acc: 0.5404
Epoch 29/100, Loss: 0.6930, Acc: 0.5126, Val Loss: 0.6931, Val Acc: 0.5015
Epoch 30/100, Loss: 0.6924, Acc: 0.5254, Val Loss: 0.6919, Val Acc: 0.5404
Epoch 31/100, Loss: 0.6924, Acc: 0.5239, Val Loss: 0.6927, Val Acc: 0.5132
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6915, Acc: 0.5474, Val Loss: 0.6912, Val Acc: 0.5566
Epoch 33/100, Loss: 0.6914, Acc: 0.5426, Val Loss: 0.6910, Val Acc: 0.5533
Epoch 34/100, Loss: 0.6911, Acc: 0.5470, Val Loss: 0.6914, Val Acc: 0.5419
Epoch 35/100, Loss: 0.6908, Acc: 0.5490, Val Loss: 0.6911, Val Acc: 0.5327
Epoch 36/100, Loss: 0.6904, Acc: 0.5533, Val Loss: 0.6908, Val Acc: 0.5382
Epoch 37/100, Loss: 0.6902, Acc: 0.5527, Val Loss: 0.6902, Val Acc: 0.5434
Epoch 38/100, Loss: 0.6899, Acc: 0.5541, Val Loss: 0.6894, Val Acc: 0.5551
Mejor modelo guardado con Val Loss: 0.6894
Epoch 39/100, Loss: 0.6895, Acc: 0.5521, Val Loss: 0.6887, Val Acc: 0.5662
Mejor modelo guardado con Val Loss: 0.6887
Epoch 40/100, Loss: 0.6891, Acc: 0.5567, Val Loss: 0.6879, Val Acc: 0.5739
Mejor modelo guardado con Val Loss: 0.6879
Epoch 41/100, Loss: 0.6890, Acc: 0.5569, Val Loss: 0.6880, Val Acc: 0.5684
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6886, Acc: 0.5620, Val Loss: 0.6877, Val Acc: 0.5680
Mejor modelo guardado con Val Loss: 0.6877
Epoch 43/100, Loss: 0.6885, Acc: 0.5555, Val Loss: 0.6878, Val Acc: 0.5596
Epoch 44/100, Loss: 0.6883, Acc: 0.5577, Val Loss: 0.6865, Val Acc: 0.5849
Mejor modelo guardado con Val Loss: 0.6865
Epoch 45/100, Loss: 0.6882, Acc: 0.5604, Val Loss: 0.6864, Val Acc: 0.5801
Mejor modelo guardado con Val Loss: 0.6864
Epoch 46/100, Loss: 0.6881, Acc: 0.5592, Val Loss: 0.6863, Val Acc: 0.5735
Mejor modelo guardado con Val Loss: 0.6863
Epoch 47/100, Loss: 0.6879, Acc: 0.5594, Val Loss: 0.6872, Val Acc: 0.5621
Epoch 48/100, Loss: 0.6878, Acc: 0.5578, Val Loss: 0.6860, Val Acc: 0.5754
Mejor modelo guardado con Val Loss: 0.6860
Epoch 49/100, Loss: 0.6877, Acc: 0.5597, Val Loss: 0.6874, Val Acc: 0.5610
Epoch 50/100, Loss: 0.6875, Acc: 0.5626, Val Loss: 0.6864, Val Acc: 0.5632
Epoch 51/100, Loss: 0.6874, Acc: 0.5600, Val Loss: 0.6852, Val Acc: 0.5772
Mejor modelo guardado con Val Loss: 0.6852
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6872, Acc: 0.5608, Val Loss: 0.6849, Val Acc: 0.5857
Mejor modelo guardado con Val Loss: 0.6849
Epoch 53/100, Loss: 0.6871, Acc: 0.5616, Val Loss: 0.6849, Val Acc: 0.5809
Epoch 54/100, Loss: 0.6870, Acc: 0.5626, Val Loss: 0.6856, Val Acc: 0.5643
Epoch 55/100, Loss: 0.6870, Acc: 0.5637, Val Loss: 0.6850, Val Acc: 0.5772
Epoch 56/100, Loss: 0.6869, Acc: 0.5638, Val Loss: 0.6847, Val Acc: 0.5783
Mejor modelo guardado con Val Loss: 0.6847
Epoch 57/100, Loss: 0.6869, Acc: 0.5610, Val Loss: 0.6850, Val Acc: 0.5746
Epoch 58/100, Loss: 0.6868, Acc: 0.5622, Val Loss: 0.6843, Val Acc: 0.5820
Mejor modelo guardado con Val Loss: 0.6843
Epoch 59/100, Loss: 0.6867, Acc: 0.5643, Val Loss: 0.6845, Val Acc: 0.5794
Epoch 60/100, Loss: 0.6867, Acc: 0.5626, Val Loss: 0.6844, Val Acc: 0.5790
Epoch 61/100, Loss: 0.6866, Acc: 0.5623, Val Loss: 0.6847, Val Acc: 0.5732
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6865, Acc: 0.5614, Val Loss: 0.6842, Val Acc: 0.5801
Mejor modelo guardado con Val Loss: 0.6842
Epoch 63/100, Loss: 0.6865, Acc: 0.5619, Val Loss: 0.6841, Val Acc: 0.5809
Mejor modelo guardado con Val Loss: 0.6841
Epoch 64/100, Loss: 0.6864, Acc: 0.5636, Val Loss: 0.6838, Val Acc: 0.5835
Mejor modelo guardado con Val Loss: 0.6838
Epoch 65/100, Loss: 0.6864, Acc: 0.5653, Val Loss: 0.6842, Val Acc: 0.5809
Epoch 66/100, Loss: 0.6864, Acc: 0.5625, Val Loss: 0.6840, Val Acc: 0.5809
Epoch 67/100, Loss: 0.6863, Acc: 0.5635, Val Loss: 0.6839, Val Acc: 0.5820
Epoch 68/100, Loss: 0.6863, Acc: 0.5649, Val Loss: 0.6841, Val Acc: 0.5779
Epoch 69/100, Loss: 0.6863, Acc: 0.5626, Val Loss: 0.6839, Val Acc: 0.5813
Epoch 70/100, Loss: 0.6862, Acc: 0.5632, Val Loss: 0.6835, Val Acc: 0.5831
Mejor modelo guardado con Val Loss: 0.6835
Epoch 71/100, Loss: 0.6862, Acc: 0.5643, Val Loss: 0.6836, Val Acc: 0.5816
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6861, Acc: 0.5650, Val Loss: 0.6837, Val Acc: 0.5831
Epoch 73/100, Loss: 0.6861, Acc: 0.5653, Val Loss: 0.6836, Val Acc: 0.5831
Epoch 74/100, Loss: 0.6861, Acc: 0.5633, Val Loss: 0.6836, Val Acc: 0.5835
Epoch 75/100, Loss: 0.6861, Acc: 0.5626, Val Loss: 0.6835, Val Acc: 0.5827
Mejor modelo guardado con Val Loss: 0.6835
Epoch 76/100, Loss: 0.6861, Acc: 0.5644, Val Loss: 0.6836, Val Acc: 0.5824
Epoch 77/100, Loss: 0.6860, Acc: 0.5629, Val Loss: 0.6834, Val Acc: 0.5813
Mejor modelo guardado con Val Loss: 0.6834
Epoch 78/100, Loss: 0.6860, Acc: 0.5644, Val Loss: 0.6834, Val Acc: 0.5827
Mejor modelo guardado con Val Loss: 0.6834
Epoch 79/100, Loss: 0.6860, Acc: 0.5637, Val Loss: 0.6834, Val Acc: 0.5827
Epoch 80/100, Loss: 0.6860, Acc: 0.5644, Val Loss: 0.6834, Val Acc: 0.5842
Epoch 81/100, Loss: 0.6859, Acc: 0.5629, Val Loss: 0.6834, Val Acc: 0.5849
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6859, Acc: 0.5642, Val Loss: 0.6833, Val Acc: 0.5846
Mejor modelo guardado con Val Loss: 0.6833
Epoch 83/100, Loss: 0.6859, Acc: 0.5633, Val Loss: 0.6832, Val Acc: 0.5846
Mejor modelo guardado con Val Loss: 0.6832
Epoch 84/100, Loss: 0.6859, Acc: 0.5647, Val Loss: 0.6833, Val Acc: 0.5842
Epoch 85/100, Loss: 0.6858, Acc: 0.5644, Val Loss: 0.6832, Val Acc: 0.5849
Mejor modelo guardado con Val Loss: 0.6832
Epoch 86/100, Loss: 0.6858, Acc: 0.5646, Val Loss: 0.6831, Val Acc: 0.5838
Mejor modelo guardado con Val Loss: 0.6831
Epoch 87/100, Loss: 0.6858, Acc: 0.5653, Val Loss: 0.6831, Val Acc: 0.5849
Mejor modelo guardado con Val Loss: 0.6831
Epoch 88/100, Loss: 0.6858, Acc: 0.5644, Val Loss: 0.6829, Val Acc: 0.5875
Mejor modelo guardado con Val Loss: 0.6829
Epoch 89/100, Loss: 0.6858, Acc: 0.5639, Val Loss: 0.6830, Val Acc: 0.5864
Epoch 90/100, Loss: 0.6857, Acc: 0.5635, Val Loss: 0.6830, Val Acc: 0.5860
Epoch 91/100, Loss: 0.6857, Acc: 0.5654, Val Loss: 0.6829, Val Acc: 0.5868
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6857, Acc: 0.5648, Val Loss: 0.6831, Val Acc: 0.5868
Epoch 93/100, Loss: 0.6856, Acc: 0.5636, Val Loss: 0.6832, Val Acc: 0.5849
Epoch 94/100, Loss: 0.6853, Acc: 0.5642, Val Loss: 0.6831, Val Acc: 0.5827
Epoch 95/100, Loss: 0.6852, Acc: 0.5650, Val Loss: 0.6830, Val Acc: 0.5846
Epoch 96/100, Loss: 0.6852, Acc: 0.5651, Val Loss: 0.6830, Val Acc: 0.5849
Epoch 97/100, Loss: 0.6851, Acc: 0.5651, Val Loss: 0.6830, Val Acc: 0.5831
Epoch 98/100, Loss: 0.6851, Acc: 0.5666, Val Loss: 0.6827, Val Acc: 0.5809
Mejor modelo guardado con Val Loss: 0.6827
Epoch 99/100, Loss: 0.6851, Acc: 0.5653, Val Loss: 0.6827, Val Acc: 0.5871
Epoch 100/100, Loss: 0.6850, Acc: 0.5653, Val Loss: 0.6828, Val Acc: 0.5813

##############################
Resultados para principal:  031  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1 
 {'training': [0.6850237941040712, 0.5652573529411765, 0.5610175317978687, 0.6, 0.5798543258127554], 'validate': [0.6828277346699737, 0.58125, 0.5803636363636364, 0.586764705882353, 0.5835466179159049], 'test': [0.6870759714532781, 0.5461764705882353, 0.5417775412453433, 0.5988235294117648, 0.5688739871472478]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  051  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  051  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  051  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6575, Acc: 0.6471, Val Loss: 0.6626, Val Acc: 0.6401
Mejor modelo guardado con Val Loss: 0.6626
Epoch 2/100, Loss: 0.6277, Acc: 0.6785, Val Loss: 0.6578, Val Acc: 0.6033
Mejor modelo guardado con Val Loss: 0.6578
Epoch 3/100, Loss: 0.6153, Acc: 0.6762, Val Loss: 0.6648, Val Acc: 0.5842
Epoch 4/100, Loss: 0.5952, Acc: 0.6914, Val Loss: 0.6670, Val Acc: 0.6044
Epoch 5/100, Loss: 0.5922, Acc: 0.6885, Val Loss: 0.6651, Val Acc: 0.6246
Epoch 6/100, Loss: 0.5876, Acc: 0.6905, Val Loss: 0.6579, Val Acc: 0.6232
Epoch 7/100, Loss: 0.5806, Acc: 0.6990, Val Loss: 0.6803, Val Acc: 0.5982
Epoch 8/100, Loss: 0.5791, Acc: 0.6988, Val Loss: 0.6560, Val Acc: 0.6276
Mejor modelo guardado con Val Loss: 0.6560
Epoch 9/100, Loss: 0.5801, Acc: 0.6935, Val Loss: 0.6934, Val Acc: 0.5938
Epoch 10/100, Loss: 0.5820, Acc: 0.7022, Val Loss: 0.6675, Val Acc: 0.6132
Epoch 11/100, Loss: 0.5867, Acc: 0.6971, Val Loss: 0.6794, Val Acc: 0.5982
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5785, Acc: 0.6996, Val Loss: 0.6602, Val Acc: 0.6327
Epoch 13/100, Loss: 0.5769, Acc: 0.6975, Val Loss: 0.6583, Val Acc: 0.6272
Epoch 14/100, Loss: 0.5750, Acc: 0.7034, Val Loss: 0.6624, Val Acc: 0.6272
Epoch 15/100, Loss: 0.5783, Acc: 0.6965, Val Loss: 0.6863, Val Acc: 0.5702
Epoch 16/100, Loss: 0.5732, Acc: 0.7044, Val Loss: 0.6931, Val Acc: 0.6287
Epoch 17/100, Loss: 0.5747, Acc: 0.7033, Val Loss: 0.6961, Val Acc: 0.5831
Epoch 18/100, Loss: 0.5689, Acc: 0.7033, Val Loss: 0.6805, Val Acc: 0.5897
Epoch 19/100, Loss: 0.5731, Acc: 0.7006, Val Loss: 0.6880, Val Acc: 0.5989
Epoch 20/100, Loss: 0.5674, Acc: 0.7071, Val Loss: 0.6853, Val Acc: 0.5838
Epoch 21/100, Loss: 0.5691, Acc: 0.7029, Val Loss: 0.6852, Val Acc: 0.6206
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5659, Acc: 0.7060, Val Loss: 0.6880, Val Acc: 0.6037
Epoch 23/100, Loss: 0.5643, Acc: 0.7070, Val Loss: 0.6771, Val Acc: 0.6118
Epoch 24/100, Loss: 0.5637, Acc: 0.7074, Val Loss: 0.6860, Val Acc: 0.6268
Epoch 25/100, Loss: 0.5624, Acc: 0.7119, Val Loss: 0.6821, Val Acc: 0.5945
Epoch 26/100, Loss: 0.5646, Acc: 0.7081, Val Loss: 0.6832, Val Acc: 0.5945
Epoch 27/100, Loss: 0.5636, Acc: 0.7096, Val Loss: 0.6979, Val Acc: 0.6004
Epoch 28/100, Loss: 0.5645, Acc: 0.7065, Val Loss: 0.6696, Val Acc: 0.6272
Epoch 29/100, Loss: 0.5644, Acc: 0.7076, Val Loss: 0.6835, Val Acc: 0.6022
Epoch 30/100, Loss: 0.5625, Acc: 0.7081, Val Loss: 0.6894, Val Acc: 0.5974
Epoch 31/100, Loss: 0.5624, Acc: 0.7086, Val Loss: 0.6871, Val Acc: 0.6099
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5610, Acc: 0.7085, Val Loss: 0.6908, Val Acc: 0.6074
Epoch 33/100, Loss: 0.5592, Acc: 0.7129, Val Loss: 0.6883, Val Acc: 0.5930
Epoch 34/100, Loss: 0.5600, Acc: 0.7118, Val Loss: 0.6878, Val Acc: 0.6051
Epoch 35/100, Loss: 0.5596, Acc: 0.7112, Val Loss: 0.7072, Val Acc: 0.5849
Epoch 36/100, Loss: 0.5594, Acc: 0.7098, Val Loss: 0.6972, Val Acc: 0.6040
Epoch 37/100, Loss: 0.5592, Acc: 0.7103, Val Loss: 0.6827, Val Acc: 0.6000
Epoch 38/100, Loss: 0.5597, Acc: 0.7119, Val Loss: 0.7170, Val Acc: 0.5890
Epoch 39/100, Loss: 0.5584, Acc: 0.7127, Val Loss: 0.6852, Val Acc: 0.6033
Epoch 40/100, Loss: 0.5587, Acc: 0.7101, Val Loss: 0.6924, Val Acc: 0.5996
Epoch 41/100, Loss: 0.5593, Acc: 0.7116, Val Loss: 0.7030, Val Acc: 0.6206
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5576, Acc: 0.7127, Val Loss: 0.6898, Val Acc: 0.6000
Epoch 43/100, Loss: 0.5578, Acc: 0.7131, Val Loss: 0.6884, Val Acc: 0.6037
Epoch 44/100, Loss: 0.5574, Acc: 0.7122, Val Loss: 0.6953, Val Acc: 0.6096
Epoch 45/100, Loss: 0.5571, Acc: 0.7122, Val Loss: 0.6984, Val Acc: 0.5982
Epoch 46/100, Loss: 0.5569, Acc: 0.7107, Val Loss: 0.7024, Val Acc: 0.5978
Epoch 47/100, Loss: 0.5566, Acc: 0.7117, Val Loss: 0.6919, Val Acc: 0.6132
Epoch 48/100, Loss: 0.5568, Acc: 0.7108, Val Loss: 0.6908, Val Acc: 0.6158
Epoch 49/100, Loss: 0.5563, Acc: 0.7122, Val Loss: 0.6982, Val Acc: 0.5982
Epoch 50/100, Loss: 0.5567, Acc: 0.7114, Val Loss: 0.6952, Val Acc: 0.5960
Epoch 51/100, Loss: 0.5563, Acc: 0.7123, Val Loss: 0.6913, Val Acc: 0.6154
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5559, Acc: 0.7119, Val Loss: 0.6912, Val Acc: 0.6074
Epoch 53/100, Loss: 0.5557, Acc: 0.7128, Val Loss: 0.6937, Val Acc: 0.6040
Epoch 54/100, Loss: 0.5557, Acc: 0.7120, Val Loss: 0.7009, Val Acc: 0.6081
Epoch 55/100, Loss: 0.5555, Acc: 0.7111, Val Loss: 0.6971, Val Acc: 0.6151
Epoch 56/100, Loss: 0.5559, Acc: 0.7113, Val Loss: 0.6968, Val Acc: 0.6074
Epoch 57/100, Loss: 0.5559, Acc: 0.7118, Val Loss: 0.6945, Val Acc: 0.6015
Epoch 58/100, Loss: 0.5556, Acc: 0.7127, Val Loss: 0.6967, Val Acc: 0.6055
Epoch 59/100, Loss: 0.5554, Acc: 0.7119, Val Loss: 0.6989, Val Acc: 0.6062
Epoch 60/100, Loss: 0.5554, Acc: 0.7120, Val Loss: 0.6986, Val Acc: 0.5934
Epoch 61/100, Loss: 0.5554, Acc: 0.7119, Val Loss: 0.6992, Val Acc: 0.5996
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5551, Acc: 0.7129, Val Loss: 0.6959, Val Acc: 0.6055
Epoch 63/100, Loss: 0.5552, Acc: 0.7131, Val Loss: 0.6988, Val Acc: 0.6033
Epoch 64/100, Loss: 0.5551, Acc: 0.7132, Val Loss: 0.6963, Val Acc: 0.6059
Epoch 65/100, Loss: 0.5551, Acc: 0.7124, Val Loss: 0.6961, Val Acc: 0.6044
Epoch 66/100, Loss: 0.5550, Acc: 0.7131, Val Loss: 0.6974, Val Acc: 0.6055
Epoch 67/100, Loss: 0.5549, Acc: 0.7134, Val Loss: 0.6953, Val Acc: 0.6037
Epoch 68/100, Loss: 0.5549, Acc: 0.7127, Val Loss: 0.6967, Val Acc: 0.6044
Epoch 69/100, Loss: 0.5549, Acc: 0.7134, Val Loss: 0.6955, Val Acc: 0.6048
Epoch 70/100, Loss: 0.5548, Acc: 0.7134, Val Loss: 0.6966, Val Acc: 0.6044
Epoch 71/100, Loss: 0.5549, Acc: 0.7132, Val Loss: 0.6972, Val Acc: 0.6062
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5548, Acc: 0.7125, Val Loss: 0.6980, Val Acc: 0.6033
Epoch 73/100, Loss: 0.5548, Acc: 0.7132, Val Loss: 0.6978, Val Acc: 0.6029
Epoch 74/100, Loss: 0.5548, Acc: 0.7133, Val Loss: 0.6978, Val Acc: 0.6044
Epoch 75/100, Loss: 0.5547, Acc: 0.7129, Val Loss: 0.6969, Val Acc: 0.6055
Epoch 76/100, Loss: 0.5547, Acc: 0.7129, Val Loss: 0.6971, Val Acc: 0.6055
Epoch 77/100, Loss: 0.5547, Acc: 0.7116, Val Loss: 0.6980, Val Acc: 0.6033
Epoch 78/100, Loss: 0.5548, Acc: 0.7130, Val Loss: 0.6966, Val Acc: 0.6051
Epoch 79/100, Loss: 0.5547, Acc: 0.7125, Val Loss: 0.6960, Val Acc: 0.6062
Epoch 80/100, Loss: 0.5547, Acc: 0.7126, Val Loss: 0.6975, Val Acc: 0.6044
Epoch 81/100, Loss: 0.5547, Acc: 0.7121, Val Loss: 0.6982, Val Acc: 0.6037
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5546, Acc: 0.7131, Val Loss: 0.6972, Val Acc: 0.6055
Epoch 83/100, Loss: 0.5546, Acc: 0.7131, Val Loss: 0.6976, Val Acc: 0.6051
Epoch 84/100, Loss: 0.5546, Acc: 0.7127, Val Loss: 0.6955, Val Acc: 0.6059
Epoch 85/100, Loss: 0.5546, Acc: 0.7127, Val Loss: 0.6968, Val Acc: 0.6040
Epoch 86/100, Loss: 0.5546, Acc: 0.7134, Val Loss: 0.6973, Val Acc: 0.6044
Epoch 87/100, Loss: 0.5545, Acc: 0.7131, Val Loss: 0.6975, Val Acc: 0.6051
Epoch 88/100, Loss: 0.5545, Acc: 0.7129, Val Loss: 0.6975, Val Acc: 0.6033
Epoch 89/100, Loss: 0.5546, Acc: 0.7129, Val Loss: 0.6983, Val Acc: 0.6055
Epoch 90/100, Loss: 0.5544, Acc: 0.7121, Val Loss: 0.6961, Val Acc: 0.6066
Epoch 91/100, Loss: 0.5545, Acc: 0.7128, Val Loss: 0.6977, Val Acc: 0.6022
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5544, Acc: 0.7130, Val Loss: 0.6972, Val Acc: 0.6011
Epoch 93/100, Loss: 0.5546, Acc: 0.7134, Val Loss: 0.6978, Val Acc: 0.6018
Epoch 94/100, Loss: 0.5545, Acc: 0.7127, Val Loss: 0.6961, Val Acc: 0.6051
Epoch 95/100, Loss: 0.5545, Acc: 0.7134, Val Loss: 0.6958, Val Acc: 0.6048
Epoch 96/100, Loss: 0.5544, Acc: 0.7129, Val Loss: 0.6972, Val Acc: 0.6037
Epoch 97/100, Loss: 0.5544, Acc: 0.7128, Val Loss: 0.6981, Val Acc: 0.6059
Epoch 98/100, Loss: 0.5543, Acc: 0.7130, Val Loss: 0.6972, Val Acc: 0.6048
Epoch 99/100, Loss: 0.5543, Acc: 0.7130, Val Loss: 0.6979, Val Acc: 0.6040
Epoch 100/100, Loss: 0.5543, Acc: 0.7121, Val Loss: 0.6978, Val Acc: 0.6048

##############################
Resultados para principal:  051  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1 
 {'training': [0.5542910158634186, 0.7121323529411765, 0.738626964433416, 0.6566176470588235, 0.6952121448034254], 'validate': [0.6977511824563493, 0.6047794117647058, 0.6163265306122448, 0.5551470588235294, 0.5841392649903289], 'test': [0.5176019773439124, 0.7623529411764706, 0.7903645833333334, 0.7141176470588235, 0.7503090234857849]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  096  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  096  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  096  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6905, Acc: 0.5336, Val Loss: 0.6765, Val Acc: 0.6518
Mejor modelo guardado con Val Loss: 0.6765
Epoch 2/100, Loss: 0.6929, Acc: 0.5033, Val Loss: 0.6933, Val Acc: 0.5011
Epoch 3/100, Loss: 0.6933, Acc: 0.4995, Val Loss: 0.6920, Val Acc: 0.5180
Epoch 4/100, Loss: 0.6937, Acc: 0.5025, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 5/100, Loss: 0.6934, Acc: 0.5002, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 6/100, Loss: 0.6934, Acc: 0.4945, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6933, Acc: 0.4970, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 8/100, Loss: 0.6935, Acc: 0.4950, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6934, Acc: 0.4938, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 10/100, Loss: 0.6934, Acc: 0.4980, Val Loss: 0.6935, Val Acc: 0.5000
Epoch 11/100, Loss: 0.6934, Acc: 0.5016, Val Loss: 0.6936, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.5011, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6933, Acc: 0.5028, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6933, Acc: 0.4939, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 16/100, Loss: 0.6933, Acc: 0.4996, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6932, Acc: 0.4994, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 18/100, Loss: 0.6933, Acc: 0.4943, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 19/100, Loss: 0.6933, Acc: 0.5011, Val Loss: 0.6932, Val Acc: 0.5040
Epoch 20/100, Loss: 0.6928, Acc: 0.5155, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 21/100, Loss: 0.6933, Acc: 0.4912, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4991, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 23/100, Loss: 0.6932, Acc: 0.4963, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 24/100, Loss: 0.6932, Acc: 0.4980, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 25/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 26/100, Loss: 0.6932, Acc: 0.4901, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 27/100, Loss: 0.6932, Acc: 0.4982, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 28/100, Loss: 0.6932, Acc: 0.5011, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 29/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 30/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 31/100, Loss: 0.6932, Acc: 0.5011, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6930, Acc: 0.5016, Val Loss: 0.6912, Val Acc: 0.5794
Epoch 33/100, Loss: 0.6904, Acc: 0.5636, Val Loss: 0.6907, Val Acc: 0.5585
Epoch 34/100, Loss: 0.6899, Acc: 0.5700, Val Loss: 0.6884, Val Acc: 0.6022
Epoch 35/100, Loss: 0.6893, Acc: 0.5801, Val Loss: 0.6878, Val Acc: 0.6026
Epoch 36/100, Loss: 0.6889, Acc: 0.5808, Val Loss: 0.6876, Val Acc: 0.6011
Epoch 37/100, Loss: 0.6884, Acc: 0.5841, Val Loss: 0.6874, Val Acc: 0.5886
Epoch 38/100, Loss: 0.6879, Acc: 0.5877, Val Loss: 0.6863, Val Acc: 0.6096
Epoch 39/100, Loss: 0.6874, Acc: 0.5869, Val Loss: 0.6856, Val Acc: 0.6114
Epoch 40/100, Loss: 0.6869, Acc: 0.5884, Val Loss: 0.6845, Val Acc: 0.6202
Epoch 41/100, Loss: 0.6866, Acc: 0.5868, Val Loss: 0.6842, Val Acc: 0.6099
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6859, Acc: 0.5944, Val Loss: 0.6841, Val Acc: 0.6162
Epoch 43/100, Loss: 0.6857, Acc: 0.5955, Val Loss: 0.6834, Val Acc: 0.6129
Epoch 44/100, Loss: 0.6855, Acc: 0.5946, Val Loss: 0.6832, Val Acc: 0.6132
Epoch 45/100, Loss: 0.6852, Acc: 0.5959, Val Loss: 0.6832, Val Acc: 0.6158
Epoch 46/100, Loss: 0.6850, Acc: 0.5934, Val Loss: 0.6824, Val Acc: 0.6162
Epoch 47/100, Loss: 0.6846, Acc: 0.5993, Val Loss: 0.6831, Val Acc: 0.6110
Epoch 48/100, Loss: 0.6845, Acc: 0.5956, Val Loss: 0.6817, Val Acc: 0.6184
Epoch 49/100, Loss: 0.6842, Acc: 0.5988, Val Loss: 0.6814, Val Acc: 0.6217
Epoch 50/100, Loss: 0.6839, Acc: 0.5965, Val Loss: 0.6809, Val Acc: 0.6210
Epoch 51/100, Loss: 0.6836, Acc: 0.5974, Val Loss: 0.6808, Val Acc: 0.6221
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6833, Acc: 0.6011, Val Loss: 0.6792, Val Acc: 0.6283
Epoch 53/100, Loss: 0.6824, Acc: 0.5959, Val Loss: 0.6773, Val Acc: 0.6250
Epoch 54/100, Loss: 0.6820, Acc: 0.5993, Val Loss: 0.6771, Val Acc: 0.6195
Epoch 55/100, Loss: 0.6816, Acc: 0.5983, Val Loss: 0.6766, Val Acc: 0.6261
Epoch 56/100, Loss: 0.6815, Acc: 0.5962, Val Loss: 0.6766, Val Acc: 0.6235
Epoch 57/100, Loss: 0.6812, Acc: 0.6017, Val Loss: 0.6771, Val Acc: 0.6176
Epoch 58/100, Loss: 0.6808, Acc: 0.5972, Val Loss: 0.6743, Val Acc: 0.6107
Mejor modelo guardado con Val Loss: 0.6743
Epoch 59/100, Loss: 0.6803, Acc: 0.6021, Val Loss: 0.6734, Val Acc: 0.6151
Mejor modelo guardado con Val Loss: 0.6734
Epoch 60/100, Loss: 0.6799, Acc: 0.6029, Val Loss: 0.6730, Val Acc: 0.6169
Mejor modelo guardado con Val Loss: 0.6730
Epoch 61/100, Loss: 0.6797, Acc: 0.5998, Val Loss: 0.6722, Val Acc: 0.6312
Mejor modelo guardado con Val Loss: 0.6722
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6794, Acc: 0.6041, Val Loss: 0.6719, Val Acc: 0.6349
Mejor modelo guardado con Val Loss: 0.6719
Epoch 63/100, Loss: 0.6792, Acc: 0.6039, Val Loss: 0.6719, Val Acc: 0.6305
Epoch 64/100, Loss: 0.6791, Acc: 0.6043, Val Loss: 0.6718, Val Acc: 0.6309
Mejor modelo guardado con Val Loss: 0.6718
Epoch 65/100, Loss: 0.6790, Acc: 0.6041, Val Loss: 0.6715, Val Acc: 0.6331
Mejor modelo guardado con Val Loss: 0.6715
Epoch 66/100, Loss: 0.6789, Acc: 0.6062, Val Loss: 0.6712, Val Acc: 0.6357
Mejor modelo guardado con Val Loss: 0.6712
Epoch 67/100, Loss: 0.6788, Acc: 0.6053, Val Loss: 0.6714, Val Acc: 0.6272
Epoch 68/100, Loss: 0.6786, Acc: 0.6040, Val Loss: 0.6707, Val Acc: 0.6368
Mejor modelo guardado con Val Loss: 0.6707
Epoch 69/100, Loss: 0.6785, Acc: 0.6074, Val Loss: 0.6711, Val Acc: 0.6294
Epoch 70/100, Loss: 0.6784, Acc: 0.6049, Val Loss: 0.6707, Val Acc: 0.6349
Mejor modelo guardado con Val Loss: 0.6707
Epoch 71/100, Loss: 0.6783, Acc: 0.6067, Val Loss: 0.6702, Val Acc: 0.6386
Mejor modelo guardado con Val Loss: 0.6702
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6782, Acc: 0.6060, Val Loss: 0.6702, Val Acc: 0.6368
Mejor modelo guardado con Val Loss: 0.6702
Epoch 73/100, Loss: 0.6781, Acc: 0.6039, Val Loss: 0.6702, Val Acc: 0.6360
Epoch 74/100, Loss: 0.6780, Acc: 0.6060, Val Loss: 0.6700, Val Acc: 0.6379
Mejor modelo guardado con Val Loss: 0.6700
Epoch 75/100, Loss: 0.6779, Acc: 0.6069, Val Loss: 0.6699, Val Acc: 0.6386
Mejor modelo guardado con Val Loss: 0.6699
Epoch 76/100, Loss: 0.6778, Acc: 0.6053, Val Loss: 0.6697, Val Acc: 0.6371
Mejor modelo guardado con Val Loss: 0.6697
Epoch 77/100, Loss: 0.6776, Acc: 0.6066, Val Loss: 0.6696, Val Acc: 0.6364
Mejor modelo guardado con Val Loss: 0.6696
Epoch 78/100, Loss: 0.6775, Acc: 0.6069, Val Loss: 0.6693, Val Acc: 0.6382
Mejor modelo guardado con Val Loss: 0.6693
Epoch 79/100, Loss: 0.6774, Acc: 0.6068, Val Loss: 0.6691, Val Acc: 0.6368
Mejor modelo guardado con Val Loss: 0.6691
Epoch 80/100, Loss: 0.6773, Acc: 0.6092, Val Loss: 0.6693, Val Acc: 0.6349
Epoch 81/100, Loss: 0.6772, Acc: 0.6068, Val Loss: 0.6691, Val Acc: 0.6360
Mejor modelo guardado con Val Loss: 0.6691
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6771, Acc: 0.6077, Val Loss: 0.6690, Val Acc: 0.6357
Mejor modelo guardado con Val Loss: 0.6690
Epoch 83/100, Loss: 0.6770, Acc: 0.6085, Val Loss: 0.6688, Val Acc: 0.6371
Mejor modelo guardado con Val Loss: 0.6688
Epoch 84/100, Loss: 0.6769, Acc: 0.6072, Val Loss: 0.6687, Val Acc: 0.6390
Mejor modelo guardado con Val Loss: 0.6687
Epoch 85/100, Loss: 0.6768, Acc: 0.6071, Val Loss: 0.6686, Val Acc: 0.6397
Mejor modelo guardado con Val Loss: 0.6686
Epoch 86/100, Loss: 0.6767, Acc: 0.6084, Val Loss: 0.6685, Val Acc: 0.6379
Mejor modelo guardado con Val Loss: 0.6685
Epoch 87/100, Loss: 0.6767, Acc: 0.6080, Val Loss: 0.6684, Val Acc: 0.6371
Mejor modelo guardado con Val Loss: 0.6684
Epoch 88/100, Loss: 0.6766, Acc: 0.6078, Val Loss: 0.6682, Val Acc: 0.6386
Mejor modelo guardado con Val Loss: 0.6682
Epoch 89/100, Loss: 0.6765, Acc: 0.6075, Val Loss: 0.6680, Val Acc: 0.6393
Mejor modelo guardado con Val Loss: 0.6680
Epoch 90/100, Loss: 0.6764, Acc: 0.6085, Val Loss: 0.6679, Val Acc: 0.6386
Mejor modelo guardado con Val Loss: 0.6679
Epoch 91/100, Loss: 0.6763, Acc: 0.6091, Val Loss: 0.6679, Val Acc: 0.6379
Mejor modelo guardado con Val Loss: 0.6679
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6762, Acc: 0.6097, Val Loss: 0.6675, Val Acc: 0.6390
Mejor modelo guardado con Val Loss: 0.6675
Epoch 93/100, Loss: 0.6761, Acc: 0.6080, Val Loss: 0.6674, Val Acc: 0.6386
Mejor modelo guardado con Val Loss: 0.6674
Epoch 94/100, Loss: 0.6759, Acc: 0.6079, Val Loss: 0.6674, Val Acc: 0.6379
Mejor modelo guardado con Val Loss: 0.6674
Epoch 95/100, Loss: 0.6758, Acc: 0.6090, Val Loss: 0.6672, Val Acc: 0.6386
Mejor modelo guardado con Val Loss: 0.6672
Epoch 96/100, Loss: 0.6757, Acc: 0.6095, Val Loss: 0.6668, Val Acc: 0.6371
Mejor modelo guardado con Val Loss: 0.6668
Epoch 97/100, Loss: 0.6756, Acc: 0.6097, Val Loss: 0.6666, Val Acc: 0.6415
Mejor modelo guardado con Val Loss: 0.6666
Epoch 98/100, Loss: 0.6754, Acc: 0.6097, Val Loss: 0.6662, Val Acc: 0.6401
Mejor modelo guardado con Val Loss: 0.6662
Epoch 99/100, Loss: 0.6752, Acc: 0.6100, Val Loss: 0.6658, Val Acc: 0.6390
Mejor modelo guardado con Val Loss: 0.6658
Epoch 100/100, Loss: 0.6749, Acc: 0.6102, Val Loss: 0.6653, Val Acc: 0.6357
Mejor modelo guardado con Val Loss: 0.6653

##############################
Resultados para principal:  096  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1 
 {'training': [0.6749223218244664, 0.610202205882353, 0.6051201122216378, 0.634375, 0.6194023153549314], 'validate': [0.6652516597925231, 0.6356617647058823, 0.6589147286821705, 0.5625, 0.6069020230067433], 'test': [0.6699071835588526, 0.6314705882352941, 0.6513202437373053, 0.5658823529411765, 0.6056027699087189]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  034  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  034  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  034  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6917, Acc: 0.5253, Val Loss: 0.6944, Val Acc: 0.4882
Mejor modelo guardado con Val Loss: 0.6944
Epoch 2/100, Loss: 0.6923, Acc: 0.5151, Val Loss: 0.6946, Val Acc: 0.4974
Epoch 3/100, Loss: 0.6932, Acc: 0.5065, Val Loss: 0.6950, Val Acc: 0.5000
Epoch 4/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6932, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6932
Epoch 5/100, Loss: 0.6934, Acc: 0.4948, Val Loss: 0.6931, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6931
Epoch 6/100, Loss: 0.6934, Acc: 0.4988, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6935, Acc: 0.4946, Val Loss: 0.6937, Val Acc: 0.5000
Epoch 8/100, Loss: 0.6932, Acc: 0.5089, Val Loss: 0.6933, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6933, Acc: 0.4965, Val Loss: 0.6941, Val Acc: 0.4989
Epoch 10/100, Loss: 0.6935, Acc: 0.4953, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 11/100, Loss: 0.6933, Acc: 0.4950, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4938, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6932, Acc: 0.5018, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 14/100, Loss: 0.6933, Acc: 0.4921, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 15/100, Loss: 0.6933, Acc: 0.4952, Val Loss: 0.6931, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6931
Epoch 16/100, Loss: 0.6933, Acc: 0.4982, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 17/100, Loss: 0.6932, Acc: 0.5051, Val Loss: 0.6935, Val Acc: 0.5000
Epoch 18/100, Loss: 0.6934, Acc: 0.4958, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 19/100, Loss: 0.6933, Acc: 0.4935, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 20/100, Loss: 0.6932, Acc: 0.5013, Val Loss: 0.6935, Val Acc: 0.5000
Epoch 21/100, Loss: 0.6934, Acc: 0.4971, Val Loss: 0.6932, Val Acc: 0.5000
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4928, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 23/100, Loss: 0.6932, Acc: 0.4939, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 24/100, Loss: 0.6932, Acc: 0.4940, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 25/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 26/100, Loss: 0.6932, Acc: 0.5039, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 27/100, Loss: 0.6932, Acc: 0.4996, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 28/100, Loss: 0.6932, Acc: 0.4917, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 29/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 30/100, Loss: 0.6933, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 31/100, Loss: 0.6932, Acc: 0.4972, Val Loss: 0.6932, Val Acc: 0.5000
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 33/100, Loss: 0.6932, Acc: 0.4976, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 34/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 35/100, Loss: 0.6932, Acc: 0.4954, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 36/100, Loss: 0.6932, Acc: 0.4903, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 37/100, Loss: 0.6932, Acc: 0.4982, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 38/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 39/100, Loss: 0.6932, Acc: 0.4870, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 40/100, Loss: 0.6932, Acc: 0.4932, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 41/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.5000
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6932, Val Acc: 0.5000
Epoch 43/100, Loss: 0.6932, Acc: 0.4943, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 44/100, Loss: 0.6932, Acc: 0.4991, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 45/100, Loss: 0.6932, Acc: 0.4912, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 46/100, Loss: 0.6932, Acc: 0.4973, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 47/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 48/100, Loss: 0.6932, Acc: 0.4948, Val Loss: 0.6931, Val Acc: 0.4989
Epoch 49/100, Loss: 0.6932, Acc: 0.5001, Val Loss: 0.6932, Val Acc: 0.5011
Epoch 50/100, Loss: 0.6921, Acc: 0.5072, Val Loss: 0.6970, Val Acc: 0.4735
Epoch 51/100, Loss: 0.6906, Acc: 0.5577, Val Loss: 0.6965, Val Acc: 0.4754
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6902, Acc: 0.5546, Val Loss: 0.6966, Val Acc: 0.4596
Epoch 53/100, Loss: 0.6901, Acc: 0.5558, Val Loss: 0.6967, Val Acc: 0.4533
Epoch 54/100, Loss: 0.6900, Acc: 0.5576, Val Loss: 0.6965, Val Acc: 0.4603
Epoch 55/100, Loss: 0.6899, Acc: 0.5561, Val Loss: 0.6965, Val Acc: 0.4570
Epoch 56/100, Loss: 0.6899, Acc: 0.5574, Val Loss: 0.6966, Val Acc: 0.4548
Epoch 57/100, Loss: 0.6897, Acc: 0.5564, Val Loss: 0.6968, Val Acc: 0.4408
Epoch 58/100, Loss: 0.6897, Acc: 0.5593, Val Loss: 0.6965, Val Acc: 0.4562
Epoch 59/100, Loss: 0.6897, Acc: 0.5582, Val Loss: 0.6967, Val Acc: 0.4493
Epoch 60/100, Loss: 0.6896, Acc: 0.5603, Val Loss: 0.6965, Val Acc: 0.4585
Epoch 61/100, Loss: 0.6895, Acc: 0.5599, Val Loss: 0.6966, Val Acc: 0.4599
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6895, Acc: 0.5612, Val Loss: 0.6966, Val Acc: 0.4559
Epoch 63/100, Loss: 0.6894, Acc: 0.5615, Val Loss: 0.6968, Val Acc: 0.4522
Epoch 64/100, Loss: 0.6894, Acc: 0.5606, Val Loss: 0.6967, Val Acc: 0.4544
Epoch 65/100, Loss: 0.6894, Acc: 0.5618, Val Loss: 0.6969, Val Acc: 0.4467
Epoch 66/100, Loss: 0.6893, Acc: 0.5622, Val Loss: 0.6967, Val Acc: 0.4562
Epoch 67/100, Loss: 0.6893, Acc: 0.5617, Val Loss: 0.6968, Val Acc: 0.4559
Epoch 68/100, Loss: 0.6893, Acc: 0.5615, Val Loss: 0.6970, Val Acc: 0.4460
Epoch 69/100, Loss: 0.6893, Acc: 0.5615, Val Loss: 0.6970, Val Acc: 0.4456
Epoch 70/100, Loss: 0.6892, Acc: 0.5614, Val Loss: 0.6970, Val Acc: 0.4511
Epoch 71/100, Loss: 0.6892, Acc: 0.5631, Val Loss: 0.6970, Val Acc: 0.4511
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6892, Acc: 0.5619, Val Loss: 0.6970, Val Acc: 0.4500
Epoch 73/100, Loss: 0.6891, Acc: 0.5620, Val Loss: 0.6971, Val Acc: 0.4496
Epoch 74/100, Loss: 0.6891, Acc: 0.5622, Val Loss: 0.6971, Val Acc: 0.4493
Epoch 75/100, Loss: 0.6891, Acc: 0.5620, Val Loss: 0.6971, Val Acc: 0.4504
Epoch 76/100, Loss: 0.6891, Acc: 0.5625, Val Loss: 0.6971, Val Acc: 0.4522
Epoch 77/100, Loss: 0.6891, Acc: 0.5608, Val Loss: 0.6972, Val Acc: 0.4437
Epoch 78/100, Loss: 0.6891, Acc: 0.5619, Val Loss: 0.6973, Val Acc: 0.4437
Epoch 79/100, Loss: 0.6890, Acc: 0.5621, Val Loss: 0.6972, Val Acc: 0.4507
Epoch 80/100, Loss: 0.6890, Acc: 0.5621, Val Loss: 0.6971, Val Acc: 0.4540
Epoch 81/100, Loss: 0.6890, Acc: 0.5620, Val Loss: 0.6972, Val Acc: 0.4537
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6890, Acc: 0.5623, Val Loss: 0.6972, Val Acc: 0.4522
Epoch 83/100, Loss: 0.6890, Acc: 0.5644, Val Loss: 0.6973, Val Acc: 0.4493
Epoch 84/100, Loss: 0.6890, Acc: 0.5633, Val Loss: 0.6972, Val Acc: 0.4515
Epoch 85/100, Loss: 0.6889, Acc: 0.5632, Val Loss: 0.6973, Val Acc: 0.4478
Epoch 86/100, Loss: 0.6889, Acc: 0.5609, Val Loss: 0.6972, Val Acc: 0.4522
Epoch 87/100, Loss: 0.6889, Acc: 0.5634, Val Loss: 0.6972, Val Acc: 0.4474
Epoch 88/100, Loss: 0.6888, Acc: 0.5611, Val Loss: 0.6969, Val Acc: 0.4551
Epoch 89/100, Loss: 0.6888, Acc: 0.5634, Val Loss: 0.6967, Val Acc: 0.4610
Epoch 90/100, Loss: 0.6887, Acc: 0.5640, Val Loss: 0.6967, Val Acc: 0.4577
Epoch 91/100, Loss: 0.6887, Acc: 0.5631, Val Loss: 0.6966, Val Acc: 0.4621
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6887, Acc: 0.5632, Val Loss: 0.6967, Val Acc: 0.4544
Epoch 93/100, Loss: 0.6887, Acc: 0.5622, Val Loss: 0.6966, Val Acc: 0.4577
Epoch 94/100, Loss: 0.6887, Acc: 0.5615, Val Loss: 0.6965, Val Acc: 0.4588
Epoch 95/100, Loss: 0.6886, Acc: 0.5631, Val Loss: 0.6967, Val Acc: 0.4570
Epoch 96/100, Loss: 0.6885, Acc: 0.5626, Val Loss: 0.6970, Val Acc: 0.4540
Epoch 97/100, Loss: 0.6883, Acc: 0.5611, Val Loss: 0.6970, Val Acc: 0.4566
Epoch 98/100, Loss: 0.6883, Acc: 0.5617, Val Loss: 0.6970, Val Acc: 0.4562
Epoch 99/100, Loss: 0.6882, Acc: 0.5631, Val Loss: 0.6971, Val Acc: 0.4544
Epoch 100/100, Loss: 0.6882, Acc: 0.5621, Val Loss: 0.6971, Val Acc: 0.4562

##############################
Resultados para principal:  034  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1 
 {'training': [0.6882028292207157, 0.5621323529411765, 0.5563333333333333, 0.6136029411764706, 0.5835664335664336], 'validate': [0.6970869011657183, 0.45625, 0.4592186429061001, 0.49264705882352944, 0.47534586732884], 'test': [0.6930228681476028, 0.5, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  014  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  014  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  014  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6662, Acc: 0.6199, Val Loss: 0.7087, Val Acc: 0.4853
Mejor modelo guardado con Val Loss: 0.7087
Epoch 2/100, Loss: 0.6393, Acc: 0.6470, Val Loss: 0.7167, Val Acc: 0.4835
Epoch 3/100, Loss: 0.6419, Acc: 0.6460, Val Loss: 0.7187, Val Acc: 0.4824
Epoch 4/100, Loss: 0.6407, Acc: 0.6458, Val Loss: 0.7234, Val Acc: 0.4721
Epoch 5/100, Loss: 0.6339, Acc: 0.6536, Val Loss: 0.7191, Val Acc: 0.5022
Epoch 6/100, Loss: 0.6286, Acc: 0.6546, Val Loss: 0.7320, Val Acc: 0.4801
Epoch 7/100, Loss: 0.6233, Acc: 0.6600, Val Loss: 0.7244, Val Acc: 0.5037
Epoch 8/100, Loss: 0.6261, Acc: 0.6665, Val Loss: 0.7421, Val Acc: 0.5018
Epoch 9/100, Loss: 0.6226, Acc: 0.6508, Val Loss: 0.7616, Val Acc: 0.4868
Epoch 10/100, Loss: 0.6160, Acc: 0.6701, Val Loss: 0.7414, Val Acc: 0.5022
Epoch 11/100, Loss: 0.6165, Acc: 0.6543, Val Loss: 0.7368, Val Acc: 0.5033
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6109, Acc: 0.6754, Val Loss: 0.7316, Val Acc: 0.5033
Epoch 13/100, Loss: 0.6087, Acc: 0.6739, Val Loss: 0.7763, Val Acc: 0.4893
Epoch 14/100, Loss: 0.6067, Acc: 0.6716, Val Loss: 0.7539, Val Acc: 0.4956
Epoch 15/100, Loss: 0.6059, Acc: 0.6786, Val Loss: 0.7482, Val Acc: 0.5000
Epoch 16/100, Loss: 0.6043, Acc: 0.6735, Val Loss: 0.7757, Val Acc: 0.4945
Epoch 17/100, Loss: 0.6054, Acc: 0.6754, Val Loss: 0.7599, Val Acc: 0.4996
Epoch 18/100, Loss: 0.6038, Acc: 0.6775, Val Loss: 0.7510, Val Acc: 0.4982
Epoch 19/100, Loss: 0.6059, Acc: 0.6772, Val Loss: 0.7543, Val Acc: 0.4945
Epoch 20/100, Loss: 0.6076, Acc: 0.6642, Val Loss: 0.7830, Val Acc: 0.4985
Epoch 21/100, Loss: 0.6065, Acc: 0.6662, Val Loss: 0.7629, Val Acc: 0.5018
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6054, Acc: 0.6790, Val Loss: 0.7695, Val Acc: 0.5000
Epoch 23/100, Loss: 0.5998, Acc: 0.6836, Val Loss: 0.7671, Val Acc: 0.5037
Epoch 24/100, Loss: 0.6004, Acc: 0.6804, Val Loss: 0.7768, Val Acc: 0.5018
Epoch 25/100, Loss: 0.6009, Acc: 0.6816, Val Loss: 0.7831, Val Acc: 0.5059
Epoch 26/100, Loss: 0.6011, Acc: 0.6805, Val Loss: 0.7531, Val Acc: 0.5051
Epoch 27/100, Loss: 0.5991, Acc: 0.6858, Val Loss: 0.7716, Val Acc: 0.4985
Epoch 28/100, Loss: 0.5992, Acc: 0.6817, Val Loss: 0.7557, Val Acc: 0.5029
Epoch 29/100, Loss: 0.6001, Acc: 0.6814, Val Loss: 0.7700, Val Acc: 0.5029
Epoch 30/100, Loss: 0.5984, Acc: 0.6843, Val Loss: 0.7638, Val Acc: 0.4967
Epoch 31/100, Loss: 0.5992, Acc: 0.6835, Val Loss: 0.7759, Val Acc: 0.4978
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5976, Acc: 0.6834, Val Loss: 0.7840, Val Acc: 0.5007
Epoch 33/100, Loss: 0.5980, Acc: 0.6849, Val Loss: 0.7703, Val Acc: 0.5048
Epoch 34/100, Loss: 0.5980, Acc: 0.6794, Val Loss: 0.7765, Val Acc: 0.5026
Epoch 35/100, Loss: 0.5970, Acc: 0.6828, Val Loss: 0.7656, Val Acc: 0.5033
Epoch 36/100, Loss: 0.5955, Acc: 0.6860, Val Loss: 0.7724, Val Acc: 0.4971
Epoch 37/100, Loss: 0.5964, Acc: 0.6827, Val Loss: 0.7732, Val Acc: 0.4978
Epoch 38/100, Loss: 0.5967, Acc: 0.6825, Val Loss: 0.7776, Val Acc: 0.5048
Epoch 39/100, Loss: 0.5971, Acc: 0.6824, Val Loss: 0.7772, Val Acc: 0.4993
Epoch 40/100, Loss: 0.5954, Acc: 0.6839, Val Loss: 0.7807, Val Acc: 0.5004
Epoch 41/100, Loss: 0.5960, Acc: 0.6851, Val Loss: 0.7854, Val Acc: 0.5029
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5954, Acc: 0.6825, Val Loss: 0.7819, Val Acc: 0.5015
Epoch 43/100, Loss: 0.5950, Acc: 0.6836, Val Loss: 0.7824, Val Acc: 0.5000
Epoch 44/100, Loss: 0.5943, Acc: 0.6843, Val Loss: 0.7715, Val Acc: 0.5026
Epoch 45/100, Loss: 0.5948, Acc: 0.6843, Val Loss: 0.7751, Val Acc: 0.5011
Epoch 46/100, Loss: 0.5942, Acc: 0.6852, Val Loss: 0.7784, Val Acc: 0.5015
Epoch 47/100, Loss: 0.5943, Acc: 0.6824, Val Loss: 0.7825, Val Acc: 0.5040
Epoch 48/100, Loss: 0.5943, Acc: 0.6845, Val Loss: 0.7823, Val Acc: 0.5000
Epoch 49/100, Loss: 0.5946, Acc: 0.6854, Val Loss: 0.7784, Val Acc: 0.5026
Epoch 50/100, Loss: 0.5934, Acc: 0.6847, Val Loss: 0.7864, Val Acc: 0.5004
Epoch 51/100, Loss: 0.5938, Acc: 0.6860, Val Loss: 0.7733, Val Acc: 0.5070
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5935, Acc: 0.6847, Val Loss: 0.7808, Val Acc: 0.5018
Epoch 53/100, Loss: 0.5936, Acc: 0.6840, Val Loss: 0.7797, Val Acc: 0.5026
Epoch 54/100, Loss: 0.5936, Acc: 0.6835, Val Loss: 0.7797, Val Acc: 0.5000
Epoch 55/100, Loss: 0.5932, Acc: 0.6862, Val Loss: 0.7786, Val Acc: 0.5037
Epoch 56/100, Loss: 0.5933, Acc: 0.6869, Val Loss: 0.7773, Val Acc: 0.5026
Epoch 57/100, Loss: 0.5933, Acc: 0.6851, Val Loss: 0.7767, Val Acc: 0.5044
Epoch 58/100, Loss: 0.5935, Acc: 0.6856, Val Loss: 0.7774, Val Acc: 0.5018
Epoch 59/100, Loss: 0.5933, Acc: 0.6853, Val Loss: 0.7794, Val Acc: 0.4985
Epoch 60/100, Loss: 0.5933, Acc: 0.6874, Val Loss: 0.7802, Val Acc: 0.5022
Epoch 61/100, Loss: 0.5931, Acc: 0.6867, Val Loss: 0.7791, Val Acc: 0.5018
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5928, Acc: 0.6861, Val Loss: 0.7782, Val Acc: 0.5037
Epoch 63/100, Loss: 0.5928, Acc: 0.6864, Val Loss: 0.7763, Val Acc: 0.5037
Epoch 64/100, Loss: 0.5929, Acc: 0.6841, Val Loss: 0.7786, Val Acc: 0.5026
Epoch 65/100, Loss: 0.5928, Acc: 0.6862, Val Loss: 0.7789, Val Acc: 0.5015
Epoch 66/100, Loss: 0.5928, Acc: 0.6862, Val Loss: 0.7786, Val Acc: 0.5029
Epoch 67/100, Loss: 0.5927, Acc: 0.6856, Val Loss: 0.7808, Val Acc: 0.5000
Epoch 68/100, Loss: 0.5929, Acc: 0.6865, Val Loss: 0.7773, Val Acc: 0.5018
Epoch 69/100, Loss: 0.5927, Acc: 0.6856, Val Loss: 0.7772, Val Acc: 0.5048
Epoch 70/100, Loss: 0.5928, Acc: 0.6852, Val Loss: 0.7788, Val Acc: 0.5029
Epoch 71/100, Loss: 0.5925, Acc: 0.6867, Val Loss: 0.7793, Val Acc: 0.5022
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5925, Acc: 0.6869, Val Loss: 0.7786, Val Acc: 0.5026
Epoch 73/100, Loss: 0.5924, Acc: 0.6851, Val Loss: 0.7808, Val Acc: 0.4996
Epoch 74/100, Loss: 0.5925, Acc: 0.6869, Val Loss: 0.7802, Val Acc: 0.5022
Epoch 75/100, Loss: 0.5924, Acc: 0.6859, Val Loss: 0.7782, Val Acc: 0.5040
Epoch 76/100, Loss: 0.5924, Acc: 0.6857, Val Loss: 0.7794, Val Acc: 0.5011
Epoch 77/100, Loss: 0.5924, Acc: 0.6882, Val Loss: 0.7782, Val Acc: 0.5037
Epoch 78/100, Loss: 0.5924, Acc: 0.6881, Val Loss: 0.7787, Val Acc: 0.5029
Epoch 79/100, Loss: 0.5924, Acc: 0.6866, Val Loss: 0.7784, Val Acc: 0.5026
Epoch 80/100, Loss: 0.5924, Acc: 0.6868, Val Loss: 0.7785, Val Acc: 0.5033
Epoch 81/100, Loss: 0.5923, Acc: 0.6875, Val Loss: 0.7782, Val Acc: 0.5037
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5924, Acc: 0.6860, Val Loss: 0.7796, Val Acc: 0.5022
Epoch 83/100, Loss: 0.5923, Acc: 0.6876, Val Loss: 0.7793, Val Acc: 0.5018
Epoch 84/100, Loss: 0.5923, Acc: 0.6872, Val Loss: 0.7793, Val Acc: 0.5015
Epoch 85/100, Loss: 0.5923, Acc: 0.6874, Val Loss: 0.7788, Val Acc: 0.5029
Epoch 86/100, Loss: 0.5922, Acc: 0.6876, Val Loss: 0.7785, Val Acc: 0.5037
Epoch 87/100, Loss: 0.5922, Acc: 0.6854, Val Loss: 0.7805, Val Acc: 0.5000
Epoch 88/100, Loss: 0.5922, Acc: 0.6869, Val Loss: 0.7800, Val Acc: 0.5018
Epoch 89/100, Loss: 0.5922, Acc: 0.6872, Val Loss: 0.7803, Val Acc: 0.5011
Epoch 90/100, Loss: 0.5922, Acc: 0.6874, Val Loss: 0.7809, Val Acc: 0.4996
Epoch 91/100, Loss: 0.5921, Acc: 0.6879, Val Loss: 0.7799, Val Acc: 0.5022
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5921, Acc: 0.6865, Val Loss: 0.7798, Val Acc: 0.5018
Epoch 93/100, Loss: 0.5921, Acc: 0.6876, Val Loss: 0.7792, Val Acc: 0.5018
Epoch 94/100, Loss: 0.5921, Acc: 0.6893, Val Loss: 0.7793, Val Acc: 0.5029
Epoch 95/100, Loss: 0.5920, Acc: 0.6875, Val Loss: 0.7810, Val Acc: 0.5007
Epoch 96/100, Loss: 0.5922, Acc: 0.6872, Val Loss: 0.7797, Val Acc: 0.5015
Epoch 97/100, Loss: 0.5921, Acc: 0.6875, Val Loss: 0.7808, Val Acc: 0.5000
Epoch 98/100, Loss: 0.5921, Acc: 0.6883, Val Loss: 0.7810, Val Acc: 0.5007
Epoch 99/100, Loss: 0.5920, Acc: 0.6878, Val Loss: 0.7805, Val Acc: 0.5000
Epoch 100/100, Loss: 0.5919, Acc: 0.6884, Val Loss: 0.7799, Val Acc: 0.5022

##############################
Resultados para principal:  014  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1 
 {'training': [0.5919478618046816, 0.6884191176470589, 0.7163360067539046, 0.6238970588235294, 0.6669286696797013], 'validate': [0.7798798001089762, 0.5022058823529412, 0.5028735632183908, 0.3860294117647059, 0.4367720465890183], 'test': [0.6880872691119159, 0.5520588235294117, 0.5433186490455213, 0.6529411764705882, 0.5931071333155223]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  092  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  092  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  092  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6842, Acc: 0.5699, Val Loss: 0.6796, Val Acc: 0.6206
Mejor modelo guardado con Val Loss: 0.6796
Epoch 2/100, Loss: 0.6755, Acc: 0.5940, Val Loss: 0.6692, Val Acc: 0.5989
Mejor modelo guardado con Val Loss: 0.6692
Epoch 3/100, Loss: 0.6622, Acc: 0.6116, Val Loss: 0.6551, Val Acc: 0.6301
Mejor modelo guardado con Val Loss: 0.6551
Epoch 4/100, Loss: 0.6542, Acc: 0.6205, Val Loss: 0.6541, Val Acc: 0.6342
Mejor modelo guardado con Val Loss: 0.6541
Epoch 5/100, Loss: 0.6488, Acc: 0.6265, Val Loss: 0.6548, Val Acc: 0.6257
Epoch 6/100, Loss: 0.6434, Acc: 0.6294, Val Loss: 0.6555, Val Acc: 0.6210
Epoch 7/100, Loss: 0.6429, Acc: 0.6242, Val Loss: 0.6778, Val Acc: 0.5607
Epoch 8/100, Loss: 0.6414, Acc: 0.6257, Val Loss: 0.6594, Val Acc: 0.6195
Epoch 9/100, Loss: 0.6394, Acc: 0.6311, Val Loss: 0.6583, Val Acc: 0.6029
Epoch 10/100, Loss: 0.6404, Acc: 0.6288, Val Loss: 0.6568, Val Acc: 0.6283
Epoch 11/100, Loss: 0.6405, Acc: 0.6269, Val Loss: 0.6692, Val Acc: 0.5787
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6386, Acc: 0.6301, Val Loss: 0.6494, Val Acc: 0.6257
Mejor modelo guardado con Val Loss: 0.6494
Epoch 13/100, Loss: 0.6349, Acc: 0.6361, Val Loss: 0.6516, Val Acc: 0.6257
Epoch 14/100, Loss: 0.6350, Acc: 0.6347, Val Loss: 0.6653, Val Acc: 0.5949
Epoch 15/100, Loss: 0.6324, Acc: 0.6396, Val Loss: 0.6708, Val Acc: 0.5801
Epoch 16/100, Loss: 0.6333, Acc: 0.6335, Val Loss: 0.6634, Val Acc: 0.5960
Epoch 17/100, Loss: 0.6338, Acc: 0.6318, Val Loss: 0.6582, Val Acc: 0.6147
Epoch 18/100, Loss: 0.6334, Acc: 0.6328, Val Loss: 0.6634, Val Acc: 0.5963
Epoch 19/100, Loss: 0.6314, Acc: 0.6379, Val Loss: 0.6663, Val Acc: 0.6154
Epoch 20/100, Loss: 0.6308, Acc: 0.6389, Val Loss: 0.6794, Val Acc: 0.5813
Epoch 21/100, Loss: 0.6302, Acc: 0.6390, Val Loss: 0.6547, Val Acc: 0.6257
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6286, Acc: 0.6431, Val Loss: 0.6642, Val Acc: 0.6018
Epoch 23/100, Loss: 0.6289, Acc: 0.6437, Val Loss: 0.6623, Val Acc: 0.5989
Epoch 24/100, Loss: 0.6287, Acc: 0.6374, Val Loss: 0.6739, Val Acc: 0.5871
Epoch 25/100, Loss: 0.6279, Acc: 0.6392, Val Loss: 0.6498, Val Acc: 0.6235
Epoch 26/100, Loss: 0.6285, Acc: 0.6379, Val Loss: 0.6546, Val Acc: 0.6040
Epoch 27/100, Loss: 0.6278, Acc: 0.6374, Val Loss: 0.6618, Val Acc: 0.6062
Epoch 28/100, Loss: 0.6279, Acc: 0.6417, Val Loss: 0.6536, Val Acc: 0.6118
Epoch 29/100, Loss: 0.6276, Acc: 0.6397, Val Loss: 0.6557, Val Acc: 0.6099
Epoch 30/100, Loss: 0.6281, Acc: 0.6385, Val Loss: 0.6622, Val Acc: 0.5765
Epoch 31/100, Loss: 0.6269, Acc: 0.6391, Val Loss: 0.6591, Val Acc: 0.6015
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6267, Acc: 0.6402, Val Loss: 0.6618, Val Acc: 0.6070
Epoch 33/100, Loss: 0.6262, Acc: 0.6407, Val Loss: 0.6589, Val Acc: 0.5978
Epoch 34/100, Loss: 0.6254, Acc: 0.6438, Val Loss: 0.6568, Val Acc: 0.6026
Epoch 35/100, Loss: 0.6248, Acc: 0.6433, Val Loss: 0.6526, Val Acc: 0.6066
Epoch 36/100, Loss: 0.6257, Acc: 0.6410, Val Loss: 0.6645, Val Acc: 0.5934
Epoch 37/100, Loss: 0.6253, Acc: 0.6431, Val Loss: 0.6660, Val Acc: 0.5853
Epoch 38/100, Loss: 0.6256, Acc: 0.6416, Val Loss: 0.6563, Val Acc: 0.5985
Epoch 39/100, Loss: 0.6251, Acc: 0.6423, Val Loss: 0.6595, Val Acc: 0.6022
Epoch 40/100, Loss: 0.6250, Acc: 0.6406, Val Loss: 0.6695, Val Acc: 0.5864
Epoch 41/100, Loss: 0.6250, Acc: 0.6399, Val Loss: 0.6619, Val Acc: 0.5945
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6242, Acc: 0.6402, Val Loss: 0.6580, Val Acc: 0.5985
Epoch 43/100, Loss: 0.6240, Acc: 0.6426, Val Loss: 0.6588, Val Acc: 0.5996
Epoch 44/100, Loss: 0.6240, Acc: 0.6456, Val Loss: 0.6561, Val Acc: 0.6007
Epoch 45/100, Loss: 0.6243, Acc: 0.6446, Val Loss: 0.6591, Val Acc: 0.5985
Epoch 46/100, Loss: 0.6240, Acc: 0.6459, Val Loss: 0.6574, Val Acc: 0.5982
Epoch 47/100, Loss: 0.6239, Acc: 0.6455, Val Loss: 0.6577, Val Acc: 0.5985
Epoch 48/100, Loss: 0.6236, Acc: 0.6424, Val Loss: 0.6607, Val Acc: 0.5985
Epoch 49/100, Loss: 0.6238, Acc: 0.6454, Val Loss: 0.6587, Val Acc: 0.5956
Epoch 50/100, Loss: 0.6240, Acc: 0.6460, Val Loss: 0.6572, Val Acc: 0.6026
Epoch 51/100, Loss: 0.6238, Acc: 0.6437, Val Loss: 0.6537, Val Acc: 0.6004
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6233, Acc: 0.6456, Val Loss: 0.6566, Val Acc: 0.5993
Epoch 53/100, Loss: 0.6230, Acc: 0.6446, Val Loss: 0.6580, Val Acc: 0.5985
Epoch 54/100, Loss: 0.6229, Acc: 0.6447, Val Loss: 0.6590, Val Acc: 0.5989
Epoch 55/100, Loss: 0.6230, Acc: 0.6442, Val Loss: 0.6571, Val Acc: 0.6000
Epoch 56/100, Loss: 0.6228, Acc: 0.6438, Val Loss: 0.6574, Val Acc: 0.5993
Epoch 57/100, Loss: 0.6227, Acc: 0.6461, Val Loss: 0.6591, Val Acc: 0.5993
Epoch 58/100, Loss: 0.6228, Acc: 0.6449, Val Loss: 0.6585, Val Acc: 0.5989
Epoch 59/100, Loss: 0.6230, Acc: 0.6441, Val Loss: 0.6569, Val Acc: 0.5974
Epoch 60/100, Loss: 0.6228, Acc: 0.6450, Val Loss: 0.6581, Val Acc: 0.5989
Epoch 61/100, Loss: 0.6227, Acc: 0.6452, Val Loss: 0.6555, Val Acc: 0.6033
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6225, Acc: 0.6432, Val Loss: 0.6567, Val Acc: 0.5996
Epoch 63/100, Loss: 0.6225, Acc: 0.6449, Val Loss: 0.6578, Val Acc: 0.5978
Epoch 64/100, Loss: 0.6225, Acc: 0.6440, Val Loss: 0.6567, Val Acc: 0.5982
Epoch 65/100, Loss: 0.6224, Acc: 0.6441, Val Loss: 0.6573, Val Acc: 0.5971
Epoch 66/100, Loss: 0.6224, Acc: 0.6443, Val Loss: 0.6557, Val Acc: 0.6026
Epoch 67/100, Loss: 0.6223, Acc: 0.6442, Val Loss: 0.6569, Val Acc: 0.5985
Epoch 68/100, Loss: 0.6223, Acc: 0.6448, Val Loss: 0.6573, Val Acc: 0.5978
Epoch 69/100, Loss: 0.6223, Acc: 0.6432, Val Loss: 0.6575, Val Acc: 0.5974
Epoch 70/100, Loss: 0.6223, Acc: 0.6434, Val Loss: 0.6561, Val Acc: 0.6007
Epoch 71/100, Loss: 0.6223, Acc: 0.6461, Val Loss: 0.6569, Val Acc: 0.5982
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6222, Acc: 0.6454, Val Loss: 0.6575, Val Acc: 0.5985
Epoch 73/100, Loss: 0.6222, Acc: 0.6454, Val Loss: 0.6573, Val Acc: 0.5978
Epoch 74/100, Loss: 0.6222, Acc: 0.6455, Val Loss: 0.6575, Val Acc: 0.5978
Epoch 75/100, Loss: 0.6222, Acc: 0.6445, Val Loss: 0.6572, Val Acc: 0.5982
Epoch 76/100, Loss: 0.6222, Acc: 0.6449, Val Loss: 0.6573, Val Acc: 0.5989
Epoch 77/100, Loss: 0.6221, Acc: 0.6451, Val Loss: 0.6566, Val Acc: 0.5993
Epoch 78/100, Loss: 0.6222, Acc: 0.6439, Val Loss: 0.6574, Val Acc: 0.5985
Epoch 79/100, Loss: 0.6221, Acc: 0.6448, Val Loss: 0.6567, Val Acc: 0.6000
Epoch 80/100, Loss: 0.6221, Acc: 0.6444, Val Loss: 0.6568, Val Acc: 0.5985
Epoch 81/100, Loss: 0.6221, Acc: 0.6456, Val Loss: 0.6576, Val Acc: 0.5989
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6221, Acc: 0.6457, Val Loss: 0.6574, Val Acc: 0.5985
Epoch 83/100, Loss: 0.6220, Acc: 0.6446, Val Loss: 0.6567, Val Acc: 0.6000
Epoch 84/100, Loss: 0.6220, Acc: 0.6442, Val Loss: 0.6568, Val Acc: 0.5989
Epoch 85/100, Loss: 0.6220, Acc: 0.6449, Val Loss: 0.6571, Val Acc: 0.5993
Epoch 86/100, Loss: 0.6220, Acc: 0.6446, Val Loss: 0.6570, Val Acc: 0.5989
Epoch 87/100, Loss: 0.6220, Acc: 0.6457, Val Loss: 0.6568, Val Acc: 0.5985
Epoch 88/100, Loss: 0.6220, Acc: 0.6447, Val Loss: 0.6579, Val Acc: 0.5996
Epoch 89/100, Loss: 0.6220, Acc: 0.6462, Val Loss: 0.6585, Val Acc: 0.5978
Epoch 90/100, Loss: 0.6221, Acc: 0.6460, Val Loss: 0.6577, Val Acc: 0.5996
Epoch 91/100, Loss: 0.6220, Acc: 0.6460, Val Loss: 0.6576, Val Acc: 0.5996
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6219, Acc: 0.6452, Val Loss: 0.6577, Val Acc: 0.5993
Epoch 93/100, Loss: 0.6220, Acc: 0.6448, Val Loss: 0.6570, Val Acc: 0.5993
Epoch 94/100, Loss: 0.6219, Acc: 0.6452, Val Loss: 0.6570, Val Acc: 0.5993
Epoch 95/100, Loss: 0.6220, Acc: 0.6466, Val Loss: 0.6571, Val Acc: 0.5993
Epoch 96/100, Loss: 0.6220, Acc: 0.6450, Val Loss: 0.6573, Val Acc: 0.5985
Epoch 97/100, Loss: 0.6220, Acc: 0.6451, Val Loss: 0.6571, Val Acc: 0.5985
Epoch 98/100, Loss: 0.6218, Acc: 0.6450, Val Loss: 0.6556, Val Acc: 0.6022
Epoch 99/100, Loss: 0.6218, Acc: 0.6458, Val Loss: 0.6559, Val Acc: 0.5996
Epoch 100/100, Loss: 0.6217, Acc: 0.6454, Val Loss: 0.6561, Val Acc: 0.5985

##############################
Resultados para principal:  092  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  1 
 {'training': [0.6217375650125392, 0.6454044117647059, 0.6802643573381951, 0.5487132352941176, 0.6074481074481074], 'validate': [0.6560902588589247, 0.5985294117647059, 0.6892655367231638, 0.3588235294117647, 0.47195357833655704], 'test': [0.8901226360488821, 0.41058823529411764, 0.4403921568627451, 0.6605882352941177, 0.5284705882352941]}

##############################
Resultados para window:  1 
 {'031:051:096:034:014:092': {'training': [0.6850237941040712, 0.5652573529411765, 0.5610175317978687, 0.6, 0.5798543258127554], 'validate': [0.6828277346699737, 0.58125, 0.5803636363636364, 0.586764705882353, 0.5835466179159049], 'test': [0.6870759714532781, 0.5461764705882353, 0.5417775412453433, 0.5988235294117648, 0.5688739871472478]}, '051:031:096:034:014:092': {'training': [0.5542910158634186, 0.7121323529411765, 0.738626964433416, 0.6566176470588235, 0.6952121448034254], 'validate': [0.6977511824563493, 0.6047794117647058, 0.6163265306122448, 0.5551470588235294, 0.5841392649903289], 'test': [0.5176019773439124, 0.7623529411764706, 0.7903645833333334, 0.7141176470588235, 0.7503090234857849]}, '096:031:051:034:014:092': {'training': [0.6749223218244664, 0.610202205882353, 0.6051201122216378, 0.634375, 0.6194023153549314], 'validate': [0.6652516597925231, 0.6356617647058823, 0.6589147286821705, 0.5625, 0.6069020230067433], 'test': [0.6699071835588526, 0.6314705882352941, 0.6513202437373053, 0.5658823529411765, 0.6056027699087189]}, '034:031:051:096:014:092': {'training': [0.6882028292207157, 0.5621323529411765, 0.5563333333333333, 0.6136029411764706, 0.5835664335664336], 'validate': [0.6970869011657183, 0.45625, 0.4592186429061001, 0.49264705882352944, 0.47534586732884], 'test': [0.6930228681476028, 0.5, 0.0, 0.0, 0.0]}, '014:031:051:096:034:092': {'training': [0.5919478618046816, 0.6884191176470589, 0.7163360067539046, 0.6238970588235294, 0.6669286696797013], 'validate': [0.7798798001089762, 0.5022058823529412, 0.5028735632183908, 0.3860294117647059, 0.4367720465890183], 'test': [0.6880872691119159, 0.5520588235294117, 0.5433186490455213, 0.6529411764705882, 0.5931071333155223]}, '092:031:051:096:034:014': {'training': [0.6217375650125392, 0.6454044117647059, 0.6802643573381951, 0.5487132352941176, 0.6074481074481074], 'validate': [0.6560902588589247, 0.5985294117647059, 0.6892655367231638, 0.3588235294117647, 0.47195357833655704], 'test': [0.8901226360488821, 0.41058823529411764, 0.4403921568627451, 0.6605882352941177, 0.5284705882352941]}}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  007  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  007  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  007  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4855, Acc: 0.8270, Val Loss: 0.3677, Val Acc: 0.8739
Mejor modelo guardado con Val Loss: 0.3677
Epoch 2/100, Loss: 0.3650, Acc: 0.8559, Val Loss: 0.4595, Val Acc: 0.7658
Epoch 3/100, Loss: 0.3536, Acc: 0.8513, Val Loss: 0.2434, Val Acc: 0.9206
Mejor modelo guardado con Val Loss: 0.2434
Epoch 4/100, Loss: 0.3337, Acc: 0.8581, Val Loss: 0.2663, Val Acc: 0.8941
Epoch 5/100, Loss: 0.3265, Acc: 0.8612, Val Loss: 0.2939, Val Acc: 0.8787
Epoch 6/100, Loss: 0.3274, Acc: 0.8574, Val Loss: 0.2875, Val Acc: 0.8739
Epoch 7/100, Loss: 0.3198, Acc: 0.8627, Val Loss: 0.3136, Val Acc: 0.8522
Epoch 8/100, Loss: 0.3198, Acc: 0.8609, Val Loss: 0.2363, Val Acc: 0.9059
Mejor modelo guardado con Val Loss: 0.2363
Epoch 9/100, Loss: 0.3197, Acc: 0.8600, Val Loss: 0.2609, Val Acc: 0.8871
Epoch 10/100, Loss: 0.3205, Acc: 0.8624, Val Loss: 0.2989, Val Acc: 0.8798
Epoch 11/100, Loss: 0.3184, Acc: 0.8628, Val Loss: 0.2635, Val Acc: 0.8941
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3105, Acc: 0.8655, Val Loss: 0.2823, Val Acc: 0.8783
Epoch 13/100, Loss: 0.3142, Acc: 0.8629, Val Loss: 0.3164, Val Acc: 0.8562
Epoch 14/100, Loss: 0.3113, Acc: 0.8653, Val Loss: 0.2903, Val Acc: 0.8746
Epoch 15/100, Loss: 0.3128, Acc: 0.8660, Val Loss: 0.4005, Val Acc: 0.7989
Epoch 16/100, Loss: 0.3116, Acc: 0.8633, Val Loss: 0.2931, Val Acc: 0.8632
Epoch 17/100, Loss: 0.3102, Acc: 0.8654, Val Loss: 0.2590, Val Acc: 0.8871
Epoch 18/100, Loss: 0.3107, Acc: 0.8641, Val Loss: 0.3312, Val Acc: 0.8210
Epoch 19/100, Loss: 0.3113, Acc: 0.8647, Val Loss: 0.2626, Val Acc: 0.8879
Epoch 20/100, Loss: 0.3085, Acc: 0.8652, Val Loss: 0.2876, Val Acc: 0.8710
Epoch 21/100, Loss: 0.3111, Acc: 0.8639, Val Loss: 0.2558, Val Acc: 0.9022
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3064, Acc: 0.8653, Val Loss: 0.3209, Val Acc: 0.8390
Epoch 23/100, Loss: 0.3049, Acc: 0.8677, Val Loss: 0.2500, Val Acc: 0.9062
Epoch 24/100, Loss: 0.3064, Acc: 0.8656, Val Loss: 0.3014, Val Acc: 0.8596
Epoch 25/100, Loss: 0.3061, Acc: 0.8676, Val Loss: 0.2751, Val Acc: 0.8963
Epoch 26/100, Loss: 0.3044, Acc: 0.8673, Val Loss: 0.2743, Val Acc: 0.8985
Epoch 27/100, Loss: 0.3050, Acc: 0.8659, Val Loss: 0.2854, Val Acc: 0.8721
Epoch 28/100, Loss: 0.3042, Acc: 0.8665, Val Loss: 0.2764, Val Acc: 0.8912
Epoch 29/100, Loss: 0.3050, Acc: 0.8700, Val Loss: 0.2647, Val Acc: 0.8941
Epoch 30/100, Loss: 0.3050, Acc: 0.8644, Val Loss: 0.3053, Val Acc: 0.8632
Epoch 31/100, Loss: 0.3040, Acc: 0.8686, Val Loss: 0.2754, Val Acc: 0.8941
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3013, Acc: 0.8709, Val Loss: 0.2650, Val Acc: 0.8798
Epoch 33/100, Loss: 0.3015, Acc: 0.8691, Val Loss: 0.2895, Val Acc: 0.8728
Epoch 34/100, Loss: 0.3018, Acc: 0.8682, Val Loss: 0.2848, Val Acc: 0.8776
Epoch 35/100, Loss: 0.3000, Acc: 0.8685, Val Loss: 0.2740, Val Acc: 0.8824
Epoch 36/100, Loss: 0.3018, Acc: 0.8681, Val Loss: 0.3010, Val Acc: 0.8555
Epoch 37/100, Loss: 0.3010, Acc: 0.8693, Val Loss: 0.2888, Val Acc: 0.8721
Epoch 38/100, Loss: 0.3003, Acc: 0.8715, Val Loss: 0.2573, Val Acc: 0.8945
Epoch 39/100, Loss: 0.3010, Acc: 0.8688, Val Loss: 0.2675, Val Acc: 0.8978
Epoch 40/100, Loss: 0.2998, Acc: 0.8711, Val Loss: 0.2526, Val Acc: 0.8952
Epoch 41/100, Loss: 0.3003, Acc: 0.8710, Val Loss: 0.2680, Val Acc: 0.8831
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2984, Acc: 0.8722, Val Loss: 0.2699, Val Acc: 0.8871
Epoch 43/100, Loss: 0.2988, Acc: 0.8715, Val Loss: 0.2773, Val Acc: 0.8772
Epoch 44/100, Loss: 0.2986, Acc: 0.8701, Val Loss: 0.2794, Val Acc: 0.8816
Epoch 45/100, Loss: 0.2977, Acc: 0.8708, Val Loss: 0.2626, Val Acc: 0.8952
Epoch 46/100, Loss: 0.2980, Acc: 0.8712, Val Loss: 0.2843, Val Acc: 0.8812
Epoch 47/100, Loss: 0.2981, Acc: 0.8713, Val Loss: 0.2656, Val Acc: 0.8915
Epoch 48/100, Loss: 0.2983, Acc: 0.8706, Val Loss: 0.2745, Val Acc: 0.8831
Epoch 49/100, Loss: 0.2977, Acc: 0.8710, Val Loss: 0.3066, Val Acc: 0.8592
Epoch 50/100, Loss: 0.2977, Acc: 0.8723, Val Loss: 0.2732, Val Acc: 0.8849
Epoch 51/100, Loss: 0.2978, Acc: 0.8703, Val Loss: 0.2871, Val Acc: 0.8739
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2977, Acc: 0.8716, Val Loss: 0.2859, Val Acc: 0.8721
Epoch 53/100, Loss: 0.2970, Acc: 0.8712, Val Loss: 0.2779, Val Acc: 0.8842
Epoch 54/100, Loss: 0.2970, Acc: 0.8714, Val Loss: 0.2944, Val Acc: 0.8654
Epoch 55/100, Loss: 0.2969, Acc: 0.8736, Val Loss: 0.2838, Val Acc: 0.8757
Epoch 56/100, Loss: 0.2971, Acc: 0.8710, Val Loss: 0.2788, Val Acc: 0.8824
Epoch 57/100, Loss: 0.2967, Acc: 0.8720, Val Loss: 0.2666, Val Acc: 0.8930
Epoch 58/100, Loss: 0.2967, Acc: 0.8733, Val Loss: 0.2682, Val Acc: 0.8915
Epoch 59/100, Loss: 0.2965, Acc: 0.8726, Val Loss: 0.2739, Val Acc: 0.8849
Epoch 60/100, Loss: 0.2966, Acc: 0.8719, Val Loss: 0.2768, Val Acc: 0.8838
Epoch 61/100, Loss: 0.2962, Acc: 0.8728, Val Loss: 0.2779, Val Acc: 0.8831
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2958, Acc: 0.8726, Val Loss: 0.2799, Val Acc: 0.8831
Epoch 63/100, Loss: 0.2957, Acc: 0.8732, Val Loss: 0.2753, Val Acc: 0.8864
Epoch 64/100, Loss: 0.2957, Acc: 0.8728, Val Loss: 0.2721, Val Acc: 0.8875
Epoch 65/100, Loss: 0.2957, Acc: 0.8722, Val Loss: 0.2848, Val Acc: 0.8761
Epoch 66/100, Loss: 0.2956, Acc: 0.8722, Val Loss: 0.2731, Val Acc: 0.8864
Epoch 67/100, Loss: 0.2958, Acc: 0.8727, Val Loss: 0.2729, Val Acc: 0.8875
Epoch 68/100, Loss: 0.2956, Acc: 0.8729, Val Loss: 0.2778, Val Acc: 0.8824
Epoch 69/100, Loss: 0.2956, Acc: 0.8727, Val Loss: 0.2755, Val Acc: 0.8842
Epoch 70/100, Loss: 0.2956, Acc: 0.8732, Val Loss: 0.2836, Val Acc: 0.8790
Epoch 71/100, Loss: 0.2956, Acc: 0.8720, Val Loss: 0.2858, Val Acc: 0.8765
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2954, Acc: 0.8727, Val Loss: 0.2780, Val Acc: 0.8831
Epoch 73/100, Loss: 0.2952, Acc: 0.8732, Val Loss: 0.2856, Val Acc: 0.8768
Epoch 74/100, Loss: 0.2953, Acc: 0.8723, Val Loss: 0.2832, Val Acc: 0.8798
Epoch 75/100, Loss: 0.2953, Acc: 0.8726, Val Loss: 0.2781, Val Acc: 0.8831
Epoch 76/100, Loss: 0.2952, Acc: 0.8724, Val Loss: 0.2767, Val Acc: 0.8846
Epoch 77/100, Loss: 0.2953, Acc: 0.8729, Val Loss: 0.2814, Val Acc: 0.8809
Epoch 78/100, Loss: 0.2951, Acc: 0.8724, Val Loss: 0.2759, Val Acc: 0.8849
Epoch 79/100, Loss: 0.2953, Acc: 0.8728, Val Loss: 0.2785, Val Acc: 0.8827
Epoch 80/100, Loss: 0.2952, Acc: 0.8726, Val Loss: 0.2809, Val Acc: 0.8805
Epoch 81/100, Loss: 0.2951, Acc: 0.8729, Val Loss: 0.2752, Val Acc: 0.8842
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2952, Acc: 0.8728, Val Loss: 0.2754, Val Acc: 0.8842
Epoch 83/100, Loss: 0.2951, Acc: 0.8729, Val Loss: 0.2742, Val Acc: 0.8857
Epoch 84/100, Loss: 0.2952, Acc: 0.8724, Val Loss: 0.2809, Val Acc: 0.8816
Epoch 85/100, Loss: 0.2950, Acc: 0.8730, Val Loss: 0.2852, Val Acc: 0.8765
Epoch 86/100, Loss: 0.2951, Acc: 0.8728, Val Loss: 0.2779, Val Acc: 0.8824
Epoch 87/100, Loss: 0.2950, Acc: 0.8733, Val Loss: 0.2743, Val Acc: 0.8857
Epoch 88/100, Loss: 0.2951, Acc: 0.8733, Val Loss: 0.2769, Val Acc: 0.8842
Epoch 89/100, Loss: 0.2950, Acc: 0.8725, Val Loss: 0.2740, Val Acc: 0.8857
Epoch 90/100, Loss: 0.2951, Acc: 0.8722, Val Loss: 0.2762, Val Acc: 0.8853
Epoch 91/100, Loss: 0.2950, Acc: 0.8733, Val Loss: 0.2739, Val Acc: 0.8857
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2950, Acc: 0.8730, Val Loss: 0.2749, Val Acc: 0.8853
Epoch 93/100, Loss: 0.2950, Acc: 0.8722, Val Loss: 0.2733, Val Acc: 0.8860
Epoch 94/100, Loss: 0.2950, Acc: 0.8728, Val Loss: 0.2771, Val Acc: 0.8835
Epoch 95/100, Loss: 0.2951, Acc: 0.8726, Val Loss: 0.2745, Val Acc: 0.8849
Epoch 96/100, Loss: 0.2950, Acc: 0.8732, Val Loss: 0.2762, Val Acc: 0.8842
Epoch 97/100, Loss: 0.2950, Acc: 0.8725, Val Loss: 0.2729, Val Acc: 0.8860
Epoch 98/100, Loss: 0.2949, Acc: 0.8731, Val Loss: 0.2742, Val Acc: 0.8853
Epoch 99/100, Loss: 0.2949, Acc: 0.8724, Val Loss: 0.2788, Val Acc: 0.8827
Epoch 100/100, Loss: 0.2948, Acc: 0.8732, Val Loss: 0.2802, Val Acc: 0.8820

##############################
Resultados para principal:  007  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1 
 {'training': [0.2948424246381311, 0.8731617647058824, 0.8630185979971388, 0.8871323529411764, 0.874909354604786], 'validate': [0.2802008866484082, 0.881985294117647, 0.8131404460518384, 0.9919117647058824, 0.8936734017886717], 'test': [0.12912860961148032, 0.9535294117647058, 1.0, 0.9070588235294118, 0.9512646514497224]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  111  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  111  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  111  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5907, Acc: 0.7482, Val Loss: 0.3844, Val Acc: 0.9298
Mejor modelo guardado con Val Loss: 0.3844
Epoch 2/100, Loss: 0.4914, Acc: 0.7833, Val Loss: 0.3088, Val Acc: 0.9511
Mejor modelo guardado con Val Loss: 0.3088
Epoch 3/100, Loss: 0.4714, Acc: 0.7820, Val Loss: 0.2521, Val Acc: 0.9426
Mejor modelo guardado con Val Loss: 0.2521
Epoch 4/100, Loss: 0.4544, Acc: 0.7869, Val Loss: 0.2426, Val Acc: 0.9272
Mejor modelo guardado con Val Loss: 0.2426
Epoch 5/100, Loss: 0.4472, Acc: 0.7889, Val Loss: 0.3554, Val Acc: 0.8364
Epoch 6/100, Loss: 0.4460, Acc: 0.7865, Val Loss: 0.2236, Val Acc: 0.9463
Mejor modelo guardado con Val Loss: 0.2236
Epoch 7/100, Loss: 0.4393, Acc: 0.7917, Val Loss: 0.2289, Val Acc: 0.9349
Epoch 8/100, Loss: 0.4417, Acc: 0.7920, Val Loss: 0.2296, Val Acc: 0.9279
Epoch 9/100, Loss: 0.4403, Acc: 0.7922, Val Loss: 0.2297, Val Acc: 0.9077
Epoch 10/100, Loss: 0.4397, Acc: 0.7913, Val Loss: 0.2228, Val Acc: 0.9331
Mejor modelo guardado con Val Loss: 0.2228
Epoch 11/100, Loss: 0.4365, Acc: 0.7911, Val Loss: 0.2819, Val Acc: 0.8901
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4297, Acc: 0.7961, Val Loss: 0.2236, Val Acc: 0.9180
Epoch 13/100, Loss: 0.4264, Acc: 0.7999, Val Loss: 0.2168, Val Acc: 0.9180
Mejor modelo guardado con Val Loss: 0.2168
Epoch 14/100, Loss: 0.4261, Acc: 0.8003, Val Loss: 0.2540, Val Acc: 0.9066
Epoch 15/100, Loss: 0.4321, Acc: 0.7934, Val Loss: 0.2380, Val Acc: 0.9191
Epoch 16/100, Loss: 0.4264, Acc: 0.8011, Val Loss: 0.2572, Val Acc: 0.8974
Epoch 17/100, Loss: 0.4271, Acc: 0.7988, Val Loss: 0.2399, Val Acc: 0.9136
Epoch 18/100, Loss: 0.4254, Acc: 0.7988, Val Loss: 0.2133, Val Acc: 0.9239
Mejor modelo guardado con Val Loss: 0.2133
Epoch 19/100, Loss: 0.4247, Acc: 0.7984, Val Loss: 0.1929, Val Acc: 0.9371
Mejor modelo guardado con Val Loss: 0.1929
Epoch 20/100, Loss: 0.4234, Acc: 0.7974, Val Loss: 0.2605, Val Acc: 0.8860
Epoch 21/100, Loss: 0.4209, Acc: 0.8023, Val Loss: 0.2041, Val Acc: 0.9151
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4177, Acc: 0.8031, Val Loss: 0.2024, Val Acc: 0.9301
Epoch 23/100, Loss: 0.4176, Acc: 0.8045, Val Loss: 0.2200, Val Acc: 0.9151
Epoch 24/100, Loss: 0.4151, Acc: 0.8031, Val Loss: 0.2208, Val Acc: 0.9129
Epoch 25/100, Loss: 0.4162, Acc: 0.8063, Val Loss: 0.2227, Val Acc: 0.9136
Epoch 26/100, Loss: 0.4145, Acc: 0.8075, Val Loss: 0.2282, Val Acc: 0.9077
Epoch 27/100, Loss: 0.4144, Acc: 0.8044, Val Loss: 0.2303, Val Acc: 0.9129
Epoch 28/100, Loss: 0.4144, Acc: 0.8049, Val Loss: 0.2292, Val Acc: 0.8993
Epoch 29/100, Loss: 0.4165, Acc: 0.8046, Val Loss: 0.2161, Val Acc: 0.9187
Epoch 30/100, Loss: 0.4140, Acc: 0.8043, Val Loss: 0.2450, Val Acc: 0.9040
Epoch 31/100, Loss: 0.4121, Acc: 0.8099, Val Loss: 0.2431, Val Acc: 0.8915
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4105, Acc: 0.8089, Val Loss: 0.1981, Val Acc: 0.9265
Epoch 33/100, Loss: 0.4107, Acc: 0.8100, Val Loss: 0.2102, Val Acc: 0.9243
Epoch 34/100, Loss: 0.4092, Acc: 0.8117, Val Loss: 0.2188, Val Acc: 0.9143
Epoch 35/100, Loss: 0.4084, Acc: 0.8082, Val Loss: 0.2385, Val Acc: 0.8941
Epoch 36/100, Loss: 0.4077, Acc: 0.8126, Val Loss: 0.2168, Val Acc: 0.9107
Epoch 37/100, Loss: 0.4077, Acc: 0.8130, Val Loss: 0.2188, Val Acc: 0.9136
Epoch 38/100, Loss: 0.4078, Acc: 0.8120, Val Loss: 0.2206, Val Acc: 0.9154
Epoch 39/100, Loss: 0.4071, Acc: 0.8141, Val Loss: 0.2269, Val Acc: 0.9051
Epoch 40/100, Loss: 0.4080, Acc: 0.8136, Val Loss: 0.2121, Val Acc: 0.9184
Epoch 41/100, Loss: 0.4067, Acc: 0.8112, Val Loss: 0.2486, Val Acc: 0.8974
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4052, Acc: 0.8132, Val Loss: 0.2094, Val Acc: 0.9206
Epoch 43/100, Loss: 0.4055, Acc: 0.8144, Val Loss: 0.2175, Val Acc: 0.9151
Epoch 44/100, Loss: 0.4047, Acc: 0.8140, Val Loss: 0.2284, Val Acc: 0.9051
Epoch 45/100, Loss: 0.4051, Acc: 0.8138, Val Loss: 0.2314, Val Acc: 0.9026
Epoch 46/100, Loss: 0.4044, Acc: 0.8143, Val Loss: 0.2179, Val Acc: 0.9195
Epoch 47/100, Loss: 0.4043, Acc: 0.8147, Val Loss: 0.2084, Val Acc: 0.9228
Epoch 48/100, Loss: 0.4037, Acc: 0.8146, Val Loss: 0.2198, Val Acc: 0.9110
Epoch 49/100, Loss: 0.4035, Acc: 0.8167, Val Loss: 0.2258, Val Acc: 0.9044
Epoch 50/100, Loss: 0.4034, Acc: 0.8148, Val Loss: 0.2086, Val Acc: 0.9136
Epoch 51/100, Loss: 0.4034, Acc: 0.8133, Val Loss: 0.2223, Val Acc: 0.9062
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4028, Acc: 0.8145, Val Loss: 0.2311, Val Acc: 0.9018
Epoch 53/100, Loss: 0.4023, Acc: 0.8153, Val Loss: 0.2123, Val Acc: 0.9202
Epoch 54/100, Loss: 0.4023, Acc: 0.8161, Val Loss: 0.2204, Val Acc: 0.9096
Epoch 55/100, Loss: 0.4022, Acc: 0.8159, Val Loss: 0.2255, Val Acc: 0.9037
Epoch 56/100, Loss: 0.4021, Acc: 0.8148, Val Loss: 0.2225, Val Acc: 0.9048
Epoch 57/100, Loss: 0.4021, Acc: 0.8166, Val Loss: 0.2206, Val Acc: 0.9062
Epoch 58/100, Loss: 0.4019, Acc: 0.8167, Val Loss: 0.2149, Val Acc: 0.9173
Epoch 59/100, Loss: 0.4018, Acc: 0.8169, Val Loss: 0.2110, Val Acc: 0.9210
Epoch 60/100, Loss: 0.4017, Acc: 0.8166, Val Loss: 0.2244, Val Acc: 0.9048
Epoch 61/100, Loss: 0.4016, Acc: 0.8156, Val Loss: 0.2260, Val Acc: 0.9051
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4012, Acc: 0.8176, Val Loss: 0.2195, Val Acc: 0.9110
Epoch 63/100, Loss: 0.4011, Acc: 0.8166, Val Loss: 0.2191, Val Acc: 0.9096
Epoch 64/100, Loss: 0.4011, Acc: 0.8176, Val Loss: 0.2185, Val Acc: 0.9121
Epoch 65/100, Loss: 0.4010, Acc: 0.8161, Val Loss: 0.2181, Val Acc: 0.9143
Epoch 66/100, Loss: 0.4010, Acc: 0.8167, Val Loss: 0.2204, Val Acc: 0.9074
Epoch 67/100, Loss: 0.4008, Acc: 0.8164, Val Loss: 0.2244, Val Acc: 0.9029
Epoch 68/100, Loss: 0.4008, Acc: 0.8176, Val Loss: 0.2232, Val Acc: 0.9059
Epoch 69/100, Loss: 0.4010, Acc: 0.8170, Val Loss: 0.2186, Val Acc: 0.9118
Epoch 70/100, Loss: 0.4007, Acc: 0.8169, Val Loss: 0.2177, Val Acc: 0.9110
Epoch 71/100, Loss: 0.4006, Acc: 0.8171, Val Loss: 0.2141, Val Acc: 0.9176
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4005, Acc: 0.8160, Val Loss: 0.2226, Val Acc: 0.9059
Epoch 73/100, Loss: 0.4004, Acc: 0.8176, Val Loss: 0.2171, Val Acc: 0.9118
Epoch 74/100, Loss: 0.4004, Acc: 0.8174, Val Loss: 0.2190, Val Acc: 0.9096
Epoch 75/100, Loss: 0.4004, Acc: 0.8166, Val Loss: 0.2156, Val Acc: 0.9151
Epoch 76/100, Loss: 0.4004, Acc: 0.8172, Val Loss: 0.2185, Val Acc: 0.9099
Epoch 77/100, Loss: 0.4003, Acc: 0.8165, Val Loss: 0.2216, Val Acc: 0.9062
Epoch 78/100, Loss: 0.4003, Acc: 0.8176, Val Loss: 0.2200, Val Acc: 0.9099
Epoch 79/100, Loss: 0.4003, Acc: 0.8175, Val Loss: 0.2197, Val Acc: 0.9081
Epoch 80/100, Loss: 0.4002, Acc: 0.8172, Val Loss: 0.2200, Val Acc: 0.9085
Epoch 81/100, Loss: 0.4002, Acc: 0.8180, Val Loss: 0.2201, Val Acc: 0.9081
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4002, Acc: 0.8176, Val Loss: 0.2184, Val Acc: 0.9099
Epoch 83/100, Loss: 0.4002, Acc: 0.8179, Val Loss: 0.2214, Val Acc: 0.9059
Epoch 84/100, Loss: 0.4001, Acc: 0.8173, Val Loss: 0.2201, Val Acc: 0.9070
Epoch 85/100, Loss: 0.4000, Acc: 0.8179, Val Loss: 0.2178, Val Acc: 0.9107
Epoch 86/100, Loss: 0.4001, Acc: 0.8172, Val Loss: 0.2221, Val Acc: 0.9059
Epoch 87/100, Loss: 0.4000, Acc: 0.8172, Val Loss: 0.2212, Val Acc: 0.9066
Epoch 88/100, Loss: 0.4000, Acc: 0.8182, Val Loss: 0.2195, Val Acc: 0.9085
Epoch 89/100, Loss: 0.3998, Acc: 0.8172, Val Loss: 0.2275, Val Acc: 0.9022
Epoch 90/100, Loss: 0.4001, Acc: 0.8174, Val Loss: 0.2184, Val Acc: 0.9107
Epoch 91/100, Loss: 0.3999, Acc: 0.8176, Val Loss: 0.2231, Val Acc: 0.9048
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3998, Acc: 0.8171, Val Loss: 0.2208, Val Acc: 0.9077
Epoch 93/100, Loss: 0.3998, Acc: 0.8185, Val Loss: 0.2208, Val Acc: 0.9074
Epoch 94/100, Loss: 0.3997, Acc: 0.8177, Val Loss: 0.2204, Val Acc: 0.9062
Epoch 95/100, Loss: 0.3997, Acc: 0.8176, Val Loss: 0.2203, Val Acc: 0.9066
Epoch 96/100, Loss: 0.3997, Acc: 0.8180, Val Loss: 0.2202, Val Acc: 0.9085
Epoch 97/100, Loss: 0.3997, Acc: 0.8176, Val Loss: 0.2200, Val Acc: 0.9074
Epoch 98/100, Loss: 0.3996, Acc: 0.8181, Val Loss: 0.2197, Val Acc: 0.9081
Epoch 99/100, Loss: 0.3996, Acc: 0.8177, Val Loss: 0.2196, Val Acc: 0.9074
Epoch 100/100, Loss: 0.3995, Acc: 0.8182, Val Loss: 0.2205, Val Acc: 0.9066

##############################
Resultados para principal:  111  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1 
 {'training': [0.39946851782939014, 0.8181985294117647, 0.7980371900826446, 0.8520220588235294, 0.8241465149359887], 'validate': [0.22046638895259346, 0.9066176470588235, 0.8590909090909091, 0.9727941176470588, 0.9124137931034483], 'test': [1.2104528836078114, 0.3811764705882353, 0.41202090592334495, 0.5564705882352942, 0.47347347347347346]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  001  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  001  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  001  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6655, Acc: 0.6522, Val Loss: 0.6751, Val Acc: 0.5787
Mejor modelo guardado con Val Loss: 0.6751
Epoch 2/100, Loss: 0.6261, Acc: 0.6890, Val Loss: 0.6603, Val Acc: 0.6070
Mejor modelo guardado con Val Loss: 0.6603
Epoch 3/100, Loss: 0.6059, Acc: 0.6921, Val Loss: 0.6744, Val Acc: 0.5897
Epoch 4/100, Loss: 0.5896, Acc: 0.6989, Val Loss: 0.6451, Val Acc: 0.6294
Mejor modelo guardado con Val Loss: 0.6451
Epoch 5/100, Loss: 0.5805, Acc: 0.7008, Val Loss: 0.6713, Val Acc: 0.6051
Epoch 6/100, Loss: 0.5801, Acc: 0.7026, Val Loss: 0.6743, Val Acc: 0.5710
Epoch 7/100, Loss: 0.5794, Acc: 0.7001, Val Loss: 0.7051, Val Acc: 0.5721
Epoch 8/100, Loss: 0.5801, Acc: 0.7009, Val Loss: 0.6494, Val Acc: 0.6070
Epoch 9/100, Loss: 0.5703, Acc: 0.7098, Val Loss: 0.6646, Val Acc: 0.5956
Epoch 10/100, Loss: 0.5689, Acc: 0.7080, Val Loss: 0.6767, Val Acc: 0.5960
Epoch 11/100, Loss: 0.5639, Acc: 0.7150, Val Loss: 0.6799, Val Acc: 0.5790
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5593, Acc: 0.7152, Val Loss: 0.6769, Val Acc: 0.5956
Epoch 13/100, Loss: 0.5580, Acc: 0.7116, Val Loss: 0.6571, Val Acc: 0.6121
Epoch 14/100, Loss: 0.5590, Acc: 0.7154, Val Loss: 0.7986, Val Acc: 0.5526
Epoch 15/100, Loss: 0.5559, Acc: 0.7159, Val Loss: 0.7099, Val Acc: 0.5890
Epoch 16/100, Loss: 0.5527, Acc: 0.7160, Val Loss: 0.7324, Val Acc: 0.5643
Epoch 17/100, Loss: 0.5513, Acc: 0.7197, Val Loss: 0.7610, Val Acc: 0.5673
Epoch 18/100, Loss: 0.5497, Acc: 0.7215, Val Loss: 0.7127, Val Acc: 0.5978
Epoch 19/100, Loss: 0.5489, Acc: 0.7226, Val Loss: 0.7028, Val Acc: 0.5732
Epoch 20/100, Loss: 0.5479, Acc: 0.7205, Val Loss: 0.6782, Val Acc: 0.5798
Epoch 21/100, Loss: 0.5491, Acc: 0.7229, Val Loss: 0.7122, Val Acc: 0.5717
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5462, Acc: 0.7217, Val Loss: 0.7261, Val Acc: 0.5816
Epoch 23/100, Loss: 0.5445, Acc: 0.7278, Val Loss: 0.7016, Val Acc: 0.5449
Epoch 24/100, Loss: 0.5426, Acc: 0.7304, Val Loss: 0.7011, Val Acc: 0.5699
Epoch 25/100, Loss: 0.5434, Acc: 0.7266, Val Loss: 0.7156, Val Acc: 0.5945
Epoch 26/100, Loss: 0.5408, Acc: 0.7289, Val Loss: 0.7036, Val Acc: 0.5842
Epoch 27/100, Loss: 0.5415, Acc: 0.7274, Val Loss: 0.7077, Val Acc: 0.5971
Epoch 28/100, Loss: 0.5386, Acc: 0.7311, Val Loss: 0.7012, Val Acc: 0.5963
Epoch 29/100, Loss: 0.5390, Acc: 0.7299, Val Loss: 0.7194, Val Acc: 0.5835
Epoch 30/100, Loss: 0.5398, Acc: 0.7244, Val Loss: 0.6972, Val Acc: 0.5654
Epoch 31/100, Loss: 0.5392, Acc: 0.7284, Val Loss: 0.7179, Val Acc: 0.5790
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5361, Acc: 0.7338, Val Loss: 0.7069, Val Acc: 0.5985
Epoch 33/100, Loss: 0.5364, Acc: 0.7299, Val Loss: 0.7233, Val Acc: 0.5691
Epoch 34/100, Loss: 0.5359, Acc: 0.7317, Val Loss: 0.7239, Val Acc: 0.5816
Epoch 35/100, Loss: 0.5354, Acc: 0.7303, Val Loss: 0.6985, Val Acc: 0.5938
Epoch 36/100, Loss: 0.5346, Acc: 0.7326, Val Loss: 0.7092, Val Acc: 0.5728
Epoch 37/100, Loss: 0.5343, Acc: 0.7334, Val Loss: 0.7140, Val Acc: 0.5654
Epoch 38/100, Loss: 0.5348, Acc: 0.7335, Val Loss: 0.7180, Val Acc: 0.5794
Epoch 39/100, Loss: 0.5339, Acc: 0.7366, Val Loss: 0.7141, Val Acc: 0.5882
Epoch 40/100, Loss: 0.5345, Acc: 0.7312, Val Loss: 0.7326, Val Acc: 0.5662
Epoch 41/100, Loss: 0.5336, Acc: 0.7333, Val Loss: 0.7136, Val Acc: 0.5746
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5321, Acc: 0.7355, Val Loss: 0.7156, Val Acc: 0.5849
Epoch 43/100, Loss: 0.5323, Acc: 0.7343, Val Loss: 0.7165, Val Acc: 0.5768
Epoch 44/100, Loss: 0.5317, Acc: 0.7347, Val Loss: 0.7281, Val Acc: 0.5691
Epoch 45/100, Loss: 0.5324, Acc: 0.7359, Val Loss: 0.7222, Val Acc: 0.5702
Epoch 46/100, Loss: 0.5315, Acc: 0.7369, Val Loss: 0.7199, Val Acc: 0.5798
Epoch 47/100, Loss: 0.5316, Acc: 0.7362, Val Loss: 0.7163, Val Acc: 0.5893
Epoch 48/100, Loss: 0.5314, Acc: 0.7345, Val Loss: 0.7295, Val Acc: 0.5713
Epoch 49/100, Loss: 0.5314, Acc: 0.7348, Val Loss: 0.7145, Val Acc: 0.5761
Epoch 50/100, Loss: 0.5314, Acc: 0.7346, Val Loss: 0.7067, Val Acc: 0.5824
Epoch 51/100, Loss: 0.5318, Acc: 0.7335, Val Loss: 0.7139, Val Acc: 0.5838
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5303, Acc: 0.7345, Val Loss: 0.7204, Val Acc: 0.5676
Epoch 53/100, Loss: 0.5301, Acc: 0.7352, Val Loss: 0.7209, Val Acc: 0.5680
Epoch 54/100, Loss: 0.5302, Acc: 0.7363, Val Loss: 0.7191, Val Acc: 0.5783
Epoch 55/100, Loss: 0.5302, Acc: 0.7354, Val Loss: 0.7225, Val Acc: 0.5735
Epoch 56/100, Loss: 0.5301, Acc: 0.7371, Val Loss: 0.7168, Val Acc: 0.5732
Epoch 57/100, Loss: 0.5300, Acc: 0.7369, Val Loss: 0.7184, Val Acc: 0.5787
Epoch 58/100, Loss: 0.5300, Acc: 0.7347, Val Loss: 0.7216, Val Acc: 0.5746
Epoch 59/100, Loss: 0.5300, Acc: 0.7365, Val Loss: 0.7222, Val Acc: 0.5801
Epoch 60/100, Loss: 0.5297, Acc: 0.7353, Val Loss: 0.7226, Val Acc: 0.5783
Epoch 61/100, Loss: 0.5297, Acc: 0.7361, Val Loss: 0.7227, Val Acc: 0.5743
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5294, Acc: 0.7365, Val Loss: 0.7231, Val Acc: 0.5750
Epoch 63/100, Loss: 0.5293, Acc: 0.7372, Val Loss: 0.7192, Val Acc: 0.5779
Epoch 64/100, Loss: 0.5294, Acc: 0.7369, Val Loss: 0.7172, Val Acc: 0.5765
Epoch 65/100, Loss: 0.5292, Acc: 0.7362, Val Loss: 0.7201, Val Acc: 0.5750
Epoch 66/100, Loss: 0.5292, Acc: 0.7369, Val Loss: 0.7206, Val Acc: 0.5721
Epoch 67/100, Loss: 0.5291, Acc: 0.7366, Val Loss: 0.7194, Val Acc: 0.5776
Epoch 68/100, Loss: 0.5292, Acc: 0.7371, Val Loss: 0.7194, Val Acc: 0.5721
Epoch 69/100, Loss: 0.5291, Acc: 0.7381, Val Loss: 0.7230, Val Acc: 0.5702
Epoch 70/100, Loss: 0.5291, Acc: 0.7378, Val Loss: 0.7207, Val Acc: 0.5721
Epoch 71/100, Loss: 0.5292, Acc: 0.7369, Val Loss: 0.7242, Val Acc: 0.5691
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5289, Acc: 0.7357, Val Loss: 0.7242, Val Acc: 0.5702
Epoch 73/100, Loss: 0.5289, Acc: 0.7370, Val Loss: 0.7226, Val Acc: 0.5695
Epoch 74/100, Loss: 0.5289, Acc: 0.7381, Val Loss: 0.7222, Val Acc: 0.5728
Epoch 75/100, Loss: 0.5289, Acc: 0.7364, Val Loss: 0.7203, Val Acc: 0.5713
Epoch 76/100, Loss: 0.5288, Acc: 0.7378, Val Loss: 0.7228, Val Acc: 0.5710
Epoch 77/100, Loss: 0.5288, Acc: 0.7379, Val Loss: 0.7206, Val Acc: 0.5754
Epoch 78/100, Loss: 0.5287, Acc: 0.7362, Val Loss: 0.7223, Val Acc: 0.5710
Epoch 79/100, Loss: 0.5287, Acc: 0.7380, Val Loss: 0.7199, Val Acc: 0.5732
Epoch 80/100, Loss: 0.5287, Acc: 0.7373, Val Loss: 0.7195, Val Acc: 0.5750
Epoch 81/100, Loss: 0.5287, Acc: 0.7363, Val Loss: 0.7203, Val Acc: 0.5743
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5287, Acc: 0.7380, Val Loss: 0.7217, Val Acc: 0.5713
Epoch 83/100, Loss: 0.5286, Acc: 0.7373, Val Loss: 0.7219, Val Acc: 0.5717
Epoch 84/100, Loss: 0.5286, Acc: 0.7374, Val Loss: 0.7218, Val Acc: 0.5706
Epoch 85/100, Loss: 0.5286, Acc: 0.7357, Val Loss: 0.7221, Val Acc: 0.5710
Epoch 86/100, Loss: 0.5286, Acc: 0.7368, Val Loss: 0.7225, Val Acc: 0.5710
Epoch 87/100, Loss: 0.5285, Acc: 0.7372, Val Loss: 0.7229, Val Acc: 0.5710
Epoch 88/100, Loss: 0.5285, Acc: 0.7370, Val Loss: 0.7219, Val Acc: 0.5710
Epoch 89/100, Loss: 0.5285, Acc: 0.7364, Val Loss: 0.7218, Val Acc: 0.5702
Epoch 90/100, Loss: 0.5285, Acc: 0.7375, Val Loss: 0.7217, Val Acc: 0.5699
Epoch 91/100, Loss: 0.5285, Acc: 0.7371, Val Loss: 0.7204, Val Acc: 0.5721
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5284, Acc: 0.7376, Val Loss: 0.7195, Val Acc: 0.5724
Epoch 93/100, Loss: 0.5284, Acc: 0.7375, Val Loss: 0.7211, Val Acc: 0.5702
Epoch 94/100, Loss: 0.5284, Acc: 0.7381, Val Loss: 0.7234, Val Acc: 0.5710
Epoch 95/100, Loss: 0.5284, Acc: 0.7382, Val Loss: 0.7202, Val Acc: 0.5743
Epoch 96/100, Loss: 0.5284, Acc: 0.7374, Val Loss: 0.7204, Val Acc: 0.5713
Epoch 97/100, Loss: 0.5283, Acc: 0.7383, Val Loss: 0.7201, Val Acc: 0.5724
Epoch 98/100, Loss: 0.5283, Acc: 0.7375, Val Loss: 0.7202, Val Acc: 0.5743
Epoch 99/100, Loss: 0.5283, Acc: 0.7372, Val Loss: 0.7248, Val Acc: 0.5710
Epoch 100/100, Loss: 0.5284, Acc: 0.7379, Val Loss: 0.7224, Val Acc: 0.5717

##############################
Resultados para principal:  001  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1 
 {'training': [0.5283512653673397, 0.7378676470588236, 0.7437829691032404, 0.725735294117647, 0.7346483066617046], 'validate': [0.7223780089339544, 0.5716911764705882, 0.5557461406518011, 0.7147058823529412, 0.6252814409778064], 'test': [0.684496682551172, 0.5664705882352942, 0.6068052930056711, 0.3776470588235294, 0.4655547498187092]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  082  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  082  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  082  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6841, Acc: 0.5790, Val Loss: 0.6798, Val Acc: 0.6199
Mejor modelo guardado con Val Loss: 0.6798
Epoch 2/100, Loss: 0.6788, Acc: 0.5907, Val Loss: 0.6775, Val Acc: 0.6261
Mejor modelo guardado con Val Loss: 0.6775
Epoch 3/100, Loss: 0.6690, Acc: 0.6215, Val Loss: 0.6710, Val Acc: 0.6077
Mejor modelo guardado con Val Loss: 0.6710
Epoch 4/100, Loss: 0.6629, Acc: 0.6269, Val Loss: 0.6636, Val Acc: 0.6261
Mejor modelo guardado con Val Loss: 0.6636
Epoch 5/100, Loss: 0.6573, Acc: 0.6340, Val Loss: 0.6583, Val Acc: 0.6342
Mejor modelo guardado con Val Loss: 0.6583
Epoch 6/100, Loss: 0.6531, Acc: 0.6372, Val Loss: 0.6478, Val Acc: 0.6555
Mejor modelo guardado con Val Loss: 0.6478
Epoch 7/100, Loss: 0.6489, Acc: 0.6415, Val Loss: 0.6815, Val Acc: 0.5676
Epoch 8/100, Loss: 0.6410, Acc: 0.6598, Val Loss: 0.6626, Val Acc: 0.5982
Epoch 9/100, Loss: 0.6373, Acc: 0.6583, Val Loss: 0.6720, Val Acc: 0.5687
Epoch 10/100, Loss: 0.6346, Acc: 0.6553, Val Loss: 0.6446, Val Acc: 0.6449
Mejor modelo guardado con Val Loss: 0.6446
Epoch 11/100, Loss: 0.6310, Acc: 0.6641, Val Loss: 0.6507, Val Acc: 0.6029
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6254, Acc: 0.6679, Val Loss: 0.6554, Val Acc: 0.6007
Epoch 13/100, Loss: 0.6226, Acc: 0.6690, Val Loss: 0.6581, Val Acc: 0.6018
Epoch 14/100, Loss: 0.6216, Acc: 0.6713, Val Loss: 0.6443, Val Acc: 0.6287
Mejor modelo guardado con Val Loss: 0.6443
Epoch 15/100, Loss: 0.6208, Acc: 0.6696, Val Loss: 0.6572, Val Acc: 0.6015
Epoch 16/100, Loss: 0.6184, Acc: 0.6707, Val Loss: 0.6523, Val Acc: 0.6055
Epoch 17/100, Loss: 0.6164, Acc: 0.6736, Val Loss: 0.6595, Val Acc: 0.5849
Epoch 18/100, Loss: 0.6161, Acc: 0.6744, Val Loss: 0.6613, Val Acc: 0.5893
Epoch 19/100, Loss: 0.6157, Acc: 0.6713, Val Loss: 0.6685, Val Acc: 0.5610
Epoch 20/100, Loss: 0.6134, Acc: 0.6744, Val Loss: 0.6457, Val Acc: 0.6044
Epoch 21/100, Loss: 0.6125, Acc: 0.6687, Val Loss: 0.6611, Val Acc: 0.5886
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6112, Acc: 0.6754, Val Loss: 0.6536, Val Acc: 0.5835
Epoch 23/100, Loss: 0.6094, Acc: 0.6786, Val Loss: 0.6564, Val Acc: 0.5978
Epoch 24/100, Loss: 0.6109, Acc: 0.6768, Val Loss: 0.6485, Val Acc: 0.6158
Epoch 25/100, Loss: 0.6089, Acc: 0.6773, Val Loss: 0.6436, Val Acc: 0.6085
Mejor modelo guardado con Val Loss: 0.6436
Epoch 26/100, Loss: 0.6099, Acc: 0.6760, Val Loss: 0.6516, Val Acc: 0.5993
Epoch 27/100, Loss: 0.6081, Acc: 0.6790, Val Loss: 0.6388, Val Acc: 0.6290
Mejor modelo guardado con Val Loss: 0.6388
Epoch 28/100, Loss: 0.6079, Acc: 0.6777, Val Loss: 0.6816, Val Acc: 0.5581
Epoch 29/100, Loss: 0.6083, Acc: 0.6735, Val Loss: 0.6594, Val Acc: 0.5868
Epoch 30/100, Loss: 0.6078, Acc: 0.6741, Val Loss: 0.6511, Val Acc: 0.6074
Epoch 31/100, Loss: 0.6076, Acc: 0.6781, Val Loss: 0.6457, Val Acc: 0.6062
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6054, Acc: 0.6785, Val Loss: 0.6535, Val Acc: 0.5835
Epoch 33/100, Loss: 0.6049, Acc: 0.6786, Val Loss: 0.6524, Val Acc: 0.5949
Epoch 34/100, Loss: 0.6046, Acc: 0.6824, Val Loss: 0.6477, Val Acc: 0.6015
Epoch 35/100, Loss: 0.6049, Acc: 0.6774, Val Loss: 0.6584, Val Acc: 0.5824
Epoch 36/100, Loss: 0.6042, Acc: 0.6801, Val Loss: 0.6559, Val Acc: 0.5912
Epoch 37/100, Loss: 0.6040, Acc: 0.6814, Val Loss: 0.6512, Val Acc: 0.5893
Epoch 38/100, Loss: 0.6035, Acc: 0.6823, Val Loss: 0.6507, Val Acc: 0.6018
Epoch 39/100, Loss: 0.6034, Acc: 0.6802, Val Loss: 0.6681, Val Acc: 0.5676
Epoch 40/100, Loss: 0.6034, Acc: 0.6811, Val Loss: 0.6488, Val Acc: 0.5985
Epoch 41/100, Loss: 0.6037, Acc: 0.6808, Val Loss: 0.6552, Val Acc: 0.5890
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6023, Acc: 0.6824, Val Loss: 0.6542, Val Acc: 0.5908
Epoch 43/100, Loss: 0.6020, Acc: 0.6835, Val Loss: 0.6545, Val Acc: 0.5926
Epoch 44/100, Loss: 0.6020, Acc: 0.6828, Val Loss: 0.6525, Val Acc: 0.5978
Epoch 45/100, Loss: 0.6021, Acc: 0.6793, Val Loss: 0.6505, Val Acc: 0.5974
Epoch 46/100, Loss: 0.6022, Acc: 0.6802, Val Loss: 0.6515, Val Acc: 0.5960
Epoch 47/100, Loss: 0.6017, Acc: 0.6819, Val Loss: 0.6582, Val Acc: 0.5813
Epoch 48/100, Loss: 0.6016, Acc: 0.6848, Val Loss: 0.6569, Val Acc: 0.5882
Epoch 49/100, Loss: 0.6015, Acc: 0.6830, Val Loss: 0.6473, Val Acc: 0.6051
Epoch 50/100, Loss: 0.6018, Acc: 0.6821, Val Loss: 0.6516, Val Acc: 0.5971
Epoch 51/100, Loss: 0.6021, Acc: 0.6836, Val Loss: 0.6557, Val Acc: 0.5919
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6010, Acc: 0.6832, Val Loss: 0.6545, Val Acc: 0.5934
Epoch 53/100, Loss: 0.6010, Acc: 0.6827, Val Loss: 0.6561, Val Acc: 0.5893
Epoch 54/100, Loss: 0.6008, Acc: 0.6834, Val Loss: 0.6529, Val Acc: 0.5978
Epoch 55/100, Loss: 0.6007, Acc: 0.6839, Val Loss: 0.6531, Val Acc: 0.5908
Epoch 56/100, Loss: 0.6008, Acc: 0.6824, Val Loss: 0.6543, Val Acc: 0.5897
Epoch 57/100, Loss: 0.6008, Acc: 0.6837, Val Loss: 0.6529, Val Acc: 0.5923
Epoch 58/100, Loss: 0.6006, Acc: 0.6830, Val Loss: 0.6547, Val Acc: 0.5941
Epoch 59/100, Loss: 0.6004, Acc: 0.6824, Val Loss: 0.6563, Val Acc: 0.5886
Epoch 60/100, Loss: 0.6006, Acc: 0.6835, Val Loss: 0.6545, Val Acc: 0.5930
Epoch 61/100, Loss: 0.6002, Acc: 0.6812, Val Loss: 0.6576, Val Acc: 0.5871
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6002, Acc: 0.6826, Val Loss: 0.6563, Val Acc: 0.5886
Epoch 63/100, Loss: 0.6001, Acc: 0.6833, Val Loss: 0.6551, Val Acc: 0.5926
Epoch 64/100, Loss: 0.6001, Acc: 0.6827, Val Loss: 0.6551, Val Acc: 0.5901
Epoch 65/100, Loss: 0.6001, Acc: 0.6839, Val Loss: 0.6551, Val Acc: 0.5915
Epoch 66/100, Loss: 0.6001, Acc: 0.6840, Val Loss: 0.6550, Val Acc: 0.5934
Epoch 67/100, Loss: 0.6000, Acc: 0.6832, Val Loss: 0.6549, Val Acc: 0.5897
Epoch 68/100, Loss: 0.6001, Acc: 0.6826, Val Loss: 0.6535, Val Acc: 0.5952
Epoch 69/100, Loss: 0.6000, Acc: 0.6832, Val Loss: 0.6536, Val Acc: 0.5956
Epoch 70/100, Loss: 0.6000, Acc: 0.6834, Val Loss: 0.6545, Val Acc: 0.5945
Epoch 71/100, Loss: 0.5998, Acc: 0.6834, Val Loss: 0.6543, Val Acc: 0.5938
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5997, Acc: 0.6842, Val Loss: 0.6537, Val Acc: 0.5952
Epoch 73/100, Loss: 0.5998, Acc: 0.6831, Val Loss: 0.6537, Val Acc: 0.5949
Epoch 74/100, Loss: 0.5997, Acc: 0.6824, Val Loss: 0.6541, Val Acc: 0.5945
Epoch 75/100, Loss: 0.5997, Acc: 0.6843, Val Loss: 0.6543, Val Acc: 0.5934
Epoch 76/100, Loss: 0.5997, Acc: 0.6837, Val Loss: 0.6549, Val Acc: 0.5930
Epoch 77/100, Loss: 0.5997, Acc: 0.6834, Val Loss: 0.6546, Val Acc: 0.5934
Epoch 78/100, Loss: 0.5996, Acc: 0.6840, Val Loss: 0.6549, Val Acc: 0.5938
Epoch 79/100, Loss: 0.5996, Acc: 0.6825, Val Loss: 0.6552, Val Acc: 0.5934
Epoch 80/100, Loss: 0.5995, Acc: 0.6840, Val Loss: 0.6552, Val Acc: 0.5945
Epoch 81/100, Loss: 0.5994, Acc: 0.6842, Val Loss: 0.6559, Val Acc: 0.5919
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5993, Acc: 0.6836, Val Loss: 0.6562, Val Acc: 0.5934
Epoch 83/100, Loss: 0.5992, Acc: 0.6843, Val Loss: 0.6566, Val Acc: 0.5938
Epoch 84/100, Loss: 0.5991, Acc: 0.6846, Val Loss: 0.6564, Val Acc: 0.5926
Epoch 85/100, Loss: 0.5991, Acc: 0.6840, Val Loss: 0.6574, Val Acc: 0.5919
Epoch 86/100, Loss: 0.5991, Acc: 0.6847, Val Loss: 0.6576, Val Acc: 0.5934
Epoch 87/100, Loss: 0.5991, Acc: 0.6844, Val Loss: 0.6571, Val Acc: 0.5901
Epoch 88/100, Loss: 0.5991, Acc: 0.6843, Val Loss: 0.6572, Val Acc: 0.5912
Epoch 89/100, Loss: 0.5990, Acc: 0.6850, Val Loss: 0.6570, Val Acc: 0.5893
Epoch 90/100, Loss: 0.5989, Acc: 0.6838, Val Loss: 0.6564, Val Acc: 0.5949
Epoch 91/100, Loss: 0.5990, Acc: 0.6843, Val Loss: 0.6569, Val Acc: 0.5930
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5990, Acc: 0.6841, Val Loss: 0.6577, Val Acc: 0.5908
Epoch 93/100, Loss: 0.5989, Acc: 0.6845, Val Loss: 0.6572, Val Acc: 0.5908
Epoch 94/100, Loss: 0.5989, Acc: 0.6840, Val Loss: 0.6577, Val Acc: 0.5904
Epoch 95/100, Loss: 0.5988, Acc: 0.6834, Val Loss: 0.6571, Val Acc: 0.5904
Epoch 96/100, Loss: 0.5989, Acc: 0.6833, Val Loss: 0.6571, Val Acc: 0.5904
Epoch 97/100, Loss: 0.5988, Acc: 0.6843, Val Loss: 0.6572, Val Acc: 0.5897
Epoch 98/100, Loss: 0.5988, Acc: 0.6839, Val Loss: 0.6576, Val Acc: 0.5908
Epoch 99/100, Loss: 0.5987, Acc: 0.6847, Val Loss: 0.6578, Val Acc: 0.5912
Epoch 100/100, Loss: 0.5987, Acc: 0.6830, Val Loss: 0.6581, Val Acc: 0.5908

##############################
Resultados para principal:  082  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1 
 {'training': [0.5986976681386723, 0.6829963235294118, 0.6639762806786361, 0.7409926470588235, 0.7003735557293024], 'validate': [0.6581261317397273, 0.5908088235294118, 0.5664335664335665, 0.774264705882353, 0.6542404473438956], 'test': [0.5220725884040197, 0.778235294117647, 0.8833063209076175, 0.6411764705882353, 0.7430129516019086]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  103  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  103  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  103  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6881, Acc: 0.5530, Val Loss: 0.6932, Val Acc: 0.5051
Mejor modelo guardado con Val Loss: 0.6932
Epoch 2/100, Loss: 0.6834, Acc: 0.6123, Val Loss: 0.6939, Val Acc: 0.5132
Epoch 3/100, Loss: 0.6769, Acc: 0.6242, Val Loss: 0.6981, Val Acc: 0.5000
Epoch 4/100, Loss: 0.6692, Acc: 0.6370, Val Loss: 0.6947, Val Acc: 0.5026
Epoch 5/100, Loss: 0.6600, Acc: 0.6569, Val Loss: 0.7024, Val Acc: 0.4757
Epoch 6/100, Loss: 0.6486, Acc: 0.6708, Val Loss: 0.7059, Val Acc: 0.4713
Epoch 7/100, Loss: 0.6413, Acc: 0.6767, Val Loss: 0.7104, Val Acc: 0.4816
Epoch 8/100, Loss: 0.6375, Acc: 0.6676, Val Loss: 0.7136, Val Acc: 0.4783
Epoch 9/100, Loss: 0.6336, Acc: 0.6756, Val Loss: 0.7173, Val Acc: 0.4754
Epoch 10/100, Loss: 0.6312, Acc: 0.6749, Val Loss: 0.7189, Val Acc: 0.4849
Epoch 11/100, Loss: 0.6287, Acc: 0.6811, Val Loss: 0.7162, Val Acc: 0.4864
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6229, Acc: 0.6881, Val Loss: 0.7234, Val Acc: 0.4919
Epoch 13/100, Loss: 0.6225, Acc: 0.6843, Val Loss: 0.7245, Val Acc: 0.4919
Epoch 14/100, Loss: 0.6191, Acc: 0.6910, Val Loss: 0.7272, Val Acc: 0.4864
Epoch 15/100, Loss: 0.6189, Acc: 0.6838, Val Loss: 0.7197, Val Acc: 0.4960
Epoch 16/100, Loss: 0.6162, Acc: 0.6885, Val Loss: 0.7166, Val Acc: 0.4897
Epoch 17/100, Loss: 0.6153, Acc: 0.6886, Val Loss: 0.7269, Val Acc: 0.4897
Epoch 18/100, Loss: 0.6156, Acc: 0.6843, Val Loss: 0.7274, Val Acc: 0.4897
Epoch 19/100, Loss: 0.6162, Acc: 0.6813, Val Loss: 0.7301, Val Acc: 0.4908
Epoch 20/100, Loss: 0.6109, Acc: 0.6912, Val Loss: 0.7339, Val Acc: 0.4941
Epoch 21/100, Loss: 0.6116, Acc: 0.6899, Val Loss: 0.7406, Val Acc: 0.4864
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6093, Acc: 0.6914, Val Loss: 0.7376, Val Acc: 0.4879
Epoch 23/100, Loss: 0.6078, Acc: 0.6911, Val Loss: 0.7334, Val Acc: 0.4915
Epoch 24/100, Loss: 0.6076, Acc: 0.6914, Val Loss: 0.7327, Val Acc: 0.4912
Epoch 25/100, Loss: 0.6055, Acc: 0.6908, Val Loss: 0.7382, Val Acc: 0.4945
Epoch 26/100, Loss: 0.6022, Acc: 0.6929, Val Loss: 0.7407, Val Acc: 0.4930
Epoch 27/100, Loss: 0.6024, Acc: 0.6897, Val Loss: 0.7430, Val Acc: 0.4904
Epoch 28/100, Loss: 0.6013, Acc: 0.6926, Val Loss: 0.7298, Val Acc: 0.4934
Epoch 29/100, Loss: 0.6003, Acc: 0.6933, Val Loss: 0.7334, Val Acc: 0.4904
Epoch 30/100, Loss: 0.6012, Acc: 0.6890, Val Loss: 0.7343, Val Acc: 0.4938
Epoch 31/100, Loss: 0.6005, Acc: 0.6914, Val Loss: 0.7430, Val Acc: 0.4886
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5986, Acc: 0.6940, Val Loss: 0.7432, Val Acc: 0.4934
Epoch 33/100, Loss: 0.5978, Acc: 0.6954, Val Loss: 0.7436, Val Acc: 0.4886
Epoch 34/100, Loss: 0.5981, Acc: 0.6945, Val Loss: 0.7423, Val Acc: 0.4904
Epoch 35/100, Loss: 0.5979, Acc: 0.6962, Val Loss: 0.7433, Val Acc: 0.4919
Epoch 36/100, Loss: 0.5971, Acc: 0.6929, Val Loss: 0.7488, Val Acc: 0.4930
Epoch 37/100, Loss: 0.5967, Acc: 0.6942, Val Loss: 0.7399, Val Acc: 0.4890
Epoch 38/100, Loss: 0.5976, Acc: 0.6938, Val Loss: 0.7349, Val Acc: 0.4912
Epoch 39/100, Loss: 0.5970, Acc: 0.6929, Val Loss: 0.7422, Val Acc: 0.4941
Epoch 40/100, Loss: 0.5966, Acc: 0.6951, Val Loss: 0.7402, Val Acc: 0.4893
Epoch 41/100, Loss: 0.5961, Acc: 0.6926, Val Loss: 0.7461, Val Acc: 0.4989
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5966, Acc: 0.6962, Val Loss: 0.7480, Val Acc: 0.4904
Epoch 43/100, Loss: 0.5962, Acc: 0.6956, Val Loss: 0.7518, Val Acc: 0.4904
Epoch 44/100, Loss: 0.5952, Acc: 0.6960, Val Loss: 0.7446, Val Acc: 0.4897
Epoch 45/100, Loss: 0.5958, Acc: 0.6963, Val Loss: 0.7507, Val Acc: 0.4926
Epoch 46/100, Loss: 0.5953, Acc: 0.6963, Val Loss: 0.7500, Val Acc: 0.4923
Epoch 47/100, Loss: 0.5950, Acc: 0.6964, Val Loss: 0.7525, Val Acc: 0.4908
Epoch 48/100, Loss: 0.5952, Acc: 0.6960, Val Loss: 0.7470, Val Acc: 0.4915
Epoch 49/100, Loss: 0.5954, Acc: 0.6946, Val Loss: 0.7469, Val Acc: 0.4908
Epoch 50/100, Loss: 0.5953, Acc: 0.6928, Val Loss: 0.7489, Val Acc: 0.4912
Epoch 51/100, Loss: 0.5958, Acc: 0.6934, Val Loss: 0.7500, Val Acc: 0.4915
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5948, Acc: 0.6949, Val Loss: 0.7489, Val Acc: 0.4912
Epoch 53/100, Loss: 0.5948, Acc: 0.6954, Val Loss: 0.7469, Val Acc: 0.4923
Epoch 54/100, Loss: 0.5946, Acc: 0.6942, Val Loss: 0.7456, Val Acc: 0.4926
Epoch 55/100, Loss: 0.5943, Acc: 0.6949, Val Loss: 0.7482, Val Acc: 0.4904
Epoch 56/100, Loss: 0.5945, Acc: 0.6943, Val Loss: 0.7479, Val Acc: 0.4915
Epoch 57/100, Loss: 0.5945, Acc: 0.6956, Val Loss: 0.7472, Val Acc: 0.4915
Epoch 58/100, Loss: 0.5944, Acc: 0.6961, Val Loss: 0.7466, Val Acc: 0.4915
Epoch 59/100, Loss: 0.5944, Acc: 0.6968, Val Loss: 0.7486, Val Acc: 0.4934
Epoch 60/100, Loss: 0.5945, Acc: 0.6960, Val Loss: 0.7474, Val Acc: 0.4934
Epoch 61/100, Loss: 0.5943, Acc: 0.6961, Val Loss: 0.7474, Val Acc: 0.4915
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5941, Acc: 0.6955, Val Loss: 0.7473, Val Acc: 0.4915
Epoch 63/100, Loss: 0.5941, Acc: 0.6937, Val Loss: 0.7486, Val Acc: 0.4919
Epoch 64/100, Loss: 0.5940, Acc: 0.6960, Val Loss: 0.7480, Val Acc: 0.4938
Epoch 65/100, Loss: 0.5941, Acc: 0.6959, Val Loss: 0.7474, Val Acc: 0.4938
Epoch 66/100, Loss: 0.5940, Acc: 0.6959, Val Loss: 0.7479, Val Acc: 0.4934
Epoch 67/100, Loss: 0.5941, Acc: 0.6951, Val Loss: 0.7487, Val Acc: 0.4908
Epoch 68/100, Loss: 0.5940, Acc: 0.6962, Val Loss: 0.7479, Val Acc: 0.4923
Epoch 69/100, Loss: 0.5939, Acc: 0.6958, Val Loss: 0.7469, Val Acc: 0.4919
Epoch 70/100, Loss: 0.5939, Acc: 0.6947, Val Loss: 0.7470, Val Acc: 0.4926
Epoch 71/100, Loss: 0.5939, Acc: 0.6956, Val Loss: 0.7476, Val Acc: 0.4938
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5938, Acc: 0.6966, Val Loss: 0.7479, Val Acc: 0.4919
Epoch 73/100, Loss: 0.5938, Acc: 0.6969, Val Loss: 0.7481, Val Acc: 0.4919
Epoch 74/100, Loss: 0.5938, Acc: 0.6960, Val Loss: 0.7480, Val Acc: 0.4923
Epoch 75/100, Loss: 0.5938, Acc: 0.6960, Val Loss: 0.7486, Val Acc: 0.4934
Epoch 76/100, Loss: 0.5937, Acc: 0.6953, Val Loss: 0.7489, Val Acc: 0.4923
Epoch 77/100, Loss: 0.5938, Acc: 0.6966, Val Loss: 0.7486, Val Acc: 0.4926
Epoch 78/100, Loss: 0.5938, Acc: 0.6951, Val Loss: 0.7480, Val Acc: 0.4923
Epoch 79/100, Loss: 0.5938, Acc: 0.6957, Val Loss: 0.7487, Val Acc: 0.4923
Epoch 80/100, Loss: 0.5937, Acc: 0.6960, Val Loss: 0.7485, Val Acc: 0.4923
Epoch 81/100, Loss: 0.5936, Acc: 0.6959, Val Loss: 0.7492, Val Acc: 0.4890
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5938, Acc: 0.6960, Val Loss: 0.7489, Val Acc: 0.4923
Epoch 83/100, Loss: 0.5936, Acc: 0.6959, Val Loss: 0.7486, Val Acc: 0.4930
Epoch 84/100, Loss: 0.5936, Acc: 0.6960, Val Loss: 0.7484, Val Acc: 0.4930
Epoch 85/100, Loss: 0.5936, Acc: 0.6966, Val Loss: 0.7488, Val Acc: 0.4926
Epoch 86/100, Loss: 0.5936, Acc: 0.6960, Val Loss: 0.7480, Val Acc: 0.4923
Epoch 87/100, Loss: 0.5936, Acc: 0.6960, Val Loss: 0.7484, Val Acc: 0.4923
Epoch 88/100, Loss: 0.5936, Acc: 0.6965, Val Loss: 0.7488, Val Acc: 0.4930
Epoch 89/100, Loss: 0.5935, Acc: 0.6953, Val Loss: 0.7485, Val Acc: 0.4901
Epoch 90/100, Loss: 0.5936, Acc: 0.6954, Val Loss: 0.7488, Val Acc: 0.4919
Epoch 91/100, Loss: 0.5935, Acc: 0.6949, Val Loss: 0.7487, Val Acc: 0.4912
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5936, Acc: 0.6954, Val Loss: 0.7481, Val Acc: 0.4923
Epoch 93/100, Loss: 0.5935, Acc: 0.6962, Val Loss: 0.7483, Val Acc: 0.4934
Epoch 94/100, Loss: 0.5935, Acc: 0.6953, Val Loss: 0.7487, Val Acc: 0.4912
Epoch 95/100, Loss: 0.5935, Acc: 0.6961, Val Loss: 0.7485, Val Acc: 0.4919
Epoch 96/100, Loss: 0.5935, Acc: 0.6953, Val Loss: 0.7486, Val Acc: 0.4934
Epoch 97/100, Loss: 0.5934, Acc: 0.6961, Val Loss: 0.7489, Val Acc: 0.4923
Epoch 98/100, Loss: 0.5935, Acc: 0.6960, Val Loss: 0.7491, Val Acc: 0.4919
Epoch 99/100, Loss: 0.5934, Acc: 0.6954, Val Loss: 0.7487, Val Acc: 0.4901
Epoch 100/100, Loss: 0.5934, Acc: 0.6958, Val Loss: 0.7487, Val Acc: 0.4926

##############################
Resultados para principal:  103  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1 
 {'training': [0.5934135619331808, 0.6957720588235294, 0.673114434330299, 0.7612132352941177, 0.7144582470669427], 'validate': [0.748710319053295, 0.49264705882352944, 0.49503968253968256, 0.7338235294117647, 0.5912322274881516], 'test': [0.6740514625001837, 0.7820588235294118, 0.8953009068425392, 0.6388235294117647, 0.7456230690010298]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  117  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  117  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  117  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5968, Acc: 0.6975, Val Loss: 0.4961, Val Acc: 0.8493
Mejor modelo guardado con Val Loss: 0.4961
Epoch 2/100, Loss: 0.5493, Acc: 0.7186, Val Loss: 0.5045, Val Acc: 0.7430
Epoch 3/100, Loss: 0.5371, Acc: 0.7227, Val Loss: 0.4249, Val Acc: 0.8176
Mejor modelo guardado con Val Loss: 0.4249
Epoch 4/100, Loss: 0.5288, Acc: 0.7256, Val Loss: 0.4913, Val Acc: 0.7493
Epoch 5/100, Loss: 0.5294, Acc: 0.7254, Val Loss: 0.4406, Val Acc: 0.8460
Epoch 6/100, Loss: 0.5256, Acc: 0.7267, Val Loss: 0.4145, Val Acc: 0.8496
Mejor modelo guardado con Val Loss: 0.4145
Epoch 7/100, Loss: 0.5231, Acc: 0.7241, Val Loss: 0.4706, Val Acc: 0.7739
Epoch 8/100, Loss: 0.5199, Acc: 0.7285, Val Loss: 0.4683, Val Acc: 0.7882
Epoch 9/100, Loss: 0.5188, Acc: 0.7292, Val Loss: 0.4924, Val Acc: 0.7404
Epoch 10/100, Loss: 0.5192, Acc: 0.7285, Val Loss: 0.4447, Val Acc: 0.7993
Epoch 11/100, Loss: 0.5152, Acc: 0.7286, Val Loss: 0.4547, Val Acc: 0.7566
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5099, Acc: 0.7329, Val Loss: 0.4169, Val Acc: 0.8051
Epoch 13/100, Loss: 0.5083, Acc: 0.7357, Val Loss: 0.4319, Val Acc: 0.7743
Epoch 14/100, Loss: 0.5094, Acc: 0.7326, Val Loss: 0.4753, Val Acc: 0.7320
Epoch 15/100, Loss: 0.5070, Acc: 0.7357, Val Loss: 0.4291, Val Acc: 0.7860
Epoch 16/100, Loss: 0.5048, Acc: 0.7355, Val Loss: 0.4401, Val Acc: 0.7676
Epoch 17/100, Loss: 0.5042, Acc: 0.7329, Val Loss: 0.4352, Val Acc: 0.7835
Epoch 18/100, Loss: 0.5041, Acc: 0.7395, Val Loss: 0.4150, Val Acc: 0.7893
Epoch 19/100, Loss: 0.5044, Acc: 0.7358, Val Loss: 0.4412, Val Acc: 0.7882
Epoch 20/100, Loss: 0.5037, Acc: 0.7368, Val Loss: 0.4636, Val Acc: 0.7445
Epoch 21/100, Loss: 0.5047, Acc: 0.7345, Val Loss: 0.4184, Val Acc: 0.8040
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5002, Acc: 0.7359, Val Loss: 0.4600, Val Acc: 0.7511
Epoch 23/100, Loss: 0.5007, Acc: 0.7369, Val Loss: 0.4249, Val Acc: 0.7798
Epoch 24/100, Loss: 0.4994, Acc: 0.7389, Val Loss: 0.4387, Val Acc: 0.7908
Epoch 25/100, Loss: 0.4985, Acc: 0.7396, Val Loss: 0.4541, Val Acc: 0.7596
Epoch 26/100, Loss: 0.4993, Acc: 0.7404, Val Loss: 0.4459, Val Acc: 0.7618
Epoch 27/100, Loss: 0.4978, Acc: 0.7392, Val Loss: 0.4383, Val Acc: 0.7651
Epoch 28/100, Loss: 0.4957, Acc: 0.7441, Val Loss: 0.4330, Val Acc: 0.7607
Epoch 29/100, Loss: 0.4966, Acc: 0.7394, Val Loss: 0.4672, Val Acc: 0.7320
Epoch 30/100, Loss: 0.4970, Acc: 0.7398, Val Loss: 0.4394, Val Acc: 0.7801
Epoch 31/100, Loss: 0.4981, Acc: 0.7417, Val Loss: 0.4283, Val Acc: 0.7787
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4942, Acc: 0.7443, Val Loss: 0.4160, Val Acc: 0.7941
Epoch 33/100, Loss: 0.4940, Acc: 0.7423, Val Loss: 0.4499, Val Acc: 0.7592
Epoch 34/100, Loss: 0.4939, Acc: 0.7431, Val Loss: 0.4124, Val Acc: 0.8092
Mejor modelo guardado con Val Loss: 0.4124
Epoch 35/100, Loss: 0.4938, Acc: 0.7449, Val Loss: 0.4187, Val Acc: 0.7919
Epoch 36/100, Loss: 0.4938, Acc: 0.7439, Val Loss: 0.4249, Val Acc: 0.7879
Epoch 37/100, Loss: 0.4934, Acc: 0.7410, Val Loss: 0.4243, Val Acc: 0.7805
Epoch 38/100, Loss: 0.4933, Acc: 0.7452, Val Loss: 0.4372, Val Acc: 0.7743
Epoch 39/100, Loss: 0.4931, Acc: 0.7440, Val Loss: 0.4220, Val Acc: 0.7897
Epoch 40/100, Loss: 0.4926, Acc: 0.7442, Val Loss: 0.4424, Val Acc: 0.7871
Epoch 41/100, Loss: 0.4934, Acc: 0.7424, Val Loss: 0.4368, Val Acc: 0.7724
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4912, Acc: 0.7466, Val Loss: 0.4164, Val Acc: 0.7985
Epoch 43/100, Loss: 0.4915, Acc: 0.7451, Val Loss: 0.4193, Val Acc: 0.7926
Epoch 44/100, Loss: 0.4906, Acc: 0.7463, Val Loss: 0.4140, Val Acc: 0.7963
Epoch 45/100, Loss: 0.4910, Acc: 0.7442, Val Loss: 0.4249, Val Acc: 0.7846
Epoch 46/100, Loss: 0.4909, Acc: 0.7449, Val Loss: 0.4089, Val Acc: 0.8048
Mejor modelo guardado con Val Loss: 0.4089
Epoch 47/100, Loss: 0.4912, Acc: 0.7450, Val Loss: 0.4377, Val Acc: 0.7750
Epoch 48/100, Loss: 0.4910, Acc: 0.7448, Val Loss: 0.4230, Val Acc: 0.7864
Epoch 49/100, Loss: 0.4908, Acc: 0.7438, Val Loss: 0.4202, Val Acc: 0.7805
Epoch 50/100, Loss: 0.4906, Acc: 0.7440, Val Loss: 0.4218, Val Acc: 0.7967
Epoch 51/100, Loss: 0.4907, Acc: 0.7458, Val Loss: 0.4315, Val Acc: 0.7801
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4902, Acc: 0.7445, Val Loss: 0.4312, Val Acc: 0.7798
Epoch 53/100, Loss: 0.4899, Acc: 0.7442, Val Loss: 0.4255, Val Acc: 0.7864
Epoch 54/100, Loss: 0.4898, Acc: 0.7450, Val Loss: 0.4313, Val Acc: 0.7801
Epoch 55/100, Loss: 0.4899, Acc: 0.7460, Val Loss: 0.4292, Val Acc: 0.7831
Epoch 56/100, Loss: 0.4896, Acc: 0.7463, Val Loss: 0.4206, Val Acc: 0.7879
Epoch 57/100, Loss: 0.4900, Acc: 0.7449, Val Loss: 0.4301, Val Acc: 0.7787
Epoch 58/100, Loss: 0.4897, Acc: 0.7458, Val Loss: 0.4230, Val Acc: 0.7901
Epoch 59/100, Loss: 0.4895, Acc: 0.7451, Val Loss: 0.4315, Val Acc: 0.7779
Epoch 60/100, Loss: 0.4896, Acc: 0.7454, Val Loss: 0.4247, Val Acc: 0.7842
Epoch 61/100, Loss: 0.4895, Acc: 0.7462, Val Loss: 0.4337, Val Acc: 0.7783
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4891, Acc: 0.7466, Val Loss: 0.4229, Val Acc: 0.7912
Epoch 63/100, Loss: 0.4890, Acc: 0.7461, Val Loss: 0.4265, Val Acc: 0.7853
Epoch 64/100, Loss: 0.4891, Acc: 0.7445, Val Loss: 0.4306, Val Acc: 0.7860
Epoch 65/100, Loss: 0.4890, Acc: 0.7464, Val Loss: 0.4237, Val Acc: 0.7912
Epoch 66/100, Loss: 0.4890, Acc: 0.7460, Val Loss: 0.4222, Val Acc: 0.7912
Epoch 67/100, Loss: 0.4890, Acc: 0.7465, Val Loss: 0.4289, Val Acc: 0.7824
Epoch 68/100, Loss: 0.4889, Acc: 0.7457, Val Loss: 0.4236, Val Acc: 0.7882
Epoch 69/100, Loss: 0.4889, Acc: 0.7458, Val Loss: 0.4284, Val Acc: 0.7853
Epoch 70/100, Loss: 0.4890, Acc: 0.7458, Val Loss: 0.4260, Val Acc: 0.7871
Epoch 71/100, Loss: 0.4889, Acc: 0.7461, Val Loss: 0.4245, Val Acc: 0.7875
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4887, Acc: 0.7472, Val Loss: 0.4253, Val Acc: 0.7868
Epoch 73/100, Loss: 0.4887, Acc: 0.7460, Val Loss: 0.4250, Val Acc: 0.7879
Epoch 74/100, Loss: 0.4887, Acc: 0.7464, Val Loss: 0.4236, Val Acc: 0.7901
Epoch 75/100, Loss: 0.4887, Acc: 0.7466, Val Loss: 0.4250, Val Acc: 0.7890
Epoch 76/100, Loss: 0.4887, Acc: 0.7462, Val Loss: 0.4242, Val Acc: 0.7890
Epoch 77/100, Loss: 0.4887, Acc: 0.7461, Val Loss: 0.4225, Val Acc: 0.7897
Epoch 78/100, Loss: 0.4886, Acc: 0.7466, Val Loss: 0.4250, Val Acc: 0.7868
Epoch 79/100, Loss: 0.4886, Acc: 0.7459, Val Loss: 0.4237, Val Acc: 0.7897
Epoch 80/100, Loss: 0.4886, Acc: 0.7461, Val Loss: 0.4220, Val Acc: 0.7915
Epoch 81/100, Loss: 0.4886, Acc: 0.7467, Val Loss: 0.4257, Val Acc: 0.7864
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4885, Acc: 0.7464, Val Loss: 0.4272, Val Acc: 0.7849
Epoch 83/100, Loss: 0.4886, Acc: 0.7458, Val Loss: 0.4260, Val Acc: 0.7864
Epoch 84/100, Loss: 0.4885, Acc: 0.7466, Val Loss: 0.4265, Val Acc: 0.7860
Epoch 85/100, Loss: 0.4886, Acc: 0.7460, Val Loss: 0.4246, Val Acc: 0.7875
Epoch 86/100, Loss: 0.4885, Acc: 0.7463, Val Loss: 0.4250, Val Acc: 0.7882
Epoch 87/100, Loss: 0.4885, Acc: 0.7455, Val Loss: 0.4235, Val Acc: 0.7893
Epoch 88/100, Loss: 0.4885, Acc: 0.7469, Val Loss: 0.4239, Val Acc: 0.7904
Epoch 89/100, Loss: 0.4884, Acc: 0.7460, Val Loss: 0.4262, Val Acc: 0.7864
Epoch 90/100, Loss: 0.4884, Acc: 0.7468, Val Loss: 0.4253, Val Acc: 0.7868
Epoch 91/100, Loss: 0.4884, Acc: 0.7463, Val Loss: 0.4262, Val Acc: 0.7864
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4884, Acc: 0.7460, Val Loss: 0.4266, Val Acc: 0.7864
Epoch 93/100, Loss: 0.4884, Acc: 0.7460, Val Loss: 0.4269, Val Acc: 0.7857
Epoch 94/100, Loss: 0.4884, Acc: 0.7463, Val Loss: 0.4244, Val Acc: 0.7871
Epoch 95/100, Loss: 0.4884, Acc: 0.7472, Val Loss: 0.4271, Val Acc: 0.7860
Epoch 96/100, Loss: 0.4883, Acc: 0.7459, Val Loss: 0.4245, Val Acc: 0.7890
Epoch 97/100, Loss: 0.4884, Acc: 0.7468, Val Loss: 0.4267, Val Acc: 0.7864
Epoch 98/100, Loss: 0.4884, Acc: 0.7468, Val Loss: 0.4261, Val Acc: 0.7868
Epoch 99/100, Loss: 0.4883, Acc: 0.7475, Val Loss: 0.4279, Val Acc: 0.7842
Epoch 100/100, Loss: 0.4883, Acc: 0.7460, Val Loss: 0.4198, Val Acc: 0.7930

##############################
Resultados para principal:  117  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  1 
 {'training': [0.4882753223180771, 0.7460477941176471, 0.695658529454758, 0.8748161764705882, 0.7750183209836332], 'validate': [0.4198182894046916, 0.7930147058823529, 0.7134440278521692, 0.9794117647058823, 0.8255345522156802], 'test': [0.4629243126621953, 0.7802941176470588, 0.7083515522518583, 0.9529411764705882, 0.8126410835214447]}

##############################
Resultados para window:  1 
 {'007:111:001:082:103:117': {'training': [0.2948424246381311, 0.8731617647058824, 0.8630185979971388, 0.8871323529411764, 0.874909354604786], 'validate': [0.2802008866484082, 0.881985294117647, 0.8131404460518384, 0.9919117647058824, 0.8936734017886717], 'test': [0.12912860961148032, 0.9535294117647058, 1.0, 0.9070588235294118, 0.9512646514497224]}, '111:007:001:082:103:117': {'training': [0.39946851782939014, 0.8181985294117647, 0.7980371900826446, 0.8520220588235294, 0.8241465149359887], 'validate': [0.22046638895259346, 0.9066176470588235, 0.8590909090909091, 0.9727941176470588, 0.9124137931034483], 'test': [1.2104528836078114, 0.3811764705882353, 0.41202090592334495, 0.5564705882352942, 0.47347347347347346]}, '001:007:111:082:103:117': {'training': [0.5283512653673397, 0.7378676470588236, 0.7437829691032404, 0.725735294117647, 0.7346483066617046], 'validate': [0.7223780089339544, 0.5716911764705882, 0.5557461406518011, 0.7147058823529412, 0.6252814409778064], 'test': [0.684496682551172, 0.5664705882352942, 0.6068052930056711, 0.3776470588235294, 0.4655547498187092]}, '082:007:111:001:103:117': {'training': [0.5986976681386723, 0.6829963235294118, 0.6639762806786361, 0.7409926470588235, 0.7003735557293024], 'validate': [0.6581261317397273, 0.5908088235294118, 0.5664335664335665, 0.774264705882353, 0.6542404473438956], 'test': [0.5220725884040197, 0.778235294117647, 0.8833063209076175, 0.6411764705882353, 0.7430129516019086]}, '103:007:111:001:082:117': {'training': [0.5934135619331808, 0.6957720588235294, 0.673114434330299, 0.7612132352941177, 0.7144582470669427], 'validate': [0.748710319053295, 0.49264705882352944, 0.49503968253968256, 0.7338235294117647, 0.5912322274881516], 'test': [0.6740514625001837, 0.7820588235294118, 0.8953009068425392, 0.6388235294117647, 0.7456230690010298]}, '117:007:111:001:082:103': {'training': [0.4882753223180771, 0.7460477941176471, 0.695658529454758, 0.8748161764705882, 0.7750183209836332], 'validate': [0.4198182894046916, 0.7930147058823529, 0.7134440278521692, 0.9794117647058823, 0.8255345522156802], 'test': [0.4629243126621953, 0.7802941176470588, 0.7083515522518583, 0.9529411764705882, 0.8126410835214447]}}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  067  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  067  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  067  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5814, Acc: 0.7428, Val Loss: 0.5557, Val Acc: 0.7544
Mejor modelo guardado con Val Loss: 0.5557
Epoch 2/100, Loss: 0.5128, Acc: 0.7646, Val Loss: 0.4731, Val Acc: 0.8004
Mejor modelo guardado con Val Loss: 0.4731
Epoch 3/100, Loss: 0.5006, Acc: 0.7715, Val Loss: 0.5643, Val Acc: 0.6908
Epoch 4/100, Loss: 0.4937, Acc: 0.7706, Val Loss: 0.5752, Val Acc: 0.6640
Epoch 5/100, Loss: 0.4886, Acc: 0.7733, Val Loss: 0.4686, Val Acc: 0.8118
Mejor modelo guardado con Val Loss: 0.4686
Epoch 6/100, Loss: 0.4874, Acc: 0.7728, Val Loss: 0.4777, Val Acc: 0.7996
Epoch 7/100, Loss: 0.4882, Acc: 0.7705, Val Loss: 0.4934, Val Acc: 0.8085
Epoch 8/100, Loss: 0.4885, Acc: 0.7699, Val Loss: 0.5130, Val Acc: 0.7489
Epoch 9/100, Loss: 0.4831, Acc: 0.7754, Val Loss: 0.4748, Val Acc: 0.7890
Epoch 10/100, Loss: 0.4878, Acc: 0.7776, Val Loss: 0.5487, Val Acc: 0.7195
Epoch 11/100, Loss: 0.4840, Acc: 0.7763, Val Loss: 0.5262, Val Acc: 0.7386
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4774, Acc: 0.7798, Val Loss: 0.4995, Val Acc: 0.7540
Epoch 13/100, Loss: 0.4761, Acc: 0.7784, Val Loss: 0.5138, Val Acc: 0.7423
Epoch 14/100, Loss: 0.4741, Acc: 0.7774, Val Loss: 0.4737, Val Acc: 0.7824
Epoch 15/100, Loss: 0.4714, Acc: 0.7784, Val Loss: 0.5157, Val Acc: 0.7393
Epoch 16/100, Loss: 0.4700, Acc: 0.7809, Val Loss: 0.5195, Val Acc: 0.7346
Epoch 17/100, Loss: 0.4722, Acc: 0.7782, Val Loss: 0.4662, Val Acc: 0.7960
Mejor modelo guardado con Val Loss: 0.4662
Epoch 18/100, Loss: 0.4730, Acc: 0.7793, Val Loss: 0.4861, Val Acc: 0.7654
Epoch 19/100, Loss: 0.4710, Acc: 0.7780, Val Loss: 0.4957, Val Acc: 0.7732
Epoch 20/100, Loss: 0.4722, Acc: 0.7789, Val Loss: 0.5641, Val Acc: 0.7063
Epoch 21/100, Loss: 0.4695, Acc: 0.7809, Val Loss: 0.4838, Val Acc: 0.7710
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4667, Acc: 0.7799, Val Loss: 0.4867, Val Acc: 0.7721
Epoch 23/100, Loss: 0.4664, Acc: 0.7815, Val Loss: 0.4979, Val Acc: 0.7618
Epoch 24/100, Loss: 0.4647, Acc: 0.7810, Val Loss: 0.5342, Val Acc: 0.7298
Epoch 25/100, Loss: 0.4655, Acc: 0.7797, Val Loss: 0.5044, Val Acc: 0.7599
Epoch 26/100, Loss: 0.4643, Acc: 0.7837, Val Loss: 0.4875, Val Acc: 0.7728
Epoch 27/100, Loss: 0.4643, Acc: 0.7828, Val Loss: 0.4852, Val Acc: 0.7776
Epoch 28/100, Loss: 0.4629, Acc: 0.7837, Val Loss: 0.5128, Val Acc: 0.7335
Epoch 29/100, Loss: 0.4624, Acc: 0.7825, Val Loss: 0.4895, Val Acc: 0.7728
Epoch 30/100, Loss: 0.4625, Acc: 0.7824, Val Loss: 0.4830, Val Acc: 0.7875
Epoch 31/100, Loss: 0.4616, Acc: 0.7829, Val Loss: 0.4920, Val Acc: 0.7673
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4601, Acc: 0.7856, Val Loss: 0.4877, Val Acc: 0.7824
Epoch 33/100, Loss: 0.4593, Acc: 0.7819, Val Loss: 0.4919, Val Acc: 0.7691
Epoch 34/100, Loss: 0.4589, Acc: 0.7838, Val Loss: 0.5009, Val Acc: 0.7585
Epoch 35/100, Loss: 0.4590, Acc: 0.7832, Val Loss: 0.5057, Val Acc: 0.7592
Epoch 36/100, Loss: 0.4584, Acc: 0.7855, Val Loss: 0.4809, Val Acc: 0.7853
Epoch 37/100, Loss: 0.4583, Acc: 0.7852, Val Loss: 0.5127, Val Acc: 0.7533
Epoch 38/100, Loss: 0.4584, Acc: 0.7847, Val Loss: 0.4970, Val Acc: 0.7713
Epoch 39/100, Loss: 0.4579, Acc: 0.7848, Val Loss: 0.4900, Val Acc: 0.7721
Epoch 40/100, Loss: 0.4586, Acc: 0.7853, Val Loss: 0.4930, Val Acc: 0.7673
Epoch 41/100, Loss: 0.4579, Acc: 0.7834, Val Loss: 0.4932, Val Acc: 0.7607
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4563, Acc: 0.7865, Val Loss: 0.4984, Val Acc: 0.7632
Epoch 43/100, Loss: 0.4558, Acc: 0.7858, Val Loss: 0.4926, Val Acc: 0.7684
Epoch 44/100, Loss: 0.4558, Acc: 0.7858, Val Loss: 0.4924, Val Acc: 0.7695
Epoch 45/100, Loss: 0.4559, Acc: 0.7857, Val Loss: 0.4979, Val Acc: 0.7662
Epoch 46/100, Loss: 0.4552, Acc: 0.7856, Val Loss: 0.4988, Val Acc: 0.7665
Epoch 47/100, Loss: 0.4555, Acc: 0.7847, Val Loss: 0.5012, Val Acc: 0.7592
Epoch 48/100, Loss: 0.4554, Acc: 0.7851, Val Loss: 0.4951, Val Acc: 0.7654
Epoch 49/100, Loss: 0.4552, Acc: 0.7850, Val Loss: 0.4941, Val Acc: 0.7680
Epoch 50/100, Loss: 0.4547, Acc: 0.7860, Val Loss: 0.4969, Val Acc: 0.7621
Epoch 51/100, Loss: 0.4551, Acc: 0.7850, Val Loss: 0.4852, Val Acc: 0.7757
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4543, Acc: 0.7869, Val Loss: 0.4958, Val Acc: 0.7673
Epoch 53/100, Loss: 0.4541, Acc: 0.7862, Val Loss: 0.4936, Val Acc: 0.7673
Epoch 54/100, Loss: 0.4542, Acc: 0.7856, Val Loss: 0.4912, Val Acc: 0.7721
Epoch 55/100, Loss: 0.4541, Acc: 0.7849, Val Loss: 0.4903, Val Acc: 0.7710
Epoch 56/100, Loss: 0.4540, Acc: 0.7859, Val Loss: 0.4903, Val Acc: 0.7717
Epoch 57/100, Loss: 0.4539, Acc: 0.7861, Val Loss: 0.5014, Val Acc: 0.7636
Epoch 58/100, Loss: 0.4538, Acc: 0.7858, Val Loss: 0.4921, Val Acc: 0.7688
Epoch 59/100, Loss: 0.4539, Acc: 0.7858, Val Loss: 0.4956, Val Acc: 0.7669
Epoch 60/100, Loss: 0.4537, Acc: 0.7868, Val Loss: 0.4909, Val Acc: 0.7695
Epoch 61/100, Loss: 0.4539, Acc: 0.7855, Val Loss: 0.4962, Val Acc: 0.7665
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4534, Acc: 0.7860, Val Loss: 0.4933, Val Acc: 0.7673
Epoch 63/100, Loss: 0.4534, Acc: 0.7865, Val Loss: 0.4978, Val Acc: 0.7651
Epoch 64/100, Loss: 0.4532, Acc: 0.7858, Val Loss: 0.4956, Val Acc: 0.7640
Epoch 65/100, Loss: 0.4533, Acc: 0.7859, Val Loss: 0.5008, Val Acc: 0.7621
Epoch 66/100, Loss: 0.4532, Acc: 0.7861, Val Loss: 0.4961, Val Acc: 0.7662
Epoch 67/100, Loss: 0.4531, Acc: 0.7863, Val Loss: 0.5007, Val Acc: 0.7621
Epoch 68/100, Loss: 0.4532, Acc: 0.7875, Val Loss: 0.4964, Val Acc: 0.7640
Epoch 69/100, Loss: 0.4531, Acc: 0.7876, Val Loss: 0.4897, Val Acc: 0.7695
Epoch 70/100, Loss: 0.4530, Acc: 0.7851, Val Loss: 0.4999, Val Acc: 0.7643
Epoch 71/100, Loss: 0.4531, Acc: 0.7869, Val Loss: 0.4957, Val Acc: 0.7640
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4529, Acc: 0.7856, Val Loss: 0.4945, Val Acc: 0.7654
Epoch 73/100, Loss: 0.4529, Acc: 0.7860, Val Loss: 0.4958, Val Acc: 0.7640
Epoch 74/100, Loss: 0.4529, Acc: 0.7868, Val Loss: 0.4958, Val Acc: 0.7640
Epoch 75/100, Loss: 0.4528, Acc: 0.7861, Val Loss: 0.4978, Val Acc: 0.7658
Epoch 76/100, Loss: 0.4529, Acc: 0.7872, Val Loss: 0.4966, Val Acc: 0.7658
Epoch 77/100, Loss: 0.4528, Acc: 0.7865, Val Loss: 0.4950, Val Acc: 0.7643
Epoch 78/100, Loss: 0.4529, Acc: 0.7869, Val Loss: 0.4965, Val Acc: 0.7658
Epoch 79/100, Loss: 0.4528, Acc: 0.7864, Val Loss: 0.4960, Val Acc: 0.7647
Epoch 80/100, Loss: 0.4528, Acc: 0.7858, Val Loss: 0.4952, Val Acc: 0.7640
Epoch 81/100, Loss: 0.4527, Acc: 0.7865, Val Loss: 0.4990, Val Acc: 0.7647
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4527, Acc: 0.7876, Val Loss: 0.4946, Val Acc: 0.7662
Epoch 83/100, Loss: 0.4528, Acc: 0.7861, Val Loss: 0.4968, Val Acc: 0.7654
Epoch 84/100, Loss: 0.4527, Acc: 0.7860, Val Loss: 0.4978, Val Acc: 0.7654
Epoch 85/100, Loss: 0.4527, Acc: 0.7862, Val Loss: 0.4969, Val Acc: 0.7654
Epoch 86/100, Loss: 0.4526, Acc: 0.7862, Val Loss: 0.4993, Val Acc: 0.7658
Epoch 87/100, Loss: 0.4527, Acc: 0.7864, Val Loss: 0.4975, Val Acc: 0.7651
Epoch 88/100, Loss: 0.4526, Acc: 0.7866, Val Loss: 0.4973, Val Acc: 0.7651
Epoch 89/100, Loss: 0.4526, Acc: 0.7872, Val Loss: 0.4987, Val Acc: 0.7651
Epoch 90/100, Loss: 0.4525, Acc: 0.7870, Val Loss: 0.4950, Val Acc: 0.7651
Epoch 91/100, Loss: 0.4525, Acc: 0.7855, Val Loss: 0.4994, Val Acc: 0.7640
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4525, Acc: 0.7867, Val Loss: 0.4976, Val Acc: 0.7658
Epoch 93/100, Loss: 0.4525, Acc: 0.7868, Val Loss: 0.4952, Val Acc: 0.7658
Epoch 94/100, Loss: 0.4525, Acc: 0.7864, Val Loss: 0.4975, Val Acc: 0.7651
Epoch 95/100, Loss: 0.4525, Acc: 0.7868, Val Loss: 0.4974, Val Acc: 0.7662
Epoch 96/100, Loss: 0.4524, Acc: 0.7860, Val Loss: 0.4956, Val Acc: 0.7658
Epoch 97/100, Loss: 0.4524, Acc: 0.7862, Val Loss: 0.4988, Val Acc: 0.7643
Epoch 98/100, Loss: 0.4524, Acc: 0.7861, Val Loss: 0.4980, Val Acc: 0.7647
Epoch 99/100, Loss: 0.4523, Acc: 0.7868, Val Loss: 0.4951, Val Acc: 0.7658
Epoch 100/100, Loss: 0.4523, Acc: 0.7860, Val Loss: 0.4956, Val Acc: 0.7654

##############################
Resultados para principal:  067  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1 
 {'training': [0.45232020861962263, 0.7860294117647059, 0.812575331458417, 0.7435661764705882, 0.7765406028028412], 'validate': [0.4955904483795166, 0.7654411764705882, 0.7222906403940886, 0.8625, 0.7861930294906166], 'test': [0.5811305385496881, 0.6844117647058824, 0.7402298850574712, 0.5682352941176471, 0.642928452579035]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  124  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  124  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  124  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6336, Acc: 0.7118, Val Loss: 0.6449, Val Acc: 0.6574
Mejor modelo guardado con Val Loss: 0.6449
Epoch 2/100, Loss: 0.5457, Acc: 0.7817, Val Loss: 0.6146, Val Acc: 0.6790
Mejor modelo guardado con Val Loss: 0.6146
Epoch 3/100, Loss: 0.4960, Acc: 0.7947, Val Loss: 0.6922, Val Acc: 0.5599
Epoch 4/100, Loss: 0.4748, Acc: 0.8011, Val Loss: 0.6607, Val Acc: 0.6327
Epoch 5/100, Loss: 0.4573, Acc: 0.8036, Val Loss: 0.7151, Val Acc: 0.5915
Epoch 6/100, Loss: 0.4557, Acc: 0.8006, Val Loss: 0.6241, Val Acc: 0.6566
Epoch 7/100, Loss: 0.4505, Acc: 0.8007, Val Loss: 0.6108, Val Acc: 0.6699
Mejor modelo guardado con Val Loss: 0.6108
Epoch 8/100, Loss: 0.4382, Acc: 0.8055, Val Loss: 0.7822, Val Acc: 0.5849
Epoch 9/100, Loss: 0.4398, Acc: 0.8089, Val Loss: 0.6713, Val Acc: 0.6107
Epoch 10/100, Loss: 0.4349, Acc: 0.8136, Val Loss: 0.8220, Val Acc: 0.5404
Epoch 11/100, Loss: 0.4326, Acc: 0.8045, Val Loss: 0.7166, Val Acc: 0.5838
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4256, Acc: 0.8093, Val Loss: 0.7502, Val Acc: 0.5809
Epoch 13/100, Loss: 0.4257, Acc: 0.8081, Val Loss: 0.6341, Val Acc: 0.6555
Epoch 14/100, Loss: 0.4243, Acc: 0.8108, Val Loss: 0.7132, Val Acc: 0.6147
Epoch 15/100, Loss: 0.4270, Acc: 0.8083, Val Loss: 0.7123, Val Acc: 0.5893
Epoch 16/100, Loss: 0.4210, Acc: 0.8103, Val Loss: 0.7156, Val Acc: 0.6283
Epoch 17/100, Loss: 0.4217, Acc: 0.8113, Val Loss: 0.7535, Val Acc: 0.5651
Epoch 18/100, Loss: 0.4217, Acc: 0.8094, Val Loss: 0.6932, Val Acc: 0.6324
Epoch 19/100, Loss: 0.4209, Acc: 0.8106, Val Loss: 0.7379, Val Acc: 0.5474
Epoch 20/100, Loss: 0.4212, Acc: 0.8107, Val Loss: 0.7447, Val Acc: 0.6169
Epoch 21/100, Loss: 0.4227, Acc: 0.8096, Val Loss: 0.6717, Val Acc: 0.6195
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4179, Acc: 0.8133, Val Loss: 0.7319, Val Acc: 0.6022
Epoch 23/100, Loss: 0.4138, Acc: 0.8165, Val Loss: 0.7669, Val Acc: 0.5971
Epoch 24/100, Loss: 0.4124, Acc: 0.8157, Val Loss: 0.7278, Val Acc: 0.5989
Epoch 25/100, Loss: 0.4155, Acc: 0.8130, Val Loss: 0.7405, Val Acc: 0.5926
Epoch 26/100, Loss: 0.4147, Acc: 0.8159, Val Loss: 0.7223, Val Acc: 0.6018
Epoch 27/100, Loss: 0.4111, Acc: 0.8175, Val Loss: 0.7541, Val Acc: 0.6085
Epoch 28/100, Loss: 0.4132, Acc: 0.8160, Val Loss: 0.7202, Val Acc: 0.6136
Epoch 29/100, Loss: 0.4109, Acc: 0.8146, Val Loss: 0.6448, Val Acc: 0.6570
Epoch 30/100, Loss: 0.4111, Acc: 0.8136, Val Loss: 0.7712, Val Acc: 0.5739
Epoch 31/100, Loss: 0.4100, Acc: 0.8144, Val Loss: 0.6871, Val Acc: 0.6033
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4074, Acc: 0.8172, Val Loss: 0.6949, Val Acc: 0.6044
Epoch 33/100, Loss: 0.4077, Acc: 0.8169, Val Loss: 0.7323, Val Acc: 0.5985
Epoch 34/100, Loss: 0.4069, Acc: 0.8160, Val Loss: 0.7070, Val Acc: 0.5809
Epoch 35/100, Loss: 0.4066, Acc: 0.8169, Val Loss: 0.7454, Val Acc: 0.5956
Epoch 36/100, Loss: 0.4069, Acc: 0.8171, Val Loss: 0.7168, Val Acc: 0.6011
Epoch 37/100, Loss: 0.4063, Acc: 0.8195, Val Loss: 0.6986, Val Acc: 0.6081
Epoch 38/100, Loss: 0.4059, Acc: 0.8165, Val Loss: 0.6897, Val Acc: 0.6276
Epoch 39/100, Loss: 0.4056, Acc: 0.8154, Val Loss: 0.6951, Val Acc: 0.6074
Epoch 40/100, Loss: 0.4051, Acc: 0.8165, Val Loss: 0.6976, Val Acc: 0.6180
Epoch 41/100, Loss: 0.4051, Acc: 0.8199, Val Loss: 0.7101, Val Acc: 0.6004
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4040, Acc: 0.8165, Val Loss: 0.7104, Val Acc: 0.5989
Epoch 43/100, Loss: 0.4042, Acc: 0.8175, Val Loss: 0.7256, Val Acc: 0.5967
Epoch 44/100, Loss: 0.4037, Acc: 0.8189, Val Loss: 0.7030, Val Acc: 0.6007
Epoch 45/100, Loss: 0.4034, Acc: 0.8175, Val Loss: 0.7055, Val Acc: 0.5915
Epoch 46/100, Loss: 0.4037, Acc: 0.8173, Val Loss: 0.7119, Val Acc: 0.6000
Epoch 47/100, Loss: 0.4030, Acc: 0.8182, Val Loss: 0.7480, Val Acc: 0.5882
Epoch 48/100, Loss: 0.4037, Acc: 0.8176, Val Loss: 0.7152, Val Acc: 0.6000
Epoch 49/100, Loss: 0.4035, Acc: 0.8178, Val Loss: 0.7041, Val Acc: 0.5923
Epoch 50/100, Loss: 0.4032, Acc: 0.8196, Val Loss: 0.6904, Val Acc: 0.6088
Epoch 51/100, Loss: 0.4026, Acc: 0.8201, Val Loss: 0.7161, Val Acc: 0.5945
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4021, Acc: 0.8179, Val Loss: 0.7121, Val Acc: 0.5941
Epoch 53/100, Loss: 0.4023, Acc: 0.8192, Val Loss: 0.7112, Val Acc: 0.5982
Epoch 54/100, Loss: 0.4023, Acc: 0.8191, Val Loss: 0.7215, Val Acc: 0.5926
Epoch 55/100, Loss: 0.4021, Acc: 0.8191, Val Loss: 0.7133, Val Acc: 0.5978
Epoch 56/100, Loss: 0.4020, Acc: 0.8178, Val Loss: 0.7079, Val Acc: 0.5971
Epoch 57/100, Loss: 0.4019, Acc: 0.8190, Val Loss: 0.7100, Val Acc: 0.6011
Epoch 58/100, Loss: 0.4021, Acc: 0.8182, Val Loss: 0.7110, Val Acc: 0.6011
Epoch 59/100, Loss: 0.4020, Acc: 0.8184, Val Loss: 0.7067, Val Acc: 0.5963
Epoch 60/100, Loss: 0.4017, Acc: 0.8181, Val Loss: 0.7124, Val Acc: 0.5915
Epoch 61/100, Loss: 0.4020, Acc: 0.8191, Val Loss: 0.7111, Val Acc: 0.5952
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4012, Acc: 0.8192, Val Loss: 0.7193, Val Acc: 0.5923
Epoch 63/100, Loss: 0.4012, Acc: 0.8189, Val Loss: 0.7084, Val Acc: 0.5985
Epoch 64/100, Loss: 0.4012, Acc: 0.8189, Val Loss: 0.7106, Val Acc: 0.6022
Epoch 65/100, Loss: 0.4011, Acc: 0.8181, Val Loss: 0.7093, Val Acc: 0.5971
Epoch 66/100, Loss: 0.4011, Acc: 0.8186, Val Loss: 0.7132, Val Acc: 0.5967
Epoch 67/100, Loss: 0.4011, Acc: 0.8187, Val Loss: 0.7141, Val Acc: 0.5945
Epoch 68/100, Loss: 0.4010, Acc: 0.8192, Val Loss: 0.7107, Val Acc: 0.6004
Epoch 69/100, Loss: 0.4011, Acc: 0.8193, Val Loss: 0.7084, Val Acc: 0.6004
Epoch 70/100, Loss: 0.4012, Acc: 0.8193, Val Loss: 0.7080, Val Acc: 0.5982
Epoch 71/100, Loss: 0.4011, Acc: 0.8184, Val Loss: 0.7162, Val Acc: 0.5971
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4008, Acc: 0.8191, Val Loss: 0.7104, Val Acc: 0.5982
Epoch 73/100, Loss: 0.4007, Acc: 0.8191, Val Loss: 0.7131, Val Acc: 0.5974
Epoch 74/100, Loss: 0.4007, Acc: 0.8179, Val Loss: 0.7155, Val Acc: 0.5967
Epoch 75/100, Loss: 0.4007, Acc: 0.8185, Val Loss: 0.7108, Val Acc: 0.5967
Epoch 76/100, Loss: 0.4008, Acc: 0.8190, Val Loss: 0.7121, Val Acc: 0.5967
Epoch 77/100, Loss: 0.4007, Acc: 0.8189, Val Loss: 0.7144, Val Acc: 0.5982
Epoch 78/100, Loss: 0.4007, Acc: 0.8195, Val Loss: 0.7088, Val Acc: 0.5985
Epoch 79/100, Loss: 0.4007, Acc: 0.8186, Val Loss: 0.7118, Val Acc: 0.6004
Epoch 80/100, Loss: 0.4007, Acc: 0.8188, Val Loss: 0.7127, Val Acc: 0.5985
Epoch 81/100, Loss: 0.4006, Acc: 0.8187, Val Loss: 0.7073, Val Acc: 0.5996
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4007, Acc: 0.8189, Val Loss: 0.7117, Val Acc: 0.5982
Epoch 83/100, Loss: 0.4007, Acc: 0.8188, Val Loss: 0.7140, Val Acc: 0.5974
Epoch 84/100, Loss: 0.4006, Acc: 0.8186, Val Loss: 0.7124, Val Acc: 0.5974
Epoch 85/100, Loss: 0.4006, Acc: 0.8188, Val Loss: 0.7110, Val Acc: 0.5974
Epoch 86/100, Loss: 0.4005, Acc: 0.8190, Val Loss: 0.7108, Val Acc: 0.5993
Epoch 87/100, Loss: 0.4005, Acc: 0.8185, Val Loss: 0.7124, Val Acc: 0.5989
Epoch 88/100, Loss: 0.4006, Acc: 0.8185, Val Loss: 0.7134, Val Acc: 0.5989
Epoch 89/100, Loss: 0.4005, Acc: 0.8178, Val Loss: 0.7158, Val Acc: 0.5945
Epoch 90/100, Loss: 0.4005, Acc: 0.8192, Val Loss: 0.7116, Val Acc: 0.5978
Epoch 91/100, Loss: 0.4005, Acc: 0.8199, Val Loss: 0.7139, Val Acc: 0.5956
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4005, Acc: 0.8185, Val Loss: 0.7127, Val Acc: 0.5993
Epoch 93/100, Loss: 0.4005, Acc: 0.8190, Val Loss: 0.7170, Val Acc: 0.5982
Epoch 94/100, Loss: 0.4005, Acc: 0.8188, Val Loss: 0.7121, Val Acc: 0.5985
Epoch 95/100, Loss: 0.4006, Acc: 0.8190, Val Loss: 0.7101, Val Acc: 0.6000
Epoch 96/100, Loss: 0.4004, Acc: 0.8187, Val Loss: 0.7134, Val Acc: 0.5989
Epoch 97/100, Loss: 0.4004, Acc: 0.8186, Val Loss: 0.7088, Val Acc: 0.6004
Epoch 98/100, Loss: 0.4004, Acc: 0.8193, Val Loss: 0.7145, Val Acc: 0.5985
Epoch 99/100, Loss: 0.4004, Acc: 0.8184, Val Loss: 0.7084, Val Acc: 0.6004
Epoch 100/100, Loss: 0.4004, Acc: 0.8190, Val Loss: 0.7107, Val Acc: 0.5993

##############################
Resultados para principal:  124  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1 
 {'training': [0.4003576290958068, 0.8190257352941176, 0.7821492440253617, 0.884375, 0.8301268225347253], 'validate': [0.7107345735610917, 0.5992647058823529, 0.5645933014354066, 0.8676470588235294, 0.6840579710144927], 'test': [0.6685640816059377, 0.6252941176470588, 0.5847929936305732, 0.8641176470588235, 0.6975308641975309]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  010  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  010  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  010  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6270, Acc: 0.6710, Val Loss: 0.7706, Val Acc: 0.3787
Mejor modelo guardado con Val Loss: 0.7706
Epoch 2/100, Loss: 0.5872, Acc: 0.6866, Val Loss: 0.7478, Val Acc: 0.4283
Mejor modelo guardado con Val Loss: 0.7478
Epoch 3/100, Loss: 0.5754, Acc: 0.6943, Val Loss: 0.8068, Val Acc: 0.4162
Epoch 4/100, Loss: 0.5711, Acc: 0.6940, Val Loss: 0.8113, Val Acc: 0.4029
Epoch 5/100, Loss: 0.5652, Acc: 0.6955, Val Loss: 0.8197, Val Acc: 0.4265
Epoch 6/100, Loss: 0.5620, Acc: 0.6986, Val Loss: 0.8149, Val Acc: 0.4228
Epoch 7/100, Loss: 0.5592, Acc: 0.6997, Val Loss: 0.8088, Val Acc: 0.4250
Epoch 8/100, Loss: 0.5603, Acc: 0.6953, Val Loss: 0.8141, Val Acc: 0.4257
Epoch 9/100, Loss: 0.5629, Acc: 0.6937, Val Loss: 0.7853, Val Acc: 0.4287
Epoch 10/100, Loss: 0.5587, Acc: 0.6961, Val Loss: 0.7932, Val Acc: 0.4114
Epoch 11/100, Loss: 0.5581, Acc: 0.6965, Val Loss: 0.7474, Val Acc: 0.4743
Mejor modelo guardado con Val Loss: 0.7474
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5574, Acc: 0.6918, Val Loss: 0.8349, Val Acc: 0.4283
Epoch 13/100, Loss: 0.5589, Acc: 0.6949, Val Loss: 0.8016, Val Acc: 0.4188
Epoch 14/100, Loss: 0.5579, Acc: 0.6949, Val Loss: 0.7992, Val Acc: 0.4283
Epoch 15/100, Loss: 0.5558, Acc: 0.6975, Val Loss: 0.7949, Val Acc: 0.4235
Epoch 16/100, Loss: 0.5539, Acc: 0.7017, Val Loss: 0.8239, Val Acc: 0.4246
Epoch 17/100, Loss: 0.5536, Acc: 0.7032, Val Loss: 0.8499, Val Acc: 0.4265
Epoch 18/100, Loss: 0.5519, Acc: 0.7063, Val Loss: 0.8038, Val Acc: 0.4430
Epoch 19/100, Loss: 0.5541, Acc: 0.7017, Val Loss: 0.8124, Val Acc: 0.4335
Epoch 20/100, Loss: 0.5533, Acc: 0.7033, Val Loss: 0.8136, Val Acc: 0.4176
Epoch 21/100, Loss: 0.5538, Acc: 0.7033, Val Loss: 0.8362, Val Acc: 0.4239
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5507, Acc: 0.7059, Val Loss: 0.8433, Val Acc: 0.4265
Epoch 23/100, Loss: 0.5514, Acc: 0.7055, Val Loss: 0.8182, Val Acc: 0.4268
Epoch 24/100, Loss: 0.5508, Acc: 0.7041, Val Loss: 0.8375, Val Acc: 0.4243
Epoch 25/100, Loss: 0.5510, Acc: 0.7024, Val Loss: 0.8259, Val Acc: 0.4228
Epoch 26/100, Loss: 0.5511, Acc: 0.7040, Val Loss: 0.7971, Val Acc: 0.4221
Epoch 27/100, Loss: 0.5503, Acc: 0.7054, Val Loss: 0.8371, Val Acc: 0.4210
Epoch 28/100, Loss: 0.5495, Acc: 0.7028, Val Loss: 0.8216, Val Acc: 0.4254
Epoch 29/100, Loss: 0.5505, Acc: 0.7041, Val Loss: 0.8100, Val Acc: 0.4210
Epoch 30/100, Loss: 0.5499, Acc: 0.7056, Val Loss: 0.8431, Val Acc: 0.4210
Epoch 31/100, Loss: 0.5496, Acc: 0.7063, Val Loss: 0.8304, Val Acc: 0.4228
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5492, Acc: 0.7074, Val Loss: 0.8367, Val Acc: 0.4250
Epoch 33/100, Loss: 0.5485, Acc: 0.7051, Val Loss: 0.8427, Val Acc: 0.4246
Epoch 34/100, Loss: 0.5487, Acc: 0.7048, Val Loss: 0.8354, Val Acc: 0.4265
Epoch 35/100, Loss: 0.5492, Acc: 0.7047, Val Loss: 0.8431, Val Acc: 0.4261
Epoch 36/100, Loss: 0.5481, Acc: 0.7078, Val Loss: 0.8221, Val Acc: 0.4265
Epoch 37/100, Loss: 0.5485, Acc: 0.7051, Val Loss: 0.8251, Val Acc: 0.4250
Epoch 38/100, Loss: 0.5479, Acc: 0.7078, Val Loss: 0.8338, Val Acc: 0.4276
Epoch 39/100, Loss: 0.5481, Acc: 0.7036, Val Loss: 0.8269, Val Acc: 0.4261
Epoch 40/100, Loss: 0.5481, Acc: 0.7056, Val Loss: 0.8426, Val Acc: 0.4243
Epoch 41/100, Loss: 0.5478, Acc: 0.7067, Val Loss: 0.8352, Val Acc: 0.4188
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5475, Acc: 0.7068, Val Loss: 0.8265, Val Acc: 0.4243
Epoch 43/100, Loss: 0.5471, Acc: 0.7068, Val Loss: 0.8350, Val Acc: 0.4254
Epoch 44/100, Loss: 0.5472, Acc: 0.7067, Val Loss: 0.8345, Val Acc: 0.4228
Epoch 45/100, Loss: 0.5470, Acc: 0.7066, Val Loss: 0.8451, Val Acc: 0.4257
Epoch 46/100, Loss: 0.5472, Acc: 0.7053, Val Loss: 0.8271, Val Acc: 0.4199
Epoch 47/100, Loss: 0.5472, Acc: 0.7074, Val Loss: 0.8279, Val Acc: 0.4188
Epoch 48/100, Loss: 0.5471, Acc: 0.7062, Val Loss: 0.8356, Val Acc: 0.4243
Epoch 49/100, Loss: 0.5470, Acc: 0.7064, Val Loss: 0.8361, Val Acc: 0.4239
Epoch 50/100, Loss: 0.5473, Acc: 0.7074, Val Loss: 0.8404, Val Acc: 0.4206
Epoch 51/100, Loss: 0.5468, Acc: 0.7088, Val Loss: 0.8351, Val Acc: 0.4221
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5462, Acc: 0.7071, Val Loss: 0.8322, Val Acc: 0.4268
Epoch 53/100, Loss: 0.5460, Acc: 0.7071, Val Loss: 0.8311, Val Acc: 0.4250
Epoch 54/100, Loss: 0.5460, Acc: 0.7062, Val Loss: 0.8362, Val Acc: 0.4257
Epoch 55/100, Loss: 0.5459, Acc: 0.7085, Val Loss: 0.8349, Val Acc: 0.4257
Epoch 56/100, Loss: 0.5459, Acc: 0.7069, Val Loss: 0.8405, Val Acc: 0.4254
Epoch 57/100, Loss: 0.5459, Acc: 0.7063, Val Loss: 0.8369, Val Acc: 0.4272
Epoch 58/100, Loss: 0.5459, Acc: 0.7074, Val Loss: 0.8404, Val Acc: 0.4265
Epoch 59/100, Loss: 0.5458, Acc: 0.7083, Val Loss: 0.8280, Val Acc: 0.4287
Epoch 60/100, Loss: 0.5457, Acc: 0.7063, Val Loss: 0.8322, Val Acc: 0.4287
Epoch 61/100, Loss: 0.5459, Acc: 0.7074, Val Loss: 0.8246, Val Acc: 0.4224
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5456, Acc: 0.7071, Val Loss: 0.8338, Val Acc: 0.4276
Epoch 63/100, Loss: 0.5455, Acc: 0.7068, Val Loss: 0.8314, Val Acc: 0.4254
Epoch 64/100, Loss: 0.5454, Acc: 0.7069, Val Loss: 0.8332, Val Acc: 0.4276
Epoch 65/100, Loss: 0.5455, Acc: 0.7063, Val Loss: 0.8330, Val Acc: 0.4228
Epoch 66/100, Loss: 0.5454, Acc: 0.7068, Val Loss: 0.8353, Val Acc: 0.4283
Epoch 67/100, Loss: 0.5455, Acc: 0.7069, Val Loss: 0.8320, Val Acc: 0.4261
Epoch 68/100, Loss: 0.5454, Acc: 0.7063, Val Loss: 0.8314, Val Acc: 0.4257
Epoch 69/100, Loss: 0.5454, Acc: 0.7062, Val Loss: 0.8298, Val Acc: 0.4272
Epoch 70/100, Loss: 0.5453, Acc: 0.7079, Val Loss: 0.8323, Val Acc: 0.4283
Epoch 71/100, Loss: 0.5452, Acc: 0.7064, Val Loss: 0.8356, Val Acc: 0.4279
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5451, Acc: 0.7059, Val Loss: 0.8304, Val Acc: 0.4254
Epoch 73/100, Loss: 0.5451, Acc: 0.7058, Val Loss: 0.8324, Val Acc: 0.4257
Epoch 74/100, Loss: 0.5451, Acc: 0.7064, Val Loss: 0.8337, Val Acc: 0.4268
Epoch 75/100, Loss: 0.5451, Acc: 0.7063, Val Loss: 0.8334, Val Acc: 0.4254
Epoch 76/100, Loss: 0.5451, Acc: 0.7062, Val Loss: 0.8325, Val Acc: 0.4254
Epoch 77/100, Loss: 0.5450, Acc: 0.7063, Val Loss: 0.8329, Val Acc: 0.4268
Epoch 78/100, Loss: 0.5451, Acc: 0.7064, Val Loss: 0.8341, Val Acc: 0.4254
Epoch 79/100, Loss: 0.5450, Acc: 0.7061, Val Loss: 0.8345, Val Acc: 0.4265
Epoch 80/100, Loss: 0.5450, Acc: 0.7066, Val Loss: 0.8349, Val Acc: 0.4261
Epoch 81/100, Loss: 0.5450, Acc: 0.7062, Val Loss: 0.8346, Val Acc: 0.4268
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5450, Acc: 0.7057, Val Loss: 0.8318, Val Acc: 0.4272
Epoch 83/100, Loss: 0.5449, Acc: 0.7062, Val Loss: 0.8325, Val Acc: 0.4261
Epoch 84/100, Loss: 0.5449, Acc: 0.7066, Val Loss: 0.8335, Val Acc: 0.4246
Epoch 85/100, Loss: 0.5449, Acc: 0.7062, Val Loss: 0.8337, Val Acc: 0.4261
Epoch 86/100, Loss: 0.5449, Acc: 0.7062, Val Loss: 0.8358, Val Acc: 0.4276
Epoch 87/100, Loss: 0.5449, Acc: 0.7059, Val Loss: 0.8341, Val Acc: 0.4272
Epoch 88/100, Loss: 0.5449, Acc: 0.7063, Val Loss: 0.8353, Val Acc: 0.4261
Epoch 89/100, Loss: 0.5449, Acc: 0.7062, Val Loss: 0.8336, Val Acc: 0.4261
Epoch 90/100, Loss: 0.5449, Acc: 0.7059, Val Loss: 0.8348, Val Acc: 0.4279
Epoch 91/100, Loss: 0.5449, Acc: 0.7063, Val Loss: 0.8326, Val Acc: 0.4272
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5448, Acc: 0.7064, Val Loss: 0.8328, Val Acc: 0.4250
Epoch 93/100, Loss: 0.5449, Acc: 0.7063, Val Loss: 0.8332, Val Acc: 0.4257
Epoch 94/100, Loss: 0.5448, Acc: 0.7057, Val Loss: 0.8337, Val Acc: 0.4261
Epoch 95/100, Loss: 0.5448, Acc: 0.7056, Val Loss: 0.8338, Val Acc: 0.4272
Epoch 96/100, Loss: 0.5448, Acc: 0.7053, Val Loss: 0.8341, Val Acc: 0.4261
Epoch 97/100, Loss: 0.5448, Acc: 0.7059, Val Loss: 0.8351, Val Acc: 0.4265
Epoch 98/100, Loss: 0.5448, Acc: 0.7056, Val Loss: 0.8329, Val Acc: 0.4265
Epoch 99/100, Loss: 0.5448, Acc: 0.7057, Val Loss: 0.8330, Val Acc: 0.4265
Epoch 100/100, Loss: 0.5447, Acc: 0.7059, Val Loss: 0.8342, Val Acc: 0.4268

##############################
Resultados para principal:  010  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1 
 {'training': [0.5447256708846373, 0.7058823529411765, 0.6499330655957162, 0.8924632352941176, 0.7521301316808675], 'validate': [0.8342154774554941, 0.42683823529411763, 0.4472708002119767, 0.6205882352941177, 0.5198644902987373], 'test': [0.6501902391513189, 0.5894117647058823, 0.8671497584541062, 0.2111764705882353, 0.33964049195837276]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  009  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  009  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  009  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4140, Acc: 0.8776, Val Loss: 0.2227, Val Acc: 0.9493
Mejor modelo guardado con Val Loss: 0.2227
Epoch 2/100, Loss: 0.2614, Acc: 0.9004, Val Loss: 0.1424, Val Acc: 0.9684
Mejor modelo guardado con Val Loss: 0.1424
Epoch 3/100, Loss: 0.2404, Acc: 0.9047, Val Loss: 0.1394, Val Acc: 0.9640
Mejor modelo guardado con Val Loss: 0.1394
Epoch 4/100, Loss: 0.2286, Acc: 0.9057, Val Loss: 0.1537, Val Acc: 0.9555
Epoch 5/100, Loss: 0.2301, Acc: 0.9028, Val Loss: 0.1190, Val Acc: 0.9662
Mejor modelo guardado con Val Loss: 0.1190
Epoch 6/100, Loss: 0.2266, Acc: 0.9058, Val Loss: 0.1550, Val Acc: 0.9500
Epoch 7/100, Loss: 0.2224, Acc: 0.9053, Val Loss: 0.1274, Val Acc: 0.9596
Epoch 8/100, Loss: 0.2147, Acc: 0.9074, Val Loss: 0.1259, Val Acc: 0.9669
Epoch 9/100, Loss: 0.2191, Acc: 0.9047, Val Loss: 0.1174, Val Acc: 0.9643
Mejor modelo guardado con Val Loss: 0.1174
Epoch 10/100, Loss: 0.2235, Acc: 0.9015, Val Loss: 0.1132, Val Acc: 0.9662
Mejor modelo guardado con Val Loss: 0.1132
Epoch 11/100, Loss: 0.2139, Acc: 0.9074, Val Loss: 0.1015, Val Acc: 0.9647
Mejor modelo guardado con Val Loss: 0.1015
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2080, Acc: 0.9063, Val Loss: 0.1159, Val Acc: 0.9640
Epoch 13/100, Loss: 0.2066, Acc: 0.9109, Val Loss: 0.1061, Val Acc: 0.9640
Epoch 14/100, Loss: 0.2086, Acc: 0.9074, Val Loss: 0.1006, Val Acc: 0.9673
Mejor modelo guardado con Val Loss: 0.1006
Epoch 15/100, Loss: 0.2063, Acc: 0.9100, Val Loss: 0.1055, Val Acc: 0.9665
Epoch 16/100, Loss: 0.2028, Acc: 0.9114, Val Loss: 0.1230, Val Acc: 0.9654
Epoch 17/100, Loss: 0.2040, Acc: 0.9078, Val Loss: 0.1052, Val Acc: 0.9647
Epoch 18/100, Loss: 0.2074, Acc: 0.9098, Val Loss: 0.1197, Val Acc: 0.9643
Epoch 19/100, Loss: 0.2036, Acc: 0.9105, Val Loss: 0.1110, Val Acc: 0.9676
Epoch 20/100, Loss: 0.2036, Acc: 0.9111, Val Loss: 0.1167, Val Acc: 0.9651
Epoch 21/100, Loss: 0.2020, Acc: 0.9119, Val Loss: 0.1070, Val Acc: 0.9684
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.1993, Acc: 0.9134, Val Loss: 0.1169, Val Acc: 0.9669
Epoch 23/100, Loss: 0.1995, Acc: 0.9120, Val Loss: 0.1047, Val Acc: 0.9673
Epoch 24/100, Loss: 0.2004, Acc: 0.9115, Val Loss: 0.1106, Val Acc: 0.9640
Epoch 25/100, Loss: 0.1990, Acc: 0.9125, Val Loss: 0.1048, Val Acc: 0.9665
Epoch 26/100, Loss: 0.1989, Acc: 0.9119, Val Loss: 0.1066, Val Acc: 0.9658
Epoch 27/100, Loss: 0.1988, Acc: 0.9137, Val Loss: 0.1096, Val Acc: 0.9673
Epoch 28/100, Loss: 0.1995, Acc: 0.9119, Val Loss: 0.1094, Val Acc: 0.9632
Epoch 29/100, Loss: 0.1979, Acc: 0.9131, Val Loss: 0.1029, Val Acc: 0.9676
Epoch 30/100, Loss: 0.1978, Acc: 0.9119, Val Loss: 0.1105, Val Acc: 0.9651
Epoch 31/100, Loss: 0.1973, Acc: 0.9121, Val Loss: 0.1012, Val Acc: 0.9647
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.1958, Acc: 0.9148, Val Loss: 0.1125, Val Acc: 0.9647
Epoch 33/100, Loss: 0.1956, Acc: 0.9142, Val Loss: 0.1026, Val Acc: 0.9665
Epoch 34/100, Loss: 0.1954, Acc: 0.9146, Val Loss: 0.1003, Val Acc: 0.9662
Mejor modelo guardado con Val Loss: 0.1003
Epoch 35/100, Loss: 0.1945, Acc: 0.9141, Val Loss: 0.1084, Val Acc: 0.9654
Epoch 36/100, Loss: 0.1941, Acc: 0.9151, Val Loss: 0.1076, Val Acc: 0.9662
Epoch 37/100, Loss: 0.1940, Acc: 0.9148, Val Loss: 0.1056, Val Acc: 0.9662
Epoch 38/100, Loss: 0.1941, Acc: 0.9153, Val Loss: 0.1058, Val Acc: 0.9651
Epoch 39/100, Loss: 0.1937, Acc: 0.9152, Val Loss: 0.1073, Val Acc: 0.9665
Epoch 40/100, Loss: 0.1929, Acc: 0.9176, Val Loss: 0.1066, Val Acc: 0.9654
Epoch 41/100, Loss: 0.1934, Acc: 0.9145, Val Loss: 0.1053, Val Acc: 0.9654
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.1927, Acc: 0.9157, Val Loss: 0.1066, Val Acc: 0.9647
Epoch 43/100, Loss: 0.1926, Acc: 0.9154, Val Loss: 0.1049, Val Acc: 0.9676
Epoch 44/100, Loss: 0.1921, Acc: 0.9163, Val Loss: 0.1021, Val Acc: 0.9658
Epoch 45/100, Loss: 0.1916, Acc: 0.9159, Val Loss: 0.1067, Val Acc: 0.9654
Epoch 46/100, Loss: 0.1917, Acc: 0.9151, Val Loss: 0.1039, Val Acc: 0.9658
Epoch 47/100, Loss: 0.1913, Acc: 0.9160, Val Loss: 0.1018, Val Acc: 0.9669
Epoch 48/100, Loss: 0.1915, Acc: 0.9166, Val Loss: 0.1012, Val Acc: 0.9665
Epoch 49/100, Loss: 0.1914, Acc: 0.9159, Val Loss: 0.0998, Val Acc: 0.9676
Mejor modelo guardado con Val Loss: 0.0998
Epoch 50/100, Loss: 0.1912, Acc: 0.9167, Val Loss: 0.1009, Val Acc: 0.9654
Epoch 51/100, Loss: 0.1912, Acc: 0.9161, Val Loss: 0.1030, Val Acc: 0.9654
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.1903, Acc: 0.9168, Val Loss: 0.1034, Val Acc: 0.9658
Epoch 53/100, Loss: 0.1902, Acc: 0.9168, Val Loss: 0.1066, Val Acc: 0.9654
Epoch 54/100, Loss: 0.1904, Acc: 0.9171, Val Loss: 0.1013, Val Acc: 0.9662
Epoch 55/100, Loss: 0.1901, Acc: 0.9184, Val Loss: 0.1028, Val Acc: 0.9665
Epoch 56/100, Loss: 0.1902, Acc: 0.9173, Val Loss: 0.1051, Val Acc: 0.9651
Epoch 57/100, Loss: 0.1901, Acc: 0.9171, Val Loss: 0.1053, Val Acc: 0.9651
Epoch 58/100, Loss: 0.1900, Acc: 0.9164, Val Loss: 0.1036, Val Acc: 0.9654
Epoch 59/100, Loss: 0.1900, Acc: 0.9169, Val Loss: 0.1046, Val Acc: 0.9662
Epoch 60/100, Loss: 0.1899, Acc: 0.9165, Val Loss: 0.1027, Val Acc: 0.9662
Epoch 61/100, Loss: 0.1900, Acc: 0.9166, Val Loss: 0.1067, Val Acc: 0.9651
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.1896, Acc: 0.9174, Val Loss: 0.1046, Val Acc: 0.9647
Epoch 63/100, Loss: 0.1896, Acc: 0.9165, Val Loss: 0.1042, Val Acc: 0.9654
Epoch 64/100, Loss: 0.1895, Acc: 0.9171, Val Loss: 0.1025, Val Acc: 0.9647
Epoch 65/100, Loss: 0.1895, Acc: 0.9177, Val Loss: 0.1036, Val Acc: 0.9651
Epoch 66/100, Loss: 0.1893, Acc: 0.9169, Val Loss: 0.1022, Val Acc: 0.9654
Epoch 67/100, Loss: 0.1893, Acc: 0.9176, Val Loss: 0.1036, Val Acc: 0.9651
Epoch 68/100, Loss: 0.1894, Acc: 0.9170, Val Loss: 0.1023, Val Acc: 0.9658
Epoch 69/100, Loss: 0.1894, Acc: 0.9172, Val Loss: 0.1033, Val Acc: 0.9651
Epoch 70/100, Loss: 0.1891, Acc: 0.9162, Val Loss: 0.1040, Val Acc: 0.9651
Epoch 71/100, Loss: 0.1894, Acc: 0.9175, Val Loss: 0.1031, Val Acc: 0.9651
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.1890, Acc: 0.9171, Val Loss: 0.1027, Val Acc: 0.9651
Epoch 73/100, Loss: 0.1889, Acc: 0.9175, Val Loss: 0.1039, Val Acc: 0.9651
Epoch 74/100, Loss: 0.1888, Acc: 0.9172, Val Loss: 0.1024, Val Acc: 0.9647
Epoch 75/100, Loss: 0.1887, Acc: 0.9171, Val Loss: 0.1025, Val Acc: 0.9651
Epoch 76/100, Loss: 0.1887, Acc: 0.9171, Val Loss: 0.1025, Val Acc: 0.9651
Epoch 77/100, Loss: 0.1888, Acc: 0.9173, Val Loss: 0.1017, Val Acc: 0.9654
Epoch 78/100, Loss: 0.1887, Acc: 0.9169, Val Loss: 0.1024, Val Acc: 0.9651
Epoch 79/100, Loss: 0.1887, Acc: 0.9165, Val Loss: 0.1032, Val Acc: 0.9651
Epoch 80/100, Loss: 0.1887, Acc: 0.9166, Val Loss: 0.1033, Val Acc: 0.9651
Epoch 81/100, Loss: 0.1887, Acc: 0.9167, Val Loss: 0.1033, Val Acc: 0.9654
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.1887, Acc: 0.9170, Val Loss: 0.1026, Val Acc: 0.9651
Epoch 83/100, Loss: 0.1887, Acc: 0.9172, Val Loss: 0.1031, Val Acc: 0.9654
Epoch 84/100, Loss: 0.1887, Acc: 0.9175, Val Loss: 0.1028, Val Acc: 0.9651
Epoch 85/100, Loss: 0.1887, Acc: 0.9167, Val Loss: 0.1025, Val Acc: 0.9651
Epoch 86/100, Loss: 0.1886, Acc: 0.9176, Val Loss: 0.1021, Val Acc: 0.9654
Epoch 87/100, Loss: 0.1887, Acc: 0.9166, Val Loss: 0.1026, Val Acc: 0.9654
Epoch 88/100, Loss: 0.1887, Acc: 0.9171, Val Loss: 0.1034, Val Acc: 0.9651
Epoch 89/100, Loss: 0.1886, Acc: 0.9170, Val Loss: 0.1027, Val Acc: 0.9651
Epoch 90/100, Loss: 0.1886, Acc: 0.9172, Val Loss: 0.1020, Val Acc: 0.9647
Epoch 91/100, Loss: 0.1886, Acc: 0.9173, Val Loss: 0.1022, Val Acc: 0.9654
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.1885, Acc: 0.9171, Val Loss: 0.1032, Val Acc: 0.9651
Epoch 93/100, Loss: 0.1885, Acc: 0.9176, Val Loss: 0.1028, Val Acc: 0.9651
Epoch 94/100, Loss: 0.1885, Acc: 0.9168, Val Loss: 0.1027, Val Acc: 0.9651
Epoch 95/100, Loss: 0.1885, Acc: 0.9175, Val Loss: 0.1015, Val Acc: 0.9654
Epoch 96/100, Loss: 0.1885, Acc: 0.9173, Val Loss: 0.1033, Val Acc: 0.9651
Epoch 97/100, Loss: 0.1886, Acc: 0.9171, Val Loss: 0.1038, Val Acc: 0.9651
Epoch 98/100, Loss: 0.1885, Acc: 0.9176, Val Loss: 0.1017, Val Acc: 0.9654
Epoch 99/100, Loss: 0.1884, Acc: 0.9173, Val Loss: 0.1027, Val Acc: 0.9654
Epoch 100/100, Loss: 0.1884, Acc: 0.9167, Val Loss: 0.1021, Val Acc: 0.9651

##############################
Resultados para principal:  009  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1 
 {'training': [0.18843176075640847, 0.9167279411764706, 0.9118822674418605, 0.9226102941176471, 0.9172149122807017], 'validate': [0.10211958345242364, 0.9650735294117647, 0.9573391178597253, 0.9735294117647059, 0.965366387167335], 'test': [0.26382643160306746, 0.8885294117647059, 0.8659279778393352, 0.9194117647058824, 0.8918687589158345]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  118  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  118  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  118  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6923, Acc: 0.5358, Val Loss: 0.6861, Val Acc: 0.5331
Mejor modelo guardado con Val Loss: 0.6861
Epoch 2/100, Loss: 0.6889, Acc: 0.5277, Val Loss: 0.6135, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6135
Epoch 3/100, Loss: 0.6854, Acc: 0.5515, Val Loss: 0.5942, Val Acc: 0.7048
Mejor modelo guardado con Val Loss: 0.5942
Epoch 4/100, Loss: 0.6798, Acc: 0.5797, Val Loss: 0.5856, Val Acc: 0.6018
Mejor modelo guardado con Val Loss: 0.5856
Epoch 5/100, Loss: 0.6751, Acc: 0.5944, Val Loss: 0.5522, Val Acc: 0.9371
Mejor modelo guardado con Val Loss: 0.5522
Epoch 6/100, Loss: 0.6722, Acc: 0.5923, Val Loss: 0.4829, Val Acc: 0.9129
Mejor modelo guardado con Val Loss: 0.4829
Epoch 7/100, Loss: 0.6678, Acc: 0.6025, Val Loss: 0.5035, Val Acc: 0.9423
Epoch 8/100, Loss: 0.6614, Acc: 0.6145, Val Loss: 0.4784, Val Acc: 0.9191
Mejor modelo guardado con Val Loss: 0.4784
Epoch 9/100, Loss: 0.6589, Acc: 0.6213, Val Loss: 0.5138, Val Acc: 0.8191
Epoch 10/100, Loss: 0.6513, Acc: 0.6325, Val Loss: 0.4729, Val Acc: 0.7199
Mejor modelo guardado con Val Loss: 0.4729
Epoch 11/100, Loss: 0.6478, Acc: 0.6338, Val Loss: 0.4434, Val Acc: 0.8504
Mejor modelo guardado con Val Loss: 0.4434
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6430, Acc: 0.6416, Val Loss: 0.4476, Val Acc: 0.8088
Epoch 13/100, Loss: 0.6413, Acc: 0.6440, Val Loss: 0.4150, Val Acc: 0.8478
Mejor modelo guardado con Val Loss: 0.4150
Epoch 14/100, Loss: 0.6394, Acc: 0.6465, Val Loss: 0.4136, Val Acc: 0.8779
Mejor modelo guardado con Val Loss: 0.4136
Epoch 15/100, Loss: 0.6388, Acc: 0.6459, Val Loss: 0.3731, Val Acc: 0.9158
Mejor modelo guardado con Val Loss: 0.3731
Epoch 16/100, Loss: 0.6372, Acc: 0.6482, Val Loss: 0.4293, Val Acc: 0.8721
Epoch 17/100, Loss: 0.6350, Acc: 0.6520, Val Loss: 0.4000, Val Acc: 0.8625
Epoch 18/100, Loss: 0.6359, Acc: 0.6451, Val Loss: 0.4165, Val Acc: 0.8684
Epoch 19/100, Loss: 0.6320, Acc: 0.6519, Val Loss: 0.3897, Val Acc: 0.8496
Epoch 20/100, Loss: 0.6314, Acc: 0.6501, Val Loss: 0.3696, Val Acc: 0.9085
Mejor modelo guardado con Val Loss: 0.3696
Epoch 21/100, Loss: 0.6321, Acc: 0.6500, Val Loss: 0.3790, Val Acc: 0.8632
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6277, Acc: 0.6578, Val Loss: 0.3753, Val Acc: 0.8706
Epoch 23/100, Loss: 0.6279, Acc: 0.6574, Val Loss: 0.3755, Val Acc: 0.8625
Epoch 24/100, Loss: 0.6263, Acc: 0.6610, Val Loss: 0.3731, Val Acc: 0.8662
Epoch 25/100, Loss: 0.6262, Acc: 0.6578, Val Loss: 0.3541, Val Acc: 0.9088
Mejor modelo guardado con Val Loss: 0.3541
Epoch 26/100, Loss: 0.6254, Acc: 0.6608, Val Loss: 0.3703, Val Acc: 0.8739
Epoch 27/100, Loss: 0.6252, Acc: 0.6549, Val Loss: 0.3663, Val Acc: 0.8809
Epoch 28/100, Loss: 0.6241, Acc: 0.6591, Val Loss: 0.3625, Val Acc: 0.8750
Epoch 29/100, Loss: 0.6237, Acc: 0.6596, Val Loss: 0.3567, Val Acc: 0.8904
Epoch 30/100, Loss: 0.6228, Acc: 0.6638, Val Loss: 0.3666, Val Acc: 0.8676
Epoch 31/100, Loss: 0.6232, Acc: 0.6583, Val Loss: 0.3898, Val Acc: 0.8654
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6219, Acc: 0.6640, Val Loss: 0.3723, Val Acc: 0.8408
Epoch 33/100, Loss: 0.6226, Acc: 0.6597, Val Loss: 0.3554, Val Acc: 0.8746
Epoch 34/100, Loss: 0.6215, Acc: 0.6631, Val Loss: 0.3629, Val Acc: 0.8599
Epoch 35/100, Loss: 0.6210, Acc: 0.6623, Val Loss: 0.3625, Val Acc: 0.8581
Epoch 36/100, Loss: 0.6213, Acc: 0.6623, Val Loss: 0.3668, Val Acc: 0.8507
Epoch 37/100, Loss: 0.6204, Acc: 0.6625, Val Loss: 0.3766, Val Acc: 0.8287
Epoch 38/100, Loss: 0.6211, Acc: 0.6593, Val Loss: 0.3572, Val Acc: 0.8673
Epoch 39/100, Loss: 0.6203, Acc: 0.6640, Val Loss: 0.3423, Val Acc: 0.8956
Mejor modelo guardado con Val Loss: 0.3423
Epoch 40/100, Loss: 0.6204, Acc: 0.6626, Val Loss: 0.3538, Val Acc: 0.8868
Epoch 41/100, Loss: 0.6203, Acc: 0.6605, Val Loss: 0.3658, Val Acc: 0.8596
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6196, Acc: 0.6642, Val Loss: 0.3523, Val Acc: 0.8688
Epoch 43/100, Loss: 0.6191, Acc: 0.6664, Val Loss: 0.3563, Val Acc: 0.8610
Epoch 44/100, Loss: 0.6191, Acc: 0.6665, Val Loss: 0.3589, Val Acc: 0.8585
Epoch 45/100, Loss: 0.6190, Acc: 0.6641, Val Loss: 0.3511, Val Acc: 0.8761
Epoch 46/100, Loss: 0.6191, Acc: 0.6654, Val Loss: 0.3577, Val Acc: 0.8665
Epoch 47/100, Loss: 0.6191, Acc: 0.6660, Val Loss: 0.3459, Val Acc: 0.8812
Epoch 48/100, Loss: 0.6187, Acc: 0.6661, Val Loss: 0.3519, Val Acc: 0.8673
Epoch 49/100, Loss: 0.6183, Acc: 0.6652, Val Loss: 0.3660, Val Acc: 0.8386
Epoch 50/100, Loss: 0.6187, Acc: 0.6635, Val Loss: 0.3663, Val Acc: 0.8371
Epoch 51/100, Loss: 0.6187, Acc: 0.6662, Val Loss: 0.3503, Val Acc: 0.8713
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6182, Acc: 0.6649, Val Loss: 0.3542, Val Acc: 0.8629
Epoch 53/100, Loss: 0.6181, Acc: 0.6669, Val Loss: 0.3564, Val Acc: 0.8544
Epoch 54/100, Loss: 0.6180, Acc: 0.6659, Val Loss: 0.3513, Val Acc: 0.8658
Epoch 55/100, Loss: 0.6179, Acc: 0.6659, Val Loss: 0.3519, Val Acc: 0.8658
Epoch 56/100, Loss: 0.6181, Acc: 0.6653, Val Loss: 0.3522, Val Acc: 0.8621
Epoch 57/100, Loss: 0.6177, Acc: 0.6669, Val Loss: 0.3560, Val Acc: 0.8592
Epoch 58/100, Loss: 0.6180, Acc: 0.6667, Val Loss: 0.3518, Val Acc: 0.8651
Epoch 59/100, Loss: 0.6179, Acc: 0.6653, Val Loss: 0.3499, Val Acc: 0.8691
Epoch 60/100, Loss: 0.6177, Acc: 0.6667, Val Loss: 0.3566, Val Acc: 0.8518
Epoch 61/100, Loss: 0.6178, Acc: 0.6665, Val Loss: 0.3483, Val Acc: 0.8706
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6175, Acc: 0.6674, Val Loss: 0.3473, Val Acc: 0.8728
Epoch 63/100, Loss: 0.6176, Acc: 0.6665, Val Loss: 0.3508, Val Acc: 0.8643
Epoch 64/100, Loss: 0.6175, Acc: 0.6670, Val Loss: 0.3521, Val Acc: 0.8629
Epoch 65/100, Loss: 0.6174, Acc: 0.6670, Val Loss: 0.3516, Val Acc: 0.8636
Epoch 66/100, Loss: 0.6174, Acc: 0.6676, Val Loss: 0.3506, Val Acc: 0.8643
Epoch 67/100, Loss: 0.6175, Acc: 0.6649, Val Loss: 0.3505, Val Acc: 0.8647
Epoch 68/100, Loss: 0.6174, Acc: 0.6666, Val Loss: 0.3496, Val Acc: 0.8691
Epoch 69/100, Loss: 0.6174, Acc: 0.6661, Val Loss: 0.3521, Val Acc: 0.8625
Epoch 70/100, Loss: 0.6173, Acc: 0.6667, Val Loss: 0.3519, Val Acc: 0.8607
Epoch 71/100, Loss: 0.6173, Acc: 0.6666, Val Loss: 0.3499, Val Acc: 0.8640
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6173, Acc: 0.6665, Val Loss: 0.3498, Val Acc: 0.8640
Epoch 73/100, Loss: 0.6173, Acc: 0.6665, Val Loss: 0.3500, Val Acc: 0.8640
Epoch 74/100, Loss: 0.6172, Acc: 0.6671, Val Loss: 0.3495, Val Acc: 0.8643
Epoch 75/100, Loss: 0.6172, Acc: 0.6676, Val Loss: 0.3494, Val Acc: 0.8651
Epoch 76/100, Loss: 0.6172, Acc: 0.6662, Val Loss: 0.3511, Val Acc: 0.8618
Epoch 77/100, Loss: 0.6172, Acc: 0.6664, Val Loss: 0.3509, Val Acc: 0.8618
Epoch 78/100, Loss: 0.6171, Acc: 0.6662, Val Loss: 0.3500, Val Acc: 0.8643
Epoch 79/100, Loss: 0.6172, Acc: 0.6678, Val Loss: 0.3501, Val Acc: 0.8640
Epoch 80/100, Loss: 0.6171, Acc: 0.6673, Val Loss: 0.3508, Val Acc: 0.8621
Epoch 81/100, Loss: 0.6171, Acc: 0.6675, Val Loss: 0.3496, Val Acc: 0.8643
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6171, Acc: 0.6672, Val Loss: 0.3496, Val Acc: 0.8629
Epoch 83/100, Loss: 0.6165, Acc: 0.6669, Val Loss: 0.3501, Val Acc: 0.8632
Epoch 84/100, Loss: 0.6162, Acc: 0.6665, Val Loss: 0.3497, Val Acc: 0.8647
Epoch 85/100, Loss: 0.6161, Acc: 0.6669, Val Loss: 0.3496, Val Acc: 0.8651
Epoch 86/100, Loss: 0.6160, Acc: 0.6670, Val Loss: 0.3497, Val Acc: 0.8643
Epoch 87/100, Loss: 0.6160, Acc: 0.6674, Val Loss: 0.3502, Val Acc: 0.8632
Epoch 88/100, Loss: 0.6160, Acc: 0.6661, Val Loss: 0.3508, Val Acc: 0.8621
Epoch 89/100, Loss: 0.6160, Acc: 0.6675, Val Loss: 0.3522, Val Acc: 0.8607
Epoch 90/100, Loss: 0.6159, Acc: 0.6665, Val Loss: 0.3512, Val Acc: 0.8618
Epoch 91/100, Loss: 0.6159, Acc: 0.6680, Val Loss: 0.3507, Val Acc: 0.8625
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6159, Acc: 0.6682, Val Loss: 0.3503, Val Acc: 0.8625
Epoch 93/100, Loss: 0.6159, Acc: 0.6669, Val Loss: 0.3489, Val Acc: 0.8658
Epoch 94/100, Loss: 0.6158, Acc: 0.6676, Val Loss: 0.3498, Val Acc: 0.8625
Epoch 95/100, Loss: 0.6158, Acc: 0.6681, Val Loss: 0.3509, Val Acc: 0.8607
Epoch 96/100, Loss: 0.6158, Acc: 0.6674, Val Loss: 0.3502, Val Acc: 0.8621
Epoch 97/100, Loss: 0.6158, Acc: 0.6676, Val Loss: 0.3492, Val Acc: 0.8632
Epoch 98/100, Loss: 0.6157, Acc: 0.6684, Val Loss: 0.3483, Val Acc: 0.8665
Epoch 99/100, Loss: 0.6157, Acc: 0.6670, Val Loss: 0.3486, Val Acc: 0.8654
Epoch 100/100, Loss: 0.6157, Acc: 0.6675, Val Loss: 0.3489, Val Acc: 0.8651

##############################
Resultados para principal:  118  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1 
 {'training': [0.6156909998725443, 0.6674632352941177, 0.6418119551681195, 0.7579044117647059, 0.6950438300741739], 'validate': [0.34889745478366696, 0.8650735294117647, 0.9901283316880553, 0.7375, 0.8453434471133586], 'test': [0.7097451350203267, 0.5402941176470588, 0.5286971093422707, 0.7423529411764705, 0.6175678982138488]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  032  --- window & package numer:  1

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  032  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  1
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  032  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6844, Acc: 0.5711, Val Loss: 0.7333, Val Acc: 0.2217
Mejor modelo guardado con Val Loss: 0.7333
Epoch 2/100, Loss: 0.6733, Acc: 0.5966, Val Loss: 0.7349, Val Acc: 0.3842
Epoch 3/100, Loss: 0.6656, Acc: 0.5975, Val Loss: 0.8126, Val Acc: 0.2320
Epoch 4/100, Loss: 0.6604, Acc: 0.6013, Val Loss: 0.7483, Val Acc: 0.4136
Epoch 5/100, Loss: 0.6555, Acc: 0.6093, Val Loss: 0.8054, Val Acc: 0.2342
Epoch 6/100, Loss: 0.6560, Acc: 0.6036, Val Loss: 0.7691, Val Acc: 0.3805
Epoch 7/100, Loss: 0.6535, Acc: 0.6085, Val Loss: 0.7778, Val Acc: 0.3643
Epoch 8/100, Loss: 0.6510, Acc: 0.6082, Val Loss: 0.7964, Val Acc: 0.3316
Epoch 9/100, Loss: 0.6471, Acc: 0.6138, Val Loss: 0.7532, Val Acc: 0.4434
Epoch 10/100, Loss: 0.6471, Acc: 0.6115, Val Loss: 0.8171, Val Acc: 0.3165
Epoch 11/100, Loss: 0.6460, Acc: 0.6155, Val Loss: 0.8200, Val Acc: 0.3460
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6441, Acc: 0.6165, Val Loss: 0.8012, Val Acc: 0.3640
Epoch 13/100, Loss: 0.6453, Acc: 0.6150, Val Loss: 0.8202, Val Acc: 0.3213
Epoch 14/100, Loss: 0.6438, Acc: 0.6153, Val Loss: 0.8440, Val Acc: 0.3272
Epoch 15/100, Loss: 0.6432, Acc: 0.6174, Val Loss: 0.8158, Val Acc: 0.3316
Epoch 16/100, Loss: 0.6428, Acc: 0.6193, Val Loss: 0.7981, Val Acc: 0.3743
Epoch 17/100, Loss: 0.6421, Acc: 0.6199, Val Loss: 0.8480, Val Acc: 0.3320
Epoch 18/100, Loss: 0.6432, Acc: 0.6147, Val Loss: 0.8397, Val Acc: 0.3408
Epoch 19/100, Loss: 0.6420, Acc: 0.6166, Val Loss: 0.8076, Val Acc: 0.3735
Epoch 20/100, Loss: 0.6414, Acc: 0.6214, Val Loss: 0.8352, Val Acc: 0.3004
Epoch 21/100, Loss: 0.6420, Acc: 0.6197, Val Loss: 0.8076, Val Acc: 0.3441
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6397, Acc: 0.6193, Val Loss: 0.7952, Val Acc: 0.3754
Epoch 23/100, Loss: 0.6393, Acc: 0.6232, Val Loss: 0.8205, Val Acc: 0.3526
Epoch 24/100, Loss: 0.6401, Acc: 0.6201, Val Loss: 0.8275, Val Acc: 0.3555
Epoch 25/100, Loss: 0.6395, Acc: 0.6219, Val Loss: 0.8450, Val Acc: 0.3173
Epoch 26/100, Loss: 0.6391, Acc: 0.6231, Val Loss: 0.8185, Val Acc: 0.3581
Epoch 27/100, Loss: 0.6387, Acc: 0.6260, Val Loss: 0.8499, Val Acc: 0.3110
Epoch 28/100, Loss: 0.6401, Acc: 0.6221, Val Loss: 0.8324, Val Acc: 0.3335
Epoch 29/100, Loss: 0.6391, Acc: 0.6231, Val Loss: 0.8066, Val Acc: 0.3842
Epoch 30/100, Loss: 0.6391, Acc: 0.6222, Val Loss: 0.8232, Val Acc: 0.3482
Epoch 31/100, Loss: 0.6390, Acc: 0.6246, Val Loss: 0.8630, Val Acc: 0.3055
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6380, Acc: 0.6257, Val Loss: 0.8417, Val Acc: 0.3316
Epoch 33/100, Loss: 0.6377, Acc: 0.6249, Val Loss: 0.8369, Val Acc: 0.3206
Epoch 34/100, Loss: 0.6373, Acc: 0.6271, Val Loss: 0.8306, Val Acc: 0.3415
Epoch 35/100, Loss: 0.6372, Acc: 0.6248, Val Loss: 0.8223, Val Acc: 0.3438
Epoch 36/100, Loss: 0.6376, Acc: 0.6241, Val Loss: 0.8175, Val Acc: 0.3607
Epoch 37/100, Loss: 0.6377, Acc: 0.6239, Val Loss: 0.8376, Val Acc: 0.3482
Epoch 38/100, Loss: 0.6381, Acc: 0.6231, Val Loss: 0.8489, Val Acc: 0.3136
Epoch 39/100, Loss: 0.6369, Acc: 0.6261, Val Loss: 0.8195, Val Acc: 0.3551
Epoch 40/100, Loss: 0.6371, Acc: 0.6253, Val Loss: 0.8013, Val Acc: 0.3768
Epoch 41/100, Loss: 0.6372, Acc: 0.6251, Val Loss: 0.8221, Val Acc: 0.3471
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6360, Acc: 0.6285, Val Loss: 0.8418, Val Acc: 0.3393
Epoch 43/100, Loss: 0.6362, Acc: 0.6281, Val Loss: 0.8121, Val Acc: 0.3643
Epoch 44/100, Loss: 0.6359, Acc: 0.6266, Val Loss: 0.8253, Val Acc: 0.3460
Epoch 45/100, Loss: 0.6361, Acc: 0.6266, Val Loss: 0.8257, Val Acc: 0.3504
Epoch 46/100, Loss: 0.6359, Acc: 0.6267, Val Loss: 0.8293, Val Acc: 0.3456
Epoch 47/100, Loss: 0.6358, Acc: 0.6262, Val Loss: 0.8130, Val Acc: 0.3596
Epoch 48/100, Loss: 0.6358, Acc: 0.6259, Val Loss: 0.8249, Val Acc: 0.3518
Epoch 49/100, Loss: 0.6355, Acc: 0.6260, Val Loss: 0.8206, Val Acc: 0.3460
Epoch 50/100, Loss: 0.6353, Acc: 0.6254, Val Loss: 0.8213, Val Acc: 0.3585
Epoch 51/100, Loss: 0.6354, Acc: 0.6261, Val Loss: 0.8296, Val Acc: 0.3364
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6350, Acc: 0.6256, Val Loss: 0.8317, Val Acc: 0.3397
Epoch 53/100, Loss: 0.6350, Acc: 0.6267, Val Loss: 0.8244, Val Acc: 0.3460
Epoch 54/100, Loss: 0.6348, Acc: 0.6250, Val Loss: 0.8222, Val Acc: 0.3456
Epoch 55/100, Loss: 0.6348, Acc: 0.6265, Val Loss: 0.8260, Val Acc: 0.3434
Epoch 56/100, Loss: 0.6346, Acc: 0.6262, Val Loss: 0.8157, Val Acc: 0.3518
Epoch 57/100, Loss: 0.6346, Acc: 0.6253, Val Loss: 0.8254, Val Acc: 0.3456
Epoch 58/100, Loss: 0.6346, Acc: 0.6276, Val Loss: 0.8249, Val Acc: 0.3460
Epoch 59/100, Loss: 0.6347, Acc: 0.6255, Val Loss: 0.8320, Val Acc: 0.3386
Epoch 60/100, Loss: 0.6346, Acc: 0.6254, Val Loss: 0.8356, Val Acc: 0.3338
Epoch 61/100, Loss: 0.6344, Acc: 0.6266, Val Loss: 0.8243, Val Acc: 0.3478
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6342, Acc: 0.6264, Val Loss: 0.8260, Val Acc: 0.3430
Epoch 63/100, Loss: 0.6342, Acc: 0.6267, Val Loss: 0.8256, Val Acc: 0.3430
Epoch 64/100, Loss: 0.6341, Acc: 0.6257, Val Loss: 0.8233, Val Acc: 0.3445
Epoch 65/100, Loss: 0.6341, Acc: 0.6267, Val Loss: 0.8255, Val Acc: 0.3430
Epoch 66/100, Loss: 0.6341, Acc: 0.6264, Val Loss: 0.8271, Val Acc: 0.3426
Epoch 67/100, Loss: 0.6341, Acc: 0.6272, Val Loss: 0.8187, Val Acc: 0.3482
Epoch 68/100, Loss: 0.6340, Acc: 0.6276, Val Loss: 0.8232, Val Acc: 0.3445
Epoch 69/100, Loss: 0.6340, Acc: 0.6274, Val Loss: 0.8251, Val Acc: 0.3438
Epoch 70/100, Loss: 0.6340, Acc: 0.6262, Val Loss: 0.8256, Val Acc: 0.3423
Epoch 71/100, Loss: 0.6339, Acc: 0.6274, Val Loss: 0.8234, Val Acc: 0.3430
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6338, Acc: 0.6268, Val Loss: 0.8222, Val Acc: 0.3430
Epoch 73/100, Loss: 0.6337, Acc: 0.6256, Val Loss: 0.8247, Val Acc: 0.3423
Epoch 74/100, Loss: 0.6337, Acc: 0.6261, Val Loss: 0.8258, Val Acc: 0.3419
Epoch 75/100, Loss: 0.6336, Acc: 0.6272, Val Loss: 0.8269, Val Acc: 0.3415
Epoch 76/100, Loss: 0.6336, Acc: 0.6268, Val Loss: 0.8226, Val Acc: 0.3430
Epoch 77/100, Loss: 0.6336, Acc: 0.6261, Val Loss: 0.8247, Val Acc: 0.3423
Epoch 78/100, Loss: 0.6336, Acc: 0.6271, Val Loss: 0.8217, Val Acc: 0.3434
Epoch 79/100, Loss: 0.6335, Acc: 0.6277, Val Loss: 0.8244, Val Acc: 0.3419
Epoch 80/100, Loss: 0.6335, Acc: 0.6262, Val Loss: 0.8234, Val Acc: 0.3419
Epoch 81/100, Loss: 0.6335, Acc: 0.6267, Val Loss: 0.8246, Val Acc: 0.3419
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6335, Acc: 0.6274, Val Loss: 0.8210, Val Acc: 0.3430
Epoch 83/100, Loss: 0.6334, Acc: 0.6264, Val Loss: 0.8233, Val Acc: 0.3419
Epoch 84/100, Loss: 0.6333, Acc: 0.6267, Val Loss: 0.8225, Val Acc: 0.3423
Epoch 85/100, Loss: 0.6333, Acc: 0.6262, Val Loss: 0.8249, Val Acc: 0.3408
Epoch 86/100, Loss: 0.6333, Acc: 0.6267, Val Loss: 0.8211, Val Acc: 0.3430
Epoch 87/100, Loss: 0.6332, Acc: 0.6264, Val Loss: 0.8216, Val Acc: 0.3430
Epoch 88/100, Loss: 0.6331, Acc: 0.6270, Val Loss: 0.8205, Val Acc: 0.3438
Epoch 89/100, Loss: 0.6329, Acc: 0.6265, Val Loss: 0.8207, Val Acc: 0.3441
Epoch 90/100, Loss: 0.6328, Acc: 0.6267, Val Loss: 0.8223, Val Acc: 0.3430
Epoch 91/100, Loss: 0.6328, Acc: 0.6279, Val Loss: 0.8263, Val Acc: 0.3404
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6326, Acc: 0.6273, Val Loss: 0.8204, Val Acc: 0.3423
Epoch 93/100, Loss: 0.6324, Acc: 0.6278, Val Loss: 0.8173, Val Acc: 0.3430
Epoch 94/100, Loss: 0.6324, Acc: 0.6277, Val Loss: 0.8163, Val Acc: 0.3423
Epoch 95/100, Loss: 0.6322, Acc: 0.6278, Val Loss: 0.8134, Val Acc: 0.3467
Epoch 96/100, Loss: 0.6322, Acc: 0.6280, Val Loss: 0.8122, Val Acc: 0.3467
Epoch 97/100, Loss: 0.6321, Acc: 0.6287, Val Loss: 0.8174, Val Acc: 0.3412
Epoch 98/100, Loss: 0.6321, Acc: 0.6278, Val Loss: 0.8116, Val Acc: 0.3463
Epoch 99/100, Loss: 0.6320, Acc: 0.6276, Val Loss: 0.8172, Val Acc: 0.3415
Epoch 100/100, Loss: 0.6319, Acc: 0.6288, Val Loss: 0.8149, Val Acc: 0.3430

##############################
Resultados para principal:  032  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  1 
 {'training': [0.6319352753022138, 0.6287683823529412, 0.5894750287393026, 0.8483455882352942, 0.6956063003994273], 'validate': [0.8149117813553921, 0.34301470588235294, 0.40689053641517664, 0.6860294117647059, 0.5108130303859841], 'test': [0.6844272492108522, 0.586764705882353, 0.5905463474524248, 0.5658823529411765, 0.5779513367377591]}

##############################
Resultados para window:  1 
 {'067:124:010:009:118:032': {'training': [0.45232020861962263, 0.7860294117647059, 0.812575331458417, 0.7435661764705882, 0.7765406028028412], 'validate': [0.4955904483795166, 0.7654411764705882, 0.7222906403940886, 0.8625, 0.7861930294906166], 'test': [0.5811305385496881, 0.6844117647058824, 0.7402298850574712, 0.5682352941176471, 0.642928452579035]}, '124:067:010:009:118:032': {'training': [0.4003576290958068, 0.8190257352941176, 0.7821492440253617, 0.884375, 0.8301268225347253], 'validate': [0.7107345735610917, 0.5992647058823529, 0.5645933014354066, 0.8676470588235294, 0.6840579710144927], 'test': [0.6685640816059377, 0.6252941176470588, 0.5847929936305732, 0.8641176470588235, 0.6975308641975309]}, '010:067:124:009:118:032': {'training': [0.5447256708846373, 0.7058823529411765, 0.6499330655957162, 0.8924632352941176, 0.7521301316808675], 'validate': [0.8342154774554941, 0.42683823529411763, 0.4472708002119767, 0.6205882352941177, 0.5198644902987373], 'test': [0.6501902391513189, 0.5894117647058823, 0.8671497584541062, 0.2111764705882353, 0.33964049195837276]}, '009:067:124:010:118:032': {'training': [0.18843176075640847, 0.9167279411764706, 0.9118822674418605, 0.9226102941176471, 0.9172149122807017], 'validate': [0.10211958345242364, 0.9650735294117647, 0.9573391178597253, 0.9735294117647059, 0.965366387167335], 'test': [0.26382643160306746, 0.8885294117647059, 0.8659279778393352, 0.9194117647058824, 0.8918687589158345]}, '118:067:124:010:009:032': {'training': [0.6156909998725443, 0.6674632352941177, 0.6418119551681195, 0.7579044117647059, 0.6950438300741739], 'validate': [0.34889745478366696, 0.8650735294117647, 0.9901283316880553, 0.7375, 0.8453434471133586], 'test': [0.7097451350203267, 0.5402941176470588, 0.5286971093422707, 0.7423529411764705, 0.6175678982138488]}, '032:067:124:010:009:118': {'training': [0.6319352753022138, 0.6287683823529412, 0.5894750287393026, 0.8483455882352942, 0.6956063003994273], 'validate': [0.8149117813553921, 0.34301470588235294, 0.40689053641517664, 0.6860294117647059, 0.5108130303859841], 'test': [0.6844272492108522, 0.586764705882353, 0.5905463474524248, 0.5658823529411765, 0.5779513367377591]}}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  095  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  095  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6871, Acc: 0.5579, Val Loss: 0.6837, Val Acc: 0.5497
Mejor modelo guardado con Val Loss: 0.6837
Epoch 2/100, Loss: 0.6856, Acc: 0.5568, Val Loss: 0.6994, Val Acc: 0.5018
Epoch 3/100, Loss: 0.6832, Acc: 0.5735, Val Loss: 0.6823, Val Acc: 0.5644
Mejor modelo guardado con Val Loss: 0.6823
Epoch 4/100, Loss: 0.6811, Acc: 0.5690, Val Loss: 0.6822, Val Acc: 0.5559
Mejor modelo guardado con Val Loss: 0.6822
Epoch 5/100, Loss: 0.6755, Acc: 0.5936, Val Loss: 0.6676, Val Acc: 0.6107
Mejor modelo guardado con Val Loss: 0.6676
Epoch 6/100, Loss: 0.6702, Acc: 0.5951, Val Loss: 0.6732, Val Acc: 0.5839
Epoch 7/100, Loss: 0.6855, Acc: 0.5663, Val Loss: 0.7032, Val Acc: 0.4996
Epoch 8/100, Loss: 0.6846, Acc: 0.5405, Val Loss: 0.6715, Val Acc: 0.5916
Epoch 9/100, Loss: 0.6678, Acc: 0.6029, Val Loss: 0.6558, Val Acc: 0.6310
Mejor modelo guardado con Val Loss: 0.6558
Epoch 10/100, Loss: 0.6659, Acc: 0.6094, Val Loss: 0.6817, Val Acc: 0.5865
Epoch 11/100, Loss: 0.6614, Acc: 0.6125, Val Loss: 0.6760, Val Acc: 0.5754
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6580, Acc: 0.6156, Val Loss: 0.6734, Val Acc: 0.5784
Epoch 13/100, Loss: 0.6568, Acc: 0.6163, Val Loss: 0.6793, Val Acc: 0.5990
Epoch 14/100, Loss: 0.6563, Acc: 0.6177, Val Loss: 0.6776, Val Acc: 0.5662
Epoch 15/100, Loss: 0.6565, Acc: 0.6137, Val Loss: 0.6497, Val Acc: 0.6365
Mejor modelo guardado con Val Loss: 0.6497
Epoch 16/100, Loss: 0.6582, Acc: 0.6141, Val Loss: 0.6533, Val Acc: 0.6266
Epoch 17/100, Loss: 0.6539, Acc: 0.6165, Val Loss: 0.6493, Val Acc: 0.6361
Mejor modelo guardado con Val Loss: 0.6493
Epoch 18/100, Loss: 0.6580, Acc: 0.6192, Val Loss: 0.6560, Val Acc: 0.6328
Epoch 19/100, Loss: 0.6532, Acc: 0.6227, Val Loss: 0.6585, Val Acc: 0.6137
Epoch 20/100, Loss: 0.6564, Acc: 0.6180, Val Loss: 0.6811, Val Acc: 0.5651
Epoch 21/100, Loss: 0.6515, Acc: 0.6225, Val Loss: 0.6469, Val Acc: 0.6435
Mejor modelo guardado con Val Loss: 0.6469
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6491, Acc: 0.6256, Val Loss: 0.6541, Val Acc: 0.6203
Epoch 23/100, Loss: 0.6498, Acc: 0.6204, Val Loss: 0.6557, Val Acc: 0.6174
Epoch 24/100, Loss: 0.6517, Acc: 0.6182, Val Loss: 0.6534, Val Acc: 0.6247
Epoch 25/100, Loss: 0.6490, Acc: 0.6236, Val Loss: 0.6530, Val Acc: 0.6244
Epoch 26/100, Loss: 0.6487, Acc: 0.6260, Val Loss: 0.6528, Val Acc: 0.6258
Epoch 27/100, Loss: 0.6483, Acc: 0.6250, Val Loss: 0.6521, Val Acc: 0.6273
Epoch 28/100, Loss: 0.6496, Acc: 0.6205, Val Loss: 0.6481, Val Acc: 0.6428
Epoch 29/100, Loss: 0.6493, Acc: 0.6267, Val Loss: 0.6484, Val Acc: 0.6380
Epoch 30/100, Loss: 0.6492, Acc: 0.6221, Val Loss: 0.6491, Val Acc: 0.6380
Epoch 31/100, Loss: 0.6495, Acc: 0.6281, Val Loss: 0.6557, Val Acc: 0.6144
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6474, Acc: 0.6262, Val Loss: 0.6486, Val Acc: 0.6383
Epoch 33/100, Loss: 0.6476, Acc: 0.6267, Val Loss: 0.6479, Val Acc: 0.6420
Epoch 34/100, Loss: 0.6469, Acc: 0.6280, Val Loss: 0.6530, Val Acc: 0.6266
Epoch 35/100, Loss: 0.6471, Acc: 0.6266, Val Loss: 0.6492, Val Acc: 0.6358
Epoch 36/100, Loss: 0.6467, Acc: 0.6271, Val Loss: 0.6486, Val Acc: 0.6428
Epoch 37/100, Loss: 0.6461, Acc: 0.6302, Val Loss: 0.6476, Val Acc: 0.6361
Epoch 38/100, Loss: 0.6459, Acc: 0.6259, Val Loss: 0.6579, Val Acc: 0.6067
Epoch 39/100, Loss: 0.6450, Acc: 0.6270, Val Loss: 0.6534, Val Acc: 0.6255
Epoch 40/100, Loss: 0.6443, Acc: 0.6276, Val Loss: 0.6542, Val Acc: 0.6148
Epoch 41/100, Loss: 0.6445, Acc: 0.6258, Val Loss: 0.6530, Val Acc: 0.6218
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6444, Acc: 0.6282, Val Loss: 0.6509, Val Acc: 0.6302
Epoch 43/100, Loss: 0.6432, Acc: 0.6290, Val Loss: 0.6527, Val Acc: 0.6255
Epoch 44/100, Loss: 0.6434, Acc: 0.6294, Val Loss: 0.6521, Val Acc: 0.6277
Epoch 45/100, Loss: 0.6436, Acc: 0.6293, Val Loss: 0.6517, Val Acc: 0.6266
Epoch 46/100, Loss: 0.6435, Acc: 0.6300, Val Loss: 0.6513, Val Acc: 0.6291
Epoch 47/100, Loss: 0.6433, Acc: 0.6298, Val Loss: 0.6523, Val Acc: 0.6247
Epoch 48/100, Loss: 0.6436, Acc: 0.6276, Val Loss: 0.6491, Val Acc: 0.6383
Epoch 49/100, Loss: 0.6434, Acc: 0.6281, Val Loss: 0.6516, Val Acc: 0.6291
Epoch 50/100, Loss: 0.6436, Acc: 0.6282, Val Loss: 0.6528, Val Acc: 0.6247
Epoch 51/100, Loss: 0.6430, Acc: 0.6303, Val Loss: 0.6536, Val Acc: 0.6148
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6434, Acc: 0.6259, Val Loss: 0.6515, Val Acc: 0.6299
Epoch 53/100, Loss: 0.6430, Acc: 0.6292, Val Loss: 0.6525, Val Acc: 0.6266
Epoch 54/100, Loss: 0.6428, Acc: 0.6311, Val Loss: 0.6524, Val Acc: 0.6277
Epoch 55/100, Loss: 0.6424, Acc: 0.6315, Val Loss: 0.6530, Val Acc: 0.6247
Epoch 56/100, Loss: 0.6429, Acc: 0.6304, Val Loss: 0.6526, Val Acc: 0.6273
Epoch 57/100, Loss: 0.6421, Acc: 0.6304, Val Loss: 0.6537, Val Acc: 0.6177
Epoch 58/100, Loss: 0.6427, Acc: 0.6281, Val Loss: 0.6519, Val Acc: 0.6288
Epoch 59/100, Loss: 0.6426, Acc: 0.6306, Val Loss: 0.6526, Val Acc: 0.6277
Epoch 60/100, Loss: 0.6428, Acc: 0.6287, Val Loss: 0.6528, Val Acc: 0.6277
Epoch 61/100, Loss: 0.6426, Acc: 0.6314, Val Loss: 0.6510, Val Acc: 0.6328
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6424, Acc: 0.6317, Val Loss: 0.6524, Val Acc: 0.6295
Epoch 63/100, Loss: 0.6423, Acc: 0.6307, Val Loss: 0.6529, Val Acc: 0.6288
Epoch 64/100, Loss: 0.6424, Acc: 0.6301, Val Loss: 0.6525, Val Acc: 0.6277
Epoch 65/100, Loss: 0.6423, Acc: 0.6306, Val Loss: 0.6525, Val Acc: 0.6277
Epoch 66/100, Loss: 0.6422, Acc: 0.6313, Val Loss: 0.6527, Val Acc: 0.6288
Epoch 67/100, Loss: 0.6424, Acc: 0.6305, Val Loss: 0.6528, Val Acc: 0.6284
Epoch 68/100, Loss: 0.6423, Acc: 0.6301, Val Loss: 0.6531, Val Acc: 0.6273
Epoch 69/100, Loss: 0.6422, Acc: 0.6304, Val Loss: 0.6530, Val Acc: 0.6280
Epoch 70/100, Loss: 0.6422, Acc: 0.6314, Val Loss: 0.6527, Val Acc: 0.6288
Epoch 71/100, Loss: 0.6422, Acc: 0.6304, Val Loss: 0.6529, Val Acc: 0.6295
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6422, Acc: 0.6300, Val Loss: 0.6533, Val Acc: 0.6288
Epoch 73/100, Loss: 0.6420, Acc: 0.6300, Val Loss: 0.6530, Val Acc: 0.6299
Epoch 74/100, Loss: 0.6420, Acc: 0.6300, Val Loss: 0.6529, Val Acc: 0.6317
Epoch 75/100, Loss: 0.6420, Acc: 0.6307, Val Loss: 0.6534, Val Acc: 0.6284
Epoch 76/100, Loss: 0.6420, Acc: 0.6301, Val Loss: 0.6536, Val Acc: 0.6280
Epoch 77/100, Loss: 0.6420, Acc: 0.6313, Val Loss: 0.6533, Val Acc: 0.6295
Epoch 78/100, Loss: 0.6419, Acc: 0.6314, Val Loss: 0.6532, Val Acc: 0.6295
Epoch 79/100, Loss: 0.6419, Acc: 0.6303, Val Loss: 0.6532, Val Acc: 0.6299
Epoch 80/100, Loss: 0.6420, Acc: 0.6294, Val Loss: 0.6534, Val Acc: 0.6273
Epoch 81/100, Loss: 0.6420, Acc: 0.6300, Val Loss: 0.6534, Val Acc: 0.6280
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6418, Acc: 0.6315, Val Loss: 0.6537, Val Acc: 0.6277
Epoch 83/100, Loss: 0.6419, Acc: 0.6293, Val Loss: 0.6534, Val Acc: 0.6284
Epoch 84/100, Loss: 0.6418, Acc: 0.6309, Val Loss: 0.6533, Val Acc: 0.6280
Epoch 85/100, Loss: 0.6419, Acc: 0.6304, Val Loss: 0.6530, Val Acc: 0.6291
Epoch 86/100, Loss: 0.6418, Acc: 0.6314, Val Loss: 0.6531, Val Acc: 0.6288
Epoch 87/100, Loss: 0.6419, Acc: 0.6314, Val Loss: 0.6534, Val Acc: 0.6280
Epoch 88/100, Loss: 0.6418, Acc: 0.6309, Val Loss: 0.6532, Val Acc: 0.6291
Epoch 89/100, Loss: 0.6418, Acc: 0.6307, Val Loss: 0.6530, Val Acc: 0.6291
Epoch 90/100, Loss: 0.6418, Acc: 0.6312, Val Loss: 0.6532, Val Acc: 0.6291
Epoch 91/100, Loss: 0.6417, Acc: 0.6307, Val Loss: 0.6533, Val Acc: 0.6288
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6418, Acc: 0.6315, Val Loss: 0.6536, Val Acc: 0.6280
Epoch 93/100, Loss: 0.6417, Acc: 0.6304, Val Loss: 0.6534, Val Acc: 0.6284
Epoch 94/100, Loss: 0.6416, Acc: 0.6304, Val Loss: 0.6526, Val Acc: 0.6310
Epoch 95/100, Loss: 0.6417, Acc: 0.6325, Val Loss: 0.6530, Val Acc: 0.6302
Epoch 96/100, Loss: 0.6416, Acc: 0.6314, Val Loss: 0.6535, Val Acc: 0.6280
Epoch 97/100, Loss: 0.6416, Acc: 0.6306, Val Loss: 0.6531, Val Acc: 0.6306
Epoch 98/100, Loss: 0.6416, Acc: 0.6307, Val Loss: 0.6527, Val Acc: 0.6306
Epoch 99/100, Loss: 0.6417, Acc: 0.6310, Val Loss: 0.6533, Val Acc: 0.6295
Epoch 100/100, Loss: 0.6416, Acc: 0.6319, Val Loss: 0.6533, Val Acc: 0.6295

##############################
Resultados para principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3 
 {'training': [0.6416207584174903, 0.631917631917632, 0.5943421052631579, 0.8306362633321074, 0.6928976836938181], 'validate': [0.6533217603384063, 0.6295069904341427, 0.5982092893116956, 0.7871870397643593, 0.6798092209856915], 'test': [0.5925974696874619, 0.7257210123602119, 0.729066985645933, 0.7179034157832744, 0.7234421364985163]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  065  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  065  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6937, Acc: 0.5007, Val Loss: 0.6933, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6933
Epoch 2/100, Loss: 0.6937, Acc: 0.4976, Val Loss: 0.6934, Val Acc: 0.4996
Epoch 3/100, Loss: 0.6934, Acc: 0.4994, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 4/100, Loss: 0.6934, Acc: 0.4999, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 5/100, Loss: 0.6935, Acc: 0.4973, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 6/100, Loss: 0.6936, Acc: 0.4973, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 7/100, Loss: 0.6932, Acc: 0.5038, Val Loss: 0.6935, Val Acc: 0.4996
Epoch 8/100, Loss: 0.6932, Acc: 0.5062, Val Loss: 0.6946, Val Acc: 0.4996
Epoch 9/100, Loss: 0.6934, Acc: 0.5012, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 10/100, Loss: 0.6935, Acc: 0.4953, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 11/100, Loss: 0.6934, Acc: 0.4937, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6934, Acc: 0.4924, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 13/100, Loss: 0.6933, Acc: 0.5043, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 14/100, Loss: 0.6933, Acc: 0.4987, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 15/100, Loss: 0.6933, Acc: 0.4955, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 16/100, Loss: 0.6933, Acc: 0.4966, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 17/100, Loss: 0.6932, Acc: 0.5019, Val Loss: 0.6935, Val Acc: 0.4996
Epoch 18/100, Loss: 0.6933, Acc: 0.5014, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 19/100, Loss: 0.6933, Acc: 0.4986, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 20/100, Loss: 0.6933, Acc: 0.4929, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 21/100, Loss: 0.6932, Acc: 0.5017, Val Loss: 0.6931, Val Acc: 0.5004
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4990, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 23/100, Loss: 0.6933, Acc: 0.4981, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 24/100, Loss: 0.6932, Acc: 0.4968, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 25/100, Loss: 0.6932, Acc: 0.4949, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 26/100, Loss: 0.6932, Acc: 0.4966, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 27/100, Loss: 0.6933, Acc: 0.4962, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 28/100, Loss: 0.6932, Acc: 0.5008, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 29/100, Loss: 0.6932, Acc: 0.4890, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 30/100, Loss: 0.6932, Acc: 0.4959, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 31/100, Loss: 0.6932, Acc: 0.4984, Val Loss: 0.6932, Val Acc: 0.4996
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4923, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 33/100, Loss: 0.6932, Acc: 0.4936, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 34/100, Loss: 0.6932, Acc: 0.4962, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 35/100, Loss: 0.6932, Acc: 0.4992, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 36/100, Loss: 0.6932, Acc: 0.5011, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 37/100, Loss: 0.6932, Acc: 0.4954, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 38/100, Loss: 0.6932, Acc: 0.4962, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 39/100, Loss: 0.6932, Acc: 0.4943, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 40/100, Loss: 0.6932, Acc: 0.4938, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 41/100, Loss: 0.6932, Acc: 0.4865, Val Loss: 0.6931, Val Acc: 0.5000
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.5004, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 43/100, Loss: 0.6932, Acc: 0.5003, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 44/100, Loss: 0.6932, Acc: 0.4979, Val Loss: 0.6929, Val Acc: 0.5651
Mejor modelo guardado con Val Loss: 0.6929
Epoch 45/100, Loss: 0.6932, Acc: 0.4970, Val Loss: 0.6930, Val Acc: 0.5600
Epoch 46/100, Loss: 0.6931, Acc: 0.4951, Val Loss: 0.6929, Val Acc: 0.4993
Mejor modelo guardado con Val Loss: 0.6929
Epoch 47/100, Loss: 0.6931, Acc: 0.4980, Val Loss: 0.6928, Val Acc: 0.5614
Mejor modelo guardado con Val Loss: 0.6928
Epoch 48/100, Loss: 0.6931, Acc: 0.4939, Val Loss: 0.6927, Val Acc: 0.5677
Mejor modelo guardado con Val Loss: 0.6927
Epoch 49/100, Loss: 0.6931, Acc: 0.5004, Val Loss: 0.6927, Val Acc: 0.5640
Epoch 50/100, Loss: 0.6931, Acc: 0.5088, Val Loss: 0.6925, Val Acc: 0.5640
Mejor modelo guardado con Val Loss: 0.6925
Epoch 51/100, Loss: 0.6931, Acc: 0.5039, Val Loss: 0.6923, Val Acc: 0.5695
Mejor modelo guardado con Val Loss: 0.6923
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6930, Acc: 0.5096, Val Loss: 0.6923, Val Acc: 0.5515
Mejor modelo guardado con Val Loss: 0.6923
Epoch 53/100, Loss: 0.6930, Acc: 0.5104, Val Loss: 0.6923, Val Acc: 0.5659
Epoch 54/100, Loss: 0.6930, Acc: 0.5029, Val Loss: 0.6923, Val Acc: 0.5662
Mejor modelo guardado con Val Loss: 0.6923
Epoch 55/100, Loss: 0.6930, Acc: 0.5104, Val Loss: 0.6923, Val Acc: 0.5614
Epoch 56/100, Loss: 0.6930, Acc: 0.5117, Val Loss: 0.6922, Val Acc: 0.5666
Mejor modelo guardado con Val Loss: 0.6922
Epoch 57/100, Loss: 0.6930, Acc: 0.4965, Val Loss: 0.6922, Val Acc: 0.5644
Epoch 58/100, Loss: 0.6930, Acc: 0.5108, Val Loss: 0.6921, Val Acc: 0.5651
Mejor modelo guardado con Val Loss: 0.6921
Epoch 59/100, Loss: 0.6930, Acc: 0.5116, Val Loss: 0.6922, Val Acc: 0.5625
Epoch 60/100, Loss: 0.6929, Acc: 0.5128, Val Loss: 0.6920, Val Acc: 0.5659
Mejor modelo guardado con Val Loss: 0.6920
Epoch 61/100, Loss: 0.6929, Acc: 0.5108, Val Loss: 0.6921, Val Acc: 0.5618
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6929, Acc: 0.5148, Val Loss: 0.6920, Val Acc: 0.5706
Mejor modelo guardado con Val Loss: 0.6920
Epoch 63/100, Loss: 0.6929, Acc: 0.5145, Val Loss: 0.6920, Val Acc: 0.5721
Mejor modelo guardado con Val Loss: 0.6920
Epoch 64/100, Loss: 0.6929, Acc: 0.5149, Val Loss: 0.6919, Val Acc: 0.5725
Mejor modelo guardado con Val Loss: 0.6919
Epoch 65/100, Loss: 0.6929, Acc: 0.5133, Val Loss: 0.6919, Val Acc: 0.5740
Mejor modelo guardado con Val Loss: 0.6919
Epoch 66/100, Loss: 0.6929, Acc: 0.5131, Val Loss: 0.6919, Val Acc: 0.5751
Mejor modelo guardado con Val Loss: 0.6919
Epoch 67/100, Loss: 0.6929, Acc: 0.5083, Val Loss: 0.6918, Val Acc: 0.5758
Mejor modelo guardado con Val Loss: 0.6918
Epoch 68/100, Loss: 0.6929, Acc: 0.5089, Val Loss: 0.6918, Val Acc: 0.5754
Mejor modelo guardado con Val Loss: 0.6918
Epoch 69/100, Loss: 0.6929, Acc: 0.5131, Val Loss: 0.6918, Val Acc: 0.5762
Mejor modelo guardado con Val Loss: 0.6918
Epoch 70/100, Loss: 0.6929, Acc: 0.5136, Val Loss: 0.6917, Val Acc: 0.5780
Mejor modelo guardado con Val Loss: 0.6917
Epoch 71/100, Loss: 0.6929, Acc: 0.5154, Val Loss: 0.6917, Val Acc: 0.5784
Mejor modelo guardado con Val Loss: 0.6917
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6929, Acc: 0.5140, Val Loss: 0.6916, Val Acc: 0.5809
Mejor modelo guardado con Val Loss: 0.6916
Epoch 73/100, Loss: 0.6929, Acc: 0.5150, Val Loss: 0.6916, Val Acc: 0.5835
Mejor modelo guardado con Val Loss: 0.6916
Epoch 74/100, Loss: 0.6929, Acc: 0.5142, Val Loss: 0.6916, Val Acc: 0.5839
Mejor modelo guardado con Val Loss: 0.6916
Epoch 75/100, Loss: 0.6929, Acc: 0.5136, Val Loss: 0.6916, Val Acc: 0.5791
Epoch 76/100, Loss: 0.6928, Acc: 0.5158, Val Loss: 0.6916, Val Acc: 0.5831
Epoch 77/100, Loss: 0.6928, Acc: 0.5134, Val Loss: 0.6915, Val Acc: 0.5839
Mejor modelo guardado con Val Loss: 0.6915
Epoch 78/100, Loss: 0.6928, Acc: 0.5162, Val Loss: 0.6915, Val Acc: 0.5824
Epoch 79/100, Loss: 0.6928, Acc: 0.5149, Val Loss: 0.6915, Val Acc: 0.5824
Mejor modelo guardado con Val Loss: 0.6915
Epoch 80/100, Loss: 0.6928, Acc: 0.5161, Val Loss: 0.6915, Val Acc: 0.5835
Mejor modelo guardado con Val Loss: 0.6915
Epoch 81/100, Loss: 0.6928, Acc: 0.5122, Val Loss: 0.6914, Val Acc: 0.5854
Mejor modelo guardado con Val Loss: 0.6914
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6928, Acc: 0.5140, Val Loss: 0.6915, Val Acc: 0.5820
Epoch 83/100, Loss: 0.6928, Acc: 0.5148, Val Loss: 0.6914, Val Acc: 0.5824
Epoch 84/100, Loss: 0.6928, Acc: 0.5158, Val Loss: 0.6914, Val Acc: 0.5831
Epoch 85/100, Loss: 0.6928, Acc: 0.5148, Val Loss: 0.6914, Val Acc: 0.5831
Mejor modelo guardado con Val Loss: 0.6914
Epoch 86/100, Loss: 0.6928, Acc: 0.5128, Val Loss: 0.6914, Val Acc: 0.5839
Mejor modelo guardado con Val Loss: 0.6914
Epoch 87/100, Loss: 0.6928, Acc: 0.5172, Val Loss: 0.6913, Val Acc: 0.5857
Mejor modelo guardado con Val Loss: 0.6913
Epoch 88/100, Loss: 0.6928, Acc: 0.5161, Val Loss: 0.6912, Val Acc: 0.5909
Mejor modelo guardado con Val Loss: 0.6912
Epoch 89/100, Loss: 0.6928, Acc: 0.5158, Val Loss: 0.6912, Val Acc: 0.5879
Epoch 90/100, Loss: 0.6928, Acc: 0.5177, Val Loss: 0.6911, Val Acc: 0.5923
Mejor modelo guardado con Val Loss: 0.6911
Epoch 91/100, Loss: 0.6928, Acc: 0.5161, Val Loss: 0.6911, Val Acc: 0.5920
Mejor modelo guardado con Val Loss: 0.6911
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6928, Acc: 0.5165, Val Loss: 0.6911, Val Acc: 0.5905
Mejor modelo guardado con Val Loss: 0.6911
Epoch 93/100, Loss: 0.6928, Acc: 0.5165, Val Loss: 0.6910, Val Acc: 0.5938
Mejor modelo guardado con Val Loss: 0.6910
Epoch 94/100, Loss: 0.6928, Acc: 0.5178, Val Loss: 0.6909, Val Acc: 0.5979
Mejor modelo guardado con Val Loss: 0.6909
Epoch 95/100, Loss: 0.6928, Acc: 0.5171, Val Loss: 0.6908, Val Acc: 0.5968
Mejor modelo guardado con Val Loss: 0.6908
Epoch 96/100, Loss: 0.6928, Acc: 0.5188, Val Loss: 0.6907, Val Acc: 0.5953
Mejor modelo guardado con Val Loss: 0.6907
Epoch 97/100, Loss: 0.6928, Acc: 0.5173, Val Loss: 0.6907, Val Acc: 0.5964
Mejor modelo guardado con Val Loss: 0.6907
Epoch 98/100, Loss: 0.6928, Acc: 0.5169, Val Loss: 0.6906, Val Acc: 0.5946
Mejor modelo guardado con Val Loss: 0.6906
Epoch 99/100, Loss: 0.6928, Acc: 0.5151, Val Loss: 0.6906, Val Acc: 0.5942
Mejor modelo guardado con Val Loss: 0.6906
Epoch 100/100, Loss: 0.6928, Acc: 0.5183, Val Loss: 0.6904, Val Acc: 0.5942
Mejor modelo guardado con Val Loss: 0.6904

##############################
Resultados para principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3 
 {'training': [0.6927520800631896, 0.5182938040080898, 0.5134437805540467, 0.695292386906951, 0.5906889548508045], 'validate': [0.6904337004173634, 0.594186902133922, 0.5915290739411343, 0.6067746686303387, 0.599054889131225], 'test': [0.6900215954692276, 0.6230135373749264, 0.6279926335174953, 0.6024734982332155, 0.6149684400360685]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  013  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  013  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6842, Acc: 0.5664, Val Loss: 0.6706, Val Acc: 0.6008
Mejor modelo guardado con Val Loss: 0.6706
Epoch 2/100, Loss: 0.6773, Acc: 0.6078, Val Loss: 0.6436, Val Acc: 0.7112
Mejor modelo guardado con Val Loss: 0.6436
Epoch 3/100, Loss: 0.6666, Acc: 0.6219, Val Loss: 0.6263, Val Acc: 0.7193
Mejor modelo guardado con Val Loss: 0.6263
Epoch 4/100, Loss: 0.6577, Acc: 0.6313, Val Loss: 0.6038, Val Acc: 0.7307
Mejor modelo guardado con Val Loss: 0.6038
Epoch 5/100, Loss: 0.6505, Acc: 0.6327, Val Loss: 0.6114, Val Acc: 0.6659
Epoch 6/100, Loss: 0.6434, Acc: 0.6401, Val Loss: 0.5728, Val Acc: 0.7550
Mejor modelo guardado con Val Loss: 0.5728
Epoch 7/100, Loss: 0.6428, Acc: 0.6354, Val Loss: 0.5635, Val Acc: 0.7575
Mejor modelo guardado con Val Loss: 0.5635
Epoch 8/100, Loss: 0.6387, Acc: 0.6426, Val Loss: 0.6007, Val Acc: 0.6766
Epoch 9/100, Loss: 0.6400, Acc: 0.6360, Val Loss: 0.5519, Val Acc: 0.7550
Mejor modelo guardado con Val Loss: 0.5519
Epoch 10/100, Loss: 0.6416, Acc: 0.6336, Val Loss: 0.5616, Val Acc: 0.7325
Epoch 11/100, Loss: 0.6340, Acc: 0.6409, Val Loss: 0.5449, Val Acc: 0.7509
Mejor modelo guardado con Val Loss: 0.5449
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6295, Acc: 0.6426, Val Loss: 0.5330, Val Acc: 0.7734
Mejor modelo guardado con Val Loss: 0.5330
Epoch 13/100, Loss: 0.6276, Acc: 0.6475, Val Loss: 0.5628, Val Acc: 0.7274
Epoch 14/100, Loss: 0.6288, Acc: 0.6444, Val Loss: 0.5693, Val Acc: 0.7296
Epoch 15/100, Loss: 0.6259, Acc: 0.6494, Val Loss: 0.5204, Val Acc: 0.7855
Mejor modelo guardado con Val Loss: 0.5204
Epoch 16/100, Loss: 0.6278, Acc: 0.6495, Val Loss: 0.5596, Val Acc: 0.7355
Epoch 17/100, Loss: 0.6251, Acc: 0.6510, Val Loss: 0.5591, Val Acc: 0.7274
Epoch 18/100, Loss: 0.6249, Acc: 0.6464, Val Loss: 0.5591, Val Acc: 0.7369
Epoch 19/100, Loss: 0.6235, Acc: 0.6520, Val Loss: 0.5376, Val Acc: 0.7391
Epoch 20/100, Loss: 0.6242, Acc: 0.6541, Val Loss: 0.5535, Val Acc: 0.7340
Epoch 21/100, Loss: 0.6236, Acc: 0.6529, Val Loss: 0.5652, Val Acc: 0.7266
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6210, Acc: 0.6520, Val Loss: 0.5410, Val Acc: 0.7498
Epoch 23/100, Loss: 0.6204, Acc: 0.6549, Val Loss: 0.5200, Val Acc: 0.7862
Mejor modelo guardado con Val Loss: 0.5200
Epoch 24/100, Loss: 0.6201, Acc: 0.6544, Val Loss: 0.5425, Val Acc: 0.7395
Epoch 25/100, Loss: 0.6191, Acc: 0.6558, Val Loss: 0.5314, Val Acc: 0.7461
Epoch 26/100, Loss: 0.6196, Acc: 0.6552, Val Loss: 0.5193, Val Acc: 0.7781
Mejor modelo guardado con Val Loss: 0.5193
Epoch 27/100, Loss: 0.6188, Acc: 0.6596, Val Loss: 0.5196, Val Acc: 0.7785
Epoch 28/100, Loss: 0.6185, Acc: 0.6555, Val Loss: 0.5504, Val Acc: 0.7399
Epoch 29/100, Loss: 0.6186, Acc: 0.6586, Val Loss: 0.5556, Val Acc: 0.7436
Epoch 30/100, Loss: 0.6179, Acc: 0.6581, Val Loss: 0.5547, Val Acc: 0.7417
Epoch 31/100, Loss: 0.6184, Acc: 0.6636, Val Loss: 0.5230, Val Acc: 0.7708
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6163, Acc: 0.6648, Val Loss: 0.5241, Val Acc: 0.7778
Epoch 33/100, Loss: 0.6164, Acc: 0.6623, Val Loss: 0.5295, Val Acc: 0.7620
Epoch 34/100, Loss: 0.6158, Acc: 0.6634, Val Loss: 0.5288, Val Acc: 0.7693
Epoch 35/100, Loss: 0.6165, Acc: 0.6594, Val Loss: 0.5396, Val Acc: 0.7550
Epoch 36/100, Loss: 0.6149, Acc: 0.6617, Val Loss: 0.5224, Val Acc: 0.7693
Epoch 37/100, Loss: 0.6146, Acc: 0.6637, Val Loss: 0.5311, Val Acc: 0.7623
Epoch 38/100, Loss: 0.6148, Acc: 0.6636, Val Loss: 0.5234, Val Acc: 0.7774
Epoch 39/100, Loss: 0.6139, Acc: 0.6653, Val Loss: 0.5287, Val Acc: 0.7667
Epoch 40/100, Loss: 0.6135, Acc: 0.6669, Val Loss: 0.5238, Val Acc: 0.7697
Epoch 41/100, Loss: 0.6135, Acc: 0.6639, Val Loss: 0.5311, Val Acc: 0.7649
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6128, Acc: 0.6652, Val Loss: 0.5347, Val Acc: 0.7631
Epoch 43/100, Loss: 0.6126, Acc: 0.6655, Val Loss: 0.5292, Val Acc: 0.7682
Epoch 44/100, Loss: 0.6124, Acc: 0.6660, Val Loss: 0.5285, Val Acc: 0.7645
Epoch 45/100, Loss: 0.6122, Acc: 0.6681, Val Loss: 0.5264, Val Acc: 0.7726
Epoch 46/100, Loss: 0.6120, Acc: 0.6676, Val Loss: 0.5359, Val Acc: 0.7638
Epoch 47/100, Loss: 0.6125, Acc: 0.6647, Val Loss: 0.5297, Val Acc: 0.7601
Epoch 48/100, Loss: 0.6121, Acc: 0.6671, Val Loss: 0.5199, Val Acc: 0.7785
Epoch 49/100, Loss: 0.6117, Acc: 0.6649, Val Loss: 0.5280, Val Acc: 0.7671
Epoch 50/100, Loss: 0.6116, Acc: 0.6688, Val Loss: 0.5328, Val Acc: 0.7605
Epoch 51/100, Loss: 0.6115, Acc: 0.6674, Val Loss: 0.5272, Val Acc: 0.7686
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6112, Acc: 0.6680, Val Loss: 0.5270, Val Acc: 0.7664
Epoch 53/100, Loss: 0.6114, Acc: 0.6678, Val Loss: 0.5337, Val Acc: 0.7638
Epoch 54/100, Loss: 0.6109, Acc: 0.6693, Val Loss: 0.5329, Val Acc: 0.7671
Epoch 55/100, Loss: 0.6109, Acc: 0.6680, Val Loss: 0.5310, Val Acc: 0.7682
Epoch 56/100, Loss: 0.6109, Acc: 0.6684, Val Loss: 0.5281, Val Acc: 0.7667
Epoch 57/100, Loss: 0.6108, Acc: 0.6688, Val Loss: 0.5312, Val Acc: 0.7682
Epoch 58/100, Loss: 0.6106, Acc: 0.6684, Val Loss: 0.5217, Val Acc: 0.7723
Epoch 59/100, Loss: 0.6106, Acc: 0.6675, Val Loss: 0.5257, Val Acc: 0.7745
Epoch 60/100, Loss: 0.6107, Acc: 0.6692, Val Loss: 0.5286, Val Acc: 0.7708
Epoch 61/100, Loss: 0.6104, Acc: 0.6690, Val Loss: 0.5284, Val Acc: 0.7704
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6103, Acc: 0.6687, Val Loss: 0.5283, Val Acc: 0.7701
Epoch 63/100, Loss: 0.6103, Acc: 0.6694, Val Loss: 0.5282, Val Acc: 0.7693
Epoch 64/100, Loss: 0.6102, Acc: 0.6694, Val Loss: 0.5300, Val Acc: 0.7693
Epoch 65/100, Loss: 0.6102, Acc: 0.6692, Val Loss: 0.5293, Val Acc: 0.7682
Epoch 66/100, Loss: 0.6101, Acc: 0.6696, Val Loss: 0.5310, Val Acc: 0.7689
Epoch 67/100, Loss: 0.6101, Acc: 0.6686, Val Loss: 0.5275, Val Acc: 0.7697
Epoch 68/100, Loss: 0.6101, Acc: 0.6698, Val Loss: 0.5331, Val Acc: 0.7645
Epoch 69/100, Loss: 0.6100, Acc: 0.6682, Val Loss: 0.5216, Val Acc: 0.7723
Epoch 70/100, Loss: 0.6101, Acc: 0.6691, Val Loss: 0.5289, Val Acc: 0.7686
Epoch 71/100, Loss: 0.6100, Acc: 0.6710, Val Loss: 0.5289, Val Acc: 0.7697
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6099, Acc: 0.6694, Val Loss: 0.5275, Val Acc: 0.7686
Epoch 73/100, Loss: 0.6100, Acc: 0.6696, Val Loss: 0.5285, Val Acc: 0.7693
Epoch 74/100, Loss: 0.6098, Acc: 0.6711, Val Loss: 0.5302, Val Acc: 0.7686
Epoch 75/100, Loss: 0.6098, Acc: 0.6704, Val Loss: 0.5257, Val Acc: 0.7730
Epoch 76/100, Loss: 0.6099, Acc: 0.6697, Val Loss: 0.5285, Val Acc: 0.7708
Epoch 77/100, Loss: 0.6098, Acc: 0.6706, Val Loss: 0.5294, Val Acc: 0.7693
Epoch 78/100, Loss: 0.6098, Acc: 0.6702, Val Loss: 0.5322, Val Acc: 0.7645
Epoch 79/100, Loss: 0.6098, Acc: 0.6702, Val Loss: 0.5308, Val Acc: 0.7689
Epoch 80/100, Loss: 0.6099, Acc: 0.6698, Val Loss: 0.5312, Val Acc: 0.7667
Epoch 81/100, Loss: 0.6097, Acc: 0.6706, Val Loss: 0.5326, Val Acc: 0.7634
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6097, Acc: 0.6699, Val Loss: 0.5328, Val Acc: 0.7634
Epoch 83/100, Loss: 0.6097, Acc: 0.6697, Val Loss: 0.5284, Val Acc: 0.7697
Epoch 84/100, Loss: 0.6098, Acc: 0.6700, Val Loss: 0.5276, Val Acc: 0.7693
Epoch 85/100, Loss: 0.6096, Acc: 0.6703, Val Loss: 0.5296, Val Acc: 0.7682
Epoch 86/100, Loss: 0.6096, Acc: 0.6703, Val Loss: 0.5330, Val Acc: 0.7638
Epoch 87/100, Loss: 0.6096, Acc: 0.6706, Val Loss: 0.5350, Val Acc: 0.7620
Epoch 88/100, Loss: 0.6096, Acc: 0.6709, Val Loss: 0.5306, Val Acc: 0.7664
Epoch 89/100, Loss: 0.6095, Acc: 0.6703, Val Loss: 0.5309, Val Acc: 0.7671
Epoch 90/100, Loss: 0.6094, Acc: 0.6703, Val Loss: 0.5260, Val Acc: 0.7693
Epoch 91/100, Loss: 0.6094, Acc: 0.6693, Val Loss: 0.5276, Val Acc: 0.7671
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6093, Acc: 0.6699, Val Loss: 0.5305, Val Acc: 0.7645
Epoch 93/100, Loss: 0.6092, Acc: 0.6695, Val Loss: 0.5284, Val Acc: 0.7678
Epoch 94/100, Loss: 0.6087, Acc: 0.6702, Val Loss: 0.5265, Val Acc: 0.7689
Epoch 95/100, Loss: 0.6081, Acc: 0.6693, Val Loss: 0.5290, Val Acc: 0.7649
Epoch 96/100, Loss: 0.6080, Acc: 0.6701, Val Loss: 0.5266, Val Acc: 0.7653
Epoch 97/100, Loss: 0.6078, Acc: 0.6703, Val Loss: 0.5263, Val Acc: 0.7653
Epoch 98/100, Loss: 0.6078, Acc: 0.6708, Val Loss: 0.5255, Val Acc: 0.7656
Epoch 99/100, Loss: 0.6077, Acc: 0.6710, Val Loss: 0.5267, Val Acc: 0.7664
Epoch 100/100, Loss: 0.6077, Acc: 0.6703, Val Loss: 0.5263, Val Acc: 0.7667

##############################
Resultados para principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3 
 {'training': [0.6076761069247819, 0.670343813200956, 0.6962696057651547, 0.6040823832291283, 0.6469082315872391], 'validate': [0.526323814724767, 0.7667402501839587, 0.7134433962264151, 0.8910162002945509, 0.7924034053700065], 'test': [0.7494432159044124, 0.49793996468510887, 0.4973404255319149, 0.44051825677267376, 0.46720799500312304]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  063  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  063  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6837, Acc: 0.5637, Val Loss: 0.7014, Val Acc: 0.4496
Mejor modelo guardado con Val Loss: 0.7014
Epoch 2/100, Loss: 0.6775, Acc: 0.5905, Val Loss: 0.7137, Val Acc: 0.4253
Epoch 3/100, Loss: 0.6677, Acc: 0.6112, Val Loss: 0.7195, Val Acc: 0.4180
Epoch 4/100, Loss: 0.6611, Acc: 0.6167, Val Loss: 0.7537, Val Acc: 0.3859
Epoch 5/100, Loss: 0.6565, Acc: 0.6160, Val Loss: 0.7311, Val Acc: 0.4555
Epoch 6/100, Loss: 0.6500, Acc: 0.6208, Val Loss: 0.7487, Val Acc: 0.4308
Epoch 7/100, Loss: 0.6470, Acc: 0.6256, Val Loss: 0.7863, Val Acc: 0.3687
Epoch 8/100, Loss: 0.6420, Acc: 0.6320, Val Loss: 0.7787, Val Acc: 0.3819
Epoch 9/100, Loss: 0.6381, Acc: 0.6338, Val Loss: 0.7711, Val Acc: 0.3742
Epoch 10/100, Loss: 0.6443, Acc: 0.6252, Val Loss: 0.7889, Val Acc: 0.3591
Epoch 11/100, Loss: 0.6385, Acc: 0.6323, Val Loss: 0.7567, Val Acc: 0.4198
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6336, Acc: 0.6398, Val Loss: 0.7709, Val Acc: 0.4290
Epoch 13/100, Loss: 0.6326, Acc: 0.6425, Val Loss: 0.7807, Val Acc: 0.3878
Epoch 14/100, Loss: 0.6299, Acc: 0.6454, Val Loss: 0.7885, Val Acc: 0.3929
Epoch 15/100, Loss: 0.6295, Acc: 0.6434, Val Loss: 0.7643, Val Acc: 0.4463
Epoch 16/100, Loss: 0.6283, Acc: 0.6461, Val Loss: 0.7875, Val Acc: 0.4113
Epoch 17/100, Loss: 0.6304, Acc: 0.6418, Val Loss: 0.7968, Val Acc: 0.4032
Epoch 18/100, Loss: 0.6272, Acc: 0.6474, Val Loss: 0.7712, Val Acc: 0.4536
Epoch 19/100, Loss: 0.6266, Acc: 0.6456, Val Loss: 0.7789, Val Acc: 0.4323
Epoch 20/100, Loss: 0.6251, Acc: 0.6523, Val Loss: 0.7643, Val Acc: 0.4452
Epoch 21/100, Loss: 0.6258, Acc: 0.6453, Val Loss: 0.8093, Val Acc: 0.3742
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6210, Acc: 0.6557, Val Loss: 0.7748, Val Acc: 0.4408
Epoch 23/100, Loss: 0.6203, Acc: 0.6583, Val Loss: 0.7781, Val Acc: 0.4386
Epoch 24/100, Loss: 0.6201, Acc: 0.6537, Val Loss: 0.7657, Val Acc: 0.4536
Epoch 25/100, Loss: 0.6213, Acc: 0.6542, Val Loss: 0.7932, Val Acc: 0.4102
Epoch 26/100, Loss: 0.6205, Acc: 0.6563, Val Loss: 0.7943, Val Acc: 0.4058
Epoch 27/100, Loss: 0.6185, Acc: 0.6573, Val Loss: 0.7999, Val Acc: 0.4051
Epoch 28/100, Loss: 0.6179, Acc: 0.6572, Val Loss: 0.7926, Val Acc: 0.4099
Epoch 29/100, Loss: 0.6172, Acc: 0.6578, Val Loss: 0.8211, Val Acc: 0.3694
Epoch 30/100, Loss: 0.6184, Acc: 0.6554, Val Loss: 0.7689, Val Acc: 0.4386
Epoch 31/100, Loss: 0.6166, Acc: 0.6595, Val Loss: 0.7822, Val Acc: 0.4312
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6159, Acc: 0.6607, Val Loss: 0.7983, Val Acc: 0.4054
Epoch 33/100, Loss: 0.6152, Acc: 0.6603, Val Loss: 0.7920, Val Acc: 0.4128
Epoch 34/100, Loss: 0.6149, Acc: 0.6586, Val Loss: 0.7901, Val Acc: 0.4183
Epoch 35/100, Loss: 0.6145, Acc: 0.6612, Val Loss: 0.7893, Val Acc: 0.4150
Epoch 36/100, Loss: 0.6139, Acc: 0.6622, Val Loss: 0.7813, Val Acc: 0.4264
Epoch 37/100, Loss: 0.6146, Acc: 0.6625, Val Loss: 0.7999, Val Acc: 0.4018
Epoch 38/100, Loss: 0.6141, Acc: 0.6601, Val Loss: 0.7943, Val Acc: 0.4077
Epoch 39/100, Loss: 0.6133, Acc: 0.6627, Val Loss: 0.7816, Val Acc: 0.4191
Epoch 40/100, Loss: 0.6133, Acc: 0.6637, Val Loss: 0.8089, Val Acc: 0.3962
Epoch 41/100, Loss: 0.6138, Acc: 0.6632, Val Loss: 0.8080, Val Acc: 0.4021
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6126, Acc: 0.6622, Val Loss: 0.7942, Val Acc: 0.4157
Epoch 43/100, Loss: 0.6118, Acc: 0.6640, Val Loss: 0.7928, Val Acc: 0.4154
Epoch 44/100, Loss: 0.6118, Acc: 0.6641, Val Loss: 0.8003, Val Acc: 0.4095
Epoch 45/100, Loss: 0.6116, Acc: 0.6639, Val Loss: 0.7978, Val Acc: 0.4124
Epoch 46/100, Loss: 0.6114, Acc: 0.6666, Val Loss: 0.8073, Val Acc: 0.4025
Epoch 47/100, Loss: 0.6115, Acc: 0.6626, Val Loss: 0.8003, Val Acc: 0.4099
Epoch 48/100, Loss: 0.6113, Acc: 0.6631, Val Loss: 0.7986, Val Acc: 0.4080
Epoch 49/100, Loss: 0.6113, Acc: 0.6647, Val Loss: 0.8015, Val Acc: 0.4073
Epoch 50/100, Loss: 0.6110, Acc: 0.6647, Val Loss: 0.8055, Val Acc: 0.4025
Epoch 51/100, Loss: 0.6108, Acc: 0.6636, Val Loss: 0.7920, Val Acc: 0.4161
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6104, Acc: 0.6657, Val Loss: 0.7983, Val Acc: 0.4128
Epoch 53/100, Loss: 0.6097, Acc: 0.6669, Val Loss: 0.7869, Val Acc: 0.4257
Epoch 54/100, Loss: 0.6104, Acc: 0.6662, Val Loss: 0.7990, Val Acc: 0.4146
Epoch 55/100, Loss: 0.6101, Acc: 0.6668, Val Loss: 0.8007, Val Acc: 0.4099
Epoch 56/100, Loss: 0.6100, Acc: 0.6662, Val Loss: 0.7958, Val Acc: 0.4165
Epoch 57/100, Loss: 0.6097, Acc: 0.6678, Val Loss: 0.8026, Val Acc: 0.4102
Epoch 58/100, Loss: 0.6099, Acc: 0.6665, Val Loss: 0.8037, Val Acc: 0.4069
Epoch 59/100, Loss: 0.6099, Acc: 0.6662, Val Loss: 0.7985, Val Acc: 0.4121
Epoch 60/100, Loss: 0.6097, Acc: 0.6669, Val Loss: 0.7954, Val Acc: 0.4169
Epoch 61/100, Loss: 0.6096, Acc: 0.6669, Val Loss: 0.8028, Val Acc: 0.4080
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6093, Acc: 0.6652, Val Loss: 0.7982, Val Acc: 0.4150
Epoch 63/100, Loss: 0.6093, Acc: 0.6660, Val Loss: 0.8011, Val Acc: 0.4117
Epoch 64/100, Loss: 0.6093, Acc: 0.6661, Val Loss: 0.8054, Val Acc: 0.4073
Epoch 65/100, Loss: 0.6092, Acc: 0.6668, Val Loss: 0.7971, Val Acc: 0.4172
Epoch 66/100, Loss: 0.6091, Acc: 0.6664, Val Loss: 0.8021, Val Acc: 0.4106
Epoch 67/100, Loss: 0.6092, Acc: 0.6672, Val Loss: 0.7979, Val Acc: 0.4169
Epoch 68/100, Loss: 0.6090, Acc: 0.6678, Val Loss: 0.7947, Val Acc: 0.4154
Epoch 69/100, Loss: 0.6091, Acc: 0.6645, Val Loss: 0.7971, Val Acc: 0.4161
Epoch 70/100, Loss: 0.6090, Acc: 0.6664, Val Loss: 0.8024, Val Acc: 0.4091
Epoch 71/100, Loss: 0.6089, Acc: 0.6672, Val Loss: 0.8004, Val Acc: 0.4135
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6088, Acc: 0.6675, Val Loss: 0.7996, Val Acc: 0.4143
Epoch 73/100, Loss: 0.6089, Acc: 0.6674, Val Loss: 0.8009, Val Acc: 0.4146
Epoch 74/100, Loss: 0.6088, Acc: 0.6670, Val Loss: 0.8025, Val Acc: 0.4113
Epoch 75/100, Loss: 0.6088, Acc: 0.6678, Val Loss: 0.8009, Val Acc: 0.4128
Epoch 76/100, Loss: 0.6088, Acc: 0.6678, Val Loss: 0.8008, Val Acc: 0.4132
Epoch 77/100, Loss: 0.6088, Acc: 0.6669, Val Loss: 0.8001, Val Acc: 0.4150
Epoch 78/100, Loss: 0.6088, Acc: 0.6675, Val Loss: 0.7988, Val Acc: 0.4165
Epoch 79/100, Loss: 0.6088, Acc: 0.6676, Val Loss: 0.8023, Val Acc: 0.4110
Epoch 80/100, Loss: 0.6087, Acc: 0.6667, Val Loss: 0.7961, Val Acc: 0.4161
Epoch 81/100, Loss: 0.6087, Acc: 0.6669, Val Loss: 0.8015, Val Acc: 0.4132
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6086, Acc: 0.6676, Val Loss: 0.8003, Val Acc: 0.4154
Epoch 83/100, Loss: 0.6085, Acc: 0.6680, Val Loss: 0.8018, Val Acc: 0.4124
Epoch 84/100, Loss: 0.6085, Acc: 0.6680, Val Loss: 0.8012, Val Acc: 0.4128
Epoch 85/100, Loss: 0.6085, Acc: 0.6684, Val Loss: 0.7993, Val Acc: 0.4157
Epoch 86/100, Loss: 0.6084, Acc: 0.6676, Val Loss: 0.8025, Val Acc: 0.4106
Epoch 87/100, Loss: 0.6084, Acc: 0.6680, Val Loss: 0.8021, Val Acc: 0.4113
Epoch 88/100, Loss: 0.6084, Acc: 0.6682, Val Loss: 0.7997, Val Acc: 0.4157
Epoch 89/100, Loss: 0.6084, Acc: 0.6678, Val Loss: 0.8008, Val Acc: 0.4139
Epoch 90/100, Loss: 0.6084, Acc: 0.6678, Val Loss: 0.8004, Val Acc: 0.4146
Epoch 91/100, Loss: 0.6084, Acc: 0.6674, Val Loss: 0.8011, Val Acc: 0.4139
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6083, Acc: 0.6680, Val Loss: 0.8019, Val Acc: 0.4117
Epoch 93/100, Loss: 0.6084, Acc: 0.6677, Val Loss: 0.8023, Val Acc: 0.4095
Epoch 94/100, Loss: 0.6083, Acc: 0.6681, Val Loss: 0.8017, Val Acc: 0.4128
Epoch 95/100, Loss: 0.6082, Acc: 0.6685, Val Loss: 0.8011, Val Acc: 0.4124
Epoch 96/100, Loss: 0.6082, Acc: 0.6683, Val Loss: 0.8049, Val Acc: 0.4077
Epoch 97/100, Loss: 0.6082, Acc: 0.6680, Val Loss: 0.8004, Val Acc: 0.4150
Epoch 98/100, Loss: 0.6081, Acc: 0.6680, Val Loss: 0.8001, Val Acc: 0.4146
Epoch 99/100, Loss: 0.6080, Acc: 0.6681, Val Loss: 0.8041, Val Acc: 0.4091
Epoch 100/100, Loss: 0.6079, Acc: 0.6686, Val Loss: 0.8008, Val Acc: 0.4139

##############################
Resultados para principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3 
 {'training': [0.6079331743276651, 0.6685971685971686, 0.6493887530562347, 0.7326222876057374, 0.688499092715804], 'validate': [0.8007529003675594, 0.4139072847682119, 0.4350469872857933, 0.5795287187039765, 0.4970003157562362], 'test': [0.6972184401971323, 0.474102413184226, 0.48374132261600294, 0.7797408716136631, 0.5970687711386696]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  070  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  070  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6917, Acc: 0.5301, Val Loss: 0.6925, Val Acc: 0.4993
Mejor modelo guardado con Val Loss: 0.6925
Epoch 2/100, Loss: 0.6919, Acc: 0.5201, Val Loss: 0.6950, Val Acc: 0.4820
Epoch 3/100, Loss: 0.6913, Acc: 0.5243, Val Loss: 0.6924, Val Acc: 0.5055
Mejor modelo guardado con Val Loss: 0.6924
Epoch 4/100, Loss: 0.6921, Acc: 0.5268, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 5/100, Loss: 0.6921, Acc: 0.5141, Val Loss: 0.6967, Val Acc: 0.4993
Epoch 6/100, Loss: 0.6881, Acc: 0.5471, Val Loss: 0.6915, Val Acc: 0.5361
Mejor modelo guardado con Val Loss: 0.6915
Epoch 7/100, Loss: 0.6870, Acc: 0.5532, Val Loss: 0.6938, Val Acc: 0.4948
Epoch 8/100, Loss: 0.6880, Acc: 0.5476, Val Loss: 0.6971, Val Acc: 0.4753
Epoch 9/100, Loss: 0.6858, Acc: 0.5593, Val Loss: 0.6954, Val Acc: 0.4886
Epoch 10/100, Loss: 0.6858, Acc: 0.5592, Val Loss: 0.7017, Val Acc: 0.4739
Epoch 11/100, Loss: 0.6889, Acc: 0.5330, Val Loss: 0.7019, Val Acc: 0.4831
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6939, Acc: 0.4949, Val Loss: 0.6937, Val Acc: 0.4974
Epoch 13/100, Loss: 0.6933, Acc: 0.4970, Val Loss: 0.6932, Val Acc: 0.5007
Epoch 14/100, Loss: 0.6933, Acc: 0.4957, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 15/100, Loss: 0.6931, Acc: 0.5068, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 16/100, Loss: 0.6933, Acc: 0.4983, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 17/100, Loss: 0.6932, Acc: 0.4971, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 18/100, Loss: 0.6932, Acc: 0.5040, Val Loss: 0.6942, Val Acc: 0.4996
Epoch 19/100, Loss: 0.6932, Acc: 0.5047, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 20/100, Loss: 0.6932, Acc: 0.5040, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 21/100, Loss: 0.6933, Acc: 0.4969, Val Loss: 0.6931, Val Acc: 0.5004
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6922, Acc: 0.5141, Val Loss: 0.6913, Val Acc: 0.5662
Mejor modelo guardado con Val Loss: 0.6913
Epoch 23/100, Loss: 0.6914, Acc: 0.5505, Val Loss: 0.6914, Val Acc: 0.5335
Epoch 24/100, Loss: 0.6908, Acc: 0.5510, Val Loss: 0.6901, Val Acc: 0.5754
Mejor modelo guardado con Val Loss: 0.6901
Epoch 25/100, Loss: 0.6903, Acc: 0.5577, Val Loss: 0.6901, Val Acc: 0.5596
Epoch 26/100, Loss: 0.6903, Acc: 0.5542, Val Loss: 0.6905, Val Acc: 0.5486
Epoch 27/100, Loss: 0.6897, Acc: 0.5624, Val Loss: 0.6890, Val Acc: 0.5762
Mejor modelo guardado con Val Loss: 0.6890
Epoch 28/100, Loss: 0.6892, Acc: 0.5643, Val Loss: 0.6896, Val Acc: 0.5570
Epoch 29/100, Loss: 0.6888, Acc: 0.5626, Val Loss: 0.6882, Val Acc: 0.5758
Mejor modelo guardado con Val Loss: 0.6882
Epoch 30/100, Loss: 0.6881, Acc: 0.5708, Val Loss: 0.6882, Val Acc: 0.5776
Mejor modelo guardado con Val Loss: 0.6882
Epoch 31/100, Loss: 0.6879, Acc: 0.5689, Val Loss: 0.6880, Val Acc: 0.5762
Mejor modelo guardado con Val Loss: 0.6880
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6872, Acc: 0.5754, Val Loss: 0.6875, Val Acc: 0.5758
Mejor modelo guardado con Val Loss: 0.6875
Epoch 33/100, Loss: 0.6869, Acc: 0.5746, Val Loss: 0.6875, Val Acc: 0.5710
Epoch 34/100, Loss: 0.6869, Acc: 0.5700, Val Loss: 0.6873, Val Acc: 0.5747
Mejor modelo guardado con Val Loss: 0.6873
Epoch 35/100, Loss: 0.6865, Acc: 0.5730, Val Loss: 0.6870, Val Acc: 0.5743
Mejor modelo guardado con Val Loss: 0.6870
Epoch 36/100, Loss: 0.6861, Acc: 0.5761, Val Loss: 0.6871, Val Acc: 0.5695
Epoch 37/100, Loss: 0.6861, Acc: 0.5737, Val Loss: 0.6868, Val Acc: 0.5780
Mejor modelo guardado con Val Loss: 0.6868
Epoch 38/100, Loss: 0.6856, Acc: 0.5776, Val Loss: 0.6867, Val Acc: 0.5692
Mejor modelo guardado con Val Loss: 0.6867
Epoch 39/100, Loss: 0.6854, Acc: 0.5751, Val Loss: 0.6866, Val Acc: 0.5762
Mejor modelo guardado con Val Loss: 0.6866
Epoch 40/100, Loss: 0.6852, Acc: 0.5756, Val Loss: 0.6862, Val Acc: 0.5736
Mejor modelo guardado con Val Loss: 0.6862
Epoch 41/100, Loss: 0.6850, Acc: 0.5804, Val Loss: 0.6860, Val Acc: 0.5747
Mejor modelo guardado con Val Loss: 0.6860
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6847, Acc: 0.5796, Val Loss: 0.6860, Val Acc: 0.5736
Mejor modelo guardado con Val Loss: 0.6860
Epoch 43/100, Loss: 0.6846, Acc: 0.5777, Val Loss: 0.6871, Val Acc: 0.5581
Epoch 44/100, Loss: 0.6846, Acc: 0.5768, Val Loss: 0.6861, Val Acc: 0.5710
Epoch 45/100, Loss: 0.6842, Acc: 0.5787, Val Loss: 0.6864, Val Acc: 0.5629
Epoch 46/100, Loss: 0.6843, Acc: 0.5762, Val Loss: 0.6858, Val Acc: 0.5769
Mejor modelo guardado con Val Loss: 0.6858
Epoch 47/100, Loss: 0.6841, Acc: 0.5815, Val Loss: 0.6856, Val Acc: 0.5710
Mejor modelo guardado con Val Loss: 0.6856
Epoch 48/100, Loss: 0.6839, Acc: 0.5784, Val Loss: 0.6858, Val Acc: 0.5754
Epoch 49/100, Loss: 0.6839, Acc: 0.5790, Val Loss: 0.6855, Val Acc: 0.5732
Mejor modelo guardado con Val Loss: 0.6855
Epoch 50/100, Loss: 0.6837, Acc: 0.5782, Val Loss: 0.6858, Val Acc: 0.5684
Epoch 51/100, Loss: 0.6836, Acc: 0.5778, Val Loss: 0.6855, Val Acc: 0.5695
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6836, Acc: 0.5800, Val Loss: 0.6853, Val Acc: 0.5773
Mejor modelo guardado con Val Loss: 0.6853
Epoch 53/100, Loss: 0.6834, Acc: 0.5809, Val Loss: 0.6853, Val Acc: 0.5780
Epoch 54/100, Loss: 0.6833, Acc: 0.5812, Val Loss: 0.6853, Val Acc: 0.5780
Mejor modelo guardado con Val Loss: 0.6853
Epoch 55/100, Loss: 0.6833, Acc: 0.5818, Val Loss: 0.6852, Val Acc: 0.5732
Mejor modelo guardado con Val Loss: 0.6852
Epoch 56/100, Loss: 0.6832, Acc: 0.5817, Val Loss: 0.6852, Val Acc: 0.5769
Mejor modelo guardado con Val Loss: 0.6852
Epoch 57/100, Loss: 0.6832, Acc: 0.5804, Val Loss: 0.6853, Val Acc: 0.5740
Epoch 58/100, Loss: 0.6831, Acc: 0.5820, Val Loss: 0.6850, Val Acc: 0.5765
Mejor modelo guardado con Val Loss: 0.6850
Epoch 59/100, Loss: 0.6830, Acc: 0.5826, Val Loss: 0.6850, Val Acc: 0.5736
Mejor modelo guardado con Val Loss: 0.6850
Epoch 60/100, Loss: 0.6830, Acc: 0.5825, Val Loss: 0.6849, Val Acc: 0.5758
Mejor modelo guardado con Val Loss: 0.6849
Epoch 61/100, Loss: 0.6829, Acc: 0.5826, Val Loss: 0.6849, Val Acc: 0.5758
Mejor modelo guardado con Val Loss: 0.6849
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6828, Acc: 0.5833, Val Loss: 0.6849, Val Acc: 0.5773
Epoch 63/100, Loss: 0.6828, Acc: 0.5818, Val Loss: 0.6850, Val Acc: 0.5773
Epoch 64/100, Loss: 0.6827, Acc: 0.5837, Val Loss: 0.6849, Val Acc: 0.5765
Epoch 65/100, Loss: 0.6827, Acc: 0.5844, Val Loss: 0.6849, Val Acc: 0.5762
Mejor modelo guardado con Val Loss: 0.6849
Epoch 66/100, Loss: 0.6827, Acc: 0.5829, Val Loss: 0.6849, Val Acc: 0.5743
Epoch 67/100, Loss: 0.6827, Acc: 0.5831, Val Loss: 0.6848, Val Acc: 0.5780
Mejor modelo guardado con Val Loss: 0.6848
Epoch 68/100, Loss: 0.6826, Acc: 0.5822, Val Loss: 0.6848, Val Acc: 0.5787
Mejor modelo guardado con Val Loss: 0.6848
Epoch 69/100, Loss: 0.6826, Acc: 0.5830, Val Loss: 0.6848, Val Acc: 0.5762
Mejor modelo guardado con Val Loss: 0.6848
Epoch 70/100, Loss: 0.6826, Acc: 0.5837, Val Loss: 0.6847, Val Acc: 0.5747
Mejor modelo guardado con Val Loss: 0.6847
Epoch 71/100, Loss: 0.6825, Acc: 0.5840, Val Loss: 0.6847, Val Acc: 0.5773
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6824, Acc: 0.5837, Val Loss: 0.6850, Val Acc: 0.5754
Epoch 73/100, Loss: 0.6823, Acc: 0.5836, Val Loss: 0.6850, Val Acc: 0.5747
Epoch 74/100, Loss: 0.6822, Acc: 0.5831, Val Loss: 0.6850, Val Acc: 0.5754
Epoch 75/100, Loss: 0.6822, Acc: 0.5829, Val Loss: 0.6849, Val Acc: 0.5758
Epoch 76/100, Loss: 0.6822, Acc: 0.5843, Val Loss: 0.6850, Val Acc: 0.5758
Epoch 77/100, Loss: 0.6822, Acc: 0.5845, Val Loss: 0.6849, Val Acc: 0.5743
Epoch 78/100, Loss: 0.6822, Acc: 0.5847, Val Loss: 0.6849, Val Acc: 0.5762
Epoch 79/100, Loss: 0.6821, Acc: 0.5826, Val Loss: 0.6849, Val Acc: 0.5743
Epoch 80/100, Loss: 0.6821, Acc: 0.5836, Val Loss: 0.6849, Val Acc: 0.5754
Epoch 81/100, Loss: 0.6821, Acc: 0.5825, Val Loss: 0.6849, Val Acc: 0.5762
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6821, Acc: 0.5837, Val Loss: 0.6849, Val Acc: 0.5740
Epoch 83/100, Loss: 0.6820, Acc: 0.5842, Val Loss: 0.6849, Val Acc: 0.5751
Epoch 84/100, Loss: 0.6820, Acc: 0.5833, Val Loss: 0.6849, Val Acc: 0.5740
Epoch 85/100, Loss: 0.6820, Acc: 0.5838, Val Loss: 0.6848, Val Acc: 0.5758
Epoch 86/100, Loss: 0.6820, Acc: 0.5839, Val Loss: 0.6848, Val Acc: 0.5751
Epoch 87/100, Loss: 0.6820, Acc: 0.5849, Val Loss: 0.6848, Val Acc: 0.5754
Epoch 88/100, Loss: 0.6819, Acc: 0.5831, Val Loss: 0.6848, Val Acc: 0.5740
Epoch 89/100, Loss: 0.6819, Acc: 0.5839, Val Loss: 0.6847, Val Acc: 0.5762
Epoch 90/100, Loss: 0.6818, Acc: 0.5837, Val Loss: 0.6846, Val Acc: 0.5754
Mejor modelo guardado con Val Loss: 0.6846
Epoch 91/100, Loss: 0.6802, Acc: 0.5852, Val Loss: 0.6827, Val Acc: 0.5758
Mejor modelo guardado con Val Loss: 0.6827
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6791, Acc: 0.5840, Val Loss: 0.6826, Val Acc: 0.5732
Mejor modelo guardado con Val Loss: 0.6826
Epoch 93/100, Loss: 0.6790, Acc: 0.5818, Val Loss: 0.6825, Val Acc: 0.5728
Mejor modelo guardado con Val Loss: 0.6825
Epoch 94/100, Loss: 0.6787, Acc: 0.5814, Val Loss: 0.6822, Val Acc: 0.5703
Mejor modelo guardado con Val Loss: 0.6822
Epoch 95/100, Loss: 0.6787, Acc: 0.5822, Val Loss: 0.6822, Val Acc: 0.5666
Epoch 96/100, Loss: 0.6786, Acc: 0.5818, Val Loss: 0.6822, Val Acc: 0.5684
Mejor modelo guardado con Val Loss: 0.6822
Epoch 97/100, Loss: 0.6785, Acc: 0.5819, Val Loss: 0.6822, Val Acc: 0.5659
Epoch 98/100, Loss: 0.6784, Acc: 0.5823, Val Loss: 0.6821, Val Acc: 0.5651
Mejor modelo guardado con Val Loss: 0.6821
Epoch 99/100, Loss: 0.6781, Acc: 0.5825, Val Loss: 0.6824, Val Acc: 0.5633
Epoch 100/100, Loss: 0.6779, Acc: 0.5820, Val Loss: 0.6826, Val Acc: 0.5622

##############################
Resultados para principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3 
 {'training': [0.6779309122916157, 0.5820003677146535, 0.6022962112514352, 0.4823464509010666, 0.535688757275605], 'validate': [0.6825980391613272, 0.5621780721118469, 0.5841683366733467, 0.42930780559646536, 0.49490662139219016], 'test': [0.7009002202086978, 0.4961742201294879, 0.4958968347010551, 0.49823321554770317, 0.4970622796709753]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  040  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  040  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6807, Acc: 0.5835, Val Loss: 0.6739, Val Acc: 0.6130
Mejor modelo guardado con Val Loss: 0.6739
Epoch 2/100, Loss: 0.6689, Acc: 0.6135, Val Loss: 0.6892, Val Acc: 0.5368
Epoch 3/100, Loss: 0.6674, Acc: 0.6091, Val Loss: 0.6781, Val Acc: 0.5817
Epoch 4/100, Loss: 0.6552, Acc: 0.6260, Val Loss: 0.6658, Val Acc: 0.5979
Mejor modelo guardado con Val Loss: 0.6658
Epoch 5/100, Loss: 0.6552, Acc: 0.6308, Val Loss: 0.6732, Val Acc: 0.5883
Epoch 6/100, Loss: 0.6507, Acc: 0.6323, Val Loss: 0.6832, Val Acc: 0.5346
Epoch 7/100, Loss: 0.6435, Acc: 0.6379, Val Loss: 0.6674, Val Acc: 0.6012
Epoch 8/100, Loss: 0.6453, Acc: 0.6353, Val Loss: 0.6646, Val Acc: 0.6049
Mejor modelo guardado con Val Loss: 0.6646
Epoch 9/100, Loss: 0.6433, Acc: 0.6377, Val Loss: 0.6703, Val Acc: 0.6060
Epoch 10/100, Loss: 0.6389, Acc: 0.6426, Val Loss: 0.6661, Val Acc: 0.5990
Epoch 11/100, Loss: 0.6418, Acc: 0.6358, Val Loss: 0.6707, Val Acc: 0.6012
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6354, Acc: 0.6466, Val Loss: 0.6733, Val Acc: 0.5968
Epoch 13/100, Loss: 0.6330, Acc: 0.6462, Val Loss: 0.6775, Val Acc: 0.5971
Epoch 14/100, Loss: 0.6410, Acc: 0.6331, Val Loss: 0.6754, Val Acc: 0.5923
Epoch 15/100, Loss: 0.6367, Acc: 0.6395, Val Loss: 0.6835, Val Acc: 0.5879
Epoch 16/100, Loss: 0.6352, Acc: 0.6485, Val Loss: 0.6686, Val Acc: 0.5960
Epoch 17/100, Loss: 0.6343, Acc: 0.6480, Val Loss: 0.6703, Val Acc: 0.5949
Epoch 18/100, Loss: 0.6327, Acc: 0.6476, Val Loss: 0.6763, Val Acc: 0.5938
Epoch 19/100, Loss: 0.6343, Acc: 0.6447, Val Loss: 0.6748, Val Acc: 0.5923
Epoch 20/100, Loss: 0.6305, Acc: 0.6508, Val Loss: 0.6665, Val Acc: 0.5942
Epoch 21/100, Loss: 0.6362, Acc: 0.6397, Val Loss: 0.6894, Val Acc: 0.5791
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6315, Acc: 0.6489, Val Loss: 0.6721, Val Acc: 0.6001
Epoch 23/100, Loss: 0.6296, Acc: 0.6494, Val Loss: 0.6701, Val Acc: 0.5986
Epoch 24/100, Loss: 0.6304, Acc: 0.6500, Val Loss: 0.6674, Val Acc: 0.6026
Epoch 25/100, Loss: 0.6287, Acc: 0.6506, Val Loss: 0.6750, Val Acc: 0.5993
Epoch 26/100, Loss: 0.6286, Acc: 0.6503, Val Loss: 0.6655, Val Acc: 0.6023
Epoch 27/100, Loss: 0.6295, Acc: 0.6483, Val Loss: 0.6724, Val Acc: 0.6015
Epoch 28/100, Loss: 0.6313, Acc: 0.6494, Val Loss: 0.6725, Val Acc: 0.6045
Epoch 29/100, Loss: 0.6282, Acc: 0.6528, Val Loss: 0.6754, Val Acc: 0.6015
Epoch 30/100, Loss: 0.6292, Acc: 0.6553, Val Loss: 0.6692, Val Acc: 0.5982
Epoch 31/100, Loss: 0.6289, Acc: 0.6514, Val Loss: 0.6775, Val Acc: 0.5946
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6276, Acc: 0.6515, Val Loss: 0.6739, Val Acc: 0.6023
Epoch 33/100, Loss: 0.6264, Acc: 0.6543, Val Loss: 0.6693, Val Acc: 0.6056
Epoch 34/100, Loss: 0.6265, Acc: 0.6560, Val Loss: 0.6703, Val Acc: 0.6052
Epoch 35/100, Loss: 0.6271, Acc: 0.6554, Val Loss: 0.6724, Val Acc: 0.6019
Epoch 36/100, Loss: 0.6264, Acc: 0.6566, Val Loss: 0.6697, Val Acc: 0.6030
Epoch 37/100, Loss: 0.6269, Acc: 0.6533, Val Loss: 0.6711, Val Acc: 0.6023
Epoch 38/100, Loss: 0.6262, Acc: 0.6555, Val Loss: 0.6784, Val Acc: 0.6001
Epoch 39/100, Loss: 0.6262, Acc: 0.6540, Val Loss: 0.6779, Val Acc: 0.5964
Epoch 40/100, Loss: 0.6267, Acc: 0.6521, Val Loss: 0.6752, Val Acc: 0.6023
Epoch 41/100, Loss: 0.6261, Acc: 0.6555, Val Loss: 0.6717, Val Acc: 0.6030
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6255, Acc: 0.6564, Val Loss: 0.6762, Val Acc: 0.6015
Epoch 43/100, Loss: 0.6255, Acc: 0.6569, Val Loss: 0.6695, Val Acc: 0.6052
Epoch 44/100, Loss: 0.6254, Acc: 0.6546, Val Loss: 0.6694, Val Acc: 0.6060
Epoch 45/100, Loss: 0.6251, Acc: 0.6564, Val Loss: 0.6733, Val Acc: 0.6041
Epoch 46/100, Loss: 0.6250, Acc: 0.6546, Val Loss: 0.6691, Val Acc: 0.6063
Epoch 47/100, Loss: 0.6250, Acc: 0.6589, Val Loss: 0.6782, Val Acc: 0.6015
Epoch 48/100, Loss: 0.6256, Acc: 0.6542, Val Loss: 0.6729, Val Acc: 0.6026
Epoch 49/100, Loss: 0.6256, Acc: 0.6550, Val Loss: 0.6711, Val Acc: 0.6023
Epoch 50/100, Loss: 0.6249, Acc: 0.6580, Val Loss: 0.6782, Val Acc: 0.5982
Epoch 51/100, Loss: 0.6244, Acc: 0.6581, Val Loss: 0.6678, Val Acc: 0.6001
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6249, Acc: 0.6555, Val Loss: 0.6729, Val Acc: 0.6001
Epoch 53/100, Loss: 0.6245, Acc: 0.6562, Val Loss: 0.6736, Val Acc: 0.6030
Epoch 54/100, Loss: 0.6244, Acc: 0.6562, Val Loss: 0.6726, Val Acc: 0.6026
Epoch 55/100, Loss: 0.6245, Acc: 0.6563, Val Loss: 0.6742, Val Acc: 0.6041
Epoch 56/100, Loss: 0.6246, Acc: 0.6572, Val Loss: 0.6711, Val Acc: 0.6030
Epoch 57/100, Loss: 0.6247, Acc: 0.6579, Val Loss: 0.6698, Val Acc: 0.6045
Epoch 58/100, Loss: 0.6246, Acc: 0.6566, Val Loss: 0.6714, Val Acc: 0.6060
Epoch 59/100, Loss: 0.6245, Acc: 0.6571, Val Loss: 0.6737, Val Acc: 0.6004
Epoch 60/100, Loss: 0.6244, Acc: 0.6566, Val Loss: 0.6711, Val Acc: 0.6052
Epoch 61/100, Loss: 0.6245, Acc: 0.6574, Val Loss: 0.6707, Val Acc: 0.6045
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6243, Acc: 0.6565, Val Loss: 0.6725, Val Acc: 0.6060
Epoch 63/100, Loss: 0.6241, Acc: 0.6572, Val Loss: 0.6719, Val Acc: 0.6060
Epoch 64/100, Loss: 0.6241, Acc: 0.6571, Val Loss: 0.6721, Val Acc: 0.6056
Epoch 65/100, Loss: 0.6241, Acc: 0.6563, Val Loss: 0.6720, Val Acc: 0.6041
Epoch 66/100, Loss: 0.6242, Acc: 0.6560, Val Loss: 0.6733, Val Acc: 0.6004
Epoch 67/100, Loss: 0.6241, Acc: 0.6577, Val Loss: 0.6724, Val Acc: 0.6041
Epoch 68/100, Loss: 0.6241, Acc: 0.6572, Val Loss: 0.6731, Val Acc: 0.6004
Epoch 69/100, Loss: 0.6242, Acc: 0.6580, Val Loss: 0.6731, Val Acc: 0.6026
Epoch 70/100, Loss: 0.6241, Acc: 0.6567, Val Loss: 0.6713, Val Acc: 0.6056
Epoch 71/100, Loss: 0.6241, Acc: 0.6574, Val Loss: 0.6714, Val Acc: 0.6056
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6240, Acc: 0.6562, Val Loss: 0.6731, Val Acc: 0.6030
Epoch 73/100, Loss: 0.6240, Acc: 0.6576, Val Loss: 0.6720, Val Acc: 0.6052
Epoch 74/100, Loss: 0.6239, Acc: 0.6568, Val Loss: 0.6714, Val Acc: 0.6056
Epoch 75/100, Loss: 0.6240, Acc: 0.6571, Val Loss: 0.6719, Val Acc: 0.6045
Epoch 76/100, Loss: 0.6240, Acc: 0.6579, Val Loss: 0.6713, Val Acc: 0.6067
Epoch 77/100, Loss: 0.6239, Acc: 0.6573, Val Loss: 0.6720, Val Acc: 0.6060
Epoch 78/100, Loss: 0.6239, Acc: 0.6580, Val Loss: 0.6721, Val Acc: 0.6045
Epoch 79/100, Loss: 0.6240, Acc: 0.6566, Val Loss: 0.6721, Val Acc: 0.6056
Epoch 80/100, Loss: 0.6240, Acc: 0.6574, Val Loss: 0.6724, Val Acc: 0.6045
Epoch 81/100, Loss: 0.6240, Acc: 0.6585, Val Loss: 0.6717, Val Acc: 0.6063
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6239, Acc: 0.6584, Val Loss: 0.6718, Val Acc: 0.6052
Epoch 83/100, Loss: 0.6240, Acc: 0.6567, Val Loss: 0.6718, Val Acc: 0.6052
Epoch 84/100, Loss: 0.6239, Acc: 0.6576, Val Loss: 0.6721, Val Acc: 0.6052
Epoch 85/100, Loss: 0.6239, Acc: 0.6569, Val Loss: 0.6717, Val Acc: 0.6056
Epoch 86/100, Loss: 0.6239, Acc: 0.6575, Val Loss: 0.6718, Val Acc: 0.6052
Epoch 87/100, Loss: 0.6239, Acc: 0.6572, Val Loss: 0.6719, Val Acc: 0.6056
Epoch 88/100, Loss: 0.6238, Acc: 0.6587, Val Loss: 0.6727, Val Acc: 0.6045
Epoch 89/100, Loss: 0.6238, Acc: 0.6581, Val Loss: 0.6717, Val Acc: 0.6056
Epoch 90/100, Loss: 0.6239, Acc: 0.6562, Val Loss: 0.6718, Val Acc: 0.6056
Epoch 91/100, Loss: 0.6239, Acc: 0.6577, Val Loss: 0.6717, Val Acc: 0.6056
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6238, Acc: 0.6567, Val Loss: 0.6724, Val Acc: 0.6041
Epoch 93/100, Loss: 0.6238, Acc: 0.6576, Val Loss: 0.6719, Val Acc: 0.6056
Epoch 94/100, Loss: 0.6238, Acc: 0.6572, Val Loss: 0.6720, Val Acc: 0.6063
Epoch 95/100, Loss: 0.6238, Acc: 0.6582, Val Loss: 0.6724, Val Acc: 0.6052
Epoch 96/100, Loss: 0.6238, Acc: 0.6577, Val Loss: 0.6728, Val Acc: 0.6034
Epoch 97/100, Loss: 0.6238, Acc: 0.6574, Val Loss: 0.6724, Val Acc: 0.6045
Epoch 98/100, Loss: 0.6238, Acc: 0.6577, Val Loss: 0.6720, Val Acc: 0.6056
Epoch 99/100, Loss: 0.6238, Acc: 0.6568, Val Loss: 0.6723, Val Acc: 0.6034
Epoch 100/100, Loss: 0.6238, Acc: 0.6576, Val Loss: 0.6713, Val Acc: 0.6045

##############################
Resultados para principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  3 
 {'training': [0.6237583597325779, 0.6575657289943004, 0.6442161980131336, 0.7035674880470761, 0.6725850399929683], 'validate': [0.6712949081908824, 0.6044885945548197, 0.5851896447922939, 0.7157584683357879, 0.6439218284200067], 'test': [0.6104804669265393, 0.6880517951736316, 0.721835883171071, 0.6113074204946997, 0.6619897959183674]}

##############################
Resultados para window:  3 
 {'095:065:013:063:070:040': {'training': [0.6416207584174903, 0.631917631917632, 0.5943421052631579, 0.8306362633321074, 0.6928976836938181], 'validate': [0.6533217603384063, 0.6295069904341427, 0.5982092893116956, 0.7871870397643593, 0.6798092209856915], 'test': [0.5925974696874619, 0.7257210123602119, 0.729066985645933, 0.7179034157832744, 0.7234421364985163]}, '065:095:013:063:070:040': {'training': [0.6927520800631896, 0.5182938040080898, 0.5134437805540467, 0.695292386906951, 0.5906889548508045], 'validate': [0.6904337004173634, 0.594186902133922, 0.5915290739411343, 0.6067746686303387, 0.599054889131225], 'test': [0.6900215954692276, 0.6230135373749264, 0.6279926335174953, 0.6024734982332155, 0.6149684400360685]}, '013:095:065:063:070:040': {'training': [0.6076761069247819, 0.670343813200956, 0.6962696057651547, 0.6040823832291283, 0.6469082315872391], 'validate': [0.526323814724767, 0.7667402501839587, 0.7134433962264151, 0.8910162002945509, 0.7924034053700065], 'test': [0.7494432159044124, 0.49793996468510887, 0.4973404255319149, 0.44051825677267376, 0.46720799500312304]}, '063:095:065:013:070:040': {'training': [0.6079331743276651, 0.6685971685971686, 0.6493887530562347, 0.7326222876057374, 0.688499092715804], 'validate': [0.8007529003675594, 0.4139072847682119, 0.4350469872857933, 0.5795287187039765, 0.4970003157562362], 'test': [0.6972184401971323, 0.474102413184226, 0.48374132261600294, 0.7797408716136631, 0.5970687711386696]}, '070:095:065:013:063:040': {'training': [0.6779309122916157, 0.5820003677146535, 0.6022962112514352, 0.4823464509010666, 0.535688757275605], 'validate': [0.6825980391613272, 0.5621780721118469, 0.5841683366733467, 0.42930780559646536, 0.49490662139219016], 'test': [0.7009002202086978, 0.4961742201294879, 0.4958968347010551, 0.49823321554770317, 0.4970622796709753]}, '040:095:065:013:063:070': {'training': [0.6237583597325779, 0.6575657289943004, 0.6442161980131336, 0.7035674880470761, 0.6725850399929683], 'validate': [0.6712949081908824, 0.6044885945548197, 0.5851896447922939, 0.7157584683357879, 0.6439218284200067], 'test': [0.6104804669265393, 0.6880517951736316, 0.721835883171071, 0.6113074204946997, 0.6619897959183674]}}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  102  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  102  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6513, Acc: 0.6505, Val Loss: 0.5079, Val Acc: 0.9319
Mejor modelo guardado con Val Loss: 0.5079
Epoch 2/100, Loss: 0.6009, Acc: 0.6998, Val Loss: 0.4235, Val Acc: 0.9007
Mejor modelo guardado con Val Loss: 0.4235
Epoch 3/100, Loss: 0.5798, Acc: 0.7069, Val Loss: 0.3687, Val Acc: 0.9286
Mejor modelo guardado con Val Loss: 0.3687
Epoch 4/100, Loss: 0.5783, Acc: 0.7050, Val Loss: 0.3895, Val Acc: 0.8959
Epoch 5/100, Loss: 0.5617, Acc: 0.7185, Val Loss: 0.3435, Val Acc: 0.9216
Mejor modelo guardado con Val Loss: 0.3435
Epoch 6/100, Loss: 0.5593, Acc: 0.7193, Val Loss: 0.3220, Val Acc: 0.9220
Mejor modelo guardado con Val Loss: 0.3220
Epoch 7/100, Loss: 0.5544, Acc: 0.7238, Val Loss: 0.3228, Val Acc: 0.9095
Epoch 8/100, Loss: 0.5532, Acc: 0.7237, Val Loss: 0.3191, Val Acc: 0.9220
Mejor modelo guardado con Val Loss: 0.3191
Epoch 9/100, Loss: 0.5530, Acc: 0.7247, Val Loss: 0.3601, Val Acc: 0.9021
Epoch 10/100, Loss: 0.5513, Acc: 0.7250, Val Loss: 0.3512, Val Acc: 0.9095
Epoch 11/100, Loss: 0.5434, Acc: 0.7352, Val Loss: 0.3604, Val Acc: 0.9117
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5391, Acc: 0.7352, Val Loss: 0.3163, Val Acc: 0.9150
Mejor modelo guardado con Val Loss: 0.3163
Epoch 13/100, Loss: 0.5391, Acc: 0.7325, Val Loss: 0.3222, Val Acc: 0.9150
Epoch 14/100, Loss: 0.5334, Acc: 0.7367, Val Loss: 0.2910, Val Acc: 0.9113
Mejor modelo guardado con Val Loss: 0.2910
Epoch 15/100, Loss: 0.5364, Acc: 0.7363, Val Loss: 0.2968, Val Acc: 0.9176
Epoch 16/100, Loss: 0.5345, Acc: 0.7367, Val Loss: 0.3230, Val Acc: 0.9080
Epoch 17/100, Loss: 0.5338, Acc: 0.7348, Val Loss: 0.3109, Val Acc: 0.9110
Epoch 18/100, Loss: 0.5314, Acc: 0.7389, Val Loss: 0.3161, Val Acc: 0.9106
Epoch 19/100, Loss: 0.5314, Acc: 0.7367, Val Loss: 0.3020, Val Acc: 0.9205
Epoch 20/100, Loss: 0.5329, Acc: 0.7374, Val Loss: 0.2962, Val Acc: 0.9169
Epoch 21/100, Loss: 0.5284, Acc: 0.7357, Val Loss: 0.2962, Val Acc: 0.9132
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5293, Acc: 0.7394, Val Loss: 0.2992, Val Acc: 0.9091
Epoch 23/100, Loss: 0.5270, Acc: 0.7395, Val Loss: 0.2943, Val Acc: 0.9194
Epoch 24/100, Loss: 0.5235, Acc: 0.7426, Val Loss: 0.2916, Val Acc: 0.9146
Epoch 25/100, Loss: 0.5257, Acc: 0.7405, Val Loss: 0.3128, Val Acc: 0.9088
Epoch 26/100, Loss: 0.5251, Acc: 0.7408, Val Loss: 0.2914, Val Acc: 0.9172
Epoch 27/100, Loss: 0.5229, Acc: 0.7439, Val Loss: 0.2976, Val Acc: 0.9106
Epoch 28/100, Loss: 0.5232, Acc: 0.7441, Val Loss: 0.2909, Val Acc: 0.9154
Mejor modelo guardado con Val Loss: 0.2909
Epoch 29/100, Loss: 0.5211, Acc: 0.7461, Val Loss: 0.3013, Val Acc: 0.9139
Epoch 30/100, Loss: 0.5210, Acc: 0.7447, Val Loss: 0.2900, Val Acc: 0.9180
Mejor modelo guardado con Val Loss: 0.2900
Epoch 31/100, Loss: 0.5194, Acc: 0.7459, Val Loss: 0.2902, Val Acc: 0.9161
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5181, Acc: 0.7464, Val Loss: 0.2893, Val Acc: 0.9183
Mejor modelo guardado con Val Loss: 0.2893
Epoch 33/100, Loss: 0.5171, Acc: 0.7471, Val Loss: 0.3101, Val Acc: 0.9161
Epoch 34/100, Loss: 0.5173, Acc: 0.7466, Val Loss: 0.2949, Val Acc: 0.9169
Epoch 35/100, Loss: 0.5177, Acc: 0.7432, Val Loss: 0.2937, Val Acc: 0.9165
Epoch 36/100, Loss: 0.5164, Acc: 0.7465, Val Loss: 0.3006, Val Acc: 0.9194
Epoch 37/100, Loss: 0.5151, Acc: 0.7479, Val Loss: 0.3089, Val Acc: 0.9157
Epoch 38/100, Loss: 0.5172, Acc: 0.7452, Val Loss: 0.2954, Val Acc: 0.9154
Epoch 39/100, Loss: 0.5158, Acc: 0.7473, Val Loss: 0.3112, Val Acc: 0.9132
Epoch 40/100, Loss: 0.5160, Acc: 0.7477, Val Loss: 0.2908, Val Acc: 0.9132
Epoch 41/100, Loss: 0.5158, Acc: 0.7466, Val Loss: 0.2949, Val Acc: 0.9198
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5140, Acc: 0.7494, Val Loss: 0.2874, Val Acc: 0.9187
Mejor modelo guardado con Val Loss: 0.2874
Epoch 43/100, Loss: 0.5133, Acc: 0.7481, Val Loss: 0.2865, Val Acc: 0.9169
Mejor modelo guardado con Val Loss: 0.2865
Epoch 44/100, Loss: 0.5134, Acc: 0.7496, Val Loss: 0.2875, Val Acc: 0.9157
Epoch 45/100, Loss: 0.5131, Acc: 0.7479, Val Loss: 0.2893, Val Acc: 0.9176
Epoch 46/100, Loss: 0.5133, Acc: 0.7481, Val Loss: 0.2942, Val Acc: 0.9154
Epoch 47/100, Loss: 0.5125, Acc: 0.7495, Val Loss: 0.2934, Val Acc: 0.9183
Epoch 48/100, Loss: 0.5132, Acc: 0.7487, Val Loss: 0.2886, Val Acc: 0.9191
Epoch 49/100, Loss: 0.5129, Acc: 0.7477, Val Loss: 0.2864, Val Acc: 0.9205
Mejor modelo guardado con Val Loss: 0.2864
Epoch 50/100, Loss: 0.5120, Acc: 0.7474, Val Loss: 0.2868, Val Acc: 0.9161
Epoch 51/100, Loss: 0.5122, Acc: 0.7493, Val Loss: 0.2868, Val Acc: 0.9202
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5115, Acc: 0.7495, Val Loss: 0.2856, Val Acc: 0.9176
Mejor modelo guardado con Val Loss: 0.2856
Epoch 53/100, Loss: 0.5111, Acc: 0.7484, Val Loss: 0.2903, Val Acc: 0.9165
Epoch 54/100, Loss: 0.5112, Acc: 0.7488, Val Loss: 0.2895, Val Acc: 0.9157
Epoch 55/100, Loss: 0.5108, Acc: 0.7490, Val Loss: 0.2942, Val Acc: 0.9191
Epoch 56/100, Loss: 0.5110, Acc: 0.7494, Val Loss: 0.2829, Val Acc: 0.9187
Mejor modelo guardado con Val Loss: 0.2829
Epoch 57/100, Loss: 0.5104, Acc: 0.7487, Val Loss: 0.2841, Val Acc: 0.9191
Epoch 58/100, Loss: 0.5103, Acc: 0.7498, Val Loss: 0.2848, Val Acc: 0.9202
Epoch 59/100, Loss: 0.5096, Acc: 0.7511, Val Loss: 0.2837, Val Acc: 0.9205
Epoch 60/100, Loss: 0.5098, Acc: 0.7501, Val Loss: 0.2845, Val Acc: 0.9209
Epoch 61/100, Loss: 0.5089, Acc: 0.7504, Val Loss: 0.2838, Val Acc: 0.9209
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5085, Acc: 0.7500, Val Loss: 0.2823, Val Acc: 0.9187
Mejor modelo guardado con Val Loss: 0.2823
Epoch 63/100, Loss: 0.5081, Acc: 0.7497, Val Loss: 0.2829, Val Acc: 0.9209
Epoch 64/100, Loss: 0.5081, Acc: 0.7514, Val Loss: 0.2807, Val Acc: 0.9191
Mejor modelo guardado con Val Loss: 0.2807
Epoch 65/100, Loss: 0.5080, Acc: 0.7506, Val Loss: 0.2837, Val Acc: 0.9194
Epoch 66/100, Loss: 0.5080, Acc: 0.7511, Val Loss: 0.2817, Val Acc: 0.9213
Epoch 67/100, Loss: 0.5078, Acc: 0.7510, Val Loss: 0.2844, Val Acc: 0.9183
Epoch 68/100, Loss: 0.5078, Acc: 0.7516, Val Loss: 0.2822, Val Acc: 0.9183
Epoch 69/100, Loss: 0.5077, Acc: 0.7508, Val Loss: 0.2838, Val Acc: 0.9191
Epoch 70/100, Loss: 0.5077, Acc: 0.7520, Val Loss: 0.2812, Val Acc: 0.9187
Epoch 71/100, Loss: 0.5075, Acc: 0.7515, Val Loss: 0.2818, Val Acc: 0.9205
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5074, Acc: 0.7512, Val Loss: 0.2823, Val Acc: 0.9187
Epoch 73/100, Loss: 0.5074, Acc: 0.7520, Val Loss: 0.2827, Val Acc: 0.9198
Epoch 74/100, Loss: 0.5073, Acc: 0.7511, Val Loss: 0.2833, Val Acc: 0.9191
Epoch 75/100, Loss: 0.5073, Acc: 0.7516, Val Loss: 0.2824, Val Acc: 0.9187
Epoch 76/100, Loss: 0.5073, Acc: 0.7512, Val Loss: 0.2831, Val Acc: 0.9198
Epoch 77/100, Loss: 0.5072, Acc: 0.7523, Val Loss: 0.2836, Val Acc: 0.9198
Epoch 78/100, Loss: 0.5071, Acc: 0.7515, Val Loss: 0.2822, Val Acc: 0.9194
Epoch 79/100, Loss: 0.5072, Acc: 0.7513, Val Loss: 0.2829, Val Acc: 0.9198
Epoch 80/100, Loss: 0.5071, Acc: 0.7514, Val Loss: 0.2833, Val Acc: 0.9191
Epoch 81/100, Loss: 0.5070, Acc: 0.7512, Val Loss: 0.2826, Val Acc: 0.9191
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5069, Acc: 0.7536, Val Loss: 0.2819, Val Acc: 0.9209
Epoch 83/100, Loss: 0.5071, Acc: 0.7511, Val Loss: 0.2820, Val Acc: 0.9198
Epoch 84/100, Loss: 0.5069, Acc: 0.7509, Val Loss: 0.2819, Val Acc: 0.9187
Epoch 85/100, Loss: 0.5068, Acc: 0.7506, Val Loss: 0.2823, Val Acc: 0.9191
Epoch 86/100, Loss: 0.5069, Acc: 0.7519, Val Loss: 0.2819, Val Acc: 0.9191
Epoch 87/100, Loss: 0.5067, Acc: 0.7523, Val Loss: 0.2827, Val Acc: 0.9194
Epoch 88/100, Loss: 0.5067, Acc: 0.7520, Val Loss: 0.2828, Val Acc: 0.9191
Epoch 89/100, Loss: 0.5067, Acc: 0.7507, Val Loss: 0.2826, Val Acc: 0.9198
Epoch 90/100, Loss: 0.5067, Acc: 0.7515, Val Loss: 0.2816, Val Acc: 0.9191
Epoch 91/100, Loss: 0.5066, Acc: 0.7521, Val Loss: 0.2820, Val Acc: 0.9198
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5064, Acc: 0.7510, Val Loss: 0.2822, Val Acc: 0.9191
Epoch 93/100, Loss: 0.5064, Acc: 0.7511, Val Loss: 0.2820, Val Acc: 0.9187
Epoch 94/100, Loss: 0.5064, Acc: 0.7518, Val Loss: 0.2824, Val Acc: 0.9191
Epoch 95/100, Loss: 0.5064, Acc: 0.7526, Val Loss: 0.2821, Val Acc: 0.9194
Epoch 96/100, Loss: 0.5064, Acc: 0.7505, Val Loss: 0.2826, Val Acc: 0.9187
Epoch 97/100, Loss: 0.5063, Acc: 0.7517, Val Loss: 0.2825, Val Acc: 0.9202
Epoch 98/100, Loss: 0.5063, Acc: 0.7519, Val Loss: 0.2823, Val Acc: 0.9187
Epoch 99/100, Loss: 0.5062, Acc: 0.7519, Val Loss: 0.2832, Val Acc: 0.9191
Epoch 100/100, Loss: 0.5062, Acc: 0.7520, Val Loss: 0.2816, Val Acc: 0.9194

##############################
Resultados para principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3 
 {'training': [0.5061580682966853, 0.7519764662621805, 0.7485486211901307, 0.7587348289812431, 0.7536073059360731], 'validate': [0.2815657412243444, 0.9194260485651214, 0.929811320754717, 0.9072164948453608, 0.9183749534103616], 'test': [0.7400477647229478, 0.5688640376692172, 0.5633496465470365, 0.6101295641931684, 0.5858071812270286]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  020  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  020  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6424, Acc: 0.6502, Val Loss: 0.7023, Val Acc: 0.5235
Mejor modelo guardado con Val Loss: 0.7023
Epoch 2/100, Loss: 0.6093, Acc: 0.6838, Val Loss: 0.6877, Val Acc: 0.5721
Mejor modelo guardado con Val Loss: 0.6877
Epoch 3/100, Loss: 0.5892, Acc: 0.6955, Val Loss: 0.7020, Val Acc: 0.5912
Epoch 4/100, Loss: 0.5693, Acc: 0.7073, Val Loss: 0.6972, Val Acc: 0.5931
Epoch 5/100, Loss: 0.5697, Acc: 0.7034, Val Loss: 0.7003, Val Acc: 0.5920
Epoch 6/100, Loss: 0.5671, Acc: 0.7097, Val Loss: 0.6862, Val Acc: 0.5817
Mejor modelo guardado con Val Loss: 0.6862
Epoch 7/100, Loss: 0.5739, Acc: 0.7031, Val Loss: 0.7128, Val Acc: 0.5625
Epoch 8/100, Loss: 0.5781, Acc: 0.6939, Val Loss: 0.7527, Val Acc: 0.5471
Epoch 9/100, Loss: 0.5720, Acc: 0.7044, Val Loss: 0.6986, Val Acc: 0.5806
Epoch 10/100, Loss: 0.5673, Acc: 0.7015, Val Loss: 0.6790, Val Acc: 0.5699
Mejor modelo guardado con Val Loss: 0.6790
Epoch 11/100, Loss: 0.5661, Acc: 0.7084, Val Loss: 0.7225, Val Acc: 0.5622
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5565, Acc: 0.7163, Val Loss: 0.7028, Val Acc: 0.5876
Epoch 13/100, Loss: 0.5564, Acc: 0.7168, Val Loss: 0.7120, Val Acc: 0.5644
Epoch 14/100, Loss: 0.5567, Acc: 0.7177, Val Loss: 0.7144, Val Acc: 0.5728
Epoch 15/100, Loss: 0.5532, Acc: 0.7178, Val Loss: 0.7004, Val Acc: 0.5912
Epoch 16/100, Loss: 0.5511, Acc: 0.7167, Val Loss: 0.7109, Val Acc: 0.5817
Epoch 17/100, Loss: 0.5521, Acc: 0.7157, Val Loss: 0.7208, Val Acc: 0.5567
Epoch 18/100, Loss: 0.5502, Acc: 0.7220, Val Loss: 0.7068, Val Acc: 0.5773
Epoch 19/100, Loss: 0.5490, Acc: 0.7202, Val Loss: 0.6865, Val Acc: 0.6045
Epoch 20/100, Loss: 0.5486, Acc: 0.7201, Val Loss: 0.7061, Val Acc: 0.5813
Epoch 21/100, Loss: 0.5519, Acc: 0.7185, Val Loss: 0.7189, Val Acc: 0.5762
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5449, Acc: 0.7220, Val Loss: 0.7019, Val Acc: 0.5909
Epoch 23/100, Loss: 0.5433, Acc: 0.7212, Val Loss: 0.7011, Val Acc: 0.5912
Epoch 24/100, Loss: 0.5418, Acc: 0.7235, Val Loss: 0.7112, Val Acc: 0.5946
Epoch 25/100, Loss: 0.5442, Acc: 0.7227, Val Loss: 0.7123, Val Acc: 0.5773
Epoch 26/100, Loss: 0.5413, Acc: 0.7238, Val Loss: 0.7170, Val Acc: 0.5747
Epoch 27/100, Loss: 0.5421, Acc: 0.7235, Val Loss: 0.7117, Val Acc: 0.5780
Epoch 28/100, Loss: 0.5402, Acc: 0.7238, Val Loss: 0.7207, Val Acc: 0.5820
Epoch 29/100, Loss: 0.5407, Acc: 0.7238, Val Loss: 0.7245, Val Acc: 0.5791
Epoch 30/100, Loss: 0.5422, Acc: 0.7231, Val Loss: 0.7038, Val Acc: 0.5942
Epoch 31/100, Loss: 0.5390, Acc: 0.7270, Val Loss: 0.7042, Val Acc: 0.5975
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5380, Acc: 0.7247, Val Loss: 0.7220, Val Acc: 0.5776
Epoch 33/100, Loss: 0.5376, Acc: 0.7257, Val Loss: 0.7208, Val Acc: 0.5765
Epoch 34/100, Loss: 0.5370, Acc: 0.7256, Val Loss: 0.7185, Val Acc: 0.5824
Epoch 35/100, Loss: 0.5368, Acc: 0.7265, Val Loss: 0.7231, Val Acc: 0.5839
Epoch 36/100, Loss: 0.5369, Acc: 0.7253, Val Loss: 0.7154, Val Acc: 0.5824
Epoch 37/100, Loss: 0.5364, Acc: 0.7261, Val Loss: 0.7132, Val Acc: 0.5876
Epoch 38/100, Loss: 0.5361, Acc: 0.7272, Val Loss: 0.7177, Val Acc: 0.5846
Epoch 39/100, Loss: 0.5362, Acc: 0.7273, Val Loss: 0.7219, Val Acc: 0.5795
Epoch 40/100, Loss: 0.5353, Acc: 0.7262, Val Loss: 0.7089, Val Acc: 0.5854
Epoch 41/100, Loss: 0.5354, Acc: 0.7292, Val Loss: 0.7263, Val Acc: 0.5688
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5345, Acc: 0.7281, Val Loss: 0.7095, Val Acc: 0.5894
Epoch 43/100, Loss: 0.5344, Acc: 0.7273, Val Loss: 0.7166, Val Acc: 0.5854
Epoch 44/100, Loss: 0.5341, Acc: 0.7264, Val Loss: 0.7143, Val Acc: 0.5861
Epoch 45/100, Loss: 0.5341, Acc: 0.7271, Val Loss: 0.7103, Val Acc: 0.5846
Epoch 46/100, Loss: 0.5338, Acc: 0.7280, Val Loss: 0.7188, Val Acc: 0.5813
Epoch 47/100, Loss: 0.5337, Acc: 0.7278, Val Loss: 0.7139, Val Acc: 0.5813
Epoch 48/100, Loss: 0.5333, Acc: 0.7280, Val Loss: 0.7169, Val Acc: 0.5861
Epoch 49/100, Loss: 0.5330, Acc: 0.7275, Val Loss: 0.7124, Val Acc: 0.5879
Epoch 50/100, Loss: 0.5333, Acc: 0.7276, Val Loss: 0.7139, Val Acc: 0.5857
Epoch 51/100, Loss: 0.5330, Acc: 0.7286, Val Loss: 0.7175, Val Acc: 0.5868
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5324, Acc: 0.7283, Val Loss: 0.7192, Val Acc: 0.5831
Epoch 53/100, Loss: 0.5321, Acc: 0.7288, Val Loss: 0.7150, Val Acc: 0.5846
Epoch 54/100, Loss: 0.5321, Acc: 0.7275, Val Loss: 0.7230, Val Acc: 0.5806
Epoch 55/100, Loss: 0.5323, Acc: 0.7277, Val Loss: 0.7206, Val Acc: 0.5850
Epoch 56/100, Loss: 0.5319, Acc: 0.7280, Val Loss: 0.7223, Val Acc: 0.5809
Epoch 57/100, Loss: 0.5318, Acc: 0.7293, Val Loss: 0.7257, Val Acc: 0.5776
Epoch 58/100, Loss: 0.5320, Acc: 0.7295, Val Loss: 0.7119, Val Acc: 0.5868
Epoch 59/100, Loss: 0.5318, Acc: 0.7284, Val Loss: 0.7178, Val Acc: 0.5831
Epoch 60/100, Loss: 0.5313, Acc: 0.7289, Val Loss: 0.7292, Val Acc: 0.5769
Epoch 61/100, Loss: 0.5320, Acc: 0.7284, Val Loss: 0.7210, Val Acc: 0.5824
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5313, Acc: 0.7289, Val Loss: 0.7194, Val Acc: 0.5809
Epoch 63/100, Loss: 0.5313, Acc: 0.7291, Val Loss: 0.7160, Val Acc: 0.5843
Epoch 64/100, Loss: 0.5312, Acc: 0.7292, Val Loss: 0.7183, Val Acc: 0.5839
Epoch 65/100, Loss: 0.5313, Acc: 0.7280, Val Loss: 0.7173, Val Acc: 0.5850
Epoch 66/100, Loss: 0.5312, Acc: 0.7284, Val Loss: 0.7176, Val Acc: 0.5854
Epoch 67/100, Loss: 0.5312, Acc: 0.7291, Val Loss: 0.7169, Val Acc: 0.5846
Epoch 68/100, Loss: 0.5311, Acc: 0.7282, Val Loss: 0.7180, Val Acc: 0.5854
Epoch 69/100, Loss: 0.5311, Acc: 0.7289, Val Loss: 0.7178, Val Acc: 0.5850
Epoch 70/100, Loss: 0.5310, Acc: 0.7289, Val Loss: 0.7188, Val Acc: 0.5820
Epoch 71/100, Loss: 0.5311, Acc: 0.7295, Val Loss: 0.7159, Val Acc: 0.5854
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5309, Acc: 0.7284, Val Loss: 0.7182, Val Acc: 0.5854
Epoch 73/100, Loss: 0.5309, Acc: 0.7295, Val Loss: 0.7181, Val Acc: 0.5850
Epoch 74/100, Loss: 0.5309, Acc: 0.7286, Val Loss: 0.7194, Val Acc: 0.5835
Epoch 75/100, Loss: 0.5308, Acc: 0.7292, Val Loss: 0.7181, Val Acc: 0.5850
Epoch 76/100, Loss: 0.5308, Acc: 0.7298, Val Loss: 0.7198, Val Acc: 0.5820
Epoch 77/100, Loss: 0.5308, Acc: 0.7295, Val Loss: 0.7164, Val Acc: 0.5857
Epoch 78/100, Loss: 0.5308, Acc: 0.7290, Val Loss: 0.7196, Val Acc: 0.5843
Epoch 79/100, Loss: 0.5308, Acc: 0.7282, Val Loss: 0.7185, Val Acc: 0.5854
Epoch 80/100, Loss: 0.5308, Acc: 0.7282, Val Loss: 0.7163, Val Acc: 0.5854
Epoch 81/100, Loss: 0.5307, Acc: 0.7284, Val Loss: 0.7181, Val Acc: 0.5857
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5307, Acc: 0.7285, Val Loss: 0.7172, Val Acc: 0.5846
Epoch 83/100, Loss: 0.5307, Acc: 0.7278, Val Loss: 0.7165, Val Acc: 0.5857
Epoch 84/100, Loss: 0.5307, Acc: 0.7293, Val Loss: 0.7178, Val Acc: 0.5854
Epoch 85/100, Loss: 0.5307, Acc: 0.7289, Val Loss: 0.7183, Val Acc: 0.5850
Epoch 86/100, Loss: 0.5305, Acc: 0.7293, Val Loss: 0.7196, Val Acc: 0.5831
Epoch 87/100, Loss: 0.5308, Acc: 0.7291, Val Loss: 0.7170, Val Acc: 0.5839
Epoch 88/100, Loss: 0.5306, Acc: 0.7291, Val Loss: 0.7174, Val Acc: 0.5854
Epoch 89/100, Loss: 0.5306, Acc: 0.7288, Val Loss: 0.7185, Val Acc: 0.5850
Epoch 90/100, Loss: 0.5305, Acc: 0.7296, Val Loss: 0.7174, Val Acc: 0.5843
Epoch 91/100, Loss: 0.5305, Acc: 0.7293, Val Loss: 0.7161, Val Acc: 0.5854
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5305, Acc: 0.7284, Val Loss: 0.7190, Val Acc: 0.5846
Epoch 93/100, Loss: 0.5304, Acc: 0.7295, Val Loss: 0.7177, Val Acc: 0.5839
Epoch 94/100, Loss: 0.5304, Acc: 0.7293, Val Loss: 0.7185, Val Acc: 0.5854
Epoch 95/100, Loss: 0.5304, Acc: 0.7294, Val Loss: 0.7182, Val Acc: 0.5850
Epoch 96/100, Loss: 0.5305, Acc: 0.7285, Val Loss: 0.7185, Val Acc: 0.5857
Epoch 97/100, Loss: 0.5304, Acc: 0.7292, Val Loss: 0.7188, Val Acc: 0.5850
Epoch 98/100, Loss: 0.5303, Acc: 0.7288, Val Loss: 0.7171, Val Acc: 0.5839
Epoch 99/100, Loss: 0.5303, Acc: 0.7294, Val Loss: 0.7199, Val Acc: 0.5835
Epoch 100/100, Loss: 0.5304, Acc: 0.7294, Val Loss: 0.7179, Val Acc: 0.5846

##############################
Resultados para principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3 
 {'training': [0.5304338349305788, 0.7293620150763008, 0.6941158156911582, 0.8199705774181685, 0.7518125105378519], 'validate': [0.7178546561058178, 0.5846210448859456, 0.551739719837325, 0.8991163475699558, 0.6838420610473257], 'test': [0.46485284136401284, 0.8649205414949971, 0.861646234676007, 0.8692579505300353, 0.8654353562005277]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  125  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  125  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6936, Acc: 0.5050, Val Loss: 0.6932, Val Acc: 0.5110
Mejor modelo guardado con Val Loss: 0.6932
Epoch 2/100, Loss: 0.6929, Acc: 0.5076, Val Loss: 0.6917, Val Acc: 0.5423
Mejor modelo guardado con Val Loss: 0.6917
Epoch 3/100, Loss: 0.6922, Acc: 0.5250, Val Loss: 0.6898, Val Acc: 0.5589
Mejor modelo guardado con Val Loss: 0.6898
Epoch 4/100, Loss: 0.6928, Acc: 0.5060, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 5/100, Loss: 0.6933, Acc: 0.4995, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 6/100, Loss: 0.6935, Acc: 0.4968, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 7/100, Loss: 0.6932, Acc: 0.5052, Val Loss: 0.6945, Val Acc: 0.4996
Epoch 8/100, Loss: 0.6939, Acc: 0.5003, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 9/100, Loss: 0.6934, Acc: 0.4916, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 10/100, Loss: 0.6921, Acc: 0.5146, Val Loss: 0.6839, Val Acc: 0.6446
Mejor modelo guardado con Val Loss: 0.6839
Epoch 11/100, Loss: 0.6907, Acc: 0.5403, Val Loss: 0.6932, Val Acc: 0.5037
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6912, Acc: 0.5343, Val Loss: 0.6795, Val Acc: 0.6641
Mejor modelo guardado con Val Loss: 0.6795
Epoch 13/100, Loss: 0.6883, Acc: 0.5607, Val Loss: 0.6779, Val Acc: 0.6560
Mejor modelo guardado con Val Loss: 0.6779
Epoch 14/100, Loss: 0.6882, Acc: 0.5540, Val Loss: 0.6760, Val Acc: 0.6641
Mejor modelo guardado con Val Loss: 0.6760
Epoch 15/100, Loss: 0.6870, Acc: 0.5641, Val Loss: 0.6740, Val Acc: 0.6729
Mejor modelo guardado con Val Loss: 0.6740
Epoch 16/100, Loss: 0.6863, Acc: 0.5673, Val Loss: 0.6744, Val Acc: 0.6538
Epoch 17/100, Loss: 0.6848, Acc: 0.5735, Val Loss: 0.6738, Val Acc: 0.6494
Mejor modelo guardado con Val Loss: 0.6738
Epoch 18/100, Loss: 0.6847, Acc: 0.5706, Val Loss: 0.6746, Val Acc: 0.6203
Epoch 19/100, Loss: 0.6835, Acc: 0.5780, Val Loss: 0.6762, Val Acc: 0.6067
Epoch 20/100, Loss: 0.6823, Acc: 0.5794, Val Loss: 0.6651, Val Acc: 0.6766
Mejor modelo guardado con Val Loss: 0.6651
Epoch 21/100, Loss: 0.6817, Acc: 0.5827, Val Loss: 0.6633, Val Acc: 0.6788
Mejor modelo guardado con Val Loss: 0.6633
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6806, Acc: 0.5825, Val Loss: 0.6640, Val Acc: 0.6674
Epoch 23/100, Loss: 0.6803, Acc: 0.5860, Val Loss: 0.6619, Val Acc: 0.6784
Mejor modelo guardado con Val Loss: 0.6619
Epoch 24/100, Loss: 0.6798, Acc: 0.5896, Val Loss: 0.6642, Val Acc: 0.6516
Epoch 25/100, Loss: 0.6793, Acc: 0.5851, Val Loss: 0.6624, Val Acc: 0.6575
Epoch 26/100, Loss: 0.6790, Acc: 0.5880, Val Loss: 0.6599, Val Acc: 0.6733
Mejor modelo guardado con Val Loss: 0.6599
Epoch 27/100, Loss: 0.6789, Acc: 0.5856, Val Loss: 0.6595, Val Acc: 0.6700
Mejor modelo guardado con Val Loss: 0.6595
Epoch 28/100, Loss: 0.6781, Acc: 0.5897, Val Loss: 0.6582, Val Acc: 0.6766
Mejor modelo guardado con Val Loss: 0.6582
Epoch 29/100, Loss: 0.6776, Acc: 0.5903, Val Loss: 0.6578, Val Acc: 0.6711
Mejor modelo guardado con Val Loss: 0.6578
Epoch 30/100, Loss: 0.6772, Acc: 0.5899, Val Loss: 0.6595, Val Acc: 0.6582
Epoch 31/100, Loss: 0.6768, Acc: 0.5913, Val Loss: 0.6573, Val Acc: 0.6645
Mejor modelo guardado con Val Loss: 0.6573
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6760, Acc: 0.5985, Val Loss: 0.6560, Val Acc: 0.6737
Mejor modelo guardado con Val Loss: 0.6560
Epoch 33/100, Loss: 0.6763, Acc: 0.5909, Val Loss: 0.6568, Val Acc: 0.6674
Epoch 34/100, Loss: 0.6763, Acc: 0.5916, Val Loss: 0.6548, Val Acc: 0.6718
Mejor modelo guardado con Val Loss: 0.6548
Epoch 35/100, Loss: 0.6757, Acc: 0.5922, Val Loss: 0.6546, Val Acc: 0.6744
Mejor modelo guardado con Val Loss: 0.6546
Epoch 36/100, Loss: 0.6755, Acc: 0.5943, Val Loss: 0.6528, Val Acc: 0.6700
Mejor modelo guardado con Val Loss: 0.6528
Epoch 37/100, Loss: 0.6755, Acc: 0.5911, Val Loss: 0.6516, Val Acc: 0.6762
Mejor modelo guardado con Val Loss: 0.6516
Epoch 38/100, Loss: 0.6749, Acc: 0.5940, Val Loss: 0.6518, Val Acc: 0.6696
Epoch 39/100, Loss: 0.6752, Acc: 0.5933, Val Loss: 0.6506, Val Acc: 0.6762
Mejor modelo guardado con Val Loss: 0.6506
Epoch 40/100, Loss: 0.6745, Acc: 0.5938, Val Loss: 0.6498, Val Acc: 0.6762
Mejor modelo guardado con Val Loss: 0.6498
Epoch 41/100, Loss: 0.6742, Acc: 0.5936, Val Loss: 0.6508, Val Acc: 0.6755
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6740, Acc: 0.5942, Val Loss: 0.6501, Val Acc: 0.6681
Epoch 43/100, Loss: 0.6739, Acc: 0.5934, Val Loss: 0.6492, Val Acc: 0.6737
Mejor modelo guardado con Val Loss: 0.6492
Epoch 44/100, Loss: 0.6739, Acc: 0.5951, Val Loss: 0.6494, Val Acc: 0.6773
Epoch 45/100, Loss: 0.6738, Acc: 0.5958, Val Loss: 0.6490, Val Acc: 0.6748
Mejor modelo guardado con Val Loss: 0.6490
Epoch 46/100, Loss: 0.6736, Acc: 0.5958, Val Loss: 0.6488, Val Acc: 0.6755
Mejor modelo guardado con Val Loss: 0.6488
Epoch 47/100, Loss: 0.6736, Acc: 0.5940, Val Loss: 0.6488, Val Acc: 0.6737
Epoch 48/100, Loss: 0.6735, Acc: 0.5962, Val Loss: 0.6491, Val Acc: 0.6685
Epoch 49/100, Loss: 0.6732, Acc: 0.5954, Val Loss: 0.6482, Val Acc: 0.6755
Mejor modelo guardado con Val Loss: 0.6482
Epoch 50/100, Loss: 0.6733, Acc: 0.5958, Val Loss: 0.6483, Val Acc: 0.6740
Epoch 51/100, Loss: 0.6731, Acc: 0.5950, Val Loss: 0.6480, Val Acc: 0.6759
Mejor modelo guardado con Val Loss: 0.6480
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6729, Acc: 0.5965, Val Loss: 0.6477, Val Acc: 0.6759
Mejor modelo guardado con Val Loss: 0.6477
Epoch 53/100, Loss: 0.6729, Acc: 0.5955, Val Loss: 0.6476, Val Acc: 0.6744
Mejor modelo guardado con Val Loss: 0.6476
Epoch 54/100, Loss: 0.6728, Acc: 0.5954, Val Loss: 0.6476, Val Acc: 0.6759
Mejor modelo guardado con Val Loss: 0.6476
Epoch 55/100, Loss: 0.6727, Acc: 0.5971, Val Loss: 0.6475, Val Acc: 0.6751
Mejor modelo guardado con Val Loss: 0.6475
Epoch 56/100, Loss: 0.6727, Acc: 0.5948, Val Loss: 0.6474, Val Acc: 0.6748
Mejor modelo guardado con Val Loss: 0.6474
Epoch 57/100, Loss: 0.6727, Acc: 0.5953, Val Loss: 0.6474, Val Acc: 0.6751
Mejor modelo guardado con Val Loss: 0.6474
Epoch 58/100, Loss: 0.6726, Acc: 0.5974, Val Loss: 0.6474, Val Acc: 0.6737
Epoch 59/100, Loss: 0.6725, Acc: 0.5959, Val Loss: 0.6478, Val Acc: 0.6700
Epoch 60/100, Loss: 0.6726, Acc: 0.5939, Val Loss: 0.6475, Val Acc: 0.6726
Epoch 61/100, Loss: 0.6725, Acc: 0.5963, Val Loss: 0.6470, Val Acc: 0.6740
Mejor modelo guardado con Val Loss: 0.6470
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6724, Acc: 0.5967, Val Loss: 0.6469, Val Acc: 0.6726
Mejor modelo guardado con Val Loss: 0.6469
Epoch 63/100, Loss: 0.6724, Acc: 0.5979, Val Loss: 0.6468, Val Acc: 0.6733
Mejor modelo guardado con Val Loss: 0.6468
Epoch 64/100, Loss: 0.6723, Acc: 0.5966, Val Loss: 0.6468, Val Acc: 0.6729
Mejor modelo guardado con Val Loss: 0.6468
Epoch 65/100, Loss: 0.6723, Acc: 0.5977, Val Loss: 0.6468, Val Acc: 0.6729
Mejor modelo guardado con Val Loss: 0.6468
Epoch 66/100, Loss: 0.6723, Acc: 0.5970, Val Loss: 0.6468, Val Acc: 0.6744
Epoch 67/100, Loss: 0.6723, Acc: 0.5966, Val Loss: 0.6467, Val Acc: 0.6729
Mejor modelo guardado con Val Loss: 0.6467
Epoch 68/100, Loss: 0.6722, Acc: 0.5971, Val Loss: 0.6466, Val Acc: 0.6740
Mejor modelo guardado con Val Loss: 0.6466
Epoch 69/100, Loss: 0.6722, Acc: 0.5971, Val Loss: 0.6466, Val Acc: 0.6726
Mejor modelo guardado con Val Loss: 0.6466
Epoch 70/100, Loss: 0.6722, Acc: 0.5961, Val Loss: 0.6466, Val Acc: 0.6722
Mejor modelo guardado con Val Loss: 0.6466
Epoch 71/100, Loss: 0.6722, Acc: 0.5975, Val Loss: 0.6466, Val Acc: 0.6737
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6721, Acc: 0.5975, Val Loss: 0.6465, Val Acc: 0.6733
Mejor modelo guardado con Val Loss: 0.6465
Epoch 73/100, Loss: 0.6721, Acc: 0.5975, Val Loss: 0.6465, Val Acc: 0.6737
Mejor modelo guardado con Val Loss: 0.6465
Epoch 74/100, Loss: 0.6721, Acc: 0.5977, Val Loss: 0.6464, Val Acc: 0.6729
Mejor modelo guardado con Val Loss: 0.6464
Epoch 75/100, Loss: 0.6721, Acc: 0.5965, Val Loss: 0.6465, Val Acc: 0.6729
Epoch 76/100, Loss: 0.6721, Acc: 0.5969, Val Loss: 0.6465, Val Acc: 0.6737
Epoch 77/100, Loss: 0.6720, Acc: 0.5973, Val Loss: 0.6464, Val Acc: 0.6733
Mejor modelo guardado con Val Loss: 0.6464
Epoch 78/100, Loss: 0.6720, Acc: 0.5970, Val Loss: 0.6463, Val Acc: 0.6737
Mejor modelo guardado con Val Loss: 0.6463
Epoch 79/100, Loss: 0.6720, Acc: 0.5961, Val Loss: 0.6464, Val Acc: 0.6729
Epoch 80/100, Loss: 0.6720, Acc: 0.5971, Val Loss: 0.6463, Val Acc: 0.6733
Mejor modelo guardado con Val Loss: 0.6463
Epoch 81/100, Loss: 0.6720, Acc: 0.5974, Val Loss: 0.6463, Val Acc: 0.6733
Mejor modelo guardado con Val Loss: 0.6463
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6720, Acc: 0.5969, Val Loss: 0.6464, Val Acc: 0.6744
Epoch 83/100, Loss: 0.6720, Acc: 0.5964, Val Loss: 0.6462, Val Acc: 0.6744
Mejor modelo guardado con Val Loss: 0.6462
Epoch 84/100, Loss: 0.6720, Acc: 0.5969, Val Loss: 0.6462, Val Acc: 0.6737
Mejor modelo guardado con Val Loss: 0.6462
Epoch 85/100, Loss: 0.6720, Acc: 0.5975, Val Loss: 0.6462, Val Acc: 0.6737
Epoch 86/100, Loss: 0.6719, Acc: 0.5970, Val Loss: 0.6462, Val Acc: 0.6733
Mejor modelo guardado con Val Loss: 0.6462
Epoch 87/100, Loss: 0.6719, Acc: 0.5960, Val Loss: 0.6462, Val Acc: 0.6726
Epoch 88/100, Loss: 0.6719, Acc: 0.5981, Val Loss: 0.6462, Val Acc: 0.6729
Epoch 89/100, Loss: 0.6719, Acc: 0.5974, Val Loss: 0.6461, Val Acc: 0.6740
Mejor modelo guardado con Val Loss: 0.6461
Epoch 90/100, Loss: 0.6719, Acc: 0.5969, Val Loss: 0.6461, Val Acc: 0.6726
Epoch 91/100, Loss: 0.6718, Acc: 0.5971, Val Loss: 0.6460, Val Acc: 0.6733
Mejor modelo guardado con Val Loss: 0.6460
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6715, Acc: 0.5966, Val Loss: 0.6471, Val Acc: 0.6718
Epoch 93/100, Loss: 0.6709, Acc: 0.5973, Val Loss: 0.6478, Val Acc: 0.6722
Epoch 94/100, Loss: 0.6708, Acc: 0.5981, Val Loss: 0.6475, Val Acc: 0.6740
Epoch 95/100, Loss: 0.6709, Acc: 0.5956, Val Loss: 0.6478, Val Acc: 0.6733
Epoch 96/100, Loss: 0.6708, Acc: 0.5965, Val Loss: 0.6475, Val Acc: 0.6726
Epoch 97/100, Loss: 0.6707, Acc: 0.5971, Val Loss: 0.6475, Val Acc: 0.6722
Epoch 98/100, Loss: 0.6707, Acc: 0.5952, Val Loss: 0.6475, Val Acc: 0.6740
Epoch 99/100, Loss: 0.6707, Acc: 0.5959, Val Loss: 0.6474, Val Acc: 0.6729
Epoch 100/100, Loss: 0.6707, Acc: 0.5958, Val Loss: 0.6474, Val Acc: 0.6729

##############################
Resultados para principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3 
 {'training': [0.6707003465643874, 0.5957896672182387, 0.5783531536956195, 0.7065097462302317, 0.6360400629086996], 'validate': [0.6474173470985057, 0.6729212656364975, 0.6886564762670957, 0.6303387334315169, 0.6582083813917724], 'test': [0.7066927706753766, 0.4885226603884638, 0.49125874125874125, 0.6619552414605419, 0.5639739086803813]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  011  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  011  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6893, Acc: 0.5350, Val Loss: 0.6813, Val Acc: 0.6803
Mejor modelo guardado con Val Loss: 0.6813
Epoch 2/100, Loss: 0.6885, Acc: 0.5483, Val Loss: 0.6747, Val Acc: 0.7425
Mejor modelo guardado con Val Loss: 0.6747
Epoch 3/100, Loss: 0.6885, Acc: 0.5398, Val Loss: 0.6649, Val Acc: 0.7704
Mejor modelo guardado con Val Loss: 0.6649
Epoch 4/100, Loss: 0.6860, Acc: 0.5641, Val Loss: 0.6689, Val Acc: 0.6376
Epoch 5/100, Loss: 0.6836, Acc: 0.5725, Val Loss: 0.6894, Val Acc: 0.5434
Epoch 6/100, Loss: 0.6795, Acc: 0.5811, Val Loss: 0.6301, Val Acc: 0.7980
Mejor modelo guardado con Val Loss: 0.6301
Epoch 7/100, Loss: 0.6779, Acc: 0.5821, Val Loss: 0.6252, Val Acc: 0.7940
Mejor modelo guardado con Val Loss: 0.6252
Epoch 8/100, Loss: 0.6750, Acc: 0.5914, Val Loss: 0.6159, Val Acc: 0.8028
Mejor modelo guardado con Val Loss: 0.6159
Epoch 9/100, Loss: 0.6745, Acc: 0.5874, Val Loss: 0.6123, Val Acc: 0.7862
Mejor modelo guardado con Val Loss: 0.6123
Epoch 10/100, Loss: 0.6718, Acc: 0.5960, Val Loss: 0.6012, Val Acc: 0.7987
Mejor modelo guardado con Val Loss: 0.6012
Epoch 11/100, Loss: 0.6727, Acc: 0.5893, Val Loss: 0.6079, Val Acc: 0.7763
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6667, Acc: 0.6043, Val Loss: 0.5951, Val Acc: 0.7980
Mejor modelo guardado con Val Loss: 0.5951
Epoch 13/100, Loss: 0.6665, Acc: 0.6050, Val Loss: 0.6089, Val Acc: 0.7535
Epoch 14/100, Loss: 0.6657, Acc: 0.6061, Val Loss: 0.5941, Val Acc: 0.7947
Mejor modelo guardado con Val Loss: 0.5941
Epoch 15/100, Loss: 0.6654, Acc: 0.6047, Val Loss: 0.5869, Val Acc: 0.7991
Mejor modelo guardado con Val Loss: 0.5869
Epoch 16/100, Loss: 0.6648, Acc: 0.6086, Val Loss: 0.5823, Val Acc: 0.8050
Mejor modelo guardado con Val Loss: 0.5823
Epoch 17/100, Loss: 0.6639, Acc: 0.6077, Val Loss: 0.5832, Val Acc: 0.7991
Epoch 18/100, Loss: 0.6644, Acc: 0.6046, Val Loss: 0.6030, Val Acc: 0.7513
Epoch 19/100, Loss: 0.6636, Acc: 0.6076, Val Loss: 0.5986, Val Acc: 0.7601
Epoch 20/100, Loss: 0.6622, Acc: 0.6082, Val Loss: 0.5746, Val Acc: 0.8057
Mejor modelo guardado con Val Loss: 0.5746
Epoch 21/100, Loss: 0.6646, Acc: 0.6033, Val Loss: 0.5767, Val Acc: 0.8006
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6614, Acc: 0.6119, Val Loss: 0.5803, Val Acc: 0.7914
Epoch 23/100, Loss: 0.6619, Acc: 0.6095, Val Loss: 0.5848, Val Acc: 0.7792
Epoch 24/100, Loss: 0.6612, Acc: 0.6101, Val Loss: 0.5707, Val Acc: 0.8087
Mejor modelo guardado con Val Loss: 0.5707
Epoch 25/100, Loss: 0.6614, Acc: 0.6097, Val Loss: 0.5802, Val Acc: 0.7892
Epoch 26/100, Loss: 0.6615, Acc: 0.6100, Val Loss: 0.5699, Val Acc: 0.8076
Mejor modelo guardado con Val Loss: 0.5699
Epoch 27/100, Loss: 0.6609, Acc: 0.6132, Val Loss: 0.5756, Val Acc: 0.7936
Epoch 28/100, Loss: 0.6607, Acc: 0.6105, Val Loss: 0.5813, Val Acc: 0.7796
Epoch 29/100, Loss: 0.6605, Acc: 0.6150, Val Loss: 0.5719, Val Acc: 0.8006
Epoch 30/100, Loss: 0.6601, Acc: 0.6147, Val Loss: 0.5734, Val Acc: 0.7943
Epoch 31/100, Loss: 0.6603, Acc: 0.6130, Val Loss: 0.5781, Val Acc: 0.7877
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6599, Acc: 0.6116, Val Loss: 0.5765, Val Acc: 0.7873
Epoch 33/100, Loss: 0.6595, Acc: 0.6145, Val Loss: 0.5744, Val Acc: 0.7903
Epoch 34/100, Loss: 0.6598, Acc: 0.6138, Val Loss: 0.5727, Val Acc: 0.7943
Epoch 35/100, Loss: 0.6594, Acc: 0.6141, Val Loss: 0.5769, Val Acc: 0.7932
Epoch 36/100, Loss: 0.6585, Acc: 0.6133, Val Loss: 0.5729, Val Acc: 0.7991
Epoch 37/100, Loss: 0.6579, Acc: 0.6141, Val Loss: 0.5770, Val Acc: 0.7918
Epoch 38/100, Loss: 0.6567, Acc: 0.6138, Val Loss: 0.5700, Val Acc: 0.8024
Epoch 39/100, Loss: 0.6568, Acc: 0.6133, Val Loss: 0.5718, Val Acc: 0.7995
Epoch 40/100, Loss: 0.6565, Acc: 0.6150, Val Loss: 0.5785, Val Acc: 0.7881
Epoch 41/100, Loss: 0.6558, Acc: 0.6136, Val Loss: 0.5779, Val Acc: 0.7929
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6556, Acc: 0.6167, Val Loss: 0.5779, Val Acc: 0.7918
Epoch 43/100, Loss: 0.6556, Acc: 0.6152, Val Loss: 0.5751, Val Acc: 0.7951
Epoch 44/100, Loss: 0.6551, Acc: 0.6163, Val Loss: 0.5759, Val Acc: 0.7932
Epoch 45/100, Loss: 0.6550, Acc: 0.6174, Val Loss: 0.5747, Val Acc: 0.7936
Epoch 46/100, Loss: 0.6547, Acc: 0.6163, Val Loss: 0.5846, Val Acc: 0.7792
Epoch 47/100, Loss: 0.6550, Acc: 0.6159, Val Loss: 0.5753, Val Acc: 0.7936
Epoch 48/100, Loss: 0.6547, Acc: 0.6171, Val Loss: 0.5781, Val Acc: 0.7921
Epoch 49/100, Loss: 0.6545, Acc: 0.6168, Val Loss: 0.5779, Val Acc: 0.7910
Epoch 50/100, Loss: 0.6544, Acc: 0.6192, Val Loss: 0.5787, Val Acc: 0.7903
Epoch 51/100, Loss: 0.6542, Acc: 0.6170, Val Loss: 0.5764, Val Acc: 0.7929
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6538, Acc: 0.6191, Val Loss: 0.5725, Val Acc: 0.7943
Epoch 53/100, Loss: 0.6536, Acc: 0.6191, Val Loss: 0.5741, Val Acc: 0.7951
Epoch 54/100, Loss: 0.6535, Acc: 0.6236, Val Loss: 0.5776, Val Acc: 0.7888
Epoch 55/100, Loss: 0.6532, Acc: 0.6233, Val Loss: 0.5792, Val Acc: 0.7866
Epoch 56/100, Loss: 0.6533, Acc: 0.6228, Val Loss: 0.5754, Val Acc: 0.7907
Epoch 57/100, Loss: 0.6532, Acc: 0.6225, Val Loss: 0.5762, Val Acc: 0.7907
Epoch 58/100, Loss: 0.6531, Acc: 0.6232, Val Loss: 0.5760, Val Acc: 0.7899
Epoch 59/100, Loss: 0.6529, Acc: 0.6234, Val Loss: 0.5769, Val Acc: 0.7899
Epoch 60/100, Loss: 0.6528, Acc: 0.6238, Val Loss: 0.5732, Val Acc: 0.7969
Epoch 61/100, Loss: 0.6529, Acc: 0.6243, Val Loss: 0.5758, Val Acc: 0.7921
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6525, Acc: 0.6232, Val Loss: 0.5772, Val Acc: 0.7899
Epoch 63/100, Loss: 0.6525, Acc: 0.6259, Val Loss: 0.5764, Val Acc: 0.7910
Epoch 64/100, Loss: 0.6525, Acc: 0.6246, Val Loss: 0.5756, Val Acc: 0.7910
Epoch 65/100, Loss: 0.6524, Acc: 0.6255, Val Loss: 0.5774, Val Acc: 0.7903
Epoch 66/100, Loss: 0.6523, Acc: 0.6261, Val Loss: 0.5766, Val Acc: 0.7899
Epoch 67/100, Loss: 0.6522, Acc: 0.6269, Val Loss: 0.5750, Val Acc: 0.7936
Epoch 68/100, Loss: 0.6514, Acc: 0.6289, Val Loss: 0.5760, Val Acc: 0.7918
Epoch 69/100, Loss: 0.6509, Acc: 0.6314, Val Loss: 0.5743, Val Acc: 0.7910
Epoch 70/100, Loss: 0.6507, Acc: 0.6303, Val Loss: 0.5748, Val Acc: 0.7918
Epoch 71/100, Loss: 0.6507, Acc: 0.6307, Val Loss: 0.5751, Val Acc: 0.7896
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6505, Acc: 0.6326, Val Loss: 0.5743, Val Acc: 0.7903
Epoch 73/100, Loss: 0.6504, Acc: 0.6320, Val Loss: 0.5739, Val Acc: 0.7914
Epoch 74/100, Loss: 0.6504, Acc: 0.6324, Val Loss: 0.5746, Val Acc: 0.7907
Epoch 75/100, Loss: 0.6504, Acc: 0.6325, Val Loss: 0.5750, Val Acc: 0.7884
Epoch 76/100, Loss: 0.6503, Acc: 0.6325, Val Loss: 0.5748, Val Acc: 0.7881
Epoch 77/100, Loss: 0.6503, Acc: 0.6328, Val Loss: 0.5742, Val Acc: 0.7884
Epoch 78/100, Loss: 0.6503, Acc: 0.6327, Val Loss: 0.5748, Val Acc: 0.7877
Epoch 79/100, Loss: 0.6502, Acc: 0.6332, Val Loss: 0.5740, Val Acc: 0.7877
Epoch 80/100, Loss: 0.6502, Acc: 0.6334, Val Loss: 0.5740, Val Acc: 0.7888
Epoch 81/100, Loss: 0.6501, Acc: 0.6326, Val Loss: 0.5737, Val Acc: 0.7877
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6501, Acc: 0.6337, Val Loss: 0.5730, Val Acc: 0.7896
Epoch 83/100, Loss: 0.6501, Acc: 0.6332, Val Loss: 0.5746, Val Acc: 0.7873
Epoch 84/100, Loss: 0.6500, Acc: 0.6334, Val Loss: 0.5738, Val Acc: 0.7884
Epoch 85/100, Loss: 0.6500, Acc: 0.6345, Val Loss: 0.5739, Val Acc: 0.7877
Epoch 86/100, Loss: 0.6499, Acc: 0.6348, Val Loss: 0.5735, Val Acc: 0.7884
Epoch 87/100, Loss: 0.6499, Acc: 0.6330, Val Loss: 0.5749, Val Acc: 0.7870
Epoch 88/100, Loss: 0.6499, Acc: 0.6339, Val Loss: 0.5746, Val Acc: 0.7870
Epoch 89/100, Loss: 0.6499, Acc: 0.6337, Val Loss: 0.5734, Val Acc: 0.7870
Epoch 90/100, Loss: 0.6498, Acc: 0.6329, Val Loss: 0.5737, Val Acc: 0.7870
Epoch 91/100, Loss: 0.6497, Acc: 0.6336, Val Loss: 0.5745, Val Acc: 0.7866
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6496, Acc: 0.6338, Val Loss: 0.5740, Val Acc: 0.7877
Epoch 93/100, Loss: 0.6496, Acc: 0.6329, Val Loss: 0.5737, Val Acc: 0.7873
Epoch 94/100, Loss: 0.6495, Acc: 0.6351, Val Loss: 0.5734, Val Acc: 0.7881
Epoch 95/100, Loss: 0.6495, Acc: 0.6345, Val Loss: 0.5741, Val Acc: 0.7870
Epoch 96/100, Loss: 0.6495, Acc: 0.6341, Val Loss: 0.5742, Val Acc: 0.7862
Epoch 97/100, Loss: 0.6494, Acc: 0.6344, Val Loss: 0.5735, Val Acc: 0.7873
Epoch 98/100, Loss: 0.6494, Acc: 0.6346, Val Loss: 0.5734, Val Acc: 0.7881
Epoch 99/100, Loss: 0.6493, Acc: 0.6351, Val Loss: 0.5735, Val Acc: 0.7873
Epoch 100/100, Loss: 0.6493, Acc: 0.6350, Val Loss: 0.5742, Val Acc: 0.7862

##############################
Resultados para principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3 
 {'training': [0.6492865306639807, 0.6350432064717779, 0.6134116192830655, 0.7300478116954763, 0.6666666666666666], 'validate': [0.5741702470668527, 0.7862398822663723, 0.7294743059657413, 0.9094256259204713, 0.8095706325794821], 'test': [0.7089081903298696, 0.5164802825191289, 0.5116673737802291, 0.7102473498233216, 0.5948212083847102]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  021  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  021  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5946, Acc: 0.7154, Val Loss: 0.4597, Val Acc: 0.8749
Mejor modelo guardado con Val Loss: 0.4597
Epoch 2/100, Loss: 0.5484, Acc: 0.7345, Val Loss: 0.4346, Val Acc: 0.8576
Mejor modelo guardado con Val Loss: 0.4346
Epoch 3/100, Loss: 0.5278, Acc: 0.7386, Val Loss: 0.4094, Val Acc: 0.8488
Mejor modelo guardado con Val Loss: 0.4094
Epoch 4/100, Loss: 0.5247, Acc: 0.7416, Val Loss: 0.4902, Val Acc: 0.7833
Epoch 5/100, Loss: 0.5176, Acc: 0.7416, Val Loss: 0.3970, Val Acc: 0.8525
Mejor modelo guardado con Val Loss: 0.3970
Epoch 6/100, Loss: 0.5133, Acc: 0.7465, Val Loss: 0.4386, Val Acc: 0.8102
Epoch 7/100, Loss: 0.5162, Acc: 0.7426, Val Loss: 0.4237, Val Acc: 0.8127
Epoch 8/100, Loss: 0.5119, Acc: 0.7451, Val Loss: 0.4406, Val Acc: 0.8157
Epoch 9/100, Loss: 0.5133, Acc: 0.7441, Val Loss: 0.3878, Val Acc: 0.8444
Mejor modelo guardado con Val Loss: 0.3878
Epoch 10/100, Loss: 0.5104, Acc: 0.7465, Val Loss: 0.3701, Val Acc: 0.8753
Mejor modelo guardado con Val Loss: 0.3701
Epoch 11/100, Loss: 0.5099, Acc: 0.7474, Val Loss: 0.3774, Val Acc: 0.8701
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5023, Acc: 0.7551, Val Loss: 0.3813, Val Acc: 0.8517
Epoch 13/100, Loss: 0.4979, Acc: 0.7571, Val Loss: 0.3655, Val Acc: 0.8672
Mejor modelo guardado con Val Loss: 0.3655
Epoch 14/100, Loss: 0.4984, Acc: 0.7540, Val Loss: 0.4076, Val Acc: 0.8396
Epoch 15/100, Loss: 0.4976, Acc: 0.7510, Val Loss: 0.3912, Val Acc: 0.8385
Epoch 16/100, Loss: 0.4981, Acc: 0.7552, Val Loss: 0.3753, Val Acc: 0.8613
Epoch 17/100, Loss: 0.4961, Acc: 0.7541, Val Loss: 0.4159, Val Acc: 0.8116
Epoch 18/100, Loss: 0.4987, Acc: 0.7543, Val Loss: 0.3749, Val Acc: 0.8631
Epoch 19/100, Loss: 0.5006, Acc: 0.7530, Val Loss: 0.4082, Val Acc: 0.8271
Epoch 20/100, Loss: 0.5000, Acc: 0.7475, Val Loss: 0.3886, Val Acc: 0.8411
Epoch 21/100, Loss: 0.4985, Acc: 0.7535, Val Loss: 0.3960, Val Acc: 0.8532
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4953, Acc: 0.7545, Val Loss: 0.3959, Val Acc: 0.8433
Epoch 23/100, Loss: 0.4910, Acc: 0.7557, Val Loss: 0.3985, Val Acc: 0.8425
Epoch 24/100, Loss: 0.4910, Acc: 0.7575, Val Loss: 0.3590, Val Acc: 0.8694
Mejor modelo guardado con Val Loss: 0.3590
Epoch 25/100, Loss: 0.4903, Acc: 0.7583, Val Loss: 0.3952, Val Acc: 0.8366
Epoch 26/100, Loss: 0.4906, Acc: 0.7564, Val Loss: 0.3704, Val Acc: 0.8624
Epoch 27/100, Loss: 0.4906, Acc: 0.7539, Val Loss: 0.3614, Val Acc: 0.8595
Epoch 28/100, Loss: 0.4884, Acc: 0.7566, Val Loss: 0.3794, Val Acc: 0.8576
Epoch 29/100, Loss: 0.4894, Acc: 0.7587, Val Loss: 0.3904, Val Acc: 0.8267
Epoch 30/100, Loss: 0.4887, Acc: 0.7562, Val Loss: 0.3548, Val Acc: 0.8624
Mejor modelo guardado con Val Loss: 0.3548
Epoch 31/100, Loss: 0.4891, Acc: 0.7584, Val Loss: 0.3461, Val Acc: 0.8720
Mejor modelo guardado con Val Loss: 0.3461
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4877, Acc: 0.7582, Val Loss: 0.3849, Val Acc: 0.8455
Epoch 33/100, Loss: 0.4858, Acc: 0.7581, Val Loss: 0.3880, Val Acc: 0.8440
Epoch 34/100, Loss: 0.4856, Acc: 0.7606, Val Loss: 0.3783, Val Acc: 0.8514
Epoch 35/100, Loss: 0.4860, Acc: 0.7594, Val Loss: 0.3755, Val Acc: 0.8532
Epoch 36/100, Loss: 0.4860, Acc: 0.7581, Val Loss: 0.3708, Val Acc: 0.8550
Epoch 37/100, Loss: 0.4853, Acc: 0.7625, Val Loss: 0.3700, Val Acc: 0.8609
Epoch 38/100, Loss: 0.4848, Acc: 0.7603, Val Loss: 0.3720, Val Acc: 0.8444
Epoch 39/100, Loss: 0.4853, Acc: 0.7579, Val Loss: 0.3800, Val Acc: 0.8525
Epoch 40/100, Loss: 0.4855, Acc: 0.7575, Val Loss: 0.3664, Val Acc: 0.8646
Epoch 41/100, Loss: 0.4856, Acc: 0.7558, Val Loss: 0.3671, Val Acc: 0.8584
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4844, Acc: 0.7577, Val Loss: 0.3811, Val Acc: 0.8591
Epoch 43/100, Loss: 0.4842, Acc: 0.7583, Val Loss: 0.3693, Val Acc: 0.8598
Epoch 44/100, Loss: 0.4841, Acc: 0.7592, Val Loss: 0.3724, Val Acc: 0.8642
Epoch 45/100, Loss: 0.4840, Acc: 0.7583, Val Loss: 0.3807, Val Acc: 0.8580
Epoch 46/100, Loss: 0.4836, Acc: 0.7578, Val Loss: 0.3762, Val Acc: 0.8631
Epoch 47/100, Loss: 0.4833, Acc: 0.7601, Val Loss: 0.3701, Val Acc: 0.8572
Epoch 48/100, Loss: 0.4837, Acc: 0.7584, Val Loss: 0.3749, Val Acc: 0.8606
Epoch 49/100, Loss: 0.4832, Acc: 0.7596, Val Loss: 0.3706, Val Acc: 0.8576
Epoch 50/100, Loss: 0.4834, Acc: 0.7582, Val Loss: 0.3777, Val Acc: 0.8543
Epoch 51/100, Loss: 0.4830, Acc: 0.7597, Val Loss: 0.3671, Val Acc: 0.8598
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4825, Acc: 0.7595, Val Loss: 0.3751, Val Acc: 0.8561
Epoch 53/100, Loss: 0.4825, Acc: 0.7603, Val Loss: 0.3743, Val Acc: 0.8550
Epoch 54/100, Loss: 0.4822, Acc: 0.7604, Val Loss: 0.3781, Val Acc: 0.8554
Epoch 55/100, Loss: 0.4825, Acc: 0.7614, Val Loss: 0.3737, Val Acc: 0.8580
Epoch 56/100, Loss: 0.4823, Acc: 0.7606, Val Loss: 0.3730, Val Acc: 0.8572
Epoch 57/100, Loss: 0.4822, Acc: 0.7610, Val Loss: 0.3766, Val Acc: 0.8561
Epoch 58/100, Loss: 0.4823, Acc: 0.7600, Val Loss: 0.3709, Val Acc: 0.8569
Epoch 59/100, Loss: 0.4819, Acc: 0.7602, Val Loss: 0.3627, Val Acc: 0.8606
Epoch 60/100, Loss: 0.4820, Acc: 0.7602, Val Loss: 0.3729, Val Acc: 0.8561
Epoch 61/100, Loss: 0.4819, Acc: 0.7641, Val Loss: 0.3673, Val Acc: 0.8595
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4817, Acc: 0.7613, Val Loss: 0.3716, Val Acc: 0.8576
Epoch 63/100, Loss: 0.4815, Acc: 0.7620, Val Loss: 0.3718, Val Acc: 0.8587
Epoch 64/100, Loss: 0.4816, Acc: 0.7617, Val Loss: 0.3689, Val Acc: 0.8576
Epoch 65/100, Loss: 0.4815, Acc: 0.7619, Val Loss: 0.3724, Val Acc: 0.8580
Epoch 66/100, Loss: 0.4814, Acc: 0.7614, Val Loss: 0.3730, Val Acc: 0.8558
Epoch 67/100, Loss: 0.4812, Acc: 0.7619, Val Loss: 0.3705, Val Acc: 0.8580
Epoch 68/100, Loss: 0.4816, Acc: 0.7608, Val Loss: 0.3713, Val Acc: 0.8576
Epoch 69/100, Loss: 0.4815, Acc: 0.7611, Val Loss: 0.3717, Val Acc: 0.8572
Epoch 70/100, Loss: 0.4813, Acc: 0.7620, Val Loss: 0.3704, Val Acc: 0.8587
Epoch 71/100, Loss: 0.4812, Acc: 0.7616, Val Loss: 0.3754, Val Acc: 0.8521
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4810, Acc: 0.7625, Val Loss: 0.3726, Val Acc: 0.8576
Epoch 73/100, Loss: 0.4810, Acc: 0.7623, Val Loss: 0.3695, Val Acc: 0.8598
Epoch 74/100, Loss: 0.4810, Acc: 0.7627, Val Loss: 0.3713, Val Acc: 0.8595
Epoch 75/100, Loss: 0.4809, Acc: 0.7621, Val Loss: 0.3709, Val Acc: 0.8584
Epoch 76/100, Loss: 0.4809, Acc: 0.7624, Val Loss: 0.3722, Val Acc: 0.8569
Epoch 77/100, Loss: 0.4810, Acc: 0.7627, Val Loss: 0.3733, Val Acc: 0.8576
Epoch 78/100, Loss: 0.4809, Acc: 0.7630, Val Loss: 0.3704, Val Acc: 0.8584
Epoch 79/100, Loss: 0.4810, Acc: 0.7630, Val Loss: 0.3701, Val Acc: 0.8580
Epoch 80/100, Loss: 0.4809, Acc: 0.7630, Val Loss: 0.3711, Val Acc: 0.8598
Epoch 81/100, Loss: 0.4809, Acc: 0.7620, Val Loss: 0.3714, Val Acc: 0.8576
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4808, Acc: 0.7624, Val Loss: 0.3712, Val Acc: 0.8572
Epoch 83/100, Loss: 0.4808, Acc: 0.7628, Val Loss: 0.3723, Val Acc: 0.8572
Epoch 84/100, Loss: 0.4808, Acc: 0.7633, Val Loss: 0.3709, Val Acc: 0.8572
Epoch 85/100, Loss: 0.4808, Acc: 0.7625, Val Loss: 0.3702, Val Acc: 0.8580
Epoch 86/100, Loss: 0.4808, Acc: 0.7635, Val Loss: 0.3711, Val Acc: 0.8569
Epoch 87/100, Loss: 0.4808, Acc: 0.7628, Val Loss: 0.3710, Val Acc: 0.8576
Epoch 88/100, Loss: 0.4807, Acc: 0.7636, Val Loss: 0.3686, Val Acc: 0.8595
Epoch 89/100, Loss: 0.4807, Acc: 0.7625, Val Loss: 0.3712, Val Acc: 0.8572
Epoch 90/100, Loss: 0.4807, Acc: 0.7624, Val Loss: 0.3720, Val Acc: 0.8569
Epoch 91/100, Loss: 0.4807, Acc: 0.7640, Val Loss: 0.3718, Val Acc: 0.8576
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4806, Acc: 0.7629, Val Loss: 0.3711, Val Acc: 0.8576
Epoch 93/100, Loss: 0.4806, Acc: 0.7633, Val Loss: 0.3704, Val Acc: 0.8572
Epoch 94/100, Loss: 0.4807, Acc: 0.7625, Val Loss: 0.3721, Val Acc: 0.8561
Epoch 95/100, Loss: 0.4805, Acc: 0.7640, Val Loss: 0.3699, Val Acc: 0.8569
Epoch 96/100, Loss: 0.4806, Acc: 0.7628, Val Loss: 0.3715, Val Acc: 0.8565
Epoch 97/100, Loss: 0.4806, Acc: 0.7640, Val Loss: 0.3716, Val Acc: 0.8561
Epoch 98/100, Loss: 0.4806, Acc: 0.7628, Val Loss: 0.3719, Val Acc: 0.8565
Epoch 99/100, Loss: 0.4806, Acc: 0.7630, Val Loss: 0.3716, Val Acc: 0.8558
Epoch 100/100, Loss: 0.4805, Acc: 0.7634, Val Loss: 0.3704, Val Acc: 0.8569

##############################
Resultados para principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3 
 {'training': [0.48048607909979685, 0.7633756205184776, 0.7548042704626334, 0.780066200809121, 0.7672273467173087], 'validate': [0.3703746409263722, 0.8568800588668138, 0.8119768190598841, 0.9285714285714286, 0.8663689453795946], 'test': [0.3800140831757475, 0.8228369629193644, 0.8558441558441559, 0.7762073027090695, 0.81408276714021]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  008  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  008  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6762, Acc: 0.5973, Val Loss: 0.7074, Val Acc: 0.4352
Mejor modelo guardado con Val Loss: 0.7074
Epoch 2/100, Loss: 0.6633, Acc: 0.6197, Val Loss: 0.7259, Val Acc: 0.4334
Epoch 3/100, Loss: 0.6571, Acc: 0.6259, Val Loss: 0.7329, Val Acc: 0.4687
Epoch 4/100, Loss: 0.6533, Acc: 0.6310, Val Loss: 0.7185, Val Acc: 0.4485
Epoch 5/100, Loss: 0.6447, Acc: 0.6453, Val Loss: 0.7676, Val Acc: 0.4323
Epoch 6/100, Loss: 0.6397, Acc: 0.6414, Val Loss: 0.7593, Val Acc: 0.4249
Epoch 7/100, Loss: 0.6314, Acc: 0.6491, Val Loss: 0.7409, Val Acc: 0.4316
Epoch 8/100, Loss: 0.6288, Acc: 0.6552, Val Loss: 0.7858, Val Acc: 0.4205
Epoch 9/100, Loss: 0.6323, Acc: 0.6521, Val Loss: 0.7834, Val Acc: 0.4235
Epoch 10/100, Loss: 0.6274, Acc: 0.6543, Val Loss: 0.7978, Val Acc: 0.4352
Epoch 11/100, Loss: 0.6338, Acc: 0.6480, Val Loss: 0.7556, Val Acc: 0.4319
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6288, Acc: 0.6635, Val Loss: 0.7702, Val Acc: 0.4595
Epoch 13/100, Loss: 0.6255, Acc: 0.6585, Val Loss: 0.7786, Val Acc: 0.4422
Epoch 14/100, Loss: 0.6253, Acc: 0.6609, Val Loss: 0.7833, Val Acc: 0.4430
Epoch 15/100, Loss: 0.6241, Acc: 0.6587, Val Loss: 0.7825, Val Acc: 0.4570
Epoch 16/100, Loss: 0.6225, Acc: 0.6629, Val Loss: 0.7844, Val Acc: 0.4433
Epoch 17/100, Loss: 0.6218, Acc: 0.6620, Val Loss: 0.7901, Val Acc: 0.4448
Epoch 18/100, Loss: 0.6249, Acc: 0.6584, Val Loss: 0.7747, Val Acc: 0.4257
Epoch 19/100, Loss: 0.6214, Acc: 0.6622, Val Loss: 0.8008, Val Acc: 0.4352
Epoch 20/100, Loss: 0.6195, Acc: 0.6678, Val Loss: 0.7942, Val Acc: 0.4455
Epoch 21/100, Loss: 0.6206, Acc: 0.6646, Val Loss: 0.7891, Val Acc: 0.4441
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6174, Acc: 0.6654, Val Loss: 0.8087, Val Acc: 0.4386
Epoch 23/100, Loss: 0.6164, Acc: 0.6691, Val Loss: 0.7954, Val Acc: 0.4400
Epoch 24/100, Loss: 0.6168, Acc: 0.6657, Val Loss: 0.7927, Val Acc: 0.4448
Epoch 25/100, Loss: 0.6152, Acc: 0.6683, Val Loss: 0.7968, Val Acc: 0.4411
Epoch 26/100, Loss: 0.6156, Acc: 0.6680, Val Loss: 0.7959, Val Acc: 0.4415
Epoch 27/100, Loss: 0.6154, Acc: 0.6694, Val Loss: 0.8046, Val Acc: 0.4474
Epoch 28/100, Loss: 0.6146, Acc: 0.6724, Val Loss: 0.8142, Val Acc: 0.4389
Epoch 29/100, Loss: 0.6135, Acc: 0.6722, Val Loss: 0.8054, Val Acc: 0.4260
Epoch 30/100, Loss: 0.6143, Acc: 0.6703, Val Loss: 0.8023, Val Acc: 0.4341
Epoch 31/100, Loss: 0.6136, Acc: 0.6746, Val Loss: 0.8010, Val Acc: 0.4356
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6113, Acc: 0.6765, Val Loss: 0.8107, Val Acc: 0.4386
Epoch 33/100, Loss: 0.6115, Acc: 0.6743, Val Loss: 0.8083, Val Acc: 0.4433
Epoch 34/100, Loss: 0.6115, Acc: 0.6747, Val Loss: 0.8085, Val Acc: 0.4400
Epoch 35/100, Loss: 0.6112, Acc: 0.6753, Val Loss: 0.7944, Val Acc: 0.4389
Epoch 36/100, Loss: 0.6112, Acc: 0.6758, Val Loss: 0.8079, Val Acc: 0.4411
Epoch 37/100, Loss: 0.6108, Acc: 0.6746, Val Loss: 0.8072, Val Acc: 0.4389
Epoch 38/100, Loss: 0.6104, Acc: 0.6787, Val Loss: 0.7965, Val Acc: 0.4408
Epoch 39/100, Loss: 0.6103, Acc: 0.6805, Val Loss: 0.8050, Val Acc: 0.4389
Epoch 40/100, Loss: 0.6102, Acc: 0.6779, Val Loss: 0.8099, Val Acc: 0.4356
Epoch 41/100, Loss: 0.6106, Acc: 0.6776, Val Loss: 0.8072, Val Acc: 0.4389
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6090, Acc: 0.6801, Val Loss: 0.8122, Val Acc: 0.4367
Epoch 43/100, Loss: 0.6093, Acc: 0.6777, Val Loss: 0.8101, Val Acc: 0.4364
Epoch 44/100, Loss: 0.6086, Acc: 0.6805, Val Loss: 0.8052, Val Acc: 0.4330
Epoch 45/100, Loss: 0.6091, Acc: 0.6794, Val Loss: 0.8144, Val Acc: 0.4327
Epoch 46/100, Loss: 0.6084, Acc: 0.6790, Val Loss: 0.8057, Val Acc: 0.4382
Epoch 47/100, Loss: 0.6085, Acc: 0.6798, Val Loss: 0.8166, Val Acc: 0.4371
Epoch 48/100, Loss: 0.6091, Acc: 0.6792, Val Loss: 0.8131, Val Acc: 0.4378
Epoch 49/100, Loss: 0.6087, Acc: 0.6796, Val Loss: 0.8098, Val Acc: 0.4375
Epoch 50/100, Loss: 0.6084, Acc: 0.6805, Val Loss: 0.8103, Val Acc: 0.4312
Epoch 51/100, Loss: 0.6083, Acc: 0.6816, Val Loss: 0.8172, Val Acc: 0.4364
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6079, Acc: 0.6817, Val Loss: 0.8130, Val Acc: 0.4356
Epoch 53/100, Loss: 0.6076, Acc: 0.6800, Val Loss: 0.8126, Val Acc: 0.4345
Epoch 54/100, Loss: 0.6077, Acc: 0.6812, Val Loss: 0.8117, Val Acc: 0.4364
Epoch 55/100, Loss: 0.6075, Acc: 0.6810, Val Loss: 0.8106, Val Acc: 0.4367
Epoch 56/100, Loss: 0.6073, Acc: 0.6814, Val Loss: 0.8113, Val Acc: 0.4397
Epoch 57/100, Loss: 0.6071, Acc: 0.6809, Val Loss: 0.8123, Val Acc: 0.4341
Epoch 58/100, Loss: 0.6069, Acc: 0.6807, Val Loss: 0.8097, Val Acc: 0.4349
Epoch 59/100, Loss: 0.6067, Acc: 0.6807, Val Loss: 0.8120, Val Acc: 0.4312
Epoch 60/100, Loss: 0.6062, Acc: 0.6813, Val Loss: 0.8151, Val Acc: 0.4301
Epoch 61/100, Loss: 0.6061, Acc: 0.6822, Val Loss: 0.8158, Val Acc: 0.4338
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6057, Acc: 0.6814, Val Loss: 0.8155, Val Acc: 0.4297
Epoch 63/100, Loss: 0.6057, Acc: 0.6827, Val Loss: 0.8155, Val Acc: 0.4323
Epoch 64/100, Loss: 0.6056, Acc: 0.6832, Val Loss: 0.8150, Val Acc: 0.4334
Epoch 65/100, Loss: 0.6055, Acc: 0.6817, Val Loss: 0.8149, Val Acc: 0.4316
Epoch 66/100, Loss: 0.6053, Acc: 0.6834, Val Loss: 0.8155, Val Acc: 0.4290
Epoch 67/100, Loss: 0.6056, Acc: 0.6828, Val Loss: 0.8154, Val Acc: 0.4312
Epoch 68/100, Loss: 0.6054, Acc: 0.6835, Val Loss: 0.8151, Val Acc: 0.4316
Epoch 69/100, Loss: 0.6053, Acc: 0.6820, Val Loss: 0.8157, Val Acc: 0.4308
Epoch 70/100, Loss: 0.6054, Acc: 0.6828, Val Loss: 0.8154, Val Acc: 0.4319
Epoch 71/100, Loss: 0.6052, Acc: 0.6815, Val Loss: 0.8169, Val Acc: 0.4308
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6052, Acc: 0.6824, Val Loss: 0.8165, Val Acc: 0.4345
Epoch 73/100, Loss: 0.6051, Acc: 0.6830, Val Loss: 0.8162, Val Acc: 0.4327
Epoch 74/100, Loss: 0.6050, Acc: 0.6833, Val Loss: 0.8164, Val Acc: 0.4323
Epoch 75/100, Loss: 0.6050, Acc: 0.6828, Val Loss: 0.8163, Val Acc: 0.4319
Epoch 76/100, Loss: 0.6050, Acc: 0.6825, Val Loss: 0.8166, Val Acc: 0.4327
Epoch 77/100, Loss: 0.6049, Acc: 0.6833, Val Loss: 0.8166, Val Acc: 0.4319
Epoch 78/100, Loss: 0.6049, Acc: 0.6817, Val Loss: 0.8166, Val Acc: 0.4301
Epoch 79/100, Loss: 0.6048, Acc: 0.6842, Val Loss: 0.8165, Val Acc: 0.4308
Epoch 80/100, Loss: 0.6048, Acc: 0.6837, Val Loss: 0.8160, Val Acc: 0.4312
Epoch 81/100, Loss: 0.6047, Acc: 0.6830, Val Loss: 0.8168, Val Acc: 0.4319
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6048, Acc: 0.6839, Val Loss: 0.8166, Val Acc: 0.4327
Epoch 83/100, Loss: 0.6047, Acc: 0.6831, Val Loss: 0.8165, Val Acc: 0.4334
Epoch 84/100, Loss: 0.6047, Acc: 0.6825, Val Loss: 0.8172, Val Acc: 0.4305
Epoch 85/100, Loss: 0.6047, Acc: 0.6835, Val Loss: 0.8170, Val Acc: 0.4305
Epoch 86/100, Loss: 0.6047, Acc: 0.6840, Val Loss: 0.8172, Val Acc: 0.4312
Epoch 87/100, Loss: 0.6046, Acc: 0.6841, Val Loss: 0.8172, Val Acc: 0.4327
Epoch 88/100, Loss: 0.6046, Acc: 0.6824, Val Loss: 0.8176, Val Acc: 0.4312
Epoch 89/100, Loss: 0.6045, Acc: 0.6839, Val Loss: 0.8171, Val Acc: 0.4327
Epoch 90/100, Loss: 0.6045, Acc: 0.6832, Val Loss: 0.8170, Val Acc: 0.4297
Epoch 91/100, Loss: 0.6044, Acc: 0.6840, Val Loss: 0.8176, Val Acc: 0.4305
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6045, Acc: 0.6832, Val Loss: 0.8172, Val Acc: 0.4323
Epoch 93/100, Loss: 0.6044, Acc: 0.6824, Val Loss: 0.8180, Val Acc: 0.4312
Epoch 94/100, Loss: 0.6044, Acc: 0.6838, Val Loss: 0.8179, Val Acc: 0.4323
Epoch 95/100, Loss: 0.6043, Acc: 0.6836, Val Loss: 0.8176, Val Acc: 0.4319
Epoch 96/100, Loss: 0.6043, Acc: 0.6839, Val Loss: 0.8178, Val Acc: 0.4319
Epoch 97/100, Loss: 0.6042, Acc: 0.6832, Val Loss: 0.8176, Val Acc: 0.4319
Epoch 98/100, Loss: 0.6042, Acc: 0.6840, Val Loss: 0.8178, Val Acc: 0.4319
Epoch 99/100, Loss: 0.6042, Acc: 0.6843, Val Loss: 0.8182, Val Acc: 0.4330
Epoch 100/100, Loss: 0.6042, Acc: 0.6840, Val Loss: 0.8180, Val Acc: 0.4323

##############################
Resultados para principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  3 
 {'training': [0.6041816698428703, 0.6840411840411841, 0.6633469387755102, 0.747149687385068, 0.702758799619476], 'validate': [0.8180091290972954, 0.4323031640912436, 0.44975556762629004, 0.6097201767304861, 0.5176617693029072], 'test': [0.59717086619801, 0.9111241907004121, 0.9604221635883905, 0.8574793875147232, 0.9060360920970753]}

##############################
Resultados para window:  3 
 {'102:020:125:011:021:008': {'training': [0.5061580682966853, 0.7519764662621805, 0.7485486211901307, 0.7587348289812431, 0.7536073059360731], 'validate': [0.2815657412243444, 0.9194260485651214, 0.929811320754717, 0.9072164948453608, 0.9183749534103616], 'test': [0.7400477647229478, 0.5688640376692172, 0.5633496465470365, 0.6101295641931684, 0.5858071812270286]}, '020:102:125:011:021:008': {'training': [0.5304338349305788, 0.7293620150763008, 0.6941158156911582, 0.8199705774181685, 0.7518125105378519], 'validate': [0.7178546561058178, 0.5846210448859456, 0.551739719837325, 0.8991163475699558, 0.6838420610473257], 'test': [0.46485284136401284, 0.8649205414949971, 0.861646234676007, 0.8692579505300353, 0.8654353562005277]}, '125:102:020:011:021:008': {'training': [0.6707003465643874, 0.5957896672182387, 0.5783531536956195, 0.7065097462302317, 0.6360400629086996], 'validate': [0.6474173470985057, 0.6729212656364975, 0.6886564762670957, 0.6303387334315169, 0.6582083813917724], 'test': [0.7066927706753766, 0.4885226603884638, 0.49125874125874125, 0.6619552414605419, 0.5639739086803813]}, '011:102:020:125:021:008': {'training': [0.6492865306639807, 0.6350432064717779, 0.6134116192830655, 0.7300478116954763, 0.6666666666666666], 'validate': [0.5741702470668527, 0.7862398822663723, 0.7294743059657413, 0.9094256259204713, 0.8095706325794821], 'test': [0.7089081903298696, 0.5164802825191289, 0.5116673737802291, 0.7102473498233216, 0.5948212083847102]}, '021:102:020:125:011:008': {'training': [0.48048607909979685, 0.7633756205184776, 0.7548042704626334, 0.780066200809121, 0.7672273467173087], 'validate': [0.3703746409263722, 0.8568800588668138, 0.8119768190598841, 0.9285714285714286, 0.8663689453795946], 'test': [0.3800140831757475, 0.8228369629193644, 0.8558441558441559, 0.7762073027090695, 0.81408276714021]}, '008:102:020:125:011:021': {'training': [0.6041816698428703, 0.6840411840411841, 0.6633469387755102, 0.747149687385068, 0.702758799619476], 'validate': [0.8180091290972954, 0.4323031640912436, 0.44975556762629004, 0.6097201767304861, 0.5176617693029072], 'test': [0.59717086619801, 0.9111241907004121, 0.9604221635883905, 0.8574793875147232, 0.9060360920970753]}}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  036  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  036  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  036  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6924, Acc: 0.5245, Val Loss: 0.6937, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6937
Epoch 2/100, Loss: 0.6932, Acc: 0.5013, Val Loss: 0.6933, Val Acc: 0.4996
Mejor modelo guardado con Val Loss: 0.6933
Epoch 3/100, Loss: 0.6933, Acc: 0.4965, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 4/100, Loss: 0.6931, Acc: 0.5100, Val Loss: 0.6940, Val Acc: 0.4996
Epoch 5/100, Loss: 0.6937, Acc: 0.4926, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 6/100, Loss: 0.6933, Acc: 0.5019, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 7/100, Loss: 0.6933, Acc: 0.4984, Val Loss: 0.6943, Val Acc: 0.5004
Epoch 8/100, Loss: 0.6936, Acc: 0.4931, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 9/100, Loss: 0.6934, Acc: 0.4986, Val Loss: 0.6935, Val Acc: 0.4996
Epoch 10/100, Loss: 0.6935, Acc: 0.4948, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 11/100, Loss: 0.6934, Acc: 0.4994, Val Loss: 0.6935, Val Acc: 0.4996
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.5017, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 13/100, Loss: 0.6933, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 14/100, Loss: 0.6933, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 15/100, Loss: 0.6932, Acc: 0.5026, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 16/100, Loss: 0.6933, Acc: 0.5006, Val Loss: 0.6934, Val Acc: 0.4996
Epoch 17/100, Loss: 0.6933, Acc: 0.4984, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 18/100, Loss: 0.6933, Acc: 0.4929, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 19/100, Loss: 0.6933, Acc: 0.4931, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 20/100, Loss: 0.6933, Acc: 0.4973, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 21/100, Loss: 0.6933, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.4996
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.5027, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 23/100, Loss: 0.6932, Acc: 0.4997, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 24/100, Loss: 0.6933, Acc: 0.4968, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 25/100, Loss: 0.6932, Acc: 0.5038, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 26/100, Loss: 0.6933, Acc: 0.4975, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 27/100, Loss: 0.6933, Acc: 0.5006, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 28/100, Loss: 0.6932, Acc: 0.5043, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 29/100, Loss: 0.6932, Acc: 0.5006, Val Loss: 0.6934, Val Acc: 0.4989
Epoch 30/100, Loss: 0.6927, Acc: 0.5071, Val Loss: 0.6942, Val Acc: 0.4665
Epoch 31/100, Loss: 0.6926, Acc: 0.5155, Val Loss: 0.6990, Val Acc: 0.3503
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6921, Acc: 0.5135, Val Loss: 0.6986, Val Acc: 0.3900
Epoch 33/100, Loss: 0.6920, Acc: 0.5238, Val Loss: 0.6970, Val Acc: 0.4235
Epoch 34/100, Loss: 0.6918, Acc: 0.5230, Val Loss: 0.7026, Val Acc: 0.3447
Epoch 35/100, Loss: 0.6917, Acc: 0.5281, Val Loss: 0.6980, Val Acc: 0.4323
Epoch 36/100, Loss: 0.6914, Acc: 0.5332, Val Loss: 0.6961, Val Acc: 0.4695
Epoch 37/100, Loss: 0.6912, Acc: 0.5332, Val Loss: 0.6930, Val Acc: 0.5467
Mejor modelo guardado con Val Loss: 0.6930
Epoch 38/100, Loss: 0.6911, Acc: 0.5338, Val Loss: 0.6967, Val Acc: 0.4831
Epoch 39/100, Loss: 0.6910, Acc: 0.5377, Val Loss: 0.7046, Val Acc: 0.3962
Epoch 40/100, Loss: 0.6909, Acc: 0.5311, Val Loss: 0.6936, Val Acc: 0.5872
Epoch 41/100, Loss: 0.6907, Acc: 0.5391, Val Loss: 0.6975, Val Acc: 0.4941
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6905, Acc: 0.5417, Val Loss: 0.6970, Val Acc: 0.5143
Epoch 43/100, Loss: 0.6904, Acc: 0.5411, Val Loss: 0.6952, Val Acc: 0.4985
Epoch 44/100, Loss: 0.6904, Acc: 0.5430, Val Loss: 0.6997, Val Acc: 0.4871
Epoch 45/100, Loss: 0.6903, Acc: 0.5407, Val Loss: 0.6956, Val Acc: 0.5394
Epoch 46/100, Loss: 0.6903, Acc: 0.5427, Val Loss: 0.6951, Val Acc: 0.5430
Epoch 47/100, Loss: 0.6902, Acc: 0.5404, Val Loss: 0.6948, Val Acc: 0.5188
Epoch 48/100, Loss: 0.6901, Acc: 0.5429, Val Loss: 0.6975, Val Acc: 0.4915
Epoch 49/100, Loss: 0.6900, Acc: 0.5435, Val Loss: 0.6973, Val Acc: 0.5092
Epoch 50/100, Loss: 0.6899, Acc: 0.5422, Val Loss: 0.6974, Val Acc: 0.4901
Epoch 51/100, Loss: 0.6898, Acc: 0.5438, Val Loss: 0.6960, Val Acc: 0.5320
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6896, Acc: 0.5449, Val Loss: 0.6977, Val Acc: 0.5022
Epoch 53/100, Loss: 0.6896, Acc: 0.5451, Val Loss: 0.6986, Val Acc: 0.4897
Epoch 54/100, Loss: 0.6896, Acc: 0.5444, Val Loss: 0.6973, Val Acc: 0.5265
Epoch 55/100, Loss: 0.6897, Acc: 0.5272, Val Loss: 0.6943, Val Acc: 0.5607
Epoch 56/100, Loss: 0.6892, Acc: 0.5470, Val Loss: 0.6941, Val Acc: 0.5574
Epoch 57/100, Loss: 0.6891, Acc: 0.5461, Val Loss: 0.6937, Val Acc: 0.5681
Epoch 58/100, Loss: 0.6891, Acc: 0.5489, Val Loss: 0.6949, Val Acc: 0.5423
Epoch 59/100, Loss: 0.6891, Acc: 0.5467, Val Loss: 0.6946, Val Acc: 0.5416
Epoch 60/100, Loss: 0.6890, Acc: 0.5492, Val Loss: 0.6950, Val Acc: 0.5180
Epoch 61/100, Loss: 0.6890, Acc: 0.5492, Val Loss: 0.6931, Val Acc: 0.5589
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6889, Acc: 0.5471, Val Loss: 0.6941, Val Acc: 0.5456
Epoch 63/100, Loss: 0.6888, Acc: 0.5506, Val Loss: 0.6939, Val Acc: 0.5603
Epoch 64/100, Loss: 0.6888, Acc: 0.5521, Val Loss: 0.6939, Val Acc: 0.5504
Epoch 65/100, Loss: 0.6888, Acc: 0.5494, Val Loss: 0.6938, Val Acc: 0.5489
Epoch 66/100, Loss: 0.6888, Acc: 0.5497, Val Loss: 0.6940, Val Acc: 0.5526
Epoch 67/100, Loss: 0.6888, Acc: 0.5509, Val Loss: 0.6941, Val Acc: 0.5563
Epoch 68/100, Loss: 0.6887, Acc: 0.5514, Val Loss: 0.6939, Val Acc: 0.5545
Epoch 69/100, Loss: 0.6887, Acc: 0.5498, Val Loss: 0.6938, Val Acc: 0.5589
Epoch 70/100, Loss: 0.6887, Acc: 0.5517, Val Loss: 0.6939, Val Acc: 0.5570
Epoch 71/100, Loss: 0.6887, Acc: 0.5505, Val Loss: 0.6941, Val Acc: 0.5552
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6886, Acc: 0.5505, Val Loss: 0.6937, Val Acc: 0.5585
Epoch 73/100, Loss: 0.6886, Acc: 0.5505, Val Loss: 0.6938, Val Acc: 0.5545
Epoch 74/100, Loss: 0.6886, Acc: 0.5517, Val Loss: 0.6936, Val Acc: 0.5567
Epoch 75/100, Loss: 0.6886, Acc: 0.5509, Val Loss: 0.6935, Val Acc: 0.5526
Epoch 76/100, Loss: 0.6886, Acc: 0.5506, Val Loss: 0.6938, Val Acc: 0.5533
Epoch 77/100, Loss: 0.6885, Acc: 0.5518, Val Loss: 0.6935, Val Acc: 0.5567
Epoch 78/100, Loss: 0.6885, Acc: 0.5503, Val Loss: 0.6935, Val Acc: 0.5611
Epoch 79/100, Loss: 0.6885, Acc: 0.5511, Val Loss: 0.6937, Val Acc: 0.5522
Epoch 80/100, Loss: 0.6885, Acc: 0.5501, Val Loss: 0.6937, Val Acc: 0.5500
Epoch 81/100, Loss: 0.6885, Acc: 0.5514, Val Loss: 0.6935, Val Acc: 0.5585
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6884, Acc: 0.5520, Val Loss: 0.6935, Val Acc: 0.5567
Epoch 83/100, Loss: 0.6882, Acc: 0.5532, Val Loss: 0.6944, Val Acc: 0.5519
Epoch 84/100, Loss: 0.6881, Acc: 0.5539, Val Loss: 0.6945, Val Acc: 0.5471
Epoch 85/100, Loss: 0.6881, Acc: 0.5535, Val Loss: 0.6942, Val Acc: 0.5493
Epoch 86/100, Loss: 0.6881, Acc: 0.5534, Val Loss: 0.6941, Val Acc: 0.5460
Epoch 87/100, Loss: 0.6881, Acc: 0.5539, Val Loss: 0.6944, Val Acc: 0.5471
Epoch 88/100, Loss: 0.6880, Acc: 0.5526, Val Loss: 0.6942, Val Acc: 0.5456
Epoch 89/100, Loss: 0.6880, Acc: 0.5530, Val Loss: 0.6941, Val Acc: 0.5412
Epoch 90/100, Loss: 0.6880, Acc: 0.5524, Val Loss: 0.6941, Val Acc: 0.5383
Epoch 91/100, Loss: 0.6880, Acc: 0.5528, Val Loss: 0.6940, Val Acc: 0.5405
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6880, Acc: 0.5515, Val Loss: 0.6941, Val Acc: 0.5445
Epoch 93/100, Loss: 0.6880, Acc: 0.5552, Val Loss: 0.6943, Val Acc: 0.5350
Epoch 94/100, Loss: 0.6879, Acc: 0.5514, Val Loss: 0.6939, Val Acc: 0.5390
Epoch 95/100, Loss: 0.6879, Acc: 0.5518, Val Loss: 0.6941, Val Acc: 0.5368
Epoch 96/100, Loss: 0.6879, Acc: 0.5534, Val Loss: 0.6938, Val Acc: 0.5416
Epoch 97/100, Loss: 0.6879, Acc: 0.5521, Val Loss: 0.6939, Val Acc: 0.5401
Epoch 98/100, Loss: 0.6879, Acc: 0.5533, Val Loss: 0.6941, Val Acc: 0.5383
Epoch 99/100, Loss: 0.6878, Acc: 0.5529, Val Loss: 0.6938, Val Acc: 0.5405
Epoch 100/100, Loss: 0.6878, Acc: 0.5527, Val Loss: 0.6938, Val Acc: 0.5408

##############################
Resultados para principal:  036  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3 
 {'training': [0.6878200934244049, 0.5526751241036956, 0.5400448053766452, 0.7092681132769401, 0.6131955484896662], 'validate': [0.6937713331954424, 0.5408388520971302, 0.5334957369062119, 0.6450662739322534, 0.584], 'test': [0.6970722487679234, 0.4605650382577987, 0.4767161090031045, 0.8138987043580683, 0.6012616924080922]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  024  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  024  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  024  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6253, Acc: 0.6589, Val Loss: 0.8117, Val Acc: 0.4503
Mejor modelo guardado con Val Loss: 0.8117
Epoch 2/100, Loss: 0.5860, Acc: 0.6919, Val Loss: 0.7469, Val Acc: 0.4757
Mejor modelo guardado con Val Loss: 0.7469
Epoch 3/100, Loss: 0.5784, Acc: 0.7054, Val Loss: 0.7580, Val Acc: 0.4757
Epoch 4/100, Loss: 0.5710, Acc: 0.7041, Val Loss: 0.7689, Val Acc: 0.4389
Epoch 5/100, Loss: 0.5639, Acc: 0.7049, Val Loss: 0.7512, Val Acc: 0.5368
Epoch 6/100, Loss: 0.5569, Acc: 0.7144, Val Loss: 0.7518, Val Acc: 0.5250
Epoch 7/100, Loss: 0.5550, Acc: 0.7133, Val Loss: 0.7353, Val Acc: 0.5195
Mejor modelo guardado con Val Loss: 0.7353
Epoch 8/100, Loss: 0.5590, Acc: 0.7114, Val Loss: 0.7731, Val Acc: 0.5221
Epoch 9/100, Loss: 0.5568, Acc: 0.7088, Val Loss: 0.8287, Val Acc: 0.5372
Epoch 10/100, Loss: 0.5520, Acc: 0.7141, Val Loss: 0.8210, Val Acc: 0.4849
Epoch 11/100, Loss: 0.5490, Acc: 0.7199, Val Loss: 0.7805, Val Acc: 0.4901
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5453, Acc: 0.7223, Val Loss: 0.8177, Val Acc: 0.5026
Epoch 13/100, Loss: 0.5443, Acc: 0.7200, Val Loss: 0.8182, Val Acc: 0.5055
Epoch 14/100, Loss: 0.5411, Acc: 0.7252, Val Loss: 0.7697, Val Acc: 0.5497
Epoch 15/100, Loss: 0.5401, Acc: 0.7211, Val Loss: 0.8037, Val Acc: 0.5493
Epoch 16/100, Loss: 0.5367, Acc: 0.7251, Val Loss: 0.7645, Val Acc: 0.5353
Epoch 17/100, Loss: 0.5367, Acc: 0.7267, Val Loss: 0.7946, Val Acc: 0.5269
Epoch 18/100, Loss: 0.5364, Acc: 0.7257, Val Loss: 0.7607, Val Acc: 0.5611
Epoch 19/100, Loss: 0.5355, Acc: 0.7242, Val Loss: 0.7440, Val Acc: 0.5338
Epoch 20/100, Loss: 0.5343, Acc: 0.7270, Val Loss: 0.7600, Val Acc: 0.5408
Epoch 21/100, Loss: 0.5397, Acc: 0.7221, Val Loss: 0.7441, Val Acc: 0.5589
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5321, Acc: 0.7276, Val Loss: 0.8088, Val Acc: 0.5408
Epoch 23/100, Loss: 0.5306, Acc: 0.7290, Val Loss: 0.7745, Val Acc: 0.5416
Epoch 24/100, Loss: 0.5289, Acc: 0.7296, Val Loss: 0.8067, Val Acc: 0.5592
Epoch 25/100, Loss: 0.5297, Acc: 0.7287, Val Loss: 0.8120, Val Acc: 0.5357
Epoch 26/100, Loss: 0.5292, Acc: 0.7301, Val Loss: 0.8149, Val Acc: 0.5603
Epoch 27/100, Loss: 0.5284, Acc: 0.7319, Val Loss: 0.7784, Val Acc: 0.5497
Epoch 28/100, Loss: 0.5281, Acc: 0.7310, Val Loss: 0.7764, Val Acc: 0.5500
Epoch 29/100, Loss: 0.5276, Acc: 0.7307, Val Loss: 0.7862, Val Acc: 0.5515
Epoch 30/100, Loss: 0.5279, Acc: 0.7307, Val Loss: 0.7920, Val Acc: 0.5368
Epoch 31/100, Loss: 0.5264, Acc: 0.7321, Val Loss: 0.7834, Val Acc: 0.5331
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5254, Acc: 0.7309, Val Loss: 0.8032, Val Acc: 0.5397
Epoch 33/100, Loss: 0.5240, Acc: 0.7323, Val Loss: 0.7827, Val Acc: 0.5548
Epoch 34/100, Loss: 0.5247, Acc: 0.7320, Val Loss: 0.7923, Val Acc: 0.5375
Epoch 35/100, Loss: 0.5244, Acc: 0.7325, Val Loss: 0.7815, Val Acc: 0.5478
Epoch 36/100, Loss: 0.5235, Acc: 0.7335, Val Loss: 0.7902, Val Acc: 0.5475
Epoch 37/100, Loss: 0.5229, Acc: 0.7332, Val Loss: 0.8067, Val Acc: 0.5434
Epoch 38/100, Loss: 0.5227, Acc: 0.7319, Val Loss: 0.7936, Val Acc: 0.5419
Epoch 39/100, Loss: 0.5226, Acc: 0.7324, Val Loss: 0.8284, Val Acc: 0.5460
Epoch 40/100, Loss: 0.5227, Acc: 0.7339, Val Loss: 0.8061, Val Acc: 0.5545
Epoch 41/100, Loss: 0.5231, Acc: 0.7302, Val Loss: 0.7714, Val Acc: 0.5508
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5215, Acc: 0.7352, Val Loss: 0.7932, Val Acc: 0.5475
Epoch 43/100, Loss: 0.5208, Acc: 0.7346, Val Loss: 0.8046, Val Acc: 0.5533
Epoch 44/100, Loss: 0.5207, Acc: 0.7341, Val Loss: 0.7934, Val Acc: 0.5478
Epoch 45/100, Loss: 0.5203, Acc: 0.7360, Val Loss: 0.8013, Val Acc: 0.5456
Epoch 46/100, Loss: 0.5208, Acc: 0.7331, Val Loss: 0.7973, Val Acc: 0.5430
Epoch 47/100, Loss: 0.5204, Acc: 0.7341, Val Loss: 0.7872, Val Acc: 0.5497
Epoch 48/100, Loss: 0.5206, Acc: 0.7323, Val Loss: 0.7984, Val Acc: 0.5412
Epoch 49/100, Loss: 0.5206, Acc: 0.7343, Val Loss: 0.8188, Val Acc: 0.5419
Epoch 50/100, Loss: 0.5203, Acc: 0.7356, Val Loss: 0.8007, Val Acc: 0.5497
Epoch 51/100, Loss: 0.5198, Acc: 0.7354, Val Loss: 0.7975, Val Acc: 0.5526
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5193, Acc: 0.7346, Val Loss: 0.7934, Val Acc: 0.5489
Epoch 53/100, Loss: 0.5189, Acc: 0.7351, Val Loss: 0.8104, Val Acc: 0.5460
Epoch 54/100, Loss: 0.5191, Acc: 0.7348, Val Loss: 0.7964, Val Acc: 0.5489
Epoch 55/100, Loss: 0.5192, Acc: 0.7336, Val Loss: 0.7986, Val Acc: 0.5467
Epoch 56/100, Loss: 0.5191, Acc: 0.7352, Val Loss: 0.8000, Val Acc: 0.5471
Epoch 57/100, Loss: 0.5192, Acc: 0.7358, Val Loss: 0.8050, Val Acc: 0.5449
Epoch 58/100, Loss: 0.5189, Acc: 0.7357, Val Loss: 0.8071, Val Acc: 0.5430
Epoch 59/100, Loss: 0.5188, Acc: 0.7363, Val Loss: 0.7989, Val Acc: 0.5522
Epoch 60/100, Loss: 0.5189, Acc: 0.7352, Val Loss: 0.8027, Val Acc: 0.5489
Epoch 61/100, Loss: 0.5187, Acc: 0.7342, Val Loss: 0.7999, Val Acc: 0.5467
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5185, Acc: 0.7364, Val Loss: 0.8046, Val Acc: 0.5482
Epoch 63/100, Loss: 0.5184, Acc: 0.7363, Val Loss: 0.8005, Val Acc: 0.5471
Epoch 64/100, Loss: 0.5183, Acc: 0.7359, Val Loss: 0.8020, Val Acc: 0.5493
Epoch 65/100, Loss: 0.5183, Acc: 0.7352, Val Loss: 0.8000, Val Acc: 0.5500
Epoch 66/100, Loss: 0.5182, Acc: 0.7363, Val Loss: 0.8007, Val Acc: 0.5497
Epoch 67/100, Loss: 0.5182, Acc: 0.7360, Val Loss: 0.7976, Val Acc: 0.5504
Epoch 68/100, Loss: 0.5181, Acc: 0.7357, Val Loss: 0.7995, Val Acc: 0.5511
Epoch 69/100, Loss: 0.5181, Acc: 0.7365, Val Loss: 0.8012, Val Acc: 0.5497
Epoch 70/100, Loss: 0.5181, Acc: 0.7356, Val Loss: 0.8052, Val Acc: 0.5478
Epoch 71/100, Loss: 0.5182, Acc: 0.7368, Val Loss: 0.8010, Val Acc: 0.5478
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5179, Acc: 0.7362, Val Loss: 0.7969, Val Acc: 0.5504
Epoch 73/100, Loss: 0.5178, Acc: 0.7363, Val Loss: 0.7983, Val Acc: 0.5478
Epoch 74/100, Loss: 0.5179, Acc: 0.7356, Val Loss: 0.7999, Val Acc: 0.5497
Epoch 75/100, Loss: 0.5179, Acc: 0.7361, Val Loss: 0.7983, Val Acc: 0.5471
Epoch 76/100, Loss: 0.5178, Acc: 0.7358, Val Loss: 0.7974, Val Acc: 0.5467
Epoch 77/100, Loss: 0.5178, Acc: 0.7363, Val Loss: 0.8026, Val Acc: 0.5438
Epoch 78/100, Loss: 0.5177, Acc: 0.7359, Val Loss: 0.8022, Val Acc: 0.5464
Epoch 79/100, Loss: 0.5177, Acc: 0.7363, Val Loss: 0.8051, Val Acc: 0.5401
Epoch 80/100, Loss: 0.5176, Acc: 0.7358, Val Loss: 0.8057, Val Acc: 0.5394
Epoch 81/100, Loss: 0.5176, Acc: 0.7348, Val Loss: 0.8031, Val Acc: 0.5416
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5176, Acc: 0.7353, Val Loss: 0.8056, Val Acc: 0.5386
Epoch 83/100, Loss: 0.5176, Acc: 0.7351, Val Loss: 0.8112, Val Acc: 0.5390
Epoch 84/100, Loss: 0.5175, Acc: 0.7349, Val Loss: 0.8072, Val Acc: 0.5394
Epoch 85/100, Loss: 0.5175, Acc: 0.7363, Val Loss: 0.8053, Val Acc: 0.5394
Epoch 86/100, Loss: 0.5174, Acc: 0.7367, Val Loss: 0.8080, Val Acc: 0.5386
Epoch 87/100, Loss: 0.5174, Acc: 0.7370, Val Loss: 0.8101, Val Acc: 0.5379
Epoch 88/100, Loss: 0.5173, Acc: 0.7365, Val Loss: 0.8099, Val Acc: 0.5364
Epoch 89/100, Loss: 0.5173, Acc: 0.7355, Val Loss: 0.8079, Val Acc: 0.5383
Epoch 90/100, Loss: 0.5173, Acc: 0.7358, Val Loss: 0.8079, Val Acc: 0.5397
Epoch 91/100, Loss: 0.5173, Acc: 0.7359, Val Loss: 0.8112, Val Acc: 0.5368
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5172, Acc: 0.7358, Val Loss: 0.8067, Val Acc: 0.5383
Epoch 93/100, Loss: 0.5173, Acc: 0.7363, Val Loss: 0.8077, Val Acc: 0.5394
Epoch 94/100, Loss: 0.5172, Acc: 0.7372, Val Loss: 0.8111, Val Acc: 0.5375
Epoch 95/100, Loss: 0.5172, Acc: 0.7367, Val Loss: 0.8115, Val Acc: 0.5386
Epoch 96/100, Loss: 0.5172, Acc: 0.7364, Val Loss: 0.8102, Val Acc: 0.5394
Epoch 97/100, Loss: 0.5172, Acc: 0.7353, Val Loss: 0.8118, Val Acc: 0.5397
Epoch 98/100, Loss: 0.5172, Acc: 0.7357, Val Loss: 0.8099, Val Acc: 0.5383
Epoch 99/100, Loss: 0.5170, Acc: 0.7365, Val Loss: 0.8117, Val Acc: 0.5383
Epoch 100/100, Loss: 0.5170, Acc: 0.7353, Val Loss: 0.8082, Val Acc: 0.5386

##############################
Resultados para principal:  024  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3 
 {'training': [0.5170055097967282, 0.735337378194521, 0.749366595205613, 0.7070614196395734, 0.7275995836881446], 'validate': [0.8081746697425842, 0.5386313465783664, 0.5376266280752533, 0.5471281296023565, 0.5423357664233577], 'test': [0.5789932542377048, 0.7001177163037081, 0.7731295253419147, 0.565959952885748, 0.6535192111526692]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  100  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  100  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  100  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6026, Acc: 0.7124, Val Loss: 0.7258, Val Acc: 0.5313
Mejor modelo guardado con Val Loss: 0.7258
Epoch 2/100, Loss: 0.5379, Acc: 0.7420, Val Loss: 0.8273, Val Acc: 0.5324
Epoch 3/100, Loss: 0.5177, Acc: 0.7477, Val Loss: 0.7524, Val Acc: 0.5335
Epoch 4/100, Loss: 0.5114, Acc: 0.7485, Val Loss: 0.7446, Val Acc: 0.5327
Epoch 5/100, Loss: 0.5011, Acc: 0.7523, Val Loss: 0.7806, Val Acc: 0.5342
Epoch 6/100, Loss: 0.4984, Acc: 0.7533, Val Loss: 0.7580, Val Acc: 0.5316
Epoch 7/100, Loss: 0.4960, Acc: 0.7505, Val Loss: 0.7720, Val Acc: 0.5408
Epoch 8/100, Loss: 0.4923, Acc: 0.7544, Val Loss: 0.8939, Val Acc: 0.5313
Epoch 9/100, Loss: 0.4903, Acc: 0.7568, Val Loss: 0.8154, Val Acc: 0.5313
Epoch 10/100, Loss: 0.4895, Acc: 0.7556, Val Loss: 0.7487, Val Acc: 0.5408
Epoch 11/100, Loss: 0.4839, Acc: 0.7596, Val Loss: 0.8115, Val Acc: 0.5261
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4757, Acc: 0.7610, Val Loss: 0.8313, Val Acc: 0.5250
Epoch 13/100, Loss: 0.4748, Acc: 0.7624, Val Loss: 0.8084, Val Acc: 0.5228
Epoch 14/100, Loss: 0.4704, Acc: 0.7668, Val Loss: 0.7872, Val Acc: 0.5280
Epoch 15/100, Loss: 0.4677, Acc: 0.7658, Val Loss: 0.8016, Val Acc: 0.5269
Epoch 16/100, Loss: 0.4695, Acc: 0.7638, Val Loss: 0.8104, Val Acc: 0.5350
Epoch 17/100, Loss: 0.4667, Acc: 0.7679, Val Loss: 0.8650, Val Acc: 0.5302
Epoch 18/100, Loss: 0.4703, Acc: 0.7593, Val Loss: 0.7940, Val Acc: 0.5258
Epoch 19/100, Loss: 0.4651, Acc: 0.7659, Val Loss: 0.8038, Val Acc: 0.5235
Epoch 20/100, Loss: 0.4638, Acc: 0.7668, Val Loss: 0.8163, Val Acc: 0.5361
Epoch 21/100, Loss: 0.4628, Acc: 0.7671, Val Loss: 0.8462, Val Acc: 0.5247
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4591, Acc: 0.7717, Val Loss: 0.8505, Val Acc: 0.5316
Epoch 23/100, Loss: 0.4583, Acc: 0.7708, Val Loss: 0.8289, Val Acc: 0.5298
Epoch 24/100, Loss: 0.4582, Acc: 0.7706, Val Loss: 0.8431, Val Acc: 0.5276
Epoch 25/100, Loss: 0.4575, Acc: 0.7680, Val Loss: 0.8208, Val Acc: 0.5309
Epoch 26/100, Loss: 0.4556, Acc: 0.7711, Val Loss: 0.8578, Val Acc: 0.5291
Epoch 27/100, Loss: 0.4559, Acc: 0.7720, Val Loss: 0.8247, Val Acc: 0.5423
Epoch 28/100, Loss: 0.4563, Acc: 0.7696, Val Loss: 0.8343, Val Acc: 0.5243
Epoch 29/100, Loss: 0.4564, Acc: 0.7681, Val Loss: 0.8510, Val Acc: 0.5258
Epoch 30/100, Loss: 0.4545, Acc: 0.7696, Val Loss: 0.8037, Val Acc: 0.5346
Epoch 31/100, Loss: 0.4564, Acc: 0.7705, Val Loss: 0.8706, Val Acc: 0.5280
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4528, Acc: 0.7694, Val Loss: 0.8858, Val Acc: 0.5302
Epoch 33/100, Loss: 0.4520, Acc: 0.7710, Val Loss: 0.8602, Val Acc: 0.5294
Epoch 34/100, Loss: 0.4520, Acc: 0.7737, Val Loss: 0.8377, Val Acc: 0.5287
Epoch 35/100, Loss: 0.4510, Acc: 0.7705, Val Loss: 0.8020, Val Acc: 0.5272
Epoch 36/100, Loss: 0.4513, Acc: 0.7733, Val Loss: 0.8827, Val Acc: 0.5309
Epoch 37/100, Loss: 0.4514, Acc: 0.7698, Val Loss: 0.8113, Val Acc: 0.5298
Epoch 38/100, Loss: 0.4501, Acc: 0.7719, Val Loss: 0.8081, Val Acc: 0.5335
Epoch 39/100, Loss: 0.4505, Acc: 0.7722, Val Loss: 0.8296, Val Acc: 0.5265
Epoch 40/100, Loss: 0.4501, Acc: 0.7709, Val Loss: 0.8224, Val Acc: 0.5313
Epoch 41/100, Loss: 0.4505, Acc: 0.7736, Val Loss: 0.8520, Val Acc: 0.5280
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4488, Acc: 0.7728, Val Loss: 0.8598, Val Acc: 0.5331
Epoch 43/100, Loss: 0.4486, Acc: 0.7720, Val Loss: 0.8391, Val Acc: 0.5294
Epoch 44/100, Loss: 0.4486, Acc: 0.7736, Val Loss: 0.8613, Val Acc: 0.5287
Epoch 45/100, Loss: 0.4484, Acc: 0.7727, Val Loss: 0.8647, Val Acc: 0.5283
Epoch 46/100, Loss: 0.4482, Acc: 0.7725, Val Loss: 0.8448, Val Acc: 0.5324
Epoch 47/100, Loss: 0.4481, Acc: 0.7727, Val Loss: 0.8429, Val Acc: 0.5287
Epoch 48/100, Loss: 0.4477, Acc: 0.7727, Val Loss: 0.8658, Val Acc: 0.5291
Epoch 49/100, Loss: 0.4483, Acc: 0.7735, Val Loss: 0.8498, Val Acc: 0.5305
Epoch 50/100, Loss: 0.4474, Acc: 0.7745, Val Loss: 0.8378, Val Acc: 0.5294
Epoch 51/100, Loss: 0.4476, Acc: 0.7728, Val Loss: 0.8739, Val Acc: 0.5298
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4469, Acc: 0.7745, Val Loss: 0.8487, Val Acc: 0.5305
Epoch 53/100, Loss: 0.4468, Acc: 0.7733, Val Loss: 0.8475, Val Acc: 0.5320
Epoch 54/100, Loss: 0.4463, Acc: 0.7742, Val Loss: 0.8618, Val Acc: 0.5287
Epoch 55/100, Loss: 0.4465, Acc: 0.7732, Val Loss: 0.8646, Val Acc: 0.5327
Epoch 56/100, Loss: 0.4465, Acc: 0.7727, Val Loss: 0.8430, Val Acc: 0.5324
Epoch 57/100, Loss: 0.4463, Acc: 0.7726, Val Loss: 0.8463, Val Acc: 0.5305
Epoch 58/100, Loss: 0.4465, Acc: 0.7739, Val Loss: 0.8584, Val Acc: 0.5294
Epoch 59/100, Loss: 0.4463, Acc: 0.7729, Val Loss: 0.8616, Val Acc: 0.5320
Epoch 60/100, Loss: 0.4461, Acc: 0.7739, Val Loss: 0.8470, Val Acc: 0.5298
Epoch 61/100, Loss: 0.4461, Acc: 0.7739, Val Loss: 0.8461, Val Acc: 0.5294
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4458, Acc: 0.7740, Val Loss: 0.8553, Val Acc: 0.5313
Epoch 63/100, Loss: 0.4457, Acc: 0.7733, Val Loss: 0.8593, Val Acc: 0.5313
Epoch 64/100, Loss: 0.4458, Acc: 0.7741, Val Loss: 0.8532, Val Acc: 0.5305
Epoch 65/100, Loss: 0.4456, Acc: 0.7743, Val Loss: 0.8568, Val Acc: 0.5302
Epoch 66/100, Loss: 0.4456, Acc: 0.7738, Val Loss: 0.8517, Val Acc: 0.5302
Epoch 67/100, Loss: 0.4455, Acc: 0.7738, Val Loss: 0.8509, Val Acc: 0.5313
Epoch 68/100, Loss: 0.4455, Acc: 0.7753, Val Loss: 0.8590, Val Acc: 0.5313
Epoch 69/100, Loss: 0.4455, Acc: 0.7746, Val Loss: 0.8570, Val Acc: 0.5313
Epoch 70/100, Loss: 0.4455, Acc: 0.7734, Val Loss: 0.8566, Val Acc: 0.5302
Epoch 71/100, Loss: 0.4454, Acc: 0.7744, Val Loss: 0.8514, Val Acc: 0.5320
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4453, Acc: 0.7751, Val Loss: 0.8561, Val Acc: 0.5327
Epoch 73/100, Loss: 0.4453, Acc: 0.7741, Val Loss: 0.8603, Val Acc: 0.5298
Epoch 74/100, Loss: 0.4452, Acc: 0.7731, Val Loss: 0.8571, Val Acc: 0.5305
Epoch 75/100, Loss: 0.4452, Acc: 0.7747, Val Loss: 0.8558, Val Acc: 0.5327
Epoch 76/100, Loss: 0.4452, Acc: 0.7739, Val Loss: 0.8532, Val Acc: 0.5316
Epoch 77/100, Loss: 0.4452, Acc: 0.7745, Val Loss: 0.8573, Val Acc: 0.5302
Epoch 78/100, Loss: 0.4451, Acc: 0.7746, Val Loss: 0.8568, Val Acc: 0.5302
Epoch 79/100, Loss: 0.4451, Acc: 0.7742, Val Loss: 0.8558, Val Acc: 0.5313
Epoch 80/100, Loss: 0.4451, Acc: 0.7745, Val Loss: 0.8549, Val Acc: 0.5316
Epoch 81/100, Loss: 0.4451, Acc: 0.7752, Val Loss: 0.8552, Val Acc: 0.5313
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4450, Acc: 0.7749, Val Loss: 0.8563, Val Acc: 0.5316
Epoch 83/100, Loss: 0.4450, Acc: 0.7749, Val Loss: 0.8541, Val Acc: 0.5313
Epoch 84/100, Loss: 0.4451, Acc: 0.7743, Val Loss: 0.8544, Val Acc: 0.5313
Epoch 85/100, Loss: 0.4450, Acc: 0.7736, Val Loss: 0.8532, Val Acc: 0.5316
Epoch 86/100, Loss: 0.4450, Acc: 0.7740, Val Loss: 0.8600, Val Acc: 0.5309
Epoch 87/100, Loss: 0.4450, Acc: 0.7741, Val Loss: 0.8604, Val Acc: 0.5302
Epoch 88/100, Loss: 0.4449, Acc: 0.7748, Val Loss: 0.8599, Val Acc: 0.5320
Epoch 89/100, Loss: 0.4449, Acc: 0.7747, Val Loss: 0.8569, Val Acc: 0.5309
Epoch 90/100, Loss: 0.4449, Acc: 0.7742, Val Loss: 0.8580, Val Acc: 0.5302
Epoch 91/100, Loss: 0.4448, Acc: 0.7746, Val Loss: 0.8565, Val Acc: 0.5316
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4449, Acc: 0.7749, Val Loss: 0.8577, Val Acc: 0.5320
Epoch 93/100, Loss: 0.4448, Acc: 0.7746, Val Loss: 0.8570, Val Acc: 0.5313
Epoch 94/100, Loss: 0.4448, Acc: 0.7731, Val Loss: 0.8643, Val Acc: 0.5302
Epoch 95/100, Loss: 0.4448, Acc: 0.7747, Val Loss: 0.8587, Val Acc: 0.5316
Epoch 96/100, Loss: 0.4447, Acc: 0.7751, Val Loss: 0.8591, Val Acc: 0.5316
Epoch 97/100, Loss: 0.4447, Acc: 0.7744, Val Loss: 0.8592, Val Acc: 0.5302
Epoch 98/100, Loss: 0.4447, Acc: 0.7745, Val Loss: 0.8609, Val Acc: 0.5309
Epoch 99/100, Loss: 0.4448, Acc: 0.7748, Val Loss: 0.8607, Val Acc: 0.5305
Epoch 100/100, Loss: 0.4447, Acc: 0.7745, Val Loss: 0.8628, Val Acc: 0.5316

##############################
Resultados para principal:  100  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3 
 {'training': [0.44465570784947694, 0.774498988784703, 0.8255179934569248, 0.69602795145274, 0.7552628953407163], 'validate': [0.8628447021162787, 0.5316409124356144, 0.6748971193415638, 0.12076583210603829, 0.20487195502810743], 'test': [0.5761062856073733, 0.7583872866391995, 0.7163295510606809, 0.8551236749116607, 0.7795973154362416]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  090  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  090  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  090  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6851, Acc: 0.5669, Val Loss: 0.7052, Val Acc: 0.4235
Mejor modelo guardado con Val Loss: 0.7052
Epoch 2/100, Loss: 0.6720, Acc: 0.6015, Val Loss: 0.7253, Val Acc: 0.4169
Epoch 3/100, Loss: 0.6640, Acc: 0.6046, Val Loss: 0.7406, Val Acc: 0.3521
Epoch 4/100, Loss: 0.6587, Acc: 0.6126, Val Loss: 0.7549, Val Acc: 0.3639
Epoch 5/100, Loss: 0.6607, Acc: 0.6053, Val Loss: 0.7311, Val Acc: 0.4319
Epoch 6/100, Loss: 0.6592, Acc: 0.6067, Val Loss: 0.7161, Val Acc: 0.4463
Epoch 7/100, Loss: 0.6628, Acc: 0.5932, Val Loss: 0.7265, Val Acc: 0.4305
Epoch 8/100, Loss: 0.6595, Acc: 0.5922, Val Loss: 0.7567, Val Acc: 0.4246
Epoch 9/100, Loss: 0.6525, Acc: 0.6078, Val Loss: 0.7322, Val Acc: 0.4489
Epoch 10/100, Loss: 0.6475, Acc: 0.6091, Val Loss: 0.7732, Val Acc: 0.4253
Epoch 11/100, Loss: 0.6452, Acc: 0.6172, Val Loss: 0.7475, Val Acc: 0.4562
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6398, Acc: 0.6279, Val Loss: 0.7689, Val Acc: 0.4452
Epoch 13/100, Loss: 0.6407, Acc: 0.6224, Val Loss: 0.7938, Val Acc: 0.4065
Epoch 14/100, Loss: 0.6394, Acc: 0.6231, Val Loss: 0.8073, Val Acc: 0.3926
Epoch 15/100, Loss: 0.6377, Acc: 0.6265, Val Loss: 0.7684, Val Acc: 0.4286
Epoch 16/100, Loss: 0.6382, Acc: 0.6270, Val Loss: 0.8078, Val Acc: 0.3675
Epoch 17/100, Loss: 0.6342, Acc: 0.6279, Val Loss: 0.7808, Val Acc: 0.4364
Epoch 18/100, Loss: 0.6352, Acc: 0.6298, Val Loss: 0.8128, Val Acc: 0.3837
Epoch 19/100, Loss: 0.6350, Acc: 0.6314, Val Loss: 0.8062, Val Acc: 0.3720
Epoch 20/100, Loss: 0.6344, Acc: 0.6304, Val Loss: 0.8045, Val Acc: 0.3499
Epoch 21/100, Loss: 0.6337, Acc: 0.6300, Val Loss: 0.8118, Val Acc: 0.3528
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6313, Acc: 0.6360, Val Loss: 0.8128, Val Acc: 0.3580
Epoch 23/100, Loss: 0.6321, Acc: 0.6369, Val Loss: 0.8038, Val Acc: 0.3716
Epoch 24/100, Loss: 0.6320, Acc: 0.6338, Val Loss: 0.7976, Val Acc: 0.3771
Epoch 25/100, Loss: 0.6317, Acc: 0.6361, Val Loss: 0.8089, Val Acc: 0.3882
Epoch 26/100, Loss: 0.6308, Acc: 0.6350, Val Loss: 0.7979, Val Acc: 0.4091
Epoch 27/100, Loss: 0.6297, Acc: 0.6349, Val Loss: 0.8097, Val Acc: 0.3687
Epoch 28/100, Loss: 0.6307, Acc: 0.6353, Val Loss: 0.8152, Val Acc: 0.3631
Epoch 29/100, Loss: 0.6297, Acc: 0.6378, Val Loss: 0.8181, Val Acc: 0.3679
Epoch 30/100, Loss: 0.6290, Acc: 0.6372, Val Loss: 0.8092, Val Acc: 0.4113
Epoch 31/100, Loss: 0.6299, Acc: 0.6359, Val Loss: 0.7959, Val Acc: 0.3786
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6290, Acc: 0.6403, Val Loss: 0.8182, Val Acc: 0.3734
Epoch 33/100, Loss: 0.6280, Acc: 0.6421, Val Loss: 0.8225, Val Acc: 0.3698
Epoch 34/100, Loss: 0.6282, Acc: 0.6387, Val Loss: 0.8273, Val Acc: 0.3661
Epoch 35/100, Loss: 0.6281, Acc: 0.6389, Val Loss: 0.8360, Val Acc: 0.3731
Epoch 36/100, Loss: 0.6275, Acc: 0.6402, Val Loss: 0.8257, Val Acc: 0.3613
Epoch 37/100, Loss: 0.6278, Acc: 0.6413, Val Loss: 0.8265, Val Acc: 0.3639
Epoch 38/100, Loss: 0.6274, Acc: 0.6382, Val Loss: 0.8203, Val Acc: 0.3687
Epoch 39/100, Loss: 0.6278, Acc: 0.6390, Val Loss: 0.8252, Val Acc: 0.3837
Epoch 40/100, Loss: 0.6277, Acc: 0.6399, Val Loss: 0.8235, Val Acc: 0.3705
Epoch 41/100, Loss: 0.6274, Acc: 0.6399, Val Loss: 0.8016, Val Acc: 0.3933
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6270, Acc: 0.6428, Val Loss: 0.8223, Val Acc: 0.3679
Epoch 43/100, Loss: 0.6265, Acc: 0.6415, Val Loss: 0.8277, Val Acc: 0.3819
Epoch 44/100, Loss: 0.6266, Acc: 0.6414, Val Loss: 0.8265, Val Acc: 0.3628
Epoch 45/100, Loss: 0.6262, Acc: 0.6400, Val Loss: 0.8298, Val Acc: 0.3657
Epoch 46/100, Loss: 0.6261, Acc: 0.6407, Val Loss: 0.8213, Val Acc: 0.3859
Epoch 47/100, Loss: 0.6262, Acc: 0.6426, Val Loss: 0.8336, Val Acc: 0.3698
Epoch 48/100, Loss: 0.6263, Acc: 0.6429, Val Loss: 0.8289, Val Acc: 0.3661
Epoch 49/100, Loss: 0.6256, Acc: 0.6441, Val Loss: 0.8288, Val Acc: 0.3694
Epoch 50/100, Loss: 0.6260, Acc: 0.6415, Val Loss: 0.8217, Val Acc: 0.3760
Epoch 51/100, Loss: 0.6257, Acc: 0.6435, Val Loss: 0.8271, Val Acc: 0.3646
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6253, Acc: 0.6416, Val Loss: 0.8309, Val Acc: 0.3664
Epoch 53/100, Loss: 0.6254, Acc: 0.6427, Val Loss: 0.8308, Val Acc: 0.3687
Epoch 54/100, Loss: 0.6252, Acc: 0.6440, Val Loss: 0.8322, Val Acc: 0.3694
Epoch 55/100, Loss: 0.6253, Acc: 0.6436, Val Loss: 0.8264, Val Acc: 0.3701
Epoch 56/100, Loss: 0.6252, Acc: 0.6433, Val Loss: 0.8261, Val Acc: 0.3709
Epoch 57/100, Loss: 0.6252, Acc: 0.6446, Val Loss: 0.8303, Val Acc: 0.3620
Epoch 58/100, Loss: 0.6250, Acc: 0.6433, Val Loss: 0.8317, Val Acc: 0.3690
Epoch 59/100, Loss: 0.6251, Acc: 0.6431, Val Loss: 0.8302, Val Acc: 0.3657
Epoch 60/100, Loss: 0.6250, Acc: 0.6436, Val Loss: 0.8258, Val Acc: 0.3720
Epoch 61/100, Loss: 0.6251, Acc: 0.6422, Val Loss: 0.8298, Val Acc: 0.3705
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6249, Acc: 0.6432, Val Loss: 0.8301, Val Acc: 0.3709
Epoch 63/100, Loss: 0.6248, Acc: 0.6420, Val Loss: 0.8291, Val Acc: 0.3701
Epoch 64/100, Loss: 0.6248, Acc: 0.6432, Val Loss: 0.8276, Val Acc: 0.3709
Epoch 65/100, Loss: 0.6247, Acc: 0.6424, Val Loss: 0.8286, Val Acc: 0.3694
Epoch 66/100, Loss: 0.6247, Acc: 0.6435, Val Loss: 0.8312, Val Acc: 0.3694
Epoch 67/100, Loss: 0.6247, Acc: 0.6440, Val Loss: 0.8291, Val Acc: 0.3709
Epoch 68/100, Loss: 0.6247, Acc: 0.6429, Val Loss: 0.8320, Val Acc: 0.3705
Epoch 69/100, Loss: 0.6248, Acc: 0.6436, Val Loss: 0.8296, Val Acc: 0.3705
Epoch 70/100, Loss: 0.6246, Acc: 0.6437, Val Loss: 0.8267, Val Acc: 0.3712
Epoch 71/100, Loss: 0.6248, Acc: 0.6443, Val Loss: 0.8299, Val Acc: 0.3690
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6245, Acc: 0.6441, Val Loss: 0.8299, Val Acc: 0.3687
Epoch 73/100, Loss: 0.6245, Acc: 0.6436, Val Loss: 0.8295, Val Acc: 0.3709
Epoch 74/100, Loss: 0.6243, Acc: 0.6445, Val Loss: 0.8282, Val Acc: 0.3705
Epoch 75/100, Loss: 0.6242, Acc: 0.6443, Val Loss: 0.8282, Val Acc: 0.3709
Epoch 76/100, Loss: 0.6242, Acc: 0.6443, Val Loss: 0.8271, Val Acc: 0.3712
Epoch 77/100, Loss: 0.6242, Acc: 0.6443, Val Loss: 0.8281, Val Acc: 0.3698
Epoch 78/100, Loss: 0.6241, Acc: 0.6451, Val Loss: 0.8280, Val Acc: 0.3698
Epoch 79/100, Loss: 0.6241, Acc: 0.6437, Val Loss: 0.8267, Val Acc: 0.3705
Epoch 80/100, Loss: 0.6240, Acc: 0.6430, Val Loss: 0.8248, Val Acc: 0.3738
Epoch 81/100, Loss: 0.6240, Acc: 0.6432, Val Loss: 0.8247, Val Acc: 0.3720
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6240, Acc: 0.6441, Val Loss: 0.8262, Val Acc: 0.3705
Epoch 83/100, Loss: 0.6239, Acc: 0.6442, Val Loss: 0.8259, Val Acc: 0.3701
Epoch 84/100, Loss: 0.6239, Acc: 0.6430, Val Loss: 0.8268, Val Acc: 0.3694
Epoch 85/100, Loss: 0.6239, Acc: 0.6440, Val Loss: 0.8262, Val Acc: 0.3701
Epoch 86/100, Loss: 0.6239, Acc: 0.6452, Val Loss: 0.8273, Val Acc: 0.3727
Epoch 87/100, Loss: 0.6239, Acc: 0.6435, Val Loss: 0.8272, Val Acc: 0.3701
Epoch 88/100, Loss: 0.6238, Acc: 0.6441, Val Loss: 0.8269, Val Acc: 0.3705
Epoch 89/100, Loss: 0.6238, Acc: 0.6445, Val Loss: 0.8271, Val Acc: 0.3705
Epoch 90/100, Loss: 0.6238, Acc: 0.6436, Val Loss: 0.8275, Val Acc: 0.3694
Epoch 91/100, Loss: 0.6238, Acc: 0.6432, Val Loss: 0.8274, Val Acc: 0.3723
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6238, Acc: 0.6436, Val Loss: 0.8263, Val Acc: 0.3723
Epoch 93/100, Loss: 0.6238, Acc: 0.6441, Val Loss: 0.8272, Val Acc: 0.3701
Epoch 94/100, Loss: 0.6237, Acc: 0.6441, Val Loss: 0.8269, Val Acc: 0.3738
Epoch 95/100, Loss: 0.6238, Acc: 0.6452, Val Loss: 0.8271, Val Acc: 0.3727
Epoch 96/100, Loss: 0.6237, Acc: 0.6444, Val Loss: 0.8275, Val Acc: 0.3731
Epoch 97/100, Loss: 0.6237, Acc: 0.6430, Val Loss: 0.8272, Val Acc: 0.3694
Epoch 98/100, Loss: 0.6237, Acc: 0.6437, Val Loss: 0.8289, Val Acc: 0.3701
Epoch 99/100, Loss: 0.6237, Acc: 0.6439, Val Loss: 0.8279, Val Acc: 0.3727
Epoch 100/100, Loss: 0.6237, Acc: 0.6450, Val Loss: 0.8282, Val Acc: 0.3705

##############################
Resultados para principal:  090  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3 
 {'training': [0.6236988358647535, 0.6449715021143593, 0.6184250075142771, 0.7567120264803237, 0.6806152828316242], 'validate': [0.8282135475513547, 0.37049300956585723, 0.40859658208182287, 0.5810014727540501, 0.47978108847674067], 'test': [0.7077903206701632, 0.4067098293113596, 0.4349427168576105, 0.6260306242638398, 0.5132786093674553]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  091  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  091  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  091  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6040, Acc: 0.7085, Val Loss: 0.6353, Val Acc: 0.6383
Mejor modelo guardado con Val Loss: 0.6353
Epoch 2/100, Loss: 0.5496, Acc: 0.7414, Val Loss: 0.6185, Val Acc: 0.6564
Mejor modelo guardado con Val Loss: 0.6185
Epoch 3/100, Loss: 0.5252, Acc: 0.7579, Val Loss: 0.6198, Val Acc: 0.6589
Epoch 4/100, Loss: 0.5238, Acc: 0.7585, Val Loss: 0.6167, Val Acc: 0.6527
Mejor modelo guardado con Val Loss: 0.6167
Epoch 5/100, Loss: 0.5194, Acc: 0.7602, Val Loss: 0.6145, Val Acc: 0.6545
Mejor modelo guardado con Val Loss: 0.6145
Epoch 6/100, Loss: 0.5184, Acc: 0.7615, Val Loss: 0.6172, Val Acc: 0.6575
Epoch 7/100, Loss: 0.5221, Acc: 0.7545, Val Loss: 0.6144, Val Acc: 0.6692
Mejor modelo guardado con Val Loss: 0.6144
Epoch 8/100, Loss: 0.5135, Acc: 0.7662, Val Loss: 0.6151, Val Acc: 0.6527
Epoch 9/100, Loss: 0.5145, Acc: 0.7642, Val Loss: 0.6287, Val Acc: 0.6405
Epoch 10/100, Loss: 0.5092, Acc: 0.7659, Val Loss: 0.6288, Val Acc: 0.6501
Epoch 11/100, Loss: 0.5103, Acc: 0.7673, Val Loss: 0.6024, Val Acc: 0.6656
Mejor modelo guardado con Val Loss: 0.6024
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5080, Acc: 0.7697, Val Loss: 0.6172, Val Acc: 0.6689
Epoch 13/100, Loss: 0.5066, Acc: 0.7667, Val Loss: 0.6435, Val Acc: 0.6597
Epoch 14/100, Loss: 0.5097, Acc: 0.7667, Val Loss: 0.6176, Val Acc: 0.6619
Epoch 15/100, Loss: 0.5052, Acc: 0.7671, Val Loss: 0.6064, Val Acc: 0.6663
Epoch 16/100, Loss: 0.5023, Acc: 0.7730, Val Loss: 0.6035, Val Acc: 0.6703
Epoch 17/100, Loss: 0.5048, Acc: 0.7654, Val Loss: 0.6146, Val Acc: 0.6703
Epoch 18/100, Loss: 0.5025, Acc: 0.7704, Val Loss: 0.6266, Val Acc: 0.6589
Epoch 19/100, Loss: 0.5039, Acc: 0.7706, Val Loss: 0.6103, Val Acc: 0.6788
Epoch 20/100, Loss: 0.5022, Acc: 0.7726, Val Loss: 0.6322, Val Acc: 0.6332
Epoch 21/100, Loss: 0.5040, Acc: 0.7702, Val Loss: 0.6155, Val Acc: 0.6726
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4976, Acc: 0.7739, Val Loss: 0.6110, Val Acc: 0.6751
Epoch 23/100, Loss: 0.4961, Acc: 0.7719, Val Loss: 0.6178, Val Acc: 0.6703
Epoch 24/100, Loss: 0.4962, Acc: 0.7734, Val Loss: 0.6170, Val Acc: 0.6707
Epoch 25/100, Loss: 0.4955, Acc: 0.7740, Val Loss: 0.6155, Val Acc: 0.6733
Epoch 26/100, Loss: 0.4960, Acc: 0.7782, Val Loss: 0.6188, Val Acc: 0.6729
Epoch 27/100, Loss: 0.4982, Acc: 0.7728, Val Loss: 0.6101, Val Acc: 0.6674
Epoch 28/100, Loss: 0.4966, Acc: 0.7726, Val Loss: 0.6064, Val Acc: 0.6700
Epoch 29/100, Loss: 0.4969, Acc: 0.7741, Val Loss: 0.6055, Val Acc: 0.6689
Epoch 30/100, Loss: 0.4953, Acc: 0.7741, Val Loss: 0.6152, Val Acc: 0.6726
Epoch 31/100, Loss: 0.4963, Acc: 0.7745, Val Loss: 0.6012, Val Acc: 0.6711
Mejor modelo guardado con Val Loss: 0.6012
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4929, Acc: 0.7753, Val Loss: 0.6126, Val Acc: 0.6726
Epoch 33/100, Loss: 0.4927, Acc: 0.7775, Val Loss: 0.6059, Val Acc: 0.6722
Epoch 34/100, Loss: 0.4940, Acc: 0.7744, Val Loss: 0.6042, Val Acc: 0.6726
Epoch 35/100, Loss: 0.4931, Acc: 0.7743, Val Loss: 0.6105, Val Acc: 0.6722
Epoch 36/100, Loss: 0.4922, Acc: 0.7774, Val Loss: 0.6069, Val Acc: 0.6751
Epoch 37/100, Loss: 0.4923, Acc: 0.7773, Val Loss: 0.6114, Val Acc: 0.6696
Epoch 38/100, Loss: 0.4922, Acc: 0.7774, Val Loss: 0.6082, Val Acc: 0.6714
Epoch 39/100, Loss: 0.4924, Acc: 0.7760, Val Loss: 0.6116, Val Acc: 0.6729
Epoch 40/100, Loss: 0.4914, Acc: 0.7766, Val Loss: 0.6109, Val Acc: 0.6685
Epoch 41/100, Loss: 0.4919, Acc: 0.7760, Val Loss: 0.6157, Val Acc: 0.6685
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4906, Acc: 0.7761, Val Loss: 0.6110, Val Acc: 0.6755
Epoch 43/100, Loss: 0.4906, Acc: 0.7764, Val Loss: 0.6108, Val Acc: 0.6733
Epoch 44/100, Loss: 0.4904, Acc: 0.7785, Val Loss: 0.6068, Val Acc: 0.6718
Epoch 45/100, Loss: 0.4907, Acc: 0.7774, Val Loss: 0.6071, Val Acc: 0.6722
Epoch 46/100, Loss: 0.4902, Acc: 0.7768, Val Loss: 0.6114, Val Acc: 0.6737
Epoch 47/100, Loss: 0.4897, Acc: 0.7782, Val Loss: 0.6105, Val Acc: 0.6718
Epoch 48/100, Loss: 0.4901, Acc: 0.7767, Val Loss: 0.6089, Val Acc: 0.6711
Epoch 49/100, Loss: 0.4900, Acc: 0.7780, Val Loss: 0.6085, Val Acc: 0.6740
Epoch 50/100, Loss: 0.4898, Acc: 0.7781, Val Loss: 0.6098, Val Acc: 0.6729
Epoch 51/100, Loss: 0.4894, Acc: 0.7793, Val Loss: 0.6088, Val Acc: 0.6700
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4891, Acc: 0.7782, Val Loss: 0.6083, Val Acc: 0.6718
Epoch 53/100, Loss: 0.4891, Acc: 0.7779, Val Loss: 0.6097, Val Acc: 0.6718
Epoch 54/100, Loss: 0.4892, Acc: 0.7788, Val Loss: 0.6083, Val Acc: 0.6714
Epoch 55/100, Loss: 0.4889, Acc: 0.7776, Val Loss: 0.6083, Val Acc: 0.6703
Epoch 56/100, Loss: 0.4888, Acc: 0.7785, Val Loss: 0.6091, Val Acc: 0.6707
Epoch 57/100, Loss: 0.4888, Acc: 0.7776, Val Loss: 0.6090, Val Acc: 0.6737
Epoch 58/100, Loss: 0.4887, Acc: 0.7785, Val Loss: 0.6125, Val Acc: 0.6733
Epoch 59/100, Loss: 0.4886, Acc: 0.7776, Val Loss: 0.6091, Val Acc: 0.6703
Epoch 60/100, Loss: 0.4886, Acc: 0.7785, Val Loss: 0.6097, Val Acc: 0.6718
Epoch 61/100, Loss: 0.4884, Acc: 0.7783, Val Loss: 0.6098, Val Acc: 0.6711
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4880, Acc: 0.7794, Val Loss: 0.6096, Val Acc: 0.6711
Epoch 63/100, Loss: 0.4879, Acc: 0.7782, Val Loss: 0.6091, Val Acc: 0.6714
Epoch 64/100, Loss: 0.4880, Acc: 0.7785, Val Loss: 0.6092, Val Acc: 0.6714
Epoch 65/100, Loss: 0.4880, Acc: 0.7787, Val Loss: 0.6093, Val Acc: 0.6729
Epoch 66/100, Loss: 0.4880, Acc: 0.7789, Val Loss: 0.6088, Val Acc: 0.6726
Epoch 67/100, Loss: 0.4878, Acc: 0.7783, Val Loss: 0.6091, Val Acc: 0.6707
Epoch 68/100, Loss: 0.4877, Acc: 0.7779, Val Loss: 0.6094, Val Acc: 0.6722
Epoch 69/100, Loss: 0.4877, Acc: 0.7786, Val Loss: 0.6094, Val Acc: 0.6714
Epoch 70/100, Loss: 0.4876, Acc: 0.7790, Val Loss: 0.6087, Val Acc: 0.6726
Epoch 71/100, Loss: 0.4879, Acc: 0.7767, Val Loss: 0.6082, Val Acc: 0.6726
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4875, Acc: 0.7785, Val Loss: 0.6084, Val Acc: 0.6722
Epoch 73/100, Loss: 0.4875, Acc: 0.7784, Val Loss: 0.6087, Val Acc: 0.6703
Epoch 74/100, Loss: 0.4875, Acc: 0.7779, Val Loss: 0.6085, Val Acc: 0.6711
Epoch 75/100, Loss: 0.4874, Acc: 0.7785, Val Loss: 0.6082, Val Acc: 0.6726
Epoch 76/100, Loss: 0.4874, Acc: 0.7786, Val Loss: 0.6085, Val Acc: 0.6718
Epoch 77/100, Loss: 0.4873, Acc: 0.7786, Val Loss: 0.6083, Val Acc: 0.6722
Epoch 78/100, Loss: 0.4871, Acc: 0.7780, Val Loss: 0.6083, Val Acc: 0.6729
Epoch 79/100, Loss: 0.4871, Acc: 0.7788, Val Loss: 0.6085, Val Acc: 0.6726
Epoch 80/100, Loss: 0.4870, Acc: 0.7795, Val Loss: 0.6090, Val Acc: 0.6707
Epoch 81/100, Loss: 0.4870, Acc: 0.7782, Val Loss: 0.6083, Val Acc: 0.6718
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4869, Acc: 0.7785, Val Loss: 0.6085, Val Acc: 0.6722
Epoch 83/100, Loss: 0.4869, Acc: 0.7785, Val Loss: 0.6085, Val Acc: 0.6722
Epoch 84/100, Loss: 0.4869, Acc: 0.7795, Val Loss: 0.6090, Val Acc: 0.6700
Epoch 85/100, Loss: 0.4869, Acc: 0.7782, Val Loss: 0.6082, Val Acc: 0.6718
Epoch 86/100, Loss: 0.4869, Acc: 0.7790, Val Loss: 0.6082, Val Acc: 0.6722
Epoch 87/100, Loss: 0.4868, Acc: 0.7782, Val Loss: 0.6084, Val Acc: 0.6733
Epoch 88/100, Loss: 0.4868, Acc: 0.7786, Val Loss: 0.6084, Val Acc: 0.6696
Epoch 89/100, Loss: 0.4868, Acc: 0.7781, Val Loss: 0.6081, Val Acc: 0.6729
Epoch 90/100, Loss: 0.4868, Acc: 0.7785, Val Loss: 0.6081, Val Acc: 0.6726
Epoch 91/100, Loss: 0.4867, Acc: 0.7785, Val Loss: 0.6086, Val Acc: 0.6703
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4866, Acc: 0.7785, Val Loss: 0.6083, Val Acc: 0.6711
Epoch 93/100, Loss: 0.4866, Acc: 0.7786, Val Loss: 0.6078, Val Acc: 0.6729
Epoch 94/100, Loss: 0.4866, Acc: 0.7784, Val Loss: 0.6079, Val Acc: 0.6729
Epoch 95/100, Loss: 0.4866, Acc: 0.7783, Val Loss: 0.6080, Val Acc: 0.6726
Epoch 96/100, Loss: 0.4865, Acc: 0.7792, Val Loss: 0.6083, Val Acc: 0.6718
Epoch 97/100, Loss: 0.4862, Acc: 0.7781, Val Loss: 0.6084, Val Acc: 0.6722
Epoch 98/100, Loss: 0.4862, Acc: 0.7779, Val Loss: 0.6084, Val Acc: 0.6729
Epoch 99/100, Loss: 0.4861, Acc: 0.7782, Val Loss: 0.6085, Val Acc: 0.6722
Epoch 100/100, Loss: 0.4861, Acc: 0.7793, Val Loss: 0.6085, Val Acc: 0.6711

##############################
Resultados para principal:  091  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3 
 {'training': [0.4860547485104333, 0.7792792792792793, 0.7818823092630407, 0.7745494667157043, 0.7781986143187067], 'validate': [0.608457027133121, 0.6710816777041942, 0.6700879765395894, 0.6730486008836525, 0.671565025716385], 'test': [0.764069069314886, 0.5885815185403178, 0.5633981403212173, 0.7850412249705536, 0.656003937007874]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  019  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  019  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  019  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6692, Acc: 0.6124, Val Loss: 0.6680, Val Acc: 0.6082
Mejor modelo guardado con Val Loss: 0.6680
Epoch 2/100, Loss: 0.6359, Acc: 0.6701, Val Loss: 0.6312, Val Acc: 0.6652
Mejor modelo guardado con Val Loss: 0.6312
Epoch 3/100, Loss: 0.6195, Acc: 0.6791, Val Loss: 0.6148, Val Acc: 0.6928
Mejor modelo guardado con Val Loss: 0.6148
Epoch 4/100, Loss: 0.6081, Acc: 0.6859, Val Loss: 0.6170, Val Acc: 0.6788
Epoch 5/100, Loss: 0.6111, Acc: 0.6835, Val Loss: 0.6015, Val Acc: 0.6965
Mejor modelo guardado con Val Loss: 0.6015
Epoch 6/100, Loss: 0.6206, Acc: 0.6691, Val Loss: 0.6795, Val Acc: 0.5762
Epoch 7/100, Loss: 0.6001, Acc: 0.7020, Val Loss: 0.6160, Val Acc: 0.6773
Epoch 8/100, Loss: 0.5918, Acc: 0.7000, Val Loss: 0.6284, Val Acc: 0.6711
Epoch 9/100, Loss: 0.5932, Acc: 0.7061, Val Loss: 0.5886, Val Acc: 0.7093
Mejor modelo guardado con Val Loss: 0.5886
Epoch 10/100, Loss: 0.5919, Acc: 0.7001, Val Loss: 0.6078, Val Acc: 0.6873
Epoch 11/100, Loss: 0.5863, Acc: 0.7055, Val Loss: 0.6360, Val Acc: 0.6766
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5841, Acc: 0.7113, Val Loss: 0.6093, Val Acc: 0.6898
Epoch 13/100, Loss: 0.5723, Acc: 0.7136, Val Loss: 0.6127, Val Acc: 0.6825
Epoch 14/100, Loss: 0.5720, Acc: 0.7171, Val Loss: 0.5914, Val Acc: 0.6979
Epoch 15/100, Loss: 0.5730, Acc: 0.7173, Val Loss: 0.5875, Val Acc: 0.7016
Mejor modelo guardado con Val Loss: 0.5875
Epoch 16/100, Loss: 0.5708, Acc: 0.7211, Val Loss: 0.5773, Val Acc: 0.7200
Mejor modelo guardado con Val Loss: 0.5773
Epoch 17/100, Loss: 0.5724, Acc: 0.7151, Val Loss: 0.6087, Val Acc: 0.6891
Epoch 18/100, Loss: 0.5722, Acc: 0.7149, Val Loss: 0.5787, Val Acc: 0.7112
Epoch 19/100, Loss: 0.5761, Acc: 0.7099, Val Loss: 0.5970, Val Acc: 0.6987
Epoch 20/100, Loss: 0.5716, Acc: 0.7181, Val Loss: 0.6521, Val Acc: 0.6553
Epoch 21/100, Loss: 0.5731, Acc: 0.7173, Val Loss: 0.6074, Val Acc: 0.6939
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5653, Acc: 0.7225, Val Loss: 0.6079, Val Acc: 0.6909
Epoch 23/100, Loss: 0.5654, Acc: 0.7191, Val Loss: 0.5976, Val Acc: 0.6976
Epoch 24/100, Loss: 0.5658, Acc: 0.7211, Val Loss: 0.5937, Val Acc: 0.7016
Epoch 25/100, Loss: 0.5632, Acc: 0.7218, Val Loss: 0.6019, Val Acc: 0.6943
Epoch 26/100, Loss: 0.5636, Acc: 0.7271, Val Loss: 0.6237, Val Acc: 0.6795
Epoch 27/100, Loss: 0.5625, Acc: 0.7258, Val Loss: 0.5985, Val Acc: 0.7049
Epoch 28/100, Loss: 0.5623, Acc: 0.7270, Val Loss: 0.5834, Val Acc: 0.7182
Epoch 29/100, Loss: 0.5635, Acc: 0.7220, Val Loss: 0.6334, Val Acc: 0.6674
Epoch 30/100, Loss: 0.5639, Acc: 0.7257, Val Loss: 0.5745, Val Acc: 0.7266
Mejor modelo guardado con Val Loss: 0.5745
Epoch 31/100, Loss: 0.5622, Acc: 0.7241, Val Loss: 0.6204, Val Acc: 0.6832
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5607, Acc: 0.7314, Val Loss: 0.5883, Val Acc: 0.7064
Epoch 33/100, Loss: 0.5598, Acc: 0.7217, Val Loss: 0.6061, Val Acc: 0.6943
Epoch 34/100, Loss: 0.5611, Acc: 0.7267, Val Loss: 0.5929, Val Acc: 0.7038
Epoch 35/100, Loss: 0.5604, Acc: 0.7270, Val Loss: 0.6056, Val Acc: 0.6917
Epoch 36/100, Loss: 0.5596, Acc: 0.7328, Val Loss: 0.5883, Val Acc: 0.7127
Epoch 37/100, Loss: 0.5594, Acc: 0.7274, Val Loss: 0.5841, Val Acc: 0.7130
Epoch 38/100, Loss: 0.5592, Acc: 0.7261, Val Loss: 0.5969, Val Acc: 0.7001
Epoch 39/100, Loss: 0.5594, Acc: 0.7259, Val Loss: 0.5948, Val Acc: 0.7104
Epoch 40/100, Loss: 0.5595, Acc: 0.7298, Val Loss: 0.5970, Val Acc: 0.7005
Epoch 41/100, Loss: 0.5579, Acc: 0.7275, Val Loss: 0.5810, Val Acc: 0.7160
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5577, Acc: 0.7284, Val Loss: 0.5893, Val Acc: 0.7075
Epoch 43/100, Loss: 0.5572, Acc: 0.7282, Val Loss: 0.6032, Val Acc: 0.6950
Epoch 44/100, Loss: 0.5575, Acc: 0.7280, Val Loss: 0.5873, Val Acc: 0.7116
Epoch 45/100, Loss: 0.5570, Acc: 0.7294, Val Loss: 0.5885, Val Acc: 0.7101
Epoch 46/100, Loss: 0.5577, Acc: 0.7302, Val Loss: 0.5928, Val Acc: 0.7049
Epoch 47/100, Loss: 0.5565, Acc: 0.7288, Val Loss: 0.6022, Val Acc: 0.6946
Epoch 48/100, Loss: 0.5573, Acc: 0.7286, Val Loss: 0.5987, Val Acc: 0.6968
Epoch 49/100, Loss: 0.5568, Acc: 0.7291, Val Loss: 0.5940, Val Acc: 0.7031
Epoch 50/100, Loss: 0.5569, Acc: 0.7283, Val Loss: 0.5948, Val Acc: 0.7027
Epoch 51/100, Loss: 0.5566, Acc: 0.7292, Val Loss: 0.5868, Val Acc: 0.7082
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5570, Acc: 0.7247, Val Loss: 0.5941, Val Acc: 0.7016
Epoch 53/100, Loss: 0.5563, Acc: 0.7298, Val Loss: 0.5949, Val Acc: 0.7001
Epoch 54/100, Loss: 0.5561, Acc: 0.7298, Val Loss: 0.5931, Val Acc: 0.7042
Epoch 55/100, Loss: 0.5560, Acc: 0.7294, Val Loss: 0.5931, Val Acc: 0.7038
Epoch 56/100, Loss: 0.5562, Acc: 0.7292, Val Loss: 0.5920, Val Acc: 0.7038
Epoch 57/100, Loss: 0.5558, Acc: 0.7295, Val Loss: 0.5996, Val Acc: 0.6968
Epoch 58/100, Loss: 0.5559, Acc: 0.7300, Val Loss: 0.5899, Val Acc: 0.7075
Epoch 59/100, Loss: 0.5559, Acc: 0.7294, Val Loss: 0.5922, Val Acc: 0.7053
Epoch 60/100, Loss: 0.5558, Acc: 0.7301, Val Loss: 0.5929, Val Acc: 0.7046
Epoch 61/100, Loss: 0.5561, Acc: 0.7295, Val Loss: 0.5924, Val Acc: 0.7049
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5554, Acc: 0.7307, Val Loss: 0.5863, Val Acc: 0.7116
Epoch 63/100, Loss: 0.5549, Acc: 0.7300, Val Loss: 0.5977, Val Acc: 0.6987
Epoch 64/100, Loss: 0.5551, Acc: 0.7289, Val Loss: 0.5896, Val Acc: 0.7071
Epoch 65/100, Loss: 0.5550, Acc: 0.7306, Val Loss: 0.5871, Val Acc: 0.7101
Epoch 66/100, Loss: 0.5549, Acc: 0.7291, Val Loss: 0.5931, Val Acc: 0.7027
Epoch 67/100, Loss: 0.5549, Acc: 0.7302, Val Loss: 0.5936, Val Acc: 0.7020
Epoch 68/100, Loss: 0.5550, Acc: 0.7293, Val Loss: 0.5907, Val Acc: 0.7068
Epoch 69/100, Loss: 0.5547, Acc: 0.7310, Val Loss: 0.5916, Val Acc: 0.7053
Epoch 70/100, Loss: 0.5546, Acc: 0.7304, Val Loss: 0.5908, Val Acc: 0.7057
Epoch 71/100, Loss: 0.5545, Acc: 0.7292, Val Loss: 0.5965, Val Acc: 0.6994
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5545, Acc: 0.7305, Val Loss: 0.5931, Val Acc: 0.7020
Epoch 73/100, Loss: 0.5544, Acc: 0.7308, Val Loss: 0.5884, Val Acc: 0.7101
Epoch 74/100, Loss: 0.5544, Acc: 0.7308, Val Loss: 0.5912, Val Acc: 0.7053
Epoch 75/100, Loss: 0.5544, Acc: 0.7310, Val Loss: 0.5903, Val Acc: 0.7068
Epoch 76/100, Loss: 0.5543, Acc: 0.7315, Val Loss: 0.5919, Val Acc: 0.7035
Epoch 77/100, Loss: 0.5543, Acc: 0.7305, Val Loss: 0.5919, Val Acc: 0.7049
Epoch 78/100, Loss: 0.5542, Acc: 0.7313, Val Loss: 0.5907, Val Acc: 0.7053
Epoch 79/100, Loss: 0.5541, Acc: 0.7315, Val Loss: 0.5873, Val Acc: 0.7104
Epoch 80/100, Loss: 0.5541, Acc: 0.7311, Val Loss: 0.5904, Val Acc: 0.7060
Epoch 81/100, Loss: 0.5540, Acc: 0.7310, Val Loss: 0.5930, Val Acc: 0.7020
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5538, Acc: 0.7318, Val Loss: 0.5871, Val Acc: 0.7108
Epoch 83/100, Loss: 0.5541, Acc: 0.7319, Val Loss: 0.5920, Val Acc: 0.7027
Epoch 84/100, Loss: 0.5541, Acc: 0.7311, Val Loss: 0.5894, Val Acc: 0.7093
Epoch 85/100, Loss: 0.5538, Acc: 0.7300, Val Loss: 0.5939, Val Acc: 0.6994
Epoch 86/100, Loss: 0.5541, Acc: 0.7308, Val Loss: 0.5899, Val Acc: 0.7068
Epoch 87/100, Loss: 0.5539, Acc: 0.7310, Val Loss: 0.5925, Val Acc: 0.7016
Epoch 88/100, Loss: 0.5539, Acc: 0.7307, Val Loss: 0.5910, Val Acc: 0.7042
Epoch 89/100, Loss: 0.5538, Acc: 0.7316, Val Loss: 0.5918, Val Acc: 0.7027
Epoch 90/100, Loss: 0.5538, Acc: 0.7311, Val Loss: 0.5913, Val Acc: 0.7027
Epoch 91/100, Loss: 0.5538, Acc: 0.7319, Val Loss: 0.5910, Val Acc: 0.7038
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5537, Acc: 0.7309, Val Loss: 0.5935, Val Acc: 0.7001
Epoch 93/100, Loss: 0.5536, Acc: 0.7306, Val Loss: 0.5879, Val Acc: 0.7108
Epoch 94/100, Loss: 0.5536, Acc: 0.7318, Val Loss: 0.5879, Val Acc: 0.7097
Epoch 95/100, Loss: 0.5536, Acc: 0.7315, Val Loss: 0.5920, Val Acc: 0.7013
Epoch 96/100, Loss: 0.5536, Acc: 0.7303, Val Loss: 0.5899, Val Acc: 0.7053
Epoch 97/100, Loss: 0.5535, Acc: 0.7320, Val Loss: 0.5881, Val Acc: 0.7101
Epoch 98/100, Loss: 0.5534, Acc: 0.7308, Val Loss: 0.5908, Val Acc: 0.7031
Epoch 99/100, Loss: 0.5535, Acc: 0.7305, Val Loss: 0.5908, Val Acc: 0.7027
Epoch 100/100, Loss: 0.5534, Acc: 0.7307, Val Loss: 0.5885, Val Acc: 0.7093

##############################
Resultados para principal:  019  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  3 
 {'training': [0.5534115094738774, 0.7307409450266593, 0.7216039568980745, 0.751195292386907, 0.7361023515632039], 'validate': [0.5885358522104662, 0.7093451066961001, 0.670059880239521, 0.8240058910162003, 0.739101717305152], 'test': [0.7669145131000766, 0.5270747498528546, 0.5265306122448979, 0.5318021201413428, 0.5291532376208614]}

##############################
Resultados para window:  3 
 {'036:024:100:090:091:019': {'training': [0.6878200934244049, 0.5526751241036956, 0.5400448053766452, 0.7092681132769401, 0.6131955484896662], 'validate': [0.6937713331954424, 0.5408388520971302, 0.5334957369062119, 0.6450662739322534, 0.584], 'test': [0.6970722487679234, 0.4605650382577987, 0.4767161090031045, 0.8138987043580683, 0.6012616924080922]}, '024:036:100:090:091:019': {'training': [0.5170055097967282, 0.735337378194521, 0.749366595205613, 0.7070614196395734, 0.7275995836881446], 'validate': [0.8081746697425842, 0.5386313465783664, 0.5376266280752533, 0.5471281296023565, 0.5423357664233577], 'test': [0.5789932542377048, 0.7001177163037081, 0.7731295253419147, 0.565959952885748, 0.6535192111526692]}, '100:036:024:090:091:019': {'training': [0.44465570784947694, 0.774498988784703, 0.8255179934569248, 0.69602795145274, 0.7552628953407163], 'validate': [0.8628447021162787, 0.5316409124356144, 0.6748971193415638, 0.12076583210603829, 0.20487195502810743], 'test': [0.5761062856073733, 0.7583872866391995, 0.7163295510606809, 0.8551236749116607, 0.7795973154362416]}, '090:036:024:100:091:019': {'training': [0.6236988358647535, 0.6449715021143593, 0.6184250075142771, 0.7567120264803237, 0.6806152828316242], 'validate': [0.8282135475513547, 0.37049300956585723, 0.40859658208182287, 0.5810014727540501, 0.47978108847674067], 'test': [0.7077903206701632, 0.4067098293113596, 0.4349427168576105, 0.6260306242638398, 0.5132786093674553]}, '091:036:024:100:090:019': {'training': [0.4860547485104333, 0.7792792792792793, 0.7818823092630407, 0.7745494667157043, 0.7781986143187067], 'validate': [0.608457027133121, 0.6710816777041942, 0.6700879765395894, 0.6730486008836525, 0.671565025716385], 'test': [0.764069069314886, 0.5885815185403178, 0.5633981403212173, 0.7850412249705536, 0.656003937007874]}, '019:036:024:100:090:091': {'training': [0.5534115094738774, 0.7307409450266593, 0.7216039568980745, 0.751195292386907, 0.7361023515632039], 'validate': [0.5885358522104662, 0.7093451066961001, 0.670059880239521, 0.8240058910162003, 0.739101717305152], 'test': [0.7669145131000766, 0.5270747498528546, 0.5265306122448979, 0.5318021201413428, 0.5291532376208614]}}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  064  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  064  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  064  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5805, Acc: 0.7307, Val Loss: 0.7354, Val Acc: 0.5364
Mejor modelo guardado con Val Loss: 0.7354
Epoch 2/100, Loss: 0.5160, Acc: 0.7569, Val Loss: 0.7429, Val Acc: 0.5405
Epoch 3/100, Loss: 0.5140, Acc: 0.7594, Val Loss: 0.7596, Val Acc: 0.5504
Epoch 4/100, Loss: 0.4938, Acc: 0.7647, Val Loss: 0.7979, Val Acc: 0.5305
Epoch 5/100, Loss: 0.4901, Acc: 0.7660, Val Loss: 0.7783, Val Acc: 0.5372
Epoch 6/100, Loss: 0.4858, Acc: 0.7667, Val Loss: 0.8202, Val Acc: 0.5368
Epoch 7/100, Loss: 0.4834, Acc: 0.7711, Val Loss: 0.8092, Val Acc: 0.5294
Epoch 8/100, Loss: 0.4846, Acc: 0.7716, Val Loss: 0.8077, Val Acc: 0.5213
Epoch 9/100, Loss: 0.4852, Acc: 0.7679, Val Loss: 0.8893, Val Acc: 0.5011
Epoch 10/100, Loss: 0.4825, Acc: 0.7720, Val Loss: 0.8240, Val Acc: 0.5258
Epoch 11/100, Loss: 0.4787, Acc: 0.7713, Val Loss: 0.7989, Val Acc: 0.5445
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4774, Acc: 0.7761, Val Loss: 0.8374, Val Acc: 0.5269
Epoch 13/100, Loss: 0.4732, Acc: 0.7784, Val Loss: 0.8516, Val Acc: 0.5213
Epoch 14/100, Loss: 0.4733, Acc: 0.7765, Val Loss: 0.8480, Val Acc: 0.5283
Epoch 15/100, Loss: 0.4725, Acc: 0.7776, Val Loss: 0.7788, Val Acc: 0.5364
Epoch 16/100, Loss: 0.4745, Acc: 0.7734, Val Loss: 0.8812, Val Acc: 0.5169
Epoch 17/100, Loss: 0.4692, Acc: 0.7781, Val Loss: 0.8492, Val Acc: 0.5342
Epoch 18/100, Loss: 0.4708, Acc: 0.7774, Val Loss: 0.8713, Val Acc: 0.5272
Epoch 19/100, Loss: 0.4687, Acc: 0.7802, Val Loss: 0.8135, Val Acc: 0.5405
Epoch 20/100, Loss: 0.4696, Acc: 0.7798, Val Loss: 0.8337, Val Acc: 0.5412
Epoch 21/100, Loss: 0.4699, Acc: 0.7784, Val Loss: 0.8637, Val Acc: 0.5390
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4670, Acc: 0.7819, Val Loss: 0.8139, Val Acc: 0.5453
Epoch 23/100, Loss: 0.4676, Acc: 0.7799, Val Loss: 0.8387, Val Acc: 0.5324
Epoch 24/100, Loss: 0.4652, Acc: 0.7819, Val Loss: 0.8530, Val Acc: 0.5364
Epoch 25/100, Loss: 0.4639, Acc: 0.7822, Val Loss: 0.8920, Val Acc: 0.5162
Epoch 26/100, Loss: 0.4654, Acc: 0.7804, Val Loss: 0.8435, Val Acc: 0.5331
Epoch 27/100, Loss: 0.4643, Acc: 0.7811, Val Loss: 0.8532, Val Acc: 0.5320
Epoch 28/100, Loss: 0.4632, Acc: 0.7838, Val Loss: 0.8184, Val Acc: 0.5423
Epoch 29/100, Loss: 0.4633, Acc: 0.7830, Val Loss: 0.8746, Val Acc: 0.5327
Epoch 30/100, Loss: 0.4631, Acc: 0.7813, Val Loss: 0.8552, Val Acc: 0.5320
Epoch 31/100, Loss: 0.4629, Acc: 0.7836, Val Loss: 0.8450, Val Acc: 0.5353
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4606, Acc: 0.7842, Val Loss: 0.8631, Val Acc: 0.5335
Epoch 33/100, Loss: 0.4607, Acc: 0.7866, Val Loss: 0.8641, Val Acc: 0.5338
Epoch 34/100, Loss: 0.4604, Acc: 0.7850, Val Loss: 0.8625, Val Acc: 0.5320
Epoch 35/100, Loss: 0.4604, Acc: 0.7849, Val Loss: 0.8437, Val Acc: 0.5342
Epoch 36/100, Loss: 0.4595, Acc: 0.7851, Val Loss: 0.8617, Val Acc: 0.5305
Epoch 37/100, Loss: 0.4607, Acc: 0.7834, Val Loss: 0.8506, Val Acc: 0.5338
Epoch 38/100, Loss: 0.4593, Acc: 0.7840, Val Loss: 0.8397, Val Acc: 0.5338
Epoch 39/100, Loss: 0.4590, Acc: 0.7853, Val Loss: 0.8537, Val Acc: 0.5287
Epoch 40/100, Loss: 0.4589, Acc: 0.7861, Val Loss: 0.8552, Val Acc: 0.5331
Epoch 41/100, Loss: 0.4595, Acc: 0.7855, Val Loss: 0.8571, Val Acc: 0.5338
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4583, Acc: 0.7864, Val Loss: 0.8625, Val Acc: 0.5338
Epoch 43/100, Loss: 0.4580, Acc: 0.7869, Val Loss: 0.8429, Val Acc: 0.5364
Epoch 44/100, Loss: 0.4582, Acc: 0.7867, Val Loss: 0.8501, Val Acc: 0.5331
Epoch 45/100, Loss: 0.4572, Acc: 0.7863, Val Loss: 0.8442, Val Acc: 0.5338
Epoch 46/100, Loss: 0.4576, Acc: 0.7867, Val Loss: 0.8592, Val Acc: 0.5316
Epoch 47/100, Loss: 0.4575, Acc: 0.7870, Val Loss: 0.8466, Val Acc: 0.5309
Epoch 48/100, Loss: 0.4577, Acc: 0.7881, Val Loss: 0.8506, Val Acc: 0.5331
Epoch 49/100, Loss: 0.4570, Acc: 0.7859, Val Loss: 0.8510, Val Acc: 0.5324
Epoch 50/100, Loss: 0.4573, Acc: 0.7873, Val Loss: 0.8604, Val Acc: 0.5305
Epoch 51/100, Loss: 0.4576, Acc: 0.7867, Val Loss: 0.8590, Val Acc: 0.5353
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4564, Acc: 0.7867, Val Loss: 0.8573, Val Acc: 0.5346
Epoch 53/100, Loss: 0.4566, Acc: 0.7862, Val Loss: 0.8494, Val Acc: 0.5309
Epoch 54/100, Loss: 0.4563, Acc: 0.7865, Val Loss: 0.8655, Val Acc: 0.5298
Epoch 55/100, Loss: 0.4566, Acc: 0.7871, Val Loss: 0.8497, Val Acc: 0.5316
Epoch 56/100, Loss: 0.4562, Acc: 0.7862, Val Loss: 0.8553, Val Acc: 0.5331
Epoch 57/100, Loss: 0.4560, Acc: 0.7879, Val Loss: 0.8642, Val Acc: 0.5346
Epoch 58/100, Loss: 0.4565, Acc: 0.7866, Val Loss: 0.8542, Val Acc: 0.5320
Epoch 59/100, Loss: 0.4564, Acc: 0.7871, Val Loss: 0.8577, Val Acc: 0.5309
Epoch 60/100, Loss: 0.4562, Acc: 0.7873, Val Loss: 0.8682, Val Acc: 0.5316
Epoch 61/100, Loss: 0.4565, Acc: 0.7868, Val Loss: 0.8501, Val Acc: 0.5342
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4558, Acc: 0.7867, Val Loss: 0.8560, Val Acc: 0.5316
Epoch 63/100, Loss: 0.4557, Acc: 0.7874, Val Loss: 0.8570, Val Acc: 0.5324
Epoch 64/100, Loss: 0.4557, Acc: 0.7873, Val Loss: 0.8571, Val Acc: 0.5324
Epoch 65/100, Loss: 0.4558, Acc: 0.7876, Val Loss: 0.8571, Val Acc: 0.5316
Epoch 66/100, Loss: 0.4556, Acc: 0.7878, Val Loss: 0.8617, Val Acc: 0.5331
Epoch 67/100, Loss: 0.4556, Acc: 0.7876, Val Loss: 0.8601, Val Acc: 0.5316
Epoch 68/100, Loss: 0.4556, Acc: 0.7867, Val Loss: 0.8576, Val Acc: 0.5327
Epoch 69/100, Loss: 0.4556, Acc: 0.7879, Val Loss: 0.8571, Val Acc: 0.5324
Epoch 70/100, Loss: 0.4555, Acc: 0.7871, Val Loss: 0.8571, Val Acc: 0.5327
Epoch 71/100, Loss: 0.4555, Acc: 0.7873, Val Loss: 0.8568, Val Acc: 0.5320
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4554, Acc: 0.7871, Val Loss: 0.8584, Val Acc: 0.5316
Epoch 73/100, Loss: 0.4552, Acc: 0.7876, Val Loss: 0.8603, Val Acc: 0.5350
Epoch 74/100, Loss: 0.4553, Acc: 0.7869, Val Loss: 0.8591, Val Acc: 0.5331
Epoch 75/100, Loss: 0.4554, Acc: 0.7869, Val Loss: 0.8587, Val Acc: 0.5327
Epoch 76/100, Loss: 0.4554, Acc: 0.7864, Val Loss: 0.8584, Val Acc: 0.5327
Epoch 77/100, Loss: 0.4553, Acc: 0.7872, Val Loss: 0.8600, Val Acc: 0.5353
Epoch 78/100, Loss: 0.4553, Acc: 0.7879, Val Loss: 0.8591, Val Acc: 0.5324
Epoch 79/100, Loss: 0.4553, Acc: 0.7866, Val Loss: 0.8566, Val Acc: 0.5320
Epoch 80/100, Loss: 0.4554, Acc: 0.7871, Val Loss: 0.8599, Val Acc: 0.5331
Epoch 81/100, Loss: 0.4552, Acc: 0.7870, Val Loss: 0.8572, Val Acc: 0.5324
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4552, Acc: 0.7873, Val Loss: 0.8586, Val Acc: 0.5327
Epoch 83/100, Loss: 0.4552, Acc: 0.7867, Val Loss: 0.8594, Val Acc: 0.5320
Epoch 84/100, Loss: 0.4552, Acc: 0.7871, Val Loss: 0.8555, Val Acc: 0.5320
Epoch 85/100, Loss: 0.4551, Acc: 0.7877, Val Loss: 0.8575, Val Acc: 0.5324
Epoch 86/100, Loss: 0.4550, Acc: 0.7877, Val Loss: 0.8609, Val Acc: 0.5324
Epoch 87/100, Loss: 0.4552, Acc: 0.7867, Val Loss: 0.8582, Val Acc: 0.5324
Epoch 88/100, Loss: 0.4551, Acc: 0.7871, Val Loss: 0.8589, Val Acc: 0.5331
Epoch 89/100, Loss: 0.4551, Acc: 0.7869, Val Loss: 0.8574, Val Acc: 0.5320
Epoch 90/100, Loss: 0.4552, Acc: 0.7873, Val Loss: 0.8582, Val Acc: 0.5327
Epoch 91/100, Loss: 0.4550, Acc: 0.7869, Val Loss: 0.8553, Val Acc: 0.5316
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4550, Acc: 0.7867, Val Loss: 0.8578, Val Acc: 0.5327
Epoch 93/100, Loss: 0.4551, Acc: 0.7875, Val Loss: 0.8611, Val Acc: 0.5327
Epoch 94/100, Loss: 0.4551, Acc: 0.7878, Val Loss: 0.8577, Val Acc: 0.5327
Epoch 95/100, Loss: 0.4550, Acc: 0.7864, Val Loss: 0.8599, Val Acc: 0.5346
Epoch 96/100, Loss: 0.4550, Acc: 0.7872, Val Loss: 0.8574, Val Acc: 0.5327
Epoch 97/100, Loss: 0.4550, Acc: 0.7872, Val Loss: 0.8571, Val Acc: 0.5320
Epoch 98/100, Loss: 0.4549, Acc: 0.7871, Val Loss: 0.8578, Val Acc: 0.5324
Epoch 99/100, Loss: 0.4549, Acc: 0.7873, Val Loss: 0.8567, Val Acc: 0.5313
Epoch 100/100, Loss: 0.4549, Acc: 0.7864, Val Loss: 0.8621, Val Acc: 0.5335

##############################
Resultados para principal:  064  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3 
 {'training': [0.4548940374902075, 0.7863577863577863, 0.7614170584284755, 0.8339463037881574, 0.7960329998244691], 'validate': [0.8621118616226108, 0.5334805003679176, 0.5208526413345691, 0.8276877761413843, 0.6393629124004551], 'test': [0.9209948049651252, 0.39081812831077106, 0.4308550185873606, 0.682567726737338, 0.5282588878760255]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  060  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  060  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  060  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6483, Acc: 0.6452, Val Loss: 0.7272, Val Acc: 0.4941
Mejor modelo guardado con Val Loss: 0.7272
Epoch 2/100, Loss: 0.6223, Acc: 0.6667, Val Loss: 0.7448, Val Acc: 0.4860
Epoch 3/100, Loss: 0.6072, Acc: 0.6738, Val Loss: 0.7545, Val Acc: 0.4695
Epoch 4/100, Loss: 0.6036, Acc: 0.6734, Val Loss: 0.7534, Val Acc: 0.4662
Epoch 5/100, Loss: 0.6001, Acc: 0.6766, Val Loss: 0.7792, Val Acc: 0.4765
Epoch 6/100, Loss: 0.6031, Acc: 0.6748, Val Loss: 0.7769, Val Acc: 0.4787
Epoch 7/100, Loss: 0.5996, Acc: 0.6758, Val Loss: 0.7674, Val Acc: 0.4621
Epoch 8/100, Loss: 0.5973, Acc: 0.6794, Val Loss: 0.7482, Val Acc: 0.4595
Epoch 9/100, Loss: 0.6010, Acc: 0.6722, Val Loss: 0.7472, Val Acc: 0.4617
Epoch 10/100, Loss: 0.6002, Acc: 0.6727, Val Loss: 0.7643, Val Acc: 0.4801
Epoch 11/100, Loss: 0.5944, Acc: 0.6812, Val Loss: 0.7763, Val Acc: 0.4746
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5910, Acc: 0.6846, Val Loss: 0.7499, Val Acc: 0.4779
Epoch 13/100, Loss: 0.5880, Acc: 0.6858, Val Loss: 0.7553, Val Acc: 0.4798
Epoch 14/100, Loss: 0.5871, Acc: 0.6861, Val Loss: 0.7752, Val Acc: 0.4842
Epoch 15/100, Loss: 0.5882, Acc: 0.6851, Val Loss: 0.7694, Val Acc: 0.4761
Epoch 16/100, Loss: 0.5856, Acc: 0.6849, Val Loss: 0.7834, Val Acc: 0.4746
Epoch 17/100, Loss: 0.5855, Acc: 0.6856, Val Loss: 0.7631, Val Acc: 0.4713
Epoch 18/100, Loss: 0.5874, Acc: 0.6900, Val Loss: 0.7601, Val Acc: 0.4695
Epoch 19/100, Loss: 0.5855, Acc: 0.6871, Val Loss: 0.7593, Val Acc: 0.4761
Epoch 20/100, Loss: 0.5843, Acc: 0.6837, Val Loss: 0.7726, Val Acc: 0.4724
Epoch 21/100, Loss: 0.5847, Acc: 0.6870, Val Loss: 0.7563, Val Acc: 0.4684
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5814, Acc: 0.6896, Val Loss: 0.7664, Val Acc: 0.4860
Epoch 23/100, Loss: 0.5820, Acc: 0.6870, Val Loss: 0.7817, Val Acc: 0.4680
Epoch 24/100, Loss: 0.5830, Acc: 0.6862, Val Loss: 0.7725, Val Acc: 0.4673
Epoch 25/100, Loss: 0.5811, Acc: 0.6885, Val Loss: 0.7644, Val Acc: 0.4816
Epoch 26/100, Loss: 0.5802, Acc: 0.6862, Val Loss: 0.7650, Val Acc: 0.4868
Epoch 27/100, Loss: 0.5818, Acc: 0.6883, Val Loss: 0.7606, Val Acc: 0.4702
Epoch 28/100, Loss: 0.5804, Acc: 0.6885, Val Loss: 0.7583, Val Acc: 0.4783
Epoch 29/100, Loss: 0.5803, Acc: 0.6867, Val Loss: 0.7647, Val Acc: 0.4735
Epoch 30/100, Loss: 0.5804, Acc: 0.6863, Val Loss: 0.7572, Val Acc: 0.4816
Epoch 31/100, Loss: 0.5806, Acc: 0.6887, Val Loss: 0.7709, Val Acc: 0.4750
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5783, Acc: 0.6884, Val Loss: 0.7664, Val Acc: 0.4823
Epoch 33/100, Loss: 0.5781, Acc: 0.6882, Val Loss: 0.7708, Val Acc: 0.4849
Epoch 34/100, Loss: 0.5775, Acc: 0.6883, Val Loss: 0.7629, Val Acc: 0.4772
Epoch 35/100, Loss: 0.5781, Acc: 0.6914, Val Loss: 0.7718, Val Acc: 0.4684
Epoch 36/100, Loss: 0.5780, Acc: 0.6907, Val Loss: 0.7726, Val Acc: 0.4706
Epoch 37/100, Loss: 0.5772, Acc: 0.6899, Val Loss: 0.7631, Val Acc: 0.4845
Epoch 38/100, Loss: 0.5775, Acc: 0.6906, Val Loss: 0.7578, Val Acc: 0.4757
Epoch 39/100, Loss: 0.5770, Acc: 0.6909, Val Loss: 0.7632, Val Acc: 0.4787
Epoch 40/100, Loss: 0.5770, Acc: 0.6921, Val Loss: 0.7707, Val Acc: 0.4809
Epoch 41/100, Loss: 0.5768, Acc: 0.6885, Val Loss: 0.7643, Val Acc: 0.4720
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5769, Acc: 0.6901, Val Loss: 0.7694, Val Acc: 0.4746
Epoch 43/100, Loss: 0.5761, Acc: 0.6908, Val Loss: 0.7640, Val Acc: 0.4838
Epoch 44/100, Loss: 0.5759, Acc: 0.6898, Val Loss: 0.7620, Val Acc: 0.4823
Epoch 45/100, Loss: 0.5756, Acc: 0.6911, Val Loss: 0.7641, Val Acc: 0.4790
Epoch 46/100, Loss: 0.5759, Acc: 0.6912, Val Loss: 0.7730, Val Acc: 0.4750
Epoch 47/100, Loss: 0.5758, Acc: 0.6909, Val Loss: 0.7578, Val Acc: 0.4691
Epoch 48/100, Loss: 0.5762, Acc: 0.6919, Val Loss: 0.7730, Val Acc: 0.4753
Epoch 49/100, Loss: 0.5758, Acc: 0.6918, Val Loss: 0.7690, Val Acc: 0.4787
Epoch 50/100, Loss: 0.5755, Acc: 0.6906, Val Loss: 0.7662, Val Acc: 0.4772
Epoch 51/100, Loss: 0.5757, Acc: 0.6908, Val Loss: 0.7701, Val Acc: 0.4735
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5754, Acc: 0.6919, Val Loss: 0.7670, Val Acc: 0.4779
Epoch 53/100, Loss: 0.5753, Acc: 0.6916, Val Loss: 0.7708, Val Acc: 0.4750
Epoch 54/100, Loss: 0.5753, Acc: 0.6917, Val Loss: 0.7668, Val Acc: 0.4776
Epoch 55/100, Loss: 0.5751, Acc: 0.6916, Val Loss: 0.7692, Val Acc: 0.4783
Epoch 56/100, Loss: 0.5752, Acc: 0.6916, Val Loss: 0.7698, Val Acc: 0.4779
Epoch 57/100, Loss: 0.5749, Acc: 0.6915, Val Loss: 0.7664, Val Acc: 0.4838
Epoch 58/100, Loss: 0.5749, Acc: 0.6908, Val Loss: 0.7656, Val Acc: 0.4776
Epoch 59/100, Loss: 0.5750, Acc: 0.6909, Val Loss: 0.7666, Val Acc: 0.4779
Epoch 60/100, Loss: 0.5747, Acc: 0.6916, Val Loss: 0.7720, Val Acc: 0.4809
Epoch 61/100, Loss: 0.5748, Acc: 0.6910, Val Loss: 0.7667, Val Acc: 0.4776
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5747, Acc: 0.6908, Val Loss: 0.7678, Val Acc: 0.4783
Epoch 63/100, Loss: 0.5747, Acc: 0.6917, Val Loss: 0.7675, Val Acc: 0.4790
Epoch 64/100, Loss: 0.5745, Acc: 0.6919, Val Loss: 0.7681, Val Acc: 0.4776
Epoch 65/100, Loss: 0.5745, Acc: 0.6924, Val Loss: 0.7673, Val Acc: 0.4776
Epoch 66/100, Loss: 0.5745, Acc: 0.6920, Val Loss: 0.7663, Val Acc: 0.4812
Epoch 67/100, Loss: 0.5745, Acc: 0.6914, Val Loss: 0.7654, Val Acc: 0.4794
Epoch 68/100, Loss: 0.5745, Acc: 0.6914, Val Loss: 0.7680, Val Acc: 0.4783
Epoch 69/100, Loss: 0.5744, Acc: 0.6919, Val Loss: 0.7672, Val Acc: 0.4779
Epoch 70/100, Loss: 0.5744, Acc: 0.6916, Val Loss: 0.7660, Val Acc: 0.4790
Epoch 71/100, Loss: 0.5744, Acc: 0.6914, Val Loss: 0.7673, Val Acc: 0.4779
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5744, Acc: 0.6910, Val Loss: 0.7666, Val Acc: 0.4776
Epoch 73/100, Loss: 0.5744, Acc: 0.6908, Val Loss: 0.7672, Val Acc: 0.4787
Epoch 74/100, Loss: 0.5744, Acc: 0.6913, Val Loss: 0.7670, Val Acc: 0.4776
Epoch 75/100, Loss: 0.5741, Acc: 0.6914, Val Loss: 0.7664, Val Acc: 0.4794
Epoch 76/100, Loss: 0.5740, Acc: 0.6916, Val Loss: 0.7659, Val Acc: 0.4805
Epoch 77/100, Loss: 0.5739, Acc: 0.6915, Val Loss: 0.7663, Val Acc: 0.4798
Epoch 78/100, Loss: 0.5739, Acc: 0.6918, Val Loss: 0.7657, Val Acc: 0.4794
Epoch 79/100, Loss: 0.5738, Acc: 0.6917, Val Loss: 0.7661, Val Acc: 0.4794
Epoch 80/100, Loss: 0.5739, Acc: 0.6919, Val Loss: 0.7662, Val Acc: 0.4783
Epoch 81/100, Loss: 0.5738, Acc: 0.6915, Val Loss: 0.7657, Val Acc: 0.4790
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5738, Acc: 0.6927, Val Loss: 0.7657, Val Acc: 0.4787
Epoch 83/100, Loss: 0.5738, Acc: 0.6919, Val Loss: 0.7661, Val Acc: 0.4798
Epoch 84/100, Loss: 0.5738, Acc: 0.6922, Val Loss: 0.7664, Val Acc: 0.4772
Epoch 85/100, Loss: 0.5738, Acc: 0.6926, Val Loss: 0.7651, Val Acc: 0.4776
Epoch 86/100, Loss: 0.5737, Acc: 0.6917, Val Loss: 0.7669, Val Acc: 0.4805
Epoch 87/100, Loss: 0.5738, Acc: 0.6918, Val Loss: 0.7667, Val Acc: 0.4798
Epoch 88/100, Loss: 0.5737, Acc: 0.6918, Val Loss: 0.7664, Val Acc: 0.4798
Epoch 89/100, Loss: 0.5738, Acc: 0.6929, Val Loss: 0.7649, Val Acc: 0.4779
Epoch 90/100, Loss: 0.5737, Acc: 0.6931, Val Loss: 0.7660, Val Acc: 0.4801
Epoch 91/100, Loss: 0.5737, Acc: 0.6920, Val Loss: 0.7661, Val Acc: 0.4809
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5737, Acc: 0.6916, Val Loss: 0.7650, Val Acc: 0.4798
Epoch 93/100, Loss: 0.5737, Acc: 0.6920, Val Loss: 0.7654, Val Acc: 0.4779
Epoch 94/100, Loss: 0.5737, Acc: 0.6920, Val Loss: 0.7655, Val Acc: 0.4809
Epoch 95/100, Loss: 0.5737, Acc: 0.6918, Val Loss: 0.7652, Val Acc: 0.4798
Epoch 96/100, Loss: 0.5736, Acc: 0.6920, Val Loss: 0.7658, Val Acc: 0.4772
Epoch 97/100, Loss: 0.5736, Acc: 0.6923, Val Loss: 0.7661, Val Acc: 0.4812
Epoch 98/100, Loss: 0.5736, Acc: 0.6921, Val Loss: 0.7656, Val Acc: 0.4812
Epoch 99/100, Loss: 0.5736, Acc: 0.6924, Val Loss: 0.7663, Val Acc: 0.4790
Epoch 100/100, Loss: 0.5736, Acc: 0.6917, Val Loss: 0.7658, Val Acc: 0.4772

##############################
Resultados para principal:  060  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3 
 {'training': [0.5735930464333044, 0.6916712630998345, 0.7699481865284974, 0.5465244575211475, 0.6392772639277264], 'validate': [0.7657825815123182, 0.4771891096394408, 0.352112676056338, 0.05522827687776141, 0.09548058561425843], 'test': [0.7265014924384929, 0.4726309593878752, 0.4528112449799197, 0.2656065959952886, 0.3348181143281366]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  028  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  028  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  028  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5482, Acc: 0.7627, Val Loss: 0.4913, Val Acc: 0.7840
Mejor modelo guardado con Val Loss: 0.4913
Epoch 2/100, Loss: 0.4566, Acc: 0.8014, Val Loss: 0.4865, Val Acc: 0.7951
Mejor modelo guardado con Val Loss: 0.4865
Epoch 3/100, Loss: 0.4431, Acc: 0.7971, Val Loss: 0.4571, Val Acc: 0.7991
Mejor modelo guardado con Val Loss: 0.4571
Epoch 4/100, Loss: 0.4447, Acc: 0.7999, Val Loss: 0.4440, Val Acc: 0.8157
Mejor modelo guardado con Val Loss: 0.4440
Epoch 5/100, Loss: 0.4391, Acc: 0.8001, Val Loss: 0.4455, Val Acc: 0.8091
Epoch 6/100, Loss: 0.4318, Acc: 0.8068, Val Loss: 0.4374, Val Acc: 0.8116
Mejor modelo guardado con Val Loss: 0.4374
Epoch 7/100, Loss: 0.4363, Acc: 0.8020, Val Loss: 0.4876, Val Acc: 0.7851
Epoch 8/100, Loss: 0.4297, Acc: 0.8059, Val Loss: 0.4605, Val Acc: 0.8194
Epoch 9/100, Loss: 0.4304, Acc: 0.8052, Val Loss: 0.4480, Val Acc: 0.8131
Epoch 10/100, Loss: 0.4265, Acc: 0.8069, Val Loss: 0.4619, Val Acc: 0.7940
Epoch 11/100, Loss: 0.4246, Acc: 0.8041, Val Loss: 0.4433, Val Acc: 0.8039
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4163, Acc: 0.8088, Val Loss: 0.4432, Val Acc: 0.8216
Epoch 13/100, Loss: 0.4155, Acc: 0.8136, Val Loss: 0.4649, Val Acc: 0.7940
Epoch 14/100, Loss: 0.4162, Acc: 0.8118, Val Loss: 0.4475, Val Acc: 0.8039
Epoch 15/100, Loss: 0.4176, Acc: 0.8140, Val Loss: 0.4540, Val Acc: 0.8072
Epoch 16/100, Loss: 0.4153, Acc: 0.8119, Val Loss: 0.4548, Val Acc: 0.8072
Epoch 17/100, Loss: 0.4134, Acc: 0.8126, Val Loss: 0.4477, Val Acc: 0.8054
Epoch 18/100, Loss: 0.4125, Acc: 0.8172, Val Loss: 0.4614, Val Acc: 0.8164
Epoch 19/100, Loss: 0.4114, Acc: 0.8102, Val Loss: 0.4487, Val Acc: 0.8105
Epoch 20/100, Loss: 0.4130, Acc: 0.8130, Val Loss: 0.4365, Val Acc: 0.8190
Mejor modelo guardado con Val Loss: 0.4365
Epoch 21/100, Loss: 0.4124, Acc: 0.8143, Val Loss: 0.4482, Val Acc: 0.8160
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4123, Acc: 0.8119, Val Loss: 0.4657, Val Acc: 0.8035
Epoch 23/100, Loss: 0.4109, Acc: 0.8116, Val Loss: 0.4481, Val Acc: 0.8102
Epoch 24/100, Loss: 0.4087, Acc: 0.8131, Val Loss: 0.4555, Val Acc: 0.8087
Epoch 25/100, Loss: 0.4078, Acc: 0.8144, Val Loss: 0.4565, Val Acc: 0.8124
Epoch 26/100, Loss: 0.4064, Acc: 0.8188, Val Loss: 0.4579, Val Acc: 0.8068
Epoch 27/100, Loss: 0.4054, Acc: 0.8177, Val Loss: 0.4469, Val Acc: 0.8160
Epoch 28/100, Loss: 0.4057, Acc: 0.8182, Val Loss: 0.4547, Val Acc: 0.8028
Epoch 29/100, Loss: 0.4071, Acc: 0.8154, Val Loss: 0.4769, Val Acc: 0.8021
Epoch 30/100, Loss: 0.4055, Acc: 0.8161, Val Loss: 0.4647, Val Acc: 0.8131
Epoch 31/100, Loss: 0.4060, Acc: 0.8151, Val Loss: 0.4817, Val Acc: 0.7980
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4031, Acc: 0.8161, Val Loss: 0.4474, Val Acc: 0.8171
Epoch 33/100, Loss: 0.4014, Acc: 0.8184, Val Loss: 0.4492, Val Acc: 0.8179
Epoch 34/100, Loss: 0.4004, Acc: 0.8188, Val Loss: 0.4533, Val Acc: 0.8194
Epoch 35/100, Loss: 0.4004, Acc: 0.8178, Val Loss: 0.4516, Val Acc: 0.8135
Epoch 36/100, Loss: 0.4007, Acc: 0.8178, Val Loss: 0.4497, Val Acc: 0.8138
Epoch 37/100, Loss: 0.3996, Acc: 0.8195, Val Loss: 0.4613, Val Acc: 0.8102
Epoch 38/100, Loss: 0.4000, Acc: 0.8183, Val Loss: 0.4646, Val Acc: 0.8142
Epoch 39/100, Loss: 0.4000, Acc: 0.8187, Val Loss: 0.4510, Val Acc: 0.8146
Epoch 40/100, Loss: 0.4000, Acc: 0.8195, Val Loss: 0.4626, Val Acc: 0.8094
Epoch 41/100, Loss: 0.3997, Acc: 0.8196, Val Loss: 0.4369, Val Acc: 0.8197
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3983, Acc: 0.8198, Val Loss: 0.4512, Val Acc: 0.8160
Epoch 43/100, Loss: 0.3976, Acc: 0.8209, Val Loss: 0.4568, Val Acc: 0.8124
Epoch 44/100, Loss: 0.3972, Acc: 0.8197, Val Loss: 0.4560, Val Acc: 0.8138
Epoch 45/100, Loss: 0.3979, Acc: 0.8201, Val Loss: 0.4587, Val Acc: 0.8168
Epoch 46/100, Loss: 0.3970, Acc: 0.8209, Val Loss: 0.4606, Val Acc: 0.8127
Epoch 47/100, Loss: 0.3974, Acc: 0.8211, Val Loss: 0.4565, Val Acc: 0.8149
Epoch 48/100, Loss: 0.3975, Acc: 0.8195, Val Loss: 0.4528, Val Acc: 0.8182
Epoch 49/100, Loss: 0.3967, Acc: 0.8221, Val Loss: 0.4623, Val Acc: 0.8146
Epoch 50/100, Loss: 0.3971, Acc: 0.8224, Val Loss: 0.4563, Val Acc: 0.8138
Epoch 51/100, Loss: 0.3966, Acc: 0.8209, Val Loss: 0.4474, Val Acc: 0.8182
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3955, Acc: 0.8213, Val Loss: 0.4496, Val Acc: 0.8164
Epoch 53/100, Loss: 0.3958, Acc: 0.8220, Val Loss: 0.4569, Val Acc: 0.8149
Epoch 54/100, Loss: 0.3956, Acc: 0.8219, Val Loss: 0.4550, Val Acc: 0.8135
Epoch 55/100, Loss: 0.3953, Acc: 0.8205, Val Loss: 0.4549, Val Acc: 0.8153
Epoch 56/100, Loss: 0.3951, Acc: 0.8220, Val Loss: 0.4565, Val Acc: 0.8142
Epoch 57/100, Loss: 0.3953, Acc: 0.8223, Val Loss: 0.4510, Val Acc: 0.8168
Epoch 58/100, Loss: 0.3953, Acc: 0.8224, Val Loss: 0.4532, Val Acc: 0.8160
Epoch 59/100, Loss: 0.3954, Acc: 0.8218, Val Loss: 0.4503, Val Acc: 0.8168
Epoch 60/100, Loss: 0.3953, Acc: 0.8221, Val Loss: 0.4509, Val Acc: 0.8164
Epoch 61/100, Loss: 0.3952, Acc: 0.8217, Val Loss: 0.4561, Val Acc: 0.8138
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3946, Acc: 0.8219, Val Loss: 0.4540, Val Acc: 0.8149
Epoch 63/100, Loss: 0.3946, Acc: 0.8233, Val Loss: 0.4541, Val Acc: 0.8160
Epoch 64/100, Loss: 0.3945, Acc: 0.8229, Val Loss: 0.4550, Val Acc: 0.8149
Epoch 65/100, Loss: 0.3946, Acc: 0.8230, Val Loss: 0.4550, Val Acc: 0.8164
Epoch 66/100, Loss: 0.3945, Acc: 0.8231, Val Loss: 0.4529, Val Acc: 0.8171
Epoch 67/100, Loss: 0.3946, Acc: 0.8227, Val Loss: 0.4523, Val Acc: 0.8164
Epoch 68/100, Loss: 0.3946, Acc: 0.8226, Val Loss: 0.4524, Val Acc: 0.8171
Epoch 69/100, Loss: 0.3944, Acc: 0.8236, Val Loss: 0.4522, Val Acc: 0.8171
Epoch 70/100, Loss: 0.3944, Acc: 0.8224, Val Loss: 0.4536, Val Acc: 0.8164
Epoch 71/100, Loss: 0.3943, Acc: 0.8229, Val Loss: 0.4550, Val Acc: 0.8164
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3942, Acc: 0.8229, Val Loss: 0.4525, Val Acc: 0.8164
Epoch 73/100, Loss: 0.3942, Acc: 0.8238, Val Loss: 0.4535, Val Acc: 0.8175
Epoch 74/100, Loss: 0.3942, Acc: 0.8235, Val Loss: 0.4542, Val Acc: 0.8175
Epoch 75/100, Loss: 0.3941, Acc: 0.8230, Val Loss: 0.4529, Val Acc: 0.8164
Epoch 76/100, Loss: 0.3941, Acc: 0.8231, Val Loss: 0.4516, Val Acc: 0.8160
Epoch 77/100, Loss: 0.3940, Acc: 0.8229, Val Loss: 0.4528, Val Acc: 0.8175
Epoch 78/100, Loss: 0.3940, Acc: 0.8229, Val Loss: 0.4513, Val Acc: 0.8168
Epoch 79/100, Loss: 0.3939, Acc: 0.8234, Val Loss: 0.4542, Val Acc: 0.8175
Epoch 80/100, Loss: 0.3940, Acc: 0.8240, Val Loss: 0.4534, Val Acc: 0.8171
Epoch 81/100, Loss: 0.3940, Acc: 0.8230, Val Loss: 0.4525, Val Acc: 0.8164
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3938, Acc: 0.8222, Val Loss: 0.4551, Val Acc: 0.8171
Epoch 83/100, Loss: 0.3937, Acc: 0.8231, Val Loss: 0.4532, Val Acc: 0.8160
Epoch 84/100, Loss: 0.3935, Acc: 0.8239, Val Loss: 0.4549, Val Acc: 0.8160
Epoch 85/100, Loss: 0.3934, Acc: 0.8240, Val Loss: 0.4554, Val Acc: 0.8160
Epoch 86/100, Loss: 0.3933, Acc: 0.8233, Val Loss: 0.4577, Val Acc: 0.8135
Epoch 87/100, Loss: 0.3931, Acc: 0.8235, Val Loss: 0.4562, Val Acc: 0.8157
Epoch 88/100, Loss: 0.3930, Acc: 0.8236, Val Loss: 0.4570, Val Acc: 0.8124
Epoch 89/100, Loss: 0.3930, Acc: 0.8229, Val Loss: 0.4557, Val Acc: 0.8146
Epoch 90/100, Loss: 0.3929, Acc: 0.8232, Val Loss: 0.4547, Val Acc: 0.8157
Epoch 91/100, Loss: 0.3929, Acc: 0.8232, Val Loss: 0.4559, Val Acc: 0.8138
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3929, Acc: 0.8229, Val Loss: 0.4565, Val Acc: 0.8135
Epoch 93/100, Loss: 0.3929, Acc: 0.8228, Val Loss: 0.4543, Val Acc: 0.8142
Epoch 94/100, Loss: 0.3929, Acc: 0.8225, Val Loss: 0.4541, Val Acc: 0.8153
Epoch 95/100, Loss: 0.3926, Acc: 0.8234, Val Loss: 0.4561, Val Acc: 0.8120
Epoch 96/100, Loss: 0.3927, Acc: 0.8234, Val Loss: 0.4545, Val Acc: 0.8149
Epoch 97/100, Loss: 0.3927, Acc: 0.8235, Val Loss: 0.4554, Val Acc: 0.8131
Epoch 98/100, Loss: 0.3926, Acc: 0.8234, Val Loss: 0.4560, Val Acc: 0.8124
Epoch 99/100, Loss: 0.3926, Acc: 0.8233, Val Loss: 0.4535, Val Acc: 0.8149
Epoch 100/100, Loss: 0.3926, Acc: 0.8237, Val Loss: 0.4543, Val Acc: 0.8157

##############################
Resultados para principal:  028  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3 
 {'training': [0.3925942424674489, 0.8236808236808236, 0.8657522859517872, 0.766090474439132, 0.8128780487804877], 'validate': [0.45432703370271726, 0.8156732891832229, 0.9350253807106599, 0.6782032400589102, 0.7861715749039693], 'test': [0.7131217043432925, 0.6177163037080635, 0.9443207126948775, 0.2497055359246172, 0.39496972519795065]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  033  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  033  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  033  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6776, Acc: 0.5924, Val Loss: 0.7081, Val Acc: 0.4397
Mejor modelo guardado con Val Loss: 0.7081
Epoch 2/100, Loss: 0.6749, Acc: 0.5897, Val Loss: 0.6980, Val Acc: 0.4948
Mejor modelo guardado con Val Loss: 0.6980
Epoch 3/100, Loss: 0.6759, Acc: 0.5794, Val Loss: 0.7117, Val Acc: 0.4463
Epoch 4/100, Loss: 0.6689, Acc: 0.6048, Val Loss: 0.7263, Val Acc: 0.4463
Epoch 5/100, Loss: 0.6874, Acc: 0.5359, Val Loss: 0.6939, Val Acc: 0.4996
Mejor modelo guardado con Val Loss: 0.6939
Epoch 6/100, Loss: 0.6933, Acc: 0.5087, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 7/100, Loss: 0.6937, Acc: 0.4911, Val Loss: 0.6935, Val Acc: 0.4996
Epoch 8/100, Loss: 0.6933, Acc: 0.4974, Val Loss: 0.6936, Val Acc: 0.4996
Epoch 9/100, Loss: 0.6935, Acc: 0.4929, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 10/100, Loss: 0.6934, Acc: 0.5002, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 11/100, Loss: 0.6865, Acc: 0.5633, Val Loss: 0.6993, Val Acc: 0.4875
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6665, Acc: 0.6172, Val Loss: 0.7492, Val Acc: 0.4717
Epoch 13/100, Loss: 0.6596, Acc: 0.6042, Val Loss: 0.7032, Val Acc: 0.4783
Epoch 14/100, Loss: 0.6548, Acc: 0.6218, Val Loss: 0.7305, Val Acc: 0.4603
Epoch 15/100, Loss: 0.6499, Acc: 0.6190, Val Loss: 0.7425, Val Acc: 0.4588
Epoch 16/100, Loss: 0.6479, Acc: 0.6245, Val Loss: 0.7361, Val Acc: 0.4882
Epoch 17/100, Loss: 0.6475, Acc: 0.6281, Val Loss: 0.7386, Val Acc: 0.4606
Epoch 18/100, Loss: 0.6472, Acc: 0.6240, Val Loss: 0.7515, Val Acc: 0.4926
Epoch 19/100, Loss: 0.6466, Acc: 0.6243, Val Loss: 0.7813, Val Acc: 0.4728
Epoch 20/100, Loss: 0.6450, Acc: 0.6268, Val Loss: 0.7639, Val Acc: 0.4636
Epoch 21/100, Loss: 0.6449, Acc: 0.6293, Val Loss: 0.7647, Val Acc: 0.4625
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6432, Acc: 0.6259, Val Loss: 0.7586, Val Acc: 0.4665
Epoch 23/100, Loss: 0.6406, Acc: 0.6323, Val Loss: 0.7674, Val Acc: 0.4765
Epoch 24/100, Loss: 0.6420, Acc: 0.6301, Val Loss: 0.7410, Val Acc: 0.5007
Epoch 25/100, Loss: 0.6403, Acc: 0.6345, Val Loss: 0.7693, Val Acc: 0.4776
Epoch 26/100, Loss: 0.6427, Acc: 0.6306, Val Loss: 0.7505, Val Acc: 0.4731
Epoch 27/100, Loss: 0.6398, Acc: 0.6333, Val Loss: 0.7500, Val Acc: 0.4923
Epoch 28/100, Loss: 0.6390, Acc: 0.6361, Val Loss: 0.7687, Val Acc: 0.4941
Epoch 29/100, Loss: 0.6390, Acc: 0.6361, Val Loss: 0.7389, Val Acc: 0.4971
Epoch 30/100, Loss: 0.6397, Acc: 0.6340, Val Loss: 0.7673, Val Acc: 0.4948
Epoch 31/100, Loss: 0.6374, Acc: 0.6368, Val Loss: 0.7613, Val Acc: 0.4937
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6364, Acc: 0.6351, Val Loss: 0.7595, Val Acc: 0.4904
Epoch 33/100, Loss: 0.6363, Acc: 0.6357, Val Loss: 0.7397, Val Acc: 0.5000
Epoch 34/100, Loss: 0.6358, Acc: 0.6362, Val Loss: 0.7674, Val Acc: 0.4926
Epoch 35/100, Loss: 0.6365, Acc: 0.6376, Val Loss: 0.7606, Val Acc: 0.4978
Epoch 36/100, Loss: 0.6365, Acc: 0.6383, Val Loss: 0.7881, Val Acc: 0.4912
Epoch 37/100, Loss: 0.6361, Acc: 0.6384, Val Loss: 0.7623, Val Acc: 0.4934
Epoch 38/100, Loss: 0.6376, Acc: 0.6335, Val Loss: 0.7687, Val Acc: 0.4926
Epoch 39/100, Loss: 0.6361, Acc: 0.6393, Val Loss: 0.7611, Val Acc: 0.4956
Epoch 40/100, Loss: 0.6357, Acc: 0.6377, Val Loss: 0.7637, Val Acc: 0.4919
Epoch 41/100, Loss: 0.6358, Acc: 0.6379, Val Loss: 0.7514, Val Acc: 0.5007
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6352, Acc: 0.6373, Val Loss: 0.7800, Val Acc: 0.4948
Epoch 43/100, Loss: 0.6349, Acc: 0.6350, Val Loss: 0.7643, Val Acc: 0.4923
Epoch 44/100, Loss: 0.6350, Acc: 0.6361, Val Loss: 0.7662, Val Acc: 0.4948
Epoch 45/100, Loss: 0.6352, Acc: 0.6380, Val Loss: 0.7565, Val Acc: 0.4982
Epoch 46/100, Loss: 0.6348, Acc: 0.6375, Val Loss: 0.7553, Val Acc: 0.4948
Epoch 47/100, Loss: 0.6351, Acc: 0.6372, Val Loss: 0.7595, Val Acc: 0.4941
Epoch 48/100, Loss: 0.6345, Acc: 0.6372, Val Loss: 0.7767, Val Acc: 0.4904
Epoch 49/100, Loss: 0.6350, Acc: 0.6361, Val Loss: 0.7569, Val Acc: 0.4919
Epoch 50/100, Loss: 0.6346, Acc: 0.6369, Val Loss: 0.7620, Val Acc: 0.4945
Epoch 51/100, Loss: 0.6341, Acc: 0.6384, Val Loss: 0.7614, Val Acc: 0.4915
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6337, Acc: 0.6398, Val Loss: 0.7608, Val Acc: 0.4930
Epoch 53/100, Loss: 0.6335, Acc: 0.6386, Val Loss: 0.7593, Val Acc: 0.4901
Epoch 54/100, Loss: 0.6335, Acc: 0.6395, Val Loss: 0.7629, Val Acc: 0.4934
Epoch 55/100, Loss: 0.6331, Acc: 0.6401, Val Loss: 0.7661, Val Acc: 0.4897
Epoch 56/100, Loss: 0.6333, Acc: 0.6383, Val Loss: 0.7604, Val Acc: 0.4879
Epoch 57/100, Loss: 0.6334, Acc: 0.6386, Val Loss: 0.7616, Val Acc: 0.4904
Epoch 58/100, Loss: 0.6332, Acc: 0.6392, Val Loss: 0.7652, Val Acc: 0.4908
Epoch 59/100, Loss: 0.6331, Acc: 0.6383, Val Loss: 0.7653, Val Acc: 0.4904
Epoch 60/100, Loss: 0.6330, Acc: 0.6387, Val Loss: 0.7600, Val Acc: 0.4904
Epoch 61/100, Loss: 0.6328, Acc: 0.6387, Val Loss: 0.7578, Val Acc: 0.4941
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6325, Acc: 0.6391, Val Loss: 0.7637, Val Acc: 0.4915
Epoch 63/100, Loss: 0.6325, Acc: 0.6396, Val Loss: 0.7632, Val Acc: 0.4930
Epoch 64/100, Loss: 0.6324, Acc: 0.6390, Val Loss: 0.7624, Val Acc: 0.4930
Epoch 65/100, Loss: 0.6321, Acc: 0.6384, Val Loss: 0.7634, Val Acc: 0.4908
Epoch 66/100, Loss: 0.6321, Acc: 0.6377, Val Loss: 0.7646, Val Acc: 0.4941
Epoch 67/100, Loss: 0.6321, Acc: 0.6396, Val Loss: 0.7615, Val Acc: 0.4926
Epoch 68/100, Loss: 0.6320, Acc: 0.6389, Val Loss: 0.7615, Val Acc: 0.4926
Epoch 69/100, Loss: 0.6320, Acc: 0.6395, Val Loss: 0.7617, Val Acc: 0.4934
Epoch 70/100, Loss: 0.6320, Acc: 0.6386, Val Loss: 0.7596, Val Acc: 0.4915
Epoch 71/100, Loss: 0.6320, Acc: 0.6387, Val Loss: 0.7613, Val Acc: 0.4923
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6318, Acc: 0.6389, Val Loss: 0.7616, Val Acc: 0.4912
Epoch 73/100, Loss: 0.6317, Acc: 0.6384, Val Loss: 0.7622, Val Acc: 0.4930
Epoch 74/100, Loss: 0.6317, Acc: 0.6379, Val Loss: 0.7626, Val Acc: 0.4937
Epoch 75/100, Loss: 0.6316, Acc: 0.6384, Val Loss: 0.7628, Val Acc: 0.4945
Epoch 76/100, Loss: 0.6317, Acc: 0.6395, Val Loss: 0.7614, Val Acc: 0.4915
Epoch 77/100, Loss: 0.6316, Acc: 0.6394, Val Loss: 0.7625, Val Acc: 0.4937
Epoch 78/100, Loss: 0.6316, Acc: 0.6378, Val Loss: 0.7630, Val Acc: 0.4937
Epoch 79/100, Loss: 0.6316, Acc: 0.6399, Val Loss: 0.7633, Val Acc: 0.4941
Epoch 80/100, Loss: 0.6316, Acc: 0.6377, Val Loss: 0.7637, Val Acc: 0.4941
Epoch 81/100, Loss: 0.6316, Acc: 0.6385, Val Loss: 0.7638, Val Acc: 0.4934
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6315, Acc: 0.6387, Val Loss: 0.7630, Val Acc: 0.4941
Epoch 83/100, Loss: 0.6314, Acc: 0.6389, Val Loss: 0.7635, Val Acc: 0.4963
Epoch 84/100, Loss: 0.6314, Acc: 0.6384, Val Loss: 0.7639, Val Acc: 0.4941
Epoch 85/100, Loss: 0.6314, Acc: 0.6396, Val Loss: 0.7623, Val Acc: 0.4915
Epoch 86/100, Loss: 0.6313, Acc: 0.6401, Val Loss: 0.7629, Val Acc: 0.4934
Epoch 87/100, Loss: 0.6313, Acc: 0.6381, Val Loss: 0.7627, Val Acc: 0.4934
Epoch 88/100, Loss: 0.6312, Acc: 0.6380, Val Loss: 0.7635, Val Acc: 0.4930
Epoch 89/100, Loss: 0.6312, Acc: 0.6396, Val Loss: 0.7621, Val Acc: 0.4934
Epoch 90/100, Loss: 0.6313, Acc: 0.6389, Val Loss: 0.7625, Val Acc: 0.4948
Epoch 91/100, Loss: 0.6312, Acc: 0.6381, Val Loss: 0.7638, Val Acc: 0.4956
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6312, Acc: 0.6393, Val Loss: 0.7618, Val Acc: 0.4934
Epoch 93/100, Loss: 0.6313, Acc: 0.6392, Val Loss: 0.7635, Val Acc: 0.4948
Epoch 94/100, Loss: 0.6311, Acc: 0.6389, Val Loss: 0.7647, Val Acc: 0.4937
Epoch 95/100, Loss: 0.6310, Acc: 0.6385, Val Loss: 0.7628, Val Acc: 0.4926
Epoch 96/100, Loss: 0.6310, Acc: 0.6389, Val Loss: 0.7650, Val Acc: 0.4919
Epoch 97/100, Loss: 0.6310, Acc: 0.6400, Val Loss: 0.7628, Val Acc: 0.4926
Epoch 98/100, Loss: 0.6309, Acc: 0.6390, Val Loss: 0.7644, Val Acc: 0.4915
Epoch 99/100, Loss: 0.6309, Acc: 0.6395, Val Loss: 0.7622, Val Acc: 0.4923
Epoch 100/100, Loss: 0.6308, Acc: 0.6402, Val Loss: 0.7639, Val Acc: 0.4915

##############################
Resultados para principal:  033  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3 
 {'training': [0.630816096186879, 0.6401912116197831, 0.6723981900452489, 0.5465244575211475, 0.6029620612700345], 'validate': [0.7639429097951844, 0.4915378955114054, 0.49193548387096775, 0.5390279823269514, 0.5144061841180604], 'test': [0.6930194861359067, 0.5002942907592701, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  026  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  026  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  026  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6798, Acc: 0.5743, Val Loss: 0.6857, Val Acc: 0.5298
Mejor modelo guardado con Val Loss: 0.6857
Epoch 2/100, Loss: 0.6688, Acc: 0.6032, Val Loss: 0.6749, Val Acc: 0.5843
Mejor modelo guardado con Val Loss: 0.6749
Epoch 3/100, Loss: 0.6566, Acc: 0.6197, Val Loss: 0.6782, Val Acc: 0.5953
Epoch 4/100, Loss: 0.6518, Acc: 0.6203, Val Loss: 0.6895, Val Acc: 0.5596
Epoch 5/100, Loss: 0.6414, Acc: 0.6382, Val Loss: 0.6922, Val Acc: 0.5283
Epoch 6/100, Loss: 0.6360, Acc: 0.6363, Val Loss: 0.7191, Val Acc: 0.5419
Epoch 7/100, Loss: 0.6381, Acc: 0.6347, Val Loss: 0.6946, Val Acc: 0.4960
Epoch 8/100, Loss: 0.6447, Acc: 0.6225, Val Loss: 0.6967, Val Acc: 0.5265
Epoch 9/100, Loss: 0.6402, Acc: 0.6469, Val Loss: 0.7012, Val Acc: 0.5368
Epoch 10/100, Loss: 0.6354, Acc: 0.6499, Val Loss: 0.7087, Val Acc: 0.4941
Epoch 11/100, Loss: 0.6310, Acc: 0.6509, Val Loss: 0.7182, Val Acc: 0.5313
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6293, Acc: 0.6504, Val Loss: 0.6980, Val Acc: 0.5530
Epoch 13/100, Loss: 0.6270, Acc: 0.6522, Val Loss: 0.6992, Val Acc: 0.5324
Epoch 14/100, Loss: 0.6255, Acc: 0.6490, Val Loss: 0.7095, Val Acc: 0.5232
Epoch 15/100, Loss: 0.6220, Acc: 0.6563, Val Loss: 0.6769, Val Acc: 0.5695
Epoch 16/100, Loss: 0.6228, Acc: 0.6561, Val Loss: 0.6958, Val Acc: 0.5596
Epoch 17/100, Loss: 0.6196, Acc: 0.6612, Val Loss: 0.6942, Val Acc: 0.5636
Epoch 18/100, Loss: 0.6205, Acc: 0.6560, Val Loss: 0.6766, Val Acc: 0.5629
Epoch 19/100, Loss: 0.6200, Acc: 0.6516, Val Loss: 0.7153, Val Acc: 0.5099
Epoch 20/100, Loss: 0.6184, Acc: 0.6603, Val Loss: 0.7156, Val Acc: 0.5254
Epoch 21/100, Loss: 0.6180, Acc: 0.6585, Val Loss: 0.7119, Val Acc: 0.4971
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6156, Acc: 0.6579, Val Loss: 0.7134, Val Acc: 0.5044
Epoch 23/100, Loss: 0.6148, Acc: 0.6608, Val Loss: 0.7142, Val Acc: 0.4963
Epoch 24/100, Loss: 0.6148, Acc: 0.6609, Val Loss: 0.7042, Val Acc: 0.5335
Epoch 25/100, Loss: 0.6150, Acc: 0.6599, Val Loss: 0.7161, Val Acc: 0.5155
Epoch 26/100, Loss: 0.6140, Acc: 0.6590, Val Loss: 0.7143, Val Acc: 0.5015
Epoch 27/100, Loss: 0.6138, Acc: 0.6594, Val Loss: 0.7171, Val Acc: 0.5007
Epoch 28/100, Loss: 0.6129, Acc: 0.6646, Val Loss: 0.7219, Val Acc: 0.5173
Epoch 29/100, Loss: 0.6128, Acc: 0.6627, Val Loss: 0.7154, Val Acc: 0.5191
Epoch 30/100, Loss: 0.6145, Acc: 0.6615, Val Loss: 0.7177, Val Acc: 0.5173
Epoch 31/100, Loss: 0.6135, Acc: 0.6595, Val Loss: 0.7115, Val Acc: 0.5132
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6110, Acc: 0.6632, Val Loss: 0.7159, Val Acc: 0.5081
Epoch 33/100, Loss: 0.6108, Acc: 0.6626, Val Loss: 0.7199, Val Acc: 0.5022
Epoch 34/100, Loss: 0.6106, Acc: 0.6641, Val Loss: 0.7156, Val Acc: 0.5096
Epoch 35/100, Loss: 0.6101, Acc: 0.6636, Val Loss: 0.7219, Val Acc: 0.5096
Epoch 36/100, Loss: 0.6109, Acc: 0.6651, Val Loss: 0.7166, Val Acc: 0.5015
Epoch 37/100, Loss: 0.6102, Acc: 0.6634, Val Loss: 0.7165, Val Acc: 0.5048
Epoch 38/100, Loss: 0.6104, Acc: 0.6623, Val Loss: 0.7168, Val Acc: 0.5063
Epoch 39/100, Loss: 0.6098, Acc: 0.6653, Val Loss: 0.7184, Val Acc: 0.5191
Epoch 40/100, Loss: 0.6106, Acc: 0.6607, Val Loss: 0.7197, Val Acc: 0.4993
Epoch 41/100, Loss: 0.6103, Acc: 0.6627, Val Loss: 0.7213, Val Acc: 0.5206
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6093, Acc: 0.6638, Val Loss: 0.7188, Val Acc: 0.5096
Epoch 43/100, Loss: 0.6095, Acc: 0.6610, Val Loss: 0.7206, Val Acc: 0.5132
Epoch 44/100, Loss: 0.6094, Acc: 0.6635, Val Loss: 0.7198, Val Acc: 0.5092
Epoch 45/100, Loss: 0.6093, Acc: 0.6643, Val Loss: 0.7207, Val Acc: 0.5114
Epoch 46/100, Loss: 0.6091, Acc: 0.6638, Val Loss: 0.7207, Val Acc: 0.5121
Epoch 47/100, Loss: 0.6092, Acc: 0.6639, Val Loss: 0.7195, Val Acc: 0.5070
Epoch 48/100, Loss: 0.6088, Acc: 0.6637, Val Loss: 0.7202, Val Acc: 0.5114
Epoch 49/100, Loss: 0.6092, Acc: 0.6634, Val Loss: 0.7196, Val Acc: 0.5158
Epoch 50/100, Loss: 0.6088, Acc: 0.6648, Val Loss: 0.7194, Val Acc: 0.5092
Epoch 51/100, Loss: 0.6090, Acc: 0.6646, Val Loss: 0.7207, Val Acc: 0.5121
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6085, Acc: 0.6631, Val Loss: 0.7199, Val Acc: 0.5063
Epoch 53/100, Loss: 0.6084, Acc: 0.6632, Val Loss: 0.7201, Val Acc: 0.5118
Epoch 54/100, Loss: 0.6086, Acc: 0.6633, Val Loss: 0.7199, Val Acc: 0.5107
Epoch 55/100, Loss: 0.6083, Acc: 0.6634, Val Loss: 0.7196, Val Acc: 0.5066
Epoch 56/100, Loss: 0.6084, Acc: 0.6643, Val Loss: 0.7195, Val Acc: 0.5063
Epoch 57/100, Loss: 0.6082, Acc: 0.6643, Val Loss: 0.7203, Val Acc: 0.5140
Epoch 58/100, Loss: 0.6081, Acc: 0.6622, Val Loss: 0.7214, Val Acc: 0.5074
Epoch 59/100, Loss: 0.6083, Acc: 0.6641, Val Loss: 0.7203, Val Acc: 0.5088
Epoch 60/100, Loss: 0.6082, Acc: 0.6642, Val Loss: 0.7208, Val Acc: 0.5077
Epoch 61/100, Loss: 0.6082, Acc: 0.6654, Val Loss: 0.7215, Val Acc: 0.5059
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6079, Acc: 0.6656, Val Loss: 0.7198, Val Acc: 0.5096
Epoch 63/100, Loss: 0.6080, Acc: 0.6649, Val Loss: 0.7202, Val Acc: 0.5066
Epoch 64/100, Loss: 0.6079, Acc: 0.6651, Val Loss: 0.7202, Val Acc: 0.5066
Epoch 65/100, Loss: 0.6079, Acc: 0.6653, Val Loss: 0.7199, Val Acc: 0.5066
Epoch 66/100, Loss: 0.6080, Acc: 0.6643, Val Loss: 0.7202, Val Acc: 0.5059
Epoch 67/100, Loss: 0.6080, Acc: 0.6630, Val Loss: 0.7205, Val Acc: 0.5063
Epoch 68/100, Loss: 0.6078, Acc: 0.6641, Val Loss: 0.7201, Val Acc: 0.5059
Epoch 69/100, Loss: 0.6078, Acc: 0.6637, Val Loss: 0.7209, Val Acc: 0.5070
Epoch 70/100, Loss: 0.6079, Acc: 0.6645, Val Loss: 0.7212, Val Acc: 0.5077
Epoch 71/100, Loss: 0.6078, Acc: 0.6642, Val Loss: 0.7206, Val Acc: 0.5107
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6077, Acc: 0.6649, Val Loss: 0.7205, Val Acc: 0.5066
Epoch 73/100, Loss: 0.6078, Acc: 0.6657, Val Loss: 0.7196, Val Acc: 0.5077
Epoch 74/100, Loss: 0.6077, Acc: 0.6652, Val Loss: 0.7202, Val Acc: 0.5063
Epoch 75/100, Loss: 0.6077, Acc: 0.6647, Val Loss: 0.7203, Val Acc: 0.5063
Epoch 76/100, Loss: 0.6077, Acc: 0.6643, Val Loss: 0.7205, Val Acc: 0.5066
Epoch 77/100, Loss: 0.6077, Acc: 0.6637, Val Loss: 0.7206, Val Acc: 0.5074
Epoch 78/100, Loss: 0.6077, Acc: 0.6641, Val Loss: 0.7208, Val Acc: 0.5110
Epoch 79/100, Loss: 0.6077, Acc: 0.6649, Val Loss: 0.7209, Val Acc: 0.5107
Epoch 80/100, Loss: 0.6077, Acc: 0.6643, Val Loss: 0.7202, Val Acc: 0.5103
Epoch 81/100, Loss: 0.6076, Acc: 0.6657, Val Loss: 0.7204, Val Acc: 0.5070
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6076, Acc: 0.6640, Val Loss: 0.7207, Val Acc: 0.5066
Epoch 83/100, Loss: 0.6076, Acc: 0.6652, Val Loss: 0.7206, Val Acc: 0.5063
Epoch 84/100, Loss: 0.6076, Acc: 0.6640, Val Loss: 0.7206, Val Acc: 0.5096
Epoch 85/100, Loss: 0.6076, Acc: 0.6638, Val Loss: 0.7210, Val Acc: 0.5074
Epoch 86/100, Loss: 0.6075, Acc: 0.6646, Val Loss: 0.7212, Val Acc: 0.5070
Epoch 87/100, Loss: 0.6075, Acc: 0.6643, Val Loss: 0.7214, Val Acc: 0.5074
Epoch 88/100, Loss: 0.6074, Acc: 0.6640, Val Loss: 0.7212, Val Acc: 0.5066
Epoch 89/100, Loss: 0.6075, Acc: 0.6653, Val Loss: 0.7209, Val Acc: 0.5074
Epoch 90/100, Loss: 0.6075, Acc: 0.6649, Val Loss: 0.7207, Val Acc: 0.5070
Epoch 91/100, Loss: 0.6075, Acc: 0.6647, Val Loss: 0.7206, Val Acc: 0.5066
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6074, Acc: 0.6645, Val Loss: 0.7213, Val Acc: 0.5063
Epoch 93/100, Loss: 0.6074, Acc: 0.6640, Val Loss: 0.7212, Val Acc: 0.5070
Epoch 94/100, Loss: 0.6074, Acc: 0.6645, Val Loss: 0.7212, Val Acc: 0.5066
Epoch 95/100, Loss: 0.6073, Acc: 0.6646, Val Loss: 0.7212, Val Acc: 0.5059
Epoch 96/100, Loss: 0.6074, Acc: 0.6626, Val Loss: 0.7213, Val Acc: 0.5070
Epoch 97/100, Loss: 0.6073, Acc: 0.6657, Val Loss: 0.7220, Val Acc: 0.5063
Epoch 98/100, Loss: 0.6073, Acc: 0.6652, Val Loss: 0.7217, Val Acc: 0.5063
Epoch 99/100, Loss: 0.6072, Acc: 0.6646, Val Loss: 0.7223, Val Acc: 0.5066
Epoch 100/100, Loss: 0.6072, Acc: 0.6649, Val Loss: 0.7214, Val Acc: 0.5055

##############################
Resultados para principal:  026  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3 
 {'training': [0.6072322300063883, 0.6649200220628793, 0.6451351788894285, 0.7328061787421847, 0.6861816616444253], 'validate': [0.7214455316926158, 0.5055187637969095, 0.5042892156862745, 0.6060382916053019, 0.5505016722408027], 'test': [0.7158887717458937, 0.47704532077692763, 0.48328396106644095, 0.6725559481743227, 0.5624230485102192]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  110  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  110  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  110  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5239, Acc: 0.7790, Val Loss: 0.7026, Val Acc: 0.6019
Mejor modelo guardado con Val Loss: 0.7026
Epoch 2/100, Loss: 0.4369, Acc: 0.8035, Val Loss: 0.7197, Val Acc: 0.6074
Epoch 3/100, Loss: 0.4261, Acc: 0.8060, Val Loss: 0.7847, Val Acc: 0.5537
Epoch 4/100, Loss: 0.4320, Acc: 0.8023, Val Loss: 0.7284, Val Acc: 0.5795
Epoch 5/100, Loss: 0.4211, Acc: 0.8054, Val Loss: 0.7382, Val Acc: 0.5990
Epoch 6/100, Loss: 0.4196, Acc: 0.8096, Val Loss: 0.7029, Val Acc: 0.6041
Epoch 7/100, Loss: 0.4252, Acc: 0.8070, Val Loss: 0.7182, Val Acc: 0.5971
Epoch 8/100, Loss: 0.4140, Acc: 0.8122, Val Loss: 0.7057, Val Acc: 0.5843
Epoch 9/100, Loss: 0.4163, Acc: 0.8104, Val Loss: 0.7193, Val Acc: 0.6056
Epoch 10/100, Loss: 0.4195, Acc: 0.8094, Val Loss: 0.7222, Val Acc: 0.5982
Epoch 11/100, Loss: 0.4164, Acc: 0.8093, Val Loss: 0.7401, Val Acc: 0.6001
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4106, Acc: 0.8138, Val Loss: 0.7948, Val Acc: 0.5879
Epoch 13/100, Loss: 0.4077, Acc: 0.8138, Val Loss: 0.7479, Val Acc: 0.5868
Epoch 14/100, Loss: 0.4066, Acc: 0.8153, Val Loss: 0.7657, Val Acc: 0.6093
Epoch 15/100, Loss: 0.4075, Acc: 0.8166, Val Loss: 0.7743, Val Acc: 0.6026
Epoch 16/100, Loss: 0.4039, Acc: 0.8176, Val Loss: 0.7515, Val Acc: 0.6038
Epoch 17/100, Loss: 0.4036, Acc: 0.8175, Val Loss: 0.7392, Val Acc: 0.6100
Epoch 18/100, Loss: 0.4013, Acc: 0.8195, Val Loss: 0.7578, Val Acc: 0.6049
Epoch 19/100, Loss: 0.4016, Acc: 0.8203, Val Loss: 0.7919, Val Acc: 0.6034
Epoch 20/100, Loss: 0.4020, Acc: 0.8200, Val Loss: 0.7490, Val Acc: 0.6074
Epoch 21/100, Loss: 0.4029, Acc: 0.8206, Val Loss: 0.7914, Val Acc: 0.6049
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3974, Acc: 0.8235, Val Loss: 0.7787, Val Acc: 0.6038
Epoch 23/100, Loss: 0.3970, Acc: 0.8213, Val Loss: 0.7792, Val Acc: 0.6082
Epoch 24/100, Loss: 0.3959, Acc: 0.8216, Val Loss: 0.7665, Val Acc: 0.6096
Epoch 25/100, Loss: 0.3939, Acc: 0.8237, Val Loss: 0.7608, Val Acc: 0.6008
Epoch 26/100, Loss: 0.3941, Acc: 0.8260, Val Loss: 0.8010, Val Acc: 0.6166
Epoch 27/100, Loss: 0.3946, Acc: 0.8242, Val Loss: 0.7653, Val Acc: 0.6067
Epoch 28/100, Loss: 0.3930, Acc: 0.8259, Val Loss: 0.7854, Val Acc: 0.6082
Epoch 29/100, Loss: 0.3941, Acc: 0.8230, Val Loss: 0.7426, Val Acc: 0.6118
Epoch 30/100, Loss: 0.3927, Acc: 0.8245, Val Loss: 0.7559, Val Acc: 0.6122
Epoch 31/100, Loss: 0.3920, Acc: 0.8256, Val Loss: 0.7597, Val Acc: 0.6137
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3897, Acc: 0.8273, Val Loss: 0.7787, Val Acc: 0.6115
Epoch 33/100, Loss: 0.3889, Acc: 0.8240, Val Loss: 0.7825, Val Acc: 0.6122
Epoch 34/100, Loss: 0.3886, Acc: 0.8260, Val Loss: 0.7671, Val Acc: 0.6100
Epoch 35/100, Loss: 0.3891, Acc: 0.8261, Val Loss: 0.7519, Val Acc: 0.6118
Epoch 36/100, Loss: 0.3877, Acc: 0.8262, Val Loss: 0.7847, Val Acc: 0.6096
Epoch 37/100, Loss: 0.3884, Acc: 0.8276, Val Loss: 0.7908, Val Acc: 0.6085
Epoch 38/100, Loss: 0.3884, Acc: 0.8287, Val Loss: 0.7613, Val Acc: 0.6107
Epoch 39/100, Loss: 0.3871, Acc: 0.8280, Val Loss: 0.7604, Val Acc: 0.6118
Epoch 40/100, Loss: 0.3871, Acc: 0.8267, Val Loss: 0.7392, Val Acc: 0.6093
Epoch 41/100, Loss: 0.3871, Acc: 0.8266, Val Loss: 0.7740, Val Acc: 0.6130
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3854, Acc: 0.8286, Val Loss: 0.7738, Val Acc: 0.6159
Epoch 43/100, Loss: 0.3854, Acc: 0.8268, Val Loss: 0.7699, Val Acc: 0.6107
Epoch 44/100, Loss: 0.3852, Acc: 0.8289, Val Loss: 0.7728, Val Acc: 0.6085
Epoch 45/100, Loss: 0.3852, Acc: 0.8284, Val Loss: 0.7678, Val Acc: 0.6096
Epoch 46/100, Loss: 0.3857, Acc: 0.8282, Val Loss: 0.7706, Val Acc: 0.6130
Epoch 47/100, Loss: 0.3843, Acc: 0.8279, Val Loss: 0.7779, Val Acc: 0.6122
Epoch 48/100, Loss: 0.3848, Acc: 0.8281, Val Loss: 0.7695, Val Acc: 0.6137
Epoch 49/100, Loss: 0.3842, Acc: 0.8292, Val Loss: 0.7631, Val Acc: 0.6130
Epoch 50/100, Loss: 0.3841, Acc: 0.8285, Val Loss: 0.7671, Val Acc: 0.6133
Epoch 51/100, Loss: 0.3844, Acc: 0.8271, Val Loss: 0.7745, Val Acc: 0.6118
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3833, Acc: 0.8283, Val Loss: 0.7615, Val Acc: 0.6118
Epoch 53/100, Loss: 0.3830, Acc: 0.8284, Val Loss: 0.7726, Val Acc: 0.6118
Epoch 54/100, Loss: 0.3834, Acc: 0.8289, Val Loss: 0.7631, Val Acc: 0.6115
Epoch 55/100, Loss: 0.3831, Acc: 0.8287, Val Loss: 0.7694, Val Acc: 0.6137
Epoch 56/100, Loss: 0.3830, Acc: 0.8289, Val Loss: 0.7750, Val Acc: 0.6089
Epoch 57/100, Loss: 0.3830, Acc: 0.8284, Val Loss: 0.7718, Val Acc: 0.6126
Epoch 58/100, Loss: 0.3830, Acc: 0.8288, Val Loss: 0.7684, Val Acc: 0.6122
Epoch 59/100, Loss: 0.3827, Acc: 0.8274, Val Loss: 0.7683, Val Acc: 0.6122
Epoch 60/100, Loss: 0.3827, Acc: 0.8290, Val Loss: 0.7663, Val Acc: 0.6118
Epoch 61/100, Loss: 0.3830, Acc: 0.8283, Val Loss: 0.7647, Val Acc: 0.6096
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3823, Acc: 0.8282, Val Loss: 0.7677, Val Acc: 0.6118
Epoch 63/100, Loss: 0.3822, Acc: 0.8289, Val Loss: 0.7660, Val Acc: 0.6107
Epoch 64/100, Loss: 0.3823, Acc: 0.8288, Val Loss: 0.7674, Val Acc: 0.6111
Epoch 65/100, Loss: 0.3822, Acc: 0.8292, Val Loss: 0.7699, Val Acc: 0.6107
Epoch 66/100, Loss: 0.3822, Acc: 0.8287, Val Loss: 0.7699, Val Acc: 0.6107
Epoch 67/100, Loss: 0.3821, Acc: 0.8285, Val Loss: 0.7665, Val Acc: 0.6115
Epoch 68/100, Loss: 0.3821, Acc: 0.8292, Val Loss: 0.7700, Val Acc: 0.6100
Epoch 69/100, Loss: 0.3820, Acc: 0.8284, Val Loss: 0.7709, Val Acc: 0.6100
Epoch 70/100, Loss: 0.3820, Acc: 0.8276, Val Loss: 0.7688, Val Acc: 0.6126
Epoch 71/100, Loss: 0.3820, Acc: 0.8289, Val Loss: 0.7706, Val Acc: 0.6104
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3818, Acc: 0.8285, Val Loss: 0.7697, Val Acc: 0.6111
Epoch 73/100, Loss: 0.3819, Acc: 0.8277, Val Loss: 0.7694, Val Acc: 0.6118
Epoch 74/100, Loss: 0.3818, Acc: 0.8299, Val Loss: 0.7696, Val Acc: 0.6100
Epoch 75/100, Loss: 0.3818, Acc: 0.8277, Val Loss: 0.7691, Val Acc: 0.6115
Epoch 76/100, Loss: 0.3817, Acc: 0.8289, Val Loss: 0.7676, Val Acc: 0.6104
Epoch 77/100, Loss: 0.3817, Acc: 0.8285, Val Loss: 0.7682, Val Acc: 0.6115
Epoch 78/100, Loss: 0.3817, Acc: 0.8278, Val Loss: 0.7671, Val Acc: 0.6118
Epoch 79/100, Loss: 0.3817, Acc: 0.8287, Val Loss: 0.7688, Val Acc: 0.6115
Epoch 80/100, Loss: 0.3817, Acc: 0.8285, Val Loss: 0.7694, Val Acc: 0.6107
Epoch 81/100, Loss: 0.3817, Acc: 0.8286, Val Loss: 0.7696, Val Acc: 0.6122
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3816, Acc: 0.8288, Val Loss: 0.7691, Val Acc: 0.6107
Epoch 83/100, Loss: 0.3816, Acc: 0.8284, Val Loss: 0.7694, Val Acc: 0.6115
Epoch 84/100, Loss: 0.3817, Acc: 0.8281, Val Loss: 0.7702, Val Acc: 0.6118
Epoch 85/100, Loss: 0.3816, Acc: 0.8291, Val Loss: 0.7687, Val Acc: 0.6104
Epoch 86/100, Loss: 0.3816, Acc: 0.8288, Val Loss: 0.7690, Val Acc: 0.6100
Epoch 87/100, Loss: 0.3815, Acc: 0.8287, Val Loss: 0.7695, Val Acc: 0.6107
Epoch 88/100, Loss: 0.3815, Acc: 0.8288, Val Loss: 0.7701, Val Acc: 0.6118
Epoch 89/100, Loss: 0.3815, Acc: 0.8286, Val Loss: 0.7688, Val Acc: 0.6115
Epoch 90/100, Loss: 0.3815, Acc: 0.8276, Val Loss: 0.7688, Val Acc: 0.6115
Epoch 91/100, Loss: 0.3815, Acc: 0.8284, Val Loss: 0.7715, Val Acc: 0.6115
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3814, Acc: 0.8280, Val Loss: 0.7699, Val Acc: 0.6115
Epoch 93/100, Loss: 0.3815, Acc: 0.8288, Val Loss: 0.7684, Val Acc: 0.6122
Epoch 94/100, Loss: 0.3814, Acc: 0.8288, Val Loss: 0.7692, Val Acc: 0.6111
Epoch 95/100, Loss: 0.3813, Acc: 0.8294, Val Loss: 0.7707, Val Acc: 0.6104
Epoch 96/100, Loss: 0.3815, Acc: 0.8285, Val Loss: 0.7692, Val Acc: 0.6100
Epoch 97/100, Loss: 0.3813, Acc: 0.8292, Val Loss: 0.7693, Val Acc: 0.6118
Epoch 98/100, Loss: 0.3814, Acc: 0.8276, Val Loss: 0.7684, Val Acc: 0.6107
Epoch 99/100, Loss: 0.3813, Acc: 0.8294, Val Loss: 0.7704, Val Acc: 0.6093
Epoch 100/100, Loss: 0.3812, Acc: 0.8280, Val Loss: 0.7682, Val Acc: 0.6111

##############################
Resultados para principal:  110  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  3 
 {'training': [0.38116481005981095, 0.8280014708586138, 0.8025445292620865, 0.8699889665318131, 0.834906909026736], 'validate': [0.7682429423858953, 0.6111111111111112, 0.5852691218130311, 0.7606774668630338, 0.6615433877681717], 'test': [0.7288113203313615, 0.5950559152442614, 0.5633858267716535, 0.842756183745583, 0.6753185464841907]}

##############################
Resultados para window:  3 
 {'064:060:028:033:026:110': {'training': [0.4548940374902075, 0.7863577863577863, 0.7614170584284755, 0.8339463037881574, 0.7960329998244691], 'validate': [0.8621118616226108, 0.5334805003679176, 0.5208526413345691, 0.8276877761413843, 0.6393629124004551], 'test': [0.9209948049651252, 0.39081812831077106, 0.4308550185873606, 0.682567726737338, 0.5282588878760255]}, '060:064:028:033:026:110': {'training': [0.5735930464333044, 0.6916712630998345, 0.7699481865284974, 0.5465244575211475, 0.6392772639277264], 'validate': [0.7657825815123182, 0.4771891096394408, 0.352112676056338, 0.05522827687776141, 0.09548058561425843], 'test': [0.7265014924384929, 0.4726309593878752, 0.4528112449799197, 0.2656065959952886, 0.3348181143281366]}, '028:064:060:033:026:110': {'training': [0.3925942424674489, 0.8236808236808236, 0.8657522859517872, 0.766090474439132, 0.8128780487804877], 'validate': [0.45432703370271726, 0.8156732891832229, 0.9350253807106599, 0.6782032400589102, 0.7861715749039693], 'test': [0.7131217043432925, 0.6177163037080635, 0.9443207126948775, 0.2497055359246172, 0.39496972519795065]}, '033:064:060:028:026:110': {'training': [0.630816096186879, 0.6401912116197831, 0.6723981900452489, 0.5465244575211475, 0.6029620612700345], 'validate': [0.7639429097951844, 0.4915378955114054, 0.49193548387096775, 0.5390279823269514, 0.5144061841180604], 'test': [0.6930194861359067, 0.5002942907592701, 0.0, 0.0, 0.0]}, '026:064:060:028:033:110': {'training': [0.6072322300063883, 0.6649200220628793, 0.6451351788894285, 0.7328061787421847, 0.6861816616444253], 'validate': [0.7214455316926158, 0.5055187637969095, 0.5042892156862745, 0.6060382916053019, 0.5505016722408027], 'test': [0.7158887717458937, 0.47704532077692763, 0.48328396106644095, 0.6725559481743227, 0.5624230485102192]}, '110:064:060:028:033:026': {'training': [0.38116481005981095, 0.8280014708586138, 0.8025445292620865, 0.8699889665318131, 0.834906909026736], 'validate': [0.7682429423858953, 0.6111111111111112, 0.5852691218130311, 0.7606774668630338, 0.6615433877681717], 'test': [0.7288113203313615, 0.5950559152442614, 0.5633858267716535, 0.842756183745583, 0.6753185464841907]}}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  104  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  104  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  104  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6843, Acc: 0.5568, Val Loss: 0.6414, Val Acc: 0.6060
Mejor modelo guardado con Val Loss: 0.6414
Epoch 2/100, Loss: 0.6809, Acc: 0.5657, Val Loss: 0.5832, Val Acc: 0.8620
Mejor modelo guardado con Val Loss: 0.5832
Epoch 3/100, Loss: 0.6772, Acc: 0.5780, Val Loss: 0.5780, Val Acc: 0.8981
Mejor modelo guardado con Val Loss: 0.5780
Epoch 4/100, Loss: 0.6767, Acc: 0.5784, Val Loss: 0.5831, Val Acc: 0.8263
Epoch 5/100, Loss: 0.6782, Acc: 0.5752, Val Loss: 0.5966, Val Acc: 0.6229
Epoch 6/100, Loss: 0.6731, Acc: 0.5780, Val Loss: 0.5494, Val Acc: 0.7524
Mejor modelo guardado con Val Loss: 0.5494
Epoch 7/100, Loss: 0.6696, Acc: 0.5834, Val Loss: 0.5543, Val Acc: 0.5552
Epoch 8/100, Loss: 0.6680, Acc: 0.5869, Val Loss: 0.4850, Val Acc: 0.9249
Mejor modelo guardado con Val Loss: 0.4850
Epoch 9/100, Loss: 0.6659, Acc: 0.5826, Val Loss: 0.4797, Val Acc: 0.8779
Mejor modelo guardado con Val Loss: 0.4797
Epoch 10/100, Loss: 0.6722, Acc: 0.5678, Val Loss: 0.5189, Val Acc: 0.8602
Epoch 11/100, Loss: 0.6657, Acc: 0.5921, Val Loss: 0.5453, Val Acc: 0.7211
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6605, Acc: 0.5999, Val Loss: 0.4924, Val Acc: 0.8948
Epoch 13/100, Loss: 0.6607, Acc: 0.5951, Val Loss: 0.5151, Val Acc: 0.8131
Epoch 14/100, Loss: 0.6603, Acc: 0.5962, Val Loss: 0.4838, Val Acc: 0.8793
Epoch 15/100, Loss: 0.6600, Acc: 0.5971, Val Loss: 0.5306, Val Acc: 0.7127
Epoch 16/100, Loss: 0.6573, Acc: 0.6005, Val Loss: 0.4940, Val Acc: 0.8458
Epoch 17/100, Loss: 0.6570, Acc: 0.6006, Val Loss: 0.5066, Val Acc: 0.8120
Epoch 18/100, Loss: 0.6576, Acc: 0.5977, Val Loss: 0.4677, Val Acc: 0.8826
Mejor modelo guardado con Val Loss: 0.4677
Epoch 19/100, Loss: 0.6566, Acc: 0.6044, Val Loss: 0.4617, Val Acc: 0.8904
Mejor modelo guardado con Val Loss: 0.4617
Epoch 20/100, Loss: 0.6560, Acc: 0.6008, Val Loss: 0.4706, Val Acc: 0.8536
Epoch 21/100, Loss: 0.6550, Acc: 0.6044, Val Loss: 0.4884, Val Acc: 0.7999
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6535, Acc: 0.6063, Val Loss: 0.4715, Val Acc: 0.8425
Epoch 23/100, Loss: 0.6531, Acc: 0.6096, Val Loss: 0.4861, Val Acc: 0.7818
Epoch 24/100, Loss: 0.6533, Acc: 0.6073, Val Loss: 0.4808, Val Acc: 0.8050
Epoch 25/100, Loss: 0.6524, Acc: 0.6061, Val Loss: 0.4593, Val Acc: 0.8492
Mejor modelo guardado con Val Loss: 0.4593
Epoch 26/100, Loss: 0.6532, Acc: 0.6052, Val Loss: 0.4612, Val Acc: 0.8392
Epoch 27/100, Loss: 0.6524, Acc: 0.6085, Val Loss: 0.4715, Val Acc: 0.8131
Epoch 28/100, Loss: 0.6519, Acc: 0.6062, Val Loss: 0.4741, Val Acc: 0.8337
Epoch 29/100, Loss: 0.6516, Acc: 0.6091, Val Loss: 0.4508, Val Acc: 0.8709
Mejor modelo guardado con Val Loss: 0.4508
Epoch 30/100, Loss: 0.6512, Acc: 0.6112, Val Loss: 0.4434, Val Acc: 0.8856
Mejor modelo guardado con Val Loss: 0.4434
Epoch 31/100, Loss: 0.6516, Acc: 0.6059, Val Loss: 0.4433, Val Acc: 0.8797
Mejor modelo guardado con Val Loss: 0.4433
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6502, Acc: 0.6110, Val Loss: 0.4628, Val Acc: 0.8319
Epoch 33/100, Loss: 0.6503, Acc: 0.6074, Val Loss: 0.4403, Val Acc: 0.8812
Mejor modelo guardado con Val Loss: 0.4403
Epoch 34/100, Loss: 0.6507, Acc: 0.6082, Val Loss: 0.4573, Val Acc: 0.8392
Epoch 35/100, Loss: 0.6499, Acc: 0.6100, Val Loss: 0.4426, Val Acc: 0.8720
Epoch 36/100, Loss: 0.6494, Acc: 0.6141, Val Loss: 0.4390, Val Acc: 0.8753
Mejor modelo guardado con Val Loss: 0.4390
Epoch 37/100, Loss: 0.6498, Acc: 0.6088, Val Loss: 0.4359, Val Acc: 0.8786
Mejor modelo guardado con Val Loss: 0.4359
Epoch 38/100, Loss: 0.6493, Acc: 0.6099, Val Loss: 0.4680, Val Acc: 0.8102
Epoch 39/100, Loss: 0.6498, Acc: 0.6120, Val Loss: 0.4637, Val Acc: 0.8102
Epoch 40/100, Loss: 0.6495, Acc: 0.6101, Val Loss: 0.4423, Val Acc: 0.8650
Epoch 41/100, Loss: 0.6490, Acc: 0.6119, Val Loss: 0.4489, Val Acc: 0.8495
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6487, Acc: 0.6115, Val Loss: 0.4548, Val Acc: 0.8407
Epoch 43/100, Loss: 0.6488, Acc: 0.6111, Val Loss: 0.4514, Val Acc: 0.8433
Epoch 44/100, Loss: 0.6487, Acc: 0.6105, Val Loss: 0.4541, Val Acc: 0.8348
Epoch 45/100, Loss: 0.6482, Acc: 0.6126, Val Loss: 0.4376, Val Acc: 0.8709
Epoch 46/100, Loss: 0.6487, Acc: 0.6122, Val Loss: 0.4428, Val Acc: 0.8617
Epoch 47/100, Loss: 0.6484, Acc: 0.6122, Val Loss: 0.4427, Val Acc: 0.8576
Epoch 48/100, Loss: 0.6483, Acc: 0.6143, Val Loss: 0.4469, Val Acc: 0.8481
Epoch 49/100, Loss: 0.6482, Acc: 0.6133, Val Loss: 0.4531, Val Acc: 0.8271
Epoch 50/100, Loss: 0.6480, Acc: 0.6123, Val Loss: 0.4501, Val Acc: 0.8418
Epoch 51/100, Loss: 0.6481, Acc: 0.6117, Val Loss: 0.4573, Val Acc: 0.8289
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6479, Acc: 0.6135, Val Loss: 0.4473, Val Acc: 0.8499
Epoch 53/100, Loss: 0.6479, Acc: 0.6130, Val Loss: 0.4533, Val Acc: 0.8359
Epoch 54/100, Loss: 0.6473, Acc: 0.6133, Val Loss: 0.4371, Val Acc: 0.8642
Epoch 55/100, Loss: 0.6476, Acc: 0.6123, Val Loss: 0.4500, Val Acc: 0.8422
Epoch 56/100, Loss: 0.6475, Acc: 0.6137, Val Loss: 0.4436, Val Acc: 0.8550
Epoch 57/100, Loss: 0.6474, Acc: 0.6138, Val Loss: 0.4407, Val Acc: 0.8587
Epoch 58/100, Loss: 0.6477, Acc: 0.6128, Val Loss: 0.4511, Val Acc: 0.8396
Epoch 59/100, Loss: 0.6474, Acc: 0.6146, Val Loss: 0.4509, Val Acc: 0.8374
Epoch 60/100, Loss: 0.6474, Acc: 0.6148, Val Loss: 0.4520, Val Acc: 0.8344
Epoch 61/100, Loss: 0.6475, Acc: 0.6143, Val Loss: 0.4456, Val Acc: 0.8506
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6472, Acc: 0.6145, Val Loss: 0.4456, Val Acc: 0.8517
Epoch 63/100, Loss: 0.6471, Acc: 0.6146, Val Loss: 0.4465, Val Acc: 0.8481
Epoch 64/100, Loss: 0.6471, Acc: 0.6160, Val Loss: 0.4469, Val Acc: 0.8458
Epoch 65/100, Loss: 0.6472, Acc: 0.6137, Val Loss: 0.4483, Val Acc: 0.8425
Epoch 66/100, Loss: 0.6471, Acc: 0.6148, Val Loss: 0.4460, Val Acc: 0.8473
Epoch 67/100, Loss: 0.6471, Acc: 0.6147, Val Loss: 0.4464, Val Acc: 0.8462
Epoch 68/100, Loss: 0.6470, Acc: 0.6134, Val Loss: 0.4411, Val Acc: 0.8536
Epoch 69/100, Loss: 0.6471, Acc: 0.6136, Val Loss: 0.4419, Val Acc: 0.8517
Epoch 70/100, Loss: 0.6470, Acc: 0.6153, Val Loss: 0.4463, Val Acc: 0.8447
Epoch 71/100, Loss: 0.6471, Acc: 0.6144, Val Loss: 0.4512, Val Acc: 0.8319
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6470, Acc: 0.6132, Val Loss: 0.4482, Val Acc: 0.8396
Epoch 73/100, Loss: 0.6470, Acc: 0.6137, Val Loss: 0.4470, Val Acc: 0.8440
Epoch 74/100, Loss: 0.6469, Acc: 0.6138, Val Loss: 0.4419, Val Acc: 0.8492
Epoch 75/100, Loss: 0.6469, Acc: 0.6144, Val Loss: 0.4433, Val Acc: 0.8484
Epoch 76/100, Loss: 0.6469, Acc: 0.6148, Val Loss: 0.4438, Val Acc: 0.8484
Epoch 77/100, Loss: 0.6468, Acc: 0.6146, Val Loss: 0.4431, Val Acc: 0.8488
Epoch 78/100, Loss: 0.6469, Acc: 0.6155, Val Loss: 0.4440, Val Acc: 0.8466
Epoch 79/100, Loss: 0.6468, Acc: 0.6142, Val Loss: 0.4435, Val Acc: 0.8481
Epoch 80/100, Loss: 0.6468, Acc: 0.6147, Val Loss: 0.4438, Val Acc: 0.8455
Epoch 81/100, Loss: 0.6468, Acc: 0.6137, Val Loss: 0.4454, Val Acc: 0.8436
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6468, Acc: 0.6145, Val Loss: 0.4463, Val Acc: 0.8425
Epoch 83/100, Loss: 0.6468, Acc: 0.6133, Val Loss: 0.4462, Val Acc: 0.8411
Epoch 84/100, Loss: 0.6468, Acc: 0.6135, Val Loss: 0.4448, Val Acc: 0.8447
Epoch 85/100, Loss: 0.6468, Acc: 0.6145, Val Loss: 0.4439, Val Acc: 0.8458
Epoch 86/100, Loss: 0.6467, Acc: 0.6145, Val Loss: 0.4459, Val Acc: 0.8436
Epoch 87/100, Loss: 0.6467, Acc: 0.6155, Val Loss: 0.4418, Val Acc: 0.8495
Epoch 88/100, Loss: 0.6467, Acc: 0.6152, Val Loss: 0.4458, Val Acc: 0.8418
Epoch 89/100, Loss: 0.6467, Acc: 0.6134, Val Loss: 0.4438, Val Acc: 0.8462
Epoch 90/100, Loss: 0.6468, Acc: 0.6147, Val Loss: 0.4434, Val Acc: 0.8462
Epoch 91/100, Loss: 0.6467, Acc: 0.6152, Val Loss: 0.4433, Val Acc: 0.8458
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6467, Acc: 0.6145, Val Loss: 0.4456, Val Acc: 0.8440
Epoch 93/100, Loss: 0.6467, Acc: 0.6145, Val Loss: 0.4444, Val Acc: 0.8451
Epoch 94/100, Loss: 0.6467, Acc: 0.6153, Val Loss: 0.4431, Val Acc: 0.8484
Epoch 95/100, Loss: 0.6466, Acc: 0.6145, Val Loss: 0.4430, Val Acc: 0.8477
Epoch 96/100, Loss: 0.6467, Acc: 0.6152, Val Loss: 0.4434, Val Acc: 0.8469
Epoch 97/100, Loss: 0.6466, Acc: 0.6153, Val Loss: 0.4425, Val Acc: 0.8484
Epoch 98/100, Loss: 0.6466, Acc: 0.6145, Val Loss: 0.4447, Val Acc: 0.8447
Epoch 99/100, Loss: 0.6466, Acc: 0.6145, Val Loss: 0.4445, Val Acc: 0.8451
Epoch 100/100, Loss: 0.6467, Acc: 0.6152, Val Loss: 0.4429, Val Acc: 0.8469

##############################
Resultados para principal:  104  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3 
 {'training': [0.6466618932154845, 0.6151866151866152, 0.5869202999166898, 0.7773078337624126, 0.6688291139240506], 'validate': [0.4428813495608263, 0.8469462840323767, 0.9776876267748479, 0.7098674521354934, 0.8225255972696246], 'test': [0.46725953232359, 0.8549146556798116, 0.8869621066152859, 0.8133097762073027, 0.8485407066052227]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  093  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  093  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  093  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6639, Acc: 0.6297, Val Loss: 0.7964, Val Acc: 0.2704
Mejor modelo guardado con Val Loss: 0.7964
Epoch 2/100, Loss: 0.6353, Acc: 0.6612, Val Loss: 0.8465, Val Acc: 0.3333
Epoch 3/100, Loss: 0.6224, Acc: 0.6677, Val Loss: 0.9438, Val Acc: 0.2255
Epoch 4/100, Loss: 0.6179, Acc: 0.6708, Val Loss: 0.9466, Val Acc: 0.3175
Epoch 5/100, Loss: 0.6250, Acc: 0.6662, Val Loss: 1.0664, Val Acc: 0.4161
Epoch 6/100, Loss: 0.6135, Acc: 0.6752, Val Loss: 0.9385, Val Acc: 0.3790
Epoch 7/100, Loss: 0.6196, Acc: 0.6732, Val Loss: 0.9110, Val Acc: 0.4272
Epoch 8/100, Loss: 0.6202, Acc: 0.6690, Val Loss: 0.9595, Val Acc: 0.3414
Epoch 9/100, Loss: 0.6123, Acc: 0.6748, Val Loss: 1.0644, Val Acc: 0.2697
Epoch 10/100, Loss: 0.6175, Acc: 0.6632, Val Loss: 0.9342, Val Acc: 0.3289
Epoch 11/100, Loss: 0.6141, Acc: 0.6733, Val Loss: 0.9448, Val Acc: 0.2796
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6065, Acc: 0.6797, Val Loss: 0.9939, Val Acc: 0.3837
Epoch 13/100, Loss: 0.6054, Acc: 0.6838, Val Loss: 1.0545, Val Acc: 0.3212
Epoch 14/100, Loss: 0.6035, Acc: 0.6814, Val Loss: 0.9861, Val Acc: 0.3661
Epoch 15/100, Loss: 0.6050, Acc: 0.6805, Val Loss: 1.0723, Val Acc: 0.2862
Epoch 16/100, Loss: 0.6047, Acc: 0.6828, Val Loss: 1.0028, Val Acc: 0.3171
Epoch 17/100, Loss: 0.6063, Acc: 0.6805, Val Loss: 0.9956, Val Acc: 0.3782
Epoch 18/100, Loss: 0.6076, Acc: 0.6834, Val Loss: 0.9661, Val Acc: 0.3779
Epoch 19/100, Loss: 0.6064, Acc: 0.6811, Val Loss: 0.9759, Val Acc: 0.3815
Epoch 20/100, Loss: 0.6041, Acc: 0.6842, Val Loss: 0.9487, Val Acc: 0.3683
Epoch 21/100, Loss: 0.6008, Acc: 0.6834, Val Loss: 0.9712, Val Acc: 0.3561
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5992, Acc: 0.6874, Val Loss: 1.0108, Val Acc: 0.3425
Epoch 23/100, Loss: 0.5992, Acc: 0.6876, Val Loss: 0.9994, Val Acc: 0.3194
Epoch 24/100, Loss: 0.6003, Acc: 0.6859, Val Loss: 0.9935, Val Acc: 0.3775
Epoch 25/100, Loss: 0.5991, Acc: 0.6895, Val Loss: 1.0143, Val Acc: 0.3315
Epoch 26/100, Loss: 0.5992, Acc: 0.6893, Val Loss: 0.9995, Val Acc: 0.3532
Epoch 27/100, Loss: 0.5968, Acc: 0.6898, Val Loss: 0.9696, Val Acc: 0.3473
Epoch 28/100, Loss: 0.5971, Acc: 0.6860, Val Loss: 0.9911, Val Acc: 0.3664
Epoch 29/100, Loss: 0.5990, Acc: 0.6882, Val Loss: 0.9591, Val Acc: 0.4099
Epoch 30/100, Loss: 0.5980, Acc: 0.6880, Val Loss: 1.0026, Val Acc: 0.3639
Epoch 31/100, Loss: 0.5971, Acc: 0.6870, Val Loss: 1.0183, Val Acc: 0.3425
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5967, Acc: 0.6931, Val Loss: 0.9881, Val Acc: 0.3433
Epoch 33/100, Loss: 0.5955, Acc: 0.6909, Val Loss: 0.9891, Val Acc: 0.3554
Epoch 34/100, Loss: 0.5953, Acc: 0.6916, Val Loss: 0.9945, Val Acc: 0.3687
Epoch 35/100, Loss: 0.5955, Acc: 0.6904, Val Loss: 0.9822, Val Acc: 0.3503
Epoch 36/100, Loss: 0.5955, Acc: 0.6918, Val Loss: 0.9890, Val Acc: 0.3598
Epoch 37/100, Loss: 0.5952, Acc: 0.6910, Val Loss: 1.0114, Val Acc: 0.3308
Epoch 38/100, Loss: 0.5950, Acc: 0.6932, Val Loss: 0.9802, Val Acc: 0.3801
Epoch 39/100, Loss: 0.5948, Acc: 0.6908, Val Loss: 0.9850, Val Acc: 0.3683
Epoch 40/100, Loss: 0.5950, Acc: 0.6938, Val Loss: 1.0118, Val Acc: 0.3525
Epoch 41/100, Loss: 0.5940, Acc: 0.6912, Val Loss: 1.0189, Val Acc: 0.3411
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5941, Acc: 0.6939, Val Loss: 0.9974, Val Acc: 0.3492
Epoch 43/100, Loss: 0.5935, Acc: 0.6925, Val Loss: 1.0031, Val Acc: 0.3473
Epoch 44/100, Loss: 0.5936, Acc: 0.6949, Val Loss: 0.9955, Val Acc: 0.3598
Epoch 45/100, Loss: 0.5935, Acc: 0.6946, Val Loss: 0.9966, Val Acc: 0.3595
Epoch 46/100, Loss: 0.5936, Acc: 0.6936, Val Loss: 0.9945, Val Acc: 0.3709
Epoch 47/100, Loss: 0.5935, Acc: 0.6953, Val Loss: 0.9909, Val Acc: 0.3701
Epoch 48/100, Loss: 0.5939, Acc: 0.6935, Val Loss: 0.9967, Val Acc: 0.3650
Epoch 49/100, Loss: 0.5932, Acc: 0.6931, Val Loss: 0.9777, Val Acc: 0.3727
Epoch 50/100, Loss: 0.5935, Acc: 0.6921, Val Loss: 0.9885, Val Acc: 0.3845
Epoch 51/100, Loss: 0.5940, Acc: 0.6914, Val Loss: 1.0015, Val Acc: 0.3528
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5925, Acc: 0.6951, Val Loss: 0.9854, Val Acc: 0.3767
Epoch 53/100, Loss: 0.5930, Acc: 0.6914, Val Loss: 0.9897, Val Acc: 0.3609
Epoch 54/100, Loss: 0.5927, Acc: 0.6942, Val Loss: 0.9872, Val Acc: 0.3731
Epoch 55/100, Loss: 0.5927, Acc: 0.6931, Val Loss: 0.9931, Val Acc: 0.3584
Epoch 56/100, Loss: 0.5927, Acc: 0.6929, Val Loss: 0.9967, Val Acc: 0.3642
Epoch 57/100, Loss: 0.5929, Acc: 0.6926, Val Loss: 0.9931, Val Acc: 0.3679
Epoch 58/100, Loss: 0.5926, Acc: 0.6942, Val Loss: 0.9951, Val Acc: 0.3606
Epoch 59/100, Loss: 0.5925, Acc: 0.6934, Val Loss: 0.9966, Val Acc: 0.3558
Epoch 60/100, Loss: 0.5926, Acc: 0.6940, Val Loss: 0.9976, Val Acc: 0.3617
Epoch 61/100, Loss: 0.5924, Acc: 0.6937, Val Loss: 0.9990, Val Acc: 0.3499
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5923, Acc: 0.6942, Val Loss: 0.9968, Val Acc: 0.3635
Epoch 63/100, Loss: 0.5923, Acc: 0.6940, Val Loss: 0.9989, Val Acc: 0.3569
Epoch 64/100, Loss: 0.5923, Acc: 0.6932, Val Loss: 0.9959, Val Acc: 0.3609
Epoch 65/100, Loss: 0.5923, Acc: 0.6933, Val Loss: 0.9941, Val Acc: 0.3679
Epoch 66/100, Loss: 0.5923, Acc: 0.6943, Val Loss: 0.9940, Val Acc: 0.3687
Epoch 67/100, Loss: 0.5921, Acc: 0.6947, Val Loss: 0.9930, Val Acc: 0.3694
Epoch 68/100, Loss: 0.5923, Acc: 0.6922, Val Loss: 0.9968, Val Acc: 0.3595
Epoch 69/100, Loss: 0.5922, Acc: 0.6939, Val Loss: 0.9950, Val Acc: 0.3675
Epoch 70/100, Loss: 0.5922, Acc: 0.6951, Val Loss: 0.9943, Val Acc: 0.3683
Epoch 71/100, Loss: 0.5921, Acc: 0.6937, Val Loss: 0.9979, Val Acc: 0.3602
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5922, Acc: 0.6942, Val Loss: 0.9945, Val Acc: 0.3675
Epoch 73/100, Loss: 0.5920, Acc: 0.6938, Val Loss: 0.9985, Val Acc: 0.3609
Epoch 74/100, Loss: 0.5920, Acc: 0.6933, Val Loss: 0.9965, Val Acc: 0.3635
Epoch 75/100, Loss: 0.5920, Acc: 0.6939, Val Loss: 0.9964, Val Acc: 0.3639
Epoch 76/100, Loss: 0.5920, Acc: 0.6935, Val Loss: 0.9958, Val Acc: 0.3646
Epoch 77/100, Loss: 0.5920, Acc: 0.6940, Val Loss: 0.9964, Val Acc: 0.3602
Epoch 78/100, Loss: 0.5920, Acc: 0.6942, Val Loss: 0.9950, Val Acc: 0.3657
Epoch 79/100, Loss: 0.5919, Acc: 0.6926, Val Loss: 0.9938, Val Acc: 0.3657
Epoch 80/100, Loss: 0.5919, Acc: 0.6927, Val Loss: 0.9942, Val Acc: 0.3631
Epoch 81/100, Loss: 0.5919, Acc: 0.6927, Val Loss: 0.9929, Val Acc: 0.3639
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5918, Acc: 0.6942, Val Loss: 0.9914, Val Acc: 0.3646
Epoch 83/100, Loss: 0.5918, Acc: 0.6931, Val Loss: 0.9942, Val Acc: 0.3602
Epoch 84/100, Loss: 0.5918, Acc: 0.6931, Val Loss: 0.9924, Val Acc: 0.3628
Epoch 85/100, Loss: 0.5918, Acc: 0.6931, Val Loss: 0.9929, Val Acc: 0.3635
Epoch 86/100, Loss: 0.5918, Acc: 0.6924, Val Loss: 0.9921, Val Acc: 0.3635
Epoch 87/100, Loss: 0.5918, Acc: 0.6937, Val Loss: 0.9951, Val Acc: 0.3587
Epoch 88/100, Loss: 0.5919, Acc: 0.6936, Val Loss: 0.9923, Val Acc: 0.3650
Epoch 89/100, Loss: 0.5917, Acc: 0.6944, Val Loss: 0.9934, Val Acc: 0.3624
Epoch 90/100, Loss: 0.5917, Acc: 0.6944, Val Loss: 0.9913, Val Acc: 0.3657
Epoch 91/100, Loss: 0.5917, Acc: 0.6931, Val Loss: 0.9941, Val Acc: 0.3584
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5917, Acc: 0.6931, Val Loss: 0.9944, Val Acc: 0.3572
Epoch 93/100, Loss: 0.5917, Acc: 0.6928, Val Loss: 0.9948, Val Acc: 0.3598
Epoch 94/100, Loss: 0.5917, Acc: 0.6926, Val Loss: 0.9950, Val Acc: 0.3587
Epoch 95/100, Loss: 0.5917, Acc: 0.6947, Val Loss: 0.9945, Val Acc: 0.3587
Epoch 96/100, Loss: 0.5916, Acc: 0.6939, Val Loss: 0.9948, Val Acc: 0.3609
Epoch 97/100, Loss: 0.5916, Acc: 0.6931, Val Loss: 0.9935, Val Acc: 0.3624
Epoch 98/100, Loss: 0.5916, Acc: 0.6937, Val Loss: 0.9954, Val Acc: 0.3595
Epoch 99/100, Loss: 0.5916, Acc: 0.6931, Val Loss: 0.9941, Val Acc: 0.3631
Epoch 100/100, Loss: 0.5916, Acc: 0.6943, Val Loss: 0.9955, Val Acc: 0.3624

##############################
Resultados para principal:  093  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3 
 {'training': [0.5915665301927685, 0.6943371943371943, 0.6851884312007012, 0.7188304523721957, 0.701606389661671], 'validate': [0.9954658906127132, 0.3623988226637233, 0.4140302613480055, 0.6649484536082474, 0.5103136479231422], 'test': [0.75182913630097, 0.3967039434961742, 0.4092783505154639, 0.46760895170789163, 0.4365035733919736]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  088  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  088  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  088  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6921, Acc: 0.5167, Val Loss: 0.6843, Val Acc: 0.5316
Mejor modelo guardado con Val Loss: 0.6843
Epoch 2/100, Loss: 0.6925, Acc: 0.5199, Val Loss: 0.6818, Val Acc: 0.6185
Mejor modelo guardado con Val Loss: 0.6818
Epoch 3/100, Loss: 0.6919, Acc: 0.5207, Val Loss: 0.6869, Val Acc: 0.5754
Epoch 4/100, Loss: 0.6914, Acc: 0.5304, Val Loss: 0.6784, Val Acc: 0.6402
Mejor modelo guardado con Val Loss: 0.6784
Epoch 5/100, Loss: 0.6900, Acc: 0.5412, Val Loss: 0.6725, Val Acc: 0.6516
Mejor modelo guardado con Val Loss: 0.6725
Epoch 6/100, Loss: 0.6926, Acc: 0.5107, Val Loss: 0.6913, Val Acc: 0.5879
Epoch 7/100, Loss: 0.6933, Acc: 0.4968, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 8/100, Loss: 0.6934, Acc: 0.5033, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 9/100, Loss: 0.6929, Acc: 0.5096, Val Loss: 0.6863, Val Acc: 0.5482
Epoch 10/100, Loss: 0.6901, Acc: 0.5382, Val Loss: 0.6942, Val Acc: 0.5022
Epoch 11/100, Loss: 0.6897, Acc: 0.5353, Val Loss: 0.6482, Val Acc: 0.8002
Mejor modelo guardado con Val Loss: 0.6482
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6869, Acc: 0.5577, Val Loss: 0.6482, Val Acc: 0.8091
Epoch 13/100, Loss: 0.6864, Acc: 0.5576, Val Loss: 0.6445, Val Acc: 0.8094
Mejor modelo guardado con Val Loss: 0.6445
Epoch 14/100, Loss: 0.6862, Acc: 0.5581, Val Loss: 0.6629, Val Acc: 0.6711
Epoch 15/100, Loss: 0.6852, Acc: 0.5622, Val Loss: 0.6382, Val Acc: 0.8120
Mejor modelo guardado con Val Loss: 0.6382
Epoch 16/100, Loss: 0.6847, Acc: 0.5622, Val Loss: 0.6402, Val Acc: 0.7686
Epoch 17/100, Loss: 0.6849, Acc: 0.5568, Val Loss: 0.6471, Val Acc: 0.7031
Epoch 18/100, Loss: 0.6843, Acc: 0.5606, Val Loss: 0.6301, Val Acc: 0.7951
Mejor modelo guardado con Val Loss: 0.6301
Epoch 19/100, Loss: 0.6831, Acc: 0.5633, Val Loss: 0.6338, Val Acc: 0.7575
Epoch 20/100, Loss: 0.6833, Acc: 0.5674, Val Loss: 0.6226, Val Acc: 0.8109
Mejor modelo guardado con Val Loss: 0.6226
Epoch 21/100, Loss: 0.6836, Acc: 0.5644, Val Loss: 0.6214, Val Acc: 0.8017
Mejor modelo guardado con Val Loss: 0.6214
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6825, Acc: 0.5632, Val Loss: 0.6238, Val Acc: 0.7855
Epoch 23/100, Loss: 0.6819, Acc: 0.5681, Val Loss: 0.6247, Val Acc: 0.7737
Epoch 24/100, Loss: 0.6818, Acc: 0.5657, Val Loss: 0.6299, Val Acc: 0.7414
Epoch 25/100, Loss: 0.6816, Acc: 0.5664, Val Loss: 0.6220, Val Acc: 0.7726
Epoch 26/100, Loss: 0.6818, Acc: 0.5666, Val Loss: 0.6184, Val Acc: 0.7822
Mejor modelo guardado con Val Loss: 0.6184
Epoch 27/100, Loss: 0.6812, Acc: 0.5668, Val Loss: 0.6258, Val Acc: 0.7450
Epoch 28/100, Loss: 0.6814, Acc: 0.5677, Val Loss: 0.6372, Val Acc: 0.7020
Epoch 29/100, Loss: 0.6811, Acc: 0.5660, Val Loss: 0.6219, Val Acc: 0.7528
Epoch 30/100, Loss: 0.6808, Acc: 0.5667, Val Loss: 0.6040, Val Acc: 0.8216
Mejor modelo guardado con Val Loss: 0.6040
Epoch 31/100, Loss: 0.6810, Acc: 0.5685, Val Loss: 0.6179, Val Acc: 0.7597
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6799, Acc: 0.5686, Val Loss: 0.6216, Val Acc: 0.7450
Epoch 33/100, Loss: 0.6799, Acc: 0.5675, Val Loss: 0.6157, Val Acc: 0.7638
Epoch 34/100, Loss: 0.6800, Acc: 0.5687, Val Loss: 0.6247, Val Acc: 0.7093
Epoch 35/100, Loss: 0.6797, Acc: 0.5684, Val Loss: 0.6145, Val Acc: 0.7535
Epoch 36/100, Loss: 0.6793, Acc: 0.5688, Val Loss: 0.6000, Val Acc: 0.7910
Mejor modelo guardado con Val Loss: 0.6000
Epoch 37/100, Loss: 0.6793, Acc: 0.5710, Val Loss: 0.6080, Val Acc: 0.7572
Epoch 38/100, Loss: 0.6791, Acc: 0.5694, Val Loss: 0.6074, Val Acc: 0.7557
Epoch 39/100, Loss: 0.6791, Acc: 0.5691, Val Loss: 0.6124, Val Acc: 0.7391
Epoch 40/100, Loss: 0.6790, Acc: 0.5664, Val Loss: 0.6033, Val Acc: 0.7649
Epoch 41/100, Loss: 0.6790, Acc: 0.5703, Val Loss: 0.5947, Val Acc: 0.7962
Mejor modelo guardado con Val Loss: 0.5947
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6785, Acc: 0.5699, Val Loss: 0.6020, Val Acc: 0.7664
Epoch 43/100, Loss: 0.6785, Acc: 0.5682, Val Loss: 0.6014, Val Acc: 0.7667
Epoch 44/100, Loss: 0.6784, Acc: 0.5682, Val Loss: 0.6090, Val Acc: 0.7421
Epoch 45/100, Loss: 0.6784, Acc: 0.5697, Val Loss: 0.5965, Val Acc: 0.7800
Epoch 46/100, Loss: 0.6784, Acc: 0.5684, Val Loss: 0.6001, Val Acc: 0.7678
Epoch 47/100, Loss: 0.6783, Acc: 0.5674, Val Loss: 0.5998, Val Acc: 0.7675
Epoch 48/100, Loss: 0.6781, Acc: 0.5707, Val Loss: 0.6027, Val Acc: 0.7590
Epoch 49/100, Loss: 0.6780, Acc: 0.5689, Val Loss: 0.5978, Val Acc: 0.7715
Epoch 50/100, Loss: 0.6781, Acc: 0.5692, Val Loss: 0.6064, Val Acc: 0.7436
Epoch 51/100, Loss: 0.6782, Acc: 0.5685, Val Loss: 0.5972, Val Acc: 0.7704
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6778, Acc: 0.5689, Val Loss: 0.5995, Val Acc: 0.7638
Epoch 53/100, Loss: 0.6778, Acc: 0.5700, Val Loss: 0.5968, Val Acc: 0.7719
Epoch 54/100, Loss: 0.6777, Acc: 0.5695, Val Loss: 0.5959, Val Acc: 0.7715
Epoch 55/100, Loss: 0.6776, Acc: 0.5701, Val Loss: 0.6011, Val Acc: 0.7557
Epoch 56/100, Loss: 0.6777, Acc: 0.5680, Val Loss: 0.5981, Val Acc: 0.7656
Epoch 57/100, Loss: 0.6776, Acc: 0.5705, Val Loss: 0.6006, Val Acc: 0.7564
Epoch 58/100, Loss: 0.6776, Acc: 0.5697, Val Loss: 0.5962, Val Acc: 0.7697
Epoch 59/100, Loss: 0.6776, Acc: 0.5676, Val Loss: 0.6022, Val Acc: 0.7513
Epoch 60/100, Loss: 0.6775, Acc: 0.5686, Val Loss: 0.5963, Val Acc: 0.7675
Epoch 61/100, Loss: 0.6775, Acc: 0.5689, Val Loss: 0.5976, Val Acc: 0.7631
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6775, Acc: 0.5691, Val Loss: 0.5961, Val Acc: 0.7671
Epoch 63/100, Loss: 0.6775, Acc: 0.5687, Val Loss: 0.5963, Val Acc: 0.7667
Epoch 64/100, Loss: 0.6774, Acc: 0.5700, Val Loss: 0.5958, Val Acc: 0.7675
Epoch 65/100, Loss: 0.6774, Acc: 0.5700, Val Loss: 0.5964, Val Acc: 0.7667
Epoch 66/100, Loss: 0.6774, Acc: 0.5693, Val Loss: 0.5962, Val Acc: 0.7667
Epoch 67/100, Loss: 0.6773, Acc: 0.5687, Val Loss: 0.5962, Val Acc: 0.7667
Epoch 68/100, Loss: 0.6773, Acc: 0.5689, Val Loss: 0.5948, Val Acc: 0.7704
Epoch 69/100, Loss: 0.6773, Acc: 0.5689, Val Loss: 0.5955, Val Acc: 0.7664
Epoch 70/100, Loss: 0.6773, Acc: 0.5689, Val Loss: 0.5959, Val Acc: 0.7667
Epoch 71/100, Loss: 0.6773, Acc: 0.5686, Val Loss: 0.5954, Val Acc: 0.7664
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6773, Acc: 0.5697, Val Loss: 0.5949, Val Acc: 0.7678
Epoch 73/100, Loss: 0.6772, Acc: 0.5696, Val Loss: 0.5939, Val Acc: 0.7715
Mejor modelo guardado con Val Loss: 0.5939
Epoch 74/100, Loss: 0.6772, Acc: 0.5693, Val Loss: 0.5941, Val Acc: 0.7708
Epoch 75/100, Loss: 0.6772, Acc: 0.5694, Val Loss: 0.5949, Val Acc: 0.7667
Epoch 76/100, Loss: 0.6772, Acc: 0.5695, Val Loss: 0.5946, Val Acc: 0.7678
Epoch 77/100, Loss: 0.6772, Acc: 0.5686, Val Loss: 0.5939, Val Acc: 0.7704
Epoch 78/100, Loss: 0.6772, Acc: 0.5693, Val Loss: 0.5944, Val Acc: 0.7675
Epoch 79/100, Loss: 0.6772, Acc: 0.5710, Val Loss: 0.5959, Val Acc: 0.7660
Epoch 80/100, Loss: 0.6772, Acc: 0.5695, Val Loss: 0.5952, Val Acc: 0.7667
Epoch 81/100, Loss: 0.6772, Acc: 0.5697, Val Loss: 0.5958, Val Acc: 0.7660
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6772, Acc: 0.5696, Val Loss: 0.5950, Val Acc: 0.7667
Epoch 83/100, Loss: 0.6771, Acc: 0.5689, Val Loss: 0.5947, Val Acc: 0.7667
Epoch 84/100, Loss: 0.6772, Acc: 0.5692, Val Loss: 0.5941, Val Acc: 0.7671
Epoch 85/100, Loss: 0.6772, Acc: 0.5691, Val Loss: 0.5942, Val Acc: 0.7667
Epoch 86/100, Loss: 0.6771, Acc: 0.5704, Val Loss: 0.5931, Val Acc: 0.7715
Mejor modelo guardado con Val Loss: 0.5931
Epoch 87/100, Loss: 0.6771, Acc: 0.5703, Val Loss: 0.5937, Val Acc: 0.7686
Epoch 88/100, Loss: 0.6771, Acc: 0.5700, Val Loss: 0.5938, Val Acc: 0.7675
Epoch 89/100, Loss: 0.6771, Acc: 0.5699, Val Loss: 0.5932, Val Acc: 0.7697
Epoch 90/100, Loss: 0.6771, Acc: 0.5690, Val Loss: 0.5930, Val Acc: 0.7704
Mejor modelo guardado con Val Loss: 0.5930
Epoch 91/100, Loss: 0.6771, Acc: 0.5702, Val Loss: 0.5932, Val Acc: 0.7693
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6771, Acc: 0.5698, Val Loss: 0.5934, Val Acc: 0.7675
Epoch 93/100, Loss: 0.6771, Acc: 0.5704, Val Loss: 0.5935, Val Acc: 0.7671
Epoch 94/100, Loss: 0.6771, Acc: 0.5694, Val Loss: 0.5936, Val Acc: 0.7667
Epoch 95/100, Loss: 0.6771, Acc: 0.5695, Val Loss: 0.5942, Val Acc: 0.7664
Epoch 96/100, Loss: 0.6771, Acc: 0.5690, Val Loss: 0.5933, Val Acc: 0.7671
Epoch 97/100, Loss: 0.6770, Acc: 0.5698, Val Loss: 0.5930, Val Acc: 0.7675
Mejor modelo guardado con Val Loss: 0.5930
Epoch 98/100, Loss: 0.6770, Acc: 0.5696, Val Loss: 0.5941, Val Acc: 0.7671
Epoch 99/100, Loss: 0.6771, Acc: 0.5705, Val Loss: 0.5931, Val Acc: 0.7675
Epoch 100/100, Loss: 0.6770, Acc: 0.5694, Val Loss: 0.5928, Val Acc: 0.7675
Mejor modelo guardado con Val Loss: 0.5928

##############################
Resultados para principal:  088  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3 
 {'training': [0.6770309219138546, 0.5694061408347123, 0.548771021992238, 0.780066200809121, 0.6442891859052248], 'validate': [0.5928223077640977, 0.7674760853568801, 0.8524271844660194, 0.646539027982327, 0.7353433835845896], 'test': [0.591089955634541, 0.788993525603296, 0.8199608610567515, 0.7402826855123675, 0.7780872794800371]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  055  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  055  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  055  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6600, Acc: 0.6221, Val Loss: 0.5462, Val Acc: 0.7660
Mejor modelo guardado con Val Loss: 0.5462
Epoch 2/100, Loss: 0.6378, Acc: 0.6490, Val Loss: 0.5737, Val Acc: 0.6799
Epoch 3/100, Loss: 0.6301, Acc: 0.6513, Val Loss: 0.4688, Val Acc: 0.8363
Mejor modelo guardado con Val Loss: 0.4688
Epoch 4/100, Loss: 0.6312, Acc: 0.6480, Val Loss: 0.4606, Val Acc: 0.8304
Mejor modelo guardado con Val Loss: 0.4606
Epoch 5/100, Loss: 0.6232, Acc: 0.6610, Val Loss: 0.4461, Val Acc: 0.9065
Mejor modelo guardado con Val Loss: 0.4461
Epoch 6/100, Loss: 0.6233, Acc: 0.6617, Val Loss: 0.4167, Val Acc: 0.8617
Mejor modelo guardado con Val Loss: 0.4167
Epoch 7/100, Loss: 0.6203, Acc: 0.6617, Val Loss: 0.4250, Val Acc: 0.8863
Epoch 8/100, Loss: 0.6170, Acc: 0.6643, Val Loss: 0.4567, Val Acc: 0.8046
Epoch 9/100, Loss: 0.6167, Acc: 0.6599, Val Loss: 0.4450, Val Acc: 0.8245
Epoch 10/100, Loss: 0.6111, Acc: 0.6657, Val Loss: 0.4840, Val Acc: 0.7833
Epoch 11/100, Loss: 0.6184, Acc: 0.6590, Val Loss: 0.4733, Val Acc: 0.8683
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6093, Acc: 0.6674, Val Loss: 0.4223, Val Acc: 0.8466
Epoch 13/100, Loss: 0.6058, Acc: 0.6744, Val Loss: 0.4575, Val Acc: 0.7899
Epoch 14/100, Loss: 0.6049, Acc: 0.6719, Val Loss: 0.3933, Val Acc: 0.8628
Mejor modelo guardado con Val Loss: 0.3933
Epoch 15/100, Loss: 0.6052, Acc: 0.6704, Val Loss: 0.4457, Val Acc: 0.7995
Epoch 16/100, Loss: 0.6043, Acc: 0.6678, Val Loss: 0.4354, Val Acc: 0.8035
Epoch 17/100, Loss: 0.6044, Acc: 0.6735, Val Loss: 0.4067, Val Acc: 0.8628
Epoch 18/100, Loss: 0.6055, Acc: 0.6703, Val Loss: 0.4417, Val Acc: 0.8216
Epoch 19/100, Loss: 0.6040, Acc: 0.6722, Val Loss: 0.4258, Val Acc: 0.8241
Epoch 20/100, Loss: 0.6061, Acc: 0.6673, Val Loss: 0.4019, Val Acc: 0.8639
Epoch 21/100, Loss: 0.6035, Acc: 0.6697, Val Loss: 0.4005, Val Acc: 0.8514
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6003, Acc: 0.6753, Val Loss: 0.3771, Val Acc: 0.8951
Mejor modelo guardado con Val Loss: 0.3771
Epoch 23/100, Loss: 0.5991, Acc: 0.6739, Val Loss: 0.3705, Val Acc: 0.8797
Mejor modelo guardado con Val Loss: 0.3705
Epoch 24/100, Loss: 0.5978, Acc: 0.6781, Val Loss: 0.4127, Val Acc: 0.8182
Epoch 25/100, Loss: 0.5986, Acc: 0.6756, Val Loss: 0.3955, Val Acc: 0.8297
Epoch 26/100, Loss: 0.5982, Acc: 0.6742, Val Loss: 0.3858, Val Acc: 0.8366
Epoch 27/100, Loss: 0.5974, Acc: 0.6748, Val Loss: 0.3741, Val Acc: 0.8576
Epoch 28/100, Loss: 0.5977, Acc: 0.6779, Val Loss: 0.4543, Val Acc: 0.7737
Epoch 29/100, Loss: 0.5980, Acc: 0.6754, Val Loss: 0.3849, Val Acc: 0.8385
Epoch 30/100, Loss: 0.5981, Acc: 0.6782, Val Loss: 0.4229, Val Acc: 0.7954
Epoch 31/100, Loss: 0.5964, Acc: 0.6783, Val Loss: 0.3861, Val Acc: 0.8447
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5978, Acc: 0.6774, Val Loss: 0.3964, Val Acc: 0.8348
Epoch 33/100, Loss: 0.5968, Acc: 0.6766, Val Loss: 0.4025, Val Acc: 0.8175
Epoch 34/100, Loss: 0.5975, Acc: 0.6756, Val Loss: 0.3784, Val Acc: 0.8503
Epoch 35/100, Loss: 0.5972, Acc: 0.6775, Val Loss: 0.4075, Val Acc: 0.8201
Epoch 36/100, Loss: 0.5960, Acc: 0.6794, Val Loss: 0.3967, Val Acc: 0.8293
Epoch 37/100, Loss: 0.5953, Acc: 0.6794, Val Loss: 0.3992, Val Acc: 0.8355
Epoch 38/100, Loss: 0.5950, Acc: 0.6771, Val Loss: 0.4039, Val Acc: 0.8190
Epoch 39/100, Loss: 0.5946, Acc: 0.6771, Val Loss: 0.3799, Val Acc: 0.8639
Epoch 40/100, Loss: 0.5950, Acc: 0.6770, Val Loss: 0.3903, Val Acc: 0.8495
Epoch 41/100, Loss: 0.5944, Acc: 0.6805, Val Loss: 0.3937, Val Acc: 0.8455
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5935, Acc: 0.6794, Val Loss: 0.4031, Val Acc: 0.8212
Epoch 43/100, Loss: 0.5938, Acc: 0.6806, Val Loss: 0.3914, Val Acc: 0.8392
Epoch 44/100, Loss: 0.5936, Acc: 0.6805, Val Loss: 0.3866, Val Acc: 0.8473
Epoch 45/100, Loss: 0.5932, Acc: 0.6793, Val Loss: 0.3693, Val Acc: 0.8609
Mejor modelo guardado con Val Loss: 0.3693
Epoch 46/100, Loss: 0.5939, Acc: 0.6804, Val Loss: 0.3788, Val Acc: 0.8525
Epoch 47/100, Loss: 0.5933, Acc: 0.6805, Val Loss: 0.3842, Val Acc: 0.8473
Epoch 48/100, Loss: 0.5936, Acc: 0.6782, Val Loss: 0.3849, Val Acc: 0.8400
Epoch 49/100, Loss: 0.5931, Acc: 0.6806, Val Loss: 0.3958, Val Acc: 0.8205
Epoch 50/100, Loss: 0.5930, Acc: 0.6809, Val Loss: 0.4033, Val Acc: 0.8227
Epoch 51/100, Loss: 0.5931, Acc: 0.6807, Val Loss: 0.3857, Val Acc: 0.8433
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5928, Acc: 0.6793, Val Loss: 0.3884, Val Acc: 0.8374
Epoch 53/100, Loss: 0.5926, Acc: 0.6796, Val Loss: 0.3984, Val Acc: 0.8219
Epoch 54/100, Loss: 0.5928, Acc: 0.6792, Val Loss: 0.3854, Val Acc: 0.8414
Epoch 55/100, Loss: 0.5926, Acc: 0.6790, Val Loss: 0.3886, Val Acc: 0.8396
Epoch 56/100, Loss: 0.5925, Acc: 0.6793, Val Loss: 0.3895, Val Acc: 0.8411
Epoch 57/100, Loss: 0.5928, Acc: 0.6816, Val Loss: 0.3822, Val Acc: 0.8492
Epoch 58/100, Loss: 0.5928, Acc: 0.6817, Val Loss: 0.3846, Val Acc: 0.8447
Epoch 59/100, Loss: 0.5928, Acc: 0.6806, Val Loss: 0.3916, Val Acc: 0.8333
Epoch 60/100, Loss: 0.5926, Acc: 0.6804, Val Loss: 0.3889, Val Acc: 0.8355
Epoch 61/100, Loss: 0.5924, Acc: 0.6796, Val Loss: 0.3861, Val Acc: 0.8425
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5923, Acc: 0.6804, Val Loss: 0.3933, Val Acc: 0.8315
Epoch 63/100, Loss: 0.5923, Acc: 0.6803, Val Loss: 0.3872, Val Acc: 0.8411
Epoch 64/100, Loss: 0.5922, Acc: 0.6801, Val Loss: 0.3847, Val Acc: 0.8425
Epoch 65/100, Loss: 0.5922, Acc: 0.6805, Val Loss: 0.3951, Val Acc: 0.8300
Epoch 66/100, Loss: 0.5922, Acc: 0.6806, Val Loss: 0.3904, Val Acc: 0.8355
Epoch 67/100, Loss: 0.5922, Acc: 0.6808, Val Loss: 0.3887, Val Acc: 0.8377
Epoch 68/100, Loss: 0.5922, Acc: 0.6806, Val Loss: 0.3875, Val Acc: 0.8389
Epoch 69/100, Loss: 0.5922, Acc: 0.6805, Val Loss: 0.3905, Val Acc: 0.8355
Epoch 70/100, Loss: 0.5922, Acc: 0.6805, Val Loss: 0.3868, Val Acc: 0.8396
Epoch 71/100, Loss: 0.5921, Acc: 0.6821, Val Loss: 0.3890, Val Acc: 0.8370
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5921, Acc: 0.6812, Val Loss: 0.3875, Val Acc: 0.8377
Epoch 73/100, Loss: 0.5922, Acc: 0.6807, Val Loss: 0.3869, Val Acc: 0.8392
Epoch 74/100, Loss: 0.5921, Acc: 0.6811, Val Loss: 0.3910, Val Acc: 0.8337
Epoch 75/100, Loss: 0.5920, Acc: 0.6806, Val Loss: 0.3877, Val Acc: 0.8374
Epoch 76/100, Loss: 0.5920, Acc: 0.6810, Val Loss: 0.3859, Val Acc: 0.8414
Epoch 77/100, Loss: 0.5920, Acc: 0.6805, Val Loss: 0.3902, Val Acc: 0.8348
Epoch 78/100, Loss: 0.5920, Acc: 0.6805, Val Loss: 0.3907, Val Acc: 0.8352
Epoch 79/100, Loss: 0.5920, Acc: 0.6803, Val Loss: 0.3886, Val Acc: 0.8377
Epoch 80/100, Loss: 0.5920, Acc: 0.6813, Val Loss: 0.3852, Val Acc: 0.8418
Epoch 81/100, Loss: 0.5920, Acc: 0.6806, Val Loss: 0.3886, Val Acc: 0.8359
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5920, Acc: 0.6816, Val Loss: 0.3861, Val Acc: 0.8403
Epoch 83/100, Loss: 0.5920, Acc: 0.6802, Val Loss: 0.3883, Val Acc: 0.8370
Epoch 84/100, Loss: 0.5919, Acc: 0.6812, Val Loss: 0.3865, Val Acc: 0.8400
Epoch 85/100, Loss: 0.5920, Acc: 0.6809, Val Loss: 0.3880, Val Acc: 0.8377
Epoch 86/100, Loss: 0.5920, Acc: 0.6814, Val Loss: 0.3863, Val Acc: 0.8403
Epoch 87/100, Loss: 0.5920, Acc: 0.6805, Val Loss: 0.3882, Val Acc: 0.8377
Epoch 88/100, Loss: 0.5919, Acc: 0.6809, Val Loss: 0.3860, Val Acc: 0.8414
Epoch 89/100, Loss: 0.5919, Acc: 0.6812, Val Loss: 0.3875, Val Acc: 0.8370
Epoch 90/100, Loss: 0.5920, Acc: 0.6802, Val Loss: 0.3863, Val Acc: 0.8396
Epoch 91/100, Loss: 0.5919, Acc: 0.6809, Val Loss: 0.3876, Val Acc: 0.8374
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5919, Acc: 0.6804, Val Loss: 0.3879, Val Acc: 0.8377
Epoch 93/100, Loss: 0.5919, Acc: 0.6811, Val Loss: 0.3872, Val Acc: 0.8370
Epoch 94/100, Loss: 0.5918, Acc: 0.6805, Val Loss: 0.3881, Val Acc: 0.8374
Epoch 95/100, Loss: 0.5918, Acc: 0.6811, Val Loss: 0.3842, Val Acc: 0.8418
Epoch 96/100, Loss: 0.5918, Acc: 0.6808, Val Loss: 0.3885, Val Acc: 0.8352
Epoch 97/100, Loss: 0.5916, Acc: 0.6805, Val Loss: 0.3838, Val Acc: 0.8374
Epoch 98/100, Loss: 0.5915, Acc: 0.6805, Val Loss: 0.3818, Val Acc: 0.8400
Epoch 99/100, Loss: 0.5915, Acc: 0.6814, Val Loss: 0.3814, Val Acc: 0.8403
Epoch 100/100, Loss: 0.5915, Acc: 0.6807, Val Loss: 0.3822, Val Acc: 0.8385

##############################
Resultados para principal:  055  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3 
 {'training': [0.59146251460826, 0.6807317521603236, 0.6759806555615261, 0.6940051489518205, 0.6848743308229743], 'validate': [0.38217881131310794, 0.8384841795437822, 0.9935553168635876, 0.6811487481590575, 0.8082131935342944], 'test': [0.4682338933149974, 0.7834020011771631, 0.8660578386605784, 0.6702002355712603, 0.7556440903054449]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  045  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  045  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  045  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6009, Acc: 0.7375, Val Loss: 0.3963, Val Acc: 0.9481
Mejor modelo guardado con Val Loss: 0.3963
Epoch 2/100, Loss: 0.4696, Acc: 0.8074, Val Loss: 0.3282, Val Acc: 0.9003
Mejor modelo guardado con Val Loss: 0.3282
Epoch 3/100, Loss: 0.4313, Acc: 0.8165, Val Loss: 0.2552, Val Acc: 0.9419
Mejor modelo guardado con Val Loss: 0.2552
Epoch 4/100, Loss: 0.4112, Acc: 0.8237, Val Loss: 0.2098, Val Acc: 0.9441
Mejor modelo guardado con Val Loss: 0.2098
Epoch 5/100, Loss: 0.4056, Acc: 0.8227, Val Loss: 0.2205, Val Acc: 0.9371
Epoch 6/100, Loss: 0.3935, Acc: 0.8265, Val Loss: 0.2192, Val Acc: 0.9437
Epoch 7/100, Loss: 0.3931, Acc: 0.8279, Val Loss: 0.2065, Val Acc: 0.9463
Mejor modelo guardado con Val Loss: 0.2065
Epoch 8/100, Loss: 0.3916, Acc: 0.8251, Val Loss: 0.1979, Val Acc: 0.9316
Mejor modelo guardado con Val Loss: 0.1979
Epoch 9/100, Loss: 0.3886, Acc: 0.8300, Val Loss: 0.2031, Val Acc: 0.9338
Epoch 10/100, Loss: 0.3867, Acc: 0.8288, Val Loss: 0.2544, Val Acc: 0.9386
Epoch 11/100, Loss: 0.3918, Acc: 0.8287, Val Loss: 0.2090, Val Acc: 0.9367
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3825, Acc: 0.8314, Val Loss: 0.2045, Val Acc: 0.9305
Epoch 13/100, Loss: 0.3821, Acc: 0.8304, Val Loss: 0.1972, Val Acc: 0.9375
Mejor modelo guardado con Val Loss: 0.1972
Epoch 14/100, Loss: 0.3791, Acc: 0.8312, Val Loss: 0.2055, Val Acc: 0.9378
Epoch 15/100, Loss: 0.3748, Acc: 0.8331, Val Loss: 0.2010, Val Acc: 0.9308
Epoch 16/100, Loss: 0.3754, Acc: 0.8324, Val Loss: 0.1916, Val Acc: 0.9367
Mejor modelo guardado con Val Loss: 0.1916
Epoch 17/100, Loss: 0.3763, Acc: 0.8327, Val Loss: 0.2000, Val Acc: 0.9393
Epoch 18/100, Loss: 0.3747, Acc: 0.8324, Val Loss: 0.1778, Val Acc: 0.9444
Mejor modelo guardado con Val Loss: 0.1778
Epoch 19/100, Loss: 0.3799, Acc: 0.8297, Val Loss: 0.1757, Val Acc: 0.9463
Mejor modelo guardado con Val Loss: 0.1757
Epoch 20/100, Loss: 0.3721, Acc: 0.8324, Val Loss: 0.1797, Val Acc: 0.9319
Epoch 21/100, Loss: 0.3710, Acc: 0.8341, Val Loss: 0.1967, Val Acc: 0.9338
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3675, Acc: 0.8354, Val Loss: 0.1761, Val Acc: 0.9352
Epoch 23/100, Loss: 0.3662, Acc: 0.8370, Val Loss: 0.1732, Val Acc: 0.9408
Mejor modelo guardado con Val Loss: 0.1732
Epoch 24/100, Loss: 0.3668, Acc: 0.8380, Val Loss: 0.1807, Val Acc: 0.9345
Epoch 25/100, Loss: 0.3646, Acc: 0.8382, Val Loss: 0.1776, Val Acc: 0.9375
Epoch 26/100, Loss: 0.3665, Acc: 0.8378, Val Loss: 0.1731, Val Acc: 0.9378
Mejor modelo guardado con Val Loss: 0.1731
Epoch 27/100, Loss: 0.3652, Acc: 0.8393, Val Loss: 0.1785, Val Acc: 0.9393
Epoch 28/100, Loss: 0.3664, Acc: 0.8380, Val Loss: 0.1812, Val Acc: 0.9345
Epoch 29/100, Loss: 0.3637, Acc: 0.8423, Val Loss: 0.1905, Val Acc: 0.9382
Epoch 30/100, Loss: 0.3674, Acc: 0.8352, Val Loss: 0.1871, Val Acc: 0.9349
Epoch 31/100, Loss: 0.3634, Acc: 0.8405, Val Loss: 0.1773, Val Acc: 0.9408
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3610, Acc: 0.8415, Val Loss: 0.1826, Val Acc: 0.9341
Epoch 33/100, Loss: 0.3609, Acc: 0.8399, Val Loss: 0.1792, Val Acc: 0.9367
Epoch 34/100, Loss: 0.3602, Acc: 0.8410, Val Loss: 0.1811, Val Acc: 0.9393
Epoch 35/100, Loss: 0.3602, Acc: 0.8407, Val Loss: 0.1735, Val Acc: 0.9386
Epoch 36/100, Loss: 0.3591, Acc: 0.8418, Val Loss: 0.1722, Val Acc: 0.9389
Mejor modelo guardado con Val Loss: 0.1722
Epoch 37/100, Loss: 0.3600, Acc: 0.8411, Val Loss: 0.1775, Val Acc: 0.9408
Epoch 38/100, Loss: 0.3598, Acc: 0.8404, Val Loss: 0.1791, Val Acc: 0.9393
Epoch 39/100, Loss: 0.3592, Acc: 0.8409, Val Loss: 0.1730, Val Acc: 0.9375
Epoch 40/100, Loss: 0.3585, Acc: 0.8421, Val Loss: 0.1835, Val Acc: 0.9386
Epoch 41/100, Loss: 0.3592, Acc: 0.8411, Val Loss: 0.1739, Val Acc: 0.9426
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3571, Acc: 0.8431, Val Loss: 0.1750, Val Acc: 0.9404
Epoch 43/100, Loss: 0.3564, Acc: 0.8447, Val Loss: 0.1717, Val Acc: 0.9419
Mejor modelo guardado con Val Loss: 0.1717
Epoch 44/100, Loss: 0.3560, Acc: 0.8446, Val Loss: 0.1696, Val Acc: 0.9411
Mejor modelo guardado con Val Loss: 0.1696
Epoch 45/100, Loss: 0.3565, Acc: 0.8435, Val Loss: 0.1747, Val Acc: 0.9397
Epoch 46/100, Loss: 0.3566, Acc: 0.8428, Val Loss: 0.1738, Val Acc: 0.9411
Epoch 47/100, Loss: 0.3563, Acc: 0.8425, Val Loss: 0.1710, Val Acc: 0.9404
Epoch 48/100, Loss: 0.3560, Acc: 0.8436, Val Loss: 0.1710, Val Acc: 0.9408
Epoch 49/100, Loss: 0.3556, Acc: 0.8414, Val Loss: 0.1700, Val Acc: 0.9404
Epoch 50/100, Loss: 0.3552, Acc: 0.8428, Val Loss: 0.1704, Val Acc: 0.9419
Epoch 51/100, Loss: 0.3553, Acc: 0.8431, Val Loss: 0.1704, Val Acc: 0.9415
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3546, Acc: 0.8431, Val Loss: 0.1697, Val Acc: 0.9411
Epoch 53/100, Loss: 0.3544, Acc: 0.8426, Val Loss: 0.1729, Val Acc: 0.9408
Epoch 54/100, Loss: 0.3544, Acc: 0.8433, Val Loss: 0.1715, Val Acc: 0.9404
Epoch 55/100, Loss: 0.3542, Acc: 0.8434, Val Loss: 0.1718, Val Acc: 0.9397
Epoch 56/100, Loss: 0.3541, Acc: 0.8446, Val Loss: 0.1711, Val Acc: 0.9400
Epoch 57/100, Loss: 0.3542, Acc: 0.8447, Val Loss: 0.1723, Val Acc: 0.9397
Epoch 58/100, Loss: 0.3540, Acc: 0.8445, Val Loss: 0.1708, Val Acc: 0.9415
Epoch 59/100, Loss: 0.3541, Acc: 0.8445, Val Loss: 0.1711, Val Acc: 0.9400
Epoch 60/100, Loss: 0.3539, Acc: 0.8434, Val Loss: 0.1735, Val Acc: 0.9408
Epoch 61/100, Loss: 0.3541, Acc: 0.8433, Val Loss: 0.1714, Val Acc: 0.9411
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3534, Acc: 0.8429, Val Loss: 0.1710, Val Acc: 0.9411
Epoch 63/100, Loss: 0.3533, Acc: 0.8423, Val Loss: 0.1712, Val Acc: 0.9408
Epoch 64/100, Loss: 0.3533, Acc: 0.8451, Val Loss: 0.1715, Val Acc: 0.9408
Epoch 65/100, Loss: 0.3534, Acc: 0.8437, Val Loss: 0.1712, Val Acc: 0.9415
Epoch 66/100, Loss: 0.3532, Acc: 0.8437, Val Loss: 0.1702, Val Acc: 0.9408
Epoch 67/100, Loss: 0.3531, Acc: 0.8446, Val Loss: 0.1697, Val Acc: 0.9411
Epoch 68/100, Loss: 0.3531, Acc: 0.8445, Val Loss: 0.1699, Val Acc: 0.9411
Epoch 69/100, Loss: 0.3531, Acc: 0.8451, Val Loss: 0.1700, Val Acc: 0.9419
Epoch 70/100, Loss: 0.3532, Acc: 0.8438, Val Loss: 0.1709, Val Acc: 0.9411
Epoch 71/100, Loss: 0.3531, Acc: 0.8445, Val Loss: 0.1704, Val Acc: 0.9411
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3526, Acc: 0.8441, Val Loss: 0.1707, Val Acc: 0.9404
Epoch 73/100, Loss: 0.3525, Acc: 0.8449, Val Loss: 0.1715, Val Acc: 0.9404
Epoch 74/100, Loss: 0.3525, Acc: 0.8445, Val Loss: 0.1708, Val Acc: 0.9404
Epoch 75/100, Loss: 0.3526, Acc: 0.8441, Val Loss: 0.1713, Val Acc: 0.9408
Epoch 76/100, Loss: 0.3524, Acc: 0.8441, Val Loss: 0.1704, Val Acc: 0.9411
Epoch 77/100, Loss: 0.3524, Acc: 0.8448, Val Loss: 0.1705, Val Acc: 0.9408
Epoch 78/100, Loss: 0.3525, Acc: 0.8449, Val Loss: 0.1705, Val Acc: 0.9415
Epoch 79/100, Loss: 0.3525, Acc: 0.8436, Val Loss: 0.1709, Val Acc: 0.9404
Epoch 80/100, Loss: 0.3525, Acc: 0.8442, Val Loss: 0.1707, Val Acc: 0.9411
Epoch 81/100, Loss: 0.3523, Acc: 0.8441, Val Loss: 0.1707, Val Acc: 0.9400
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3524, Acc: 0.8441, Val Loss: 0.1706, Val Acc: 0.9400
Epoch 83/100, Loss: 0.3522, Acc: 0.8458, Val Loss: 0.1714, Val Acc: 0.9404
Epoch 84/100, Loss: 0.3524, Acc: 0.8447, Val Loss: 0.1709, Val Acc: 0.9408
Epoch 85/100, Loss: 0.3523, Acc: 0.8452, Val Loss: 0.1716, Val Acc: 0.9408
Epoch 86/100, Loss: 0.3523, Acc: 0.8444, Val Loss: 0.1718, Val Acc: 0.9408
Epoch 87/100, Loss: 0.3523, Acc: 0.8443, Val Loss: 0.1708, Val Acc: 0.9411
Epoch 88/100, Loss: 0.3522, Acc: 0.8446, Val Loss: 0.1705, Val Acc: 0.9411
Epoch 89/100, Loss: 0.3523, Acc: 0.8452, Val Loss: 0.1706, Val Acc: 0.9411
Epoch 90/100, Loss: 0.3520, Acc: 0.8441, Val Loss: 0.1693, Val Acc: 0.9411
Mejor modelo guardado con Val Loss: 0.1693
Epoch 91/100, Loss: 0.3519, Acc: 0.8443, Val Loss: 0.1689, Val Acc: 0.9419
Mejor modelo guardado con Val Loss: 0.1689
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3520, Acc: 0.8436, Val Loss: 0.1689, Val Acc: 0.9415
Mejor modelo guardado con Val Loss: 0.1689
Epoch 93/100, Loss: 0.3520, Acc: 0.8447, Val Loss: 0.1692, Val Acc: 0.9422
Epoch 94/100, Loss: 0.3520, Acc: 0.8460, Val Loss: 0.1686, Val Acc: 0.9422
Mejor modelo guardado con Val Loss: 0.1686
Epoch 95/100, Loss: 0.3519, Acc: 0.8453, Val Loss: 0.1684, Val Acc: 0.9419
Mejor modelo guardado con Val Loss: 0.1684
Epoch 96/100, Loss: 0.3518, Acc: 0.8447, Val Loss: 0.1684, Val Acc: 0.9411
Epoch 97/100, Loss: 0.3520, Acc: 0.8436, Val Loss: 0.1683, Val Acc: 0.9426
Mejor modelo guardado con Val Loss: 0.1683
Epoch 98/100, Loss: 0.3519, Acc: 0.8445, Val Loss: 0.1692, Val Acc: 0.9426
Epoch 99/100, Loss: 0.3518, Acc: 0.8444, Val Loss: 0.1687, Val Acc: 0.9426
Epoch 100/100, Loss: 0.3517, Acc: 0.8444, Val Loss: 0.1678, Val Acc: 0.9426
Mejor modelo guardado con Val Loss: 0.1678

##############################
Resultados para principal:  045  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3 
 {'training': [0.35174036190382235, 0.8443647729362015, 0.8689655172413793, 0.8109599117322545, 0.838961286026824], 'validate': [0.16775325402011013, 0.9426048565121413, 0.9491778774289985, 0.93519882179676, 0.9421364985163204], 'test': [1.2161730024618682, 0.5412007062978222, 0.5289221806075739, 0.748527679623086, 0.6198488173616191]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  022  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  022  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  022  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5803, Acc: 0.7329, Val Loss: 0.3495, Val Acc: 0.9673
Mejor modelo guardado con Val Loss: 0.3495
Epoch 2/100, Loss: 0.5156, Acc: 0.7656, Val Loss: 0.2519, Val Acc: 0.9739
Mejor modelo guardado con Val Loss: 0.2519
Epoch 3/100, Loss: 0.4880, Acc: 0.7735, Val Loss: 0.2197, Val Acc: 0.9731
Mejor modelo guardado con Val Loss: 0.2197
Epoch 4/100, Loss: 0.4841, Acc: 0.7741, Val Loss: 0.2206, Val Acc: 0.9713
Epoch 5/100, Loss: 0.4749, Acc: 0.7790, Val Loss: 0.1977, Val Acc: 0.9731
Mejor modelo guardado con Val Loss: 0.1977
Epoch 6/100, Loss: 0.4626, Acc: 0.7842, Val Loss: 0.1751, Val Acc: 0.9750
Mejor modelo guardado con Val Loss: 0.1751
Epoch 7/100, Loss: 0.4652, Acc: 0.7790, Val Loss: 0.1937, Val Acc: 0.9676
Epoch 8/100, Loss: 0.4592, Acc: 0.7858, Val Loss: 0.1474, Val Acc: 0.9742
Mejor modelo guardado con Val Loss: 0.1474
Epoch 9/100, Loss: 0.4603, Acc: 0.7832, Val Loss: 0.1916, Val Acc: 0.9687
Epoch 10/100, Loss: 0.4631, Acc: 0.7763, Val Loss: 0.1897, Val Acc: 0.9654
Epoch 11/100, Loss: 0.4530, Acc: 0.7882, Val Loss: 0.1612, Val Acc: 0.9717
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4456, Acc: 0.7917, Val Loss: 0.1610, Val Acc: 0.9753
Epoch 13/100, Loss: 0.4454, Acc: 0.7914, Val Loss: 0.1818, Val Acc: 0.9662
Epoch 14/100, Loss: 0.4450, Acc: 0.7928, Val Loss: 0.1852, Val Acc: 0.9654
Epoch 15/100, Loss: 0.4430, Acc: 0.7913, Val Loss: 0.1381, Val Acc: 0.9735
Mejor modelo guardado con Val Loss: 0.1381
Epoch 16/100, Loss: 0.4454, Acc: 0.7881, Val Loss: 0.1582, Val Acc: 0.9709
Epoch 17/100, Loss: 0.4463, Acc: 0.7864, Val Loss: 0.1380, Val Acc: 0.9772
Mejor modelo guardado con Val Loss: 0.1380
Epoch 18/100, Loss: 0.4430, Acc: 0.7913, Val Loss: 0.1419, Val Acc: 0.9761
Epoch 19/100, Loss: 0.4404, Acc: 0.7929, Val Loss: 0.1572, Val Acc: 0.9709
Epoch 20/100, Loss: 0.4392, Acc: 0.7921, Val Loss: 0.1234, Val Acc: 0.9783
Mejor modelo guardado con Val Loss: 0.1234
Epoch 21/100, Loss: 0.4399, Acc: 0.7931, Val Loss: 0.1495, Val Acc: 0.9753
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4363, Acc: 0.7947, Val Loss: 0.1426, Val Acc: 0.9731
Epoch 23/100, Loss: 0.4325, Acc: 0.7988, Val Loss: 0.1457, Val Acc: 0.9735
Epoch 24/100, Loss: 0.4345, Acc: 0.7948, Val Loss: 0.1403, Val Acc: 0.9739
Epoch 25/100, Loss: 0.4332, Acc: 0.7958, Val Loss: 0.1406, Val Acc: 0.9731
Epoch 26/100, Loss: 0.4328, Acc: 0.7957, Val Loss: 0.1173, Val Acc: 0.9787
Mejor modelo guardado con Val Loss: 0.1173
Epoch 27/100, Loss: 0.4342, Acc: 0.7950, Val Loss: 0.1438, Val Acc: 0.9753
Epoch 28/100, Loss: 0.4330, Acc: 0.7960, Val Loss: 0.1355, Val Acc: 0.9768
Epoch 29/100, Loss: 0.4326, Acc: 0.7955, Val Loss: 0.1409, Val Acc: 0.9783
Epoch 30/100, Loss: 0.4325, Acc: 0.7933, Val Loss: 0.1296, Val Acc: 0.9772
Epoch 31/100, Loss: 0.4312, Acc: 0.7981, Val Loss: 0.1384, Val Acc: 0.9742
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4287, Acc: 0.7967, Val Loss: 0.1359, Val Acc: 0.9702
Epoch 33/100, Loss: 0.4288, Acc: 0.7964, Val Loss: 0.1365, Val Acc: 0.9753
Epoch 34/100, Loss: 0.4279, Acc: 0.7997, Val Loss: 0.1398, Val Acc: 0.9735
Epoch 35/100, Loss: 0.4280, Acc: 0.7978, Val Loss: 0.1401, Val Acc: 0.9717
Epoch 36/100, Loss: 0.4268, Acc: 0.7983, Val Loss: 0.1389, Val Acc: 0.9739
Epoch 37/100, Loss: 0.4266, Acc: 0.7983, Val Loss: 0.1469, Val Acc: 0.9768
Epoch 38/100, Loss: 0.4267, Acc: 0.7983, Val Loss: 0.1435, Val Acc: 0.9757
Epoch 39/100, Loss: 0.4287, Acc: 0.7973, Val Loss: 0.1295, Val Acc: 0.9753
Epoch 40/100, Loss: 0.4267, Acc: 0.8006, Val Loss: 0.1390, Val Acc: 0.9724
Epoch 41/100, Loss: 0.4261, Acc: 0.7993, Val Loss: 0.1344, Val Acc: 0.9761
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4244, Acc: 0.8006, Val Loss: 0.1381, Val Acc: 0.9742
Epoch 43/100, Loss: 0.4246, Acc: 0.7997, Val Loss: 0.1355, Val Acc: 0.9742
Epoch 44/100, Loss: 0.4245, Acc: 0.8001, Val Loss: 0.1344, Val Acc: 0.9750
Epoch 45/100, Loss: 0.4240, Acc: 0.8000, Val Loss: 0.1291, Val Acc: 0.9750
Epoch 46/100, Loss: 0.4243, Acc: 0.7990, Val Loss: 0.1375, Val Acc: 0.9739
Epoch 47/100, Loss: 0.4235, Acc: 0.8010, Val Loss: 0.1319, Val Acc: 0.9753
Epoch 48/100, Loss: 0.4244, Acc: 0.7988, Val Loss: 0.1410, Val Acc: 0.9757
Epoch 49/100, Loss: 0.4237, Acc: 0.8003, Val Loss: 0.1325, Val Acc: 0.9757
Epoch 50/100, Loss: 0.4235, Acc: 0.8008, Val Loss: 0.1365, Val Acc: 0.9750
Epoch 51/100, Loss: 0.4234, Acc: 0.8005, Val Loss: 0.1328, Val Acc: 0.9757
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4226, Acc: 0.8002, Val Loss: 0.1312, Val Acc: 0.9757
Epoch 53/100, Loss: 0.4230, Acc: 0.7986, Val Loss: 0.1356, Val Acc: 0.9753
Epoch 54/100, Loss: 0.4228, Acc: 0.8008, Val Loss: 0.1342, Val Acc: 0.9750
Epoch 55/100, Loss: 0.4224, Acc: 0.8016, Val Loss: 0.1330, Val Acc: 0.9753
Epoch 56/100, Loss: 0.4225, Acc: 0.8015, Val Loss: 0.1331, Val Acc: 0.9757
Epoch 57/100, Loss: 0.4224, Acc: 0.8002, Val Loss: 0.1366, Val Acc: 0.9746
Epoch 58/100, Loss: 0.4222, Acc: 0.8004, Val Loss: 0.1383, Val Acc: 0.9753
Epoch 59/100, Loss: 0.4222, Acc: 0.8006, Val Loss: 0.1380, Val Acc: 0.9753
Epoch 60/100, Loss: 0.4222, Acc: 0.8001, Val Loss: 0.1342, Val Acc: 0.9776
Epoch 61/100, Loss: 0.4220, Acc: 0.8004, Val Loss: 0.1391, Val Acc: 0.9742
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4218, Acc: 0.8010, Val Loss: 0.1386, Val Acc: 0.9757
Epoch 63/100, Loss: 0.4216, Acc: 0.8007, Val Loss: 0.1353, Val Acc: 0.9757
Epoch 64/100, Loss: 0.4216, Acc: 0.8013, Val Loss: 0.1353, Val Acc: 0.9757
Epoch 65/100, Loss: 0.4216, Acc: 0.8009, Val Loss: 0.1359, Val Acc: 0.9761
Epoch 66/100, Loss: 0.4216, Acc: 0.7999, Val Loss: 0.1369, Val Acc: 0.9757
Epoch 67/100, Loss: 0.4216, Acc: 0.8010, Val Loss: 0.1374, Val Acc: 0.9753
Epoch 68/100, Loss: 0.4215, Acc: 0.8017, Val Loss: 0.1339, Val Acc: 0.9750
Epoch 69/100, Loss: 0.4213, Acc: 0.8007, Val Loss: 0.1340, Val Acc: 0.9765
Epoch 70/100, Loss: 0.4217, Acc: 0.8014, Val Loss: 0.1338, Val Acc: 0.9757
Epoch 71/100, Loss: 0.4214, Acc: 0.8013, Val Loss: 0.1361, Val Acc: 0.9757
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4211, Acc: 0.8012, Val Loss: 0.1351, Val Acc: 0.9753
Epoch 73/100, Loss: 0.4211, Acc: 0.8013, Val Loss: 0.1351, Val Acc: 0.9753
Epoch 74/100, Loss: 0.4211, Acc: 0.8011, Val Loss: 0.1346, Val Acc: 0.9750
Epoch 75/100, Loss: 0.4211, Acc: 0.8018, Val Loss: 0.1337, Val Acc: 0.9753
Epoch 76/100, Loss: 0.4211, Acc: 0.8002, Val Loss: 0.1335, Val Acc: 0.9757
Epoch 77/100, Loss: 0.4211, Acc: 0.8012, Val Loss: 0.1349, Val Acc: 0.9757
Epoch 78/100, Loss: 0.4210, Acc: 0.8009, Val Loss: 0.1356, Val Acc: 0.9753
Epoch 79/100, Loss: 0.4211, Acc: 0.8016, Val Loss: 0.1343, Val Acc: 0.9757
Epoch 80/100, Loss: 0.4210, Acc: 0.8014, Val Loss: 0.1333, Val Acc: 0.9757
Epoch 81/100, Loss: 0.4210, Acc: 0.8014, Val Loss: 0.1334, Val Acc: 0.9750
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4208, Acc: 0.8017, Val Loss: 0.1356, Val Acc: 0.9757
Epoch 83/100, Loss: 0.4210, Acc: 0.8011, Val Loss: 0.1364, Val Acc: 0.9757
Epoch 84/100, Loss: 0.4209, Acc: 0.8023, Val Loss: 0.1346, Val Acc: 0.9753
Epoch 85/100, Loss: 0.4209, Acc: 0.8017, Val Loss: 0.1341, Val Acc: 0.9753
Epoch 86/100, Loss: 0.4208, Acc: 0.8013, Val Loss: 0.1344, Val Acc: 0.9753
Epoch 87/100, Loss: 0.4209, Acc: 0.8022, Val Loss: 0.1352, Val Acc: 0.9753
Epoch 88/100, Loss: 0.4208, Acc: 0.8008, Val Loss: 0.1338, Val Acc: 0.9757
Epoch 89/100, Loss: 0.4207, Acc: 0.8018, Val Loss: 0.1344, Val Acc: 0.9753
Epoch 90/100, Loss: 0.4208, Acc: 0.8011, Val Loss: 0.1339, Val Acc: 0.9750
Epoch 91/100, Loss: 0.4207, Acc: 0.8015, Val Loss: 0.1351, Val Acc: 0.9761
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4207, Acc: 0.8024, Val Loss: 0.1346, Val Acc: 0.9750
Epoch 93/100, Loss: 0.4205, Acc: 0.8014, Val Loss: 0.1333, Val Acc: 0.9765
Epoch 94/100, Loss: 0.4207, Acc: 0.8004, Val Loss: 0.1335, Val Acc: 0.9765
Epoch 95/100, Loss: 0.4206, Acc: 0.8016, Val Loss: 0.1354, Val Acc: 0.9761
Epoch 96/100, Loss: 0.4206, Acc: 0.8026, Val Loss: 0.1361, Val Acc: 0.9761
Epoch 97/100, Loss: 0.4206, Acc: 0.8026, Val Loss: 0.1341, Val Acc: 0.9753
Epoch 98/100, Loss: 0.4205, Acc: 0.8022, Val Loss: 0.1348, Val Acc: 0.9757
Epoch 99/100, Loss: 0.4205, Acc: 0.8013, Val Loss: 0.1350, Val Acc: 0.9757
Epoch 100/100, Loss: 0.4204, Acc: 0.8013, Val Loss: 0.1333, Val Acc: 0.9765

##############################
Resultados para principal:  022  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  3 
 {'training': [0.4204241345857605, 0.8013421584850157, 0.8217160808953465, 0.7695844060316293, 0.7947963156395405], 'validate': [0.13328181683670642, 0.9764532744665195, 0.9857357357357357, 0.9668630338733432, 0.9762081784386617], 'test': [1.6182267992860742, 0.34343731606827543, 0.3877894736842105, 0.5424028268551236, 0.452246501350356]}

##############################
Resultados para window:  3 
 {'104:093:088:055:045:022': {'training': [0.6466618932154845, 0.6151866151866152, 0.5869202999166898, 0.7773078337624126, 0.6688291139240506], 'validate': [0.4428813495608263, 0.8469462840323767, 0.9776876267748479, 0.7098674521354934, 0.8225255972696246], 'test': [0.46725953232359, 0.8549146556798116, 0.8869621066152859, 0.8133097762073027, 0.8485407066052227]}, '093:104:088:055:045:022': {'training': [0.5915665301927685, 0.6943371943371943, 0.6851884312007012, 0.7188304523721957, 0.701606389661671], 'validate': [0.9954658906127132, 0.3623988226637233, 0.4140302613480055, 0.6649484536082474, 0.5103136479231422], 'test': [0.75182913630097, 0.3967039434961742, 0.4092783505154639, 0.46760895170789163, 0.4365035733919736]}, '088:104:093:055:045:022': {'training': [0.6770309219138546, 0.5694061408347123, 0.548771021992238, 0.780066200809121, 0.6442891859052248], 'validate': [0.5928223077640977, 0.7674760853568801, 0.8524271844660194, 0.646539027982327, 0.7353433835845896], 'test': [0.591089955634541, 0.788993525603296, 0.8199608610567515, 0.7402826855123675, 0.7780872794800371]}, '055:104:093:088:045:022': {'training': [0.59146251460826, 0.6807317521603236, 0.6759806555615261, 0.6940051489518205, 0.6848743308229743], 'validate': [0.38217881131310794, 0.8384841795437822, 0.9935553168635876, 0.6811487481590575, 0.8082131935342944], 'test': [0.4682338933149974, 0.7834020011771631, 0.8660578386605784, 0.6702002355712603, 0.7556440903054449]}, '045:104:093:088:055:022': {'training': [0.35174036190382235, 0.8443647729362015, 0.8689655172413793, 0.8109599117322545, 0.838961286026824], 'validate': [0.16775325402011013, 0.9426048565121413, 0.9491778774289985, 0.93519882179676, 0.9421364985163204], 'test': [1.2161730024618682, 0.5412007062978222, 0.5289221806075739, 0.748527679623086, 0.6198488173616191]}, '022:104:093:088:055:045': {'training': [0.4204241345857605, 0.8013421584850157, 0.8217160808953465, 0.7695844060316293, 0.7947963156395405], 'validate': [0.13328181683670642, 0.9764532744665195, 0.9857357357357357, 0.9668630338733432, 0.9762081784386617], 'test': [1.6182267992860742, 0.34343731606827543, 0.3877894736842105, 0.5424028268551236, 0.452246501350356]}}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  062  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  062  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  062  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4243, Acc: 0.8602, Val Loss: 0.6212, Val Acc: 0.6692
Mejor modelo guardado con Val Loss: 0.6212
Epoch 2/100, Loss: 0.2986, Acc: 0.8875, Val Loss: 0.6387, Val Acc: 0.6766
Epoch 3/100, Loss: 0.2707, Acc: 0.8918, Val Loss: 0.6282, Val Acc: 0.6961
Epoch 4/100, Loss: 0.2792, Acc: 0.8878, Val Loss: 0.7374, Val Acc: 0.6634
Epoch 5/100, Loss: 0.2793, Acc: 0.8870, Val Loss: 0.5893, Val Acc: 0.7090
Mejor modelo guardado con Val Loss: 0.5893
Epoch 6/100, Loss: 0.2660, Acc: 0.8898, Val Loss: 0.6437, Val Acc: 0.6748
Epoch 7/100, Loss: 0.2725, Acc: 0.8870, Val Loss: 0.5910, Val Acc: 0.7057
Epoch 8/100, Loss: 0.2709, Acc: 0.8890, Val Loss: 0.5972, Val Acc: 0.7112
Epoch 9/100, Loss: 0.2605, Acc: 0.8956, Val Loss: 0.7077, Val Acc: 0.6884
Epoch 10/100, Loss: 0.2631, Acc: 0.8934, Val Loss: 0.5694, Val Acc: 0.7068
Mejor modelo guardado con Val Loss: 0.5694
Epoch 11/100, Loss: 0.2560, Acc: 0.8936, Val Loss: 0.7328, Val Acc: 0.6928
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2513, Acc: 0.8969, Val Loss: 0.6097, Val Acc: 0.7016
Epoch 13/100, Loss: 0.2550, Acc: 0.8932, Val Loss: 0.6149, Val Acc: 0.6965
Epoch 14/100, Loss: 0.2523, Acc: 0.8956, Val Loss: 0.6482, Val Acc: 0.6957
Epoch 15/100, Loss: 0.2516, Acc: 0.8961, Val Loss: 0.6721, Val Acc: 0.6950
Epoch 16/100, Loss: 0.2479, Acc: 0.8984, Val Loss: 0.7453, Val Acc: 0.6873
Epoch 17/100, Loss: 0.2487, Acc: 0.8980, Val Loss: 0.6169, Val Acc: 0.6987
Epoch 18/100, Loss: 0.2491, Acc: 0.8978, Val Loss: 0.7365, Val Acc: 0.6806
Epoch 19/100, Loss: 0.2467, Acc: 0.8981, Val Loss: 0.6331, Val Acc: 0.7024
Epoch 20/100, Loss: 0.2462, Acc: 0.8968, Val Loss: 0.6214, Val Acc: 0.7093
Epoch 21/100, Loss: 0.2491, Acc: 0.8975, Val Loss: 0.6675, Val Acc: 0.6954
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2431, Acc: 0.9001, Val Loss: 0.6647, Val Acc: 0.7082
Epoch 23/100, Loss: 0.2427, Acc: 0.9012, Val Loss: 0.6875, Val Acc: 0.6932
Epoch 24/100, Loss: 0.2396, Acc: 0.9031, Val Loss: 0.7171, Val Acc: 0.6928
Epoch 25/100, Loss: 0.2389, Acc: 0.9011, Val Loss: 0.7592, Val Acc: 0.6939
Epoch 26/100, Loss: 0.2410, Acc: 0.8991, Val Loss: 0.6896, Val Acc: 0.6921
Epoch 27/100, Loss: 0.2401, Acc: 0.9021, Val Loss: 0.6561, Val Acc: 0.6972
Epoch 28/100, Loss: 0.2381, Acc: 0.9016, Val Loss: 0.6524, Val Acc: 0.6968
Epoch 29/100, Loss: 0.2356, Acc: 0.9038, Val Loss: 0.7143, Val Acc: 0.6965
Epoch 30/100, Loss: 0.2374, Acc: 0.9013, Val Loss: 0.6589, Val Acc: 0.6972
Epoch 31/100, Loss: 0.2382, Acc: 0.9011, Val Loss: 0.6445, Val Acc: 0.6987
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2343, Acc: 0.9037, Val Loss: 0.7101, Val Acc: 0.7005
Epoch 33/100, Loss: 0.2340, Acc: 0.9045, Val Loss: 0.6935, Val Acc: 0.6998
Epoch 34/100, Loss: 0.2343, Acc: 0.9040, Val Loss: 0.7165, Val Acc: 0.6979
Epoch 35/100, Loss: 0.2339, Acc: 0.9031, Val Loss: 0.6751, Val Acc: 0.6935
Epoch 36/100, Loss: 0.2346, Acc: 0.9022, Val Loss: 0.6325, Val Acc: 0.7053
Epoch 37/100, Loss: 0.2328, Acc: 0.9048, Val Loss: 0.6395, Val Acc: 0.7035
Epoch 38/100, Loss: 0.2335, Acc: 0.9018, Val Loss: 0.7031, Val Acc: 0.6968
Epoch 39/100, Loss: 0.2336, Acc: 0.9032, Val Loss: 0.7000, Val Acc: 0.6965
Epoch 40/100, Loss: 0.2336, Acc: 0.9043, Val Loss: 0.6981, Val Acc: 0.6928
Epoch 41/100, Loss: 0.2326, Acc: 0.9038, Val Loss: 0.6721, Val Acc: 0.6972
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2316, Acc: 0.9023, Val Loss: 0.7307, Val Acc: 0.6887
Epoch 43/100, Loss: 0.2311, Acc: 0.9040, Val Loss: 0.7086, Val Acc: 0.6921
Epoch 44/100, Loss: 0.2303, Acc: 0.9041, Val Loss: 0.6602, Val Acc: 0.7016
Epoch 45/100, Loss: 0.2303, Acc: 0.9053, Val Loss: 0.6923, Val Acc: 0.6998
Epoch 46/100, Loss: 0.2296, Acc: 0.9045, Val Loss: 0.6820, Val Acc: 0.7001
Epoch 47/100, Loss: 0.2303, Acc: 0.9057, Val Loss: 0.6846, Val Acc: 0.7001
Epoch 48/100, Loss: 0.2299, Acc: 0.9058, Val Loss: 0.6781, Val Acc: 0.6976
Epoch 49/100, Loss: 0.2292, Acc: 0.9056, Val Loss: 0.6713, Val Acc: 0.6972
Epoch 50/100, Loss: 0.2300, Acc: 0.9037, Val Loss: 0.6973, Val Acc: 0.6965
Epoch 51/100, Loss: 0.2297, Acc: 0.9039, Val Loss: 0.6811, Val Acc: 0.6990
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2283, Acc: 0.9044, Val Loss: 0.6898, Val Acc: 0.6990
Epoch 53/100, Loss: 0.2281, Acc: 0.9061, Val Loss: 0.7342, Val Acc: 0.6932
Epoch 54/100, Loss: 0.2280, Acc: 0.9057, Val Loss: 0.6822, Val Acc: 0.6990
Epoch 55/100, Loss: 0.2283, Acc: 0.9049, Val Loss: 0.6973, Val Acc: 0.6983
Epoch 56/100, Loss: 0.2281, Acc: 0.9053, Val Loss: 0.6792, Val Acc: 0.6990
Epoch 57/100, Loss: 0.2274, Acc: 0.9054, Val Loss: 0.6880, Val Acc: 0.6998
Epoch 58/100, Loss: 0.2278, Acc: 0.9057, Val Loss: 0.6760, Val Acc: 0.6990
Epoch 59/100, Loss: 0.2275, Acc: 0.9062, Val Loss: 0.6960, Val Acc: 0.6961
Epoch 60/100, Loss: 0.2276, Acc: 0.9053, Val Loss: 0.6688, Val Acc: 0.6990
Epoch 61/100, Loss: 0.2279, Acc: 0.9056, Val Loss: 0.6965, Val Acc: 0.6976
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2272, Acc: 0.9047, Val Loss: 0.6931, Val Acc: 0.6972
Epoch 63/100, Loss: 0.2267, Acc: 0.9062, Val Loss: 0.6762, Val Acc: 0.6976
Epoch 64/100, Loss: 0.2269, Acc: 0.9076, Val Loss: 0.6921, Val Acc: 0.6979
Epoch 65/100, Loss: 0.2268, Acc: 0.9056, Val Loss: 0.6974, Val Acc: 0.6965
Epoch 66/100, Loss: 0.2267, Acc: 0.9060, Val Loss: 0.6972, Val Acc: 0.6965
Epoch 67/100, Loss: 0.2268, Acc: 0.9062, Val Loss: 0.6995, Val Acc: 0.6972
Epoch 68/100, Loss: 0.2265, Acc: 0.9052, Val Loss: 0.6764, Val Acc: 0.7005
Epoch 69/100, Loss: 0.2266, Acc: 0.9060, Val Loss: 0.6987, Val Acc: 0.6972
Epoch 70/100, Loss: 0.2268, Acc: 0.9055, Val Loss: 0.6985, Val Acc: 0.6976
Epoch 71/100, Loss: 0.2268, Acc: 0.9059, Val Loss: 0.6986, Val Acc: 0.6976
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2266, Acc: 0.9062, Val Loss: 0.6968, Val Acc: 0.6965
Epoch 73/100, Loss: 0.2264, Acc: 0.9066, Val Loss: 0.6987, Val Acc: 0.6968
Epoch 74/100, Loss: 0.2265, Acc: 0.9058, Val Loss: 0.6852, Val Acc: 0.6987
Epoch 75/100, Loss: 0.2264, Acc: 0.9059, Val Loss: 0.6860, Val Acc: 0.6983
Epoch 76/100, Loss: 0.2264, Acc: 0.9064, Val Loss: 0.6949, Val Acc: 0.6968
Epoch 77/100, Loss: 0.2262, Acc: 0.9078, Val Loss: 0.6840, Val Acc: 0.6990
Epoch 78/100, Loss: 0.2263, Acc: 0.9063, Val Loss: 0.6968, Val Acc: 0.6972
Epoch 79/100, Loss: 0.2264, Acc: 0.9056, Val Loss: 0.6842, Val Acc: 0.6987
Epoch 80/100, Loss: 0.2263, Acc: 0.9055, Val Loss: 0.6935, Val Acc: 0.6979
Epoch 81/100, Loss: 0.2262, Acc: 0.9062, Val Loss: 0.6948, Val Acc: 0.6983
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2262, Acc: 0.9057, Val Loss: 0.6865, Val Acc: 0.6979
Epoch 83/100, Loss: 0.2262, Acc: 0.9059, Val Loss: 0.6913, Val Acc: 0.6979
Epoch 84/100, Loss: 0.2261, Acc: 0.9061, Val Loss: 0.6869, Val Acc: 0.6979
Epoch 85/100, Loss: 0.2260, Acc: 0.9068, Val Loss: 0.7012, Val Acc: 0.6968
Epoch 86/100, Loss: 0.2261, Acc: 0.9063, Val Loss: 0.6977, Val Acc: 0.6968
Epoch 87/100, Loss: 0.2260, Acc: 0.9061, Val Loss: 0.6924, Val Acc: 0.6968
Epoch 88/100, Loss: 0.2261, Acc: 0.9059, Val Loss: 0.6948, Val Acc: 0.6965
Epoch 89/100, Loss: 0.2259, Acc: 0.9057, Val Loss: 0.6824, Val Acc: 0.6987
Epoch 90/100, Loss: 0.2260, Acc: 0.9063, Val Loss: 0.6877, Val Acc: 0.6987
Epoch 91/100, Loss: 0.2259, Acc: 0.9063, Val Loss: 0.6988, Val Acc: 0.6972
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2259, Acc: 0.9058, Val Loss: 0.6912, Val Acc: 0.6983
Epoch 93/100, Loss: 0.2259, Acc: 0.9060, Val Loss: 0.6889, Val Acc: 0.6976
Epoch 94/100, Loss: 0.2259, Acc: 0.9065, Val Loss: 0.6978, Val Acc: 0.6965
Epoch 95/100, Loss: 0.2259, Acc: 0.9061, Val Loss: 0.6955, Val Acc: 0.6961
Epoch 96/100, Loss: 0.2258, Acc: 0.9068, Val Loss: 0.6938, Val Acc: 0.6972
Epoch 97/100, Loss: 0.2259, Acc: 0.9059, Val Loss: 0.6984, Val Acc: 0.6965
Epoch 98/100, Loss: 0.2257, Acc: 0.9055, Val Loss: 0.6942, Val Acc: 0.6972
Epoch 99/100, Loss: 0.2258, Acc: 0.9063, Val Loss: 0.6975, Val Acc: 0.6972
Epoch 100/100, Loss: 0.2256, Acc: 0.9068, Val Loss: 0.6922, Val Acc: 0.6976

##############################
Resultados para principal:  062  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3 
 {'training': [0.2256288756658365, 0.906784335355764, 0.9005795001810938, 0.9144906215520412, 0.9074817518248175], 'validate': [0.6922432179021281, 0.6975717439293598, 0.7925764192139738, 0.5346097201767305, 0.6385224274406333], 'test': [0.29191167114509475, 0.88905238375515, 0.8772130211307824, 0.9045936395759717, 0.8906929544795593]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  035  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  035  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  035  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6698, Acc: 0.6245, Val Loss: 0.6423, Val Acc: 0.7108
Mejor modelo guardado con Val Loss: 0.6423
Epoch 2/100, Loss: 0.6309, Acc: 0.6875, Val Loss: 0.5880, Val Acc: 0.7410
Mejor modelo guardado con Val Loss: 0.5880
Epoch 3/100, Loss: 0.5863, Acc: 0.7247, Val Loss: 0.5653, Val Acc: 0.7314
Mejor modelo guardado con Val Loss: 0.5653
Epoch 4/100, Loss: 0.5609, Acc: 0.7352, Val Loss: 0.5973, Val Acc: 0.7082
Epoch 5/100, Loss: 0.5489, Acc: 0.7325, Val Loss: 0.5639, Val Acc: 0.7369
Mejor modelo guardado con Val Loss: 0.5639
Epoch 6/100, Loss: 0.5509, Acc: 0.7317, Val Loss: 0.5396, Val Acc: 0.7480
Mejor modelo guardado con Val Loss: 0.5396
Epoch 7/100, Loss: 0.5352, Acc: 0.7480, Val Loss: 0.6174, Val Acc: 0.6898
Epoch 8/100, Loss: 0.5291, Acc: 0.7493, Val Loss: 0.5532, Val Acc: 0.7384
Epoch 9/100, Loss: 0.5215, Acc: 0.7510, Val Loss: 0.5309, Val Acc: 0.7550
Mejor modelo guardado con Val Loss: 0.5309
Epoch 10/100, Loss: 0.5251, Acc: 0.7482, Val Loss: 0.5399, Val Acc: 0.7524
Epoch 11/100, Loss: 0.5265, Acc: 0.7443, Val Loss: 0.5780, Val Acc: 0.6968
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5129, Acc: 0.7568, Val Loss: 0.5999, Val Acc: 0.6961
Epoch 13/100, Loss: 0.5124, Acc: 0.7607, Val Loss: 0.5574, Val Acc: 0.7141
Epoch 14/100, Loss: 0.5108, Acc: 0.7606, Val Loss: 0.5145, Val Acc: 0.7572
Mejor modelo guardado con Val Loss: 0.5145
Epoch 15/100, Loss: 0.5084, Acc: 0.7614, Val Loss: 0.5451, Val Acc: 0.7237
Epoch 16/100, Loss: 0.5082, Acc: 0.7587, Val Loss: 0.5423, Val Acc: 0.7524
Epoch 17/100, Loss: 0.5057, Acc: 0.7639, Val Loss: 0.5073, Val Acc: 0.7627
Mejor modelo guardado con Val Loss: 0.5073
Epoch 18/100, Loss: 0.5069, Acc: 0.7614, Val Loss: 0.5319, Val Acc: 0.7546
Epoch 19/100, Loss: 0.5061, Acc: 0.7626, Val Loss: 0.5232, Val Acc: 0.7406
Epoch 20/100, Loss: 0.5104, Acc: 0.7630, Val Loss: 0.5054, Val Acc: 0.7609
Mejor modelo guardado con Val Loss: 0.5054
Epoch 21/100, Loss: 0.5049, Acc: 0.7644, Val Loss: 0.5096, Val Acc: 0.7553
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5050, Acc: 0.7636, Val Loss: 0.5594, Val Acc: 0.6968
Epoch 23/100, Loss: 0.5007, Acc: 0.7666, Val Loss: 0.5246, Val Acc: 0.7579
Epoch 24/100, Loss: 0.5008, Acc: 0.7685, Val Loss: 0.5276, Val Acc: 0.7579
Epoch 25/100, Loss: 0.5003, Acc: 0.7643, Val Loss: 0.5216, Val Acc: 0.7616
Epoch 26/100, Loss: 0.4985, Acc: 0.7621, Val Loss: 0.5211, Val Acc: 0.7627
Epoch 27/100, Loss: 0.4995, Acc: 0.7658, Val Loss: 0.5366, Val Acc: 0.7546
Epoch 28/100, Loss: 0.4991, Acc: 0.7663, Val Loss: 0.5379, Val Acc: 0.7550
Epoch 29/100, Loss: 0.4967, Acc: 0.7678, Val Loss: 0.5211, Val Acc: 0.7634
Epoch 30/100, Loss: 0.4990, Acc: 0.7647, Val Loss: 0.5811, Val Acc: 0.7149
Epoch 31/100, Loss: 0.4991, Acc: 0.7657, Val Loss: 0.5044, Val Acc: 0.7675
Mejor modelo guardado con Val Loss: 0.5044
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4937, Acc: 0.7705, Val Loss: 0.5281, Val Acc: 0.7609
Epoch 33/100, Loss: 0.4927, Acc: 0.7700, Val Loss: 0.5253, Val Acc: 0.7590
Epoch 34/100, Loss: 0.4924, Acc: 0.7676, Val Loss: 0.5202, Val Acc: 0.7616
Epoch 35/100, Loss: 0.4913, Acc: 0.7726, Val Loss: 0.5329, Val Acc: 0.7597
Epoch 36/100, Loss: 0.4914, Acc: 0.7713, Val Loss: 0.5177, Val Acc: 0.7634
Epoch 37/100, Loss: 0.4917, Acc: 0.7686, Val Loss: 0.5254, Val Acc: 0.7601
Epoch 38/100, Loss: 0.4909, Acc: 0.7708, Val Loss: 0.5261, Val Acc: 0.7616
Epoch 39/100, Loss: 0.4908, Acc: 0.7694, Val Loss: 0.5394, Val Acc: 0.7542
Epoch 40/100, Loss: 0.4905, Acc: 0.7673, Val Loss: 0.5263, Val Acc: 0.7605
Epoch 41/100, Loss: 0.4903, Acc: 0.7705, Val Loss: 0.5418, Val Acc: 0.7542
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4888, Acc: 0.7716, Val Loss: 0.5219, Val Acc: 0.7664
Epoch 43/100, Loss: 0.4887, Acc: 0.7735, Val Loss: 0.5340, Val Acc: 0.7528
Epoch 44/100, Loss: 0.4880, Acc: 0.7739, Val Loss: 0.5165, Val Acc: 0.7667
Epoch 45/100, Loss: 0.4875, Acc: 0.7744, Val Loss: 0.5213, Val Acc: 0.7656
Epoch 46/100, Loss: 0.4882, Acc: 0.7695, Val Loss: 0.5348, Val Acc: 0.7535
Epoch 47/100, Loss: 0.4879, Acc: 0.7740, Val Loss: 0.5261, Val Acc: 0.7590
Epoch 48/100, Loss: 0.4873, Acc: 0.7735, Val Loss: 0.5226, Val Acc: 0.7642
Epoch 49/100, Loss: 0.4874, Acc: 0.7755, Val Loss: 0.5316, Val Acc: 0.7572
Epoch 50/100, Loss: 0.4867, Acc: 0.7729, Val Loss: 0.5315, Val Acc: 0.7572
Epoch 51/100, Loss: 0.4864, Acc: 0.7718, Val Loss: 0.5215, Val Acc: 0.7597
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4863, Acc: 0.7731, Val Loss: 0.5337, Val Acc: 0.7539
Epoch 53/100, Loss: 0.4856, Acc: 0.7741, Val Loss: 0.5266, Val Acc: 0.7590
Epoch 54/100, Loss: 0.4863, Acc: 0.7729, Val Loss: 0.5304, Val Acc: 0.7550
Epoch 55/100, Loss: 0.4854, Acc: 0.7725, Val Loss: 0.5266, Val Acc: 0.7586
Epoch 56/100, Loss: 0.4856, Acc: 0.7756, Val Loss: 0.5307, Val Acc: 0.7583
Epoch 57/100, Loss: 0.4852, Acc: 0.7728, Val Loss: 0.5276, Val Acc: 0.7583
Epoch 58/100, Loss: 0.4852, Acc: 0.7739, Val Loss: 0.5303, Val Acc: 0.7542
Epoch 59/100, Loss: 0.4850, Acc: 0.7744, Val Loss: 0.5257, Val Acc: 0.7623
Epoch 60/100, Loss: 0.4844, Acc: 0.7736, Val Loss: 0.5435, Val Acc: 0.7469
Epoch 61/100, Loss: 0.4845, Acc: 0.7738, Val Loss: 0.5172, Val Acc: 0.7645
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4850, Acc: 0.7737, Val Loss: 0.5227, Val Acc: 0.7616
Epoch 63/100, Loss: 0.4845, Acc: 0.7742, Val Loss: 0.5288, Val Acc: 0.7586
Epoch 64/100, Loss: 0.4843, Acc: 0.7739, Val Loss: 0.5219, Val Acc: 0.7616
Epoch 65/100, Loss: 0.4842, Acc: 0.7736, Val Loss: 0.5298, Val Acc: 0.7586
Epoch 66/100, Loss: 0.4844, Acc: 0.7727, Val Loss: 0.5278, Val Acc: 0.7583
Epoch 67/100, Loss: 0.4841, Acc: 0.7736, Val Loss: 0.5287, Val Acc: 0.7583
Epoch 68/100, Loss: 0.4840, Acc: 0.7735, Val Loss: 0.5272, Val Acc: 0.7583
Epoch 69/100, Loss: 0.4840, Acc: 0.7738, Val Loss: 0.5320, Val Acc: 0.7550
Epoch 70/100, Loss: 0.4840, Acc: 0.7722, Val Loss: 0.5318, Val Acc: 0.7542
Epoch 71/100, Loss: 0.4840, Acc: 0.7740, Val Loss: 0.5280, Val Acc: 0.7590
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4838, Acc: 0.7740, Val Loss: 0.5278, Val Acc: 0.7579
Epoch 73/100, Loss: 0.4839, Acc: 0.7745, Val Loss: 0.5274, Val Acc: 0.7586
Epoch 74/100, Loss: 0.4837, Acc: 0.7728, Val Loss: 0.5266, Val Acc: 0.7594
Epoch 75/100, Loss: 0.4837, Acc: 0.7738, Val Loss: 0.5279, Val Acc: 0.7586
Epoch 76/100, Loss: 0.4837, Acc: 0.7739, Val Loss: 0.5284, Val Acc: 0.7586
Epoch 77/100, Loss: 0.4837, Acc: 0.7735, Val Loss: 0.5288, Val Acc: 0.7590
Epoch 78/100, Loss: 0.4835, Acc: 0.7736, Val Loss: 0.5254, Val Acc: 0.7601
Epoch 79/100, Loss: 0.4836, Acc: 0.7738, Val Loss: 0.5263, Val Acc: 0.7597
Epoch 80/100, Loss: 0.4834, Acc: 0.7737, Val Loss: 0.5275, Val Acc: 0.7590
Epoch 81/100, Loss: 0.4835, Acc: 0.7730, Val Loss: 0.5237, Val Acc: 0.7627
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4836, Acc: 0.7728, Val Loss: 0.5266, Val Acc: 0.7590
Epoch 83/100, Loss: 0.4835, Acc: 0.7734, Val Loss: 0.5266, Val Acc: 0.7594
Epoch 84/100, Loss: 0.4833, Acc: 0.7734, Val Loss: 0.5267, Val Acc: 0.7590
Epoch 85/100, Loss: 0.4834, Acc: 0.7732, Val Loss: 0.5273, Val Acc: 0.7586
Epoch 86/100, Loss: 0.4833, Acc: 0.7728, Val Loss: 0.5271, Val Acc: 0.7594
Epoch 87/100, Loss: 0.4834, Acc: 0.7737, Val Loss: 0.5257, Val Acc: 0.7609
Epoch 88/100, Loss: 0.4833, Acc: 0.7730, Val Loss: 0.5262, Val Acc: 0.7605
Epoch 89/100, Loss: 0.4833, Acc: 0.7737, Val Loss: 0.5262, Val Acc: 0.7597
Epoch 90/100, Loss: 0.4831, Acc: 0.7741, Val Loss: 0.5294, Val Acc: 0.7586
Epoch 91/100, Loss: 0.4831, Acc: 0.7734, Val Loss: 0.5268, Val Acc: 0.7594
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4830, Acc: 0.7742, Val Loss: 0.5236, Val Acc: 0.7620
Epoch 93/100, Loss: 0.4831, Acc: 0.7736, Val Loss: 0.5273, Val Acc: 0.7594
Epoch 94/100, Loss: 0.4829, Acc: 0.7740, Val Loss: 0.5228, Val Acc: 0.7620
Epoch 95/100, Loss: 0.4831, Acc: 0.7736, Val Loss: 0.5262, Val Acc: 0.7597
Epoch 96/100, Loss: 0.4829, Acc: 0.7739, Val Loss: 0.5245, Val Acc: 0.7612
Epoch 97/100, Loss: 0.4831, Acc: 0.7737, Val Loss: 0.5286, Val Acc: 0.7583
Epoch 98/100, Loss: 0.4829, Acc: 0.7738, Val Loss: 0.5293, Val Acc: 0.7579
Epoch 99/100, Loss: 0.4828, Acc: 0.7739, Val Loss: 0.5269, Val Acc: 0.7594
Epoch 100/100, Loss: 0.4829, Acc: 0.7739, Val Loss: 0.5294, Val Acc: 0.7579

##############################
Resultados para principal:  035  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3 
 {'training': [0.48286573312961567, 0.7739474168045597, 0.7710646041856233, 0.7791467451268849, 0.775084606237995], 'validate': [0.5293822978125062, 0.7579102281089036, 0.710589651022864, 0.8696612665684831, 0.7821192052980133], 'test': [0.560920178062386, 0.7333725721012361, 0.6902017291066282, 0.8462897526501767, 0.7603174603174603]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  002  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  002  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  002  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6833, Acc: 0.5706, Val Loss: 0.6903, Val Acc: 0.5294
Mejor modelo guardado con Val Loss: 0.6903
Epoch 2/100, Loss: 0.6735, Acc: 0.6010, Val Loss: 0.6848, Val Acc: 0.5537
Mejor modelo guardado con Val Loss: 0.6848
Epoch 3/100, Loss: 0.6694, Acc: 0.6052, Val Loss: 0.6858, Val Acc: 0.5276
Epoch 4/100, Loss: 0.6686, Acc: 0.6041, Val Loss: 0.6926, Val Acc: 0.5228
Epoch 5/100, Loss: 0.6596, Acc: 0.6221, Val Loss: 0.6861, Val Acc: 0.5397
Epoch 6/100, Loss: 0.6559, Acc: 0.6236, Val Loss: 0.6888, Val Acc: 0.5331
Epoch 7/100, Loss: 0.6579, Acc: 0.6243, Val Loss: 0.6917, Val Acc: 0.5445
Epoch 8/100, Loss: 0.6535, Acc: 0.6241, Val Loss: 0.6904, Val Acc: 0.5607
Epoch 9/100, Loss: 0.6482, Acc: 0.6306, Val Loss: 0.6985, Val Acc: 0.5269
Epoch 10/100, Loss: 0.6504, Acc: 0.6238, Val Loss: 0.7042, Val Acc: 0.5283
Epoch 11/100, Loss: 0.6486, Acc: 0.6286, Val Loss: 0.7021, Val Acc: 0.5305
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6450, Acc: 0.6355, Val Loss: 0.7041, Val Acc: 0.5324
Epoch 13/100, Loss: 0.6440, Acc: 0.6362, Val Loss: 0.7045, Val Acc: 0.5309
Epoch 14/100, Loss: 0.6428, Acc: 0.6374, Val Loss: 0.7075, Val Acc: 0.5350
Epoch 15/100, Loss: 0.6421, Acc: 0.6366, Val Loss: 0.7018, Val Acc: 0.5265
Epoch 16/100, Loss: 0.6434, Acc: 0.6323, Val Loss: 0.7082, Val Acc: 0.5342
Epoch 17/100, Loss: 0.6407, Acc: 0.6378, Val Loss: 0.6996, Val Acc: 0.5453
Epoch 18/100, Loss: 0.6405, Acc: 0.6403, Val Loss: 0.6978, Val Acc: 0.5280
Epoch 19/100, Loss: 0.6413, Acc: 0.6379, Val Loss: 0.7106, Val Acc: 0.5342
Epoch 20/100, Loss: 0.6404, Acc: 0.6388, Val Loss: 0.7069, Val Acc: 0.5287
Epoch 21/100, Loss: 0.6397, Acc: 0.6373, Val Loss: 0.7115, Val Acc: 0.5313
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6372, Acc: 0.6431, Val Loss: 0.7105, Val Acc: 0.5280
Epoch 23/100, Loss: 0.6362, Acc: 0.6436, Val Loss: 0.7097, Val Acc: 0.5342
Epoch 24/100, Loss: 0.6365, Acc: 0.6407, Val Loss: 0.7056, Val Acc: 0.5276
Epoch 25/100, Loss: 0.6364, Acc: 0.6464, Val Loss: 0.7077, Val Acc: 0.5320
Epoch 26/100, Loss: 0.6368, Acc: 0.6456, Val Loss: 0.7131, Val Acc: 0.5309
Epoch 27/100, Loss: 0.6371, Acc: 0.6442, Val Loss: 0.7069, Val Acc: 0.5261
Epoch 28/100, Loss: 0.6357, Acc: 0.6454, Val Loss: 0.7083, Val Acc: 0.5313
Epoch 29/100, Loss: 0.6357, Acc: 0.6467, Val Loss: 0.7085, Val Acc: 0.5302
Epoch 30/100, Loss: 0.6360, Acc: 0.6438, Val Loss: 0.7091, Val Acc: 0.5327
Epoch 31/100, Loss: 0.6355, Acc: 0.6477, Val Loss: 0.7100, Val Acc: 0.5327
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6342, Acc: 0.6455, Val Loss: 0.7095, Val Acc: 0.5291
Epoch 33/100, Loss: 0.6339, Acc: 0.6465, Val Loss: 0.7127, Val Acc: 0.5305
Epoch 34/100, Loss: 0.6340, Acc: 0.6467, Val Loss: 0.7107, Val Acc: 0.5291
Epoch 35/100, Loss: 0.6338, Acc: 0.6492, Val Loss: 0.7132, Val Acc: 0.5305
Epoch 36/100, Loss: 0.6331, Acc: 0.6479, Val Loss: 0.7108, Val Acc: 0.5280
Epoch 37/100, Loss: 0.6331, Acc: 0.6489, Val Loss: 0.7146, Val Acc: 0.5342
Epoch 38/100, Loss: 0.6320, Acc: 0.6475, Val Loss: 0.7138, Val Acc: 0.5350
Epoch 39/100, Loss: 0.6314, Acc: 0.6475, Val Loss: 0.7133, Val Acc: 0.5324
Epoch 40/100, Loss: 0.6310, Acc: 0.6467, Val Loss: 0.7092, Val Acc: 0.5361
Epoch 41/100, Loss: 0.6304, Acc: 0.6487, Val Loss: 0.7140, Val Acc: 0.5397
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6298, Acc: 0.6500, Val Loss: 0.7131, Val Acc: 0.5335
Epoch 43/100, Loss: 0.6297, Acc: 0.6492, Val Loss: 0.7155, Val Acc: 0.5338
Epoch 44/100, Loss: 0.6291, Acc: 0.6488, Val Loss: 0.7129, Val Acc: 0.5298
Epoch 45/100, Loss: 0.6293, Acc: 0.6489, Val Loss: 0.7143, Val Acc: 0.5280
Epoch 46/100, Loss: 0.6292, Acc: 0.6489, Val Loss: 0.7132, Val Acc: 0.5309
Epoch 47/100, Loss: 0.6287, Acc: 0.6488, Val Loss: 0.7152, Val Acc: 0.5327
Epoch 48/100, Loss: 0.6291, Acc: 0.6496, Val Loss: 0.7131, Val Acc: 0.5294
Epoch 49/100, Loss: 0.6284, Acc: 0.6511, Val Loss: 0.7153, Val Acc: 0.5357
Epoch 50/100, Loss: 0.6286, Acc: 0.6478, Val Loss: 0.7148, Val Acc: 0.5338
Epoch 51/100, Loss: 0.6280, Acc: 0.6506, Val Loss: 0.7155, Val Acc: 0.5327
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6273, Acc: 0.6492, Val Loss: 0.7135, Val Acc: 0.5280
Epoch 53/100, Loss: 0.6273, Acc: 0.6511, Val Loss: 0.7140, Val Acc: 0.5327
Epoch 54/100, Loss: 0.6270, Acc: 0.6509, Val Loss: 0.7141, Val Acc: 0.5313
Epoch 55/100, Loss: 0.6270, Acc: 0.6513, Val Loss: 0.7147, Val Acc: 0.5320
Epoch 56/100, Loss: 0.6267, Acc: 0.6495, Val Loss: 0.7153, Val Acc: 0.5320
Epoch 57/100, Loss: 0.6270, Acc: 0.6518, Val Loss: 0.7156, Val Acc: 0.5302
Epoch 58/100, Loss: 0.6267, Acc: 0.6519, Val Loss: 0.7158, Val Acc: 0.5331
Epoch 59/100, Loss: 0.6268, Acc: 0.6506, Val Loss: 0.7150, Val Acc: 0.5313
Epoch 60/100, Loss: 0.6264, Acc: 0.6512, Val Loss: 0.7151, Val Acc: 0.5302
Epoch 61/100, Loss: 0.6264, Acc: 0.6506, Val Loss: 0.7153, Val Acc: 0.5313
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6261, Acc: 0.6519, Val Loss: 0.7156, Val Acc: 0.5346
Epoch 63/100, Loss: 0.6261, Acc: 0.6511, Val Loss: 0.7152, Val Acc: 0.5331
Epoch 64/100, Loss: 0.6261, Acc: 0.6516, Val Loss: 0.7156, Val Acc: 0.5320
Epoch 65/100, Loss: 0.6261, Acc: 0.6520, Val Loss: 0.7156, Val Acc: 0.5327
Epoch 66/100, Loss: 0.6260, Acc: 0.6522, Val Loss: 0.7152, Val Acc: 0.5291
Epoch 67/100, Loss: 0.6259, Acc: 0.6518, Val Loss: 0.7160, Val Acc: 0.5324
Epoch 68/100, Loss: 0.6259, Acc: 0.6526, Val Loss: 0.7155, Val Acc: 0.5338
Epoch 69/100, Loss: 0.6259, Acc: 0.6506, Val Loss: 0.7155, Val Acc: 0.5298
Epoch 70/100, Loss: 0.6257, Acc: 0.6519, Val Loss: 0.7157, Val Acc: 0.5331
Epoch 71/100, Loss: 0.6256, Acc: 0.6513, Val Loss: 0.7158, Val Acc: 0.5291
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6256, Acc: 0.6519, Val Loss: 0.7158, Val Acc: 0.5335
Epoch 73/100, Loss: 0.6256, Acc: 0.6518, Val Loss: 0.7156, Val Acc: 0.5338
Epoch 74/100, Loss: 0.6255, Acc: 0.6519, Val Loss: 0.7159, Val Acc: 0.5338
Epoch 75/100, Loss: 0.6255, Acc: 0.6529, Val Loss: 0.7156, Val Acc: 0.5324
Epoch 76/100, Loss: 0.6255, Acc: 0.6512, Val Loss: 0.7160, Val Acc: 0.5342
Epoch 77/100, Loss: 0.6254, Acc: 0.6530, Val Loss: 0.7157, Val Acc: 0.5305
Epoch 78/100, Loss: 0.6254, Acc: 0.6520, Val Loss: 0.7159, Val Acc: 0.5342
Epoch 79/100, Loss: 0.6255, Acc: 0.6519, Val Loss: 0.7162, Val Acc: 0.5342
Epoch 80/100, Loss: 0.6254, Acc: 0.6523, Val Loss: 0.7164, Val Acc: 0.5346
Epoch 81/100, Loss: 0.6253, Acc: 0.6516, Val Loss: 0.7162, Val Acc: 0.5313
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6252, Acc: 0.6520, Val Loss: 0.7162, Val Acc: 0.5335
Epoch 83/100, Loss: 0.6253, Acc: 0.6525, Val Loss: 0.7164, Val Acc: 0.5313
Epoch 84/100, Loss: 0.6252, Acc: 0.6518, Val Loss: 0.7162, Val Acc: 0.5313
Epoch 85/100, Loss: 0.6252, Acc: 0.6524, Val Loss: 0.7161, Val Acc: 0.5298
Epoch 86/100, Loss: 0.6249, Acc: 0.6525, Val Loss: 0.7153, Val Acc: 0.5335
Epoch 87/100, Loss: 0.6248, Acc: 0.6531, Val Loss: 0.7150, Val Acc: 0.5320
Epoch 88/100, Loss: 0.6247, Acc: 0.6529, Val Loss: 0.7153, Val Acc: 0.5320
Epoch 89/100, Loss: 0.6247, Acc: 0.6527, Val Loss: 0.7152, Val Acc: 0.5316
Epoch 90/100, Loss: 0.6247, Acc: 0.6527, Val Loss: 0.7153, Val Acc: 0.5324
Epoch 91/100, Loss: 0.6246, Acc: 0.6532, Val Loss: 0.7155, Val Acc: 0.5316
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6246, Acc: 0.6535, Val Loss: 0.7154, Val Acc: 0.5331
Epoch 93/100, Loss: 0.6245, Acc: 0.6527, Val Loss: 0.7153, Val Acc: 0.5327
Epoch 94/100, Loss: 0.6246, Acc: 0.6532, Val Loss: 0.7153, Val Acc: 0.5335
Epoch 95/100, Loss: 0.6245, Acc: 0.6520, Val Loss: 0.7152, Val Acc: 0.5316
Epoch 96/100, Loss: 0.6245, Acc: 0.6524, Val Loss: 0.7156, Val Acc: 0.5338
Epoch 97/100, Loss: 0.6244, Acc: 0.6531, Val Loss: 0.7155, Val Acc: 0.5361
Epoch 98/100, Loss: 0.6244, Acc: 0.6518, Val Loss: 0.7157, Val Acc: 0.5331
Epoch 99/100, Loss: 0.6244, Acc: 0.6538, Val Loss: 0.7159, Val Acc: 0.5327
Epoch 100/100, Loss: 0.6243, Acc: 0.6527, Val Loss: 0.7157, Val Acc: 0.5331

##############################
Resultados para principal:  002  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3 
 {'training': [0.6243306443541776, 0.652693509836367, 0.6187750429307384, 0.7951452739977933, 0.6959600836954772], 'validate': [0.7157242339710856, 0.5331125827814569, 0.5229736706246774, 0.7459499263622975, 0.6148710166919575], 'test': [0.6796639914865847, 0.5818128310771041, 0.6351219512195122, 0.3833922261484099, 0.4781491002570694]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  043  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  043  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  043  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5270, Acc: 0.7824, Val Loss: 0.7098, Val Acc: 0.5648
Mejor modelo guardado con Val Loss: 0.7098
Epoch 2/100, Loss: 0.4293, Acc: 0.8109, Val Loss: 0.6884, Val Acc: 0.5883
Mejor modelo guardado con Val Loss: 0.6884
Epoch 3/100, Loss: 0.4095, Acc: 0.8172, Val Loss: 0.7195, Val Acc: 0.6251
Epoch 4/100, Loss: 0.4078, Acc: 0.8157, Val Loss: 0.7115, Val Acc: 0.6203
Epoch 5/100, Loss: 0.4132, Acc: 0.8174, Val Loss: 0.7255, Val Acc: 0.5769
Epoch 6/100, Loss: 0.4038, Acc: 0.8177, Val Loss: 0.7565, Val Acc: 0.5942
Epoch 7/100, Loss: 0.3963, Acc: 0.8215, Val Loss: 0.7096, Val Acc: 0.6269
Epoch 8/100, Loss: 0.3935, Acc: 0.8207, Val Loss: 0.7491, Val Acc: 0.5990
Epoch 9/100, Loss: 0.3976, Acc: 0.8195, Val Loss: 0.7202, Val Acc: 0.6299
Epoch 10/100, Loss: 0.3969, Acc: 0.8196, Val Loss: 0.7057, Val Acc: 0.6063
Epoch 11/100, Loss: 0.3997, Acc: 0.8170, Val Loss: 0.7225, Val Acc: 0.6214
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3852, Acc: 0.8273, Val Loss: 0.7261, Val Acc: 0.6188
Epoch 13/100, Loss: 0.3824, Acc: 0.8279, Val Loss: 0.7302, Val Acc: 0.6247
Epoch 14/100, Loss: 0.3823, Acc: 0.8270, Val Loss: 0.7425, Val Acc: 0.6273
Epoch 15/100, Loss: 0.3826, Acc: 0.8284, Val Loss: 0.7208, Val Acc: 0.6034
Epoch 16/100, Loss: 0.3791, Acc: 0.8274, Val Loss: 0.7611, Val Acc: 0.6100
Epoch 17/100, Loss: 0.3788, Acc: 0.8277, Val Loss: 0.6920, Val Acc: 0.6118
Epoch 18/100, Loss: 0.3809, Acc: 0.8258, Val Loss: 0.7246, Val Acc: 0.6093
Epoch 19/100, Loss: 0.3759, Acc: 0.8301, Val Loss: 0.7390, Val Acc: 0.6163
Epoch 20/100, Loss: 0.3793, Acc: 0.8257, Val Loss: 0.7420, Val Acc: 0.5997
Epoch 21/100, Loss: 0.3816, Acc: 0.8260, Val Loss: 0.6850, Val Acc: 0.6424
Mejor modelo guardado con Val Loss: 0.6850
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3735, Acc: 0.8320, Val Loss: 0.7228, Val Acc: 0.6453
Epoch 23/100, Loss: 0.3724, Acc: 0.8291, Val Loss: 0.6962, Val Acc: 0.6387
Epoch 24/100, Loss: 0.3729, Acc: 0.8289, Val Loss: 0.6982, Val Acc: 0.6288
Epoch 25/100, Loss: 0.3715, Acc: 0.8317, Val Loss: 0.7386, Val Acc: 0.6258
Epoch 26/100, Loss: 0.3707, Acc: 0.8290, Val Loss: 0.7155, Val Acc: 0.6317
Epoch 27/100, Loss: 0.3711, Acc: 0.8291, Val Loss: 0.7044, Val Acc: 0.6225
Epoch 28/100, Loss: 0.3715, Acc: 0.8303, Val Loss: 0.7077, Val Acc: 0.6372
Epoch 29/100, Loss: 0.3727, Acc: 0.8289, Val Loss: 0.7030, Val Acc: 0.6361
Epoch 30/100, Loss: 0.3715, Acc: 0.8274, Val Loss: 0.7073, Val Acc: 0.6383
Epoch 31/100, Loss: 0.3696, Acc: 0.8308, Val Loss: 0.7143, Val Acc: 0.6310
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3660, Acc: 0.8330, Val Loss: 0.6922, Val Acc: 0.6365
Epoch 33/100, Loss: 0.3645, Acc: 0.8320, Val Loss: 0.7137, Val Acc: 0.6387
Epoch 34/100, Loss: 0.3649, Acc: 0.8313, Val Loss: 0.7100, Val Acc: 0.6306
Epoch 35/100, Loss: 0.3641, Acc: 0.8331, Val Loss: 0.7278, Val Acc: 0.6262
Epoch 36/100, Loss: 0.3645, Acc: 0.8331, Val Loss: 0.7074, Val Acc: 0.6313
Epoch 37/100, Loss: 0.3637, Acc: 0.8328, Val Loss: 0.6931, Val Acc: 0.6328
Epoch 38/100, Loss: 0.3634, Acc: 0.8331, Val Loss: 0.7015, Val Acc: 0.6328
Epoch 39/100, Loss: 0.3642, Acc: 0.8323, Val Loss: 0.7092, Val Acc: 0.6325
Epoch 40/100, Loss: 0.3634, Acc: 0.8330, Val Loss: 0.7202, Val Acc: 0.6376
Epoch 41/100, Loss: 0.3636, Acc: 0.8334, Val Loss: 0.7330, Val Acc: 0.6328
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3612, Acc: 0.8340, Val Loss: 0.7164, Val Acc: 0.6321
Epoch 43/100, Loss: 0.3612, Acc: 0.8336, Val Loss: 0.7200, Val Acc: 0.6332
Epoch 44/100, Loss: 0.3610, Acc: 0.8345, Val Loss: 0.7129, Val Acc: 0.6310
Epoch 45/100, Loss: 0.3608, Acc: 0.8342, Val Loss: 0.7063, Val Acc: 0.6328
Epoch 46/100, Loss: 0.3604, Acc: 0.8342, Val Loss: 0.7218, Val Acc: 0.6317
Epoch 47/100, Loss: 0.3606, Acc: 0.8340, Val Loss: 0.7140, Val Acc: 0.6284
Epoch 48/100, Loss: 0.3604, Acc: 0.8347, Val Loss: 0.7073, Val Acc: 0.6284
Epoch 49/100, Loss: 0.3597, Acc: 0.8354, Val Loss: 0.7070, Val Acc: 0.6339
Epoch 50/100, Loss: 0.3596, Acc: 0.8359, Val Loss: 0.7119, Val Acc: 0.6325
Epoch 51/100, Loss: 0.3599, Acc: 0.8353, Val Loss: 0.7170, Val Acc: 0.6299
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3586, Acc: 0.8358, Val Loss: 0.7062, Val Acc: 0.6302
Epoch 53/100, Loss: 0.3587, Acc: 0.8347, Val Loss: 0.7123, Val Acc: 0.6291
Epoch 54/100, Loss: 0.3587, Acc: 0.8359, Val Loss: 0.7129, Val Acc: 0.6284
Epoch 55/100, Loss: 0.3585, Acc: 0.8360, Val Loss: 0.7121, Val Acc: 0.6328
Epoch 56/100, Loss: 0.3585, Acc: 0.8348, Val Loss: 0.7080, Val Acc: 0.6336
Epoch 57/100, Loss: 0.3585, Acc: 0.8363, Val Loss: 0.7103, Val Acc: 0.6313
Epoch 58/100, Loss: 0.3581, Acc: 0.8366, Val Loss: 0.7065, Val Acc: 0.6339
Epoch 59/100, Loss: 0.3584, Acc: 0.8338, Val Loss: 0.7141, Val Acc: 0.6313
Epoch 60/100, Loss: 0.3583, Acc: 0.8358, Val Loss: 0.7206, Val Acc: 0.6325
Epoch 61/100, Loss: 0.3582, Acc: 0.8363, Val Loss: 0.7092, Val Acc: 0.6317
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3575, Acc: 0.8354, Val Loss: 0.7144, Val Acc: 0.6325
Epoch 63/100, Loss: 0.3575, Acc: 0.8360, Val Loss: 0.7199, Val Acc: 0.6332
Epoch 64/100, Loss: 0.3575, Acc: 0.8367, Val Loss: 0.7153, Val Acc: 0.6302
Epoch 65/100, Loss: 0.3575, Acc: 0.8361, Val Loss: 0.7178, Val Acc: 0.6310
Epoch 66/100, Loss: 0.3574, Acc: 0.8358, Val Loss: 0.7159, Val Acc: 0.6317
Epoch 67/100, Loss: 0.3575, Acc: 0.8354, Val Loss: 0.7166, Val Acc: 0.6325
Epoch 68/100, Loss: 0.3573, Acc: 0.8352, Val Loss: 0.7162, Val Acc: 0.6306
Epoch 69/100, Loss: 0.3574, Acc: 0.8360, Val Loss: 0.7140, Val Acc: 0.6321
Epoch 70/100, Loss: 0.3572, Acc: 0.8377, Val Loss: 0.7220, Val Acc: 0.6332
Epoch 71/100, Loss: 0.3572, Acc: 0.8368, Val Loss: 0.7128, Val Acc: 0.6302
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3570, Acc: 0.8354, Val Loss: 0.7173, Val Acc: 0.6332
Epoch 73/100, Loss: 0.3571, Acc: 0.8362, Val Loss: 0.7156, Val Acc: 0.6332
Epoch 74/100, Loss: 0.3570, Acc: 0.8367, Val Loss: 0.7157, Val Acc: 0.6313
Epoch 75/100, Loss: 0.3570, Acc: 0.8351, Val Loss: 0.7159, Val Acc: 0.6306
Epoch 76/100, Loss: 0.3569, Acc: 0.8359, Val Loss: 0.7154, Val Acc: 0.6317
Epoch 77/100, Loss: 0.3568, Acc: 0.8363, Val Loss: 0.7162, Val Acc: 0.6306
Epoch 78/100, Loss: 0.3569, Acc: 0.8365, Val Loss: 0.7172, Val Acc: 0.6325
Epoch 79/100, Loss: 0.3567, Acc: 0.8355, Val Loss: 0.7164, Val Acc: 0.6302
Epoch 80/100, Loss: 0.3568, Acc: 0.8361, Val Loss: 0.7146, Val Acc: 0.6306
Epoch 81/100, Loss: 0.3567, Acc: 0.8367, Val Loss: 0.7194, Val Acc: 0.6328
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3569, Acc: 0.8357, Val Loss: 0.7130, Val Acc: 0.6310
Epoch 83/100, Loss: 0.3567, Acc: 0.8357, Val Loss: 0.7159, Val Acc: 0.6313
Epoch 84/100, Loss: 0.3566, Acc: 0.8354, Val Loss: 0.7154, Val Acc: 0.6313
Epoch 85/100, Loss: 0.3566, Acc: 0.8361, Val Loss: 0.7137, Val Acc: 0.6310
Epoch 86/100, Loss: 0.3565, Acc: 0.8361, Val Loss: 0.7136, Val Acc: 0.6328
Epoch 87/100, Loss: 0.3565, Acc: 0.8372, Val Loss: 0.7154, Val Acc: 0.6328
Epoch 88/100, Loss: 0.3565, Acc: 0.8353, Val Loss: 0.7150, Val Acc: 0.6328
Epoch 89/100, Loss: 0.3564, Acc: 0.8363, Val Loss: 0.7172, Val Acc: 0.6328
Epoch 90/100, Loss: 0.3564, Acc: 0.8364, Val Loss: 0.7172, Val Acc: 0.6328
Epoch 91/100, Loss: 0.3564, Acc: 0.8360, Val Loss: 0.7174, Val Acc: 0.6336
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3563, Acc: 0.8357, Val Loss: 0.7173, Val Acc: 0.6332
Epoch 93/100, Loss: 0.3563, Acc: 0.8360, Val Loss: 0.7154, Val Acc: 0.6332
Epoch 94/100, Loss: 0.3563, Acc: 0.8360, Val Loss: 0.7153, Val Acc: 0.6336
Epoch 95/100, Loss: 0.3562, Acc: 0.8354, Val Loss: 0.7148, Val Acc: 0.6325
Epoch 96/100, Loss: 0.3562, Acc: 0.8359, Val Loss: 0.7130, Val Acc: 0.6339
Epoch 97/100, Loss: 0.3563, Acc: 0.8366, Val Loss: 0.7149, Val Acc: 0.6339
Epoch 98/100, Loss: 0.3562, Acc: 0.8357, Val Loss: 0.7139, Val Acc: 0.6325
Epoch 99/100, Loss: 0.3562, Acc: 0.8354, Val Loss: 0.7142, Val Acc: 0.6339
Epoch 100/100, Loss: 0.3562, Acc: 0.8357, Val Loss: 0.7114, Val Acc: 0.6354

##############################
Resultados para principal:  043  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3 
 {'training': [0.35620078866392796, 0.8357234785806215, 0.8483113909559244, 0.8175799926443545, 0.8326622342916004], 'validate': [0.7114471800105516, 0.6353936718175128, 0.6423584173778123, 0.6097201767304861, 0.6256139025311673], 'test': [0.4337506201118231, 0.7975279576221307, 0.7497527200791295, 0.8928150765606596, 0.8150537634408602]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  073  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  073  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  073  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6845, Acc: 0.5588, Val Loss: 0.7215, Val Acc: 0.4047
Mejor modelo guardado con Val Loss: 0.7215
Epoch 2/100, Loss: 0.6835, Acc: 0.5596, Val Loss: 0.7221, Val Acc: 0.2314
Epoch 3/100, Loss: 0.6846, Acc: 0.5615, Val Loss: 0.7031, Val Acc: 0.4816
Mejor modelo guardado con Val Loss: 0.7031
Epoch 4/100, Loss: 0.6790, Acc: 0.5745, Val Loss: 0.7161, Val Acc: 0.4018
Epoch 5/100, Loss: 0.6760, Acc: 0.5762, Val Loss: 0.7047, Val Acc: 0.4974
Epoch 6/100, Loss: 0.6761, Acc: 0.5728, Val Loss: 0.7394, Val Acc: 0.3532
Epoch 7/100, Loss: 0.6704, Acc: 0.5851, Val Loss: 0.7370, Val Acc: 0.3444
Epoch 8/100, Loss: 0.6761, Acc: 0.5695, Val Loss: 0.7163, Val Acc: 0.4334
Epoch 9/100, Loss: 0.6742, Acc: 0.5871, Val Loss: 0.7525, Val Acc: 0.2870
Epoch 10/100, Loss: 0.6755, Acc: 0.5816, Val Loss: 0.7869, Val Acc: 0.2414
Epoch 11/100, Loss: 0.6736, Acc: 0.5822, Val Loss: 0.7633, Val Acc: 0.3127
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6719, Acc: 0.5864, Val Loss: 0.7610, Val Acc: 0.3223
Epoch 13/100, Loss: 0.6685, Acc: 0.5982, Val Loss: 0.7947, Val Acc: 0.2656
Epoch 14/100, Loss: 0.6680, Acc: 0.5968, Val Loss: 0.7483, Val Acc: 0.3874
Epoch 15/100, Loss: 0.6675, Acc: 0.6008, Val Loss: 0.7281, Val Acc: 0.4411
Epoch 16/100, Loss: 0.6685, Acc: 0.5936, Val Loss: 0.7816, Val Acc: 0.3146
Epoch 17/100, Loss: 0.6669, Acc: 0.5968, Val Loss: 0.8182, Val Acc: 0.2458
Epoch 18/100, Loss: 0.6658, Acc: 0.5988, Val Loss: 0.8459, Val Acc: 0.2009
Epoch 19/100, Loss: 0.6657, Acc: 0.6041, Val Loss: 0.7524, Val Acc: 0.4238
Epoch 20/100, Loss: 0.6674, Acc: 0.5969, Val Loss: 0.7710, Val Acc: 0.3532
Epoch 21/100, Loss: 0.6676, Acc: 0.5972, Val Loss: 0.7649, Val Acc: 0.3709
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6633, Acc: 0.6054, Val Loss: 0.8032, Val Acc: 0.2958
Epoch 23/100, Loss: 0.6633, Acc: 0.6057, Val Loss: 0.8124, Val Acc: 0.2723
Epoch 24/100, Loss: 0.6633, Acc: 0.6044, Val Loss: 0.8219, Val Acc: 0.2631
Epoch 25/100, Loss: 0.6629, Acc: 0.6063, Val Loss: 0.7800, Val Acc: 0.3510
Epoch 26/100, Loss: 0.6621, Acc: 0.6101, Val Loss: 0.8195, Val Acc: 0.2671
Epoch 27/100, Loss: 0.6632, Acc: 0.6034, Val Loss: 0.7917, Val Acc: 0.3363
Epoch 28/100, Loss: 0.6629, Acc: 0.6047, Val Loss: 0.8091, Val Acc: 0.2965
Epoch 29/100, Loss: 0.6632, Acc: 0.6080, Val Loss: 0.7998, Val Acc: 0.3223
Epoch 30/100, Loss: 0.6621, Acc: 0.6040, Val Loss: 0.8125, Val Acc: 0.2940
Epoch 31/100, Loss: 0.6622, Acc: 0.6065, Val Loss: 0.7923, Val Acc: 0.3400
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6617, Acc: 0.6062, Val Loss: 0.7960, Val Acc: 0.3282
Epoch 33/100, Loss: 0.6614, Acc: 0.6079, Val Loss: 0.8036, Val Acc: 0.3190
Epoch 34/100, Loss: 0.6616, Acc: 0.6092, Val Loss: 0.8091, Val Acc: 0.3105
Epoch 35/100, Loss: 0.6617, Acc: 0.6079, Val Loss: 0.7994, Val Acc: 0.3263
Epoch 36/100, Loss: 0.6614, Acc: 0.6063, Val Loss: 0.8099, Val Acc: 0.3072
Epoch 37/100, Loss: 0.6613, Acc: 0.6064, Val Loss: 0.7941, Val Acc: 0.3396
Epoch 38/100, Loss: 0.6612, Acc: 0.6089, Val Loss: 0.8048, Val Acc: 0.3208
Epoch 39/100, Loss: 0.6611, Acc: 0.6067, Val Loss: 0.7959, Val Acc: 0.3366
Epoch 40/100, Loss: 0.6609, Acc: 0.6094, Val Loss: 0.8026, Val Acc: 0.3252
Epoch 41/100, Loss: 0.6608, Acc: 0.6102, Val Loss: 0.7861, Val Acc: 0.3550
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6608, Acc: 0.6101, Val Loss: 0.8024, Val Acc: 0.3267
Epoch 43/100, Loss: 0.6608, Acc: 0.6088, Val Loss: 0.7979, Val Acc: 0.3355
Epoch 44/100, Loss: 0.6605, Acc: 0.6088, Val Loss: 0.7874, Val Acc: 0.3550
Epoch 45/100, Loss: 0.6610, Acc: 0.6086, Val Loss: 0.7986, Val Acc: 0.3359
Epoch 46/100, Loss: 0.6608, Acc: 0.6110, Val Loss: 0.8039, Val Acc: 0.3263
Epoch 47/100, Loss: 0.6603, Acc: 0.6099, Val Loss: 0.8040, Val Acc: 0.3263
Epoch 48/100, Loss: 0.6604, Acc: 0.6097, Val Loss: 0.8000, Val Acc: 0.3359
Epoch 49/100, Loss: 0.6605, Acc: 0.6094, Val Loss: 0.7995, Val Acc: 0.3359
Epoch 50/100, Loss: 0.6605, Acc: 0.6097, Val Loss: 0.7974, Val Acc: 0.3400
Epoch 51/100, Loss: 0.6604, Acc: 0.6093, Val Loss: 0.7881, Val Acc: 0.3572
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6601, Acc: 0.6096, Val Loss: 0.7997, Val Acc: 0.3359
Epoch 53/100, Loss: 0.6601, Acc: 0.6109, Val Loss: 0.8019, Val Acc: 0.3322
Epoch 54/100, Loss: 0.6600, Acc: 0.6097, Val Loss: 0.7966, Val Acc: 0.3414
Epoch 55/100, Loss: 0.6601, Acc: 0.6090, Val Loss: 0.8040, Val Acc: 0.3271
Epoch 56/100, Loss: 0.6600, Acc: 0.6115, Val Loss: 0.7957, Val Acc: 0.3436
Epoch 57/100, Loss: 0.6601, Acc: 0.6095, Val Loss: 0.7933, Val Acc: 0.3462
Epoch 58/100, Loss: 0.6602, Acc: 0.6096, Val Loss: 0.8003, Val Acc: 0.3366
Epoch 59/100, Loss: 0.6601, Acc: 0.6086, Val Loss: 0.8008, Val Acc: 0.3348
Epoch 60/100, Loss: 0.6600, Acc: 0.6117, Val Loss: 0.8042, Val Acc: 0.3293
Epoch 61/100, Loss: 0.6599, Acc: 0.6132, Val Loss: 0.7949, Val Acc: 0.3458
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6600, Acc: 0.6094, Val Loss: 0.7973, Val Acc: 0.3422
Epoch 63/100, Loss: 0.6599, Acc: 0.6106, Val Loss: 0.8005, Val Acc: 0.3370
Epoch 64/100, Loss: 0.6598, Acc: 0.6113, Val Loss: 0.7962, Val Acc: 0.3440
Epoch 65/100, Loss: 0.6599, Acc: 0.6106, Val Loss: 0.7973, Val Acc: 0.3422
Epoch 66/100, Loss: 0.6599, Acc: 0.6099, Val Loss: 0.7984, Val Acc: 0.3396
Epoch 67/100, Loss: 0.6599, Acc: 0.6111, Val Loss: 0.8012, Val Acc: 0.3359
Epoch 68/100, Loss: 0.6598, Acc: 0.6109, Val Loss: 0.8022, Val Acc: 0.3341
Epoch 69/100, Loss: 0.6598, Acc: 0.6115, Val Loss: 0.8006, Val Acc: 0.3374
Epoch 70/100, Loss: 0.6598, Acc: 0.6126, Val Loss: 0.7991, Val Acc: 0.3396
Epoch 71/100, Loss: 0.6599, Acc: 0.6102, Val Loss: 0.7980, Val Acc: 0.3422
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6598, Acc: 0.6096, Val Loss: 0.7999, Val Acc: 0.3385
Epoch 73/100, Loss: 0.6598, Acc: 0.6118, Val Loss: 0.7987, Val Acc: 0.3407
Epoch 74/100, Loss: 0.6597, Acc: 0.6099, Val Loss: 0.8012, Val Acc: 0.3363
Epoch 75/100, Loss: 0.6598, Acc: 0.6118, Val Loss: 0.7994, Val Acc: 0.3392
Epoch 76/100, Loss: 0.6597, Acc: 0.6117, Val Loss: 0.8010, Val Acc: 0.3366
Epoch 77/100, Loss: 0.6597, Acc: 0.6121, Val Loss: 0.7956, Val Acc: 0.3455
Epoch 78/100, Loss: 0.6598, Acc: 0.6099, Val Loss: 0.8001, Val Acc: 0.3381
Epoch 79/100, Loss: 0.6598, Acc: 0.6127, Val Loss: 0.7985, Val Acc: 0.3403
Epoch 80/100, Loss: 0.6597, Acc: 0.6121, Val Loss: 0.7968, Val Acc: 0.3429
Epoch 81/100, Loss: 0.6597, Acc: 0.6106, Val Loss: 0.7981, Val Acc: 0.3403
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6597, Acc: 0.6106, Val Loss: 0.7993, Val Acc: 0.3381
Epoch 83/100, Loss: 0.6598, Acc: 0.6099, Val Loss: 0.8004, Val Acc: 0.3359
Epoch 84/100, Loss: 0.6597, Acc: 0.6120, Val Loss: 0.7990, Val Acc: 0.3385
Epoch 85/100, Loss: 0.6597, Acc: 0.6119, Val Loss: 0.7999, Val Acc: 0.3370
Epoch 86/100, Loss: 0.6597, Acc: 0.6103, Val Loss: 0.8027, Val Acc: 0.3319
Epoch 87/100, Loss: 0.6597, Acc: 0.6122, Val Loss: 0.7987, Val Acc: 0.3389
Epoch 88/100, Loss: 0.6598, Acc: 0.6102, Val Loss: 0.7981, Val Acc: 0.3400
Epoch 89/100, Loss: 0.6597, Acc: 0.6099, Val Loss: 0.8015, Val Acc: 0.3341
Epoch 90/100, Loss: 0.6596, Acc: 0.6123, Val Loss: 0.7989, Val Acc: 0.3385
Epoch 91/100, Loss: 0.6596, Acc: 0.6117, Val Loss: 0.7983, Val Acc: 0.3392
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6598, Acc: 0.6088, Val Loss: 0.7990, Val Acc: 0.3389
Epoch 93/100, Loss: 0.6596, Acc: 0.6124, Val Loss: 0.7971, Val Acc: 0.3418
Epoch 94/100, Loss: 0.6596, Acc: 0.6107, Val Loss: 0.7990, Val Acc: 0.3389
Epoch 95/100, Loss: 0.6596, Acc: 0.6111, Val Loss: 0.8016, Val Acc: 0.3341
Epoch 96/100, Loss: 0.6597, Acc: 0.6116, Val Loss: 0.8007, Val Acc: 0.3352
Epoch 97/100, Loss: 0.6596, Acc: 0.6122, Val Loss: 0.8003, Val Acc: 0.3359
Epoch 98/100, Loss: 0.6596, Acc: 0.6110, Val Loss: 0.7967, Val Acc: 0.3425
Epoch 99/100, Loss: 0.6596, Acc: 0.6101, Val Loss: 0.8009, Val Acc: 0.3352
Epoch 100/100, Loss: 0.6597, Acc: 0.6108, Val Loss: 0.8002, Val Acc: 0.3366

##############################
Resultados para principal:  073  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3 
 {'training': [0.6597332296772112, 0.6107740393454679, 0.588974283180609, 0.7328061787421847, 0.6530645689937725], 'validate': [0.8002044974371444, 0.336644591611479, 0.39835541343079034, 0.6421207658321061, 0.4916831124894277], 'test': [0.7000019462020309, 0.48057680988816953, 0.4898207231844424, 0.9493521790341578, 0.6462216877129685]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  109  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  109  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  109  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6894, Acc: 0.5476, Val Loss: 0.6958, Val Acc: 0.4765
Mejor modelo guardado con Val Loss: 0.6958
Epoch 2/100, Loss: 0.6840, Acc: 0.5732, Val Loss: 0.7051, Val Acc: 0.4268
Epoch 3/100, Loss: 0.6759, Acc: 0.5901, Val Loss: 0.7135, Val Acc: 0.4426
Epoch 4/100, Loss: 0.6711, Acc: 0.5976, Val Loss: 0.7195, Val Acc: 0.4573
Epoch 5/100, Loss: 0.6669, Acc: 0.5995, Val Loss: 0.7270, Val Acc: 0.4150
Epoch 6/100, Loss: 0.6657, Acc: 0.5980, Val Loss: 0.7491, Val Acc: 0.4054
Epoch 7/100, Loss: 0.6628, Acc: 0.6018, Val Loss: 0.7372, Val Acc: 0.4529
Epoch 8/100, Loss: 0.6602, Acc: 0.6041, Val Loss: 0.7545, Val Acc: 0.4264
Epoch 9/100, Loss: 0.6607, Acc: 0.6031, Val Loss: 0.7426, Val Acc: 0.4356
Epoch 10/100, Loss: 0.6571, Acc: 0.6023, Val Loss: 0.7388, Val Acc: 0.4426
Epoch 11/100, Loss: 0.6543, Acc: 0.6113, Val Loss: 0.7279, Val Acc: 0.4650
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6556, Acc: 0.6080, Val Loss: 0.7396, Val Acc: 0.4621
Epoch 13/100, Loss: 0.6514, Acc: 0.6154, Val Loss: 0.7407, Val Acc: 0.4581
Epoch 14/100, Loss: 0.6531, Acc: 0.6065, Val Loss: 0.7525, Val Acc: 0.4478
Epoch 15/100, Loss: 0.6504, Acc: 0.6113, Val Loss: 0.7419, Val Acc: 0.4581
Epoch 16/100, Loss: 0.6509, Acc: 0.6131, Val Loss: 0.7481, Val Acc: 0.4566
Epoch 17/100, Loss: 0.6515, Acc: 0.6167, Val Loss: 0.7347, Val Acc: 0.4628
Epoch 18/100, Loss: 0.6497, Acc: 0.6147, Val Loss: 0.7561, Val Acc: 0.4441
Epoch 19/100, Loss: 0.6502, Acc: 0.6144, Val Loss: 0.7407, Val Acc: 0.4632
Epoch 20/100, Loss: 0.6483, Acc: 0.6143, Val Loss: 0.7512, Val Acc: 0.4606
Epoch 21/100, Loss: 0.6499, Acc: 0.6099, Val Loss: 0.7479, Val Acc: 0.4459
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6460, Acc: 0.6196, Val Loss: 0.7484, Val Acc: 0.4595
Epoch 23/100, Loss: 0.6459, Acc: 0.6161, Val Loss: 0.7424, Val Acc: 0.4584
Epoch 24/100, Loss: 0.6462, Acc: 0.6189, Val Loss: 0.7453, Val Acc: 0.4588
Epoch 25/100, Loss: 0.6462, Acc: 0.6178, Val Loss: 0.7545, Val Acc: 0.4533
Epoch 26/100, Loss: 0.6456, Acc: 0.6167, Val Loss: 0.7507, Val Acc: 0.4599
Epoch 27/100, Loss: 0.6458, Acc: 0.6150, Val Loss: 0.7555, Val Acc: 0.4592
Epoch 28/100, Loss: 0.6454, Acc: 0.6150, Val Loss: 0.7492, Val Acc: 0.4606
Epoch 29/100, Loss: 0.6454, Acc: 0.6166, Val Loss: 0.7406, Val Acc: 0.4702
Epoch 30/100, Loss: 0.6457, Acc: 0.6124, Val Loss: 0.7476, Val Acc: 0.4603
Epoch 31/100, Loss: 0.6451, Acc: 0.6181, Val Loss: 0.7625, Val Acc: 0.4463
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6442, Acc: 0.6182, Val Loss: 0.7558, Val Acc: 0.4573
Epoch 33/100, Loss: 0.6440, Acc: 0.6177, Val Loss: 0.7515, Val Acc: 0.4603
Epoch 34/100, Loss: 0.6443, Acc: 0.6181, Val Loss: 0.7562, Val Acc: 0.4511
Epoch 35/100, Loss: 0.6440, Acc: 0.6197, Val Loss: 0.7413, Val Acc: 0.4639
Epoch 36/100, Loss: 0.6446, Acc: 0.6213, Val Loss: 0.7529, Val Acc: 0.4544
Epoch 37/100, Loss: 0.6440, Acc: 0.6196, Val Loss: 0.7549, Val Acc: 0.4562
Epoch 38/100, Loss: 0.6434, Acc: 0.6204, Val Loss: 0.7450, Val Acc: 0.4621
Epoch 39/100, Loss: 0.6439, Acc: 0.6203, Val Loss: 0.7575, Val Acc: 0.4536
Epoch 40/100, Loss: 0.6433, Acc: 0.6210, Val Loss: 0.7566, Val Acc: 0.4540
Epoch 41/100, Loss: 0.6435, Acc: 0.6176, Val Loss: 0.7541, Val Acc: 0.4573
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6429, Acc: 0.6220, Val Loss: 0.7579, Val Acc: 0.4525
Epoch 43/100, Loss: 0.6428, Acc: 0.6213, Val Loss: 0.7516, Val Acc: 0.4577
Epoch 44/100, Loss: 0.6423, Acc: 0.6227, Val Loss: 0.7553, Val Acc: 0.4562
Epoch 45/100, Loss: 0.6425, Acc: 0.6236, Val Loss: 0.7536, Val Acc: 0.4584
Epoch 46/100, Loss: 0.6425, Acc: 0.6245, Val Loss: 0.7572, Val Acc: 0.4584
Epoch 47/100, Loss: 0.6425, Acc: 0.6256, Val Loss: 0.7553, Val Acc: 0.4540
Epoch 48/100, Loss: 0.6423, Acc: 0.6240, Val Loss: 0.7540, Val Acc: 0.4573
Epoch 49/100, Loss: 0.6422, Acc: 0.6232, Val Loss: 0.7578, Val Acc: 0.4551
Epoch 50/100, Loss: 0.6419, Acc: 0.6259, Val Loss: 0.7505, Val Acc: 0.4588
Epoch 51/100, Loss: 0.6419, Acc: 0.6247, Val Loss: 0.7531, Val Acc: 0.4581
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6411, Acc: 0.6277, Val Loss: 0.7524, Val Acc: 0.4592
Epoch 53/100, Loss: 0.6410, Acc: 0.6259, Val Loss: 0.7499, Val Acc: 0.4599
Epoch 54/100, Loss: 0.6410, Acc: 0.6251, Val Loss: 0.7544, Val Acc: 0.4584
Epoch 55/100, Loss: 0.6410, Acc: 0.6241, Val Loss: 0.7533, Val Acc: 0.4588
Epoch 56/100, Loss: 0.6409, Acc: 0.6238, Val Loss: 0.7522, Val Acc: 0.4581
Epoch 57/100, Loss: 0.6409, Acc: 0.6269, Val Loss: 0.7552, Val Acc: 0.4603
Epoch 58/100, Loss: 0.6409, Acc: 0.6256, Val Loss: 0.7539, Val Acc: 0.4610
Epoch 59/100, Loss: 0.6408, Acc: 0.6261, Val Loss: 0.7546, Val Acc: 0.4603
Epoch 60/100, Loss: 0.6407, Acc: 0.6243, Val Loss: 0.7537, Val Acc: 0.4599
Epoch 61/100, Loss: 0.6408, Acc: 0.6254, Val Loss: 0.7548, Val Acc: 0.4603
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6405, Acc: 0.6232, Val Loss: 0.7538, Val Acc: 0.4599
Epoch 63/100, Loss: 0.6404, Acc: 0.6246, Val Loss: 0.7533, Val Acc: 0.4603
Epoch 64/100, Loss: 0.6404, Acc: 0.6221, Val Loss: 0.7548, Val Acc: 0.4610
Epoch 65/100, Loss: 0.6403, Acc: 0.6244, Val Loss: 0.7543, Val Acc: 0.4606
Epoch 66/100, Loss: 0.6403, Acc: 0.6224, Val Loss: 0.7526, Val Acc: 0.4592
Epoch 67/100, Loss: 0.6403, Acc: 0.6218, Val Loss: 0.7539, Val Acc: 0.4603
Epoch 68/100, Loss: 0.6401, Acc: 0.6224, Val Loss: 0.7564, Val Acc: 0.4584
Epoch 69/100, Loss: 0.6403, Acc: 0.6229, Val Loss: 0.7545, Val Acc: 0.4603
Epoch 70/100, Loss: 0.6402, Acc: 0.6222, Val Loss: 0.7538, Val Acc: 0.4581
Epoch 71/100, Loss: 0.6401, Acc: 0.6234, Val Loss: 0.7528, Val Acc: 0.4581
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6401, Acc: 0.6217, Val Loss: 0.7546, Val Acc: 0.4617
Epoch 73/100, Loss: 0.6400, Acc: 0.6235, Val Loss: 0.7544, Val Acc: 0.4617
Epoch 74/100, Loss: 0.6400, Acc: 0.6219, Val Loss: 0.7550, Val Acc: 0.4603
Epoch 75/100, Loss: 0.6400, Acc: 0.6231, Val Loss: 0.7548, Val Acc: 0.4603
Epoch 76/100, Loss: 0.6399, Acc: 0.6251, Val Loss: 0.7538, Val Acc: 0.4592
Epoch 77/100, Loss: 0.6400, Acc: 0.6224, Val Loss: 0.7552, Val Acc: 0.4614
Epoch 78/100, Loss: 0.6400, Acc: 0.6224, Val Loss: 0.7545, Val Acc: 0.4606
Epoch 79/100, Loss: 0.6400, Acc: 0.6224, Val Loss: 0.7552, Val Acc: 0.4610
Epoch 80/100, Loss: 0.6399, Acc: 0.6236, Val Loss: 0.7552, Val Acc: 0.4610
Epoch 81/100, Loss: 0.6399, Acc: 0.6229, Val Loss: 0.7551, Val Acc: 0.4603
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6399, Acc: 0.6231, Val Loss: 0.7550, Val Acc: 0.4606
Epoch 83/100, Loss: 0.6399, Acc: 0.6225, Val Loss: 0.7548, Val Acc: 0.4614
Epoch 84/100, Loss: 0.6399, Acc: 0.6238, Val Loss: 0.7546, Val Acc: 0.4606
Epoch 85/100, Loss: 0.6398, Acc: 0.6234, Val Loss: 0.7551, Val Acc: 0.4603
Epoch 86/100, Loss: 0.6399, Acc: 0.6225, Val Loss: 0.7545, Val Acc: 0.4606
Epoch 87/100, Loss: 0.6399, Acc: 0.6237, Val Loss: 0.7548, Val Acc: 0.4603
Epoch 88/100, Loss: 0.6398, Acc: 0.6236, Val Loss: 0.7549, Val Acc: 0.4603
Epoch 89/100, Loss: 0.6398, Acc: 0.6233, Val Loss: 0.7547, Val Acc: 0.4606
Epoch 90/100, Loss: 0.6398, Acc: 0.6239, Val Loss: 0.7550, Val Acc: 0.4606
Epoch 91/100, Loss: 0.6398, Acc: 0.6228, Val Loss: 0.7548, Val Acc: 0.4603
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6397, Acc: 0.6232, Val Loss: 0.7555, Val Acc: 0.4603
Epoch 93/100, Loss: 0.6398, Acc: 0.6231, Val Loss: 0.7548, Val Acc: 0.4617
Epoch 94/100, Loss: 0.6398, Acc: 0.6237, Val Loss: 0.7549, Val Acc: 0.4606
Epoch 95/100, Loss: 0.6397, Acc: 0.6228, Val Loss: 0.7548, Val Acc: 0.4599
Epoch 96/100, Loss: 0.6397, Acc: 0.6245, Val Loss: 0.7549, Val Acc: 0.4606
Epoch 97/100, Loss: 0.6397, Acc: 0.6236, Val Loss: 0.7550, Val Acc: 0.4603
Epoch 98/100, Loss: 0.6397, Acc: 0.6245, Val Loss: 0.7548, Val Acc: 0.4610
Epoch 99/100, Loss: 0.6396, Acc: 0.6236, Val Loss: 0.7542, Val Acc: 0.4595
Epoch 100/100, Loss: 0.6397, Acc: 0.6231, Val Loss: 0.7539, Val Acc: 0.4595

##############################
Resultados para principal:  109  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  3 
 {'training': [0.6397047787493786, 0.6230924802353374, 0.5959552495697074, 0.7640676719382126, 0.669621273166801], 'validate': [0.753887744837029, 0.45952906548933037, 0.47551830613145124, 0.7938144329896907, 0.5947586206896551], 'test': [0.6878630154662662, 0.5638610947616245, 0.7317596566523605, 0.20082449941107186, 0.31515711645101663]}

##############################
Resultados para window:  3 
 {'062:035:002:043:073:109': {'training': [0.2256288756658365, 0.906784335355764, 0.9005795001810938, 0.9144906215520412, 0.9074817518248175], 'validate': [0.6922432179021281, 0.6975717439293598, 0.7925764192139738, 0.5346097201767305, 0.6385224274406333], 'test': [0.29191167114509475, 0.88905238375515, 0.8772130211307824, 0.9045936395759717, 0.8906929544795593]}, '035:062:002:043:073:109': {'training': [0.48286573312961567, 0.7739474168045597, 0.7710646041856233, 0.7791467451268849, 0.775084606237995], 'validate': [0.5293822978125062, 0.7579102281089036, 0.710589651022864, 0.8696612665684831, 0.7821192052980133], 'test': [0.560920178062386, 0.7333725721012361, 0.6902017291066282, 0.8462897526501767, 0.7603174603174603]}, '002:062:035:043:073:109': {'training': [0.6243306443541776, 0.652693509836367, 0.6187750429307384, 0.7951452739977933, 0.6959600836954772], 'validate': [0.7157242339710856, 0.5331125827814569, 0.5229736706246774, 0.7459499263622975, 0.6148710166919575], 'test': [0.6796639914865847, 0.5818128310771041, 0.6351219512195122, 0.3833922261484099, 0.4781491002570694]}, '043:062:035:002:073:109': {'training': [0.35620078866392796, 0.8357234785806215, 0.8483113909559244, 0.8175799926443545, 0.8326622342916004], 'validate': [0.7114471800105516, 0.6353936718175128, 0.6423584173778123, 0.6097201767304861, 0.6256139025311673], 'test': [0.4337506201118231, 0.7975279576221307, 0.7497527200791295, 0.8928150765606596, 0.8150537634408602]}, '073:062:035:002:043:109': {'training': [0.6597332296772112, 0.6107740393454679, 0.588974283180609, 0.7328061787421847, 0.6530645689937725], 'validate': [0.8002044974371444, 0.336644591611479, 0.39835541343079034, 0.6421207658321061, 0.4916831124894277], 'test': [0.7000019462020309, 0.48057680988816953, 0.4898207231844424, 0.9493521790341578, 0.6462216877129685]}, '109:062:035:002:043:073': {'training': [0.6397047787493786, 0.6230924802353374, 0.5959552495697074, 0.7640676719382126, 0.669621273166801], 'validate': [0.753887744837029, 0.45952906548933037, 0.47551830613145124, 0.7938144329896907, 0.5947586206896551], 'test': [0.6878630154662662, 0.5638610947616245, 0.7317596566523605, 0.20082449941107186, 0.31515711645101663]}}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  098  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  098  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  098  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6695, Acc: 0.6019, Val Loss: 0.5766, Val Acc: 0.7568
Mejor modelo guardado con Val Loss: 0.5766
Epoch 2/100, Loss: 0.6336, Acc: 0.6422, Val Loss: 0.5103, Val Acc: 0.8922
Mejor modelo guardado con Val Loss: 0.5103
Epoch 3/100, Loss: 0.6123, Acc: 0.6565, Val Loss: 0.4425, Val Acc: 0.8679
Mejor modelo guardado con Val Loss: 0.4425
Epoch 4/100, Loss: 0.6039, Acc: 0.6553, Val Loss: 0.4842, Val Acc: 0.8812
Epoch 5/100, Loss: 0.5991, Acc: 0.6607, Val Loss: 0.4555, Val Acc: 0.9029
Epoch 6/100, Loss: 0.6020, Acc: 0.6593, Val Loss: 0.4543, Val Acc: 0.8668
Epoch 7/100, Loss: 0.5950, Acc: 0.6643, Val Loss: 0.4183, Val Acc: 0.8896
Mejor modelo guardado con Val Loss: 0.4183
Epoch 8/100, Loss: 0.5966, Acc: 0.6608, Val Loss: 0.4113, Val Acc: 0.9047
Mejor modelo guardado con Val Loss: 0.4113
Epoch 9/100, Loss: 0.5941, Acc: 0.6606, Val Loss: 0.4038, Val Acc: 0.9032
Mejor modelo guardado con Val Loss: 0.4038
Epoch 10/100, Loss: 0.5937, Acc: 0.6599, Val Loss: 0.4649, Val Acc: 0.7918
Epoch 11/100, Loss: 0.5925, Acc: 0.6595, Val Loss: 0.3981, Val Acc: 0.9124
Mejor modelo guardado con Val Loss: 0.3981
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5860, Acc: 0.6661, Val Loss: 0.4214, Val Acc: 0.8311
Epoch 13/100, Loss: 0.5841, Acc: 0.6714, Val Loss: 0.3801, Val Acc: 0.8981
Mejor modelo guardado con Val Loss: 0.3801
Epoch 14/100, Loss: 0.5836, Acc: 0.6728, Val Loss: 0.3803, Val Acc: 0.8937
Epoch 15/100, Loss: 0.5845, Acc: 0.6691, Val Loss: 0.4010, Val Acc: 0.8679
Epoch 16/100, Loss: 0.5827, Acc: 0.6703, Val Loss: 0.4048, Val Acc: 0.9043
Epoch 17/100, Loss: 0.5844, Acc: 0.6680, Val Loss: 0.4070, Val Acc: 0.8587
Epoch 18/100, Loss: 0.5850, Acc: 0.6688, Val Loss: 0.4115, Val Acc: 0.8061
Epoch 19/100, Loss: 0.5830, Acc: 0.6672, Val Loss: 0.3725, Val Acc: 0.9135
Mejor modelo guardado con Val Loss: 0.3725
Epoch 20/100, Loss: 0.5815, Acc: 0.6722, Val Loss: 0.3758, Val Acc: 0.9051
Epoch 21/100, Loss: 0.5827, Acc: 0.6687, Val Loss: 0.3749, Val Acc: 0.9062
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5808, Acc: 0.6726, Val Loss: 0.3770, Val Acc: 0.9043
Epoch 23/100, Loss: 0.5808, Acc: 0.6732, Val Loss: 0.3755, Val Acc: 0.9036
Epoch 24/100, Loss: 0.5785, Acc: 0.6759, Val Loss: 0.3677, Val Acc: 0.9157
Mejor modelo guardado con Val Loss: 0.3677
Epoch 25/100, Loss: 0.5801, Acc: 0.6723, Val Loss: 0.3714, Val Acc: 0.9077
Epoch 26/100, Loss: 0.5793, Acc: 0.6746, Val Loss: 0.3852, Val Acc: 0.8985
Epoch 27/100, Loss: 0.5799, Acc: 0.6735, Val Loss: 0.3742, Val Acc: 0.9069
Epoch 28/100, Loss: 0.5807, Acc: 0.6737, Val Loss: 0.3720, Val Acc: 0.9029
Epoch 29/100, Loss: 0.5801, Acc: 0.6695, Val Loss: 0.3702, Val Acc: 0.9110
Epoch 30/100, Loss: 0.5793, Acc: 0.6750, Val Loss: 0.3859, Val Acc: 0.8812
Epoch 31/100, Loss: 0.5786, Acc: 0.6748, Val Loss: 0.3704, Val Acc: 0.9128
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5782, Acc: 0.6763, Val Loss: 0.3681, Val Acc: 0.9124
Epoch 33/100, Loss: 0.5780, Acc: 0.6773, Val Loss: 0.3749, Val Acc: 0.9018
Epoch 34/100, Loss: 0.5777, Acc: 0.6744, Val Loss: 0.3677, Val Acc: 0.9154
Mejor modelo guardado con Val Loss: 0.3677
Epoch 35/100, Loss: 0.5777, Acc: 0.6783, Val Loss: 0.3753, Val Acc: 0.9080
Epoch 36/100, Loss: 0.5769, Acc: 0.6769, Val Loss: 0.3694, Val Acc: 0.9110
Epoch 37/100, Loss: 0.5778, Acc: 0.6760, Val Loss: 0.3697, Val Acc: 0.9099
Epoch 38/100, Loss: 0.5773, Acc: 0.6765, Val Loss: 0.3707, Val Acc: 0.9117
Epoch 39/100, Loss: 0.5770, Acc: 0.6775, Val Loss: 0.3715, Val Acc: 0.9106
Epoch 40/100, Loss: 0.5767, Acc: 0.6763, Val Loss: 0.3752, Val Acc: 0.9032
Epoch 41/100, Loss: 0.5771, Acc: 0.6769, Val Loss: 0.3725, Val Acc: 0.9065
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5760, Acc: 0.6788, Val Loss: 0.3672, Val Acc: 0.9172
Mejor modelo guardado con Val Loss: 0.3672
Epoch 43/100, Loss: 0.5763, Acc: 0.6769, Val Loss: 0.3709, Val Acc: 0.9132
Epoch 44/100, Loss: 0.5763, Acc: 0.6771, Val Loss: 0.3705, Val Acc: 0.9088
Epoch 45/100, Loss: 0.5762, Acc: 0.6785, Val Loss: 0.3709, Val Acc: 0.9073
Epoch 46/100, Loss: 0.5757, Acc: 0.6792, Val Loss: 0.3756, Val Acc: 0.8988
Epoch 47/100, Loss: 0.5763, Acc: 0.6783, Val Loss: 0.3682, Val Acc: 0.9176
Epoch 48/100, Loss: 0.5754, Acc: 0.6786, Val Loss: 0.3682, Val Acc: 0.9139
Epoch 49/100, Loss: 0.5753, Acc: 0.6794, Val Loss: 0.3696, Val Acc: 0.9091
Epoch 50/100, Loss: 0.5751, Acc: 0.6776, Val Loss: 0.3648, Val Acc: 0.9180
Mejor modelo guardado con Val Loss: 0.3648
Epoch 51/100, Loss: 0.5748, Acc: 0.6781, Val Loss: 0.3681, Val Acc: 0.9110
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5748, Acc: 0.6780, Val Loss: 0.3684, Val Acc: 0.9121
Epoch 53/100, Loss: 0.5747, Acc: 0.6793, Val Loss: 0.3696, Val Acc: 0.9080
Epoch 54/100, Loss: 0.5747, Acc: 0.6788, Val Loss: 0.3698, Val Acc: 0.9088
Epoch 55/100, Loss: 0.5746, Acc: 0.6790, Val Loss: 0.3683, Val Acc: 0.9150
Epoch 56/100, Loss: 0.5744, Acc: 0.6783, Val Loss: 0.3684, Val Acc: 0.9095
Epoch 57/100, Loss: 0.5745, Acc: 0.6787, Val Loss: 0.3681, Val Acc: 0.9113
Epoch 58/100, Loss: 0.5746, Acc: 0.6785, Val Loss: 0.3706, Val Acc: 0.9091
Epoch 59/100, Loss: 0.5744, Acc: 0.6779, Val Loss: 0.3682, Val Acc: 0.9146
Epoch 60/100, Loss: 0.5745, Acc: 0.6794, Val Loss: 0.3693, Val Acc: 0.9113
Epoch 61/100, Loss: 0.5744, Acc: 0.6796, Val Loss: 0.3701, Val Acc: 0.9073
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5741, Acc: 0.6786, Val Loss: 0.3685, Val Acc: 0.9128
Epoch 63/100, Loss: 0.5742, Acc: 0.6792, Val Loss: 0.3691, Val Acc: 0.9091
Epoch 64/100, Loss: 0.5741, Acc: 0.6793, Val Loss: 0.3685, Val Acc: 0.9139
Epoch 65/100, Loss: 0.5740, Acc: 0.6789, Val Loss: 0.3687, Val Acc: 0.9132
Epoch 66/100, Loss: 0.5741, Acc: 0.6791, Val Loss: 0.3686, Val Acc: 0.9128
Epoch 67/100, Loss: 0.5740, Acc: 0.6786, Val Loss: 0.3679, Val Acc: 0.9143
Epoch 68/100, Loss: 0.5740, Acc: 0.6791, Val Loss: 0.3681, Val Acc: 0.9139
Epoch 69/100, Loss: 0.5739, Acc: 0.6791, Val Loss: 0.3689, Val Acc: 0.9132
Epoch 70/100, Loss: 0.5740, Acc: 0.6787, Val Loss: 0.3690, Val Acc: 0.9124
Epoch 71/100, Loss: 0.5737, Acc: 0.6800, Val Loss: 0.3728, Val Acc: 0.9054
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5738, Acc: 0.6798, Val Loss: 0.3701, Val Acc: 0.9117
Epoch 73/100, Loss: 0.5736, Acc: 0.6790, Val Loss: 0.3708, Val Acc: 0.9106
Epoch 74/100, Loss: 0.5736, Acc: 0.6792, Val Loss: 0.3704, Val Acc: 0.9117
Epoch 75/100, Loss: 0.5737, Acc: 0.6792, Val Loss: 0.3705, Val Acc: 0.9110
Epoch 76/100, Loss: 0.5737, Acc: 0.6800, Val Loss: 0.3705, Val Acc: 0.9113
Epoch 77/100, Loss: 0.5737, Acc: 0.6788, Val Loss: 0.3693, Val Acc: 0.9154
Epoch 78/100, Loss: 0.5735, Acc: 0.6791, Val Loss: 0.3697, Val Acc: 0.9135
Epoch 79/100, Loss: 0.5735, Acc: 0.6798, Val Loss: 0.3708, Val Acc: 0.9106
Epoch 80/100, Loss: 0.5734, Acc: 0.6784, Val Loss: 0.3690, Val Acc: 0.9150
Epoch 81/100, Loss: 0.5735, Acc: 0.6791, Val Loss: 0.3708, Val Acc: 0.9102
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5733, Acc: 0.6789, Val Loss: 0.3719, Val Acc: 0.9069
Epoch 83/100, Loss: 0.5732, Acc: 0.6791, Val Loss: 0.3715, Val Acc: 0.9113
Epoch 84/100, Loss: 0.5730, Acc: 0.6794, Val Loss: 0.3738, Val Acc: 0.9099
Epoch 85/100, Loss: 0.5729, Acc: 0.6795, Val Loss: 0.3727, Val Acc: 0.9113
Epoch 86/100, Loss: 0.5728, Acc: 0.6797, Val Loss: 0.3724, Val Acc: 0.9124
Epoch 87/100, Loss: 0.5728, Acc: 0.6797, Val Loss: 0.3732, Val Acc: 0.9102
Epoch 88/100, Loss: 0.5728, Acc: 0.6805, Val Loss: 0.3727, Val Acc: 0.9102
Epoch 89/100, Loss: 0.5727, Acc: 0.6801, Val Loss: 0.3733, Val Acc: 0.9102
Epoch 90/100, Loss: 0.5728, Acc: 0.6802, Val Loss: 0.3719, Val Acc: 0.9099
Epoch 91/100, Loss: 0.5727, Acc: 0.6801, Val Loss: 0.3709, Val Acc: 0.9117
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5727, Acc: 0.6798, Val Loss: 0.3722, Val Acc: 0.9106
Epoch 93/100, Loss: 0.5727, Acc: 0.6797, Val Loss: 0.3729, Val Acc: 0.9091
Epoch 94/100, Loss: 0.5727, Acc: 0.6799, Val Loss: 0.3730, Val Acc: 0.9102
Epoch 95/100, Loss: 0.5726, Acc: 0.6801, Val Loss: 0.3719, Val Acc: 0.9110
Epoch 96/100, Loss: 0.5727, Acc: 0.6796, Val Loss: 0.3711, Val Acc: 0.9113
Epoch 97/100, Loss: 0.5726, Acc: 0.6796, Val Loss: 0.3714, Val Acc: 0.9117
Epoch 98/100, Loss: 0.5725, Acc: 0.6797, Val Loss: 0.3710, Val Acc: 0.9121
Epoch 99/100, Loss: 0.5725, Acc: 0.6798, Val Loss: 0.3708, Val Acc: 0.9124
Epoch 100/100, Loss: 0.5726, Acc: 0.6800, Val Loss: 0.3716, Val Acc: 0.9106

##############################
Resultados para principal:  098  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3 
 {'training': [0.5725622290108743, 0.6799963228534657, 0.6218403685717844, 0.9183523354174329, 0.741554681119608], 'validate': [0.37163500791025716, 0.9105960264900662, 0.9358874120406567, 0.8814432989690721, 0.9078498293515358], 'test': [0.6273113875477402, 0.6297822248381401, 0.5823353293413174, 0.9163722025912838, 0.7121281464530892]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  025  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  025  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  025  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6704, Acc: 0.6031, Val Loss: 0.5929, Val Acc: 0.7116
Mejor modelo guardado con Val Loss: 0.5929
Epoch 2/100, Loss: 0.6466, Acc: 0.6228, Val Loss: 0.5312, Val Acc: 0.8882
Mejor modelo guardado con Val Loss: 0.5312
Epoch 3/100, Loss: 0.6274, Acc: 0.6404, Val Loss: 0.5659, Val Acc: 0.7837
Epoch 4/100, Loss: 0.6217, Acc: 0.6468, Val Loss: 0.4936, Val Acc: 0.8959
Mejor modelo guardado con Val Loss: 0.4936
Epoch 5/100, Loss: 0.6126, Acc: 0.6462, Val Loss: 0.4581, Val Acc: 0.8330
Mejor modelo guardado con Val Loss: 0.4581
Epoch 6/100, Loss: 0.6126, Acc: 0.6454, Val Loss: 0.4608, Val Acc: 0.8705
Epoch 7/100, Loss: 0.6085, Acc: 0.6498, Val Loss: 0.4874, Val Acc: 0.8451
Epoch 8/100, Loss: 0.6099, Acc: 0.6479, Val Loss: 0.4342, Val Acc: 0.8918
Mejor modelo guardado con Val Loss: 0.4342
Epoch 9/100, Loss: 0.6055, Acc: 0.6479, Val Loss: 0.4594, Val Acc: 0.8863
Epoch 10/100, Loss: 0.6014, Acc: 0.6537, Val Loss: 0.4223, Val Acc: 0.8709
Mejor modelo guardado con Val Loss: 0.4223
Epoch 11/100, Loss: 0.6090, Acc: 0.6424, Val Loss: 0.4519, Val Acc: 0.8661
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5996, Acc: 0.6550, Val Loss: 0.4253, Val Acc: 0.8801
Epoch 13/100, Loss: 0.5993, Acc: 0.6559, Val Loss: 0.4153, Val Acc: 0.8951
Mejor modelo guardado con Val Loss: 0.4153
Epoch 14/100, Loss: 0.5975, Acc: 0.6598, Val Loss: 0.4402, Val Acc: 0.8403
Epoch 15/100, Loss: 0.5968, Acc: 0.6582, Val Loss: 0.4482, Val Acc: 0.8804
Epoch 16/100, Loss: 0.5953, Acc: 0.6599, Val Loss: 0.4274, Val Acc: 0.8944
Epoch 17/100, Loss: 0.5949, Acc: 0.6600, Val Loss: 0.4096, Val Acc: 0.8889
Mejor modelo guardado con Val Loss: 0.4096
Epoch 18/100, Loss: 0.5950, Acc: 0.6589, Val Loss: 0.4148, Val Acc: 0.8885
Epoch 19/100, Loss: 0.5938, Acc: 0.6598, Val Loss: 0.4191, Val Acc: 0.8705
Epoch 20/100, Loss: 0.5934, Acc: 0.6596, Val Loss: 0.4191, Val Acc: 0.8543
Epoch 21/100, Loss: 0.5954, Acc: 0.6584, Val Loss: 0.4191, Val Acc: 0.8694
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5924, Acc: 0.6613, Val Loss: 0.4072, Val Acc: 0.8790
Mejor modelo guardado con Val Loss: 0.4072
Epoch 23/100, Loss: 0.5898, Acc: 0.6608, Val Loss: 0.4140, Val Acc: 0.8635
Epoch 24/100, Loss: 0.5903, Acc: 0.6633, Val Loss: 0.4150, Val Acc: 0.8870
Epoch 25/100, Loss: 0.5914, Acc: 0.6614, Val Loss: 0.4271, Val Acc: 0.8679
Epoch 26/100, Loss: 0.5910, Acc: 0.6619, Val Loss: 0.4161, Val Acc: 0.8738
Epoch 27/100, Loss: 0.5898, Acc: 0.6645, Val Loss: 0.4092, Val Acc: 0.8705
Epoch 28/100, Loss: 0.5893, Acc: 0.6621, Val Loss: 0.4015, Val Acc: 0.8907
Mejor modelo guardado con Val Loss: 0.4015
Epoch 29/100, Loss: 0.5891, Acc: 0.6624, Val Loss: 0.4093, Val Acc: 0.8826
Epoch 30/100, Loss: 0.5906, Acc: 0.6612, Val Loss: 0.4179, Val Acc: 0.8683
Epoch 31/100, Loss: 0.5888, Acc: 0.6634, Val Loss: 0.4101, Val Acc: 0.8683
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5882, Acc: 0.6649, Val Loss: 0.4093, Val Acc: 0.8756
Epoch 33/100, Loss: 0.5873, Acc: 0.6634, Val Loss: 0.4228, Val Acc: 0.8466
Epoch 34/100, Loss: 0.5879, Acc: 0.6647, Val Loss: 0.4156, Val Acc: 0.8558
Epoch 35/100, Loss: 0.5875, Acc: 0.6635, Val Loss: 0.4090, Val Acc: 0.8716
Epoch 36/100, Loss: 0.5876, Acc: 0.6646, Val Loss: 0.4147, Val Acc: 0.8745
Epoch 37/100, Loss: 0.5879, Acc: 0.6661, Val Loss: 0.4129, Val Acc: 0.8624
Epoch 38/100, Loss: 0.5868, Acc: 0.6657, Val Loss: 0.4143, Val Acc: 0.8624
Epoch 39/100, Loss: 0.5870, Acc: 0.6640, Val Loss: 0.4076, Val Acc: 0.8790
Epoch 40/100, Loss: 0.5872, Acc: 0.6637, Val Loss: 0.4132, Val Acc: 0.8569
Epoch 41/100, Loss: 0.5870, Acc: 0.6630, Val Loss: 0.4126, Val Acc: 0.8675
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5863, Acc: 0.6657, Val Loss: 0.4129, Val Acc: 0.8650
Epoch 43/100, Loss: 0.5864, Acc: 0.6650, Val Loss: 0.4096, Val Acc: 0.8734
Epoch 44/100, Loss: 0.5862, Acc: 0.6652, Val Loss: 0.4100, Val Acc: 0.8727
Epoch 45/100, Loss: 0.5863, Acc: 0.6656, Val Loss: 0.4117, Val Acc: 0.8683
Epoch 46/100, Loss: 0.5860, Acc: 0.6634, Val Loss: 0.4051, Val Acc: 0.8815
Epoch 47/100, Loss: 0.5859, Acc: 0.6672, Val Loss: 0.4111, Val Acc: 0.8631
Epoch 48/100, Loss: 0.5858, Acc: 0.6666, Val Loss: 0.4151, Val Acc: 0.8572
Epoch 49/100, Loss: 0.5862, Acc: 0.6658, Val Loss: 0.4087, Val Acc: 0.8661
Epoch 50/100, Loss: 0.5860, Acc: 0.6642, Val Loss: 0.4126, Val Acc: 0.8672
Epoch 51/100, Loss: 0.5859, Acc: 0.6653, Val Loss: 0.4063, Val Acc: 0.8720
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5857, Acc: 0.6653, Val Loss: 0.4094, Val Acc: 0.8642
Epoch 53/100, Loss: 0.5857, Acc: 0.6650, Val Loss: 0.4104, Val Acc: 0.8664
Epoch 54/100, Loss: 0.5854, Acc: 0.6657, Val Loss: 0.4123, Val Acc: 0.8727
Epoch 55/100, Loss: 0.5855, Acc: 0.6652, Val Loss: 0.4109, Val Acc: 0.8683
Epoch 56/100, Loss: 0.5855, Acc: 0.6657, Val Loss: 0.4115, Val Acc: 0.8664
Epoch 57/100, Loss: 0.5855, Acc: 0.6656, Val Loss: 0.4091, Val Acc: 0.8679
Epoch 58/100, Loss: 0.5854, Acc: 0.6659, Val Loss: 0.4091, Val Acc: 0.8672
Epoch 59/100, Loss: 0.5855, Acc: 0.6650, Val Loss: 0.4093, Val Acc: 0.8642
Epoch 60/100, Loss: 0.5854, Acc: 0.6660, Val Loss: 0.4128, Val Acc: 0.8664
Epoch 61/100, Loss: 0.5853, Acc: 0.6653, Val Loss: 0.4100, Val Acc: 0.8631
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5852, Acc: 0.6664, Val Loss: 0.4100, Val Acc: 0.8628
Epoch 63/100, Loss: 0.5852, Acc: 0.6653, Val Loss: 0.4100, Val Acc: 0.8639
Epoch 64/100, Loss: 0.5851, Acc: 0.6666, Val Loss: 0.4107, Val Acc: 0.8620
Epoch 65/100, Loss: 0.5852, Acc: 0.6656, Val Loss: 0.4106, Val Acc: 0.8657
Epoch 66/100, Loss: 0.5851, Acc: 0.6656, Val Loss: 0.4099, Val Acc: 0.8635
Epoch 67/100, Loss: 0.5852, Acc: 0.6653, Val Loss: 0.4107, Val Acc: 0.8653
Epoch 68/100, Loss: 0.5850, Acc: 0.6659, Val Loss: 0.4099, Val Acc: 0.8657
Epoch 69/100, Loss: 0.5851, Acc: 0.6659, Val Loss: 0.4108, Val Acc: 0.8650
Epoch 70/100, Loss: 0.5851, Acc: 0.6667, Val Loss: 0.4096, Val Acc: 0.8657
Epoch 71/100, Loss: 0.5852, Acc: 0.6658, Val Loss: 0.4100, Val Acc: 0.8650
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5850, Acc: 0.6657, Val Loss: 0.4103, Val Acc: 0.8657
Epoch 73/100, Loss: 0.5850, Acc: 0.6667, Val Loss: 0.4106, Val Acc: 0.8650
Epoch 74/100, Loss: 0.5850, Acc: 0.6657, Val Loss: 0.4104, Val Acc: 0.8653
Epoch 75/100, Loss: 0.5850, Acc: 0.6664, Val Loss: 0.4107, Val Acc: 0.8653
Epoch 76/100, Loss: 0.5850, Acc: 0.6666, Val Loss: 0.4103, Val Acc: 0.8653
Epoch 77/100, Loss: 0.5850, Acc: 0.6659, Val Loss: 0.4103, Val Acc: 0.8653
Epoch 78/100, Loss: 0.5849, Acc: 0.6664, Val Loss: 0.4101, Val Acc: 0.8646
Epoch 79/100, Loss: 0.5849, Acc: 0.6659, Val Loss: 0.4098, Val Acc: 0.8657
Epoch 80/100, Loss: 0.5849, Acc: 0.6662, Val Loss: 0.4110, Val Acc: 0.8664
Epoch 81/100, Loss: 0.5849, Acc: 0.6661, Val Loss: 0.4103, Val Acc: 0.8653
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5849, Acc: 0.6675, Val Loss: 0.4105, Val Acc: 0.8653
Epoch 83/100, Loss: 0.5849, Acc: 0.6656, Val Loss: 0.4104, Val Acc: 0.8668
Epoch 84/100, Loss: 0.5849, Acc: 0.6660, Val Loss: 0.4103, Val Acc: 0.8653
Epoch 85/100, Loss: 0.5849, Acc: 0.6668, Val Loss: 0.4107, Val Acc: 0.8650
Epoch 86/100, Loss: 0.5849, Acc: 0.6657, Val Loss: 0.4106, Val Acc: 0.8653
Epoch 87/100, Loss: 0.5848, Acc: 0.6665, Val Loss: 0.4106, Val Acc: 0.8650
Epoch 88/100, Loss: 0.5849, Acc: 0.6659, Val Loss: 0.4109, Val Acc: 0.8650
Epoch 89/100, Loss: 0.5849, Acc: 0.6662, Val Loss: 0.4105, Val Acc: 0.8650
Epoch 90/100, Loss: 0.5849, Acc: 0.6662, Val Loss: 0.4111, Val Acc: 0.8646
Epoch 91/100, Loss: 0.5849, Acc: 0.6663, Val Loss: 0.4104, Val Acc: 0.8664
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5848, Acc: 0.6669, Val Loss: 0.4102, Val Acc: 0.8657
Epoch 93/100, Loss: 0.5848, Acc: 0.6666, Val Loss: 0.4117, Val Acc: 0.8657
Epoch 94/100, Loss: 0.5846, Acc: 0.6665, Val Loss: 0.4122, Val Acc: 0.8646
Epoch 95/100, Loss: 0.5846, Acc: 0.6665, Val Loss: 0.4118, Val Acc: 0.8642
Epoch 96/100, Loss: 0.5846, Acc: 0.6668, Val Loss: 0.4122, Val Acc: 0.8642
Epoch 97/100, Loss: 0.5846, Acc: 0.6665, Val Loss: 0.4123, Val Acc: 0.8639
Epoch 98/100, Loss: 0.5845, Acc: 0.6667, Val Loss: 0.4122, Val Acc: 0.8642
Epoch 99/100, Loss: 0.5846, Acc: 0.6663, Val Loss: 0.4119, Val Acc: 0.8661
Epoch 100/100, Loss: 0.5845, Acc: 0.6666, Val Loss: 0.4121, Val Acc: 0.8646

##############################
Resultados para principal:  025  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3 
 {'training': [0.584505236834852, 0.6665747380033095, 0.6151303242212333, 0.889665318131666, 0.7273547320153348], 'validate': [0.41211369321789854, 0.8646063281824872, 0.9064039408866995, 0.812960235640648, 0.8571428571428571], 'test': [0.627940332448041, 0.6527369040612124, 0.6049432739059968, 0.8792697290930507, 0.7167546807489198]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  059  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  059  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  059  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6282, Acc: 0.6736, Val Loss: 0.4386, Val Acc: 0.8911
Mejor modelo guardado con Val Loss: 0.4386
Epoch 2/100, Loss: 0.5893, Acc: 0.6892, Val Loss: 0.4012, Val Acc: 0.9058
Mejor modelo guardado con Val Loss: 0.4012
Epoch 3/100, Loss: 0.5813, Acc: 0.6907, Val Loss: 0.3825, Val Acc: 0.9051
Mejor modelo guardado con Val Loss: 0.3825
Epoch 4/100, Loss: 0.5836, Acc: 0.6841, Val Loss: 0.3653, Val Acc: 0.9095
Mejor modelo guardado con Val Loss: 0.3653
Epoch 5/100, Loss: 0.5742, Acc: 0.6929, Val Loss: 0.3844, Val Acc: 0.9036
Epoch 6/100, Loss: 0.5693, Acc: 0.6898, Val Loss: 0.3754, Val Acc: 0.9154
Epoch 7/100, Loss: 0.5703, Acc: 0.6901, Val Loss: 0.3598, Val Acc: 0.9051
Mejor modelo guardado con Val Loss: 0.3598
Epoch 8/100, Loss: 0.5700, Acc: 0.6899, Val Loss: 0.3163, Val Acc: 0.9106
Mejor modelo guardado con Val Loss: 0.3163
Epoch 9/100, Loss: 0.5635, Acc: 0.6925, Val Loss: 0.3386, Val Acc: 0.9040
Epoch 10/100, Loss: 0.5648, Acc: 0.6876, Val Loss: 0.3189, Val Acc: 0.9010
Epoch 11/100, Loss: 0.5694, Acc: 0.6931, Val Loss: 0.3425, Val Acc: 0.9099
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5573, Acc: 0.7016, Val Loss: 0.3245, Val Acc: 0.8937
Epoch 13/100, Loss: 0.5530, Acc: 0.6972, Val Loss: 0.3190, Val Acc: 0.8933
Epoch 14/100, Loss: 0.5537, Acc: 0.7011, Val Loss: 0.2925, Val Acc: 0.9080
Mejor modelo guardado con Val Loss: 0.2925
Epoch 15/100, Loss: 0.5509, Acc: 0.7025, Val Loss: 0.3383, Val Acc: 0.8918
Epoch 16/100, Loss: 0.5526, Acc: 0.6934, Val Loss: 0.3377, Val Acc: 0.8918
Epoch 17/100, Loss: 0.5497, Acc: 0.6965, Val Loss: 0.2983, Val Acc: 0.9032
Epoch 18/100, Loss: 0.5487, Acc: 0.6993, Val Loss: 0.3701, Val Acc: 0.9191
Epoch 19/100, Loss: 0.5471, Acc: 0.7033, Val Loss: 0.3325, Val Acc: 0.9073
Epoch 20/100, Loss: 0.5510, Acc: 0.6976, Val Loss: 0.2983, Val Acc: 0.9080
Epoch 21/100, Loss: 0.5464, Acc: 0.6964, Val Loss: 0.2965, Val Acc: 0.9084
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5437, Acc: 0.7050, Val Loss: 0.3150, Val Acc: 0.9065
Epoch 23/100, Loss: 0.5442, Acc: 0.7019, Val Loss: 0.3052, Val Acc: 0.9040
Epoch 24/100, Loss: 0.5412, Acc: 0.7075, Val Loss: 0.3284, Val Acc: 0.8955
Epoch 25/100, Loss: 0.5406, Acc: 0.7080, Val Loss: 0.3265, Val Acc: 0.9003
Epoch 26/100, Loss: 0.5406, Acc: 0.7077, Val Loss: 0.3033, Val Acc: 0.9043
Epoch 27/100, Loss: 0.5414, Acc: 0.7083, Val Loss: 0.3097, Val Acc: 0.8996
Epoch 28/100, Loss: 0.5392, Acc: 0.7084, Val Loss: 0.3020, Val Acc: 0.9040
Epoch 29/100, Loss: 0.5403, Acc: 0.7090, Val Loss: 0.3322, Val Acc: 0.8985
Epoch 30/100, Loss: 0.5394, Acc: 0.7112, Val Loss: 0.3215, Val Acc: 0.9069
Epoch 31/100, Loss: 0.5393, Acc: 0.7097, Val Loss: 0.2843, Val Acc: 0.9088
Mejor modelo guardado con Val Loss: 0.2843
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5387, Acc: 0.7073, Val Loss: 0.3045, Val Acc: 0.9032
Epoch 33/100, Loss: 0.5365, Acc: 0.7091, Val Loss: 0.3239, Val Acc: 0.8970
Epoch 34/100, Loss: 0.5365, Acc: 0.7078, Val Loss: 0.3125, Val Acc: 0.8966
Epoch 35/100, Loss: 0.5372, Acc: 0.7108, Val Loss: 0.3032, Val Acc: 0.9036
Epoch 36/100, Loss: 0.5358, Acc: 0.7127, Val Loss: 0.3012, Val Acc: 0.9003
Epoch 37/100, Loss: 0.5364, Acc: 0.7122, Val Loss: 0.3160, Val Acc: 0.9007
Epoch 38/100, Loss: 0.5357, Acc: 0.7103, Val Loss: 0.3006, Val Acc: 0.9058
Epoch 39/100, Loss: 0.5356, Acc: 0.7099, Val Loss: 0.3104, Val Acc: 0.9014
Epoch 40/100, Loss: 0.5355, Acc: 0.7112, Val Loss: 0.3063, Val Acc: 0.9010
Epoch 41/100, Loss: 0.5347, Acc: 0.7121, Val Loss: 0.3029, Val Acc: 0.9007
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5339, Acc: 0.7139, Val Loss: 0.2976, Val Acc: 0.9040
Epoch 43/100, Loss: 0.5337, Acc: 0.7155, Val Loss: 0.3178, Val Acc: 0.8966
Epoch 44/100, Loss: 0.5334, Acc: 0.7102, Val Loss: 0.3018, Val Acc: 0.9025
Epoch 45/100, Loss: 0.5332, Acc: 0.7113, Val Loss: 0.2967, Val Acc: 0.9051
Epoch 46/100, Loss: 0.5334, Acc: 0.7128, Val Loss: 0.3038, Val Acc: 0.9007
Epoch 47/100, Loss: 0.5336, Acc: 0.7131, Val Loss: 0.3163, Val Acc: 0.8959
Epoch 48/100, Loss: 0.5334, Acc: 0.7139, Val Loss: 0.3111, Val Acc: 0.8974
Epoch 49/100, Loss: 0.5331, Acc: 0.7109, Val Loss: 0.3114, Val Acc: 0.8985
Epoch 50/100, Loss: 0.5336, Acc: 0.7125, Val Loss: 0.3080, Val Acc: 0.9018
Epoch 51/100, Loss: 0.5328, Acc: 0.7142, Val Loss: 0.3002, Val Acc: 0.9025
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5324, Acc: 0.7135, Val Loss: 0.3083, Val Acc: 0.8985
Epoch 53/100, Loss: 0.5321, Acc: 0.7131, Val Loss: 0.3160, Val Acc: 0.9007
Epoch 54/100, Loss: 0.5323, Acc: 0.7141, Val Loss: 0.3045, Val Acc: 0.9014
Epoch 55/100, Loss: 0.5322, Acc: 0.7128, Val Loss: 0.3090, Val Acc: 0.8996
Epoch 56/100, Loss: 0.5321, Acc: 0.7125, Val Loss: 0.3055, Val Acc: 0.9003
Epoch 57/100, Loss: 0.5321, Acc: 0.7135, Val Loss: 0.3052, Val Acc: 0.8999
Epoch 58/100, Loss: 0.5319, Acc: 0.7135, Val Loss: 0.3034, Val Acc: 0.9007
Epoch 59/100, Loss: 0.5321, Acc: 0.7134, Val Loss: 0.3081, Val Acc: 0.8974
Epoch 60/100, Loss: 0.5318, Acc: 0.7126, Val Loss: 0.3080, Val Acc: 0.9036
Epoch 61/100, Loss: 0.5319, Acc: 0.7133, Val Loss: 0.3046, Val Acc: 0.9003
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5316, Acc: 0.7141, Val Loss: 0.3083, Val Acc: 0.8981
Epoch 63/100, Loss: 0.5315, Acc: 0.7144, Val Loss: 0.3060, Val Acc: 0.8988
Epoch 64/100, Loss: 0.5315, Acc: 0.7136, Val Loss: 0.3065, Val Acc: 0.8988
Epoch 65/100, Loss: 0.5315, Acc: 0.7124, Val Loss: 0.3073, Val Acc: 0.9007
Epoch 66/100, Loss: 0.5315, Acc: 0.7142, Val Loss: 0.3085, Val Acc: 0.8981
Epoch 67/100, Loss: 0.5314, Acc: 0.7128, Val Loss: 0.3068, Val Acc: 0.9010
Epoch 68/100, Loss: 0.5313, Acc: 0.7134, Val Loss: 0.3095, Val Acc: 0.8974
Epoch 69/100, Loss: 0.5314, Acc: 0.7139, Val Loss: 0.3051, Val Acc: 0.9007
Epoch 70/100, Loss: 0.5313, Acc: 0.7129, Val Loss: 0.3054, Val Acc: 0.8992
Epoch 71/100, Loss: 0.5314, Acc: 0.7137, Val Loss: 0.3069, Val Acc: 0.8996
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5312, Acc: 0.7136, Val Loss: 0.3072, Val Acc: 0.8988
Epoch 73/100, Loss: 0.5312, Acc: 0.7131, Val Loss: 0.3065, Val Acc: 0.8992
Epoch 74/100, Loss: 0.5311, Acc: 0.7133, Val Loss: 0.3058, Val Acc: 0.8999
Epoch 75/100, Loss: 0.5311, Acc: 0.7138, Val Loss: 0.3067, Val Acc: 0.8992
Epoch 76/100, Loss: 0.5311, Acc: 0.7124, Val Loss: 0.3061, Val Acc: 0.8988
Epoch 77/100, Loss: 0.5311, Acc: 0.7130, Val Loss: 0.3061, Val Acc: 0.8992
Epoch 78/100, Loss: 0.5311, Acc: 0.7139, Val Loss: 0.3067, Val Acc: 0.8992
Epoch 79/100, Loss: 0.5311, Acc: 0.7138, Val Loss: 0.3066, Val Acc: 0.8999
Epoch 80/100, Loss: 0.5310, Acc: 0.7139, Val Loss: 0.3056, Val Acc: 0.9007
Epoch 81/100, Loss: 0.5310, Acc: 0.7120, Val Loss: 0.3065, Val Acc: 0.9007
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5310, Acc: 0.7142, Val Loss: 0.3069, Val Acc: 0.8988
Epoch 83/100, Loss: 0.5310, Acc: 0.7125, Val Loss: 0.3072, Val Acc: 0.8988
Epoch 84/100, Loss: 0.5309, Acc: 0.7133, Val Loss: 0.3059, Val Acc: 0.8999
Epoch 85/100, Loss: 0.5310, Acc: 0.7144, Val Loss: 0.3064, Val Acc: 0.8985
Epoch 86/100, Loss: 0.5309, Acc: 0.7137, Val Loss: 0.3059, Val Acc: 0.8988
Epoch 87/100, Loss: 0.5309, Acc: 0.7135, Val Loss: 0.3042, Val Acc: 0.9007
Epoch 88/100, Loss: 0.5310, Acc: 0.7141, Val Loss: 0.3059, Val Acc: 0.8999
Epoch 89/100, Loss: 0.5310, Acc: 0.7142, Val Loss: 0.3074, Val Acc: 0.8988
Epoch 90/100, Loss: 0.5309, Acc: 0.7131, Val Loss: 0.3070, Val Acc: 0.8992
Epoch 91/100, Loss: 0.5310, Acc: 0.7135, Val Loss: 0.3080, Val Acc: 0.8981
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5309, Acc: 0.7142, Val Loss: 0.3064, Val Acc: 0.8992
Epoch 93/100, Loss: 0.5308, Acc: 0.7137, Val Loss: 0.3070, Val Acc: 0.8996
Epoch 94/100, Loss: 0.5308, Acc: 0.7131, Val Loss: 0.3068, Val Acc: 0.8988
Epoch 95/100, Loss: 0.5308, Acc: 0.7127, Val Loss: 0.3071, Val Acc: 0.8981
Epoch 96/100, Loss: 0.5307, Acc: 0.7152, Val Loss: 0.3051, Val Acc: 0.8988
Epoch 97/100, Loss: 0.5308, Acc: 0.7126, Val Loss: 0.3064, Val Acc: 0.9003
Epoch 98/100, Loss: 0.5307, Acc: 0.7147, Val Loss: 0.3075, Val Acc: 0.8985
Epoch 99/100, Loss: 0.5307, Acc: 0.7135, Val Loss: 0.3058, Val Acc: 0.8996
Epoch 100/100, Loss: 0.5307, Acc: 0.7142, Val Loss: 0.3068, Val Acc: 0.8985

##############################
Resultados para principal:  059  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3 
 {'training': [0.5307207613071113, 0.714193785622357, 0.7024161307144099, 0.7431040823832291, 0.7221874720757752], 'validate': [0.30682102954664897, 0.8984547461368654, 0.9515859766277128, 0.8394698085419735, 0.892018779342723], 'test': [0.5202615901275918, 0.7363154796939376, 0.6985148514851485, 0.8309776207302709, 0.7590102205486821]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  121  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  121  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  121  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5036, Acc: 0.8407, Val Loss: 0.6178, Val Acc: 0.6781
Mejor modelo guardado con Val Loss: 0.6178
Epoch 2/100, Loss: 0.3476, Acc: 0.8798, Val Loss: 0.5650, Val Acc: 0.7241
Mejor modelo guardado con Val Loss: 0.5650
Epoch 3/100, Loss: 0.3186, Acc: 0.8775, Val Loss: 0.6556, Val Acc: 0.6755
Epoch 4/100, Loss: 0.3006, Acc: 0.8825, Val Loss: 0.6389, Val Acc: 0.6814
Epoch 5/100, Loss: 0.2946, Acc: 0.8834, Val Loss: 0.8285, Val Acc: 0.6115
Epoch 6/100, Loss: 0.2916, Acc: 0.8858, Val Loss: 0.6920, Val Acc: 0.6718
Epoch 7/100, Loss: 0.2863, Acc: 0.8855, Val Loss: 0.7868, Val Acc: 0.6608
Epoch 8/100, Loss: 0.2848, Acc: 0.8852, Val Loss: 0.6403, Val Acc: 0.7057
Epoch 9/100, Loss: 0.2845, Acc: 0.8848, Val Loss: 0.7186, Val Acc: 0.6508
Epoch 10/100, Loss: 0.2851, Acc: 0.8855, Val Loss: 0.6031, Val Acc: 0.7174
Epoch 11/100, Loss: 0.2882, Acc: 0.8849, Val Loss: 0.6746, Val Acc: 0.7013
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2751, Acc: 0.8910, Val Loss: 0.7568, Val Acc: 0.6244
Epoch 13/100, Loss: 0.2747, Acc: 0.8892, Val Loss: 0.7036, Val Acc: 0.6751
Epoch 14/100, Loss: 0.2736, Acc: 0.8881, Val Loss: 0.7645, Val Acc: 0.6678
Epoch 15/100, Loss: 0.2730, Acc: 0.8903, Val Loss: 0.8206, Val Acc: 0.6118
Epoch 16/100, Loss: 0.2720, Acc: 0.8919, Val Loss: 0.7265, Val Acc: 0.6413
Epoch 17/100, Loss: 0.2715, Acc: 0.8900, Val Loss: 0.6799, Val Acc: 0.6611
Epoch 18/100, Loss: 0.2696, Acc: 0.8915, Val Loss: 0.7422, Val Acc: 0.6549
Epoch 19/100, Loss: 0.2709, Acc: 0.8912, Val Loss: 0.6621, Val Acc: 0.7035
Epoch 20/100, Loss: 0.2698, Acc: 0.8901, Val Loss: 0.7309, Val Acc: 0.6932
Epoch 21/100, Loss: 0.2727, Acc: 0.8893, Val Loss: 0.8653, Val Acc: 0.6468
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2669, Acc: 0.8924, Val Loss: 0.7387, Val Acc: 0.6711
Epoch 23/100, Loss: 0.2642, Acc: 0.8928, Val Loss: 0.6874, Val Acc: 0.6615
Epoch 24/100, Loss: 0.2646, Acc: 0.8922, Val Loss: 0.7636, Val Acc: 0.6387
Epoch 25/100, Loss: 0.2637, Acc: 0.8942, Val Loss: 0.6974, Val Acc: 0.6748
Epoch 26/100, Loss: 0.2646, Acc: 0.8937, Val Loss: 0.7332, Val Acc: 0.6501
Epoch 27/100, Loss: 0.2622, Acc: 0.8929, Val Loss: 0.7077, Val Acc: 0.6825
Epoch 28/100, Loss: 0.2640, Acc: 0.8928, Val Loss: 0.7150, Val Acc: 0.6696
Epoch 29/100, Loss: 0.2610, Acc: 0.8941, Val Loss: 0.6899, Val Acc: 0.6766
Epoch 30/100, Loss: 0.2616, Acc: 0.8929, Val Loss: 0.7508, Val Acc: 0.6582
Epoch 31/100, Loss: 0.2603, Acc: 0.8924, Val Loss: 0.6796, Val Acc: 0.6994
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2600, Acc: 0.8935, Val Loss: 0.7154, Val Acc: 0.6737
Epoch 33/100, Loss: 0.2596, Acc: 0.8921, Val Loss: 0.7097, Val Acc: 0.6737
Epoch 34/100, Loss: 0.2584, Acc: 0.8924, Val Loss: 0.7189, Val Acc: 0.6733
Epoch 35/100, Loss: 0.2586, Acc: 0.8942, Val Loss: 0.7615, Val Acc: 0.6439
Epoch 36/100, Loss: 0.2586, Acc: 0.8942, Val Loss: 0.7583, Val Acc: 0.6670
Epoch 37/100, Loss: 0.2574, Acc: 0.8941, Val Loss: 0.6917, Val Acc: 0.6829
Epoch 38/100, Loss: 0.2571, Acc: 0.8940, Val Loss: 0.7285, Val Acc: 0.6542
Epoch 39/100, Loss: 0.2569, Acc: 0.8954, Val Loss: 0.6678, Val Acc: 0.6788
Epoch 40/100, Loss: 0.2568, Acc: 0.8956, Val Loss: 0.7695, Val Acc: 0.6512
Epoch 41/100, Loss: 0.2563, Acc: 0.8950, Val Loss: 0.7337, Val Acc: 0.6737
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2545, Acc: 0.8967, Val Loss: 0.7175, Val Acc: 0.6703
Epoch 43/100, Loss: 0.2535, Acc: 0.8969, Val Loss: 0.6773, Val Acc: 0.6932
Epoch 44/100, Loss: 0.2542, Acc: 0.8951, Val Loss: 0.7353, Val Acc: 0.6637
Epoch 45/100, Loss: 0.2535, Acc: 0.8971, Val Loss: 0.7318, Val Acc: 0.6714
Epoch 46/100, Loss: 0.2540, Acc: 0.8969, Val Loss: 0.7011, Val Acc: 0.6729
Epoch 47/100, Loss: 0.2539, Acc: 0.8957, Val Loss: 0.7416, Val Acc: 0.6645
Epoch 48/100, Loss: 0.2536, Acc: 0.8962, Val Loss: 0.7247, Val Acc: 0.6663
Epoch 49/100, Loss: 0.2536, Acc: 0.8969, Val Loss: 0.7131, Val Acc: 0.6722
Epoch 50/100, Loss: 0.2534, Acc: 0.8968, Val Loss: 0.7201, Val Acc: 0.6600
Epoch 51/100, Loss: 0.2535, Acc: 0.8956, Val Loss: 0.7466, Val Acc: 0.6542
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2524, Acc: 0.8964, Val Loss: 0.7280, Val Acc: 0.6670
Epoch 53/100, Loss: 0.2524, Acc: 0.8971, Val Loss: 0.7103, Val Acc: 0.6748
Epoch 54/100, Loss: 0.2522, Acc: 0.8973, Val Loss: 0.7087, Val Acc: 0.6711
Epoch 55/100, Loss: 0.2525, Acc: 0.8950, Val Loss: 0.7127, Val Acc: 0.6637
Epoch 56/100, Loss: 0.2521, Acc: 0.8970, Val Loss: 0.7329, Val Acc: 0.6641
Epoch 57/100, Loss: 0.2524, Acc: 0.8976, Val Loss: 0.7103, Val Acc: 0.6722
Epoch 58/100, Loss: 0.2522, Acc: 0.8966, Val Loss: 0.7333, Val Acc: 0.6564
Epoch 59/100, Loss: 0.2523, Acc: 0.8965, Val Loss: 0.7155, Val Acc: 0.6729
Epoch 60/100, Loss: 0.2522, Acc: 0.8968, Val Loss: 0.6991, Val Acc: 0.6795
Epoch 61/100, Loss: 0.2523, Acc: 0.8968, Val Loss: 0.7170, Val Acc: 0.6711
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2515, Acc: 0.8974, Val Loss: 0.7316, Val Acc: 0.6634
Epoch 63/100, Loss: 0.2516, Acc: 0.8969, Val Loss: 0.7223, Val Acc: 0.6692
Epoch 64/100, Loss: 0.2516, Acc: 0.8977, Val Loss: 0.7125, Val Acc: 0.6696
Epoch 65/100, Loss: 0.2515, Acc: 0.8975, Val Loss: 0.7149, Val Acc: 0.6707
Epoch 66/100, Loss: 0.2515, Acc: 0.8973, Val Loss: 0.7234, Val Acc: 0.6670
Epoch 67/100, Loss: 0.2514, Acc: 0.8968, Val Loss: 0.7159, Val Acc: 0.6714
Epoch 68/100, Loss: 0.2514, Acc: 0.8963, Val Loss: 0.7206, Val Acc: 0.6692
Epoch 69/100, Loss: 0.2513, Acc: 0.8975, Val Loss: 0.7188, Val Acc: 0.6711
Epoch 70/100, Loss: 0.2513, Acc: 0.8975, Val Loss: 0.7050, Val Acc: 0.6759
Epoch 71/100, Loss: 0.2514, Acc: 0.8973, Val Loss: 0.7125, Val Acc: 0.6729
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2511, Acc: 0.8970, Val Loss: 0.7168, Val Acc: 0.6722
Epoch 73/100, Loss: 0.2511, Acc: 0.8978, Val Loss: 0.7236, Val Acc: 0.6685
Epoch 74/100, Loss: 0.2511, Acc: 0.8971, Val Loss: 0.7285, Val Acc: 0.6626
Epoch 75/100, Loss: 0.2510, Acc: 0.8967, Val Loss: 0.7144, Val Acc: 0.6711
Epoch 76/100, Loss: 0.2511, Acc: 0.8978, Val Loss: 0.7240, Val Acc: 0.6656
Epoch 77/100, Loss: 0.2511, Acc: 0.8970, Val Loss: 0.7249, Val Acc: 0.6652
Epoch 78/100, Loss: 0.2510, Acc: 0.8974, Val Loss: 0.7214, Val Acc: 0.6681
Epoch 79/100, Loss: 0.2510, Acc: 0.8974, Val Loss: 0.7121, Val Acc: 0.6726
Epoch 80/100, Loss: 0.2510, Acc: 0.8977, Val Loss: 0.7139, Val Acc: 0.6729
Epoch 81/100, Loss: 0.2509, Acc: 0.8984, Val Loss: 0.7181, Val Acc: 0.6700
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2509, Acc: 0.8969, Val Loss: 0.7213, Val Acc: 0.6689
Epoch 83/100, Loss: 0.2508, Acc: 0.8972, Val Loss: 0.7186, Val Acc: 0.6700
Epoch 84/100, Loss: 0.2508, Acc: 0.8976, Val Loss: 0.7187, Val Acc: 0.6711
Epoch 85/100, Loss: 0.2507, Acc: 0.8971, Val Loss: 0.7304, Val Acc: 0.6645
Epoch 86/100, Loss: 0.2508, Acc: 0.8975, Val Loss: 0.7174, Val Acc: 0.6700
Epoch 87/100, Loss: 0.2508, Acc: 0.8975, Val Loss: 0.7139, Val Acc: 0.6722
Epoch 88/100, Loss: 0.2508, Acc: 0.8971, Val Loss: 0.7197, Val Acc: 0.6700
Epoch 89/100, Loss: 0.2507, Acc: 0.8970, Val Loss: 0.7136, Val Acc: 0.6718
Epoch 90/100, Loss: 0.2506, Acc: 0.8974, Val Loss: 0.7165, Val Acc: 0.6711
Epoch 91/100, Loss: 0.2506, Acc: 0.8972, Val Loss: 0.7091, Val Acc: 0.6733
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2507, Acc: 0.8968, Val Loss: 0.7147, Val Acc: 0.6707
Epoch 93/100, Loss: 0.2506, Acc: 0.8970, Val Loss: 0.7253, Val Acc: 0.6641
Epoch 94/100, Loss: 0.2506, Acc: 0.8966, Val Loss: 0.7142, Val Acc: 0.6711
Epoch 95/100, Loss: 0.2507, Acc: 0.8972, Val Loss: 0.7169, Val Acc: 0.6703
Epoch 96/100, Loss: 0.2506, Acc: 0.8972, Val Loss: 0.7143, Val Acc: 0.6703
Epoch 97/100, Loss: 0.2505, Acc: 0.8976, Val Loss: 0.7244, Val Acc: 0.6659
Epoch 98/100, Loss: 0.2505, Acc: 0.8973, Val Loss: 0.7186, Val Acc: 0.6703
Epoch 99/100, Loss: 0.2505, Acc: 0.8973, Val Loss: 0.7229, Val Acc: 0.6674
Epoch 100/100, Loss: 0.2505, Acc: 0.8978, Val Loss: 0.7214, Val Acc: 0.6692

##############################
Resultados para principal:  121  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3 
 {'training': [0.25049595978904854, 0.8977753263467549, 0.8828318584070797, 0.9172489885987496, 0.8997113997113997], 'validate': [0.721382975968164, 0.6692420897718911, 0.6136701337295691, 0.9123711340206185, 0.7337873852531833], 'test': [0.47095197604762185, 0.77781047675103, 0.8327452364149612, 0.6949352179034158, 0.7576243980738363]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  107  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  107  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  107  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4599, Acc: 0.8372, Val Loss: 1.0981, Val Acc: 0.4448
Mejor modelo guardado con Val Loss: 1.0981
Epoch 2/100, Loss: 0.3433, Acc: 0.8680, Val Loss: 1.2879, Val Acc: 0.4205
Epoch 3/100, Loss: 0.3153, Acc: 0.8759, Val Loss: 1.3301, Val Acc: 0.4507
Epoch 4/100, Loss: 0.3115, Acc: 0.8771, Val Loss: 1.3218, Val Acc: 0.4246
Epoch 5/100, Loss: 0.3107, Acc: 0.8771, Val Loss: 1.2676, Val Acc: 0.4525
Epoch 6/100, Loss: 0.3095, Acc: 0.8760, Val Loss: 1.3086, Val Acc: 0.4213
Epoch 7/100, Loss: 0.3017, Acc: 0.8794, Val Loss: 1.2767, Val Acc: 0.4139
Epoch 8/100, Loss: 0.3101, Acc: 0.8723, Val Loss: 1.3328, Val Acc: 0.4481
Epoch 9/100, Loss: 0.2995, Acc: 0.8800, Val Loss: 1.3489, Val Acc: 0.4790
Epoch 10/100, Loss: 0.3010, Acc: 0.8796, Val Loss: 1.3630, Val Acc: 0.4308
Epoch 11/100, Loss: 0.3054, Acc: 0.8776, Val Loss: 1.3761, Val Acc: 0.4695
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2903, Acc: 0.8854, Val Loss: 1.2897, Val Acc: 0.4540
Epoch 13/100, Loss: 0.2904, Acc: 0.8804, Val Loss: 1.3688, Val Acc: 0.4691
Epoch 14/100, Loss: 0.2918, Acc: 0.8786, Val Loss: 1.4365, Val Acc: 0.4540
Epoch 15/100, Loss: 0.2914, Acc: 0.8829, Val Loss: 1.3327, Val Acc: 0.4444
Epoch 16/100, Loss: 0.2881, Acc: 0.8826, Val Loss: 1.2667, Val Acc: 0.4514
Epoch 17/100, Loss: 0.2883, Acc: 0.8828, Val Loss: 1.4031, Val Acc: 0.4735
Epoch 18/100, Loss: 0.2861, Acc: 0.8857, Val Loss: 1.4590, Val Acc: 0.4547
Epoch 19/100, Loss: 0.2861, Acc: 0.8844, Val Loss: 1.3431, Val Acc: 0.4603
Epoch 20/100, Loss: 0.2899, Acc: 0.8804, Val Loss: 1.4024, Val Acc: 0.4301
Epoch 21/100, Loss: 0.2898, Acc: 0.8843, Val Loss: 1.4930, Val Acc: 0.4673
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2833, Acc: 0.8867, Val Loss: 1.4628, Val Acc: 0.4463
Epoch 23/100, Loss: 0.2803, Acc: 0.8875, Val Loss: 1.4692, Val Acc: 0.4823
Epoch 24/100, Loss: 0.2809, Acc: 0.8867, Val Loss: 1.3412, Val Acc: 0.4753
Epoch 25/100, Loss: 0.2788, Acc: 0.8870, Val Loss: 1.3882, Val Acc: 0.4632
Epoch 26/100, Loss: 0.2781, Acc: 0.8870, Val Loss: 1.4050, Val Acc: 0.4746
Epoch 27/100, Loss: 0.2791, Acc: 0.8863, Val Loss: 1.3985, Val Acc: 0.4621
Epoch 28/100, Loss: 0.2762, Acc: 0.8891, Val Loss: 1.3795, Val Acc: 0.4662
Epoch 29/100, Loss: 0.2769, Acc: 0.8876, Val Loss: 1.3971, Val Acc: 0.4558
Epoch 30/100, Loss: 0.2779, Acc: 0.8878, Val Loss: 1.4020, Val Acc: 0.4573
Epoch 31/100, Loss: 0.2756, Acc: 0.8904, Val Loss: 1.3762, Val Acc: 0.4662
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2730, Acc: 0.8892, Val Loss: 1.4454, Val Acc: 0.4522
Epoch 33/100, Loss: 0.2730, Acc: 0.8899, Val Loss: 1.4442, Val Acc: 0.4636
Epoch 34/100, Loss: 0.2731, Acc: 0.8888, Val Loss: 1.5073, Val Acc: 0.4610
Epoch 35/100, Loss: 0.2728, Acc: 0.8893, Val Loss: 1.5007, Val Acc: 0.4577
Epoch 36/100, Loss: 0.2735, Acc: 0.8882, Val Loss: 1.4990, Val Acc: 0.4522
Epoch 37/100, Loss: 0.2725, Acc: 0.8887, Val Loss: 1.4435, Val Acc: 0.4650
Epoch 38/100, Loss: 0.2737, Acc: 0.8882, Val Loss: 1.4567, Val Acc: 0.4628
Epoch 39/100, Loss: 0.2736, Acc: 0.8876, Val Loss: 1.4179, Val Acc: 0.4628
Epoch 40/100, Loss: 0.2715, Acc: 0.8906, Val Loss: 1.3949, Val Acc: 0.4617
Epoch 41/100, Loss: 0.2716, Acc: 0.8906, Val Loss: 1.4424, Val Acc: 0.4639
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2706, Acc: 0.8903, Val Loss: 1.4323, Val Acc: 0.4592
Epoch 43/100, Loss: 0.2698, Acc: 0.8910, Val Loss: 1.4208, Val Acc: 0.4647
Epoch 44/100, Loss: 0.2701, Acc: 0.8907, Val Loss: 1.4297, Val Acc: 0.4614
Epoch 45/100, Loss: 0.2702, Acc: 0.8897, Val Loss: 1.4596, Val Acc: 0.4632
Epoch 46/100, Loss: 0.2692, Acc: 0.8902, Val Loss: 1.4299, Val Acc: 0.4625
Epoch 47/100, Loss: 0.2695, Acc: 0.8916, Val Loss: 1.4559, Val Acc: 0.4654
Epoch 48/100, Loss: 0.2696, Acc: 0.8909, Val Loss: 1.4720, Val Acc: 0.4584
Epoch 49/100, Loss: 0.2688, Acc: 0.8893, Val Loss: 1.4418, Val Acc: 0.4573
Epoch 50/100, Loss: 0.2690, Acc: 0.8894, Val Loss: 1.4679, Val Acc: 0.4628
Epoch 51/100, Loss: 0.2689, Acc: 0.8917, Val Loss: 1.4698, Val Acc: 0.4614
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2681, Acc: 0.8910, Val Loss: 1.4669, Val Acc: 0.4632
Epoch 53/100, Loss: 0.2678, Acc: 0.8912, Val Loss: 1.4521, Val Acc: 0.4584
Epoch 54/100, Loss: 0.2681, Acc: 0.8914, Val Loss: 1.4556, Val Acc: 0.4588
Epoch 55/100, Loss: 0.2677, Acc: 0.8913, Val Loss: 1.4612, Val Acc: 0.4643
Epoch 56/100, Loss: 0.2677, Acc: 0.8916, Val Loss: 1.4550, Val Acc: 0.4632
Epoch 57/100, Loss: 0.2676, Acc: 0.8905, Val Loss: 1.4628, Val Acc: 0.4614
Epoch 58/100, Loss: 0.2675, Acc: 0.8897, Val Loss: 1.4595, Val Acc: 0.4584
Epoch 59/100, Loss: 0.2675, Acc: 0.8914, Val Loss: 1.4718, Val Acc: 0.4584
Epoch 60/100, Loss: 0.2675, Acc: 0.8908, Val Loss: 1.4696, Val Acc: 0.4562
Epoch 61/100, Loss: 0.2672, Acc: 0.8915, Val Loss: 1.4702, Val Acc: 0.4566
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2671, Acc: 0.8916, Val Loss: 1.4581, Val Acc: 0.4599
Epoch 63/100, Loss: 0.2668, Acc: 0.8911, Val Loss: 1.4669, Val Acc: 0.4599
Epoch 64/100, Loss: 0.2668, Acc: 0.8921, Val Loss: 1.4664, Val Acc: 0.4592
Epoch 65/100, Loss: 0.2667, Acc: 0.8922, Val Loss: 1.4652, Val Acc: 0.4595
Epoch 66/100, Loss: 0.2667, Acc: 0.8916, Val Loss: 1.4746, Val Acc: 0.4614
Epoch 67/100, Loss: 0.2668, Acc: 0.8910, Val Loss: 1.4573, Val Acc: 0.4577
Epoch 68/100, Loss: 0.2666, Acc: 0.8908, Val Loss: 1.4684, Val Acc: 0.4588
Epoch 69/100, Loss: 0.2666, Acc: 0.8916, Val Loss: 1.4693, Val Acc: 0.4610
Epoch 70/100, Loss: 0.2664, Acc: 0.8911, Val Loss: 1.4753, Val Acc: 0.4566
Epoch 71/100, Loss: 0.2667, Acc: 0.8912, Val Loss: 1.4676, Val Acc: 0.4599
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2664, Acc: 0.8912, Val Loss: 1.4651, Val Acc: 0.4584
Epoch 73/100, Loss: 0.2663, Acc: 0.8911, Val Loss: 1.4718, Val Acc: 0.4595
Epoch 74/100, Loss: 0.2663, Acc: 0.8910, Val Loss: 1.4732, Val Acc: 0.4588
Epoch 75/100, Loss: 0.2663, Acc: 0.8912, Val Loss: 1.4688, Val Acc: 0.4592
Epoch 76/100, Loss: 0.2663, Acc: 0.8910, Val Loss: 1.4681, Val Acc: 0.4588
Epoch 77/100, Loss: 0.2662, Acc: 0.8915, Val Loss: 1.4722, Val Acc: 0.4603
Epoch 78/100, Loss: 0.2662, Acc: 0.8906, Val Loss: 1.4712, Val Acc: 0.4588
Epoch 79/100, Loss: 0.2662, Acc: 0.8910, Val Loss: 1.4705, Val Acc: 0.4595
Epoch 80/100, Loss: 0.2661, Acc: 0.8916, Val Loss: 1.4706, Val Acc: 0.4606
Epoch 81/100, Loss: 0.2662, Acc: 0.8917, Val Loss: 1.4728, Val Acc: 0.4584
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2661, Acc: 0.8911, Val Loss: 1.4685, Val Acc: 0.4588
Epoch 83/100, Loss: 0.2661, Acc: 0.8917, Val Loss: 1.4712, Val Acc: 0.4636
Epoch 84/100, Loss: 0.2662, Acc: 0.8912, Val Loss: 1.4737, Val Acc: 0.4599
Epoch 85/100, Loss: 0.2662, Acc: 0.8910, Val Loss: 1.4671, Val Acc: 0.4581
Epoch 86/100, Loss: 0.2661, Acc: 0.8914, Val Loss: 1.4695, Val Acc: 0.4584
Epoch 87/100, Loss: 0.2661, Acc: 0.8910, Val Loss: 1.4721, Val Acc: 0.4588
Epoch 88/100, Loss: 0.2661, Acc: 0.8914, Val Loss: 1.4698, Val Acc: 0.4588
Epoch 89/100, Loss: 0.2660, Acc: 0.8914, Val Loss: 1.4695, Val Acc: 0.4588
Epoch 90/100, Loss: 0.2659, Acc: 0.8917, Val Loss: 1.4659, Val Acc: 0.4628
Epoch 91/100, Loss: 0.2660, Acc: 0.8909, Val Loss: 1.4694, Val Acc: 0.4588
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2659, Acc: 0.8910, Val Loss: 1.4778, Val Acc: 0.4643
Epoch 93/100, Loss: 0.2661, Acc: 0.8915, Val Loss: 1.4722, Val Acc: 0.4588
Epoch 94/100, Loss: 0.2659, Acc: 0.8914, Val Loss: 1.4750, Val Acc: 0.4595
Epoch 95/100, Loss: 0.2660, Acc: 0.8907, Val Loss: 1.4737, Val Acc: 0.4603
Epoch 96/100, Loss: 0.2659, Acc: 0.8912, Val Loss: 1.4713, Val Acc: 0.4577
Epoch 97/100, Loss: 0.2658, Acc: 0.8907, Val Loss: 1.4681, Val Acc: 0.4581
Epoch 98/100, Loss: 0.2658, Acc: 0.8909, Val Loss: 1.4732, Val Acc: 0.4592
Epoch 99/100, Loss: 0.2658, Acc: 0.8909, Val Loss: 1.4693, Val Acc: 0.4588
Epoch 100/100, Loss: 0.2657, Acc: 0.8918, Val Loss: 1.4748, Val Acc: 0.4592

##############################
Resultados para principal:  107  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3 
 {'training': [0.26572731843567177, 0.8917999632285346, 0.8667584782234464, 0.925891872011769, 0.8953498710767316], 'validate': [1.4747851380082064, 0.45916114790286977, 0.4765886287625418, 0.8394698085419735, 0.608], 'test': [0.4349747921029727, 0.8113596233078282, 0.7480056311590803, 0.9387514723203769, 0.8325933664142073]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  086  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  086  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  086  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6458, Acc: 0.6476, Val Loss: 0.8246, Val Acc: 0.3013
Mejor modelo guardado con Val Loss: 0.8246
Epoch 2/100, Loss: 0.6141, Acc: 0.6723, Val Loss: 0.8634, Val Acc: 0.3344
Epoch 3/100, Loss: 0.6000, Acc: 0.6828, Val Loss: 0.8888, Val Acc: 0.3631
Epoch 4/100, Loss: 0.5863, Acc: 0.6965, Val Loss: 0.8814, Val Acc: 0.3639
Epoch 5/100, Loss: 0.5803, Acc: 0.7007, Val Loss: 0.9143, Val Acc: 0.3234
Epoch 6/100, Loss: 0.5690, Acc: 0.7090, Val Loss: 0.9036, Val Acc: 0.3322
Epoch 7/100, Loss: 0.5649, Acc: 0.7096, Val Loss: 0.8595, Val Acc: 0.3959
Epoch 8/100, Loss: 0.5681, Acc: 0.7118, Val Loss: 0.8240, Val Acc: 0.3635
Mejor modelo guardado con Val Loss: 0.8240
Epoch 9/100, Loss: 0.5764, Acc: 0.7118, Val Loss: 0.9623, Val Acc: 0.3212
Epoch 10/100, Loss: 0.5606, Acc: 0.7192, Val Loss: 0.8881, Val Acc: 0.3366
Epoch 11/100, Loss: 0.5592, Acc: 0.7158, Val Loss: 0.9410, Val Acc: 0.3815
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5499, Acc: 0.7225, Val Loss: 0.9569, Val Acc: 0.3628
Epoch 13/100, Loss: 0.5492, Acc: 0.7227, Val Loss: 0.9650, Val Acc: 0.3624
Epoch 14/100, Loss: 0.5483, Acc: 0.7265, Val Loss: 0.9703, Val Acc: 0.3569
Epoch 15/100, Loss: 0.5469, Acc: 0.7247, Val Loss: 0.9987, Val Acc: 0.3451
Epoch 16/100, Loss: 0.5469, Acc: 0.7260, Val Loss: 0.9994, Val Acc: 0.3440
Epoch 17/100, Loss: 0.5462, Acc: 0.7240, Val Loss: 1.0031, Val Acc: 0.3606
Epoch 18/100, Loss: 0.5444, Acc: 0.7276, Val Loss: 0.9514, Val Acc: 0.3650
Epoch 19/100, Loss: 0.5449, Acc: 0.7275, Val Loss: 0.9891, Val Acc: 0.3745
Epoch 20/100, Loss: 0.5452, Acc: 0.7290, Val Loss: 0.9672, Val Acc: 0.3668
Epoch 21/100, Loss: 0.5422, Acc: 0.7280, Val Loss: 0.9687, Val Acc: 0.3745
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5386, Acc: 0.7271, Val Loss: 0.9873, Val Acc: 0.3771
Epoch 23/100, Loss: 0.5383, Acc: 0.7272, Val Loss: 0.9529, Val Acc: 0.3756
Epoch 24/100, Loss: 0.5377, Acc: 0.7260, Val Loss: 0.9664, Val Acc: 0.3830
Epoch 25/100, Loss: 0.5381, Acc: 0.7287, Val Loss: 0.9351, Val Acc: 0.3738
Epoch 26/100, Loss: 0.5385, Acc: 0.7293, Val Loss: 0.9461, Val Acc: 0.3698
Epoch 27/100, Loss: 0.5368, Acc: 0.7284, Val Loss: 0.9137, Val Acc: 0.4073
Epoch 28/100, Loss: 0.5367, Acc: 0.7292, Val Loss: 0.9013, Val Acc: 0.3679
Epoch 29/100, Loss: 0.5362, Acc: 0.7274, Val Loss: 0.9657, Val Acc: 0.3760
Epoch 30/100, Loss: 0.5359, Acc: 0.7279, Val Loss: 0.9711, Val Acc: 0.3716
Epoch 31/100, Loss: 0.5364, Acc: 0.7318, Val Loss: 0.9398, Val Acc: 0.3882
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5334, Acc: 0.7310, Val Loss: 0.9851, Val Acc: 0.3701
Epoch 33/100, Loss: 0.5341, Acc: 0.7319, Val Loss: 0.9362, Val Acc: 0.3727
Epoch 34/100, Loss: 0.5333, Acc: 0.7310, Val Loss: 0.9678, Val Acc: 0.3683
Epoch 35/100, Loss: 0.5329, Acc: 0.7325, Val Loss: 0.9266, Val Acc: 0.3893
Epoch 36/100, Loss: 0.5327, Acc: 0.7315, Val Loss: 0.9621, Val Acc: 0.3731
Epoch 37/100, Loss: 0.5326, Acc: 0.7308, Val Loss: 0.9690, Val Acc: 0.3668
Epoch 38/100, Loss: 0.5321, Acc: 0.7321, Val Loss: 0.9956, Val Acc: 0.3716
Epoch 39/100, Loss: 0.5331, Acc: 0.7332, Val Loss: 0.9383, Val Acc: 0.3690
Epoch 40/100, Loss: 0.5321, Acc: 0.7297, Val Loss: 0.9329, Val Acc: 0.3712
Epoch 41/100, Loss: 0.5327, Acc: 0.7336, Val Loss: 0.9403, Val Acc: 0.3775
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5309, Acc: 0.7338, Val Loss: 0.9353, Val Acc: 0.3859
Epoch 43/100, Loss: 0.5306, Acc: 0.7305, Val Loss: 0.9485, Val Acc: 0.3705
Epoch 44/100, Loss: 0.5309, Acc: 0.7317, Val Loss: 0.9523, Val Acc: 0.3720
Epoch 45/100, Loss: 0.5311, Acc: 0.7294, Val Loss: 0.9417, Val Acc: 0.3727
Epoch 46/100, Loss: 0.5304, Acc: 0.7325, Val Loss: 0.9389, Val Acc: 0.3830
Epoch 47/100, Loss: 0.5304, Acc: 0.7334, Val Loss: 0.9356, Val Acc: 0.3742
Epoch 48/100, Loss: 0.5306, Acc: 0.7319, Val Loss: 0.9536, Val Acc: 0.3723
Epoch 49/100, Loss: 0.5307, Acc: 0.7333, Val Loss: 0.9515, Val Acc: 0.3749
Epoch 50/100, Loss: 0.5307, Acc: 0.7326, Val Loss: 0.9393, Val Acc: 0.3848
Epoch 51/100, Loss: 0.5306, Acc: 0.7319, Val Loss: 0.9484, Val Acc: 0.3731
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5296, Acc: 0.7319, Val Loss: 0.9357, Val Acc: 0.3808
Epoch 53/100, Loss: 0.5295, Acc: 0.7307, Val Loss: 0.9493, Val Acc: 0.3760
Epoch 54/100, Loss: 0.5294, Acc: 0.7350, Val Loss: 0.9561, Val Acc: 0.3720
Epoch 55/100, Loss: 0.5292, Acc: 0.7330, Val Loss: 0.9592, Val Acc: 0.3738
Epoch 56/100, Loss: 0.5294, Acc: 0.7323, Val Loss: 0.9394, Val Acc: 0.3779
Epoch 57/100, Loss: 0.5294, Acc: 0.7320, Val Loss: 0.9473, Val Acc: 0.3767
Epoch 58/100, Loss: 0.5294, Acc: 0.7321, Val Loss: 0.9510, Val Acc: 0.3782
Epoch 59/100, Loss: 0.5292, Acc: 0.7327, Val Loss: 0.9451, Val Acc: 0.3756
Epoch 60/100, Loss: 0.5291, Acc: 0.7321, Val Loss: 0.9525, Val Acc: 0.3767
Epoch 61/100, Loss: 0.5289, Acc: 0.7341, Val Loss: 0.9405, Val Acc: 0.3775
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5288, Acc: 0.7326, Val Loss: 0.9461, Val Acc: 0.3764
Epoch 63/100, Loss: 0.5287, Acc: 0.7326, Val Loss: 0.9471, Val Acc: 0.3779
Epoch 64/100, Loss: 0.5287, Acc: 0.7333, Val Loss: 0.9475, Val Acc: 0.3745
Epoch 65/100, Loss: 0.5286, Acc: 0.7329, Val Loss: 0.9516, Val Acc: 0.3760
Epoch 66/100, Loss: 0.5285, Acc: 0.7334, Val Loss: 0.9543, Val Acc: 0.3775
Epoch 67/100, Loss: 0.5286, Acc: 0.7331, Val Loss: 0.9551, Val Acc: 0.3756
Epoch 68/100, Loss: 0.5284, Acc: 0.7325, Val Loss: 0.9483, Val Acc: 0.3782
Epoch 69/100, Loss: 0.5285, Acc: 0.7344, Val Loss: 0.9567, Val Acc: 0.3742
Epoch 70/100, Loss: 0.5285, Acc: 0.7337, Val Loss: 0.9510, Val Acc: 0.3771
Epoch 71/100, Loss: 0.5281, Acc: 0.7329, Val Loss: 0.9380, Val Acc: 0.3823
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5273, Acc: 0.7344, Val Loss: 0.9344, Val Acc: 0.3786
Epoch 73/100, Loss: 0.5271, Acc: 0.7340, Val Loss: 0.9353, Val Acc: 0.3808
Epoch 74/100, Loss: 0.5270, Acc: 0.7352, Val Loss: 0.9328, Val Acc: 0.3804
Epoch 75/100, Loss: 0.5270, Acc: 0.7338, Val Loss: 0.9331, Val Acc: 0.3808
Epoch 76/100, Loss: 0.5271, Acc: 0.7352, Val Loss: 0.9341, Val Acc: 0.3808
Epoch 77/100, Loss: 0.5270, Acc: 0.7339, Val Loss: 0.9325, Val Acc: 0.3804
Epoch 78/100, Loss: 0.5270, Acc: 0.7360, Val Loss: 0.9340, Val Acc: 0.3808
Epoch 79/100, Loss: 0.5270, Acc: 0.7341, Val Loss: 0.9313, Val Acc: 0.3830
Epoch 80/100, Loss: 0.5269, Acc: 0.7349, Val Loss: 0.9319, Val Acc: 0.3808
Epoch 81/100, Loss: 0.5269, Acc: 0.7352, Val Loss: 0.9310, Val Acc: 0.3815
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5269, Acc: 0.7346, Val Loss: 0.9338, Val Acc: 0.3808
Epoch 83/100, Loss: 0.5268, Acc: 0.7344, Val Loss: 0.9329, Val Acc: 0.3834
Epoch 84/100, Loss: 0.5269, Acc: 0.7360, Val Loss: 0.9333, Val Acc: 0.3808
Epoch 85/100, Loss: 0.5268, Acc: 0.7341, Val Loss: 0.9331, Val Acc: 0.3812
Epoch 86/100, Loss: 0.5268, Acc: 0.7352, Val Loss: 0.9329, Val Acc: 0.3830
Epoch 87/100, Loss: 0.5267, Acc: 0.7360, Val Loss: 0.9365, Val Acc: 0.3797
Epoch 88/100, Loss: 0.5267, Acc: 0.7335, Val Loss: 0.9333, Val Acc: 0.3812
Epoch 89/100, Loss: 0.5266, Acc: 0.7353, Val Loss: 0.9324, Val Acc: 0.3830
Epoch 90/100, Loss: 0.5267, Acc: 0.7333, Val Loss: 0.9309, Val Acc: 0.3823
Epoch 91/100, Loss: 0.5266, Acc: 0.7340, Val Loss: 0.9326, Val Acc: 0.3815
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5268, Acc: 0.7349, Val Loss: 0.9319, Val Acc: 0.3834
Epoch 93/100, Loss: 0.5267, Acc: 0.7348, Val Loss: 0.9283, Val Acc: 0.3845
Epoch 94/100, Loss: 0.5265, Acc: 0.7334, Val Loss: 0.9306, Val Acc: 0.3826
Epoch 95/100, Loss: 0.5265, Acc: 0.7355, Val Loss: 0.9311, Val Acc: 0.3834
Epoch 96/100, Loss: 0.5266, Acc: 0.7363, Val Loss: 0.9316, Val Acc: 0.3826
Epoch 97/100, Loss: 0.5266, Acc: 0.7345, Val Loss: 0.9331, Val Acc: 0.3823
Epoch 98/100, Loss: 0.5265, Acc: 0.7353, Val Loss: 0.9320, Val Acc: 0.3826
Epoch 99/100, Loss: 0.5265, Acc: 0.7329, Val Loss: 0.9301, Val Acc: 0.3837
Epoch 100/100, Loss: 0.5265, Acc: 0.7344, Val Loss: 0.9301, Val Acc: 0.3826

##############################
Resultados para principal:  086  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  3 
 {'training': [0.5264985320497511, 0.7344180915609487, 0.717157948543193, 0.7739977933063626, 0.7444945608914831], 'validate': [0.9300895485767099, 0.3826342899190581, 0.41778006166495374, 0.5986745213549337, 0.49213075060532685], 'test': [0.7633702103738431, 0.424072984108299, 0.45024971187091817, 0.690223792697291, 0.544989537316903]}

##############################
Resultados para window:  3 
 {'098:025:059:121:107:086': {'training': [0.5725622290108743, 0.6799963228534657, 0.6218403685717844, 0.9183523354174329, 0.741554681119608], 'validate': [0.37163500791025716, 0.9105960264900662, 0.9358874120406567, 0.8814432989690721, 0.9078498293515358], 'test': [0.6273113875477402, 0.6297822248381401, 0.5823353293413174, 0.9163722025912838, 0.7121281464530892]}, '025:098:059:121:107:086': {'training': [0.584505236834852, 0.6665747380033095, 0.6151303242212333, 0.889665318131666, 0.7273547320153348], 'validate': [0.41211369321789854, 0.8646063281824872, 0.9064039408866995, 0.812960235640648, 0.8571428571428571], 'test': [0.627940332448041, 0.6527369040612124, 0.6049432739059968, 0.8792697290930507, 0.7167546807489198]}, '059:098:025:121:107:086': {'training': [0.5307207613071113, 0.714193785622357, 0.7024161307144099, 0.7431040823832291, 0.7221874720757752], 'validate': [0.30682102954664897, 0.8984547461368654, 0.9515859766277128, 0.8394698085419735, 0.892018779342723], 'test': [0.5202615901275918, 0.7363154796939376, 0.6985148514851485, 0.8309776207302709, 0.7590102205486821]}, '121:098:025:059:107:086': {'training': [0.25049595978904854, 0.8977753263467549, 0.8828318584070797, 0.9172489885987496, 0.8997113997113997], 'validate': [0.721382975968164, 0.6692420897718911, 0.6136701337295691, 0.9123711340206185, 0.7337873852531833], 'test': [0.47095197604762185, 0.77781047675103, 0.8327452364149612, 0.6949352179034158, 0.7576243980738363]}, '107:098:025:059:121:086': {'training': [0.26572731843567177, 0.8917999632285346, 0.8667584782234464, 0.925891872011769, 0.8953498710767316], 'validate': [1.4747851380082064, 0.45916114790286977, 0.4765886287625418, 0.8394698085419735, 0.608], 'test': [0.4349747921029727, 0.8113596233078282, 0.7480056311590803, 0.9387514723203769, 0.8325933664142073]}, '086:098:025:059:121:107': {'training': [0.5264985320497511, 0.7344180915609487, 0.717157948543193, 0.7739977933063626, 0.7444945608914831], 'validate': [0.9300895485767099, 0.3826342899190581, 0.41778006166495374, 0.5986745213549337, 0.49213075060532685], 'test': [0.7633702103738431, 0.424072984108299, 0.45024971187091817, 0.690223792697291, 0.544989537316903]}}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  031  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  031  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  031  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6915, Acc: 0.5249, Val Loss: 0.6926, Val Acc: 0.4982
Mejor modelo guardado con Val Loss: 0.6926
Epoch 2/100, Loss: 0.6927, Acc: 0.5165, Val Loss: 0.6927, Val Acc: 0.5004
Epoch 3/100, Loss: 0.6934, Acc: 0.5038, Val Loss: 0.6934, Val Acc: 0.4996
Epoch 4/100, Loss: 0.6933, Acc: 0.4957, Val Loss: 0.6935, Val Acc: 0.4996
Epoch 5/100, Loss: 0.6933, Acc: 0.5023, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 6/100, Loss: 0.6935, Acc: 0.4922, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 7/100, Loss: 0.6932, Acc: 0.4970, Val Loss: 0.6934, Val Acc: 0.4996
Epoch 8/100, Loss: 0.6935, Acc: 0.4943, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 9/100, Loss: 0.6926, Acc: 0.5142, Val Loss: 0.6935, Val Acc: 0.5004
Epoch 10/100, Loss: 0.6936, Acc: 0.5006, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 11/100, Loss: 0.6933, Acc: 0.4948, Val Loss: 0.6931, Val Acc: 0.5004
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4880, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 13/100, Loss: 0.6934, Acc: 0.4907, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 14/100, Loss: 0.6932, Acc: 0.5014, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 15/100, Loss: 0.6934, Acc: 0.4915, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 16/100, Loss: 0.6932, Acc: 0.5030, Val Loss: 0.6935, Val Acc: 0.4996
Epoch 17/100, Loss: 0.6933, Acc: 0.4990, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 18/100, Loss: 0.6932, Acc: 0.5027, Val Loss: 0.6937, Val Acc: 0.4996
Epoch 19/100, Loss: 0.6932, Acc: 0.5034, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 20/100, Loss: 0.6933, Acc: 0.4938, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 21/100, Loss: 0.6933, Acc: 0.4883, Val Loss: 0.6932, Val Acc: 0.4996
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4942, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 23/100, Loss: 0.6933, Acc: 0.4924, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 24/100, Loss: 0.6932, Acc: 0.4909, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 25/100, Loss: 0.6932, Acc: 0.4970, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 26/100, Loss: 0.6932, Acc: 0.4933, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 27/100, Loss: 0.6932, Acc: 0.4875, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 28/100, Loss: 0.6932, Acc: 0.4953, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 29/100, Loss: 0.6932, Acc: 0.4959, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 30/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 31/100, Loss: 0.6932, Acc: 0.4940, Val Loss: 0.6931, Val Acc: 0.5007
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4965, Val Loss: 0.6931, Val Acc: 0.5059
Epoch 33/100, Loss: 0.6932, Acc: 0.4999, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 34/100, Loss: 0.6932, Acc: 0.4935, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 35/100, Loss: 0.6932, Acc: 0.4905, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 36/100, Loss: 0.6932, Acc: 0.4977, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 37/100, Loss: 0.6932, Acc: 0.4979, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 38/100, Loss: 0.6932, Acc: 0.4913, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 39/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 40/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 41/100, Loss: 0.6932, Acc: 0.4972, Val Loss: 0.6931, Val Acc: 0.5026
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6931, Val Acc: 0.5033
Epoch 43/100, Loss: 0.6932, Acc: 0.4909, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 44/100, Loss: 0.6932, Acc: 0.4927, Val Loss: 0.6931, Val Acc: 0.5059
Epoch 45/100, Loss: 0.6932, Acc: 0.4922, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 46/100, Loss: 0.6932, Acc: 0.4907, Val Loss: 0.6931, Val Acc: 0.5383
Epoch 47/100, Loss: 0.6932, Acc: 0.4955, Val Loss: 0.6931, Val Acc: 0.5029
Epoch 48/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 49/100, Loss: 0.6932, Acc: 0.4927, Val Loss: 0.6931, Val Acc: 0.5118
Epoch 50/100, Loss: 0.6932, Acc: 0.4972, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 51/100, Loss: 0.6932, Acc: 0.4883, Val Loss: 0.6931, Val Acc: 0.5004
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6932, Acc: 0.4977, Val Loss: 0.6931, Val Acc: 0.5247
Epoch 53/100, Loss: 0.6932, Acc: 0.4962, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 54/100, Loss: 0.6932, Acc: 0.4968, Val Loss: 0.6931, Val Acc: 0.5728
Epoch 55/100, Loss: 0.6931, Acc: 0.4969, Val Loss: 0.6930, Val Acc: 0.5191
Epoch 56/100, Loss: 0.6931, Acc: 0.4989, Val Loss: 0.6927, Val Acc: 0.5224
Epoch 57/100, Loss: 0.6931, Acc: 0.5000, Val Loss: 0.6927, Val Acc: 0.5806
Epoch 58/100, Loss: 0.6931, Acc: 0.5022, Val Loss: 0.6926, Val Acc: 0.5879
Epoch 59/100, Loss: 0.6931, Acc: 0.5056, Val Loss: 0.6926, Val Acc: 0.5857
Mejor modelo guardado con Val Loss: 0.6926
Epoch 60/100, Loss: 0.6931, Acc: 0.4994, Val Loss: 0.6926, Val Acc: 0.5854
Mejor modelo guardado con Val Loss: 0.6926
Epoch 61/100, Loss: 0.6931, Acc: 0.5009, Val Loss: 0.6926, Val Acc: 0.5721
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6931, Acc: 0.5091, Val Loss: 0.6926, Val Acc: 0.5706
Epoch 63/100, Loss: 0.6931, Acc: 0.5073, Val Loss: 0.6926, Val Acc: 0.5854
Mejor modelo guardado con Val Loss: 0.6926
Epoch 64/100, Loss: 0.6931, Acc: 0.5069, Val Loss: 0.6926, Val Acc: 0.5751
Epoch 65/100, Loss: 0.6931, Acc: 0.5088, Val Loss: 0.6926, Val Acc: 0.5695
Epoch 66/100, Loss: 0.6931, Acc: 0.5099, Val Loss: 0.6926, Val Acc: 0.5673
Epoch 67/100, Loss: 0.6931, Acc: 0.5092, Val Loss: 0.6926, Val Acc: 0.5695
Mejor modelo guardado con Val Loss: 0.6926
Epoch 68/100, Loss: 0.6931, Acc: 0.5080, Val Loss: 0.6926, Val Acc: 0.5688
Mejor modelo guardado con Val Loss: 0.6926
Epoch 69/100, Loss: 0.6931, Acc: 0.5108, Val Loss: 0.6925, Val Acc: 0.5714
Mejor modelo guardado con Val Loss: 0.6925
Epoch 70/100, Loss: 0.6931, Acc: 0.5089, Val Loss: 0.6925, Val Acc: 0.5706
Mejor modelo guardado con Val Loss: 0.6925
Epoch 71/100, Loss: 0.6931, Acc: 0.5106, Val Loss: 0.6925, Val Acc: 0.5666
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6931, Acc: 0.5099, Val Loss: 0.6925, Val Acc: 0.5688
Mejor modelo guardado con Val Loss: 0.6925
Epoch 73/100, Loss: 0.6930, Acc: 0.5114, Val Loss: 0.6925, Val Acc: 0.5728
Mejor modelo guardado con Val Loss: 0.6925
Epoch 74/100, Loss: 0.6930, Acc: 0.5114, Val Loss: 0.6925, Val Acc: 0.5692
Mejor modelo guardado con Val Loss: 0.6925
Epoch 75/100, Loss: 0.6930, Acc: 0.5116, Val Loss: 0.6925, Val Acc: 0.5677
Mejor modelo guardado con Val Loss: 0.6925
Epoch 76/100, Loss: 0.6930, Acc: 0.5127, Val Loss: 0.6925, Val Acc: 0.5692
Mejor modelo guardado con Val Loss: 0.6925
Epoch 77/100, Loss: 0.6930, Acc: 0.5132, Val Loss: 0.6925, Val Acc: 0.5644
Mejor modelo guardado con Val Loss: 0.6925
Epoch 78/100, Loss: 0.6930, Acc: 0.5108, Val Loss: 0.6925, Val Acc: 0.5662
Mejor modelo guardado con Val Loss: 0.6925
Epoch 79/100, Loss: 0.6930, Acc: 0.5122, Val Loss: 0.6925, Val Acc: 0.5666
Mejor modelo guardado con Val Loss: 0.6925
Epoch 80/100, Loss: 0.6930, Acc: 0.5106, Val Loss: 0.6924, Val Acc: 0.5699
Mejor modelo guardado con Val Loss: 0.6924
Epoch 81/100, Loss: 0.6930, Acc: 0.5115, Val Loss: 0.6925, Val Acc: 0.5677
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6930, Acc: 0.5131, Val Loss: 0.6924, Val Acc: 0.5644
Mejor modelo guardado con Val Loss: 0.6924
Epoch 83/100, Loss: 0.6930, Acc: 0.5136, Val Loss: 0.6924, Val Acc: 0.5614
Mejor modelo guardado con Val Loss: 0.6924
Epoch 84/100, Loss: 0.6930, Acc: 0.5126, Val Loss: 0.6925, Val Acc: 0.5618
Epoch 85/100, Loss: 0.6930, Acc: 0.5084, Val Loss: 0.6925, Val Acc: 0.5570
Epoch 86/100, Loss: 0.6930, Acc: 0.5123, Val Loss: 0.6925, Val Acc: 0.5541
Epoch 87/100, Loss: 0.6930, Acc: 0.5083, Val Loss: 0.6925, Val Acc: 0.5567
Epoch 88/100, Loss: 0.6930, Acc: 0.5133, Val Loss: 0.6925, Val Acc: 0.5556
Epoch 89/100, Loss: 0.6930, Acc: 0.5130, Val Loss: 0.6925, Val Acc: 0.5522
Epoch 90/100, Loss: 0.6930, Acc: 0.5121, Val Loss: 0.6925, Val Acc: 0.5515
Epoch 91/100, Loss: 0.6930, Acc: 0.5152, Val Loss: 0.6925, Val Acc: 0.5460
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6930, Acc: 0.5125, Val Loss: 0.6925, Val Acc: 0.5442
Epoch 93/100, Loss: 0.6930, Acc: 0.5168, Val Loss: 0.6925, Val Acc: 0.5442
Epoch 94/100, Loss: 0.6930, Acc: 0.5145, Val Loss: 0.6925, Val Acc: 0.5460
Epoch 95/100, Loss: 0.6929, Acc: 0.5116, Val Loss: 0.6926, Val Acc: 0.5434
Epoch 96/100, Loss: 0.6928, Acc: 0.5205, Val Loss: 0.6933, Val Acc: 0.5217
Epoch 97/100, Loss: 0.6920, Acc: 0.5256, Val Loss: 0.6948, Val Acc: 0.4790
Epoch 98/100, Loss: 0.6917, Acc: 0.5252, Val Loss: 0.6947, Val Acc: 0.4695
Epoch 99/100, Loss: 0.6916, Acc: 0.5286, Val Loss: 0.6947, Val Acc: 0.4599
Epoch 100/100, Loss: 0.6916, Acc: 0.5341, Val Loss: 0.6948, Val Acc: 0.4628

##############################
Resultados para principal:  031  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3 
 {'training': [0.6915885401924955, 0.5341055341055341, 0.5270388775211926, 0.663111438028687, 0.5872964169381107], 'validate': [0.6947970057642737, 0.4628403237674761, 0.47157190635451507, 0.6229749631811488, 0.5368020304568528], 'test': [0.693274974822998, 0.475868157739847, 0.4816777041942605, 0.6425206124852768, 0.5505929851122887]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  051  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  051  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  051  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6716, Acc: 0.6035, Val Loss: 0.6843, Val Acc: 0.5552
Mejor modelo guardado con Val Loss: 0.6843
Epoch 2/100, Loss: 0.6532, Acc: 0.6468, Val Loss: 0.6842, Val Acc: 0.5585
Mejor modelo guardado con Val Loss: 0.6842
Epoch 3/100, Loss: 0.6455, Acc: 0.6494, Val Loss: 0.6961, Val Acc: 0.5361
Epoch 4/100, Loss: 0.6305, Acc: 0.6598, Val Loss: 0.6874, Val Acc: 0.5684
Epoch 5/100, Loss: 0.6211, Acc: 0.6669, Val Loss: 0.6864, Val Acc: 0.5706
Epoch 6/100, Loss: 0.6163, Acc: 0.6726, Val Loss: 0.6943, Val Acc: 0.5592
Epoch 7/100, Loss: 0.6142, Acc: 0.6655, Val Loss: 0.6874, Val Acc: 0.5574
Epoch 8/100, Loss: 0.6102, Acc: 0.6685, Val Loss: 0.7161, Val Acc: 0.5596
Epoch 9/100, Loss: 0.6088, Acc: 0.6673, Val Loss: 0.6891, Val Acc: 0.5614
Epoch 10/100, Loss: 0.6072, Acc: 0.6677, Val Loss: 0.7031, Val Acc: 0.5747
Epoch 11/100, Loss: 0.6064, Acc: 0.6739, Val Loss: 0.6973, Val Acc: 0.5673
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6018, Acc: 0.6797, Val Loss: 0.7025, Val Acc: 0.5618
Epoch 13/100, Loss: 0.6015, Acc: 0.6782, Val Loss: 0.7063, Val Acc: 0.5699
Epoch 14/100, Loss: 0.5979, Acc: 0.6813, Val Loss: 0.7124, Val Acc: 0.5677
Epoch 15/100, Loss: 0.5958, Acc: 0.6796, Val Loss: 0.7125, Val Acc: 0.5725
Epoch 16/100, Loss: 0.5937, Acc: 0.6871, Val Loss: 0.7044, Val Acc: 0.5710
Epoch 17/100, Loss: 0.5931, Acc: 0.6833, Val Loss: 0.7227, Val Acc: 0.5751
Epoch 18/100, Loss: 0.5920, Acc: 0.6827, Val Loss: 0.7142, Val Acc: 0.5721
Epoch 19/100, Loss: 0.5941, Acc: 0.6852, Val Loss: 0.7073, Val Acc: 0.5644
Epoch 20/100, Loss: 0.5903, Acc: 0.6868, Val Loss: 0.7222, Val Acc: 0.5736
Epoch 21/100, Loss: 0.5903, Acc: 0.6863, Val Loss: 0.7125, Val Acc: 0.5574
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5880, Acc: 0.6863, Val Loss: 0.7122, Val Acc: 0.5736
Epoch 23/100, Loss: 0.5860, Acc: 0.6922, Val Loss: 0.7130, Val Acc: 0.5670
Epoch 24/100, Loss: 0.5870, Acc: 0.6906, Val Loss: 0.7267, Val Acc: 0.5765
Epoch 25/100, Loss: 0.5876, Acc: 0.6897, Val Loss: 0.7199, Val Acc: 0.5798
Epoch 26/100, Loss: 0.5869, Acc: 0.6906, Val Loss: 0.7095, Val Acc: 0.5758
Epoch 27/100, Loss: 0.5865, Acc: 0.6903, Val Loss: 0.7071, Val Acc: 0.5548
Epoch 28/100, Loss: 0.5853, Acc: 0.6884, Val Loss: 0.7166, Val Acc: 0.5740
Epoch 29/100, Loss: 0.5856, Acc: 0.6896, Val Loss: 0.7131, Val Acc: 0.5677
Epoch 30/100, Loss: 0.5838, Acc: 0.6931, Val Loss: 0.7242, Val Acc: 0.5725
Epoch 31/100, Loss: 0.5849, Acc: 0.6877, Val Loss: 0.7195, Val Acc: 0.5791
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5836, Acc: 0.6949, Val Loss: 0.7116, Val Acc: 0.5751
Epoch 33/100, Loss: 0.5834, Acc: 0.6930, Val Loss: 0.7144, Val Acc: 0.5806
Epoch 34/100, Loss: 0.5834, Acc: 0.6933, Val Loss: 0.7118, Val Acc: 0.5710
Epoch 35/100, Loss: 0.5841, Acc: 0.6922, Val Loss: 0.7130, Val Acc: 0.5765
Epoch 36/100, Loss: 0.5836, Acc: 0.6927, Val Loss: 0.7107, Val Acc: 0.5758
Epoch 37/100, Loss: 0.5826, Acc: 0.6942, Val Loss: 0.7126, Val Acc: 0.5703
Epoch 38/100, Loss: 0.5830, Acc: 0.6949, Val Loss: 0.7192, Val Acc: 0.5751
Epoch 39/100, Loss: 0.5832, Acc: 0.6946, Val Loss: 0.7206, Val Acc: 0.5751
Epoch 40/100, Loss: 0.5832, Acc: 0.6920, Val Loss: 0.7136, Val Acc: 0.5732
Epoch 41/100, Loss: 0.5822, Acc: 0.6910, Val Loss: 0.7140, Val Acc: 0.5762
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5817, Acc: 0.6938, Val Loss: 0.7208, Val Acc: 0.5809
Epoch 43/100, Loss: 0.5812, Acc: 0.6942, Val Loss: 0.7214, Val Acc: 0.5780
Epoch 44/100, Loss: 0.5811, Acc: 0.6938, Val Loss: 0.7195, Val Acc: 0.5747
Epoch 45/100, Loss: 0.5811, Acc: 0.6951, Val Loss: 0.7194, Val Acc: 0.5809
Epoch 46/100, Loss: 0.5818, Acc: 0.6916, Val Loss: 0.7114, Val Acc: 0.5736
Epoch 47/100, Loss: 0.5811, Acc: 0.6958, Val Loss: 0.7177, Val Acc: 0.5732
Epoch 48/100, Loss: 0.5808, Acc: 0.6952, Val Loss: 0.7150, Val Acc: 0.5773
Epoch 49/100, Loss: 0.5816, Acc: 0.6955, Val Loss: 0.7176, Val Acc: 0.5806
Epoch 50/100, Loss: 0.5809, Acc: 0.6946, Val Loss: 0.7137, Val Acc: 0.5784
Epoch 51/100, Loss: 0.5805, Acc: 0.6935, Val Loss: 0.7125, Val Acc: 0.5758
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5804, Acc: 0.6955, Val Loss: 0.7191, Val Acc: 0.5846
Epoch 53/100, Loss: 0.5804, Acc: 0.6955, Val Loss: 0.7186, Val Acc: 0.5828
Epoch 54/100, Loss: 0.5798, Acc: 0.6945, Val Loss: 0.7189, Val Acc: 0.5780
Epoch 55/100, Loss: 0.5800, Acc: 0.6985, Val Loss: 0.7170, Val Acc: 0.5817
Epoch 56/100, Loss: 0.5798, Acc: 0.6950, Val Loss: 0.7177, Val Acc: 0.5817
Epoch 57/100, Loss: 0.5796, Acc: 0.6962, Val Loss: 0.7191, Val Acc: 0.5820
Epoch 58/100, Loss: 0.5796, Acc: 0.6951, Val Loss: 0.7167, Val Acc: 0.5824
Epoch 59/100, Loss: 0.5795, Acc: 0.6945, Val Loss: 0.7182, Val Acc: 0.5817
Epoch 60/100, Loss: 0.5798, Acc: 0.6958, Val Loss: 0.7171, Val Acc: 0.5784
Epoch 61/100, Loss: 0.5796, Acc: 0.6962, Val Loss: 0.7149, Val Acc: 0.5791
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5794, Acc: 0.6955, Val Loss: 0.7179, Val Acc: 0.5769
Epoch 63/100, Loss: 0.5793, Acc: 0.6966, Val Loss: 0.7168, Val Acc: 0.5813
Epoch 64/100, Loss: 0.5792, Acc: 0.6963, Val Loss: 0.7186, Val Acc: 0.5828
Epoch 65/100, Loss: 0.5791, Acc: 0.6965, Val Loss: 0.7181, Val Acc: 0.5736
Epoch 66/100, Loss: 0.5792, Acc: 0.6962, Val Loss: 0.7181, Val Acc: 0.5765
Epoch 67/100, Loss: 0.5791, Acc: 0.6957, Val Loss: 0.7186, Val Acc: 0.5732
Epoch 68/100, Loss: 0.5791, Acc: 0.6964, Val Loss: 0.7190, Val Acc: 0.5802
Epoch 69/100, Loss: 0.5790, Acc: 0.6954, Val Loss: 0.7193, Val Acc: 0.5795
Epoch 70/100, Loss: 0.5790, Acc: 0.6966, Val Loss: 0.7184, Val Acc: 0.5791
Epoch 71/100, Loss: 0.5790, Acc: 0.6965, Val Loss: 0.7192, Val Acc: 0.5780
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5788, Acc: 0.6979, Val Loss: 0.7184, Val Acc: 0.5798
Epoch 73/100, Loss: 0.5788, Acc: 0.6964, Val Loss: 0.7181, Val Acc: 0.5776
Epoch 74/100, Loss: 0.5788, Acc: 0.6953, Val Loss: 0.7181, Val Acc: 0.5769
Epoch 75/100, Loss: 0.5789, Acc: 0.6978, Val Loss: 0.7178, Val Acc: 0.5732
Epoch 76/100, Loss: 0.5788, Acc: 0.6965, Val Loss: 0.7178, Val Acc: 0.5714
Epoch 77/100, Loss: 0.5788, Acc: 0.6971, Val Loss: 0.7187, Val Acc: 0.5798
Epoch 78/100, Loss: 0.5787, Acc: 0.6959, Val Loss: 0.7183, Val Acc: 0.5773
Epoch 79/100, Loss: 0.5787, Acc: 0.6969, Val Loss: 0.7193, Val Acc: 0.5791
Epoch 80/100, Loss: 0.5787, Acc: 0.6964, Val Loss: 0.7188, Val Acc: 0.5776
Epoch 81/100, Loss: 0.5788, Acc: 0.6966, Val Loss: 0.7184, Val Acc: 0.5795
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5787, Acc: 0.6968, Val Loss: 0.7191, Val Acc: 0.5791
Epoch 83/100, Loss: 0.5787, Acc: 0.6959, Val Loss: 0.7184, Val Acc: 0.5740
Epoch 84/100, Loss: 0.5786, Acc: 0.6976, Val Loss: 0.7188, Val Acc: 0.5784
Epoch 85/100, Loss: 0.5786, Acc: 0.6967, Val Loss: 0.7190, Val Acc: 0.5784
Epoch 86/100, Loss: 0.5786, Acc: 0.6962, Val Loss: 0.7185, Val Acc: 0.5795
Epoch 87/100, Loss: 0.5787, Acc: 0.6970, Val Loss: 0.7186, Val Acc: 0.5791
Epoch 88/100, Loss: 0.5785, Acc: 0.6966, Val Loss: 0.7191, Val Acc: 0.5784
Epoch 89/100, Loss: 0.5786, Acc: 0.6963, Val Loss: 0.7192, Val Acc: 0.5787
Epoch 90/100, Loss: 0.5785, Acc: 0.6955, Val Loss: 0.7182, Val Acc: 0.5728
Epoch 91/100, Loss: 0.5785, Acc: 0.6976, Val Loss: 0.7186, Val Acc: 0.5784
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5785, Acc: 0.6970, Val Loss: 0.7191, Val Acc: 0.5802
Epoch 93/100, Loss: 0.5785, Acc: 0.6968, Val Loss: 0.7195, Val Acc: 0.5773
Epoch 94/100, Loss: 0.5784, Acc: 0.6969, Val Loss: 0.7197, Val Acc: 0.5795
Epoch 95/100, Loss: 0.5783, Acc: 0.6973, Val Loss: 0.7194, Val Acc: 0.5791
Epoch 96/100, Loss: 0.5783, Acc: 0.6969, Val Loss: 0.7200, Val Acc: 0.5802
Epoch 97/100, Loss: 0.5782, Acc: 0.6974, Val Loss: 0.7194, Val Acc: 0.5776
Epoch 98/100, Loss: 0.5783, Acc: 0.6965, Val Loss: 0.7192, Val Acc: 0.5780
Epoch 99/100, Loss: 0.5782, Acc: 0.6964, Val Loss: 0.7182, Val Acc: 0.5769
Epoch 100/100, Loss: 0.5781, Acc: 0.6964, Val Loss: 0.7186, Val Acc: 0.5769

##############################
Resultados para principal:  051  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3 
 {'training': [0.5781422520981354, 0.6963596249310535, 0.7086999022482894, 0.6666053696211842, 0.6870084336207714], 'validate': [0.7185970905215241, 0.5768947755702722, 0.5779610194902549, 0.5677466863033873, 0.5728083209509658], 'test': [0.6239887636016916, 0.6880517951736316, 0.8513215859030837, 0.4552414605418139, 0.5932463545663853]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  096  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  096  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  096  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6901, Acc: 0.5367, Val Loss: 0.6905, Val Acc: 0.6332
Mejor modelo guardado con Val Loss: 0.6905
Epoch 2/100, Loss: 0.6925, Acc: 0.5182, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 3/100, Loss: 0.6931, Acc: 0.5063, Val Loss: 0.6899, Val Acc: 0.4996
Mejor modelo guardado con Val Loss: 0.6899
Epoch 4/100, Loss: 0.6893, Acc: 0.5553, Val Loss: 0.6808, Val Acc: 0.6696
Mejor modelo guardado con Val Loss: 0.6808
Epoch 5/100, Loss: 0.6856, Acc: 0.5807, Val Loss: 0.6865, Val Acc: 0.5511
Epoch 6/100, Loss: 0.6802, Acc: 0.5927, Val Loss: 0.6735, Val Acc: 0.6144
Mejor modelo guardado con Val Loss: 0.6735
Epoch 7/100, Loss: 0.6772, Acc: 0.5996, Val Loss: 0.6676, Val Acc: 0.6273
Mejor modelo guardado con Val Loss: 0.6676
Epoch 8/100, Loss: 0.6738, Acc: 0.6040, Val Loss: 0.6752, Val Acc: 0.5894
Epoch 9/100, Loss: 0.6767, Acc: 0.5909, Val Loss: 0.6617, Val Acc: 0.6358
Mejor modelo guardado con Val Loss: 0.6617
Epoch 10/100, Loss: 0.6708, Acc: 0.6043, Val Loss: 0.6612, Val Acc: 0.6244
Mejor modelo guardado con Val Loss: 0.6612
Epoch 11/100, Loss: 0.6661, Acc: 0.6131, Val Loss: 0.6620, Val Acc: 0.6207
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6635, Acc: 0.6175, Val Loss: 0.6611, Val Acc: 0.6210
Mejor modelo guardado con Val Loss: 0.6611
Epoch 13/100, Loss: 0.6633, Acc: 0.6156, Val Loss: 0.6503, Val Acc: 0.6501
Mejor modelo guardado con Val Loss: 0.6503
Epoch 14/100, Loss: 0.6606, Acc: 0.6214, Val Loss: 0.6462, Val Acc: 0.6505
Mejor modelo guardado con Val Loss: 0.6462
Epoch 15/100, Loss: 0.6611, Acc: 0.6191, Val Loss: 0.6527, Val Acc: 0.6339
Epoch 16/100, Loss: 0.6599, Acc: 0.6203, Val Loss: 0.6617, Val Acc: 0.6163
Epoch 17/100, Loss: 0.6590, Acc: 0.6204, Val Loss: 0.6601, Val Acc: 0.6166
Epoch 18/100, Loss: 0.6594, Acc: 0.6229, Val Loss: 0.6456, Val Acc: 0.6472
Mejor modelo guardado con Val Loss: 0.6456
Epoch 19/100, Loss: 0.6582, Acc: 0.6204, Val Loss: 0.6536, Val Acc: 0.6328
Epoch 20/100, Loss: 0.6619, Acc: 0.6159, Val Loss: 0.6470, Val Acc: 0.6475
Epoch 21/100, Loss: 0.6578, Acc: 0.6232, Val Loss: 0.6711, Val Acc: 0.5960
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6563, Acc: 0.6226, Val Loss: 0.6477, Val Acc: 0.6439
Epoch 23/100, Loss: 0.6551, Acc: 0.6257, Val Loss: 0.6537, Val Acc: 0.6310
Epoch 24/100, Loss: 0.6553, Acc: 0.6279, Val Loss: 0.6470, Val Acc: 0.6450
Epoch 25/100, Loss: 0.6552, Acc: 0.6249, Val Loss: 0.6500, Val Acc: 0.6328
Epoch 26/100, Loss: 0.6551, Acc: 0.6279, Val Loss: 0.6433, Val Acc: 0.6431
Mejor modelo guardado con Val Loss: 0.6433
Epoch 27/100, Loss: 0.6543, Acc: 0.6262, Val Loss: 0.6485, Val Acc: 0.6369
Epoch 28/100, Loss: 0.6549, Acc: 0.6236, Val Loss: 0.6566, Val Acc: 0.6291
Epoch 29/100, Loss: 0.6559, Acc: 0.6233, Val Loss: 0.6553, Val Acc: 0.6291
Epoch 30/100, Loss: 0.6546, Acc: 0.6261, Val Loss: 0.6437, Val Acc: 0.6431
Epoch 31/100, Loss: 0.6537, Acc: 0.6282, Val Loss: 0.6454, Val Acc: 0.6453
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6531, Acc: 0.6312, Val Loss: 0.6503, Val Acc: 0.6317
Epoch 33/100, Loss: 0.6531, Acc: 0.6309, Val Loss: 0.6463, Val Acc: 0.6446
Epoch 34/100, Loss: 0.6531, Acc: 0.6293, Val Loss: 0.6572, Val Acc: 0.6247
Epoch 35/100, Loss: 0.6528, Acc: 0.6281, Val Loss: 0.6553, Val Acc: 0.6291
Epoch 36/100, Loss: 0.6534, Acc: 0.6262, Val Loss: 0.6495, Val Acc: 0.6347
Epoch 37/100, Loss: 0.6529, Acc: 0.6293, Val Loss: 0.6436, Val Acc: 0.6413
Epoch 38/100, Loss: 0.6526, Acc: 0.6306, Val Loss: 0.6452, Val Acc: 0.6453
Epoch 39/100, Loss: 0.6528, Acc: 0.6315, Val Loss: 0.6434, Val Acc: 0.6420
Epoch 40/100, Loss: 0.6528, Acc: 0.6280, Val Loss: 0.6452, Val Acc: 0.6446
Epoch 41/100, Loss: 0.6525, Acc: 0.6325, Val Loss: 0.6481, Val Acc: 0.6376
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6521, Acc: 0.6304, Val Loss: 0.6449, Val Acc: 0.6450
Epoch 43/100, Loss: 0.6524, Acc: 0.6287, Val Loss: 0.6454, Val Acc: 0.6457
Epoch 44/100, Loss: 0.6519, Acc: 0.6298, Val Loss: 0.6465, Val Acc: 0.6409
Epoch 45/100, Loss: 0.6519, Acc: 0.6294, Val Loss: 0.6449, Val Acc: 0.6442
Epoch 46/100, Loss: 0.6521, Acc: 0.6299, Val Loss: 0.6453, Val Acc: 0.6439
Epoch 47/100, Loss: 0.6521, Acc: 0.6284, Val Loss: 0.6483, Val Acc: 0.6372
Epoch 48/100, Loss: 0.6517, Acc: 0.6316, Val Loss: 0.6512, Val Acc: 0.6336
Epoch 49/100, Loss: 0.6516, Acc: 0.6322, Val Loss: 0.6492, Val Acc: 0.6321
Epoch 50/100, Loss: 0.6515, Acc: 0.6316, Val Loss: 0.6457, Val Acc: 0.6428
Epoch 51/100, Loss: 0.6515, Acc: 0.6302, Val Loss: 0.6505, Val Acc: 0.6343
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6515, Acc: 0.6330, Val Loss: 0.6464, Val Acc: 0.6387
Epoch 53/100, Loss: 0.6514, Acc: 0.6317, Val Loss: 0.6451, Val Acc: 0.6435
Epoch 54/100, Loss: 0.6513, Acc: 0.6299, Val Loss: 0.6465, Val Acc: 0.6383
Epoch 55/100, Loss: 0.6512, Acc: 0.6326, Val Loss: 0.6455, Val Acc: 0.6435
Epoch 56/100, Loss: 0.6511, Acc: 0.6342, Val Loss: 0.6444, Val Acc: 0.6435
Epoch 57/100, Loss: 0.6515, Acc: 0.6304, Val Loss: 0.6464, Val Acc: 0.6387
Epoch 58/100, Loss: 0.6512, Acc: 0.6313, Val Loss: 0.6472, Val Acc: 0.6376
Epoch 59/100, Loss: 0.6512, Acc: 0.6330, Val Loss: 0.6429, Val Acc: 0.6479
Mejor modelo guardado con Val Loss: 0.6429
Epoch 60/100, Loss: 0.6512, Acc: 0.6314, Val Loss: 0.6484, Val Acc: 0.6354
Epoch 61/100, Loss: 0.6512, Acc: 0.6326, Val Loss: 0.6458, Val Acc: 0.6435
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6509, Acc: 0.6325, Val Loss: 0.6478, Val Acc: 0.6387
Epoch 63/100, Loss: 0.6510, Acc: 0.6341, Val Loss: 0.6464, Val Acc: 0.6398
Epoch 64/100, Loss: 0.6510, Acc: 0.6325, Val Loss: 0.6451, Val Acc: 0.6446
Epoch 65/100, Loss: 0.6511, Acc: 0.6309, Val Loss: 0.6456, Val Acc: 0.6424
Epoch 66/100, Loss: 0.6511, Acc: 0.6336, Val Loss: 0.6455, Val Acc: 0.6428
Epoch 67/100, Loss: 0.6508, Acc: 0.6323, Val Loss: 0.6476, Val Acc: 0.6380
Epoch 68/100, Loss: 0.6510, Acc: 0.6322, Val Loss: 0.6463, Val Acc: 0.6402
Epoch 69/100, Loss: 0.6509, Acc: 0.6326, Val Loss: 0.6461, Val Acc: 0.6420
Epoch 70/100, Loss: 0.6510, Acc: 0.6328, Val Loss: 0.6459, Val Acc: 0.6428
Epoch 71/100, Loss: 0.6509, Acc: 0.6319, Val Loss: 0.6474, Val Acc: 0.6383
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6509, Acc: 0.6327, Val Loss: 0.6467, Val Acc: 0.6383
Epoch 73/100, Loss: 0.6508, Acc: 0.6331, Val Loss: 0.6454, Val Acc: 0.6424
Epoch 74/100, Loss: 0.6508, Acc: 0.6314, Val Loss: 0.6458, Val Acc: 0.6435
Epoch 75/100, Loss: 0.6508, Acc: 0.6321, Val Loss: 0.6461, Val Acc: 0.6416
Epoch 76/100, Loss: 0.6508, Acc: 0.6318, Val Loss: 0.6459, Val Acc: 0.6424
Epoch 77/100, Loss: 0.6508, Acc: 0.6316, Val Loss: 0.6468, Val Acc: 0.6372
Epoch 78/100, Loss: 0.6508, Acc: 0.6317, Val Loss: 0.6461, Val Acc: 0.6416
Epoch 79/100, Loss: 0.6508, Acc: 0.6326, Val Loss: 0.6467, Val Acc: 0.6376
Epoch 80/100, Loss: 0.6508, Acc: 0.6324, Val Loss: 0.6466, Val Acc: 0.6376
Epoch 81/100, Loss: 0.6508, Acc: 0.6320, Val Loss: 0.6470, Val Acc: 0.6372
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6508, Acc: 0.6327, Val Loss: 0.6463, Val Acc: 0.6405
Epoch 83/100, Loss: 0.6508, Acc: 0.6315, Val Loss: 0.6458, Val Acc: 0.6428
Epoch 84/100, Loss: 0.6508, Acc: 0.6317, Val Loss: 0.6461, Val Acc: 0.6416
Epoch 85/100, Loss: 0.6508, Acc: 0.6319, Val Loss: 0.6465, Val Acc: 0.6383
Epoch 86/100, Loss: 0.6507, Acc: 0.6322, Val Loss: 0.6468, Val Acc: 0.6372
Epoch 87/100, Loss: 0.6508, Acc: 0.6314, Val Loss: 0.6463, Val Acc: 0.6402
Epoch 88/100, Loss: 0.6507, Acc: 0.6328, Val Loss: 0.6459, Val Acc: 0.6424
Epoch 89/100, Loss: 0.6507, Acc: 0.6319, Val Loss: 0.6466, Val Acc: 0.6376
Epoch 90/100, Loss: 0.6507, Acc: 0.6316, Val Loss: 0.6459, Val Acc: 0.6420
Epoch 91/100, Loss: 0.6507, Acc: 0.6327, Val Loss: 0.6462, Val Acc: 0.6409
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6507, Acc: 0.6329, Val Loss: 0.6462, Val Acc: 0.6409
Epoch 93/100, Loss: 0.6506, Acc: 0.6321, Val Loss: 0.6465, Val Acc: 0.6398
Epoch 94/100, Loss: 0.6501, Acc: 0.6336, Val Loss: 0.6472, Val Acc: 0.6398
Epoch 95/100, Loss: 0.6499, Acc: 0.6321, Val Loss: 0.6470, Val Acc: 0.6405
Epoch 96/100, Loss: 0.6499, Acc: 0.6328, Val Loss: 0.6466, Val Acc: 0.6405
Epoch 97/100, Loss: 0.6498, Acc: 0.6325, Val Loss: 0.6475, Val Acc: 0.6394
Epoch 98/100, Loss: 0.6499, Acc: 0.6315, Val Loss: 0.6475, Val Acc: 0.6398
Epoch 99/100, Loss: 0.6498, Acc: 0.6339, Val Loss: 0.6478, Val Acc: 0.6387
Epoch 100/100, Loss: 0.6498, Acc: 0.6330, Val Loss: 0.6470, Val Acc: 0.6402

##############################
Resultados para principal:  096  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3 
 {'training': [0.6498272485933797, 0.6330207758779187, 0.6227921195652174, 0.6743287973519676, 0.6475366413561716], 'validate': [0.6470436675604, 0.6401766004415012, 0.6669595782073814, 0.5589101620029455, 0.6081730769230769], 'test': [0.6684881995121638, 0.5994702766333138, 0.5923287671232876, 0.6366313309776207, 0.613681521430599]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  034  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  034  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  034  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6931, Acc: 0.4981, Val Loss: 0.6932, Val Acc: 0.4996
Mejor modelo guardado con Val Loss: 0.6932
Epoch 2/100, Loss: 0.6932, Acc: 0.5015, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 3/100, Loss: 0.6931, Acc: 0.5054, Val Loss: 0.6934, Val Acc: 0.4923
Epoch 4/100, Loss: 0.6927, Acc: 0.5086, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 5/100, Loss: 0.6934, Acc: 0.4915, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 6/100, Loss: 0.6933, Acc: 0.5008, Val Loss: 0.6940, Val Acc: 0.4996
Epoch 7/100, Loss: 0.6934, Acc: 0.4922, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 8/100, Loss: 0.6932, Acc: 0.5026, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 9/100, Loss: 0.6934, Acc: 0.5011, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 10/100, Loss: 0.6933, Acc: 0.4977, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 11/100, Loss: 0.6933, Acc: 0.4953, Val Loss: 0.6936, Val Acc: 0.4996
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.5005, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 13/100, Loss: 0.6933, Acc: 0.5019, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 14/100, Loss: 0.6933, Acc: 0.4990, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 15/100, Loss: 0.6933, Acc: 0.4988, Val Loss: 0.6931, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6931
Epoch 16/100, Loss: 0.6932, Acc: 0.5024, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 17/100, Loss: 0.6933, Acc: 0.4974, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 18/100, Loss: 0.6933, Acc: 0.4920, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 19/100, Loss: 0.6933, Acc: 0.4911, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 20/100, Loss: 0.6934, Acc: 0.4909, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 21/100, Loss: 0.6933, Acc: 0.4918, Val Loss: 0.6932, Val Acc: 0.4996
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4965, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 23/100, Loss: 0.6932, Acc: 0.4930, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 24/100, Loss: 0.6932, Acc: 0.5012, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 25/100, Loss: 0.6932, Acc: 0.4999, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 26/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 27/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 28/100, Loss: 0.6932, Acc: 0.5036, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 29/100, Loss: 0.6933, Acc: 0.4970, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 30/100, Loss: 0.6932, Acc: 0.4962, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 31/100, Loss: 0.6933, Acc: 0.4955, Val Loss: 0.6931, Val Acc: 0.5004
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4968, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 33/100, Loss: 0.6932, Acc: 0.4985, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 34/100, Loss: 0.6932, Acc: 0.5001, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 35/100, Loss: 0.6932, Acc: 0.4972, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 36/100, Loss: 0.6932, Acc: 0.4942, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 37/100, Loss: 0.6932, Acc: 0.4991, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 38/100, Loss: 0.6932, Acc: 0.4970, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 39/100, Loss: 0.6932, Acc: 0.4968, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 40/100, Loss: 0.6931, Acc: 0.4990, Val Loss: 0.6933, Val Acc: 0.4912
Epoch 41/100, Loss: 0.6927, Acc: 0.5161, Val Loss: 0.6950, Val Acc: 0.4007
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6924, Acc: 0.5341, Val Loss: 0.6951, Val Acc: 0.4025
Epoch 43/100, Loss: 0.6923, Acc: 0.5389, Val Loss: 0.6954, Val Acc: 0.4113
Epoch 44/100, Loss: 0.6922, Acc: 0.5373, Val Loss: 0.6949, Val Acc: 0.4283
Epoch 45/100, Loss: 0.6922, Acc: 0.5401, Val Loss: 0.6953, Val Acc: 0.4180
Epoch 46/100, Loss: 0.6920, Acc: 0.5409, Val Loss: 0.6959, Val Acc: 0.4110
Epoch 47/100, Loss: 0.6919, Acc: 0.5407, Val Loss: 0.6949, Val Acc: 0.4393
Epoch 48/100, Loss: 0.6919, Acc: 0.5427, Val Loss: 0.6958, Val Acc: 0.4095
Epoch 49/100, Loss: 0.6918, Acc: 0.5413, Val Loss: 0.6957, Val Acc: 0.4253
Epoch 50/100, Loss: 0.6917, Acc: 0.5446, Val Loss: 0.6965, Val Acc: 0.4161
Epoch 51/100, Loss: 0.6915, Acc: 0.5438, Val Loss: 0.6985, Val Acc: 0.4128
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6908, Acc: 0.5443, Val Loss: 0.6989, Val Acc: 0.4128
Epoch 53/100, Loss: 0.6906, Acc: 0.5420, Val Loss: 0.6997, Val Acc: 0.4110
Epoch 54/100, Loss: 0.6905, Acc: 0.5456, Val Loss: 0.7003, Val Acc: 0.4135
Epoch 55/100, Loss: 0.6904, Acc: 0.5494, Val Loss: 0.7003, Val Acc: 0.4143
Epoch 56/100, Loss: 0.6902, Acc: 0.5480, Val Loss: 0.7007, Val Acc: 0.4183
Epoch 57/100, Loss: 0.6902, Acc: 0.5461, Val Loss: 0.7007, Val Acc: 0.4117
Epoch 58/100, Loss: 0.6901, Acc: 0.5459, Val Loss: 0.7005, Val Acc: 0.4150
Epoch 59/100, Loss: 0.6899, Acc: 0.5484, Val Loss: 0.7005, Val Acc: 0.4084
Epoch 60/100, Loss: 0.6899, Acc: 0.5460, Val Loss: 0.7009, Val Acc: 0.4117
Epoch 61/100, Loss: 0.6897, Acc: 0.5478, Val Loss: 0.7012, Val Acc: 0.4121
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6896, Acc: 0.5456, Val Loss: 0.7015, Val Acc: 0.4073
Epoch 63/100, Loss: 0.6895, Acc: 0.5504, Val Loss: 0.7015, Val Acc: 0.4069
Epoch 64/100, Loss: 0.6895, Acc: 0.5487, Val Loss: 0.7016, Val Acc: 0.4113
Epoch 65/100, Loss: 0.6894, Acc: 0.5524, Val Loss: 0.7018, Val Acc: 0.4062
Epoch 66/100, Loss: 0.6894, Acc: 0.5472, Val Loss: 0.7019, Val Acc: 0.4073
Epoch 67/100, Loss: 0.6893, Acc: 0.5511, Val Loss: 0.7020, Val Acc: 0.4124
Epoch 68/100, Loss: 0.6893, Acc: 0.5515, Val Loss: 0.7019, Val Acc: 0.4099
Epoch 69/100, Loss: 0.6892, Acc: 0.5492, Val Loss: 0.7019, Val Acc: 0.4117
Epoch 70/100, Loss: 0.6892, Acc: 0.5516, Val Loss: 0.7023, Val Acc: 0.4150
Epoch 71/100, Loss: 0.6891, Acc: 0.5514, Val Loss: 0.7024, Val Acc: 0.4073
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6890, Acc: 0.5523, Val Loss: 0.7025, Val Acc: 0.4080
Epoch 73/100, Loss: 0.6890, Acc: 0.5514, Val Loss: 0.7025, Val Acc: 0.4110
Epoch 74/100, Loss: 0.6890, Acc: 0.5492, Val Loss: 0.7025, Val Acc: 0.4117
Epoch 75/100, Loss: 0.6889, Acc: 0.5530, Val Loss: 0.7026, Val Acc: 0.4132
Epoch 76/100, Loss: 0.6889, Acc: 0.5538, Val Loss: 0.7027, Val Acc: 0.4080
Epoch 77/100, Loss: 0.6888, Acc: 0.5557, Val Loss: 0.7027, Val Acc: 0.4054
Epoch 78/100, Loss: 0.6888, Acc: 0.5540, Val Loss: 0.7028, Val Acc: 0.4080
Epoch 79/100, Loss: 0.6888, Acc: 0.5532, Val Loss: 0.7026, Val Acc: 0.4091
Epoch 80/100, Loss: 0.6888, Acc: 0.5525, Val Loss: 0.7028, Val Acc: 0.4106
Epoch 81/100, Loss: 0.6887, Acc: 0.5532, Val Loss: 0.7029, Val Acc: 0.4088
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6887, Acc: 0.5533, Val Loss: 0.7031, Val Acc: 0.4095
Epoch 83/100, Loss: 0.6887, Acc: 0.5533, Val Loss: 0.7032, Val Acc: 0.4091
Epoch 84/100, Loss: 0.6886, Acc: 0.5526, Val Loss: 0.7031, Val Acc: 0.4069
Epoch 85/100, Loss: 0.6886, Acc: 0.5550, Val Loss: 0.7033, Val Acc: 0.4091
Epoch 86/100, Loss: 0.6885, Acc: 0.5552, Val Loss: 0.7034, Val Acc: 0.4084
Epoch 87/100, Loss: 0.6885, Acc: 0.5541, Val Loss: 0.7036, Val Acc: 0.4113
Epoch 88/100, Loss: 0.6884, Acc: 0.5563, Val Loss: 0.7036, Val Acc: 0.4077
Epoch 89/100, Loss: 0.6884, Acc: 0.5538, Val Loss: 0.7036, Val Acc: 0.4065
Epoch 90/100, Loss: 0.6884, Acc: 0.5557, Val Loss: 0.7036, Val Acc: 0.4099
Epoch 91/100, Loss: 0.6883, Acc: 0.5558, Val Loss: 0.7036, Val Acc: 0.4069
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6883, Acc: 0.5559, Val Loss: 0.7038, Val Acc: 0.4095
Epoch 93/100, Loss: 0.6883, Acc: 0.5559, Val Loss: 0.7039, Val Acc: 0.4095
Epoch 94/100, Loss: 0.6882, Acc: 0.5566, Val Loss: 0.7038, Val Acc: 0.4036
Epoch 95/100, Loss: 0.6882, Acc: 0.5552, Val Loss: 0.7039, Val Acc: 0.4043
Epoch 96/100, Loss: 0.6882, Acc: 0.5580, Val Loss: 0.7040, Val Acc: 0.4054
Epoch 97/100, Loss: 0.6881, Acc: 0.5551, Val Loss: 0.7041, Val Acc: 0.4058
Epoch 98/100, Loss: 0.6881, Acc: 0.5553, Val Loss: 0.7042, Val Acc: 0.4065
Epoch 99/100, Loss: 0.6881, Acc: 0.5559, Val Loss: 0.7041, Val Acc: 0.4043
Epoch 100/100, Loss: 0.6880, Acc: 0.5568, Val Loss: 0.7044, Val Acc: 0.4084

##############################
Resultados para principal:  034  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3 
 {'training': [0.6880212897411886, 0.5568119139547711, 0.5543420820856086, 0.5787054063994116, 0.5662618083670715], 'validate': [0.7043711210406104, 0.4083885209713024, 0.40795287187039764, 0.40795287187039764, 0.40795287187039764], 'test': [0.6930055949423048, 0.5002942907592701, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  014  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  014  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  014  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6752, Acc: 0.5924, Val Loss: 0.6914, Val Acc: 0.5327
Mejor modelo guardado con Val Loss: 0.6914
Epoch 2/100, Loss: 0.6689, Acc: 0.6097, Val Loss: 0.6897, Val Acc: 0.5254
Mejor modelo guardado con Val Loss: 0.6897
Epoch 3/100, Loss: 0.6529, Acc: 0.6307, Val Loss: 0.6844, Val Acc: 0.5427
Mejor modelo guardado con Val Loss: 0.6844
Epoch 4/100, Loss: 0.6549, Acc: 0.6259, Val Loss: 0.6887, Val Acc: 0.5442
Epoch 5/100, Loss: 0.6503, Acc: 0.6384, Val Loss: 0.6849, Val Acc: 0.5526
Epoch 6/100, Loss: 0.6394, Acc: 0.6460, Val Loss: 0.6896, Val Acc: 0.5350
Epoch 7/100, Loss: 0.6320, Acc: 0.6530, Val Loss: 0.6902, Val Acc: 0.5464
Epoch 8/100, Loss: 0.6264, Acc: 0.6557, Val Loss: 0.6929, Val Acc: 0.5537
Epoch 9/100, Loss: 0.6237, Acc: 0.6577, Val Loss: 0.7006, Val Acc: 0.5467
Epoch 10/100, Loss: 0.6314, Acc: 0.6511, Val Loss: 0.6934, Val Acc: 0.5478
Epoch 11/100, Loss: 0.6229, Acc: 0.6509, Val Loss: 0.6865, Val Acc: 0.5659
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6149, Acc: 0.6634, Val Loss: 0.6891, Val Acc: 0.5581
Epoch 13/100, Loss: 0.6163, Acc: 0.6625, Val Loss: 0.7017, Val Acc: 0.5511
Epoch 14/100, Loss: 0.6126, Acc: 0.6658, Val Loss: 0.6982, Val Acc: 0.5622
Epoch 15/100, Loss: 0.6135, Acc: 0.6673, Val Loss: 0.7049, Val Acc: 0.5390
Epoch 16/100, Loss: 0.6115, Acc: 0.6682, Val Loss: 0.7012, Val Acc: 0.5493
Epoch 17/100, Loss: 0.6124, Acc: 0.6642, Val Loss: 0.6979, Val Acc: 0.5541
Epoch 18/100, Loss: 0.6118, Acc: 0.6645, Val Loss: 0.7017, Val Acc: 0.5578
Epoch 19/100, Loss: 0.6108, Acc: 0.6674, Val Loss: 0.7047, Val Acc: 0.5530
Epoch 20/100, Loss: 0.6121, Acc: 0.6656, Val Loss: 0.6979, Val Acc: 0.5526
Epoch 21/100, Loss: 0.6102, Acc: 0.6659, Val Loss: 0.7106, Val Acc: 0.5445
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6084, Acc: 0.6663, Val Loss: 0.7051, Val Acc: 0.5500
Epoch 23/100, Loss: 0.6085, Acc: 0.6697, Val Loss: 0.7058, Val Acc: 0.5578
Epoch 24/100, Loss: 0.6076, Acc: 0.6701, Val Loss: 0.7088, Val Acc: 0.5423
Epoch 25/100, Loss: 0.6082, Acc: 0.6697, Val Loss: 0.6974, Val Acc: 0.5600
Epoch 26/100, Loss: 0.6066, Acc: 0.6714, Val Loss: 0.6822, Val Acc: 0.5795
Mejor modelo guardado con Val Loss: 0.6822
Epoch 27/100, Loss: 0.6077, Acc: 0.6670, Val Loss: 0.7020, Val Acc: 0.5556
Epoch 28/100, Loss: 0.6081, Acc: 0.6678, Val Loss: 0.7057, Val Acc: 0.5567
Epoch 29/100, Loss: 0.6071, Acc: 0.6704, Val Loss: 0.7010, Val Acc: 0.5574
Epoch 30/100, Loss: 0.6082, Acc: 0.6698, Val Loss: 0.6994, Val Acc: 0.5596
Epoch 31/100, Loss: 0.6055, Acc: 0.6731, Val Loss: 0.7065, Val Acc: 0.5500
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6038, Acc: 0.6728, Val Loss: 0.6975, Val Acc: 0.5614
Epoch 33/100, Loss: 0.6049, Acc: 0.6724, Val Loss: 0.7119, Val Acc: 0.5471
Epoch 34/100, Loss: 0.6040, Acc: 0.6733, Val Loss: 0.7054, Val Acc: 0.5500
Epoch 35/100, Loss: 0.6038, Acc: 0.6746, Val Loss: 0.7147, Val Acc: 0.5434
Epoch 36/100, Loss: 0.6047, Acc: 0.6738, Val Loss: 0.7089, Val Acc: 0.5515
Epoch 37/100, Loss: 0.6041, Acc: 0.6735, Val Loss: 0.7128, Val Acc: 0.5449
Epoch 38/100, Loss: 0.6051, Acc: 0.6731, Val Loss: 0.7040, Val Acc: 0.5500
Epoch 39/100, Loss: 0.6039, Acc: 0.6745, Val Loss: 0.7047, Val Acc: 0.5511
Epoch 40/100, Loss: 0.6035, Acc: 0.6751, Val Loss: 0.7157, Val Acc: 0.5482
Epoch 41/100, Loss: 0.6039, Acc: 0.6734, Val Loss: 0.7123, Val Acc: 0.5570
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6031, Acc: 0.6743, Val Loss: 0.7103, Val Acc: 0.5500
Epoch 43/100, Loss: 0.6030, Acc: 0.6746, Val Loss: 0.7084, Val Acc: 0.5537
Epoch 44/100, Loss: 0.6031, Acc: 0.6739, Val Loss: 0.7091, Val Acc: 0.5449
Epoch 45/100, Loss: 0.6027, Acc: 0.6762, Val Loss: 0.7136, Val Acc: 0.5442
Epoch 46/100, Loss: 0.6026, Acc: 0.6740, Val Loss: 0.7081, Val Acc: 0.5508
Epoch 47/100, Loss: 0.6026, Acc: 0.6745, Val Loss: 0.7083, Val Acc: 0.5508
Epoch 48/100, Loss: 0.6026, Acc: 0.6738, Val Loss: 0.7129, Val Acc: 0.5442
Epoch 49/100, Loss: 0.6024, Acc: 0.6762, Val Loss: 0.7112, Val Acc: 0.5482
Epoch 50/100, Loss: 0.6023, Acc: 0.6728, Val Loss: 0.7113, Val Acc: 0.5515
Epoch 51/100, Loss: 0.6023, Acc: 0.6758, Val Loss: 0.7124, Val Acc: 0.5453
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6019, Acc: 0.6749, Val Loss: 0.7075, Val Acc: 0.5511
Epoch 53/100, Loss: 0.6018, Acc: 0.6768, Val Loss: 0.7117, Val Acc: 0.5471
Epoch 54/100, Loss: 0.6017, Acc: 0.6750, Val Loss: 0.7105, Val Acc: 0.5456
Epoch 55/100, Loss: 0.6016, Acc: 0.6751, Val Loss: 0.7112, Val Acc: 0.5467
Epoch 56/100, Loss: 0.6019, Acc: 0.6751, Val Loss: 0.7100, Val Acc: 0.5464
Epoch 57/100, Loss: 0.6015, Acc: 0.6750, Val Loss: 0.7114, Val Acc: 0.5489
Epoch 58/100, Loss: 0.6016, Acc: 0.6744, Val Loss: 0.7097, Val Acc: 0.5493
Epoch 59/100, Loss: 0.6012, Acc: 0.6754, Val Loss: 0.7116, Val Acc: 0.5471
Epoch 60/100, Loss: 0.6012, Acc: 0.6746, Val Loss: 0.7101, Val Acc: 0.5497
Epoch 61/100, Loss: 0.6010, Acc: 0.6750, Val Loss: 0.7132, Val Acc: 0.5460
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6011, Acc: 0.6756, Val Loss: 0.7111, Val Acc: 0.5486
Epoch 63/100, Loss: 0.6009, Acc: 0.6760, Val Loss: 0.7105, Val Acc: 0.5475
Epoch 64/100, Loss: 0.6009, Acc: 0.6760, Val Loss: 0.7108, Val Acc: 0.5482
Epoch 65/100, Loss: 0.6008, Acc: 0.6760, Val Loss: 0.7101, Val Acc: 0.5471
Epoch 66/100, Loss: 0.6008, Acc: 0.6750, Val Loss: 0.7101, Val Acc: 0.5467
Epoch 67/100, Loss: 0.6007, Acc: 0.6770, Val Loss: 0.7120, Val Acc: 0.5482
Epoch 68/100, Loss: 0.6007, Acc: 0.6755, Val Loss: 0.7092, Val Acc: 0.5500
Epoch 69/100, Loss: 0.6006, Acc: 0.6760, Val Loss: 0.7118, Val Acc: 0.5486
Epoch 70/100, Loss: 0.6006, Acc: 0.6773, Val Loss: 0.7129, Val Acc: 0.5442
Epoch 71/100, Loss: 0.6009, Acc: 0.6750, Val Loss: 0.7119, Val Acc: 0.5475
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6006, Acc: 0.6764, Val Loss: 0.7111, Val Acc: 0.5467
Epoch 73/100, Loss: 0.6005, Acc: 0.6766, Val Loss: 0.7111, Val Acc: 0.5467
Epoch 74/100, Loss: 0.6005, Acc: 0.6762, Val Loss: 0.7106, Val Acc: 0.5467
Epoch 75/100, Loss: 0.6006, Acc: 0.6773, Val Loss: 0.7117, Val Acc: 0.5475
Epoch 76/100, Loss: 0.6006, Acc: 0.6758, Val Loss: 0.7119, Val Acc: 0.5486
Epoch 77/100, Loss: 0.6005, Acc: 0.6765, Val Loss: 0.7109, Val Acc: 0.5467
Epoch 78/100, Loss: 0.6004, Acc: 0.6764, Val Loss: 0.7102, Val Acc: 0.5482
Epoch 79/100, Loss: 0.6005, Acc: 0.6774, Val Loss: 0.7109, Val Acc: 0.5471
Epoch 80/100, Loss: 0.6005, Acc: 0.6778, Val Loss: 0.7117, Val Acc: 0.5460
Epoch 81/100, Loss: 0.6004, Acc: 0.6767, Val Loss: 0.7115, Val Acc: 0.5475
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6004, Acc: 0.6763, Val Loss: 0.7110, Val Acc: 0.5482
Epoch 83/100, Loss: 0.6004, Acc: 0.6768, Val Loss: 0.7113, Val Acc: 0.5467
Epoch 84/100, Loss: 0.6005, Acc: 0.6767, Val Loss: 0.7117, Val Acc: 0.5475
Epoch 85/100, Loss: 0.6003, Acc: 0.6753, Val Loss: 0.7124, Val Acc: 0.5482
Epoch 86/100, Loss: 0.6005, Acc: 0.6758, Val Loss: 0.7114, Val Acc: 0.5464
Epoch 87/100, Loss: 0.6003, Acc: 0.6777, Val Loss: 0.7126, Val Acc: 0.5486
Epoch 88/100, Loss: 0.6003, Acc: 0.6764, Val Loss: 0.7114, Val Acc: 0.5464
Epoch 89/100, Loss: 0.6004, Acc: 0.6769, Val Loss: 0.7115, Val Acc: 0.5467
Epoch 90/100, Loss: 0.6002, Acc: 0.6766, Val Loss: 0.7108, Val Acc: 0.5482
Epoch 91/100, Loss: 0.6003, Acc: 0.6771, Val Loss: 0.7112, Val Acc: 0.5464
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6003, Acc: 0.6781, Val Loss: 0.7123, Val Acc: 0.5482
Epoch 93/100, Loss: 0.6003, Acc: 0.6763, Val Loss: 0.7122, Val Acc: 0.5449
Epoch 94/100, Loss: 0.6002, Acc: 0.6763, Val Loss: 0.7127, Val Acc: 0.5467
Epoch 95/100, Loss: 0.6003, Acc: 0.6769, Val Loss: 0.7118, Val Acc: 0.5456
Epoch 96/100, Loss: 0.6002, Acc: 0.6772, Val Loss: 0.7112, Val Acc: 0.5460
Epoch 97/100, Loss: 0.6002, Acc: 0.6771, Val Loss: 0.7128, Val Acc: 0.5475
Epoch 98/100, Loss: 0.6003, Acc: 0.6765, Val Loss: 0.7120, Val Acc: 0.5460
Epoch 99/100, Loss: 0.6002, Acc: 0.6772, Val Loss: 0.7123, Val Acc: 0.5464
Epoch 100/100, Loss: 0.6002, Acc: 0.6771, Val Loss: 0.7114, Val Acc: 0.5460

##############################
Resultados para principal:  014  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3 
 {'training': [0.6002394284893428, 0.6771465342893914, 0.711555360281195, 0.5956233909525561, 0.6484484484484484], 'validate': [0.7113610041695971, 0.5459896983075792, 0.5722610722610723, 0.36156111929307805, 0.44314079422382674], 'test': [0.7863962959360193, 0.5161859917598587, 0.5101656626506024, 0.797997644287397, 0.6224161690399632]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  092  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  092  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  092  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6753, Acc: 0.5850, Val Loss: 0.6998, Val Acc: 0.5040
Mejor modelo guardado con Val Loss: 0.6998
Epoch 2/100, Loss: 0.6645, Acc: 0.6120, Val Loss: 0.7077, Val Acc: 0.4890
Epoch 3/100, Loss: 0.6607, Acc: 0.6162, Val Loss: 0.7185, Val Acc: 0.4709
Epoch 4/100, Loss: 0.6512, Acc: 0.6282, Val Loss: 0.7186, Val Acc: 0.4514
Epoch 5/100, Loss: 0.6456, Acc: 0.6283, Val Loss: 0.7372, Val Acc: 0.4779
Epoch 6/100, Loss: 0.6451, Acc: 0.6326, Val Loss: 0.7047, Val Acc: 0.4739
Epoch 7/100, Loss: 0.6466, Acc: 0.6304, Val Loss: 0.7289, Val Acc: 0.4845
Epoch 8/100, Loss: 0.6443, Acc: 0.6284, Val Loss: 0.7295, Val Acc: 0.4636
Epoch 9/100, Loss: 0.6425, Acc: 0.6385, Val Loss: 0.7439, Val Acc: 0.4845
Epoch 10/100, Loss: 0.6434, Acc: 0.6305, Val Loss: 0.7391, Val Acc: 0.4827
Epoch 11/100, Loss: 0.6397, Acc: 0.6359, Val Loss: 0.7542, Val Acc: 0.4728
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6339, Acc: 0.6441, Val Loss: 0.7462, Val Acc: 0.4709
Epoch 13/100, Loss: 0.6337, Acc: 0.6372, Val Loss: 0.7290, Val Acc: 0.4768
Epoch 14/100, Loss: 0.6358, Acc: 0.6407, Val Loss: 0.7356, Val Acc: 0.4868
Epoch 15/100, Loss: 0.6337, Acc: 0.6423, Val Loss: 0.7526, Val Acc: 0.4658
Epoch 16/100, Loss: 0.6321, Acc: 0.6372, Val Loss: 0.7494, Val Acc: 0.4809
Epoch 17/100, Loss: 0.6309, Acc: 0.6384, Val Loss: 0.7488, Val Acc: 0.4746
Epoch 18/100, Loss: 0.6302, Acc: 0.6444, Val Loss: 0.7426, Val Acc: 0.4742
Epoch 19/100, Loss: 0.6349, Acc: 0.6396, Val Loss: 0.7443, Val Acc: 0.4746
Epoch 20/100, Loss: 0.6316, Acc: 0.6421, Val Loss: 0.7494, Val Acc: 0.4746
Epoch 21/100, Loss: 0.6294, Acc: 0.6481, Val Loss: 0.7505, Val Acc: 0.4687
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6266, Acc: 0.6460, Val Loss: 0.7747, Val Acc: 0.4724
Epoch 23/100, Loss: 0.6273, Acc: 0.6465, Val Loss: 0.7660, Val Acc: 0.4750
Epoch 24/100, Loss: 0.6287, Acc: 0.6429, Val Loss: 0.7727, Val Acc: 0.4709
Epoch 25/100, Loss: 0.6253, Acc: 0.6484, Val Loss: 0.7598, Val Acc: 0.4746
Epoch 26/100, Loss: 0.6257, Acc: 0.6485, Val Loss: 0.7612, Val Acc: 0.4684
Epoch 27/100, Loss: 0.6249, Acc: 0.6490, Val Loss: 0.7653, Val Acc: 0.4783
Epoch 28/100, Loss: 0.6284, Acc: 0.6480, Val Loss: 0.7667, Val Acc: 0.4783
Epoch 29/100, Loss: 0.6253, Acc: 0.6478, Val Loss: 0.7552, Val Acc: 0.4739
Epoch 30/100, Loss: 0.6263, Acc: 0.6456, Val Loss: 0.7450, Val Acc: 0.4614
Epoch 31/100, Loss: 0.6263, Acc: 0.6447, Val Loss: 0.7511, Val Acc: 0.4687
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6244, Acc: 0.6465, Val Loss: 0.7663, Val Acc: 0.4717
Epoch 33/100, Loss: 0.6241, Acc: 0.6485, Val Loss: 0.7703, Val Acc: 0.4713
Epoch 34/100, Loss: 0.6230, Acc: 0.6521, Val Loss: 0.7675, Val Acc: 0.4728
Epoch 35/100, Loss: 0.6223, Acc: 0.6509, Val Loss: 0.7808, Val Acc: 0.4750
Epoch 36/100, Loss: 0.6227, Acc: 0.6532, Val Loss: 0.7760, Val Acc: 0.4742
Epoch 37/100, Loss: 0.6232, Acc: 0.6524, Val Loss: 0.7627, Val Acc: 0.4783
Epoch 38/100, Loss: 0.6235, Acc: 0.6497, Val Loss: 0.7665, Val Acc: 0.4669
Epoch 39/100, Loss: 0.6229, Acc: 0.6521, Val Loss: 0.7596, Val Acc: 0.4879
Epoch 40/100, Loss: 0.6222, Acc: 0.6502, Val Loss: 0.7766, Val Acc: 0.4720
Epoch 41/100, Loss: 0.6218, Acc: 0.6519, Val Loss: 0.7612, Val Acc: 0.4713
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6213, Acc: 0.6523, Val Loss: 0.7737, Val Acc: 0.4687
Epoch 43/100, Loss: 0.6211, Acc: 0.6555, Val Loss: 0.7688, Val Acc: 0.4702
Epoch 44/100, Loss: 0.6211, Acc: 0.6551, Val Loss: 0.7644, Val Acc: 0.4680
Epoch 45/100, Loss: 0.6215, Acc: 0.6539, Val Loss: 0.7646, Val Acc: 0.4673
Epoch 46/100, Loss: 0.6208, Acc: 0.6549, Val Loss: 0.7659, Val Acc: 0.4643
Epoch 47/100, Loss: 0.6209, Acc: 0.6543, Val Loss: 0.7715, Val Acc: 0.4691
Epoch 48/100, Loss: 0.6209, Acc: 0.6554, Val Loss: 0.7687, Val Acc: 0.4698
Epoch 49/100, Loss: 0.6208, Acc: 0.6534, Val Loss: 0.7686, Val Acc: 0.4680
Epoch 50/100, Loss: 0.6198, Acc: 0.6542, Val Loss: 0.7766, Val Acc: 0.4698
Epoch 51/100, Loss: 0.6206, Acc: 0.6568, Val Loss: 0.7737, Val Acc: 0.4676
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6199, Acc: 0.6566, Val Loss: 0.7708, Val Acc: 0.4650
Epoch 53/100, Loss: 0.6197, Acc: 0.6544, Val Loss: 0.7739, Val Acc: 0.4676
Epoch 54/100, Loss: 0.6195, Acc: 0.6562, Val Loss: 0.7650, Val Acc: 0.4639
Epoch 55/100, Loss: 0.6196, Acc: 0.6543, Val Loss: 0.7689, Val Acc: 0.4658
Epoch 56/100, Loss: 0.6195, Acc: 0.6560, Val Loss: 0.7704, Val Acc: 0.4684
Epoch 57/100, Loss: 0.6196, Acc: 0.6550, Val Loss: 0.7710, Val Acc: 0.4702
Epoch 58/100, Loss: 0.6194, Acc: 0.6566, Val Loss: 0.7725, Val Acc: 0.4691
Epoch 59/100, Loss: 0.6194, Acc: 0.6575, Val Loss: 0.7666, Val Acc: 0.4610
Epoch 60/100, Loss: 0.6194, Acc: 0.6552, Val Loss: 0.7690, Val Acc: 0.4647
Epoch 61/100, Loss: 0.6195, Acc: 0.6545, Val Loss: 0.7707, Val Acc: 0.4669
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6191, Acc: 0.6556, Val Loss: 0.7713, Val Acc: 0.4654
Epoch 63/100, Loss: 0.6190, Acc: 0.6582, Val Loss: 0.7703, Val Acc: 0.4669
Epoch 64/100, Loss: 0.6191, Acc: 0.6560, Val Loss: 0.7703, Val Acc: 0.4665
Epoch 65/100, Loss: 0.6190, Acc: 0.6559, Val Loss: 0.7723, Val Acc: 0.4669
Epoch 66/100, Loss: 0.6189, Acc: 0.6568, Val Loss: 0.7696, Val Acc: 0.4673
Epoch 67/100, Loss: 0.6191, Acc: 0.6570, Val Loss: 0.7695, Val Acc: 0.4662
Epoch 68/100, Loss: 0.6190, Acc: 0.6566, Val Loss: 0.7706, Val Acc: 0.4650
Epoch 69/100, Loss: 0.6189, Acc: 0.6566, Val Loss: 0.7714, Val Acc: 0.4662
Epoch 70/100, Loss: 0.6187, Acc: 0.6573, Val Loss: 0.7694, Val Acc: 0.4662
Epoch 71/100, Loss: 0.6185, Acc: 0.6560, Val Loss: 0.7695, Val Acc: 0.4669
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6185, Acc: 0.6555, Val Loss: 0.7703, Val Acc: 0.4658
Epoch 73/100, Loss: 0.6184, Acc: 0.6557, Val Loss: 0.7700, Val Acc: 0.4665
Epoch 74/100, Loss: 0.6185, Acc: 0.6557, Val Loss: 0.7710, Val Acc: 0.4628
Epoch 75/100, Loss: 0.6184, Acc: 0.6556, Val Loss: 0.7714, Val Acc: 0.4628
Epoch 76/100, Loss: 0.6184, Acc: 0.6567, Val Loss: 0.7706, Val Acc: 0.4658
Epoch 77/100, Loss: 0.6184, Acc: 0.6554, Val Loss: 0.7717, Val Acc: 0.4650
Epoch 78/100, Loss: 0.6184, Acc: 0.6560, Val Loss: 0.7720, Val Acc: 0.4650
Epoch 79/100, Loss: 0.6183, Acc: 0.6570, Val Loss: 0.7710, Val Acc: 0.4632
Epoch 80/100, Loss: 0.6183, Acc: 0.6565, Val Loss: 0.7717, Val Acc: 0.4647
Epoch 81/100, Loss: 0.6183, Acc: 0.6558, Val Loss: 0.7708, Val Acc: 0.4654
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6183, Acc: 0.6556, Val Loss: 0.7718, Val Acc: 0.4639
Epoch 83/100, Loss: 0.6183, Acc: 0.6563, Val Loss: 0.7722, Val Acc: 0.4639
Epoch 84/100, Loss: 0.6183, Acc: 0.6564, Val Loss: 0.7717, Val Acc: 0.4636
Epoch 85/100, Loss: 0.6183, Acc: 0.6566, Val Loss: 0.7717, Val Acc: 0.4643
Epoch 86/100, Loss: 0.6183, Acc: 0.6566, Val Loss: 0.7717, Val Acc: 0.4625
Epoch 87/100, Loss: 0.6183, Acc: 0.6565, Val Loss: 0.7711, Val Acc: 0.4654
Epoch 88/100, Loss: 0.6183, Acc: 0.6561, Val Loss: 0.7725, Val Acc: 0.4639
Epoch 89/100, Loss: 0.6182, Acc: 0.6562, Val Loss: 0.7726, Val Acc: 0.4636
Epoch 90/100, Loss: 0.6182, Acc: 0.6565, Val Loss: 0.7735, Val Acc: 0.4628
Epoch 91/100, Loss: 0.6182, Acc: 0.6567, Val Loss: 0.7734, Val Acc: 0.4658
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6181, Acc: 0.6565, Val Loss: 0.7736, Val Acc: 0.4639
Epoch 93/100, Loss: 0.6180, Acc: 0.6568, Val Loss: 0.7732, Val Acc: 0.4650
Epoch 94/100, Loss: 0.6179, Acc: 0.6553, Val Loss: 0.7723, Val Acc: 0.4665
Epoch 95/100, Loss: 0.6177, Acc: 0.6572, Val Loss: 0.7740, Val Acc: 0.4647
Epoch 96/100, Loss: 0.6177, Acc: 0.6568, Val Loss: 0.7727, Val Acc: 0.4658
Epoch 97/100, Loss: 0.6176, Acc: 0.6570, Val Loss: 0.7718, Val Acc: 0.4665
Epoch 98/100, Loss: 0.6176, Acc: 0.6572, Val Loss: 0.7716, Val Acc: 0.4658
Epoch 99/100, Loss: 0.6176, Acc: 0.6558, Val Loss: 0.7730, Val Acc: 0.4658
Epoch 100/100, Loss: 0.6176, Acc: 0.6573, Val Loss: 0.7722, Val Acc: 0.4669

##############################
Resultados para principal:  092  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  3 
 {'training': [0.6176389194100322, 0.6572899430042287, 0.6837129351095832, 0.5851415961750643, 0.63059849385652], 'validate': [0.772237406220547, 0.46688741721854304, 0.45687203791469194, 0.3549337260677467, 0.3995026937422296], 'test': [0.7448030312856039, 0.34873454973513834, 0.3515850144092219, 0.35924617196702, 0.3553743081852607]}

##############################
Resultados para window:  3 
 {'031:051:096:034:014:092': {'training': [0.6915885401924955, 0.5341055341055341, 0.5270388775211926, 0.663111438028687, 0.5872964169381107], 'validate': [0.6947970057642737, 0.4628403237674761, 0.47157190635451507, 0.6229749631811488, 0.5368020304568528], 'test': [0.693274974822998, 0.475868157739847, 0.4816777041942605, 0.6425206124852768, 0.5505929851122887]}, '051:031:096:034:014:092': {'training': [0.5781422520981354, 0.6963596249310535, 0.7086999022482894, 0.6666053696211842, 0.6870084336207714], 'validate': [0.7185970905215241, 0.5768947755702722, 0.5779610194902549, 0.5677466863033873, 0.5728083209509658], 'test': [0.6239887636016916, 0.6880517951736316, 0.8513215859030837, 0.4552414605418139, 0.5932463545663853]}, '096:031:051:034:014:092': {'training': [0.6498272485933797, 0.6330207758779187, 0.6227921195652174, 0.6743287973519676, 0.6475366413561716], 'validate': [0.6470436675604, 0.6401766004415012, 0.6669595782073814, 0.5589101620029455, 0.6081730769230769], 'test': [0.6684881995121638, 0.5994702766333138, 0.5923287671232876, 0.6366313309776207, 0.613681521430599]}, '034:031:051:096:014:092': {'training': [0.6880212897411886, 0.5568119139547711, 0.5543420820856086, 0.5787054063994116, 0.5662618083670715], 'validate': [0.7043711210406104, 0.4083885209713024, 0.40795287187039764, 0.40795287187039764, 0.40795287187039764], 'test': [0.6930055949423048, 0.5002942907592701, 0.0, 0.0, 0.0]}, '014:031:051:096:034:092': {'training': [0.6002394284893428, 0.6771465342893914, 0.711555360281195, 0.5956233909525561, 0.6484484484484484], 'validate': [0.7113610041695971, 0.5459896983075792, 0.5722610722610723, 0.36156111929307805, 0.44314079422382674], 'test': [0.7863962959360193, 0.5161859917598587, 0.5101656626506024, 0.797997644287397, 0.6224161690399632]}, '092:031:051:096:034:014': {'training': [0.6176389194100322, 0.6572899430042287, 0.6837129351095832, 0.5851415961750643, 0.63059849385652], 'validate': [0.772237406220547, 0.46688741721854304, 0.45687203791469194, 0.3549337260677467, 0.3995026937422296], 'test': [0.7448030312856039, 0.34873454973513834, 0.3515850144092219, 0.35924617196702, 0.3553743081852607]}}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  007  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  007  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  007  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4831, Acc: 0.8078, Val Loss: 0.3368, Val Acc: 0.8823
Mejor modelo guardado con Val Loss: 0.3368
Epoch 2/100, Loss: 0.3790, Acc: 0.8333, Val Loss: 0.3323, Val Acc: 0.8587
Mejor modelo guardado con Val Loss: 0.3323
Epoch 3/100, Loss: 0.3691, Acc: 0.8313, Val Loss: 0.2829, Val Acc: 0.8889
Mejor modelo guardado con Val Loss: 0.2829
Epoch 4/100, Loss: 0.3595, Acc: 0.8352, Val Loss: 0.2210, Val Acc: 0.9349
Mejor modelo guardado con Val Loss: 0.2210
Epoch 5/100, Loss: 0.3595, Acc: 0.8382, Val Loss: 0.2450, Val Acc: 0.9139
Epoch 6/100, Loss: 0.3525, Acc: 0.8359, Val Loss: 0.2969, Val Acc: 0.8962
Epoch 7/100, Loss: 0.3521, Acc: 0.8385, Val Loss: 0.2135, Val Acc: 0.9352
Mejor modelo guardado con Val Loss: 0.2135
Epoch 8/100, Loss: 0.3497, Acc: 0.8415, Val Loss: 0.2462, Val Acc: 0.9257
Epoch 9/100, Loss: 0.3461, Acc: 0.8418, Val Loss: 0.2526, Val Acc: 0.8996
Epoch 10/100, Loss: 0.3515, Acc: 0.8305, Val Loss: 0.2978, Val Acc: 0.8664
Epoch 11/100, Loss: 0.3496, Acc: 0.8368, Val Loss: 0.2560, Val Acc: 0.8929
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3395, Acc: 0.8449, Val Loss: 0.3310, Val Acc: 0.8377
Epoch 13/100, Loss: 0.3349, Acc: 0.8462, Val Loss: 0.2366, Val Acc: 0.8988
Epoch 14/100, Loss: 0.3355, Acc: 0.8394, Val Loss: 0.2973, Val Acc: 0.8709
Epoch 15/100, Loss: 0.3332, Acc: 0.8459, Val Loss: 0.2041, Val Acc: 0.9198
Mejor modelo guardado con Val Loss: 0.2041
Epoch 16/100, Loss: 0.3328, Acc: 0.8443, Val Loss: 0.2578, Val Acc: 0.8882
Epoch 17/100, Loss: 0.3332, Acc: 0.8454, Val Loss: 0.2611, Val Acc: 0.8815
Epoch 18/100, Loss: 0.3300, Acc: 0.8525, Val Loss: 0.2563, Val Acc: 0.8819
Epoch 19/100, Loss: 0.3302, Acc: 0.8508, Val Loss: 0.2127, Val Acc: 0.9227
Epoch 20/100, Loss: 0.3321, Acc: 0.8468, Val Loss: 0.3400, Val Acc: 0.8418
Epoch 21/100, Loss: 0.3312, Acc: 0.8486, Val Loss: 0.2210, Val Acc: 0.9032
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3277, Acc: 0.8476, Val Loss: 0.2989, Val Acc: 0.8595
Epoch 23/100, Loss: 0.3256, Acc: 0.8512, Val Loss: 0.2285, Val Acc: 0.9143
Epoch 24/100, Loss: 0.3256, Acc: 0.8488, Val Loss: 0.2387, Val Acc: 0.9069
Epoch 25/100, Loss: 0.3238, Acc: 0.8521, Val Loss: 0.2289, Val Acc: 0.9157
Epoch 26/100, Loss: 0.3226, Acc: 0.8491, Val Loss: 0.2839, Val Acc: 0.8675
Epoch 27/100, Loss: 0.3234, Acc: 0.8508, Val Loss: 0.2907, Val Acc: 0.8712
Epoch 28/100, Loss: 0.3216, Acc: 0.8526, Val Loss: 0.2224, Val Acc: 0.9161
Epoch 29/100, Loss: 0.3243, Acc: 0.8514, Val Loss: 0.2835, Val Acc: 0.8760
Epoch 30/100, Loss: 0.3239, Acc: 0.8510, Val Loss: 0.2216, Val Acc: 0.9106
Epoch 31/100, Loss: 0.3228, Acc: 0.8532, Val Loss: 0.2559, Val Acc: 0.8911
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3197, Acc: 0.8533, Val Loss: 0.2702, Val Acc: 0.8911
Epoch 33/100, Loss: 0.3189, Acc: 0.8536, Val Loss: 0.2837, Val Acc: 0.8756
Epoch 34/100, Loss: 0.3191, Acc: 0.8540, Val Loss: 0.2961, Val Acc: 0.8609
Epoch 35/100, Loss: 0.3189, Acc: 0.8544, Val Loss: 0.2689, Val Acc: 0.8797
Epoch 36/100, Loss: 0.3178, Acc: 0.8553, Val Loss: 0.2940, Val Acc: 0.8675
Epoch 37/100, Loss: 0.3185, Acc: 0.8550, Val Loss: 0.2436, Val Acc: 0.9018
Epoch 38/100, Loss: 0.3168, Acc: 0.8559, Val Loss: 0.2566, Val Acc: 0.8834
Epoch 39/100, Loss: 0.3164, Acc: 0.8571, Val Loss: 0.2656, Val Acc: 0.8815
Epoch 40/100, Loss: 0.3168, Acc: 0.8557, Val Loss: 0.2332, Val Acc: 0.9080
Epoch 41/100, Loss: 0.3172, Acc: 0.8564, Val Loss: 0.2510, Val Acc: 0.8940
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3142, Acc: 0.8588, Val Loss: 0.2544, Val Acc: 0.8933
Epoch 43/100, Loss: 0.3142, Acc: 0.8576, Val Loss: 0.2634, Val Acc: 0.8837
Epoch 44/100, Loss: 0.3142, Acc: 0.8590, Val Loss: 0.2683, Val Acc: 0.8874
Epoch 45/100, Loss: 0.3138, Acc: 0.8589, Val Loss: 0.2412, Val Acc: 0.9010
Epoch 46/100, Loss: 0.3140, Acc: 0.8583, Val Loss: 0.2534, Val Acc: 0.8922
Epoch 47/100, Loss: 0.3130, Acc: 0.8601, Val Loss: 0.2385, Val Acc: 0.8999
Epoch 48/100, Loss: 0.3132, Acc: 0.8590, Val Loss: 0.2369, Val Acc: 0.9003
Epoch 49/100, Loss: 0.3134, Acc: 0.8591, Val Loss: 0.2395, Val Acc: 0.8988
Epoch 50/100, Loss: 0.3135, Acc: 0.8574, Val Loss: 0.2629, Val Acc: 0.8889
Epoch 51/100, Loss: 0.3129, Acc: 0.8582, Val Loss: 0.2605, Val Acc: 0.8867
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3121, Acc: 0.8591, Val Loss: 0.2453, Val Acc: 0.8948
Epoch 53/100, Loss: 0.3123, Acc: 0.8578, Val Loss: 0.2509, Val Acc: 0.8933
Epoch 54/100, Loss: 0.3119, Acc: 0.8599, Val Loss: 0.2642, Val Acc: 0.8867
Epoch 55/100, Loss: 0.3119, Acc: 0.8594, Val Loss: 0.2549, Val Acc: 0.8911
Epoch 56/100, Loss: 0.3117, Acc: 0.8606, Val Loss: 0.2442, Val Acc: 0.8974
Epoch 57/100, Loss: 0.3117, Acc: 0.8597, Val Loss: 0.2471, Val Acc: 0.8948
Epoch 58/100, Loss: 0.3117, Acc: 0.8589, Val Loss: 0.2488, Val Acc: 0.8937
Epoch 59/100, Loss: 0.3118, Acc: 0.8602, Val Loss: 0.2451, Val Acc: 0.8948
Epoch 60/100, Loss: 0.3118, Acc: 0.8593, Val Loss: 0.2634, Val Acc: 0.8882
Epoch 61/100, Loss: 0.3119, Acc: 0.8587, Val Loss: 0.2636, Val Acc: 0.8889
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3111, Acc: 0.8596, Val Loss: 0.2528, Val Acc: 0.8922
Epoch 63/100, Loss: 0.3110, Acc: 0.8604, Val Loss: 0.2518, Val Acc: 0.8922
Epoch 64/100, Loss: 0.3109, Acc: 0.8605, Val Loss: 0.2555, Val Acc: 0.8911
Epoch 65/100, Loss: 0.3110, Acc: 0.8600, Val Loss: 0.2622, Val Acc: 0.8874
Epoch 66/100, Loss: 0.3109, Acc: 0.8602, Val Loss: 0.2560, Val Acc: 0.8907
Epoch 67/100, Loss: 0.3109, Acc: 0.8601, Val Loss: 0.2583, Val Acc: 0.8904
Epoch 68/100, Loss: 0.3108, Acc: 0.8609, Val Loss: 0.2556, Val Acc: 0.8907
Epoch 69/100, Loss: 0.3108, Acc: 0.8600, Val Loss: 0.2642, Val Acc: 0.8867
Epoch 70/100, Loss: 0.3107, Acc: 0.8605, Val Loss: 0.2703, Val Acc: 0.8830
Epoch 71/100, Loss: 0.3110, Acc: 0.8596, Val Loss: 0.2567, Val Acc: 0.8907
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3106, Acc: 0.8598, Val Loss: 0.2591, Val Acc: 0.8893
Epoch 73/100, Loss: 0.3105, Acc: 0.8600, Val Loss: 0.2605, Val Acc: 0.8904
Epoch 74/100, Loss: 0.3106, Acc: 0.8601, Val Loss: 0.2557, Val Acc: 0.8907
Epoch 75/100, Loss: 0.3105, Acc: 0.8596, Val Loss: 0.2563, Val Acc: 0.8907
Epoch 76/100, Loss: 0.3104, Acc: 0.8606, Val Loss: 0.2580, Val Acc: 0.8904
Epoch 77/100, Loss: 0.3105, Acc: 0.8600, Val Loss: 0.2559, Val Acc: 0.8904
Epoch 78/100, Loss: 0.3104, Acc: 0.8604, Val Loss: 0.2580, Val Acc: 0.8904
Epoch 79/100, Loss: 0.3104, Acc: 0.8599, Val Loss: 0.2546, Val Acc: 0.8915
Epoch 80/100, Loss: 0.3104, Acc: 0.8602, Val Loss: 0.2583, Val Acc: 0.8900
Epoch 81/100, Loss: 0.3105, Acc: 0.8605, Val Loss: 0.2570, Val Acc: 0.8904
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3103, Acc: 0.8601, Val Loss: 0.2559, Val Acc: 0.8907
Epoch 83/100, Loss: 0.3103, Acc: 0.8607, Val Loss: 0.2569, Val Acc: 0.8907
Epoch 84/100, Loss: 0.3103, Acc: 0.8600, Val Loss: 0.2578, Val Acc: 0.8900
Epoch 85/100, Loss: 0.3102, Acc: 0.8613, Val Loss: 0.2555, Val Acc: 0.8907
Epoch 86/100, Loss: 0.3103, Acc: 0.8595, Val Loss: 0.2593, Val Acc: 0.8896
Epoch 87/100, Loss: 0.3103, Acc: 0.8594, Val Loss: 0.2567, Val Acc: 0.8907
Epoch 88/100, Loss: 0.3101, Acc: 0.8600, Val Loss: 0.2645, Val Acc: 0.8867
Epoch 89/100, Loss: 0.3102, Acc: 0.8593, Val Loss: 0.2552, Val Acc: 0.8915
Epoch 90/100, Loss: 0.3101, Acc: 0.8598, Val Loss: 0.2578, Val Acc: 0.8896
Epoch 91/100, Loss: 0.3101, Acc: 0.8603, Val Loss: 0.2569, Val Acc: 0.8904
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3101, Acc: 0.8602, Val Loss: 0.2536, Val Acc: 0.8922
Epoch 93/100, Loss: 0.3101, Acc: 0.8600, Val Loss: 0.2565, Val Acc: 0.8907
Epoch 94/100, Loss: 0.3101, Acc: 0.8599, Val Loss: 0.2531, Val Acc: 0.8922
Epoch 95/100, Loss: 0.3100, Acc: 0.8594, Val Loss: 0.2621, Val Acc: 0.8885
Epoch 96/100, Loss: 0.3101, Acc: 0.8604, Val Loss: 0.2523, Val Acc: 0.8922
Epoch 97/100, Loss: 0.3100, Acc: 0.8603, Val Loss: 0.2536, Val Acc: 0.8922
Epoch 98/100, Loss: 0.3101, Acc: 0.8605, Val Loss: 0.2580, Val Acc: 0.8900
Epoch 99/100, Loss: 0.3100, Acc: 0.8605, Val Loss: 0.2557, Val Acc: 0.8915
Epoch 100/100, Loss: 0.3099, Acc: 0.8608, Val Loss: 0.2605, Val Acc: 0.8896

##############################
Resultados para principal:  007  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3 
 {'training': [0.30993995993184265, 0.8608200036771465, 0.8521177315147165, 0.873115115851416, 0.8624886466848319], 'validate': [0.2604812885699577, 0.8896247240618101, 0.8229548229548229, 0.9926362297496318, 0.8998664886515354], 'test': [0.12869043286061949, 0.9520306062389641, 0.9961215255332903, 0.9075382803297998, 0.949768875192604]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  111  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  111  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  111  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5053, Acc: 0.7955, Val Loss: 0.3156, Val Acc: 0.9040
Mejor modelo guardado con Val Loss: 0.3156
Epoch 2/100, Loss: 0.3954, Acc: 0.8356, Val Loss: 0.3690, Val Acc: 0.8241
Epoch 3/100, Loss: 0.3702, Acc: 0.8380, Val Loss: 0.2440, Val Acc: 0.9444
Mejor modelo guardado con Val Loss: 0.2440
Epoch 4/100, Loss: 0.3634, Acc: 0.8358, Val Loss: 0.3053, Val Acc: 0.8606
Epoch 5/100, Loss: 0.3512, Acc: 0.8426, Val Loss: 0.3193, Val Acc: 0.8650
Epoch 6/100, Loss: 0.3586, Acc: 0.8403, Val Loss: 0.2141, Val Acc: 0.9275
Mejor modelo guardado con Val Loss: 0.2141
Epoch 7/100, Loss: 0.3521, Acc: 0.8416, Val Loss: 0.2477, Val Acc: 0.8911
Epoch 8/100, Loss: 0.3474, Acc: 0.8442, Val Loss: 0.2181, Val Acc: 0.9216
Epoch 9/100, Loss: 0.3429, Acc: 0.8462, Val Loss: 0.1768, Val Acc: 0.9529
Mejor modelo guardado con Val Loss: 0.1768
Epoch 10/100, Loss: 0.3431, Acc: 0.8485, Val Loss: 0.1866, Val Acc: 0.9459
Epoch 11/100, Loss: 0.3419, Acc: 0.8497, Val Loss: 0.3129, Val Acc: 0.8503
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3331, Acc: 0.8523, Val Loss: 0.1969, Val Acc: 0.9286
Epoch 13/100, Loss: 0.3304, Acc: 0.8525, Val Loss: 0.1924, Val Acc: 0.9216
Epoch 14/100, Loss: 0.3287, Acc: 0.8534, Val Loss: 0.1844, Val Acc: 0.9260
Epoch 15/100, Loss: 0.3298, Acc: 0.8539, Val Loss: 0.2593, Val Acc: 0.8826
Epoch 16/100, Loss: 0.3293, Acc: 0.8500, Val Loss: 0.2102, Val Acc: 0.9209
Epoch 17/100, Loss: 0.3273, Acc: 0.8537, Val Loss: 0.2077, Val Acc: 0.9316
Epoch 18/100, Loss: 0.3252, Acc: 0.8543, Val Loss: 0.1757, Val Acc: 0.9400
Mejor modelo guardado con Val Loss: 0.1757
Epoch 19/100, Loss: 0.3278, Acc: 0.8549, Val Loss: 0.2426, Val Acc: 0.9036
Epoch 20/100, Loss: 0.3256, Acc: 0.8569, Val Loss: 0.2236, Val Acc: 0.8996
Epoch 21/100, Loss: 0.3266, Acc: 0.8551, Val Loss: 0.2250, Val Acc: 0.8996
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3219, Acc: 0.8554, Val Loss: 0.1563, Val Acc: 0.9481
Mejor modelo guardado con Val Loss: 0.1563
Epoch 23/100, Loss: 0.3230, Acc: 0.8524, Val Loss: 0.2216, Val Acc: 0.9065
Epoch 24/100, Loss: 0.3211, Acc: 0.8587, Val Loss: 0.2111, Val Acc: 0.9191
Epoch 25/100, Loss: 0.3207, Acc: 0.8576, Val Loss: 0.2174, Val Acc: 0.9032
Epoch 26/100, Loss: 0.3213, Acc: 0.8547, Val Loss: 0.2014, Val Acc: 0.9191
Epoch 27/100, Loss: 0.3178, Acc: 0.8571, Val Loss: 0.2007, Val Acc: 0.9113
Epoch 28/100, Loss: 0.3181, Acc: 0.8575, Val Loss: 0.2001, Val Acc: 0.9161
Epoch 29/100, Loss: 0.3197, Acc: 0.8582, Val Loss: 0.1881, Val Acc: 0.9220
Epoch 30/100, Loss: 0.3189, Acc: 0.8564, Val Loss: 0.2376, Val Acc: 0.8951
Epoch 31/100, Loss: 0.3155, Acc: 0.8578, Val Loss: 0.1780, Val Acc: 0.9341
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3138, Acc: 0.8590, Val Loss: 0.2142, Val Acc: 0.9135
Epoch 33/100, Loss: 0.3141, Acc: 0.8579, Val Loss: 0.2028, Val Acc: 0.9231
Epoch 34/100, Loss: 0.3130, Acc: 0.8612, Val Loss: 0.1887, Val Acc: 0.9220
Epoch 35/100, Loss: 0.3120, Acc: 0.8614, Val Loss: 0.1848, Val Acc: 0.9286
Epoch 36/100, Loss: 0.3129, Acc: 0.8594, Val Loss: 0.1983, Val Acc: 0.9202
Epoch 37/100, Loss: 0.3135, Acc: 0.8625, Val Loss: 0.2278, Val Acc: 0.9010
Epoch 38/100, Loss: 0.3132, Acc: 0.8609, Val Loss: 0.1973, Val Acc: 0.9154
Epoch 39/100, Loss: 0.3134, Acc: 0.8593, Val Loss: 0.1917, Val Acc: 0.9187
Epoch 40/100, Loss: 0.3121, Acc: 0.8610, Val Loss: 0.1861, Val Acc: 0.9235
Epoch 41/100, Loss: 0.3117, Acc: 0.8611, Val Loss: 0.2121, Val Acc: 0.9088
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3088, Acc: 0.8612, Val Loss: 0.1906, Val Acc: 0.9216
Epoch 43/100, Loss: 0.3085, Acc: 0.8620, Val Loss: 0.1974, Val Acc: 0.9187
Epoch 44/100, Loss: 0.3083, Acc: 0.8624, Val Loss: 0.2094, Val Acc: 0.9124
Epoch 45/100, Loss: 0.3082, Acc: 0.8621, Val Loss: 0.1994, Val Acc: 0.9161
Epoch 46/100, Loss: 0.3082, Acc: 0.8610, Val Loss: 0.1902, Val Acc: 0.9191
Epoch 47/100, Loss: 0.3085, Acc: 0.8623, Val Loss: 0.1912, Val Acc: 0.9194
Epoch 48/100, Loss: 0.3089, Acc: 0.8622, Val Loss: 0.1845, Val Acc: 0.9227
Epoch 49/100, Loss: 0.3079, Acc: 0.8619, Val Loss: 0.2186, Val Acc: 0.9047
Epoch 50/100, Loss: 0.3084, Acc: 0.8620, Val Loss: 0.2143, Val Acc: 0.9077
Epoch 51/100, Loss: 0.3080, Acc: 0.8627, Val Loss: 0.2066, Val Acc: 0.9121
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3068, Acc: 0.8629, Val Loss: 0.1926, Val Acc: 0.9209
Epoch 53/100, Loss: 0.3068, Acc: 0.8623, Val Loss: 0.2045, Val Acc: 0.9139
Epoch 54/100, Loss: 0.3066, Acc: 0.8628, Val Loss: 0.2013, Val Acc: 0.9165
Epoch 55/100, Loss: 0.3066, Acc: 0.8632, Val Loss: 0.2071, Val Acc: 0.9128
Epoch 56/100, Loss: 0.3068, Acc: 0.8632, Val Loss: 0.2026, Val Acc: 0.9157
Epoch 57/100, Loss: 0.3065, Acc: 0.8622, Val Loss: 0.1951, Val Acc: 0.9198
Epoch 58/100, Loss: 0.3062, Acc: 0.8636, Val Loss: 0.2046, Val Acc: 0.9161
Epoch 59/100, Loss: 0.3064, Acc: 0.8617, Val Loss: 0.1944, Val Acc: 0.9194
Epoch 60/100, Loss: 0.3063, Acc: 0.8646, Val Loss: 0.2127, Val Acc: 0.9095
Epoch 61/100, Loss: 0.3063, Acc: 0.8630, Val Loss: 0.2045, Val Acc: 0.9117
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3055, Acc: 0.8631, Val Loss: 0.2026, Val Acc: 0.9165
Epoch 63/100, Loss: 0.3056, Acc: 0.8632, Val Loss: 0.2012, Val Acc: 0.9180
Epoch 64/100, Loss: 0.3055, Acc: 0.8641, Val Loss: 0.2000, Val Acc: 0.9180
Epoch 65/100, Loss: 0.3056, Acc: 0.8635, Val Loss: 0.1980, Val Acc: 0.9187
Epoch 66/100, Loss: 0.3055, Acc: 0.8630, Val Loss: 0.2004, Val Acc: 0.9176
Epoch 67/100, Loss: 0.3051, Acc: 0.8647, Val Loss: 0.2122, Val Acc: 0.9099
Epoch 68/100, Loss: 0.3054, Acc: 0.8633, Val Loss: 0.1975, Val Acc: 0.9194
Epoch 69/100, Loss: 0.3053, Acc: 0.8629, Val Loss: 0.1993, Val Acc: 0.9183
Epoch 70/100, Loss: 0.3054, Acc: 0.8634, Val Loss: 0.2000, Val Acc: 0.9183
Epoch 71/100, Loss: 0.3051, Acc: 0.8625, Val Loss: 0.2079, Val Acc: 0.9113
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3051, Acc: 0.8635, Val Loss: 0.2010, Val Acc: 0.9172
Epoch 73/100, Loss: 0.3049, Acc: 0.8639, Val Loss: 0.2050, Val Acc: 0.9143
Epoch 74/100, Loss: 0.3050, Acc: 0.8632, Val Loss: 0.2012, Val Acc: 0.9176
Epoch 75/100, Loss: 0.3049, Acc: 0.8628, Val Loss: 0.2038, Val Acc: 0.9146
Epoch 76/100, Loss: 0.3049, Acc: 0.8638, Val Loss: 0.2027, Val Acc: 0.9157
Epoch 77/100, Loss: 0.3049, Acc: 0.8631, Val Loss: 0.1966, Val Acc: 0.9194
Epoch 78/100, Loss: 0.3049, Acc: 0.8631, Val Loss: 0.1975, Val Acc: 0.9183
Epoch 79/100, Loss: 0.3049, Acc: 0.8639, Val Loss: 0.2033, Val Acc: 0.9154
Epoch 80/100, Loss: 0.3047, Acc: 0.8639, Val Loss: 0.2085, Val Acc: 0.9121
Epoch 81/100, Loss: 0.3047, Acc: 0.8646, Val Loss: 0.1960, Val Acc: 0.9202
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3049, Acc: 0.8636, Val Loss: 0.2023, Val Acc: 0.9157
Epoch 83/100, Loss: 0.3048, Acc: 0.8641, Val Loss: 0.1967, Val Acc: 0.9194
Epoch 84/100, Loss: 0.3048, Acc: 0.8644, Val Loss: 0.1982, Val Acc: 0.9191
Epoch 85/100, Loss: 0.3047, Acc: 0.8629, Val Loss: 0.2052, Val Acc: 0.9135
Epoch 86/100, Loss: 0.3048, Acc: 0.8629, Val Loss: 0.2020, Val Acc: 0.9169
Epoch 87/100, Loss: 0.3048, Acc: 0.8632, Val Loss: 0.2062, Val Acc: 0.9132
Epoch 88/100, Loss: 0.3047, Acc: 0.8633, Val Loss: 0.2015, Val Acc: 0.9165
Epoch 89/100, Loss: 0.3047, Acc: 0.8643, Val Loss: 0.2001, Val Acc: 0.9180
Epoch 90/100, Loss: 0.3047, Acc: 0.8625, Val Loss: 0.2018, Val Acc: 0.9169
Epoch 91/100, Loss: 0.3046, Acc: 0.8630, Val Loss: 0.2031, Val Acc: 0.9161
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3048, Acc: 0.8638, Val Loss: 0.2012, Val Acc: 0.9176
Epoch 93/100, Loss: 0.3045, Acc: 0.8637, Val Loss: 0.2098, Val Acc: 0.9099
Epoch 94/100, Loss: 0.3047, Acc: 0.8632, Val Loss: 0.2037, Val Acc: 0.9146
Epoch 95/100, Loss: 0.3045, Acc: 0.8643, Val Loss: 0.1981, Val Acc: 0.9191
Epoch 96/100, Loss: 0.3045, Acc: 0.8628, Val Loss: 0.2041, Val Acc: 0.9150
Epoch 97/100, Loss: 0.3044, Acc: 0.8639, Val Loss: 0.1991, Val Acc: 0.9191
Epoch 98/100, Loss: 0.3045, Acc: 0.8642, Val Loss: 0.1996, Val Acc: 0.9183
Epoch 99/100, Loss: 0.3044, Acc: 0.8639, Val Loss: 0.2051, Val Acc: 0.9146
Epoch 100/100, Loss: 0.3046, Acc: 0.8629, Val Loss: 0.2025, Val Acc: 0.9154

##############################
Resultados para principal:  111  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3 
 {'training': [0.3046031736740187, 0.862934362934363, 0.8531043120415102, 0.8767929385803604, 0.8647864333000816], 'validate': [0.20252005158122197, 0.9153789551140544, 0.8610755441741357, 0.9904270986745214, 0.9212328767123288], 'test': [1.6348721211845125, 0.3687463213655091, 0.4112743152044462, 0.6101295641931684, 0.49134455774247093]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  001  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  001  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  001  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6167, Acc: 0.7028, Val Loss: 0.7078, Val Acc: 0.5235
Mejor modelo guardado con Val Loss: 0.7078
Epoch 2/100, Loss: 0.5349, Acc: 0.7540, Val Loss: 0.6429, Val Acc: 0.6468
Mejor modelo guardado con Val Loss: 0.6429
Epoch 3/100, Loss: 0.5069, Acc: 0.7570, Val Loss: 0.7038, Val Acc: 0.5515
Epoch 4/100, Loss: 0.4882, Acc: 0.7678, Val Loss: 0.7444, Val Acc: 0.5611
Epoch 5/100, Loss: 0.4777, Acc: 0.7731, Val Loss: 0.7090, Val Acc: 0.5695
Epoch 6/100, Loss: 0.4696, Acc: 0.7721, Val Loss: 0.7509, Val Acc: 0.5357
Epoch 7/100, Loss: 0.4723, Acc: 0.7726, Val Loss: 0.7042, Val Acc: 0.5633
Epoch 8/100, Loss: 0.4589, Acc: 0.7782, Val Loss: 0.8642, Val Acc: 0.5283
Epoch 9/100, Loss: 0.4605, Acc: 0.7750, Val Loss: 0.8224, Val Acc: 0.5015
Epoch 10/100, Loss: 0.4530, Acc: 0.7756, Val Loss: 0.7934, Val Acc: 0.5302
Epoch 11/100, Loss: 0.4499, Acc: 0.7784, Val Loss: 0.7940, Val Acc: 0.5364
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4457, Acc: 0.7849, Val Loss: 0.8865, Val Acc: 0.5136
Epoch 13/100, Loss: 0.4391, Acc: 0.7872, Val Loss: 0.8050, Val Acc: 0.4982
Epoch 14/100, Loss: 0.4339, Acc: 0.7905, Val Loss: 0.8839, Val Acc: 0.5063
Epoch 15/100, Loss: 0.4338, Acc: 0.7854, Val Loss: 0.8426, Val Acc: 0.5151
Epoch 16/100, Loss: 0.4356, Acc: 0.7882, Val Loss: 0.8183, Val Acc: 0.5114
Epoch 17/100, Loss: 0.4302, Acc: 0.7876, Val Loss: 0.7606, Val Acc: 0.4967
Epoch 18/100, Loss: 0.4297, Acc: 0.7911, Val Loss: 0.8028, Val Acc: 0.5243
Epoch 19/100, Loss: 0.4337, Acc: 0.7883, Val Loss: 0.8770, Val Acc: 0.5015
Epoch 20/100, Loss: 0.4290, Acc: 0.7881, Val Loss: 0.8330, Val Acc: 0.5033
Epoch 21/100, Loss: 0.4305, Acc: 0.7915, Val Loss: 0.8811, Val Acc: 0.5052
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4241, Acc: 0.7932, Val Loss: 0.8580, Val Acc: 0.4923
Epoch 23/100, Loss: 0.4230, Acc: 0.7920, Val Loss: 0.8987, Val Acc: 0.5059
Epoch 24/100, Loss: 0.4217, Acc: 0.7940, Val Loss: 0.8853, Val Acc: 0.5048
Epoch 25/100, Loss: 0.4246, Acc: 0.7917, Val Loss: 0.9048, Val Acc: 0.5088
Epoch 26/100, Loss: 0.4205, Acc: 0.7940, Val Loss: 0.8480, Val Acc: 0.5180
Epoch 27/100, Loss: 0.4205, Acc: 0.7921, Val Loss: 0.8355, Val Acc: 0.5018
Epoch 28/100, Loss: 0.4196, Acc: 0.7972, Val Loss: 0.8683, Val Acc: 0.5022
Epoch 29/100, Loss: 0.4197, Acc: 0.7986, Val Loss: 0.8676, Val Acc: 0.4971
Epoch 30/100, Loss: 0.4187, Acc: 0.7972, Val Loss: 0.8619, Val Acc: 0.5033
Epoch 31/100, Loss: 0.4174, Acc: 0.7960, Val Loss: 0.8525, Val Acc: 0.4993
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4152, Acc: 0.7980, Val Loss: 0.8260, Val Acc: 0.5088
Epoch 33/100, Loss: 0.4144, Acc: 0.7980, Val Loss: 0.8635, Val Acc: 0.5037
Epoch 34/100, Loss: 0.4155, Acc: 0.7968, Val Loss: 0.8902, Val Acc: 0.5202
Epoch 35/100, Loss: 0.4164, Acc: 0.7968, Val Loss: 0.8742, Val Acc: 0.4985
Epoch 36/100, Loss: 0.4153, Acc: 0.7987, Val Loss: 0.9088, Val Acc: 0.4985
Epoch 37/100, Loss: 0.4138, Acc: 0.7957, Val Loss: 0.8269, Val Acc: 0.5372
Epoch 38/100, Loss: 0.4151, Acc: 0.7964, Val Loss: 0.8441, Val Acc: 0.5143
Epoch 39/100, Loss: 0.4132, Acc: 0.7974, Val Loss: 0.8902, Val Acc: 0.5143
Epoch 40/100, Loss: 0.4139, Acc: 0.7977, Val Loss: 0.8750, Val Acc: 0.5022
Epoch 41/100, Loss: 0.4140, Acc: 0.7979, Val Loss: 0.8312, Val Acc: 0.5044
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4117, Acc: 0.7987, Val Loss: 0.8797, Val Acc: 0.5081
Epoch 43/100, Loss: 0.4101, Acc: 0.8001, Val Loss: 0.8753, Val Acc: 0.5037
Epoch 44/100, Loss: 0.4104, Acc: 0.8005, Val Loss: 0.8479, Val Acc: 0.5099
Epoch 45/100, Loss: 0.4103, Acc: 0.7987, Val Loss: 0.8397, Val Acc: 0.5037
Epoch 46/100, Loss: 0.4105, Acc: 0.7981, Val Loss: 0.8478, Val Acc: 0.5081
Epoch 47/100, Loss: 0.4100, Acc: 0.7996, Val Loss: 0.8757, Val Acc: 0.5081
Epoch 48/100, Loss: 0.4093, Acc: 0.8005, Val Loss: 0.8690, Val Acc: 0.5048
Epoch 49/100, Loss: 0.4102, Acc: 0.7993, Val Loss: 0.8649, Val Acc: 0.5063
Epoch 50/100, Loss: 0.4091, Acc: 0.7986, Val Loss: 0.8559, Val Acc: 0.5088
Epoch 51/100, Loss: 0.4088, Acc: 0.8009, Val Loss: 0.8675, Val Acc: 0.5048
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4081, Acc: 0.8001, Val Loss: 0.8746, Val Acc: 0.5037
Epoch 53/100, Loss: 0.4079, Acc: 0.8013, Val Loss: 0.8645, Val Acc: 0.5044
Epoch 54/100, Loss: 0.4080, Acc: 0.8015, Val Loss: 0.8742, Val Acc: 0.5044
Epoch 55/100, Loss: 0.4080, Acc: 0.8004, Val Loss: 0.8772, Val Acc: 0.5015
Epoch 56/100, Loss: 0.4077, Acc: 0.8016, Val Loss: 0.8503, Val Acc: 0.5059
Epoch 57/100, Loss: 0.4075, Acc: 0.8002, Val Loss: 0.8838, Val Acc: 0.5029
Epoch 58/100, Loss: 0.4077, Acc: 0.8015, Val Loss: 0.8846, Val Acc: 0.5022
Epoch 59/100, Loss: 0.4078, Acc: 0.8009, Val Loss: 0.8593, Val Acc: 0.5059
Epoch 60/100, Loss: 0.4076, Acc: 0.8018, Val Loss: 0.8688, Val Acc: 0.4985
Epoch 61/100, Loss: 0.4073, Acc: 0.8032, Val Loss: 0.8694, Val Acc: 0.5033
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4069, Acc: 0.8018, Val Loss: 0.8701, Val Acc: 0.5040
Epoch 63/100, Loss: 0.4066, Acc: 0.8014, Val Loss: 0.8682, Val Acc: 0.5077
Epoch 64/100, Loss: 0.4066, Acc: 0.8025, Val Loss: 0.8691, Val Acc: 0.5015
Epoch 65/100, Loss: 0.4067, Acc: 0.8016, Val Loss: 0.8698, Val Acc: 0.5029
Epoch 66/100, Loss: 0.4066, Acc: 0.8001, Val Loss: 0.8613, Val Acc: 0.5052
Epoch 67/100, Loss: 0.4067, Acc: 0.8046, Val Loss: 0.8697, Val Acc: 0.5048
Epoch 68/100, Loss: 0.4067, Acc: 0.8005, Val Loss: 0.8700, Val Acc: 0.5066
Epoch 69/100, Loss: 0.4065, Acc: 0.8024, Val Loss: 0.8642, Val Acc: 0.5055
Epoch 70/100, Loss: 0.4065, Acc: 0.8022, Val Loss: 0.8692, Val Acc: 0.5040
Epoch 71/100, Loss: 0.4063, Acc: 0.8021, Val Loss: 0.8665, Val Acc: 0.5033
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4062, Acc: 0.8028, Val Loss: 0.8647, Val Acc: 0.5040
Epoch 73/100, Loss: 0.4061, Acc: 0.8016, Val Loss: 0.8680, Val Acc: 0.5048
Epoch 74/100, Loss: 0.4061, Acc: 0.8028, Val Loss: 0.8641, Val Acc: 0.5052
Epoch 75/100, Loss: 0.4060, Acc: 0.8027, Val Loss: 0.8621, Val Acc: 0.5048
Epoch 76/100, Loss: 0.4058, Acc: 0.8030, Val Loss: 0.8707, Val Acc: 0.5044
Epoch 77/100, Loss: 0.4057, Acc: 0.8022, Val Loss: 0.8704, Val Acc: 0.5018
Epoch 78/100, Loss: 0.4057, Acc: 0.8022, Val Loss: 0.8722, Val Acc: 0.5018
Epoch 79/100, Loss: 0.4056, Acc: 0.8027, Val Loss: 0.8659, Val Acc: 0.5033
Epoch 80/100, Loss: 0.4055, Acc: 0.8027, Val Loss: 0.8734, Val Acc: 0.5048
Epoch 81/100, Loss: 0.4056, Acc: 0.8026, Val Loss: 0.8721, Val Acc: 0.5026
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4054, Acc: 0.8037, Val Loss: 0.8697, Val Acc: 0.5026
Epoch 83/100, Loss: 0.4054, Acc: 0.8029, Val Loss: 0.8654, Val Acc: 0.5026
Epoch 84/100, Loss: 0.4054, Acc: 0.8039, Val Loss: 0.8671, Val Acc: 0.5029
Epoch 85/100, Loss: 0.4054, Acc: 0.8040, Val Loss: 0.8662, Val Acc: 0.5029
Epoch 86/100, Loss: 0.4054, Acc: 0.8036, Val Loss: 0.8632, Val Acc: 0.5033
Epoch 87/100, Loss: 0.4054, Acc: 0.8041, Val Loss: 0.8765, Val Acc: 0.5004
Epoch 88/100, Loss: 0.4053, Acc: 0.8035, Val Loss: 0.8699, Val Acc: 0.5029
Epoch 89/100, Loss: 0.4052, Acc: 0.8028, Val Loss: 0.8659, Val Acc: 0.5026
Epoch 90/100, Loss: 0.4053, Acc: 0.8040, Val Loss: 0.8697, Val Acc: 0.5029
Epoch 91/100, Loss: 0.4052, Acc: 0.8039, Val Loss: 0.8806, Val Acc: 0.5037
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4055, Acc: 0.8025, Val Loss: 0.8723, Val Acc: 0.5040
Epoch 93/100, Loss: 0.4053, Acc: 0.8033, Val Loss: 0.8701, Val Acc: 0.5026
Epoch 94/100, Loss: 0.4053, Acc: 0.8041, Val Loss: 0.8723, Val Acc: 0.5011
Epoch 95/100, Loss: 0.4051, Acc: 0.8033, Val Loss: 0.8687, Val Acc: 0.5026
Epoch 96/100, Loss: 0.4051, Acc: 0.8035, Val Loss: 0.8696, Val Acc: 0.5033
Epoch 97/100, Loss: 0.4051, Acc: 0.8040, Val Loss: 0.8683, Val Acc: 0.5026
Epoch 98/100, Loss: 0.4051, Acc: 0.8041, Val Loss: 0.8627, Val Acc: 0.5048
Epoch 99/100, Loss: 0.4049, Acc: 0.8037, Val Loss: 0.8732, Val Acc: 0.5048
Epoch 100/100, Loss: 0.4049, Acc: 0.8031, Val Loss: 0.8697, Val Acc: 0.5022

##############################
Resultados para principal:  001  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3 
 {'training': [0.40493717831293213, 0.803088803088803, 0.7791327913279132, 0.8458992276572269, 0.811144418973726], 'validate': [0.8697160378445027, 0.5022075055187638, 0.5011720581340835, 0.7871870397643593, 0.6124319679175021], 'test': [0.7296822645046093, 0.5541494997057093, 0.637593984962406, 0.2497055359246172, 0.35886584849767245]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  082  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  082  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  082  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6874, Acc: 0.5601, Val Loss: 0.6903, Val Acc: 0.5614
Mejor modelo guardado con Val Loss: 0.6903
Epoch 2/100, Loss: 0.6749, Acc: 0.6163, Val Loss: 0.6885, Val Acc: 0.5740
Mejor modelo guardado con Val Loss: 0.6885
Epoch 3/100, Loss: 0.6579, Acc: 0.6656, Val Loss: 0.6752, Val Acc: 0.6078
Mejor modelo guardado con Val Loss: 0.6752
Epoch 4/100, Loss: 0.6391, Acc: 0.6919, Val Loss: 0.6695, Val Acc: 0.6130
Mejor modelo guardado con Val Loss: 0.6695
Epoch 5/100, Loss: 0.6247, Acc: 0.6972, Val Loss: 0.6705, Val Acc: 0.5953
Epoch 6/100, Loss: 0.6130, Acc: 0.6988, Val Loss: 0.6650, Val Acc: 0.5990
Mejor modelo guardado con Val Loss: 0.6650
Epoch 7/100, Loss: 0.6046, Acc: 0.7022, Val Loss: 0.6839, Val Acc: 0.5405
Epoch 8/100, Loss: 0.5966, Acc: 0.7060, Val Loss: 0.6560, Val Acc: 0.6229
Mejor modelo guardado con Val Loss: 0.6560
Epoch 9/100, Loss: 0.5944, Acc: 0.7035, Val Loss: 0.6932, Val Acc: 0.5651
Epoch 10/100, Loss: 0.5839, Acc: 0.7113, Val Loss: 0.6535, Val Acc: 0.6133
Mejor modelo guardado con Val Loss: 0.6535
Epoch 11/100, Loss: 0.5811, Acc: 0.7117, Val Loss: 0.6744, Val Acc: 0.6012
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5716, Acc: 0.7205, Val Loss: 0.6547, Val Acc: 0.6229
Epoch 13/100, Loss: 0.5679, Acc: 0.7174, Val Loss: 0.6733, Val Acc: 0.6030
Epoch 14/100, Loss: 0.5656, Acc: 0.7243, Val Loss: 0.6717, Val Acc: 0.6049
Epoch 15/100, Loss: 0.5651, Acc: 0.7227, Val Loss: 0.6557, Val Acc: 0.6258
Epoch 16/100, Loss: 0.5625, Acc: 0.7212, Val Loss: 0.6820, Val Acc: 0.5916
Epoch 17/100, Loss: 0.5611, Acc: 0.7249, Val Loss: 0.6609, Val Acc: 0.6177
Epoch 18/100, Loss: 0.5605, Acc: 0.7226, Val Loss: 0.6672, Val Acc: 0.6045
Epoch 19/100, Loss: 0.5618, Acc: 0.7174, Val Loss: 0.6953, Val Acc: 0.5931
Epoch 20/100, Loss: 0.5599, Acc: 0.7245, Val Loss: 0.6643, Val Acc: 0.6177
Epoch 21/100, Loss: 0.5563, Acc: 0.7257, Val Loss: 0.6612, Val Acc: 0.6262
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5536, Acc: 0.7258, Val Loss: 0.6548, Val Acc: 0.6262
Epoch 23/100, Loss: 0.5527, Acc: 0.7297, Val Loss: 0.6624, Val Acc: 0.6111
Epoch 24/100, Loss: 0.5519, Acc: 0.7253, Val Loss: 0.6697, Val Acc: 0.6056
Epoch 25/100, Loss: 0.5504, Acc: 0.7301, Val Loss: 0.6565, Val Acc: 0.6214
Epoch 26/100, Loss: 0.5503, Acc: 0.7315, Val Loss: 0.6567, Val Acc: 0.6166
Epoch 27/100, Loss: 0.5509, Acc: 0.7272, Val Loss: 0.6838, Val Acc: 0.6071
Epoch 28/100, Loss: 0.5494, Acc: 0.7309, Val Loss: 0.6607, Val Acc: 0.6177
Epoch 29/100, Loss: 0.5474, Acc: 0.7305, Val Loss: 0.6664, Val Acc: 0.6199
Epoch 30/100, Loss: 0.5478, Acc: 0.7302, Val Loss: 0.6554, Val Acc: 0.6258
Epoch 31/100, Loss: 0.5459, Acc: 0.7291, Val Loss: 0.6516, Val Acc: 0.6313
Mejor modelo guardado con Val Loss: 0.6516
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5449, Acc: 0.7337, Val Loss: 0.6623, Val Acc: 0.6144
Epoch 33/100, Loss: 0.5451, Acc: 0.7311, Val Loss: 0.6603, Val Acc: 0.6236
Epoch 34/100, Loss: 0.5439, Acc: 0.7349, Val Loss: 0.6583, Val Acc: 0.6199
Epoch 35/100, Loss: 0.5435, Acc: 0.7328, Val Loss: 0.6598, Val Acc: 0.6258
Epoch 36/100, Loss: 0.5437, Acc: 0.7309, Val Loss: 0.6663, Val Acc: 0.6155
Epoch 37/100, Loss: 0.5431, Acc: 0.7329, Val Loss: 0.6573, Val Acc: 0.6170
Epoch 38/100, Loss: 0.5424, Acc: 0.7345, Val Loss: 0.6570, Val Acc: 0.6210
Epoch 39/100, Loss: 0.5436, Acc: 0.7338, Val Loss: 0.6643, Val Acc: 0.6152
Epoch 40/100, Loss: 0.5423, Acc: 0.7313, Val Loss: 0.6604, Val Acc: 0.6174
Epoch 41/100, Loss: 0.5420, Acc: 0.7321, Val Loss: 0.6554, Val Acc: 0.6258
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5411, Acc: 0.7343, Val Loss: 0.6585, Val Acc: 0.6258
Epoch 43/100, Loss: 0.5405, Acc: 0.7354, Val Loss: 0.6574, Val Acc: 0.6196
Epoch 44/100, Loss: 0.5410, Acc: 0.7356, Val Loss: 0.6565, Val Acc: 0.6258
Epoch 45/100, Loss: 0.5397, Acc: 0.7333, Val Loss: 0.6597, Val Acc: 0.6236
Epoch 46/100, Loss: 0.5399, Acc: 0.7333, Val Loss: 0.6596, Val Acc: 0.6214
Epoch 47/100, Loss: 0.5397, Acc: 0.7342, Val Loss: 0.6589, Val Acc: 0.6170
Epoch 48/100, Loss: 0.5397, Acc: 0.7318, Val Loss: 0.6600, Val Acc: 0.6192
Epoch 49/100, Loss: 0.5390, Acc: 0.7343, Val Loss: 0.6591, Val Acc: 0.6269
Epoch 50/100, Loss: 0.5390, Acc: 0.7350, Val Loss: 0.6609, Val Acc: 0.6210
Epoch 51/100, Loss: 0.5385, Acc: 0.7351, Val Loss: 0.6651, Val Acc: 0.6133
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5381, Acc: 0.7347, Val Loss: 0.6597, Val Acc: 0.6166
Epoch 53/100, Loss: 0.5378, Acc: 0.7349, Val Loss: 0.6634, Val Acc: 0.6159
Epoch 54/100, Loss: 0.5375, Acc: 0.7358, Val Loss: 0.6597, Val Acc: 0.6229
Epoch 55/100, Loss: 0.5376, Acc: 0.7344, Val Loss: 0.6593, Val Acc: 0.6166
Epoch 56/100, Loss: 0.5371, Acc: 0.7354, Val Loss: 0.6604, Val Acc: 0.6141
Epoch 57/100, Loss: 0.5373, Acc: 0.7355, Val Loss: 0.6636, Val Acc: 0.6163
Epoch 58/100, Loss: 0.5370, Acc: 0.7352, Val Loss: 0.6581, Val Acc: 0.6210
Epoch 59/100, Loss: 0.5371, Acc: 0.7360, Val Loss: 0.6598, Val Acc: 0.6203
Epoch 60/100, Loss: 0.5368, Acc: 0.7350, Val Loss: 0.6605, Val Acc: 0.6177
Epoch 61/100, Loss: 0.5367, Acc: 0.7363, Val Loss: 0.6655, Val Acc: 0.6159
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5356, Acc: 0.7347, Val Loss: 0.6638, Val Acc: 0.6159
Epoch 63/100, Loss: 0.5354, Acc: 0.7341, Val Loss: 0.6621, Val Acc: 0.6177
Epoch 64/100, Loss: 0.5354, Acc: 0.7339, Val Loss: 0.6620, Val Acc: 0.6181
Epoch 65/100, Loss: 0.5352, Acc: 0.7350, Val Loss: 0.6608, Val Acc: 0.6185
Epoch 66/100, Loss: 0.5352, Acc: 0.7343, Val Loss: 0.6619, Val Acc: 0.6170
Epoch 67/100, Loss: 0.5352, Acc: 0.7342, Val Loss: 0.6614, Val Acc: 0.6174
Epoch 68/100, Loss: 0.5350, Acc: 0.7352, Val Loss: 0.6634, Val Acc: 0.6174
Epoch 69/100, Loss: 0.5349, Acc: 0.7348, Val Loss: 0.6602, Val Acc: 0.6174
Epoch 70/100, Loss: 0.5349, Acc: 0.7345, Val Loss: 0.6606, Val Acc: 0.6166
Epoch 71/100, Loss: 0.5349, Acc: 0.7368, Val Loss: 0.6634, Val Acc: 0.6166
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5348, Acc: 0.7348, Val Loss: 0.6623, Val Acc: 0.6185
Epoch 73/100, Loss: 0.5346, Acc: 0.7360, Val Loss: 0.6626, Val Acc: 0.6181
Epoch 74/100, Loss: 0.5346, Acc: 0.7351, Val Loss: 0.6624, Val Acc: 0.6188
Epoch 75/100, Loss: 0.5346, Acc: 0.7356, Val Loss: 0.6624, Val Acc: 0.6196
Epoch 76/100, Loss: 0.5345, Acc: 0.7353, Val Loss: 0.6620, Val Acc: 0.6185
Epoch 77/100, Loss: 0.5345, Acc: 0.7345, Val Loss: 0.6628, Val Acc: 0.6177
Epoch 78/100, Loss: 0.5344, Acc: 0.7353, Val Loss: 0.6621, Val Acc: 0.6170
Epoch 79/100, Loss: 0.5343, Acc: 0.7360, Val Loss: 0.6609, Val Acc: 0.6188
Epoch 80/100, Loss: 0.5342, Acc: 0.7362, Val Loss: 0.6619, Val Acc: 0.6181
Epoch 81/100, Loss: 0.5341, Acc: 0.7359, Val Loss: 0.6604, Val Acc: 0.6177
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5341, Acc: 0.7377, Val Loss: 0.6620, Val Acc: 0.6185
Epoch 83/100, Loss: 0.5340, Acc: 0.7361, Val Loss: 0.6617, Val Acc: 0.6181
Epoch 84/100, Loss: 0.5339, Acc: 0.7365, Val Loss: 0.6629, Val Acc: 0.6163
Epoch 85/100, Loss: 0.5339, Acc: 0.7360, Val Loss: 0.6617, Val Acc: 0.6174
Epoch 86/100, Loss: 0.5338, Acc: 0.7363, Val Loss: 0.6602, Val Acc: 0.6170
Epoch 87/100, Loss: 0.5335, Acc: 0.7369, Val Loss: 0.6606, Val Acc: 0.6199
Epoch 88/100, Loss: 0.5327, Acc: 0.7361, Val Loss: 0.6619, Val Acc: 0.6185
Epoch 89/100, Loss: 0.5315, Acc: 0.7351, Val Loss: 0.6637, Val Acc: 0.6133
Epoch 90/100, Loss: 0.5307, Acc: 0.7333, Val Loss: 0.6624, Val Acc: 0.6185
Epoch 91/100, Loss: 0.5304, Acc: 0.7347, Val Loss: 0.6654, Val Acc: 0.6126
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5303, Acc: 0.7338, Val Loss: 0.6644, Val Acc: 0.6166
Epoch 93/100, Loss: 0.5300, Acc: 0.7332, Val Loss: 0.6657, Val Acc: 0.6115
Epoch 94/100, Loss: 0.5298, Acc: 0.7336, Val Loss: 0.6660, Val Acc: 0.6085
Epoch 95/100, Loss: 0.5296, Acc: 0.7322, Val Loss: 0.6652, Val Acc: 0.6089
Epoch 96/100, Loss: 0.5295, Acc: 0.7325, Val Loss: 0.6677, Val Acc: 0.6089
Epoch 97/100, Loss: 0.5295, Acc: 0.7324, Val Loss: 0.6651, Val Acc: 0.6085
Epoch 98/100, Loss: 0.5293, Acc: 0.7325, Val Loss: 0.6657, Val Acc: 0.6078
Epoch 99/100, Loss: 0.5292, Acc: 0.7329, Val Loss: 0.6659, Val Acc: 0.6085
Epoch 100/100, Loss: 0.5291, Acc: 0.7322, Val Loss: 0.6656, Val Acc: 0.6082

##############################
Resultados para principal:  082  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3 
 {'training': [0.529122769350426, 0.7322118036403751, 0.708161582852432, 0.7898124310408239, 0.7467617143353907], 'validate': [0.6655551451583241, 0.608167770419426, 0.5828151498021481, 0.7592047128129602, 0.6594179724976016], 'test': [0.7106344821276488, 0.5373749264273102, 0.5284039675383229, 0.690223792697291, 0.5985699693564862]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  103  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  103  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  103  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6656, Acc: 0.6454, Val Loss: 0.6883, Val Acc: 0.5482
Mejor modelo guardado con Val Loss: 0.6883
Epoch 2/100, Loss: 0.6160, Acc: 0.7213, Val Loss: 0.6582, Val Acc: 0.6225
Mejor modelo guardado con Val Loss: 0.6582
Epoch 3/100, Loss: 0.5767, Acc: 0.7357, Val Loss: 0.6728, Val Acc: 0.5923
Epoch 4/100, Loss: 0.5480, Acc: 0.7527, Val Loss: 0.6741, Val Acc: 0.5894
Epoch 5/100, Loss: 0.5370, Acc: 0.7481, Val Loss: 0.6606, Val Acc: 0.6038
Epoch 6/100, Loss: 0.5300, Acc: 0.7468, Val Loss: 0.6481, Val Acc: 0.6258
Mejor modelo guardado con Val Loss: 0.6481
Epoch 7/100, Loss: 0.5226, Acc: 0.7519, Val Loss: 0.6881, Val Acc: 0.5890
Epoch 8/100, Loss: 0.5124, Acc: 0.7599, Val Loss: 0.6347, Val Acc: 0.6637
Mejor modelo guardado con Val Loss: 0.6347
Epoch 9/100, Loss: 0.5091, Acc: 0.7618, Val Loss: 0.7187, Val Acc: 0.5769
Epoch 10/100, Loss: 0.5063, Acc: 0.7593, Val Loss: 0.6680, Val Acc: 0.6280
Epoch 11/100, Loss: 0.5118, Acc: 0.7556, Val Loss: 0.6757, Val Acc: 0.6148
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4953, Acc: 0.7676, Val Loss: 0.7048, Val Acc: 0.6052
Epoch 13/100, Loss: 0.4919, Acc: 0.7700, Val Loss: 0.7455, Val Acc: 0.5743
Epoch 14/100, Loss: 0.4954, Acc: 0.7651, Val Loss: 0.7317, Val Acc: 0.5854
Epoch 15/100, Loss: 0.4904, Acc: 0.7713, Val Loss: 0.6917, Val Acc: 0.6188
Epoch 16/100, Loss: 0.4873, Acc: 0.7713, Val Loss: 0.6906, Val Acc: 0.6026
Epoch 17/100, Loss: 0.4893, Acc: 0.7676, Val Loss: 0.7209, Val Acc: 0.5935
Epoch 18/100, Loss: 0.4850, Acc: 0.7757, Val Loss: 0.6879, Val Acc: 0.6115
Epoch 19/100, Loss: 0.4945, Acc: 0.7691, Val Loss: 0.6988, Val Acc: 0.5949
Epoch 20/100, Loss: 0.4881, Acc: 0.7719, Val Loss: 0.6671, Val Acc: 0.6310
Epoch 21/100, Loss: 0.4862, Acc: 0.7767, Val Loss: 0.7330, Val Acc: 0.5876
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4813, Acc: 0.7783, Val Loss: 0.6843, Val Acc: 0.6218
Epoch 23/100, Loss: 0.4813, Acc: 0.7765, Val Loss: 0.6636, Val Acc: 0.6137
Epoch 24/100, Loss: 0.4785, Acc: 0.7787, Val Loss: 0.6833, Val Acc: 0.6078
Epoch 25/100, Loss: 0.4795, Acc: 0.7787, Val Loss: 0.6637, Val Acc: 0.6225
Epoch 26/100, Loss: 0.4795, Acc: 0.7778, Val Loss: 0.6938, Val Acc: 0.6148
Epoch 27/100, Loss: 0.4786, Acc: 0.7788, Val Loss: 0.6894, Val Acc: 0.6056
Epoch 28/100, Loss: 0.4787, Acc: 0.7785, Val Loss: 0.7340, Val Acc: 0.5876
Epoch 29/100, Loss: 0.4761, Acc: 0.7816, Val Loss: 0.6759, Val Acc: 0.6159
Epoch 30/100, Loss: 0.4758, Acc: 0.7785, Val Loss: 0.6862, Val Acc: 0.6148
Epoch 31/100, Loss: 0.4768, Acc: 0.7794, Val Loss: 0.7097, Val Acc: 0.6041
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4738, Acc: 0.7825, Val Loss: 0.7042, Val Acc: 0.6115
Epoch 33/100, Loss: 0.4726, Acc: 0.7829, Val Loss: 0.6876, Val Acc: 0.6159
Epoch 34/100, Loss: 0.4733, Acc: 0.7832, Val Loss: 0.7142, Val Acc: 0.6060
Epoch 35/100, Loss: 0.4726, Acc: 0.7853, Val Loss: 0.6959, Val Acc: 0.6115
Epoch 36/100, Loss: 0.4720, Acc: 0.7819, Val Loss: 0.6746, Val Acc: 0.6247
Epoch 37/100, Loss: 0.4716, Acc: 0.7829, Val Loss: 0.6873, Val Acc: 0.6207
Epoch 38/100, Loss: 0.4722, Acc: 0.7824, Val Loss: 0.6841, Val Acc: 0.6233
Epoch 39/100, Loss: 0.4711, Acc: 0.7831, Val Loss: 0.6915, Val Acc: 0.6159
Epoch 40/100, Loss: 0.4706, Acc: 0.7857, Val Loss: 0.7157, Val Acc: 0.6056
Epoch 41/100, Loss: 0.4710, Acc: 0.7830, Val Loss: 0.6747, Val Acc: 0.6280
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4701, Acc: 0.7856, Val Loss: 0.6950, Val Acc: 0.6133
Epoch 43/100, Loss: 0.4702, Acc: 0.7862, Val Loss: 0.6947, Val Acc: 0.6115
Epoch 44/100, Loss: 0.4701, Acc: 0.7863, Val Loss: 0.6923, Val Acc: 0.6166
Epoch 45/100, Loss: 0.4691, Acc: 0.7861, Val Loss: 0.6932, Val Acc: 0.6155
Epoch 46/100, Loss: 0.4691, Acc: 0.7868, Val Loss: 0.6865, Val Acc: 0.6177
Epoch 47/100, Loss: 0.4693, Acc: 0.7858, Val Loss: 0.6895, Val Acc: 0.6188
Epoch 48/100, Loss: 0.4698, Acc: 0.7852, Val Loss: 0.7035, Val Acc: 0.6082
Epoch 49/100, Loss: 0.4688, Acc: 0.7864, Val Loss: 0.7045, Val Acc: 0.6111
Epoch 50/100, Loss: 0.4687, Acc: 0.7866, Val Loss: 0.7055, Val Acc: 0.6093
Epoch 51/100, Loss: 0.4693, Acc: 0.7864, Val Loss: 0.6994, Val Acc: 0.6137
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4681, Acc: 0.7864, Val Loss: 0.7002, Val Acc: 0.6115
Epoch 53/100, Loss: 0.4680, Acc: 0.7868, Val Loss: 0.6949, Val Acc: 0.6152
Epoch 54/100, Loss: 0.4680, Acc: 0.7854, Val Loss: 0.6989, Val Acc: 0.6133
Epoch 55/100, Loss: 0.4679, Acc: 0.7868, Val Loss: 0.6937, Val Acc: 0.6152
Epoch 56/100, Loss: 0.4678, Acc: 0.7867, Val Loss: 0.6958, Val Acc: 0.6144
Epoch 57/100, Loss: 0.4677, Acc: 0.7860, Val Loss: 0.6993, Val Acc: 0.6111
Epoch 58/100, Loss: 0.4678, Acc: 0.7855, Val Loss: 0.7027, Val Acc: 0.6107
Epoch 59/100, Loss: 0.4674, Acc: 0.7875, Val Loss: 0.6939, Val Acc: 0.6144
Epoch 60/100, Loss: 0.4677, Acc: 0.7872, Val Loss: 0.6853, Val Acc: 0.6192
Epoch 61/100, Loss: 0.4677, Acc: 0.7865, Val Loss: 0.6953, Val Acc: 0.6155
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4671, Acc: 0.7870, Val Loss: 0.6966, Val Acc: 0.6152
Epoch 63/100, Loss: 0.4669, Acc: 0.7878, Val Loss: 0.6995, Val Acc: 0.6118
Epoch 64/100, Loss: 0.4670, Acc: 0.7872, Val Loss: 0.7012, Val Acc: 0.6111
Epoch 65/100, Loss: 0.4669, Acc: 0.7868, Val Loss: 0.6978, Val Acc: 0.6133
Epoch 66/100, Loss: 0.4669, Acc: 0.7868, Val Loss: 0.7010, Val Acc: 0.6107
Epoch 67/100, Loss: 0.4668, Acc: 0.7871, Val Loss: 0.6940, Val Acc: 0.6163
Epoch 68/100, Loss: 0.4668, Acc: 0.7870, Val Loss: 0.6973, Val Acc: 0.6133
Epoch 69/100, Loss: 0.4668, Acc: 0.7878, Val Loss: 0.6990, Val Acc: 0.6141
Epoch 70/100, Loss: 0.4667, Acc: 0.7872, Val Loss: 0.6994, Val Acc: 0.6118
Epoch 71/100, Loss: 0.4667, Acc: 0.7878, Val Loss: 0.6968, Val Acc: 0.6148
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4666, Acc: 0.7881, Val Loss: 0.6961, Val Acc: 0.6148
Epoch 73/100, Loss: 0.4666, Acc: 0.7878, Val Loss: 0.6974, Val Acc: 0.6148
Epoch 74/100, Loss: 0.4666, Acc: 0.7872, Val Loss: 0.6974, Val Acc: 0.6152
Epoch 75/100, Loss: 0.4665, Acc: 0.7869, Val Loss: 0.7004, Val Acc: 0.6118
Epoch 76/100, Loss: 0.4665, Acc: 0.7877, Val Loss: 0.6949, Val Acc: 0.6148
Epoch 77/100, Loss: 0.4665, Acc: 0.7872, Val Loss: 0.6993, Val Acc: 0.6126
Epoch 78/100, Loss: 0.4665, Acc: 0.7877, Val Loss: 0.6973, Val Acc: 0.6148
Epoch 79/100, Loss: 0.4664, Acc: 0.7877, Val Loss: 0.6960, Val Acc: 0.6155
Epoch 80/100, Loss: 0.4664, Acc: 0.7876, Val Loss: 0.6962, Val Acc: 0.6144
Epoch 81/100, Loss: 0.4664, Acc: 0.7873, Val Loss: 0.6953, Val Acc: 0.6148
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4665, Acc: 0.7885, Val Loss: 0.6982, Val Acc: 0.6141
Epoch 83/100, Loss: 0.4664, Acc: 0.7884, Val Loss: 0.6956, Val Acc: 0.6152
Epoch 84/100, Loss: 0.4664, Acc: 0.7876, Val Loss: 0.6997, Val Acc: 0.6133
Epoch 85/100, Loss: 0.4663, Acc: 0.7873, Val Loss: 0.6968, Val Acc: 0.6148
Epoch 86/100, Loss: 0.4662, Acc: 0.7876, Val Loss: 0.7021, Val Acc: 0.6118
Epoch 87/100, Loss: 0.4663, Acc: 0.7879, Val Loss: 0.7002, Val Acc: 0.6118
Epoch 88/100, Loss: 0.4663, Acc: 0.7876, Val Loss: 0.7006, Val Acc: 0.6118
Epoch 89/100, Loss: 0.4661, Acc: 0.7866, Val Loss: 0.6991, Val Acc: 0.6148
Epoch 90/100, Loss: 0.4662, Acc: 0.7879, Val Loss: 0.6987, Val Acc: 0.6137
Epoch 91/100, Loss: 0.4662, Acc: 0.7878, Val Loss: 0.7005, Val Acc: 0.6111
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4661, Acc: 0.7878, Val Loss: 0.6943, Val Acc: 0.6163
Epoch 93/100, Loss: 0.4662, Acc: 0.7871, Val Loss: 0.6937, Val Acc: 0.6174
Epoch 94/100, Loss: 0.4662, Acc: 0.7875, Val Loss: 0.6967, Val Acc: 0.6152
Epoch 95/100, Loss: 0.4661, Acc: 0.7885, Val Loss: 0.6979, Val Acc: 0.6144
Epoch 96/100, Loss: 0.4660, Acc: 0.7874, Val Loss: 0.7016, Val Acc: 0.6118
Epoch 97/100, Loss: 0.4662, Acc: 0.7874, Val Loss: 0.6997, Val Acc: 0.6126
Epoch 98/100, Loss: 0.4661, Acc: 0.7876, Val Loss: 0.6982, Val Acc: 0.6144
Epoch 99/100, Loss: 0.4661, Acc: 0.7876, Val Loss: 0.6976, Val Acc: 0.6152
Epoch 100/100, Loss: 0.4661, Acc: 0.7874, Val Loss: 0.7000, Val Acc: 0.6126

##############################
Resultados para principal:  103  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3 
 {'training': [0.46607563290269, 0.7873690016547159, 0.7556864670266732, 0.8492092681132769, 0.7997229197333102], 'validate': [0.6999793648719788, 0.6125827814569537, 0.5799685369690614, 0.8144329896907216, 0.6774885145482389], 'test': [0.3762772709683136, 0.8731606827545615, 0.994535519125683, 0.7502944640753828, 0.855320577374958]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  117  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  117  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  117  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6152, Acc: 0.7032, Val Loss: 0.4955, Val Acc: 0.8164
Mejor modelo guardado con Val Loss: 0.4955
Epoch 2/100, Loss: 0.5700, Acc: 0.7125, Val Loss: 0.4652, Val Acc: 0.8142
Mejor modelo guardado con Val Loss: 0.4652
Epoch 3/100, Loss: 0.5570, Acc: 0.7149, Val Loss: 0.4116, Val Acc: 0.8801
Mejor modelo guardado con Val Loss: 0.4116
Epoch 4/100, Loss: 0.5466, Acc: 0.7198, Val Loss: 0.4056, Val Acc: 0.8572
Mejor modelo guardado con Val Loss: 0.4056
Epoch 5/100, Loss: 0.5456, Acc: 0.7164, Val Loss: 0.4800, Val Acc: 0.8745
Epoch 6/100, Loss: 0.5473, Acc: 0.7173, Val Loss: 0.3876, Val Acc: 0.8613
Mejor modelo guardado con Val Loss: 0.3876
Epoch 7/100, Loss: 0.5438, Acc: 0.7201, Val Loss: 0.4458, Val Acc: 0.7984
Epoch 8/100, Loss: 0.5354, Acc: 0.7224, Val Loss: 0.5026, Val Acc: 0.7193
Epoch 9/100, Loss: 0.5381, Acc: 0.7207, Val Loss: 0.4334, Val Acc: 0.8469
Epoch 10/100, Loss: 0.5402, Acc: 0.7224, Val Loss: 0.4564, Val Acc: 0.8091
Epoch 11/100, Loss: 0.5390, Acc: 0.7194, Val Loss: 0.3566, Val Acc: 0.8900
Mejor modelo guardado con Val Loss: 0.3566
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5283, Acc: 0.7208, Val Loss: 0.4099, Val Acc: 0.8481
Epoch 13/100, Loss: 0.5258, Acc: 0.7291, Val Loss: 0.4120, Val Acc: 0.8094
Epoch 14/100, Loss: 0.5256, Acc: 0.7204, Val Loss: 0.4338, Val Acc: 0.7336
Epoch 15/100, Loss: 0.5248, Acc: 0.7249, Val Loss: 0.3965, Val Acc: 0.8333
Epoch 16/100, Loss: 0.5198, Acc: 0.7264, Val Loss: 0.3483, Val Acc: 0.8668
Mejor modelo guardado con Val Loss: 0.3483
Epoch 17/100, Loss: 0.5214, Acc: 0.7275, Val Loss: 0.3956, Val Acc: 0.8315
Epoch 18/100, Loss: 0.5196, Acc: 0.7285, Val Loss: 0.4765, Val Acc: 0.7042
Epoch 19/100, Loss: 0.5185, Acc: 0.7299, Val Loss: 0.4360, Val Acc: 0.7770
Epoch 20/100, Loss: 0.5156, Acc: 0.7278, Val Loss: 0.4132, Val Acc: 0.8558
Epoch 21/100, Loss: 0.5201, Acc: 0.7272, Val Loss: 0.3988, Val Acc: 0.7962
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5153, Acc: 0.7300, Val Loss: 0.4276, Val Acc: 0.7656
Epoch 23/100, Loss: 0.5157, Acc: 0.7298, Val Loss: 0.3758, Val Acc: 0.8245
Epoch 24/100, Loss: 0.5165, Acc: 0.7303, Val Loss: 0.4077, Val Acc: 0.7726
Epoch 25/100, Loss: 0.5144, Acc: 0.7301, Val Loss: 0.3512, Val Acc: 0.8182
Epoch 26/100, Loss: 0.5141, Acc: 0.7309, Val Loss: 0.3871, Val Acc: 0.7980
Epoch 27/100, Loss: 0.5099, Acc: 0.7335, Val Loss: 0.3916, Val Acc: 0.8057
Epoch 28/100, Loss: 0.5098, Acc: 0.7351, Val Loss: 0.4090, Val Acc: 0.7973
Epoch 29/100, Loss: 0.5121, Acc: 0.7325, Val Loss: 0.3701, Val Acc: 0.8363
Epoch 30/100, Loss: 0.5085, Acc: 0.7356, Val Loss: 0.4146, Val Acc: 0.7708
Epoch 31/100, Loss: 0.5093, Acc: 0.7344, Val Loss: 0.3851, Val Acc: 0.8311
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5067, Acc: 0.7371, Val Loss: 0.3746, Val Acc: 0.8146
Epoch 33/100, Loss: 0.5063, Acc: 0.7331, Val Loss: 0.3803, Val Acc: 0.7899
Epoch 34/100, Loss: 0.5060, Acc: 0.7371, Val Loss: 0.3624, Val Acc: 0.8330
Epoch 35/100, Loss: 0.5063, Acc: 0.7348, Val Loss: 0.3875, Val Acc: 0.7862
Epoch 36/100, Loss: 0.5052, Acc: 0.7373, Val Loss: 0.3988, Val Acc: 0.7829
Epoch 37/100, Loss: 0.5073, Acc: 0.7345, Val Loss: 0.3758, Val Acc: 0.8043
Epoch 38/100, Loss: 0.5051, Acc: 0.7358, Val Loss: 0.3690, Val Acc: 0.8175
Epoch 39/100, Loss: 0.5051, Acc: 0.7358, Val Loss: 0.3729, Val Acc: 0.8109
Epoch 40/100, Loss: 0.5037, Acc: 0.7383, Val Loss: 0.3863, Val Acc: 0.8028
Epoch 41/100, Loss: 0.5042, Acc: 0.7348, Val Loss: 0.3628, Val Acc: 0.8322
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5033, Acc: 0.7366, Val Loss: 0.3674, Val Acc: 0.8190
Epoch 43/100, Loss: 0.5032, Acc: 0.7375, Val Loss: 0.3618, Val Acc: 0.8194
Epoch 44/100, Loss: 0.5032, Acc: 0.7352, Val Loss: 0.3536, Val Acc: 0.8311
Epoch 45/100, Loss: 0.5030, Acc: 0.7374, Val Loss: 0.3552, Val Acc: 0.8194
Epoch 46/100, Loss: 0.5027, Acc: 0.7380, Val Loss: 0.3842, Val Acc: 0.7837
Epoch 47/100, Loss: 0.5026, Acc: 0.7361, Val Loss: 0.3623, Val Acc: 0.8127
Epoch 48/100, Loss: 0.5024, Acc: 0.7375, Val Loss: 0.3641, Val Acc: 0.8124
Epoch 49/100, Loss: 0.5025, Acc: 0.7362, Val Loss: 0.3410, Val Acc: 0.8433
Mejor modelo guardado con Val Loss: 0.3410
Epoch 50/100, Loss: 0.5020, Acc: 0.7375, Val Loss: 0.3801, Val Acc: 0.7951
Epoch 51/100, Loss: 0.5025, Acc: 0.7365, Val Loss: 0.3627, Val Acc: 0.8153
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5014, Acc: 0.7370, Val Loss: 0.3706, Val Acc: 0.8039
Epoch 53/100, Loss: 0.5015, Acc: 0.7362, Val Loss: 0.3677, Val Acc: 0.8072
Epoch 54/100, Loss: 0.5014, Acc: 0.7372, Val Loss: 0.3638, Val Acc: 0.8094
Epoch 55/100, Loss: 0.5012, Acc: 0.7373, Val Loss: 0.3609, Val Acc: 0.8171
Epoch 56/100, Loss: 0.5009, Acc: 0.7368, Val Loss: 0.3643, Val Acc: 0.8076
Epoch 57/100, Loss: 0.5011, Acc: 0.7368, Val Loss: 0.3619, Val Acc: 0.8113
Epoch 58/100, Loss: 0.5011, Acc: 0.7373, Val Loss: 0.3687, Val Acc: 0.8109
Epoch 59/100, Loss: 0.5011, Acc: 0.7371, Val Loss: 0.3634, Val Acc: 0.8127
Epoch 60/100, Loss: 0.5007, Acc: 0.7373, Val Loss: 0.3646, Val Acc: 0.8072
Epoch 61/100, Loss: 0.5009, Acc: 0.7375, Val Loss: 0.3607, Val Acc: 0.8127
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5004, Acc: 0.7379, Val Loss: 0.3603, Val Acc: 0.8157
Epoch 63/100, Loss: 0.5004, Acc: 0.7378, Val Loss: 0.3644, Val Acc: 0.8102
Epoch 64/100, Loss: 0.5004, Acc: 0.7381, Val Loss: 0.3593, Val Acc: 0.8153
Epoch 65/100, Loss: 0.5004, Acc: 0.7375, Val Loss: 0.3639, Val Acc: 0.8098
Epoch 66/100, Loss: 0.5003, Acc: 0.7365, Val Loss: 0.3590, Val Acc: 0.8146
Epoch 67/100, Loss: 0.5002, Acc: 0.7387, Val Loss: 0.3628, Val Acc: 0.8109
Epoch 68/100, Loss: 0.5003, Acc: 0.7376, Val Loss: 0.3596, Val Acc: 0.8138
Epoch 69/100, Loss: 0.5001, Acc: 0.7386, Val Loss: 0.3714, Val Acc: 0.8028
Epoch 70/100, Loss: 0.5004, Acc: 0.7379, Val Loss: 0.3705, Val Acc: 0.8043
Epoch 71/100, Loss: 0.5001, Acc: 0.7380, Val Loss: 0.3628, Val Acc: 0.8157
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5001, Acc: 0.7386, Val Loss: 0.3647, Val Acc: 0.8109
Epoch 73/100, Loss: 0.5000, Acc: 0.7386, Val Loss: 0.3621, Val Acc: 0.8120
Epoch 74/100, Loss: 0.5000, Acc: 0.7379, Val Loss: 0.3644, Val Acc: 0.8102
Epoch 75/100, Loss: 0.5000, Acc: 0.7384, Val Loss: 0.3617, Val Acc: 0.8131
Epoch 76/100, Loss: 0.4999, Acc: 0.7382, Val Loss: 0.3646, Val Acc: 0.8094
Epoch 77/100, Loss: 0.4999, Acc: 0.7376, Val Loss: 0.3666, Val Acc: 0.8079
Epoch 78/100, Loss: 0.4999, Acc: 0.7384, Val Loss: 0.3619, Val Acc: 0.8116
Epoch 79/100, Loss: 0.4999, Acc: 0.7379, Val Loss: 0.3625, Val Acc: 0.8116
Epoch 80/100, Loss: 0.4998, Acc: 0.7386, Val Loss: 0.3671, Val Acc: 0.8065
Epoch 81/100, Loss: 0.4998, Acc: 0.7375, Val Loss: 0.3623, Val Acc: 0.8113
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4998, Acc: 0.7385, Val Loss: 0.3593, Val Acc: 0.8146
Epoch 83/100, Loss: 0.4998, Acc: 0.7368, Val Loss: 0.3613, Val Acc: 0.8116
Epoch 84/100, Loss: 0.4997, Acc: 0.7382, Val Loss: 0.3649, Val Acc: 0.8091
Epoch 85/100, Loss: 0.4997, Acc: 0.7381, Val Loss: 0.3617, Val Acc: 0.8120
Epoch 86/100, Loss: 0.4997, Acc: 0.7389, Val Loss: 0.3659, Val Acc: 0.8079
Epoch 87/100, Loss: 0.4998, Acc: 0.7378, Val Loss: 0.3636, Val Acc: 0.8098
Epoch 88/100, Loss: 0.4997, Acc: 0.7375, Val Loss: 0.3622, Val Acc: 0.8109
Epoch 89/100, Loss: 0.4996, Acc: 0.7388, Val Loss: 0.3607, Val Acc: 0.8142
Epoch 90/100, Loss: 0.4996, Acc: 0.7384, Val Loss: 0.3641, Val Acc: 0.8087
Epoch 91/100, Loss: 0.4997, Acc: 0.7383, Val Loss: 0.3643, Val Acc: 0.8087
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4996, Acc: 0.7379, Val Loss: 0.3633, Val Acc: 0.8083
Epoch 93/100, Loss: 0.4996, Acc: 0.7377, Val Loss: 0.3655, Val Acc: 0.8076
Epoch 94/100, Loss: 0.4996, Acc: 0.7378, Val Loss: 0.3632, Val Acc: 0.8091
Epoch 95/100, Loss: 0.4995, Acc: 0.7387, Val Loss: 0.3630, Val Acc: 0.8091
Epoch 96/100, Loss: 0.4995, Acc: 0.7377, Val Loss: 0.3622, Val Acc: 0.8109
Epoch 97/100, Loss: 0.4995, Acc: 0.7388, Val Loss: 0.3624, Val Acc: 0.8105
Epoch 98/100, Loss: 0.4995, Acc: 0.7375, Val Loss: 0.3639, Val Acc: 0.8091
Epoch 99/100, Loss: 0.4994, Acc: 0.7379, Val Loss: 0.3635, Val Acc: 0.8087
Epoch 100/100, Loss: 0.4994, Acc: 0.7391, Val Loss: 0.3605, Val Acc: 0.8131

##############################
Resultados para principal:  117  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  3 
 {'training': [0.4993577710756771, 0.7391064533921676, 0.689173457508731, 0.8709084222140493, 0.7694557270511779], 'validate': [0.36050914020039315, 0.8130978660779985, 0.7317339149400218, 0.9882179675994109, 0.8408521303258145], 'test': [0.3728109838234054, 0.8502060035314891, 0.7921375921375922, 0.9493521790341578, 0.8636485400482186]}

##############################
Resultados para window:  3 
 {'007:111:001:082:103:117': {'training': [0.30993995993184265, 0.8608200036771465, 0.8521177315147165, 0.873115115851416, 0.8624886466848319], 'validate': [0.2604812885699577, 0.8896247240618101, 0.8229548229548229, 0.9926362297496318, 0.8998664886515354], 'test': [0.12869043286061949, 0.9520306062389641, 0.9961215255332903, 0.9075382803297998, 0.949768875192604]}, '111:007:001:082:103:117': {'training': [0.3046031736740187, 0.862934362934363, 0.8531043120415102, 0.8767929385803604, 0.8647864333000816], 'validate': [0.20252005158122197, 0.9153789551140544, 0.8610755441741357, 0.9904270986745214, 0.9212328767123288], 'test': [1.6348721211845125, 0.3687463213655091, 0.4112743152044462, 0.6101295641931684, 0.49134455774247093]}, '001:007:111:082:103:117': {'training': [0.40493717831293213, 0.803088803088803, 0.7791327913279132, 0.8458992276572269, 0.811144418973726], 'validate': [0.8697160378445027, 0.5022075055187638, 0.5011720581340835, 0.7871870397643593, 0.6124319679175021], 'test': [0.7296822645046093, 0.5541494997057093, 0.637593984962406, 0.2497055359246172, 0.35886584849767245]}, '082:007:111:001:103:117': {'training': [0.529122769350426, 0.7322118036403751, 0.708161582852432, 0.7898124310408239, 0.7467617143353907], 'validate': [0.6655551451583241, 0.608167770419426, 0.5828151498021481, 0.7592047128129602, 0.6594179724976016], 'test': [0.7106344821276488, 0.5373749264273102, 0.5284039675383229, 0.690223792697291, 0.5985699693564862]}, '103:007:111:001:082:117': {'training': [0.46607563290269, 0.7873690016547159, 0.7556864670266732, 0.8492092681132769, 0.7997229197333102], 'validate': [0.6999793648719788, 0.6125827814569537, 0.5799685369690614, 0.8144329896907216, 0.6774885145482389], 'test': [0.3762772709683136, 0.8731606827545615, 0.994535519125683, 0.7502944640753828, 0.855320577374958]}, '117:007:111:001:082:103': {'training': [0.4993577710756771, 0.7391064533921676, 0.689173457508731, 0.8709084222140493, 0.7694557270511779], 'validate': [0.36050914020039315, 0.8130978660779985, 0.7317339149400218, 0.9882179675994109, 0.8408521303258145], 'test': [0.3728109838234054, 0.8502060035314891, 0.7921375921375922, 0.9493521790341578, 0.8636485400482186]}}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  067  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  067  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  067  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5846, Acc: 0.7096, Val Loss: 0.5320, Val Acc: 0.7792
Mejor modelo guardado con Val Loss: 0.5320
Epoch 2/100, Loss: 0.5492, Acc: 0.7249, Val Loss: 0.5142, Val Acc: 0.8194
Mejor modelo guardado con Val Loss: 0.5142
Epoch 3/100, Loss: 0.5393, Acc: 0.7302, Val Loss: 0.5267, Val Acc: 0.8046
Epoch 4/100, Loss: 0.5359, Acc: 0.7315, Val Loss: 0.5065, Val Acc: 0.8168
Mejor modelo guardado con Val Loss: 0.5065
Epoch 5/100, Loss: 0.5363, Acc: 0.7345, Val Loss: 0.5184, Val Acc: 0.8017
Epoch 6/100, Loss: 0.5318, Acc: 0.7330, Val Loss: 0.5500, Val Acc: 0.8249
Epoch 7/100, Loss: 0.5372, Acc: 0.7293, Val Loss: 0.5279, Val Acc: 0.7689
Epoch 8/100, Loss: 0.5316, Acc: 0.7366, Val Loss: 0.5289, Val Acc: 0.7737
Epoch 9/100, Loss: 0.5374, Acc: 0.7243, Val Loss: 0.5327, Val Acc: 0.8194
Epoch 10/100, Loss: 0.5318, Acc: 0.7344, Val Loss: 0.5501, Val Acc: 0.7351
Epoch 11/100, Loss: 0.5356, Acc: 0.7308, Val Loss: 0.5251, Val Acc: 0.8010
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5282, Acc: 0.7327, Val Loss: 0.5367, Val Acc: 0.7730
Epoch 13/100, Loss: 0.5244, Acc: 0.7400, Val Loss: 0.4969, Val Acc: 0.7918
Mejor modelo guardado con Val Loss: 0.4969
Epoch 14/100, Loss: 0.5242, Acc: 0.7407, Val Loss: 0.4958, Val Acc: 0.7837
Mejor modelo guardado con Val Loss: 0.4958
Epoch 15/100, Loss: 0.5246, Acc: 0.7338, Val Loss: 0.5088, Val Acc: 0.7844
Epoch 16/100, Loss: 0.5204, Acc: 0.7395, Val Loss: 0.5458, Val Acc: 0.7340
Epoch 17/100, Loss: 0.5220, Acc: 0.7367, Val Loss: 0.4723, Val Acc: 0.7980
Mejor modelo guardado con Val Loss: 0.4723
Epoch 18/100, Loss: 0.5169, Acc: 0.7396, Val Loss: 0.4916, Val Acc: 0.7675
Epoch 19/100, Loss: 0.5195, Acc: 0.7379, Val Loss: 0.4682, Val Acc: 0.8124
Mejor modelo guardado con Val Loss: 0.4682
Epoch 20/100, Loss: 0.5219, Acc: 0.7363, Val Loss: 0.5321, Val Acc: 0.7119
Epoch 21/100, Loss: 0.5196, Acc: 0.7419, Val Loss: 0.5188, Val Acc: 0.7840
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5169, Acc: 0.7390, Val Loss: 0.4717, Val Acc: 0.8061
Epoch 23/100, Loss: 0.5151, Acc: 0.7375, Val Loss: 0.4761, Val Acc: 0.7954
Epoch 24/100, Loss: 0.5145, Acc: 0.7397, Val Loss: 0.4965, Val Acc: 0.7572
Epoch 25/100, Loss: 0.5149, Acc: 0.7420, Val Loss: 0.4600, Val Acc: 0.8087
Mejor modelo guardado con Val Loss: 0.4600
Epoch 26/100, Loss: 0.5154, Acc: 0.7410, Val Loss: 0.4848, Val Acc: 0.8120
Epoch 27/100, Loss: 0.5137, Acc: 0.7420, Val Loss: 0.4759, Val Acc: 0.8017
Epoch 28/100, Loss: 0.5135, Acc: 0.7408, Val Loss: 0.4904, Val Acc: 0.7918
Epoch 29/100, Loss: 0.5131, Acc: 0.7454, Val Loss: 0.4752, Val Acc: 0.8072
Epoch 30/100, Loss: 0.5129, Acc: 0.7447, Val Loss: 0.4904, Val Acc: 0.7965
Epoch 31/100, Loss: 0.5157, Acc: 0.7359, Val Loss: 0.4944, Val Acc: 0.7877
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5114, Acc: 0.7442, Val Loss: 0.4820, Val Acc: 0.7914
Epoch 33/100, Loss: 0.5100, Acc: 0.7454, Val Loss: 0.4753, Val Acc: 0.8035
Epoch 34/100, Loss: 0.5092, Acc: 0.7451, Val Loss: 0.4913, Val Acc: 0.7726
Epoch 35/100, Loss: 0.5097, Acc: 0.7462, Val Loss: 0.4805, Val Acc: 0.7925
Epoch 36/100, Loss: 0.5084, Acc: 0.7466, Val Loss: 0.4755, Val Acc: 0.7881
Epoch 37/100, Loss: 0.5089, Acc: 0.7441, Val Loss: 0.4906, Val Acc: 0.7910
Epoch 38/100, Loss: 0.5075, Acc: 0.7466, Val Loss: 0.4799, Val Acc: 0.8061
Epoch 39/100, Loss: 0.5077, Acc: 0.7449, Val Loss: 0.4955, Val Acc: 0.7701
Epoch 40/100, Loss: 0.5067, Acc: 0.7466, Val Loss: 0.4832, Val Acc: 0.7980
Epoch 41/100, Loss: 0.5063, Acc: 0.7477, Val Loss: 0.4974, Val Acc: 0.7726
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5061, Acc: 0.7472, Val Loss: 0.4839, Val Acc: 0.7851
Epoch 43/100, Loss: 0.5055, Acc: 0.7495, Val Loss: 0.4865, Val Acc: 0.7910
Epoch 44/100, Loss: 0.5057, Acc: 0.7490, Val Loss: 0.4739, Val Acc: 0.7951
Epoch 45/100, Loss: 0.5059, Acc: 0.7477, Val Loss: 0.5004, Val Acc: 0.7642
Epoch 46/100, Loss: 0.5056, Acc: 0.7487, Val Loss: 0.4844, Val Acc: 0.7848
Epoch 47/100, Loss: 0.5055, Acc: 0.7487, Val Loss: 0.4827, Val Acc: 0.7884
Epoch 48/100, Loss: 0.5054, Acc: 0.7480, Val Loss: 0.4789, Val Acc: 0.7907
Epoch 49/100, Loss: 0.5051, Acc: 0.7487, Val Loss: 0.4744, Val Acc: 0.7965
Epoch 50/100, Loss: 0.5049, Acc: 0.7478, Val Loss: 0.4848, Val Acc: 0.7907
Epoch 51/100, Loss: 0.5046, Acc: 0.7472, Val Loss: 0.4766, Val Acc: 0.7984
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5042, Acc: 0.7487, Val Loss: 0.4839, Val Acc: 0.7822
Epoch 53/100, Loss: 0.5044, Acc: 0.7490, Val Loss: 0.4823, Val Acc: 0.7940
Epoch 54/100, Loss: 0.5041, Acc: 0.7496, Val Loss: 0.4863, Val Acc: 0.7818
Epoch 55/100, Loss: 0.5040, Acc: 0.7502, Val Loss: 0.4852, Val Acc: 0.7866
Epoch 56/100, Loss: 0.5039, Acc: 0.7486, Val Loss: 0.4841, Val Acc: 0.7873
Epoch 57/100, Loss: 0.5036, Acc: 0.7482, Val Loss: 0.4852, Val Acc: 0.7851
Epoch 58/100, Loss: 0.5035, Acc: 0.7489, Val Loss: 0.4804, Val Acc: 0.7929
Epoch 59/100, Loss: 0.5036, Acc: 0.7481, Val Loss: 0.4828, Val Acc: 0.7873
Epoch 60/100, Loss: 0.5035, Acc: 0.7487, Val Loss: 0.4856, Val Acc: 0.7837
Epoch 61/100, Loss: 0.5033, Acc: 0.7472, Val Loss: 0.4864, Val Acc: 0.7796
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5032, Acc: 0.7495, Val Loss: 0.4859, Val Acc: 0.7848
Epoch 63/100, Loss: 0.5030, Acc: 0.7495, Val Loss: 0.4818, Val Acc: 0.7884
Epoch 64/100, Loss: 0.5031, Acc: 0.7480, Val Loss: 0.4840, Val Acc: 0.7859
Epoch 65/100, Loss: 0.5030, Acc: 0.7500, Val Loss: 0.4831, Val Acc: 0.7859
Epoch 66/100, Loss: 0.5030, Acc: 0.7499, Val Loss: 0.4837, Val Acc: 0.7862
Epoch 67/100, Loss: 0.5029, Acc: 0.7494, Val Loss: 0.4827, Val Acc: 0.7866
Epoch 68/100, Loss: 0.5029, Acc: 0.7495, Val Loss: 0.4819, Val Acc: 0.7884
Epoch 69/100, Loss: 0.5024, Acc: 0.7487, Val Loss: 0.4805, Val Acc: 0.7881
Epoch 70/100, Loss: 0.5021, Acc: 0.7494, Val Loss: 0.4834, Val Acc: 0.7855
Epoch 71/100, Loss: 0.5021, Acc: 0.7486, Val Loss: 0.4822, Val Acc: 0.7859
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5019, Acc: 0.7501, Val Loss: 0.4816, Val Acc: 0.7855
Epoch 73/100, Loss: 0.5018, Acc: 0.7495, Val Loss: 0.4805, Val Acc: 0.7884
Epoch 74/100, Loss: 0.5019, Acc: 0.7489, Val Loss: 0.4812, Val Acc: 0.7873
Epoch 75/100, Loss: 0.5018, Acc: 0.7499, Val Loss: 0.4809, Val Acc: 0.7881
Epoch 76/100, Loss: 0.5018, Acc: 0.7491, Val Loss: 0.4816, Val Acc: 0.7859
Epoch 77/100, Loss: 0.5017, Acc: 0.7488, Val Loss: 0.4819, Val Acc: 0.7859
Epoch 78/100, Loss: 0.5018, Acc: 0.7495, Val Loss: 0.4811, Val Acc: 0.7866
Epoch 79/100, Loss: 0.5018, Acc: 0.7499, Val Loss: 0.4830, Val Acc: 0.7848
Epoch 80/100, Loss: 0.5017, Acc: 0.7496, Val Loss: 0.4815, Val Acc: 0.7877
Epoch 81/100, Loss: 0.5017, Acc: 0.7493, Val Loss: 0.4814, Val Acc: 0.7870
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5016, Acc: 0.7497, Val Loss: 0.4818, Val Acc: 0.7870
Epoch 83/100, Loss: 0.5016, Acc: 0.7492, Val Loss: 0.4827, Val Acc: 0.7859
Epoch 84/100, Loss: 0.5016, Acc: 0.7487, Val Loss: 0.4834, Val Acc: 0.7855
Epoch 85/100, Loss: 0.5015, Acc: 0.7491, Val Loss: 0.4821, Val Acc: 0.7851
Epoch 86/100, Loss: 0.5015, Acc: 0.7498, Val Loss: 0.4819, Val Acc: 0.7855
Epoch 87/100, Loss: 0.5015, Acc: 0.7497, Val Loss: 0.4811, Val Acc: 0.7892
Epoch 88/100, Loss: 0.5016, Acc: 0.7495, Val Loss: 0.4810, Val Acc: 0.7873
Epoch 89/100, Loss: 0.5014, Acc: 0.7501, Val Loss: 0.4815, Val Acc: 0.7873
Epoch 90/100, Loss: 0.5013, Acc: 0.7490, Val Loss: 0.4808, Val Acc: 0.7892
Epoch 91/100, Loss: 0.5010, Acc: 0.7500, Val Loss: 0.4812, Val Acc: 0.7877
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5009, Acc: 0.7494, Val Loss: 0.4827, Val Acc: 0.7862
Epoch 93/100, Loss: 0.5009, Acc: 0.7496, Val Loss: 0.4823, Val Acc: 0.7859
Epoch 94/100, Loss: 0.5008, Acc: 0.7495, Val Loss: 0.4818, Val Acc: 0.7855
Epoch 95/100, Loss: 0.5009, Acc: 0.7495, Val Loss: 0.4817, Val Acc: 0.7855
Epoch 96/100, Loss: 0.5008, Acc: 0.7493, Val Loss: 0.4828, Val Acc: 0.7855
Epoch 97/100, Loss: 0.5008, Acc: 0.7490, Val Loss: 0.4816, Val Acc: 0.7870
Epoch 98/100, Loss: 0.5008, Acc: 0.7496, Val Loss: 0.4827, Val Acc: 0.7855
Epoch 99/100, Loss: 0.5007, Acc: 0.7492, Val Loss: 0.4825, Val Acc: 0.7859
Epoch 100/100, Loss: 0.5007, Acc: 0.7497, Val Loss: 0.4816, Val Acc: 0.7873

##############################
Resultados para principal:  067  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3 
 {'training': [0.5006685289615085, 0.7496782496782497, 0.760806916426513, 0.728208900331004, 0.7441510852203326], 'validate': [0.4815915382878725, 0.7873436350257542, 0.7542372881355932, 0.8519882179675994, 0.8001383125864454], 'test': [0.5565282186424291, 0.7189523248969982, 0.8233246301131418, 0.5571260306242638, 0.6645591851071303]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  124  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  124  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  124  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6341, Acc: 0.6934, Val Loss: 0.6861, Val Acc: 0.5585
Mejor modelo guardado con Val Loss: 0.6861
Epoch 2/100, Loss: 0.5412, Acc: 0.7777, Val Loss: 0.6872, Val Acc: 0.5537
Epoch 3/100, Loss: 0.4944, Acc: 0.7927, Val Loss: 0.7380, Val Acc: 0.5364
Epoch 4/100, Loss: 0.4631, Acc: 0.8038, Val Loss: 0.6912, Val Acc: 0.5931
Epoch 5/100, Loss: 0.4617, Acc: 0.7978, Val Loss: 0.7885, Val Acc: 0.5221
Epoch 6/100, Loss: 0.4433, Acc: 0.8098, Val Loss: 0.7115, Val Acc: 0.5909
Epoch 7/100, Loss: 0.4415, Acc: 0.8069, Val Loss: 0.8451, Val Acc: 0.5210
Epoch 8/100, Loss: 0.4381, Acc: 0.8100, Val Loss: 0.8297, Val Acc: 0.5077
Epoch 9/100, Loss: 0.4342, Acc: 0.8099, Val Loss: 0.7910, Val Acc: 0.5809
Epoch 10/100, Loss: 0.4378, Acc: 0.8070, Val Loss: 0.8710, Val Acc: 0.5132
Epoch 11/100, Loss: 0.4266, Acc: 0.8152, Val Loss: 0.7975, Val Acc: 0.5386
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4232, Acc: 0.8141, Val Loss: 0.9376, Val Acc: 0.4971
Epoch 13/100, Loss: 0.4149, Acc: 0.8204, Val Loss: 0.8455, Val Acc: 0.4960
Epoch 14/100, Loss: 0.4203, Acc: 0.8172, Val Loss: 0.9299, Val Acc: 0.5162
Epoch 15/100, Loss: 0.4161, Acc: 0.8163, Val Loss: 0.8795, Val Acc: 0.5143
Epoch 16/100, Loss: 0.4103, Acc: 0.8226, Val Loss: 0.8907, Val Acc: 0.5221
Epoch 17/100, Loss: 0.4159, Acc: 0.8185, Val Loss: 0.8132, Val Acc: 0.5335
Epoch 18/100, Loss: 0.4160, Acc: 0.8170, Val Loss: 0.8991, Val Acc: 0.5096
Epoch 19/100, Loss: 0.4072, Acc: 0.8215, Val Loss: 0.9131, Val Acc: 0.5063
Epoch 20/100, Loss: 0.4086, Acc: 0.8214, Val Loss: 0.9213, Val Acc: 0.5037
Epoch 21/100, Loss: 0.4119, Acc: 0.8179, Val Loss: 0.9054, Val Acc: 0.5033
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4036, Acc: 0.8219, Val Loss: 0.8914, Val Acc: 0.5316
Epoch 23/100, Loss: 0.4027, Acc: 0.8245, Val Loss: 0.8926, Val Acc: 0.5258
Epoch 24/100, Loss: 0.4017, Acc: 0.8263, Val Loss: 0.9036, Val Acc: 0.4915
Epoch 25/100, Loss: 0.4021, Acc: 0.8229, Val Loss: 0.8963, Val Acc: 0.5235
Epoch 26/100, Loss: 0.4011, Acc: 0.8268, Val Loss: 0.8759, Val Acc: 0.5342
Epoch 27/100, Loss: 0.3995, Acc: 0.8269, Val Loss: 0.8921, Val Acc: 0.5118
Epoch 28/100, Loss: 0.4001, Acc: 0.8257, Val Loss: 0.8074, Val Acc: 0.5228
Epoch 29/100, Loss: 0.3992, Acc: 0.8274, Val Loss: 0.9118, Val Acc: 0.5140
Epoch 30/100, Loss: 0.4004, Acc: 0.8255, Val Loss: 0.8322, Val Acc: 0.5276
Epoch 31/100, Loss: 0.3978, Acc: 0.8270, Val Loss: 0.8673, Val Acc: 0.5272
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3944, Acc: 0.8261, Val Loss: 0.8845, Val Acc: 0.5077
Epoch 33/100, Loss: 0.3938, Acc: 0.8287, Val Loss: 0.8693, Val Acc: 0.5298
Epoch 34/100, Loss: 0.3933, Acc: 0.8284, Val Loss: 0.8537, Val Acc: 0.5162
Epoch 35/100, Loss: 0.3955, Acc: 0.8297, Val Loss: 0.8823, Val Acc: 0.5132
Epoch 36/100, Loss: 0.3932, Acc: 0.8286, Val Loss: 0.8474, Val Acc: 0.5195
Epoch 37/100, Loss: 0.3926, Acc: 0.8307, Val Loss: 0.8240, Val Acc: 0.5272
Epoch 38/100, Loss: 0.3926, Acc: 0.8304, Val Loss: 0.8886, Val Acc: 0.5191
Epoch 39/100, Loss: 0.3927, Acc: 0.8274, Val Loss: 0.8848, Val Acc: 0.5191
Epoch 40/100, Loss: 0.3915, Acc: 0.8302, Val Loss: 0.8912, Val Acc: 0.5177
Epoch 41/100, Loss: 0.3941, Acc: 0.8286, Val Loss: 0.8143, Val Acc: 0.5280
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3904, Acc: 0.8295, Val Loss: 0.8705, Val Acc: 0.5221
Epoch 43/100, Loss: 0.3899, Acc: 0.8320, Val Loss: 0.9056, Val Acc: 0.5158
Epoch 44/100, Loss: 0.3894, Acc: 0.8309, Val Loss: 0.8751, Val Acc: 0.5132
Epoch 45/100, Loss: 0.3889, Acc: 0.8319, Val Loss: 0.8917, Val Acc: 0.5195
Epoch 46/100, Loss: 0.3893, Acc: 0.8315, Val Loss: 0.8890, Val Acc: 0.5143
Epoch 47/100, Loss: 0.3895, Acc: 0.8315, Val Loss: 0.9000, Val Acc: 0.5199
Epoch 48/100, Loss: 0.3885, Acc: 0.8305, Val Loss: 0.8800, Val Acc: 0.5202
Epoch 49/100, Loss: 0.3881, Acc: 0.8327, Val Loss: 0.8969, Val Acc: 0.5243
Epoch 50/100, Loss: 0.3890, Acc: 0.8314, Val Loss: 0.8481, Val Acc: 0.5316
Epoch 51/100, Loss: 0.3890, Acc: 0.8320, Val Loss: 0.8943, Val Acc: 0.5210
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3874, Acc: 0.8311, Val Loss: 0.8893, Val Acc: 0.5213
Epoch 53/100, Loss: 0.3866, Acc: 0.8323, Val Loss: 0.8746, Val Acc: 0.5221
Epoch 54/100, Loss: 0.3871, Acc: 0.8312, Val Loss: 0.8802, Val Acc: 0.5247
Epoch 55/100, Loss: 0.3870, Acc: 0.8325, Val Loss: 0.8772, Val Acc: 0.5173
Epoch 56/100, Loss: 0.3872, Acc: 0.8307, Val Loss: 0.8872, Val Acc: 0.5195
Epoch 57/100, Loss: 0.3866, Acc: 0.8312, Val Loss: 0.8904, Val Acc: 0.5188
Epoch 58/100, Loss: 0.3867, Acc: 0.8342, Val Loss: 0.8845, Val Acc: 0.5173
Epoch 59/100, Loss: 0.3865, Acc: 0.8313, Val Loss: 0.8918, Val Acc: 0.5180
Epoch 60/100, Loss: 0.3864, Acc: 0.8330, Val Loss: 0.8792, Val Acc: 0.5261
Epoch 61/100, Loss: 0.3867, Acc: 0.8319, Val Loss: 0.8830, Val Acc: 0.5202
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3859, Acc: 0.8333, Val Loss: 0.8858, Val Acc: 0.5184
Epoch 63/100, Loss: 0.3857, Acc: 0.8324, Val Loss: 0.8865, Val Acc: 0.5199
Epoch 64/100, Loss: 0.3856, Acc: 0.8326, Val Loss: 0.8818, Val Acc: 0.5195
Epoch 65/100, Loss: 0.3856, Acc: 0.8322, Val Loss: 0.8955, Val Acc: 0.5162
Epoch 66/100, Loss: 0.3860, Acc: 0.8320, Val Loss: 0.8863, Val Acc: 0.5188
Epoch 67/100, Loss: 0.3856, Acc: 0.8330, Val Loss: 0.8822, Val Acc: 0.5206
Epoch 68/100, Loss: 0.3857, Acc: 0.8338, Val Loss: 0.8855, Val Acc: 0.5195
Epoch 69/100, Loss: 0.3857, Acc: 0.8331, Val Loss: 0.8903, Val Acc: 0.5188
Epoch 70/100, Loss: 0.3856, Acc: 0.8334, Val Loss: 0.8904, Val Acc: 0.5210
Epoch 71/100, Loss: 0.3857, Acc: 0.8322, Val Loss: 0.8908, Val Acc: 0.5191
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3853, Acc: 0.8328, Val Loss: 0.8863, Val Acc: 0.5195
Epoch 73/100, Loss: 0.3852, Acc: 0.8327, Val Loss: 0.8800, Val Acc: 0.5199
Epoch 74/100, Loss: 0.3852, Acc: 0.8331, Val Loss: 0.8811, Val Acc: 0.5184
Epoch 75/100, Loss: 0.3851, Acc: 0.8341, Val Loss: 0.8844, Val Acc: 0.5191
Epoch 76/100, Loss: 0.3852, Acc: 0.8341, Val Loss: 0.8869, Val Acc: 0.5195
Epoch 77/100, Loss: 0.3853, Acc: 0.8339, Val Loss: 0.8860, Val Acc: 0.5188
Epoch 78/100, Loss: 0.3851, Acc: 0.8333, Val Loss: 0.8846, Val Acc: 0.5202
Epoch 79/100, Loss: 0.3851, Acc: 0.8327, Val Loss: 0.8792, Val Acc: 0.5232
Epoch 80/100, Loss: 0.3843, Acc: 0.8329, Val Loss: 0.8888, Val Acc: 0.5224
Epoch 81/100, Loss: 0.3835, Acc: 0.8330, Val Loss: 0.8776, Val Acc: 0.5269
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3831, Acc: 0.8332, Val Loss: 0.8710, Val Acc: 0.5305
Epoch 83/100, Loss: 0.3831, Acc: 0.8331, Val Loss: 0.8724, Val Acc: 0.5283
Epoch 84/100, Loss: 0.3831, Acc: 0.8333, Val Loss: 0.8725, Val Acc: 0.5283
Epoch 85/100, Loss: 0.3830, Acc: 0.8334, Val Loss: 0.8688, Val Acc: 0.5294
Epoch 86/100, Loss: 0.3830, Acc: 0.8337, Val Loss: 0.8741, Val Acc: 0.5280
Epoch 87/100, Loss: 0.3829, Acc: 0.8332, Val Loss: 0.8727, Val Acc: 0.5302
Epoch 88/100, Loss: 0.3829, Acc: 0.8332, Val Loss: 0.8754, Val Acc: 0.5280
Epoch 89/100, Loss: 0.3829, Acc: 0.8326, Val Loss: 0.8832, Val Acc: 0.5258
Epoch 90/100, Loss: 0.3828, Acc: 0.8331, Val Loss: 0.8760, Val Acc: 0.5287
Epoch 91/100, Loss: 0.3828, Acc: 0.8331, Val Loss: 0.8765, Val Acc: 0.5283
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3828, Acc: 0.8336, Val Loss: 0.8750, Val Acc: 0.5294
Epoch 93/100, Loss: 0.3826, Acc: 0.8335, Val Loss: 0.8746, Val Acc: 0.5298
Epoch 94/100, Loss: 0.3828, Acc: 0.8337, Val Loss: 0.8751, Val Acc: 0.5291
Epoch 95/100, Loss: 0.3827, Acc: 0.8335, Val Loss: 0.8755, Val Acc: 0.5291
Epoch 96/100, Loss: 0.3826, Acc: 0.8333, Val Loss: 0.8783, Val Acc: 0.5291
Epoch 97/100, Loss: 0.3825, Acc: 0.8342, Val Loss: 0.8790, Val Acc: 0.5261
Epoch 98/100, Loss: 0.3824, Acc: 0.8338, Val Loss: 0.8677, Val Acc: 0.5305
Epoch 99/100, Loss: 0.3825, Acc: 0.8341, Val Loss: 0.8735, Val Acc: 0.5298
Epoch 100/100, Loss: 0.3824, Acc: 0.8338, Val Loss: 0.8768, Val Acc: 0.5294

##############################
Resultados para principal:  124  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3 
 {'training': [0.38241736131416654, 0.8337929766501195, 0.7937843962447394, 0.9018021331371828, 0.8443526170798898], 'validate': [0.8768062241548715, 0.5294334069168506, 0.5172564438619485, 0.8718703976435935, 0.6493007951741158], 'test': [0.7200566502632918, 0.4958799293702178, 0.4974039460020768, 0.8462897526501767, 0.6265533028122956]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  010  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  010  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  010  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6141, Acc: 0.6900, Val Loss: 0.6861, Val Acc: 0.5596
Mejor modelo guardado con Val Loss: 0.6861
Epoch 2/100, Loss: 0.5608, Acc: 0.7154, Val Loss: 0.6857, Val Acc: 0.5570
Mejor modelo guardado con Val Loss: 0.6857
Epoch 3/100, Loss: 0.5454, Acc: 0.7208, Val Loss: 0.6900, Val Acc: 0.5677
Epoch 4/100, Loss: 0.5369, Acc: 0.7240, Val Loss: 0.7088, Val Acc: 0.5883
Epoch 5/100, Loss: 0.5377, Acc: 0.7164, Val Loss: 0.6928, Val Acc: 0.5754
Epoch 6/100, Loss: 0.5312, Acc: 0.7250, Val Loss: 0.7376, Val Acc: 0.5909
Epoch 7/100, Loss: 0.5310, Acc: 0.7240, Val Loss: 0.7088, Val Acc: 0.5762
Epoch 8/100, Loss: 0.5295, Acc: 0.7263, Val Loss: 0.7074, Val Acc: 0.5353
Epoch 9/100, Loss: 0.5292, Acc: 0.7279, Val Loss: 0.7179, Val Acc: 0.5099
Epoch 10/100, Loss: 0.5280, Acc: 0.7261, Val Loss: 0.7550, Val Acc: 0.5898
Epoch 11/100, Loss: 0.5276, Acc: 0.7264, Val Loss: 0.7143, Val Acc: 0.5475
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5234, Acc: 0.7275, Val Loss: 0.7108, Val Acc: 0.6041
Epoch 13/100, Loss: 0.5223, Acc: 0.7304, Val Loss: 0.7113, Val Acc: 0.5901
Epoch 14/100, Loss: 0.5201, Acc: 0.7308, Val Loss: 0.7435, Val Acc: 0.5379
Epoch 15/100, Loss: 0.5217, Acc: 0.7283, Val Loss: 0.7241, Val Acc: 0.5644
Epoch 16/100, Loss: 0.5230, Acc: 0.7305, Val Loss: 0.7055, Val Acc: 0.5758
Epoch 17/100, Loss: 0.5212, Acc: 0.7327, Val Loss: 0.7235, Val Acc: 0.5835
Epoch 18/100, Loss: 0.5187, Acc: 0.7314, Val Loss: 0.7369, Val Acc: 0.5453
Epoch 19/100, Loss: 0.5205, Acc: 0.7295, Val Loss: 0.7208, Val Acc: 0.6012
Epoch 20/100, Loss: 0.5192, Acc: 0.7311, Val Loss: 0.7249, Val Acc: 0.6012
Epoch 21/100, Loss: 0.5174, Acc: 0.7339, Val Loss: 0.7263, Val Acc: 0.5898
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5144, Acc: 0.7370, Val Loss: 0.7331, Val Acc: 0.6015
Epoch 23/100, Loss: 0.5147, Acc: 0.7351, Val Loss: 0.7238, Val Acc: 0.5508
Epoch 24/100, Loss: 0.5142, Acc: 0.7339, Val Loss: 0.7248, Val Acc: 0.6001
Epoch 25/100, Loss: 0.5136, Acc: 0.7378, Val Loss: 0.7355, Val Acc: 0.5920
Epoch 26/100, Loss: 0.5143, Acc: 0.7377, Val Loss: 0.7202, Val Acc: 0.5868
Epoch 27/100, Loss: 0.5134, Acc: 0.7349, Val Loss: 0.7415, Val Acc: 0.5938
Epoch 28/100, Loss: 0.5136, Acc: 0.7347, Val Loss: 0.7470, Val Acc: 0.5868
Epoch 29/100, Loss: 0.5129, Acc: 0.7356, Val Loss: 0.7330, Val Acc: 0.5699
Epoch 30/100, Loss: 0.5148, Acc: 0.7345, Val Loss: 0.7268, Val Acc: 0.5732
Epoch 31/100, Loss: 0.5137, Acc: 0.7363, Val Loss: 0.7343, Val Acc: 0.5857
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5110, Acc: 0.7382, Val Loss: 0.7328, Val Acc: 0.5780
Epoch 33/100, Loss: 0.5110, Acc: 0.7375, Val Loss: 0.7563, Val Acc: 0.5920
Epoch 34/100, Loss: 0.5101, Acc: 0.7382, Val Loss: 0.7409, Val Acc: 0.5927
Epoch 35/100, Loss: 0.5103, Acc: 0.7367, Val Loss: 0.7408, Val Acc: 0.5935
Epoch 36/100, Loss: 0.5105, Acc: 0.7378, Val Loss: 0.7462, Val Acc: 0.5710
Epoch 37/100, Loss: 0.5101, Acc: 0.7382, Val Loss: 0.7340, Val Acc: 0.5780
Epoch 38/100, Loss: 0.5102, Acc: 0.7391, Val Loss: 0.7351, Val Acc: 0.5843
Epoch 39/100, Loss: 0.5095, Acc: 0.7375, Val Loss: 0.7418, Val Acc: 0.5618
Epoch 40/100, Loss: 0.5098, Acc: 0.7389, Val Loss: 0.7357, Val Acc: 0.5747
Epoch 41/100, Loss: 0.5096, Acc: 0.7398, Val Loss: 0.7539, Val Acc: 0.5887
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5085, Acc: 0.7381, Val Loss: 0.7482, Val Acc: 0.6004
Epoch 43/100, Loss: 0.5087, Acc: 0.7384, Val Loss: 0.7319, Val Acc: 0.5920
Epoch 44/100, Loss: 0.5082, Acc: 0.7403, Val Loss: 0.7396, Val Acc: 0.5990
Epoch 45/100, Loss: 0.5083, Acc: 0.7389, Val Loss: 0.7426, Val Acc: 0.5901
Epoch 46/100, Loss: 0.5085, Acc: 0.7399, Val Loss: 0.7380, Val Acc: 0.5865
Epoch 47/100, Loss: 0.5082, Acc: 0.7397, Val Loss: 0.7360, Val Acc: 0.5868
Epoch 48/100, Loss: 0.5082, Acc: 0.7405, Val Loss: 0.7329, Val Acc: 0.6019
Epoch 49/100, Loss: 0.5083, Acc: 0.7381, Val Loss: 0.7505, Val Acc: 0.5946
Epoch 50/100, Loss: 0.5079, Acc: 0.7389, Val Loss: 0.7528, Val Acc: 0.6001
Epoch 51/100, Loss: 0.5079, Acc: 0.7391, Val Loss: 0.7372, Val Acc: 0.5813
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5075, Acc: 0.7390, Val Loss: 0.7410, Val Acc: 0.5920
Epoch 53/100, Loss: 0.5077, Acc: 0.7390, Val Loss: 0.7385, Val Acc: 0.5935
Epoch 54/100, Loss: 0.5074, Acc: 0.7392, Val Loss: 0.7412, Val Acc: 0.5960
Epoch 55/100, Loss: 0.5073, Acc: 0.7394, Val Loss: 0.7473, Val Acc: 0.5986
Epoch 56/100, Loss: 0.5075, Acc: 0.7383, Val Loss: 0.7373, Val Acc: 0.5912
Epoch 57/100, Loss: 0.5073, Acc: 0.7402, Val Loss: 0.7379, Val Acc: 0.5890
Epoch 58/100, Loss: 0.5072, Acc: 0.7385, Val Loss: 0.7504, Val Acc: 0.5843
Epoch 59/100, Loss: 0.5071, Acc: 0.7394, Val Loss: 0.7530, Val Acc: 0.5872
Epoch 60/100, Loss: 0.5072, Acc: 0.7386, Val Loss: 0.7423, Val Acc: 0.5935
Epoch 61/100, Loss: 0.5070, Acc: 0.7397, Val Loss: 0.7385, Val Acc: 0.5868
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5069, Acc: 0.7393, Val Loss: 0.7426, Val Acc: 0.5968
Epoch 63/100, Loss: 0.5068, Acc: 0.7389, Val Loss: 0.7414, Val Acc: 0.5957
Epoch 64/100, Loss: 0.5067, Acc: 0.7396, Val Loss: 0.7457, Val Acc: 0.5997
Epoch 65/100, Loss: 0.5069, Acc: 0.7386, Val Loss: 0.7424, Val Acc: 0.5982
Epoch 66/100, Loss: 0.5068, Acc: 0.7401, Val Loss: 0.7465, Val Acc: 0.5968
Epoch 67/100, Loss: 0.5068, Acc: 0.7388, Val Loss: 0.7443, Val Acc: 0.5938
Epoch 68/100, Loss: 0.5067, Acc: 0.7398, Val Loss: 0.7449, Val Acc: 0.5964
Epoch 69/100, Loss: 0.5067, Acc: 0.7401, Val Loss: 0.7440, Val Acc: 0.5916
Epoch 70/100, Loss: 0.5067, Acc: 0.7390, Val Loss: 0.7424, Val Acc: 0.5960
Epoch 71/100, Loss: 0.5067, Acc: 0.7397, Val Loss: 0.7431, Val Acc: 0.5916
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5065, Acc: 0.7386, Val Loss: 0.7443, Val Acc: 0.5968
Epoch 73/100, Loss: 0.5065, Acc: 0.7403, Val Loss: 0.7437, Val Acc: 0.5957
Epoch 74/100, Loss: 0.5065, Acc: 0.7389, Val Loss: 0.7472, Val Acc: 0.5986
Epoch 75/100, Loss: 0.5065, Acc: 0.7396, Val Loss: 0.7444, Val Acc: 0.5968
Epoch 76/100, Loss: 0.5065, Acc: 0.7397, Val Loss: 0.7422, Val Acc: 0.5957
Epoch 77/100, Loss: 0.5065, Acc: 0.7393, Val Loss: 0.7438, Val Acc: 0.5946
Epoch 78/100, Loss: 0.5065, Acc: 0.7389, Val Loss: 0.7439, Val Acc: 0.5960
Epoch 79/100, Loss: 0.5065, Acc: 0.7395, Val Loss: 0.7442, Val Acc: 0.5960
Epoch 80/100, Loss: 0.5064, Acc: 0.7397, Val Loss: 0.7451, Val Acc: 0.5957
Epoch 81/100, Loss: 0.5064, Acc: 0.7390, Val Loss: 0.7464, Val Acc: 0.5968
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5064, Acc: 0.7400, Val Loss: 0.7437, Val Acc: 0.5957
Epoch 83/100, Loss: 0.5064, Acc: 0.7397, Val Loss: 0.7440, Val Acc: 0.5957
Epoch 84/100, Loss: 0.5064, Acc: 0.7390, Val Loss: 0.7437, Val Acc: 0.5946
Epoch 85/100, Loss: 0.5064, Acc: 0.7389, Val Loss: 0.7465, Val Acc: 0.5957
Epoch 86/100, Loss: 0.5064, Acc: 0.7396, Val Loss: 0.7448, Val Acc: 0.5957
Epoch 87/100, Loss: 0.5063, Acc: 0.7400, Val Loss: 0.7447, Val Acc: 0.5957
Epoch 88/100, Loss: 0.5064, Acc: 0.7391, Val Loss: 0.7458, Val Acc: 0.5960
Epoch 89/100, Loss: 0.5064, Acc: 0.7397, Val Loss: 0.7450, Val Acc: 0.5957
Epoch 90/100, Loss: 0.5064, Acc: 0.7398, Val Loss: 0.7470, Val Acc: 0.5957
Epoch 91/100, Loss: 0.5063, Acc: 0.7395, Val Loss: 0.7482, Val Acc: 0.5960
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5063, Acc: 0.7387, Val Loss: 0.7434, Val Acc: 0.5916
Epoch 93/100, Loss: 0.5062, Acc: 0.7401, Val Loss: 0.7444, Val Acc: 0.5920
Epoch 94/100, Loss: 0.5063, Acc: 0.7398, Val Loss: 0.7448, Val Acc: 0.5938
Epoch 95/100, Loss: 0.5063, Acc: 0.7390, Val Loss: 0.7455, Val Acc: 0.5968
Epoch 96/100, Loss: 0.5063, Acc: 0.7400, Val Loss: 0.7475, Val Acc: 0.5960
Epoch 97/100, Loss: 0.5062, Acc: 0.7398, Val Loss: 0.7451, Val Acc: 0.5949
Epoch 98/100, Loss: 0.5062, Acc: 0.7397, Val Loss: 0.7451, Val Acc: 0.5957
Epoch 99/100, Loss: 0.5062, Acc: 0.7396, Val Loss: 0.7451, Val Acc: 0.5953
Epoch 100/100, Loss: 0.5062, Acc: 0.7399, Val Loss: 0.7446, Val Acc: 0.5975

##############################
Resultados para principal:  010  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3 
 {'training': [0.5061873260897121, 0.7399338113623828, 0.6805536332179931, 0.9041927179109966, 0.7765932243544184], 'validate': [0.7446266315704169, 0.5974981604120677, 0.5944206008583691, 0.6119293078055965, 0.6030478955007257], 'test': [0.7002480504689393, 0.575927015891701, 0.5491020252197172, 0.8462897526501767, 0.6660486674391657]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  009  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  009  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  009  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4000, Acc: 0.8711, Val Loss: 0.1859, Val Acc: 0.9765
Mejor modelo guardado con Val Loss: 0.1859
Epoch 2/100, Loss: 0.2614, Acc: 0.8967, Val Loss: 0.1352, Val Acc: 0.9706
Mejor modelo guardado con Val Loss: 0.1352
Epoch 3/100, Loss: 0.2391, Acc: 0.9031, Val Loss: 0.1156, Val Acc: 0.9731
Mejor modelo guardado con Val Loss: 0.1156
Epoch 4/100, Loss: 0.2202, Acc: 0.9061, Val Loss: 0.1265, Val Acc: 0.9592
Epoch 5/100, Loss: 0.2177, Acc: 0.9080, Val Loss: 0.1132, Val Acc: 0.9643
Mejor modelo guardado con Val Loss: 0.1132
Epoch 6/100, Loss: 0.2167, Acc: 0.9072, Val Loss: 0.2094, Val Acc: 0.9077
Epoch 7/100, Loss: 0.2152, Acc: 0.9056, Val Loss: 0.1115, Val Acc: 0.9691
Mejor modelo guardado con Val Loss: 0.1115
Epoch 8/100, Loss: 0.2060, Acc: 0.9114, Val Loss: 0.0854, Val Acc: 0.9706
Mejor modelo guardado con Val Loss: 0.0854
Epoch 9/100, Loss: 0.2052, Acc: 0.9134, Val Loss: 0.1411, Val Acc: 0.9489
Epoch 10/100, Loss: 0.2087, Acc: 0.9087, Val Loss: 0.1391, Val Acc: 0.9525
Epoch 11/100, Loss: 0.2139, Acc: 0.9086, Val Loss: 0.1294, Val Acc: 0.9617
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.1970, Acc: 0.9120, Val Loss: 0.0957, Val Acc: 0.9695
Epoch 13/100, Loss: 0.1928, Acc: 0.9138, Val Loss: 0.0824, Val Acc: 0.9746
Mejor modelo guardado con Val Loss: 0.0824
Epoch 14/100, Loss: 0.1992, Acc: 0.9084, Val Loss: 0.1130, Val Acc: 0.9592
Epoch 15/100, Loss: 0.1953, Acc: 0.9122, Val Loss: 0.1202, Val Acc: 0.9676
Epoch 16/100, Loss: 0.1966, Acc: 0.9123, Val Loss: 0.0916, Val Acc: 0.9731
Epoch 17/100, Loss: 0.1934, Acc: 0.9117, Val Loss: 0.1151, Val Acc: 0.9632
Epoch 18/100, Loss: 0.1966, Acc: 0.9141, Val Loss: 0.1214, Val Acc: 0.9492
Epoch 19/100, Loss: 0.1948, Acc: 0.9154, Val Loss: 0.1353, Val Acc: 0.9415
Epoch 20/100, Loss: 0.1960, Acc: 0.9138, Val Loss: 0.1140, Val Acc: 0.9632
Epoch 21/100, Loss: 0.1936, Acc: 0.9149, Val Loss: 0.1008, Val Acc: 0.9680
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.1847, Acc: 0.9187, Val Loss: 0.1399, Val Acc: 0.9386
Epoch 23/100, Loss: 0.1851, Acc: 0.9171, Val Loss: 0.1008, Val Acc: 0.9639
Epoch 24/100, Loss: 0.1863, Acc: 0.9164, Val Loss: 0.0910, Val Acc: 0.9687
Epoch 25/100, Loss: 0.1856, Acc: 0.9181, Val Loss: 0.0990, Val Acc: 0.9643
Epoch 26/100, Loss: 0.1843, Acc: 0.9196, Val Loss: 0.1226, Val Acc: 0.9522
Epoch 27/100, Loss: 0.1842, Acc: 0.9182, Val Loss: 0.1080, Val Acc: 0.9610
Epoch 28/100, Loss: 0.1840, Acc: 0.9179, Val Loss: 0.0899, Val Acc: 0.9698
Epoch 29/100, Loss: 0.1830, Acc: 0.9203, Val Loss: 0.1104, Val Acc: 0.9592
Epoch 30/100, Loss: 0.1833, Acc: 0.9181, Val Loss: 0.0999, Val Acc: 0.9647
Epoch 31/100, Loss: 0.1823, Acc: 0.9176, Val Loss: 0.1024, Val Acc: 0.9617
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.1816, Acc: 0.9196, Val Loss: 0.0965, Val Acc: 0.9662
Epoch 33/100, Loss: 0.1798, Acc: 0.9210, Val Loss: 0.1074, Val Acc: 0.9628
Epoch 34/100, Loss: 0.1797, Acc: 0.9206, Val Loss: 0.0988, Val Acc: 0.9662
Epoch 35/100, Loss: 0.1794, Acc: 0.9208, Val Loss: 0.1051, Val Acc: 0.9606
Epoch 36/100, Loss: 0.1796, Acc: 0.9197, Val Loss: 0.1045, Val Acc: 0.9628
Epoch 37/100, Loss: 0.1793, Acc: 0.9209, Val Loss: 0.1125, Val Acc: 0.9603
Epoch 38/100, Loss: 0.1793, Acc: 0.9205, Val Loss: 0.1076, Val Acc: 0.9610
Epoch 39/100, Loss: 0.1789, Acc: 0.9208, Val Loss: 0.1055, Val Acc: 0.9628
Epoch 40/100, Loss: 0.1784, Acc: 0.9206, Val Loss: 0.0950, Val Acc: 0.9654
Epoch 41/100, Loss: 0.1791, Acc: 0.9207, Val Loss: 0.1018, Val Acc: 0.9628
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.1769, Acc: 0.9213, Val Loss: 0.1015, Val Acc: 0.9625
Epoch 43/100, Loss: 0.1768, Acc: 0.9211, Val Loss: 0.0993, Val Acc: 0.9625
Epoch 44/100, Loss: 0.1766, Acc: 0.9217, Val Loss: 0.0977, Val Acc: 0.9636
Epoch 45/100, Loss: 0.1762, Acc: 0.9220, Val Loss: 0.0954, Val Acc: 0.9636
Epoch 46/100, Loss: 0.1768, Acc: 0.9202, Val Loss: 0.0931, Val Acc: 0.9669
Epoch 47/100, Loss: 0.1772, Acc: 0.9214, Val Loss: 0.1046, Val Acc: 0.9617
Epoch 48/100, Loss: 0.1759, Acc: 0.9226, Val Loss: 0.1094, Val Acc: 0.9617
Epoch 49/100, Loss: 0.1760, Acc: 0.9219, Val Loss: 0.1012, Val Acc: 0.9628
Epoch 50/100, Loss: 0.1754, Acc: 0.9225, Val Loss: 0.0994, Val Acc: 0.9628
Epoch 51/100, Loss: 0.1760, Acc: 0.9216, Val Loss: 0.1082, Val Acc: 0.9617
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.1751, Acc: 0.9221, Val Loss: 0.1003, Val Acc: 0.9628
Epoch 53/100, Loss: 0.1749, Acc: 0.9220, Val Loss: 0.1027, Val Acc: 0.9621
Epoch 54/100, Loss: 0.1749, Acc: 0.9217, Val Loss: 0.0972, Val Acc: 0.9632
Epoch 55/100, Loss: 0.1750, Acc: 0.9219, Val Loss: 0.0986, Val Acc: 0.9625
Epoch 56/100, Loss: 0.1747, Acc: 0.9217, Val Loss: 0.1008, Val Acc: 0.9621
Epoch 57/100, Loss: 0.1746, Acc: 0.9226, Val Loss: 0.1001, Val Acc: 0.9625
Epoch 58/100, Loss: 0.1745, Acc: 0.9215, Val Loss: 0.1047, Val Acc: 0.9617
Epoch 59/100, Loss: 0.1745, Acc: 0.9220, Val Loss: 0.1014, Val Acc: 0.9617
Epoch 60/100, Loss: 0.1744, Acc: 0.9215, Val Loss: 0.0999, Val Acc: 0.9625
Epoch 61/100, Loss: 0.1744, Acc: 0.9220, Val Loss: 0.1008, Val Acc: 0.9628
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.1740, Acc: 0.9220, Val Loss: 0.0997, Val Acc: 0.9628
Epoch 63/100, Loss: 0.1740, Acc: 0.9218, Val Loss: 0.0995, Val Acc: 0.9621
Epoch 64/100, Loss: 0.1741, Acc: 0.9221, Val Loss: 0.1003, Val Acc: 0.9617
Epoch 65/100, Loss: 0.1740, Acc: 0.9221, Val Loss: 0.0995, Val Acc: 0.9628
Epoch 66/100, Loss: 0.1740, Acc: 0.9220, Val Loss: 0.1009, Val Acc: 0.9621
Epoch 67/100, Loss: 0.1740, Acc: 0.9224, Val Loss: 0.0996, Val Acc: 0.9625
Epoch 68/100, Loss: 0.1739, Acc: 0.9222, Val Loss: 0.1028, Val Acc: 0.9617
Epoch 69/100, Loss: 0.1739, Acc: 0.9220, Val Loss: 0.0985, Val Acc: 0.9628
Epoch 70/100, Loss: 0.1740, Acc: 0.9223, Val Loss: 0.1014, Val Acc: 0.9617
Epoch 71/100, Loss: 0.1738, Acc: 0.9223, Val Loss: 0.1006, Val Acc: 0.9621
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.1736, Acc: 0.9229, Val Loss: 0.0995, Val Acc: 0.9621
Epoch 73/100, Loss: 0.1736, Acc: 0.9219, Val Loss: 0.1006, Val Acc: 0.9621
Epoch 74/100, Loss: 0.1735, Acc: 0.9231, Val Loss: 0.0993, Val Acc: 0.9628
Epoch 75/100, Loss: 0.1736, Acc: 0.9217, Val Loss: 0.0996, Val Acc: 0.9628
Epoch 76/100, Loss: 0.1735, Acc: 0.9221, Val Loss: 0.1015, Val Acc: 0.9617
Epoch 77/100, Loss: 0.1736, Acc: 0.9224, Val Loss: 0.0991, Val Acc: 0.9628
Epoch 78/100, Loss: 0.1735, Acc: 0.9219, Val Loss: 0.0994, Val Acc: 0.9628
Epoch 79/100, Loss: 0.1736, Acc: 0.9223, Val Loss: 0.0992, Val Acc: 0.9628
Epoch 80/100, Loss: 0.1734, Acc: 0.9221, Val Loss: 0.1004, Val Acc: 0.9617
Epoch 81/100, Loss: 0.1735, Acc: 0.9227, Val Loss: 0.0999, Val Acc: 0.9621
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.1734, Acc: 0.9222, Val Loss: 0.1013, Val Acc: 0.9621
Epoch 83/100, Loss: 0.1734, Acc: 0.9225, Val Loss: 0.1001, Val Acc: 0.9621
Epoch 84/100, Loss: 0.1734, Acc: 0.9229, Val Loss: 0.1002, Val Acc: 0.9617
Epoch 85/100, Loss: 0.1734, Acc: 0.9226, Val Loss: 0.1006, Val Acc: 0.9617
Epoch 86/100, Loss: 0.1733, Acc: 0.9232, Val Loss: 0.0975, Val Acc: 0.9628
Epoch 87/100, Loss: 0.1734, Acc: 0.9225, Val Loss: 0.0991, Val Acc: 0.9628
Epoch 88/100, Loss: 0.1733, Acc: 0.9228, Val Loss: 0.1017, Val Acc: 0.9614
Epoch 89/100, Loss: 0.1733, Acc: 0.9228, Val Loss: 0.0999, Val Acc: 0.9625
Epoch 90/100, Loss: 0.1733, Acc: 0.9231, Val Loss: 0.1000, Val Acc: 0.9621
Epoch 91/100, Loss: 0.1732, Acc: 0.9214, Val Loss: 0.1004, Val Acc: 0.9617
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.1732, Acc: 0.9227, Val Loss: 0.1025, Val Acc: 0.9614
Epoch 93/100, Loss: 0.1732, Acc: 0.9224, Val Loss: 0.0987, Val Acc: 0.9628
Epoch 94/100, Loss: 0.1732, Acc: 0.9224, Val Loss: 0.0999, Val Acc: 0.9617
Epoch 95/100, Loss: 0.1732, Acc: 0.9229, Val Loss: 0.1003, Val Acc: 0.9617
Epoch 96/100, Loss: 0.1732, Acc: 0.9227, Val Loss: 0.0995, Val Acc: 0.9625
Epoch 97/100, Loss: 0.1731, Acc: 0.9230, Val Loss: 0.0996, Val Acc: 0.9625
Epoch 98/100, Loss: 0.1731, Acc: 0.9227, Val Loss: 0.0986, Val Acc: 0.9628
Epoch 99/100, Loss: 0.1730, Acc: 0.9229, Val Loss: 0.1002, Val Acc: 0.9617
Epoch 100/100, Loss: 0.1730, Acc: 0.9230, Val Loss: 0.1001, Val Acc: 0.9621

##############################
Resultados para principal:  009  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3 
 {'training': [0.17301172285170693, 0.9229637801066373, 0.9138179201151493, 0.9339830820154469, 0.9237904692615496], 'validate': [0.10007979329892022, 0.9621044885945548, 0.9504666188083274, 0.9749631811487481, 0.9625590694292985], 'test': [0.1774700368858046, 0.9326074161271336, 0.9411411411411411, 0.9228504122497055, 0.9319060362771335]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  118  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  118  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  118  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6782, Acc: 0.5878, Val Loss: 0.6391, Val Acc: 0.7848
Mejor modelo guardado con Val Loss: 0.6391
Epoch 2/100, Loss: 0.6662, Acc: 0.6122, Val Loss: 0.6056, Val Acc: 0.8521
Mejor modelo guardado con Val Loss: 0.6056
Epoch 3/100, Loss: 0.6581, Acc: 0.6167, Val Loss: 0.6638, Val Acc: 0.6508
Epoch 4/100, Loss: 0.6495, Acc: 0.6307, Val Loss: 0.5604, Val Acc: 0.8620
Mejor modelo guardado con Val Loss: 0.5604
Epoch 5/100, Loss: 0.6345, Acc: 0.6498, Val Loss: 0.5579, Val Acc: 0.8043
Mejor modelo guardado con Val Loss: 0.5579
Epoch 6/100, Loss: 0.6393, Acc: 0.6328, Val Loss: 0.5126, Val Acc: 0.8403
Mejor modelo guardado con Val Loss: 0.5126
Epoch 7/100, Loss: 0.6281, Acc: 0.6484, Val Loss: 0.5212, Val Acc: 0.7969
Epoch 8/100, Loss: 0.6244, Acc: 0.6530, Val Loss: 0.4887, Val Acc: 0.8142
Mejor modelo guardado con Val Loss: 0.4887
Epoch 9/100, Loss: 0.6190, Acc: 0.6491, Val Loss: 0.5222, Val Acc: 0.8411
Epoch 10/100, Loss: 0.6166, Acc: 0.6525, Val Loss: 0.5121, Val Acc: 0.7907
Epoch 11/100, Loss: 0.6154, Acc: 0.6510, Val Loss: 0.4978, Val Acc: 0.8517
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6078, Acc: 0.6613, Val Loss: 0.5032, Val Acc: 0.7951
Epoch 13/100, Loss: 0.6001, Acc: 0.6634, Val Loss: 0.4928, Val Acc: 0.8521
Epoch 14/100, Loss: 0.5935, Acc: 0.6605, Val Loss: 0.4832, Val Acc: 0.8370
Mejor modelo guardado con Val Loss: 0.4832
Epoch 15/100, Loss: 0.5861, Acc: 0.6644, Val Loss: 0.4828, Val Acc: 0.8451
Mejor modelo guardado con Val Loss: 0.4828
Epoch 16/100, Loss: 0.5851, Acc: 0.6661, Val Loss: 0.4838, Val Acc: 0.7785
Epoch 17/100, Loss: 0.5843, Acc: 0.6768, Val Loss: 0.4668, Val Acc: 0.8297
Mejor modelo guardado con Val Loss: 0.4668
Epoch 18/100, Loss: 0.5750, Acc: 0.7198, Val Loss: 0.4738, Val Acc: 0.8098
Epoch 19/100, Loss: 0.5740, Acc: 0.7254, Val Loss: 0.4668, Val Acc: 0.8149
Mejor modelo guardado con Val Loss: 0.4668
Epoch 20/100, Loss: 0.5718, Acc: 0.7282, Val Loss: 0.4660, Val Acc: 0.8194
Mejor modelo guardado con Val Loss: 0.4660
Epoch 21/100, Loss: 0.5686, Acc: 0.7235, Val Loss: 0.4619, Val Acc: 0.8245
Mejor modelo guardado con Val Loss: 0.4619
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5623, Acc: 0.7333, Val Loss: 0.4615, Val Acc: 0.8017
Mejor modelo guardado con Val Loss: 0.4615
Epoch 23/100, Loss: 0.5616, Acc: 0.7310, Val Loss: 0.4595, Val Acc: 0.7936
Mejor modelo guardado con Val Loss: 0.4595
Epoch 24/100, Loss: 0.5618, Acc: 0.7329, Val Loss: 0.4654, Val Acc: 0.7862
Epoch 25/100, Loss: 0.5593, Acc: 0.7316, Val Loss: 0.4682, Val Acc: 0.8286
Epoch 26/100, Loss: 0.5575, Acc: 0.7314, Val Loss: 0.4582, Val Acc: 0.8017
Mejor modelo guardado con Val Loss: 0.4582
Epoch 27/100, Loss: 0.5579, Acc: 0.7298, Val Loss: 0.4693, Val Acc: 0.7870
Epoch 28/100, Loss: 0.5547, Acc: 0.7349, Val Loss: 0.4757, Val Acc: 0.8102
Epoch 29/100, Loss: 0.5542, Acc: 0.7345, Val Loss: 0.4687, Val Acc: 0.8201
Epoch 30/100, Loss: 0.5568, Acc: 0.7296, Val Loss: 0.4600, Val Acc: 0.7943
Epoch 31/100, Loss: 0.5517, Acc: 0.7336, Val Loss: 0.4580, Val Acc: 0.8065
Mejor modelo guardado con Val Loss: 0.4580
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5498, Acc: 0.7371, Val Loss: 0.4512, Val Acc: 0.8274
Mejor modelo guardado con Val Loss: 0.4512
Epoch 33/100, Loss: 0.5493, Acc: 0.7358, Val Loss: 0.4471, Val Acc: 0.8194
Mejor modelo guardado con Val Loss: 0.4471
Epoch 34/100, Loss: 0.5484, Acc: 0.7389, Val Loss: 0.4493, Val Acc: 0.8223
Epoch 35/100, Loss: 0.5489, Acc: 0.7358, Val Loss: 0.4480, Val Acc: 0.8263
Epoch 36/100, Loss: 0.5492, Acc: 0.7355, Val Loss: 0.4494, Val Acc: 0.8293
Epoch 37/100, Loss: 0.5469, Acc: 0.7395, Val Loss: 0.4531, Val Acc: 0.7973
Epoch 38/100, Loss: 0.5464, Acc: 0.7373, Val Loss: 0.4540, Val Acc: 0.8205
Epoch 39/100, Loss: 0.5469, Acc: 0.7374, Val Loss: 0.4478, Val Acc: 0.8201
Epoch 40/100, Loss: 0.5461, Acc: 0.7387, Val Loss: 0.4555, Val Acc: 0.8068
Epoch 41/100, Loss: 0.5458, Acc: 0.7388, Val Loss: 0.4561, Val Acc: 0.8076
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5441, Acc: 0.7387, Val Loss: 0.4531, Val Acc: 0.8113
Epoch 43/100, Loss: 0.5440, Acc: 0.7383, Val Loss: 0.4589, Val Acc: 0.8105
Epoch 44/100, Loss: 0.5451, Acc: 0.7390, Val Loss: 0.4515, Val Acc: 0.8091
Epoch 45/100, Loss: 0.5433, Acc: 0.7406, Val Loss: 0.4534, Val Acc: 0.8057
Epoch 46/100, Loss: 0.5427, Acc: 0.7399, Val Loss: 0.4572, Val Acc: 0.8065
Epoch 47/100, Loss: 0.5431, Acc: 0.7410, Val Loss: 0.4473, Val Acc: 0.8102
Epoch 48/100, Loss: 0.5426, Acc: 0.7396, Val Loss: 0.4544, Val Acc: 0.8024
Epoch 49/100, Loss: 0.5430, Acc: 0.7386, Val Loss: 0.4492, Val Acc: 0.8087
Epoch 50/100, Loss: 0.5422, Acc: 0.7397, Val Loss: 0.4454, Val Acc: 0.8105
Mejor modelo guardado con Val Loss: 0.4454
Epoch 51/100, Loss: 0.5413, Acc: 0.7391, Val Loss: 0.4458, Val Acc: 0.8138
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5406, Acc: 0.7404, Val Loss: 0.4469, Val Acc: 0.8238
Epoch 53/100, Loss: 0.5404, Acc: 0.7409, Val Loss: 0.4459, Val Acc: 0.8175
Epoch 54/100, Loss: 0.5403, Acc: 0.7398, Val Loss: 0.4482, Val Acc: 0.8223
Epoch 55/100, Loss: 0.5403, Acc: 0.7418, Val Loss: 0.4442, Val Acc: 0.8219
Mejor modelo guardado con Val Loss: 0.4442
Epoch 56/100, Loss: 0.5406, Acc: 0.7408, Val Loss: 0.4484, Val Acc: 0.8175
Epoch 57/100, Loss: 0.5400, Acc: 0.7415, Val Loss: 0.4463, Val Acc: 0.8175
Epoch 58/100, Loss: 0.5399, Acc: 0.7411, Val Loss: 0.4456, Val Acc: 0.8179
Epoch 59/100, Loss: 0.5401, Acc: 0.7412, Val Loss: 0.4476, Val Acc: 0.8194
Epoch 60/100, Loss: 0.5397, Acc: 0.7428, Val Loss: 0.4480, Val Acc: 0.8212
Epoch 61/100, Loss: 0.5395, Acc: 0.7432, Val Loss: 0.4460, Val Acc: 0.8223
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5392, Acc: 0.7428, Val Loss: 0.4461, Val Acc: 0.8216
Epoch 63/100, Loss: 0.5393, Acc: 0.7424, Val Loss: 0.4463, Val Acc: 0.8208
Epoch 64/100, Loss: 0.5387, Acc: 0.7420, Val Loss: 0.4452, Val Acc: 0.8216
Epoch 65/100, Loss: 0.5390, Acc: 0.7419, Val Loss: 0.4448, Val Acc: 0.8212
Epoch 66/100, Loss: 0.5387, Acc: 0.7425, Val Loss: 0.4475, Val Acc: 0.8201
Epoch 67/100, Loss: 0.5386, Acc: 0.7428, Val Loss: 0.4468, Val Acc: 0.8241
Epoch 68/100, Loss: 0.5387, Acc: 0.7419, Val Loss: 0.4479, Val Acc: 0.8179
Epoch 69/100, Loss: 0.5386, Acc: 0.7427, Val Loss: 0.4462, Val Acc: 0.8205
Epoch 70/100, Loss: 0.5387, Acc: 0.7428, Val Loss: 0.4456, Val Acc: 0.8197
Epoch 71/100, Loss: 0.5384, Acc: 0.7429, Val Loss: 0.4493, Val Acc: 0.8168
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5384, Acc: 0.7427, Val Loss: 0.4456, Val Acc: 0.8190
Epoch 73/100, Loss: 0.5382, Acc: 0.7420, Val Loss: 0.4458, Val Acc: 0.8208
Epoch 74/100, Loss: 0.5381, Acc: 0.7438, Val Loss: 0.4458, Val Acc: 0.8197
Epoch 75/100, Loss: 0.5382, Acc: 0.7427, Val Loss: 0.4458, Val Acc: 0.8201
Epoch 76/100, Loss: 0.5382, Acc: 0.7435, Val Loss: 0.4446, Val Acc: 0.8219
Epoch 77/100, Loss: 0.5381, Acc: 0.7433, Val Loss: 0.4455, Val Acc: 0.8227
Epoch 78/100, Loss: 0.5381, Acc: 0.7422, Val Loss: 0.4453, Val Acc: 0.8219
Epoch 79/100, Loss: 0.5380, Acc: 0.7436, Val Loss: 0.4447, Val Acc: 0.8227
Epoch 80/100, Loss: 0.5379, Acc: 0.7432, Val Loss: 0.4441, Val Acc: 0.8201
Mejor modelo guardado con Val Loss: 0.4441
Epoch 81/100, Loss: 0.5380, Acc: 0.7433, Val Loss: 0.4458, Val Acc: 0.8227
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5378, Acc: 0.7447, Val Loss: 0.4448, Val Acc: 0.8205
Epoch 83/100, Loss: 0.5377, Acc: 0.7436, Val Loss: 0.4453, Val Acc: 0.8219
Epoch 84/100, Loss: 0.5376, Acc: 0.7443, Val Loss: 0.4453, Val Acc: 0.8216
Epoch 85/100, Loss: 0.5376, Acc: 0.7436, Val Loss: 0.4449, Val Acc: 0.8223
Epoch 86/100, Loss: 0.5375, Acc: 0.7420, Val Loss: 0.4466, Val Acc: 0.8208
Epoch 87/100, Loss: 0.5375, Acc: 0.7436, Val Loss: 0.4462, Val Acc: 0.8205
Epoch 88/100, Loss: 0.5374, Acc: 0.7440, Val Loss: 0.4465, Val Acc: 0.8205
Epoch 89/100, Loss: 0.5374, Acc: 0.7433, Val Loss: 0.4451, Val Acc: 0.8216
Epoch 90/100, Loss: 0.5374, Acc: 0.7443, Val Loss: 0.4469, Val Acc: 0.8208
Epoch 91/100, Loss: 0.5374, Acc: 0.7435, Val Loss: 0.4470, Val Acc: 0.8201
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5373, Acc: 0.7433, Val Loss: 0.4455, Val Acc: 0.8205
Epoch 93/100, Loss: 0.5373, Acc: 0.7433, Val Loss: 0.4448, Val Acc: 0.8219
Epoch 94/100, Loss: 0.5372, Acc: 0.7441, Val Loss: 0.4462, Val Acc: 0.8201
Epoch 95/100, Loss: 0.5372, Acc: 0.7429, Val Loss: 0.4451, Val Acc: 0.8205
Epoch 96/100, Loss: 0.5372, Acc: 0.7427, Val Loss: 0.4450, Val Acc: 0.8219
Epoch 97/100, Loss: 0.5371, Acc: 0.7436, Val Loss: 0.4462, Val Acc: 0.8216
Epoch 98/100, Loss: 0.5370, Acc: 0.7438, Val Loss: 0.4462, Val Acc: 0.8205
Epoch 99/100, Loss: 0.5370, Acc: 0.7443, Val Loss: 0.4457, Val Acc: 0.8208
Epoch 100/100, Loss: 0.5369, Acc: 0.7446, Val Loss: 0.4460, Val Acc: 0.8227

##############################
Resultados para principal:  118  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3 
 {'training': [0.5369037827118988, 0.7446221731936018, 0.7279739458347617, 0.7809856564913571, 0.7535486160397445], 'validate': [0.44598456316216045, 0.8226637233259749, 0.8762886597938144, 0.7511045655375552, 0.8088818398096749], 'test': [0.6579290628433228, 0.6303708063566804, 0.6002722323049002, 0.7791519434628975, 0.6781137878011276]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  032  --- window & package numer:  3

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  032  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  3
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  032  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6664, Acc: 0.6381, Val Loss: 0.7587, Val Acc: 0.3536
Mejor modelo guardado con Val Loss: 0.7587
Epoch 2/100, Loss: 0.6394, Acc: 0.6618, Val Loss: 0.7454, Val Acc: 0.4393
Mejor modelo guardado con Val Loss: 0.7454
Epoch 3/100, Loss: 0.6233, Acc: 0.6677, Val Loss: 0.8253, Val Acc: 0.3238
Epoch 4/100, Loss: 0.6167, Acc: 0.6716, Val Loss: 0.8477, Val Acc: 0.3499
Epoch 5/100, Loss: 0.6114, Acc: 0.6697, Val Loss: 0.8131, Val Acc: 0.3624
Epoch 6/100, Loss: 0.6121, Acc: 0.6744, Val Loss: 0.8018, Val Acc: 0.4169
Epoch 7/100, Loss: 0.6057, Acc: 0.6781, Val Loss: 0.8733, Val Acc: 0.3407
Epoch 8/100, Loss: 0.6052, Acc: 0.6740, Val Loss: 0.7994, Val Acc: 0.4139
Epoch 9/100, Loss: 0.6041, Acc: 0.6757, Val Loss: 0.7963, Val Acc: 0.4187
Epoch 10/100, Loss: 0.6019, Acc: 0.6778, Val Loss: 0.7851, Val Acc: 0.4099
Epoch 11/100, Loss: 0.6001, Acc: 0.6782, Val Loss: 0.8455, Val Acc: 0.3580
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5974, Acc: 0.6793, Val Loss: 0.7861, Val Acc: 0.3970
Epoch 13/100, Loss: 0.5931, Acc: 0.6812, Val Loss: 0.7623, Val Acc: 0.4246
Epoch 14/100, Loss: 0.5934, Acc: 0.6798, Val Loss: 0.8105, Val Acc: 0.3698
Epoch 15/100, Loss: 0.5931, Acc: 0.6836, Val Loss: 0.8071, Val Acc: 0.3631
Epoch 16/100, Loss: 0.5890, Acc: 0.6826, Val Loss: 0.7730, Val Acc: 0.3992
Epoch 17/100, Loss: 0.5888, Acc: 0.6829, Val Loss: 0.8112, Val Acc: 0.3565
Epoch 18/100, Loss: 0.5896, Acc: 0.6807, Val Loss: 0.7721, Val Acc: 0.4062
Epoch 19/100, Loss: 0.5866, Acc: 0.6831, Val Loss: 0.8169, Val Acc: 0.3565
Epoch 20/100, Loss: 0.5858, Acc: 0.6817, Val Loss: 0.7659, Val Acc: 0.4007
Epoch 21/100, Loss: 0.5863, Acc: 0.6818, Val Loss: 0.7936, Val Acc: 0.3937
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5832, Acc: 0.6835, Val Loss: 0.7570, Val Acc: 0.4099
Epoch 23/100, Loss: 0.5825, Acc: 0.6846, Val Loss: 0.7905, Val Acc: 0.3771
Epoch 24/100, Loss: 0.5821, Acc: 0.6858, Val Loss: 0.8107, Val Acc: 0.3598
Epoch 25/100, Loss: 0.5822, Acc: 0.6825, Val Loss: 0.7566, Val Acc: 0.4058
Epoch 26/100, Loss: 0.5818, Acc: 0.6846, Val Loss: 0.8040, Val Acc: 0.3613
Epoch 27/100, Loss: 0.5808, Acc: 0.6847, Val Loss: 0.8096, Val Acc: 0.3584
Epoch 28/100, Loss: 0.5812, Acc: 0.6839, Val Loss: 0.8237, Val Acc: 0.3477
Epoch 29/100, Loss: 0.5801, Acc: 0.6842, Val Loss: 0.7469, Val Acc: 0.4051
Epoch 30/100, Loss: 0.5801, Acc: 0.6860, Val Loss: 0.7657, Val Acc: 0.3933
Epoch 31/100, Loss: 0.5797, Acc: 0.6869, Val Loss: 0.7414, Val Acc: 0.4073
Mejor modelo guardado con Val Loss: 0.7414
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5783, Acc: 0.6860, Val Loss: 0.7486, Val Acc: 0.3962
Epoch 33/100, Loss: 0.5784, Acc: 0.6859, Val Loss: 0.7539, Val Acc: 0.4014
Epoch 34/100, Loss: 0.5782, Acc: 0.6862, Val Loss: 0.7576, Val Acc: 0.3955
Epoch 35/100, Loss: 0.5779, Acc: 0.6859, Val Loss: 0.7426, Val Acc: 0.4080
Epoch 36/100, Loss: 0.5785, Acc: 0.6844, Val Loss: 0.7429, Val Acc: 0.4088
Epoch 37/100, Loss: 0.5774, Acc: 0.6873, Val Loss: 0.7416, Val Acc: 0.4091
Epoch 38/100, Loss: 0.5770, Acc: 0.6866, Val Loss: 0.7650, Val Acc: 0.3852
Epoch 39/100, Loss: 0.5770, Acc: 0.6871, Val Loss: 0.7697, Val Acc: 0.3797
Epoch 40/100, Loss: 0.5774, Acc: 0.6870, Val Loss: 0.7429, Val Acc: 0.4051
Epoch 41/100, Loss: 0.5769, Acc: 0.6874, Val Loss: 0.7609, Val Acc: 0.3856
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5757, Acc: 0.6884, Val Loss: 0.7488, Val Acc: 0.3933
Epoch 43/100, Loss: 0.5758, Acc: 0.6874, Val Loss: 0.7528, Val Acc: 0.3944
Epoch 44/100, Loss: 0.5757, Acc: 0.6870, Val Loss: 0.7553, Val Acc: 0.3896
Epoch 45/100, Loss: 0.5752, Acc: 0.6886, Val Loss: 0.7695, Val Acc: 0.3771
Epoch 46/100, Loss: 0.5755, Acc: 0.6884, Val Loss: 0.7461, Val Acc: 0.3959
Epoch 47/100, Loss: 0.5760, Acc: 0.6881, Val Loss: 0.7532, Val Acc: 0.3911
Epoch 48/100, Loss: 0.5754, Acc: 0.6874, Val Loss: 0.7593, Val Acc: 0.3826
Epoch 49/100, Loss: 0.5754, Acc: 0.6875, Val Loss: 0.7476, Val Acc: 0.3951
Epoch 50/100, Loss: 0.5753, Acc: 0.6874, Val Loss: 0.7453, Val Acc: 0.3981
Epoch 51/100, Loss: 0.5749, Acc: 0.6886, Val Loss: 0.7630, Val Acc: 0.3786
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5745, Acc: 0.6856, Val Loss: 0.7434, Val Acc: 0.3970
Epoch 53/100, Loss: 0.5746, Acc: 0.6881, Val Loss: 0.7620, Val Acc: 0.3801
Epoch 54/100, Loss: 0.5743, Acc: 0.6878, Val Loss: 0.7390, Val Acc: 0.3999
Mejor modelo guardado con Val Loss: 0.7390
Epoch 55/100, Loss: 0.5744, Acc: 0.6888, Val Loss: 0.7496, Val Acc: 0.3896
Epoch 56/100, Loss: 0.5745, Acc: 0.6873, Val Loss: 0.7579, Val Acc: 0.3867
Epoch 57/100, Loss: 0.5745, Acc: 0.6878, Val Loss: 0.7520, Val Acc: 0.3889
Epoch 58/100, Loss: 0.5743, Acc: 0.6877, Val Loss: 0.7443, Val Acc: 0.3970
Epoch 59/100, Loss: 0.5742, Acc: 0.6884, Val Loss: 0.7611, Val Acc: 0.3859
Epoch 60/100, Loss: 0.5744, Acc: 0.6885, Val Loss: 0.7503, Val Acc: 0.3907
Epoch 61/100, Loss: 0.5743, Acc: 0.6887, Val Loss: 0.7445, Val Acc: 0.3981
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5740, Acc: 0.6882, Val Loss: 0.7473, Val Acc: 0.3959
Epoch 63/100, Loss: 0.5740, Acc: 0.6886, Val Loss: 0.7488, Val Acc: 0.3951
Epoch 64/100, Loss: 0.5739, Acc: 0.6886, Val Loss: 0.7481, Val Acc: 0.3970
Epoch 65/100, Loss: 0.5739, Acc: 0.6893, Val Loss: 0.7507, Val Acc: 0.3959
Epoch 66/100, Loss: 0.5739, Acc: 0.6888, Val Loss: 0.7428, Val Acc: 0.4010
Epoch 67/100, Loss: 0.5738, Acc: 0.6885, Val Loss: 0.7561, Val Acc: 0.3937
Epoch 68/100, Loss: 0.5739, Acc: 0.6878, Val Loss: 0.7527, Val Acc: 0.3933
Epoch 69/100, Loss: 0.5737, Acc: 0.6878, Val Loss: 0.7427, Val Acc: 0.4040
Epoch 70/100, Loss: 0.5737, Acc: 0.6885, Val Loss: 0.7479, Val Acc: 0.4010
Epoch 71/100, Loss: 0.5737, Acc: 0.6887, Val Loss: 0.7420, Val Acc: 0.4043
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5737, Acc: 0.6884, Val Loss: 0.7465, Val Acc: 0.3988
Epoch 73/100, Loss: 0.5736, Acc: 0.6894, Val Loss: 0.7456, Val Acc: 0.4025
Epoch 74/100, Loss: 0.5736, Acc: 0.6890, Val Loss: 0.7442, Val Acc: 0.4029
Epoch 75/100, Loss: 0.5736, Acc: 0.6885, Val Loss: 0.7470, Val Acc: 0.4010
Epoch 76/100, Loss: 0.5736, Acc: 0.6885, Val Loss: 0.7493, Val Acc: 0.3999
Epoch 77/100, Loss: 0.5736, Acc: 0.6889, Val Loss: 0.7413, Val Acc: 0.4065
Epoch 78/100, Loss: 0.5736, Acc: 0.6886, Val Loss: 0.7433, Val Acc: 0.4051
Epoch 79/100, Loss: 0.5735, Acc: 0.6890, Val Loss: 0.7459, Val Acc: 0.4036
Epoch 80/100, Loss: 0.5735, Acc: 0.6880, Val Loss: 0.7478, Val Acc: 0.4010
Epoch 81/100, Loss: 0.5735, Acc: 0.6896, Val Loss: 0.7458, Val Acc: 0.4029
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5735, Acc: 0.6894, Val Loss: 0.7446, Val Acc: 0.4036
Epoch 83/100, Loss: 0.5734, Acc: 0.6889, Val Loss: 0.7460, Val Acc: 0.4029
Epoch 84/100, Loss: 0.5735, Acc: 0.6892, Val Loss: 0.7439, Val Acc: 0.4043
Epoch 85/100, Loss: 0.5734, Acc: 0.6889, Val Loss: 0.7440, Val Acc: 0.4051
Epoch 86/100, Loss: 0.5734, Acc: 0.6889, Val Loss: 0.7437, Val Acc: 0.4051
Epoch 87/100, Loss: 0.5734, Acc: 0.6893, Val Loss: 0.7460, Val Acc: 0.4029
Epoch 88/100, Loss: 0.5734, Acc: 0.6874, Val Loss: 0.7410, Val Acc: 0.4080
Epoch 89/100, Loss: 0.5734, Acc: 0.6892, Val Loss: 0.7453, Val Acc: 0.4036
Epoch 90/100, Loss: 0.5733, Acc: 0.6893, Val Loss: 0.7413, Val Acc: 0.4069
Epoch 91/100, Loss: 0.5733, Acc: 0.6885, Val Loss: 0.7435, Val Acc: 0.4051
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5733, Acc: 0.6890, Val Loss: 0.7446, Val Acc: 0.4040
Epoch 93/100, Loss: 0.5733, Acc: 0.6886, Val Loss: 0.7413, Val Acc: 0.4073
Epoch 94/100, Loss: 0.5733, Acc: 0.6888, Val Loss: 0.7397, Val Acc: 0.4077
Epoch 95/100, Loss: 0.5733, Acc: 0.6890, Val Loss: 0.7395, Val Acc: 0.4073
Epoch 96/100, Loss: 0.5732, Acc: 0.6891, Val Loss: 0.7408, Val Acc: 0.4062
Epoch 97/100, Loss: 0.5731, Acc: 0.6898, Val Loss: 0.7371, Val Acc: 0.4102
Mejor modelo guardado con Val Loss: 0.7371
Epoch 98/100, Loss: 0.5731, Acc: 0.6891, Val Loss: 0.7406, Val Acc: 0.4073
Epoch 99/100, Loss: 0.5731, Acc: 0.6899, Val Loss: 0.7416, Val Acc: 0.4077
Epoch 100/100, Loss: 0.5731, Acc: 0.6898, Val Loss: 0.7420, Val Acc: 0.4054

##############################
Resultados para principal:  032  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  3 
 {'training': [0.5730591343592844, 0.6898326898326899, 0.6443356643356644, 0.8471864656123574, 0.7319669526533206], 'validate': [0.7419959493847781, 0.40544518027961735, 0.4451530612244898, 0.7709867452135494, 0.5644204851752022], 'test': [0.7331084377235837, 0.533254855797528, 0.5192439862542956, 0.8898704358068316, 0.6558159722222222]}

##############################
Resultados para window:  3 
 {'067:124:010:009:118:032': {'training': [0.5006685289615085, 0.7496782496782497, 0.760806916426513, 0.728208900331004, 0.7441510852203326], 'validate': [0.4815915382878725, 0.7873436350257542, 0.7542372881355932, 0.8519882179675994, 0.8001383125864454], 'test': [0.5565282186424291, 0.7189523248969982, 0.8233246301131418, 0.5571260306242638, 0.6645591851071303]}, '124:067:010:009:118:032': {'training': [0.38241736131416654, 0.8337929766501195, 0.7937843962447394, 0.9018021331371828, 0.8443526170798898], 'validate': [0.8768062241548715, 0.5294334069168506, 0.5172564438619485, 0.8718703976435935, 0.6493007951741158], 'test': [0.7200566502632918, 0.4958799293702178, 0.4974039460020768, 0.8462897526501767, 0.6265533028122956]}, '010:067:124:009:118:032': {'training': [0.5061873260897121, 0.7399338113623828, 0.6805536332179931, 0.9041927179109966, 0.7765932243544184], 'validate': [0.7446266315704169, 0.5974981604120677, 0.5944206008583691, 0.6119293078055965, 0.6030478955007257], 'test': [0.7002480504689393, 0.575927015891701, 0.5491020252197172, 0.8462897526501767, 0.6660486674391657]}, '009:067:124:010:118:032': {'training': [0.17301172285170693, 0.9229637801066373, 0.9138179201151493, 0.9339830820154469, 0.9237904692615496], 'validate': [0.10007979329892022, 0.9621044885945548, 0.9504666188083274, 0.9749631811487481, 0.9625590694292985], 'test': [0.1774700368858046, 0.9326074161271336, 0.9411411411411411, 0.9228504122497055, 0.9319060362771335]}, '118:067:124:010:009:032': {'training': [0.5369037827118988, 0.7446221731936018, 0.7279739458347617, 0.7809856564913571, 0.7535486160397445], 'validate': [0.44598456316216045, 0.8226637233259749, 0.8762886597938144, 0.7511045655375552, 0.8088818398096749], 'test': [0.6579290628433228, 0.6303708063566804, 0.6002722323049002, 0.7791519434628975, 0.6781137878011276]}, '032:067:124:010:009:118': {'training': [0.5730591343592844, 0.6898326898326899, 0.6443356643356644, 0.8471864656123574, 0.7319669526533206], 'validate': [0.7419959493847781, 0.40544518027961735, 0.4451530612244898, 0.7709867452135494, 0.5644204851752022], 'test': [0.7331084377235837, 0.533254855797528, 0.5192439862542956, 0.8898704358068316, 0.6558159722222222]}}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  095  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  095  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6916, Acc: 0.5215, Val Loss: 0.6925, Val Acc: 0.5188
Mejor modelo guardado con Val Loss: 0.6925
Epoch 2/100, Loss: 0.6917, Acc: 0.5304, Val Loss: 0.6908, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6908
Epoch 3/100, Loss: 0.6899, Acc: 0.5453, Val Loss: 0.6922, Val Acc: 0.5103
Epoch 4/100, Loss: 0.6885, Acc: 0.5565, Val Loss: 0.6870, Val Acc: 0.5508
Mejor modelo guardado con Val Loss: 0.6870
Epoch 5/100, Loss: 0.6922, Acc: 0.5191, Val Loss: 0.6933, Val Acc: 0.5007
Epoch 6/100, Loss: 0.6932, Acc: 0.5033, Val Loss: 0.6932, Val Acc: 0.5007
Epoch 7/100, Loss: 0.6934, Acc: 0.5031, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 8/100, Loss: 0.6935, Acc: 0.4923, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 9/100, Loss: 0.6934, Acc: 0.5018, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 10/100, Loss: 0.6935, Acc: 0.4946, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 11/100, Loss: 0.6934, Acc: 0.5006, Val Loss: 0.6934, Val Acc: 0.5007
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6935, Acc: 0.5015, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 13/100, Loss: 0.6933, Acc: 0.4971, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 14/100, Loss: 0.6932, Acc: 0.4961, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 15/100, Loss: 0.6933, Acc: 0.4962, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 16/100, Loss: 0.6933, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 17/100, Loss: 0.6934, Acc: 0.4958, Val Loss: 0.6936, Val Acc: 0.4993
Epoch 18/100, Loss: 0.6930, Acc: 0.5041, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 19/100, Loss: 0.6933, Acc: 0.5026, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 20/100, Loss: 0.6932, Acc: 0.5020, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 21/100, Loss: 0.6932, Acc: 0.5051, Val Loss: 0.6933, Val Acc: 0.4993
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.5004, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 23/100, Loss: 0.6932, Acc: 0.5015, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 24/100, Loss: 0.6932, Acc: 0.4987, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 25/100, Loss: 0.6932, Acc: 0.4996, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 26/100, Loss: 0.6933, Acc: 0.4954, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 27/100, Loss: 0.6932, Acc: 0.4949, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 28/100, Loss: 0.6932, Acc: 0.4967, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 29/100, Loss: 0.6932, Acc: 0.4935, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 30/100, Loss: 0.6933, Acc: 0.5028, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 31/100, Loss: 0.6933, Acc: 0.4980, Val Loss: 0.6932, Val Acc: 0.4993
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4928, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 33/100, Loss: 0.6932, Acc: 0.4996, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 34/100, Loss: 0.6932, Acc: 0.4982, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 35/100, Loss: 0.6932, Acc: 0.5024, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 36/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6932, Val Acc: 0.4989
Epoch 37/100, Loss: 0.6932, Acc: 0.4946, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 38/100, Loss: 0.6932, Acc: 0.4893, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 39/100, Loss: 0.6932, Acc: 0.4955, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 40/100, Loss: 0.6932, Acc: 0.4926, Val Loss: 0.6932, Val Acc: 0.4989
Epoch 41/100, Loss: 0.6932, Acc: 0.4964, Val Loss: 0.6932, Val Acc: 0.4993
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 43/100, Loss: 0.6932, Acc: 0.5006, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 44/100, Loss: 0.6932, Acc: 0.5011, Val Loss: 0.6931, Val Acc: 0.5394
Epoch 45/100, Loss: 0.6931, Acc: 0.4995, Val Loss: 0.6931, Val Acc: 0.5446
Epoch 46/100, Loss: 0.6931, Acc: 0.4982, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 47/100, Loss: 0.6931, Acc: 0.5038, Val Loss: 0.6931, Val Acc: 0.5011
Epoch 48/100, Loss: 0.6931, Acc: 0.4987, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 49/100, Loss: 0.6931, Acc: 0.5070, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 50/100, Loss: 0.6931, Acc: 0.5024, Val Loss: 0.6931, Val Acc: 0.5306
Epoch 51/100, Loss: 0.6931, Acc: 0.5042, Val Loss: 0.6931, Val Acc: 0.5490
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6931, Acc: 0.5123, Val Loss: 0.6931, Val Acc: 0.5545
Epoch 53/100, Loss: 0.6931, Acc: 0.5154, Val Loss: 0.6931, Val Acc: 0.5431
Epoch 54/100, Loss: 0.6930, Acc: 0.5237, Val Loss: 0.6931, Val Acc: 0.5453
Epoch 55/100, Loss: 0.6930, Acc: 0.5063, Val Loss: 0.6931, Val Acc: 0.5471
Epoch 56/100, Loss: 0.6930, Acc: 0.5319, Val Loss: 0.6931, Val Acc: 0.5457
Epoch 57/100, Loss: 0.6931, Acc: 0.5081, Val Loss: 0.6931, Val Acc: 0.5523
Epoch 58/100, Loss: 0.6930, Acc: 0.5240, Val Loss: 0.6930, Val Acc: 0.5302
Epoch 59/100, Loss: 0.6930, Acc: 0.5297, Val Loss: 0.6929, Val Acc: 0.5493
Epoch 60/100, Loss: 0.6925, Acc: 0.5215, Val Loss: 0.6923, Val Acc: 0.5203
Epoch 61/100, Loss: 0.6923, Acc: 0.5203, Val Loss: 0.6919, Val Acc: 0.5317
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6880, Acc: 0.5495, Val Loss: 0.6842, Val Acc: 0.5556
Mejor modelo guardado con Val Loss: 0.6842
Epoch 63/100, Loss: 0.6851, Acc: 0.5706, Val Loss: 0.6840, Val Acc: 0.5615
Mejor modelo guardado con Val Loss: 0.6840
Epoch 64/100, Loss: 0.6847, Acc: 0.5736, Val Loss: 0.6836, Val Acc: 0.5703
Mejor modelo guardado con Val Loss: 0.6836
Epoch 65/100, Loss: 0.6845, Acc: 0.5751, Val Loss: 0.6842, Val Acc: 0.5619
Epoch 66/100, Loss: 0.6843, Acc: 0.5749, Val Loss: 0.6838, Val Acc: 0.5633
Epoch 67/100, Loss: 0.6842, Acc: 0.5795, Val Loss: 0.6839, Val Acc: 0.5626
Epoch 68/100, Loss: 0.6840, Acc: 0.5787, Val Loss: 0.6842, Val Acc: 0.5604
Epoch 69/100, Loss: 0.6838, Acc: 0.5787, Val Loss: 0.6836, Val Acc: 0.5685
Epoch 70/100, Loss: 0.6837, Acc: 0.5772, Val Loss: 0.6836, Val Acc: 0.5681
Epoch 71/100, Loss: 0.6836, Acc: 0.5784, Val Loss: 0.6834, Val Acc: 0.5718
Mejor modelo guardado con Val Loss: 0.6834
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6835, Acc: 0.5793, Val Loss: 0.6838, Val Acc: 0.5630
Epoch 73/100, Loss: 0.6835, Acc: 0.5794, Val Loss: 0.6836, Val Acc: 0.5696
Epoch 74/100, Loss: 0.6834, Acc: 0.5804, Val Loss: 0.6836, Val Acc: 0.5692
Epoch 75/100, Loss: 0.6833, Acc: 0.5805, Val Loss: 0.6837, Val Acc: 0.5692
Epoch 76/100, Loss: 0.6833, Acc: 0.5790, Val Loss: 0.6836, Val Acc: 0.5685
Epoch 77/100, Loss: 0.6833, Acc: 0.5797, Val Loss: 0.6837, Val Acc: 0.5659
Epoch 78/100, Loss: 0.6832, Acc: 0.5815, Val Loss: 0.6836, Val Acc: 0.5692
Epoch 79/100, Loss: 0.6832, Acc: 0.5802, Val Loss: 0.6839, Val Acc: 0.5633
Epoch 80/100, Loss: 0.6831, Acc: 0.5802, Val Loss: 0.6839, Val Acc: 0.5644
Epoch 81/100, Loss: 0.6831, Acc: 0.5818, Val Loss: 0.6838, Val Acc: 0.5652
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6828, Acc: 0.5811, Val Loss: 0.6834, Val Acc: 0.5663
Epoch 83/100, Loss: 0.6816, Acc: 0.5828, Val Loss: 0.6826, Val Acc: 0.5733
Mejor modelo guardado con Val Loss: 0.6826
Epoch 84/100, Loss: 0.6814, Acc: 0.5833, Val Loss: 0.6825, Val Acc: 0.5707
Mejor modelo guardado con Val Loss: 0.6825
Epoch 85/100, Loss: 0.6813, Acc: 0.5817, Val Loss: 0.6828, Val Acc: 0.5692
Epoch 86/100, Loss: 0.6813, Acc: 0.5826, Val Loss: 0.6827, Val Acc: 0.5685
Epoch 87/100, Loss: 0.6812, Acc: 0.5825, Val Loss: 0.6825, Val Acc: 0.5700
Mejor modelo guardado con Val Loss: 0.6825
Epoch 88/100, Loss: 0.6810, Acc: 0.5832, Val Loss: 0.6817, Val Acc: 0.5758
Mejor modelo guardado con Val Loss: 0.6817
Epoch 89/100, Loss: 0.6794, Acc: 0.5814, Val Loss: 0.6777, Val Acc: 0.5652
Mejor modelo guardado con Val Loss: 0.6777
Epoch 90/100, Loss: 0.6787, Acc: 0.5831, Val Loss: 0.6772, Val Acc: 0.5630
Mejor modelo guardado con Val Loss: 0.6772
Epoch 91/100, Loss: 0.6786, Acc: 0.5835, Val Loss: 0.6772, Val Acc: 0.5637
Mejor modelo guardado con Val Loss: 0.6772
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6785, Acc: 0.5825, Val Loss: 0.6769, Val Acc: 0.5633
Mejor modelo guardado con Val Loss: 0.6769
Epoch 93/100, Loss: 0.6784, Acc: 0.5816, Val Loss: 0.6768, Val Acc: 0.5655
Mejor modelo guardado con Val Loss: 0.6768
Epoch 94/100, Loss: 0.6784, Acc: 0.5834, Val Loss: 0.6771, Val Acc: 0.5648
Epoch 95/100, Loss: 0.6783, Acc: 0.5843, Val Loss: 0.6769, Val Acc: 0.5644
Epoch 96/100, Loss: 0.6783, Acc: 0.5843, Val Loss: 0.6768, Val Acc: 0.5637
Epoch 97/100, Loss: 0.6782, Acc: 0.5841, Val Loss: 0.6768, Val Acc: 0.5641
Mejor modelo guardado con Val Loss: 0.6768
Epoch 98/100, Loss: 0.6781, Acc: 0.5840, Val Loss: 0.6768, Val Acc: 0.5630
Epoch 99/100, Loss: 0.6781, Acc: 0.5841, Val Loss: 0.6768, Val Acc: 0.5626
Epoch 100/100, Loss: 0.6780, Acc: 0.5852, Val Loss: 0.6766, Val Acc: 0.5663
Mejor modelo guardado con Val Loss: 0.6766

##############################
Resultados para principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5 
 {'training': [0.6780150785039304, 0.585233541743288, 0.5818149655050415, 0.6050404709345106, 0.593200468933177], 'validate': [0.676568350126577, 0.5662739322533137, 0.5679389312977099, 0.5486725663716814, 0.5581395348837209], 'test': [0.6751403554722115, 0.6051236749116607, 0.6053412462908012, 0.6014150943396226, 0.6033717834960071]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  065  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  065  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6936, Acc: 0.5049, Val Loss: 0.6925, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6925
Epoch 2/100, Loss: 0.6935, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 3/100, Loss: 0.6933, Acc: 0.5049, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 4/100, Loss: 0.6934, Acc: 0.4953, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 5/100, Loss: 0.6934, Acc: 0.4968, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 6/100, Loss: 0.6935, Acc: 0.4907, Val Loss: 0.6937, Val Acc: 0.4993
Epoch 7/100, Loss: 0.6933, Acc: 0.5049, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 8/100, Loss: 0.6933, Acc: 0.5017, Val Loss: 0.6936, Val Acc: 0.4993
Epoch 9/100, Loss: 0.6936, Acc: 0.4832, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 10/100, Loss: 0.6934, Acc: 0.5022, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 11/100, Loss: 0.6935, Acc: 0.4925, Val Loss: 0.6931, Val Acc: 0.5007
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.5059, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 13/100, Loss: 0.6934, Acc: 0.4950, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 14/100, Loss: 0.6933, Acc: 0.4998, Val Loss: 0.6936, Val Acc: 0.4993
Epoch 15/100, Loss: 0.6932, Acc: 0.4995, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 16/100, Loss: 0.6934, Acc: 0.4939, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 17/100, Loss: 0.6933, Acc: 0.4976, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 18/100, Loss: 0.6933, Acc: 0.4967, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 19/100, Loss: 0.6933, Acc: 0.4947, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 20/100, Loss: 0.6935, Acc: 0.4923, Val Loss: 0.6938, Val Acc: 0.4993
Epoch 21/100, Loss: 0.6934, Acc: 0.4963, Val Loss: 0.6931, Val Acc: 0.5007
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4910, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 23/100, Loss: 0.6932, Acc: 0.4941, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 24/100, Loss: 0.6933, Acc: 0.4950, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 25/100, Loss: 0.6933, Acc: 0.4886, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 26/100, Loss: 0.6932, Acc: 0.5018, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 27/100, Loss: 0.6932, Acc: 0.5026, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 28/100, Loss: 0.6932, Acc: 0.5011, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 29/100, Loss: 0.6932, Acc: 0.5007, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 30/100, Loss: 0.6932, Acc: 0.4980, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 31/100, Loss: 0.6932, Acc: 0.4971, Val Loss: 0.6933, Val Acc: 0.4993
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4998, Val Loss: 0.6931, Val Acc: 0.5011
Epoch 33/100, Loss: 0.6932, Acc: 0.4998, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 34/100, Loss: 0.6932, Acc: 0.4976, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 35/100, Loss: 0.6932, Acc: 0.4937, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 36/100, Loss: 0.6932, Acc: 0.4994, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 37/100, Loss: 0.6932, Acc: 0.4972, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 38/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 39/100, Loss: 0.6932, Acc: 0.4991, Val Loss: 0.6931, Val Acc: 0.5011
Epoch 40/100, Loss: 0.6932, Acc: 0.4949, Val Loss: 0.6930, Val Acc: 0.5166
Epoch 41/100, Loss: 0.6932, Acc: 0.5006, Val Loss: 0.6931, Val Acc: 0.5004
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.4998, Val Loss: 0.6930, Val Acc: 0.5015
Epoch 43/100, Loss: 0.6932, Acc: 0.4952, Val Loss: 0.6931, Val Acc: 0.5361
Epoch 44/100, Loss: 0.6931, Acc: 0.5022, Val Loss: 0.6928, Val Acc: 0.5269
Epoch 45/100, Loss: 0.6930, Acc: 0.5098, Val Loss: 0.6927, Val Acc: 0.5335
Epoch 46/100, Loss: 0.6930, Acc: 0.5192, Val Loss: 0.6926, Val Acc: 0.5420
Epoch 47/100, Loss: 0.6929, Acc: 0.5217, Val Loss: 0.6924, Val Acc: 0.5596
Mejor modelo guardado con Val Loss: 0.6924
Epoch 48/100, Loss: 0.6929, Acc: 0.5219, Val Loss: 0.6922, Val Acc: 0.5615
Mejor modelo guardado con Val Loss: 0.6922
Epoch 49/100, Loss: 0.6929, Acc: 0.5169, Val Loss: 0.6924, Val Acc: 0.5434
Epoch 50/100, Loss: 0.6928, Acc: 0.5235, Val Loss: 0.6922, Val Acc: 0.5593
Mejor modelo guardado con Val Loss: 0.6922
Epoch 51/100, Loss: 0.6923, Acc: 0.5264, Val Loss: 0.6883, Val Acc: 0.6307
Mejor modelo guardado con Val Loss: 0.6883
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6913, Acc: 0.5365, Val Loss: 0.6863, Val Acc: 0.6344
Mejor modelo guardado con Val Loss: 0.6863
Epoch 53/100, Loss: 0.6910, Acc: 0.5441, Val Loss: 0.6859, Val Acc: 0.6337
Mejor modelo guardado con Val Loss: 0.6859
Epoch 54/100, Loss: 0.6904, Acc: 0.5490, Val Loss: 0.6843, Val Acc: 0.6436
Mejor modelo guardado con Val Loss: 0.6843
Epoch 55/100, Loss: 0.6901, Acc: 0.5509, Val Loss: 0.6841, Val Acc: 0.6506
Mejor modelo guardado con Val Loss: 0.6841
Epoch 56/100, Loss: 0.6899, Acc: 0.5543, Val Loss: 0.6836, Val Acc: 0.6473
Mejor modelo guardado con Val Loss: 0.6836
Epoch 57/100, Loss: 0.6898, Acc: 0.5570, Val Loss: 0.6836, Val Acc: 0.6484
Epoch 58/100, Loss: 0.6897, Acc: 0.5513, Val Loss: 0.6832, Val Acc: 0.6550
Mejor modelo guardado con Val Loss: 0.6832
Epoch 59/100, Loss: 0.6897, Acc: 0.5497, Val Loss: 0.6828, Val Acc: 0.6476
Mejor modelo guardado con Val Loss: 0.6828
Epoch 60/100, Loss: 0.6895, Acc: 0.5542, Val Loss: 0.6828, Val Acc: 0.6513
Mejor modelo guardado con Val Loss: 0.6828
Epoch 61/100, Loss: 0.6894, Acc: 0.5531, Val Loss: 0.6826, Val Acc: 0.6465
Mejor modelo guardado con Val Loss: 0.6826
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6893, Acc: 0.5553, Val Loss: 0.6825, Val Acc: 0.6543
Mejor modelo guardado con Val Loss: 0.6825
Epoch 63/100, Loss: 0.6893, Acc: 0.5553, Val Loss: 0.6823, Val Acc: 0.6546
Mejor modelo guardado con Val Loss: 0.6823
Epoch 64/100, Loss: 0.6892, Acc: 0.5560, Val Loss: 0.6823, Val Acc: 0.6462
Mejor modelo guardado con Val Loss: 0.6823
Epoch 65/100, Loss: 0.6890, Acc: 0.5548, Val Loss: 0.6795, Val Acc: 0.6443
Mejor modelo guardado con Val Loss: 0.6795
Epoch 66/100, Loss: 0.6870, Acc: 0.5689, Val Loss: 0.6796, Val Acc: 0.6256
Epoch 67/100, Loss: 0.6868, Acc: 0.5705, Val Loss: 0.6789, Val Acc: 0.6303
Mejor modelo guardado con Val Loss: 0.6789
Epoch 68/100, Loss: 0.6862, Acc: 0.5755, Val Loss: 0.6782, Val Acc: 0.6418
Mejor modelo guardado con Val Loss: 0.6782
Epoch 69/100, Loss: 0.6860, Acc: 0.5791, Val Loss: 0.6782, Val Acc: 0.6381
Epoch 70/100, Loss: 0.6860, Acc: 0.5761, Val Loss: 0.6780, Val Acc: 0.6410
Mejor modelo guardado con Val Loss: 0.6780
Epoch 71/100, Loss: 0.6858, Acc: 0.5760, Val Loss: 0.6779, Val Acc: 0.6351
Mejor modelo guardado con Val Loss: 0.6779
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6857, Acc: 0.5762, Val Loss: 0.6777, Val Acc: 0.6359
Mejor modelo guardado con Val Loss: 0.6777
Epoch 73/100, Loss: 0.6857, Acc: 0.5767, Val Loss: 0.6775, Val Acc: 0.6418
Mejor modelo guardado con Val Loss: 0.6775
Epoch 74/100, Loss: 0.6856, Acc: 0.5765, Val Loss: 0.6774, Val Acc: 0.6414
Mejor modelo guardado con Val Loss: 0.6774
Epoch 75/100, Loss: 0.6856, Acc: 0.5798, Val Loss: 0.6773, Val Acc: 0.6425
Mejor modelo guardado con Val Loss: 0.6773
Epoch 76/100, Loss: 0.6855, Acc: 0.5762, Val Loss: 0.6772, Val Acc: 0.6432
Mejor modelo guardado con Val Loss: 0.6772
Epoch 77/100, Loss: 0.6855, Acc: 0.5791, Val Loss: 0.6772, Val Acc: 0.6432
Epoch 78/100, Loss: 0.6854, Acc: 0.5799, Val Loss: 0.6771, Val Acc: 0.6421
Mejor modelo guardado con Val Loss: 0.6771
Epoch 79/100, Loss: 0.6853, Acc: 0.5795, Val Loss: 0.6770, Val Acc: 0.6429
Mejor modelo guardado con Val Loss: 0.6770
Epoch 80/100, Loss: 0.6853, Acc: 0.5773, Val Loss: 0.6769, Val Acc: 0.6440
Mejor modelo guardado con Val Loss: 0.6769
Epoch 81/100, Loss: 0.6852, Acc: 0.5798, Val Loss: 0.6768, Val Acc: 0.6403
Mejor modelo guardado con Val Loss: 0.6768
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6852, Acc: 0.5799, Val Loss: 0.6767, Val Acc: 0.6421
Mejor modelo guardado con Val Loss: 0.6767
Epoch 83/100, Loss: 0.6851, Acc: 0.5805, Val Loss: 0.6765, Val Acc: 0.6392
Mejor modelo guardado con Val Loss: 0.6765
Epoch 84/100, Loss: 0.6851, Acc: 0.5785, Val Loss: 0.6764, Val Acc: 0.6436
Mejor modelo guardado con Val Loss: 0.6764
Epoch 85/100, Loss: 0.6850, Acc: 0.5778, Val Loss: 0.6763, Val Acc: 0.6440
Mejor modelo guardado con Val Loss: 0.6763
Epoch 86/100, Loss: 0.6850, Acc: 0.5790, Val Loss: 0.6762, Val Acc: 0.6440
Mejor modelo guardado con Val Loss: 0.6762
Epoch 87/100, Loss: 0.6849, Acc: 0.5825, Val Loss: 0.6761, Val Acc: 0.6392
Mejor modelo guardado con Val Loss: 0.6761
Epoch 88/100, Loss: 0.6849, Acc: 0.5793, Val Loss: 0.6760, Val Acc: 0.6399
Mejor modelo guardado con Val Loss: 0.6760
Epoch 89/100, Loss: 0.6848, Acc: 0.5796, Val Loss: 0.6759, Val Acc: 0.6436
Mejor modelo guardado con Val Loss: 0.6759
Epoch 90/100, Loss: 0.6847, Acc: 0.5816, Val Loss: 0.6758, Val Acc: 0.6362
Mejor modelo guardado con Val Loss: 0.6758
Epoch 91/100, Loss: 0.6847, Acc: 0.5806, Val Loss: 0.6757, Val Acc: 0.6410
Mejor modelo guardado con Val Loss: 0.6757
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6846, Acc: 0.5814, Val Loss: 0.6757, Val Acc: 0.6406
Mejor modelo guardado con Val Loss: 0.6757
Epoch 93/100, Loss: 0.6846, Acc: 0.5799, Val Loss: 0.6755, Val Acc: 0.6421
Mejor modelo guardado con Val Loss: 0.6755
Epoch 94/100, Loss: 0.6845, Acc: 0.5810, Val Loss: 0.6754, Val Acc: 0.6447
Mejor modelo guardado con Val Loss: 0.6754
Epoch 95/100, Loss: 0.6845, Acc: 0.5819, Val Loss: 0.6753, Val Acc: 0.6403
Mejor modelo guardado con Val Loss: 0.6753
Epoch 96/100, Loss: 0.6844, Acc: 0.5802, Val Loss: 0.6753, Val Acc: 0.6381
Mejor modelo guardado con Val Loss: 0.6753
Epoch 97/100, Loss: 0.6844, Acc: 0.5788, Val Loss: 0.6751, Val Acc: 0.6399
Mejor modelo guardado con Val Loss: 0.6751
Epoch 98/100, Loss: 0.6843, Acc: 0.5807, Val Loss: 0.6750, Val Acc: 0.6392
Mejor modelo guardado con Val Loss: 0.6750
Epoch 99/100, Loss: 0.6842, Acc: 0.5821, Val Loss: 0.6748, Val Acc: 0.6447
Mejor modelo guardado con Val Loss: 0.6748
Epoch 100/100, Loss: 0.6842, Acc: 0.5809, Val Loss: 0.6748, Val Acc: 0.6395

##############################
Resultados para principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5 
 {'training': [0.6841989412558521, 0.5809121000367782, 0.5698155216284987, 0.6591243561442237, 0.6112248379392698], 'validate': [0.6748212381850841, 0.6395434462444771, 0.6330275229357798, 0.661504424778761, 0.6469527587450414], 'test': [0.6786067529960915, 0.6148409893992933, 0.6133177570093458, 0.6191037735849056, 0.6161971830985915]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  013  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  013  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6848, Acc: 0.5609, Val Loss: 0.6714, Val Acc: 0.6756
Mejor modelo guardado con Val Loss: 0.6714
Epoch 2/100, Loss: 0.6791, Acc: 0.6010, Val Loss: 0.6589, Val Acc: 0.6719
Mejor modelo guardado con Val Loss: 0.6589
Epoch 3/100, Loss: 0.6741, Acc: 0.5945, Val Loss: 0.6381, Val Acc: 0.7032
Mejor modelo guardado con Val Loss: 0.6381
Epoch 4/100, Loss: 0.6666, Acc: 0.6145, Val Loss: 0.6343, Val Acc: 0.7073
Mejor modelo guardado con Val Loss: 0.6343
Epoch 5/100, Loss: 0.6633, Acc: 0.6116, Val Loss: 0.6107, Val Acc: 0.7320
Mejor modelo guardado con Val Loss: 0.6107
Epoch 6/100, Loss: 0.6601, Acc: 0.6161, Val Loss: 0.6183, Val Acc: 0.7117
Epoch 7/100, Loss: 0.6579, Acc: 0.6171, Val Loss: 0.6774, Val Acc: 0.5622
Epoch 8/100, Loss: 0.6640, Acc: 0.6056, Val Loss: 0.6500, Val Acc: 0.5239
Epoch 9/100, Loss: 0.6630, Acc: 0.6054, Val Loss: 0.5968, Val Acc: 0.7172
Mejor modelo guardado con Val Loss: 0.5968
Epoch 10/100, Loss: 0.6535, Acc: 0.6217, Val Loss: 0.5811, Val Acc: 0.7441
Mejor modelo guardado con Val Loss: 0.5811
Epoch 11/100, Loss: 0.6519, Acc: 0.6204, Val Loss: 0.5964, Val Acc: 0.7014
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6461, Acc: 0.6316, Val Loss: 0.6235, Val Acc: 0.6859
Epoch 13/100, Loss: 0.6452, Acc: 0.6351, Val Loss: 0.5954, Val Acc: 0.7062
Epoch 14/100, Loss: 0.6436, Acc: 0.6353, Val Loss: 0.6191, Val Acc: 0.6896
Epoch 15/100, Loss: 0.6448, Acc: 0.6352, Val Loss: 0.5868, Val Acc: 0.7327
Epoch 16/100, Loss: 0.6432, Acc: 0.6336, Val Loss: 0.5805, Val Acc: 0.7426
Mejor modelo guardado con Val Loss: 0.5805
Epoch 17/100, Loss: 0.6422, Acc: 0.6401, Val Loss: 0.5889, Val Acc: 0.6959
Epoch 18/100, Loss: 0.6404, Acc: 0.6384, Val Loss: 0.6064, Val Acc: 0.7113
Epoch 19/100, Loss: 0.6414, Acc: 0.6380, Val Loss: 0.5771, Val Acc: 0.7430
Mejor modelo guardado con Val Loss: 0.5771
Epoch 20/100, Loss: 0.6423, Acc: 0.6410, Val Loss: 0.5639, Val Acc: 0.7507
Mejor modelo guardado con Val Loss: 0.5639
Epoch 21/100, Loss: 0.6398, Acc: 0.6387, Val Loss: 0.5595, Val Acc: 0.7610
Mejor modelo guardado con Val Loss: 0.5595
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6373, Acc: 0.6482, Val Loss: 0.5771, Val Acc: 0.7401
Epoch 23/100, Loss: 0.6381, Acc: 0.6446, Val Loss: 0.5852, Val Acc: 0.7364
Epoch 24/100, Loss: 0.6377, Acc: 0.6439, Val Loss: 0.5676, Val Acc: 0.7511
Epoch 25/100, Loss: 0.6363, Acc: 0.6497, Val Loss: 0.6006, Val Acc: 0.7213
Epoch 26/100, Loss: 0.6367, Acc: 0.6501, Val Loss: 0.5840, Val Acc: 0.7342
Epoch 27/100, Loss: 0.6359, Acc: 0.6479, Val Loss: 0.5794, Val Acc: 0.7356
Epoch 28/100, Loss: 0.6358, Acc: 0.6496, Val Loss: 0.5866, Val Acc: 0.7323
Epoch 29/100, Loss: 0.6349, Acc: 0.6483, Val Loss: 0.5786, Val Acc: 0.7364
Epoch 30/100, Loss: 0.6351, Acc: 0.6504, Val Loss: 0.5660, Val Acc: 0.7496
Epoch 31/100, Loss: 0.6344, Acc: 0.6530, Val Loss: 0.5653, Val Acc: 0.7496
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6332, Acc: 0.6528, Val Loss: 0.5608, Val Acc: 0.7563
Epoch 33/100, Loss: 0.6338, Acc: 0.6489, Val Loss: 0.5732, Val Acc: 0.7430
Epoch 34/100, Loss: 0.6331, Acc: 0.6524, Val Loss: 0.5728, Val Acc: 0.7423
Epoch 35/100, Loss: 0.6333, Acc: 0.6496, Val Loss: 0.5835, Val Acc: 0.7205
Epoch 36/100, Loss: 0.6331, Acc: 0.6527, Val Loss: 0.5926, Val Acc: 0.7176
Epoch 37/100, Loss: 0.6315, Acc: 0.6577, Val Loss: 0.5564, Val Acc: 0.7581
Mejor modelo guardado con Val Loss: 0.5564
Epoch 38/100, Loss: 0.6315, Acc: 0.6524, Val Loss: 0.5803, Val Acc: 0.7331
Epoch 39/100, Loss: 0.6313, Acc: 0.6544, Val Loss: 0.5608, Val Acc: 0.7507
Epoch 40/100, Loss: 0.6308, Acc: 0.6569, Val Loss: 0.5722, Val Acc: 0.7419
Epoch 41/100, Loss: 0.6303, Acc: 0.6552, Val Loss: 0.5738, Val Acc: 0.7294
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6302, Acc: 0.6561, Val Loss: 0.5741, Val Acc: 0.7356
Epoch 43/100, Loss: 0.6296, Acc: 0.6572, Val Loss: 0.5698, Val Acc: 0.7430
Epoch 44/100, Loss: 0.6294, Acc: 0.6565, Val Loss: 0.5745, Val Acc: 0.7375
Epoch 45/100, Loss: 0.6294, Acc: 0.6574, Val Loss: 0.5793, Val Acc: 0.7334
Epoch 46/100, Loss: 0.6293, Acc: 0.6576, Val Loss: 0.5768, Val Acc: 0.7353
Epoch 47/100, Loss: 0.6292, Acc: 0.6591, Val Loss: 0.5614, Val Acc: 0.7467
Epoch 48/100, Loss: 0.6294, Acc: 0.6565, Val Loss: 0.5757, Val Acc: 0.7375
Epoch 49/100, Loss: 0.6288, Acc: 0.6578, Val Loss: 0.5683, Val Acc: 0.7426
Epoch 50/100, Loss: 0.6287, Acc: 0.6574, Val Loss: 0.5746, Val Acc: 0.7386
Epoch 51/100, Loss: 0.6284, Acc: 0.6582, Val Loss: 0.5588, Val Acc: 0.7478
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6280, Acc: 0.6582, Val Loss: 0.5675, Val Acc: 0.7393
Epoch 53/100, Loss: 0.6278, Acc: 0.6586, Val Loss: 0.5761, Val Acc: 0.7345
Epoch 54/100, Loss: 0.6276, Acc: 0.6602, Val Loss: 0.5705, Val Acc: 0.7404
Epoch 55/100, Loss: 0.6278, Acc: 0.6592, Val Loss: 0.5745, Val Acc: 0.7349
Epoch 56/100, Loss: 0.6274, Acc: 0.6589, Val Loss: 0.5658, Val Acc: 0.7437
Epoch 57/100, Loss: 0.6274, Acc: 0.6570, Val Loss: 0.5703, Val Acc: 0.7393
Epoch 58/100, Loss: 0.6270, Acc: 0.6595, Val Loss: 0.5588, Val Acc: 0.7485
Epoch 59/100, Loss: 0.6274, Acc: 0.6589, Val Loss: 0.5719, Val Acc: 0.7375
Epoch 60/100, Loss: 0.6272, Acc: 0.6595, Val Loss: 0.5644, Val Acc: 0.7434
Epoch 61/100, Loss: 0.6272, Acc: 0.6583, Val Loss: 0.5684, Val Acc: 0.7393
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6269, Acc: 0.6604, Val Loss: 0.5678, Val Acc: 0.7408
Epoch 63/100, Loss: 0.6267, Acc: 0.6611, Val Loss: 0.5682, Val Acc: 0.7397
Epoch 64/100, Loss: 0.6267, Acc: 0.6607, Val Loss: 0.5680, Val Acc: 0.7419
Epoch 65/100, Loss: 0.6265, Acc: 0.6615, Val Loss: 0.5671, Val Acc: 0.7390
Epoch 66/100, Loss: 0.6263, Acc: 0.6604, Val Loss: 0.5678, Val Acc: 0.7378
Epoch 67/100, Loss: 0.6263, Acc: 0.6604, Val Loss: 0.5678, Val Acc: 0.7393
Epoch 68/100, Loss: 0.6262, Acc: 0.6613, Val Loss: 0.5708, Val Acc: 0.7378
Epoch 69/100, Loss: 0.6262, Acc: 0.6614, Val Loss: 0.5696, Val Acc: 0.7375
Epoch 70/100, Loss: 0.6261, Acc: 0.6604, Val Loss: 0.5652, Val Acc: 0.7397
Epoch 71/100, Loss: 0.6260, Acc: 0.6592, Val Loss: 0.5634, Val Acc: 0.7408
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6260, Acc: 0.6618, Val Loss: 0.5671, Val Acc: 0.7390
Epoch 73/100, Loss: 0.6259, Acc: 0.6614, Val Loss: 0.5666, Val Acc: 0.7390
Epoch 74/100, Loss: 0.6258, Acc: 0.6615, Val Loss: 0.5696, Val Acc: 0.7375
Epoch 75/100, Loss: 0.6258, Acc: 0.6608, Val Loss: 0.5720, Val Acc: 0.7367
Epoch 76/100, Loss: 0.6258, Acc: 0.6607, Val Loss: 0.5691, Val Acc: 0.7371
Epoch 77/100, Loss: 0.6258, Acc: 0.6612, Val Loss: 0.5671, Val Acc: 0.7401
Epoch 78/100, Loss: 0.6257, Acc: 0.6615, Val Loss: 0.5683, Val Acc: 0.7386
Epoch 79/100, Loss: 0.6257, Acc: 0.6616, Val Loss: 0.5659, Val Acc: 0.7386
Epoch 80/100, Loss: 0.6257, Acc: 0.6617, Val Loss: 0.5687, Val Acc: 0.7382
Epoch 81/100, Loss: 0.6257, Acc: 0.6621, Val Loss: 0.5683, Val Acc: 0.7386
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6257, Acc: 0.6610, Val Loss: 0.5678, Val Acc: 0.7390
Epoch 83/100, Loss: 0.6255, Acc: 0.6620, Val Loss: 0.5710, Val Acc: 0.7378
Epoch 84/100, Loss: 0.6255, Acc: 0.6615, Val Loss: 0.5710, Val Acc: 0.7364
Epoch 85/100, Loss: 0.6255, Acc: 0.6608, Val Loss: 0.5688, Val Acc: 0.7375
Epoch 86/100, Loss: 0.6250, Acc: 0.6615, Val Loss: 0.5617, Val Acc: 0.7393
Epoch 87/100, Loss: 0.6248, Acc: 0.6612, Val Loss: 0.5659, Val Acc: 0.7397
Epoch 88/100, Loss: 0.6247, Acc: 0.6616, Val Loss: 0.5657, Val Acc: 0.7397
Epoch 89/100, Loss: 0.6247, Acc: 0.6619, Val Loss: 0.5618, Val Acc: 0.7401
Epoch 90/100, Loss: 0.6247, Acc: 0.6614, Val Loss: 0.5640, Val Acc: 0.7397
Epoch 91/100, Loss: 0.6245, Acc: 0.6627, Val Loss: 0.5629, Val Acc: 0.7397
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6244, Acc: 0.6615, Val Loss: 0.5598, Val Acc: 0.7419
Epoch 93/100, Loss: 0.6243, Acc: 0.6624, Val Loss: 0.5593, Val Acc: 0.7423
Epoch 94/100, Loss: 0.6243, Acc: 0.6623, Val Loss: 0.5609, Val Acc: 0.7412
Epoch 95/100, Loss: 0.6242, Acc: 0.6617, Val Loss: 0.5600, Val Acc: 0.7412
Epoch 96/100, Loss: 0.6241, Acc: 0.6619, Val Loss: 0.5626, Val Acc: 0.7401
Epoch 97/100, Loss: 0.6241, Acc: 0.6633, Val Loss: 0.5616, Val Acc: 0.7412
Epoch 98/100, Loss: 0.6240, Acc: 0.6624, Val Loss: 0.5615, Val Acc: 0.7412
Epoch 99/100, Loss: 0.6238, Acc: 0.6633, Val Loss: 0.5598, Val Acc: 0.7423
Epoch 100/100, Loss: 0.6236, Acc: 0.6628, Val Loss: 0.5611, Val Acc: 0.7415

##############################
Resultados para principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5 
 {'training': [0.6236035893532492, 0.6628356013240162, 0.6839259721355792, 0.6050404709345106, 0.6420693020985847], 'validate': [0.5610626246346984, 0.7415316642120766, 0.6894553881807648, 0.8775811209439528, 0.772225827384815], 'test': [0.8019351799179006, 0.4637809187279152, 0.4658283214871515, 0.5023584905660378, 0.48340425531914893]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  063  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  063  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6932, Acc: 0.5074, Val Loss: 0.6940, Val Acc: 0.4993
Mejor modelo guardado con Val Loss: 0.6940
Epoch 2/100, Loss: 0.6935, Acc: 0.4956, Val Loss: 0.6931, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6931
Epoch 3/100, Loss: 0.6937, Acc: 0.4960, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 4/100, Loss: 0.6936, Acc: 0.4955, Val Loss: 0.6930, Val Acc: 0.5011
Mejor modelo guardado con Val Loss: 0.6930
Epoch 5/100, Loss: 0.6935, Acc: 0.4984, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 6/100, Loss: 0.6935, Acc: 0.5037, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 7/100, Loss: 0.6935, Acc: 0.5017, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 8/100, Loss: 0.6935, Acc: 0.4914, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 9/100, Loss: 0.6934, Acc: 0.5020, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 10/100, Loss: 0.6936, Acc: 0.4927, Val Loss: 0.6937, Val Acc: 0.4993
Epoch 11/100, Loss: 0.6935, Acc: 0.5015, Val Loss: 0.6932, Val Acc: 0.4993
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4982, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 13/100, Loss: 0.6933, Acc: 0.4971, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 14/100, Loss: 0.6932, Acc: 0.4936, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 15/100, Loss: 0.6933, Acc: 0.4875, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 16/100, Loss: 0.6933, Acc: 0.4936, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 17/100, Loss: 0.6933, Acc: 0.4982, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 18/100, Loss: 0.6934, Acc: 0.4967, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 19/100, Loss: 0.6934, Acc: 0.4928, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 20/100, Loss: 0.6933, Acc: 0.5000, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 21/100, Loss: 0.6934, Acc: 0.4928, Val Loss: 0.6935, Val Acc: 0.4993
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4969, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 23/100, Loss: 0.6932, Acc: 0.5007, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 24/100, Loss: 0.6933, Acc: 0.4980, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 25/100, Loss: 0.6932, Acc: 0.5024, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 26/100, Loss: 0.6933, Acc: 0.4961, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 27/100, Loss: 0.6932, Acc: 0.5020, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 28/100, Loss: 0.6933, Acc: 0.4910, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 29/100, Loss: 0.6932, Acc: 0.5024, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 30/100, Loss: 0.6932, Acc: 0.5015, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 31/100, Loss: 0.6932, Acc: 0.4941, Val Loss: 0.6932, Val Acc: 0.4993
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4926, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 33/100, Loss: 0.6932, Acc: 0.5018, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 34/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 35/100, Loss: 0.6932, Acc: 0.4950, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 36/100, Loss: 0.6932, Acc: 0.4880, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 37/100, Loss: 0.6932, Acc: 0.4974, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 38/100, Loss: 0.6932, Acc: 0.4993, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 39/100, Loss: 0.6932, Acc: 0.4942, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 40/100, Loss: 0.6932, Acc: 0.4954, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 41/100, Loss: 0.6932, Acc: 0.4936, Val Loss: 0.6931, Val Acc: 0.5007
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 43/100, Loss: 0.6931, Acc: 0.4960, Val Loss: 0.6930, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6930
Epoch 44/100, Loss: 0.6930, Acc: 0.5012, Val Loss: 0.6930, Val Acc: 0.5122
Epoch 45/100, Loss: 0.6930, Acc: 0.5031, Val Loss: 0.6930, Val Acc: 0.5041
Mejor modelo guardado con Val Loss: 0.6930
Epoch 46/100, Loss: 0.6930, Acc: 0.4994, Val Loss: 0.6930, Val Acc: 0.5077
Epoch 47/100, Loss: 0.6930, Acc: 0.5040, Val Loss: 0.6930, Val Acc: 0.5114
Epoch 48/100, Loss: 0.6930, Acc: 0.5105, Val Loss: 0.6930, Val Acc: 0.5099
Epoch 49/100, Loss: 0.6930, Acc: 0.5039, Val Loss: 0.6930, Val Acc: 0.5125
Epoch 50/100, Loss: 0.6930, Acc: 0.5017, Val Loss: 0.6930, Val Acc: 0.5077
Epoch 51/100, Loss: 0.6930, Acc: 0.5090, Val Loss: 0.6929, Val Acc: 0.5147
Mejor modelo guardado con Val Loss: 0.6929
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6926, Acc: 0.5193, Val Loss: 0.6931, Val Acc: 0.5133
Epoch 53/100, Loss: 0.6927, Acc: 0.5169, Val Loss: 0.6928, Val Acc: 0.5136
Mejor modelo guardado con Val Loss: 0.6928
Epoch 54/100, Loss: 0.6924, Acc: 0.5245, Val Loss: 0.6930, Val Acc: 0.5048
Epoch 55/100, Loss: 0.6924, Acc: 0.5252, Val Loss: 0.6931, Val Acc: 0.5155
Epoch 56/100, Loss: 0.6924, Acc: 0.5248, Val Loss: 0.6930, Val Acc: 0.5063
Epoch 57/100, Loss: 0.6924, Acc: 0.5217, Val Loss: 0.6931, Val Acc: 0.5066
Epoch 58/100, Loss: 0.6924, Acc: 0.5229, Val Loss: 0.6930, Val Acc: 0.5122
Epoch 59/100, Loss: 0.6924, Acc: 0.5248, Val Loss: 0.6931, Val Acc: 0.5114
Epoch 60/100, Loss: 0.6923, Acc: 0.5240, Val Loss: 0.6931, Val Acc: 0.5122
Epoch 61/100, Loss: 0.6923, Acc: 0.5270, Val Loss: 0.6931, Val Acc: 0.5103
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6922, Acc: 0.5294, Val Loss: 0.6931, Val Acc: 0.5107
Epoch 63/100, Loss: 0.6922, Acc: 0.5291, Val Loss: 0.6931, Val Acc: 0.5081
Epoch 64/100, Loss: 0.6922, Acc: 0.5310, Val Loss: 0.6931, Val Acc: 0.5151
Epoch 65/100, Loss: 0.6922, Acc: 0.5304, Val Loss: 0.6931, Val Acc: 0.5191
Epoch 66/100, Loss: 0.6922, Acc: 0.5285, Val Loss: 0.6930, Val Acc: 0.5199
Epoch 67/100, Loss: 0.6922, Acc: 0.5285, Val Loss: 0.6930, Val Acc: 0.5129
Epoch 68/100, Loss: 0.6922, Acc: 0.5273, Val Loss: 0.6931, Val Acc: 0.5107
Epoch 69/100, Loss: 0.6922, Acc: 0.5315, Val Loss: 0.6931, Val Acc: 0.5140
Epoch 70/100, Loss: 0.6921, Acc: 0.5318, Val Loss: 0.6931, Val Acc: 0.5180
Epoch 71/100, Loss: 0.6921, Acc: 0.5310, Val Loss: 0.6931, Val Acc: 0.5151
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6921, Acc: 0.5307, Val Loss: 0.6931, Val Acc: 0.5166
Epoch 73/100, Loss: 0.6921, Acc: 0.5300, Val Loss: 0.6931, Val Acc: 0.5144
Epoch 74/100, Loss: 0.6921, Acc: 0.5290, Val Loss: 0.6931, Val Acc: 0.5147
Epoch 75/100, Loss: 0.6921, Acc: 0.5323, Val Loss: 0.6930, Val Acc: 0.5133
Epoch 76/100, Loss: 0.6921, Acc: 0.5308, Val Loss: 0.6930, Val Acc: 0.5144
Epoch 77/100, Loss: 0.6921, Acc: 0.5308, Val Loss: 0.6930, Val Acc: 0.5129
Epoch 78/100, Loss: 0.6921, Acc: 0.5323, Val Loss: 0.6930, Val Acc: 0.5144
Epoch 79/100, Loss: 0.6921, Acc: 0.5319, Val Loss: 0.6930, Val Acc: 0.5158
Epoch 80/100, Loss: 0.6920, Acc: 0.5331, Val Loss: 0.6930, Val Acc: 0.5180
Epoch 81/100, Loss: 0.6920, Acc: 0.5300, Val Loss: 0.6930, Val Acc: 0.5151
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6920, Acc: 0.5319, Val Loss: 0.6931, Val Acc: 0.5158
Epoch 83/100, Loss: 0.6920, Acc: 0.5325, Val Loss: 0.6930, Val Acc: 0.5162
Epoch 84/100, Loss: 0.6920, Acc: 0.5330, Val Loss: 0.6930, Val Acc: 0.5166
Epoch 85/100, Loss: 0.6920, Acc: 0.5313, Val Loss: 0.6931, Val Acc: 0.5180
Epoch 86/100, Loss: 0.6920, Acc: 0.5335, Val Loss: 0.6931, Val Acc: 0.5173
Epoch 87/100, Loss: 0.6920, Acc: 0.5292, Val Loss: 0.6930, Val Acc: 0.5151
Epoch 88/100, Loss: 0.6920, Acc: 0.5315, Val Loss: 0.6930, Val Acc: 0.5173
Epoch 89/100, Loss: 0.6920, Acc: 0.5327, Val Loss: 0.6930, Val Acc: 0.5147
Epoch 90/100, Loss: 0.6920, Acc: 0.5319, Val Loss: 0.6930, Val Acc: 0.5162
Epoch 91/100, Loss: 0.6920, Acc: 0.5317, Val Loss: 0.6930, Val Acc: 0.5173
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6920, Acc: 0.5328, Val Loss: 0.6930, Val Acc: 0.5191
Epoch 93/100, Loss: 0.6919, Acc: 0.5300, Val Loss: 0.6930, Val Acc: 0.5169
Epoch 94/100, Loss: 0.6920, Acc: 0.5314, Val Loss: 0.6930, Val Acc: 0.5158
Epoch 95/100, Loss: 0.6919, Acc: 0.5322, Val Loss: 0.6930, Val Acc: 0.5140
Epoch 96/100, Loss: 0.6919, Acc: 0.5324, Val Loss: 0.6930, Val Acc: 0.5147
Epoch 97/100, Loss: 0.6919, Acc: 0.5336, Val Loss: 0.6930, Val Acc: 0.5177
Epoch 98/100, Loss: 0.6919, Acc: 0.5348, Val Loss: 0.6929, Val Acc: 0.5188
Epoch 99/100, Loss: 0.6919, Acc: 0.5314, Val Loss: 0.6929, Val Acc: 0.5191
Epoch 100/100, Loss: 0.6919, Acc: 0.5325, Val Loss: 0.6929, Val Acc: 0.5184

##############################
Resultados para principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5 
 {'training': [0.6918582623607317, 0.5325487311511585, 0.524155915454296, 0.7025386313465783, 0.6003772991667977], 'validate': [0.692907664664956, 0.5184094256259205, 0.5140350877192983, 0.6482300884955752, 0.5733855185909981], 'test': [0.693275017870797, 0.49322732626619553, 0.49506903353057197, 0.7399764150943396, 0.5932403687071615]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  070  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  070  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6940, Acc: 0.5013, Val Loss: 0.6937, Val Acc: 0.4993
Mejor modelo guardado con Val Loss: 0.6937
Epoch 2/100, Loss: 0.6936, Acc: 0.4947, Val Loss: 0.6939, Val Acc: 0.4993
Epoch 3/100, Loss: 0.6935, Acc: 0.4926, Val Loss: 0.6932, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6932
Epoch 4/100, Loss: 0.6933, Acc: 0.5009, Val Loss: 0.6930, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6930
Epoch 5/100, Loss: 0.6935, Acc: 0.4971, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 6/100, Loss: 0.6934, Acc: 0.4888, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 7/100, Loss: 0.6932, Acc: 0.5018, Val Loss: 0.6935, Val Acc: 0.5007
Epoch 8/100, Loss: 0.6937, Acc: 0.4974, Val Loss: 0.6934, Val Acc: 0.5007
Epoch 9/100, Loss: 0.6932, Acc: 0.5007, Val Loss: 0.6940, Val Acc: 0.4993
Epoch 10/100, Loss: 0.6936, Acc: 0.4993, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 11/100, Loss: 0.6933, Acc: 0.4994, Val Loss: 0.6930, Val Acc: 0.5007
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.5019, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 13/100, Loss: 0.6933, Acc: 0.4958, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 14/100, Loss: 0.6932, Acc: 0.4915, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 15/100, Loss: 0.6935, Acc: 0.4969, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 16/100, Loss: 0.6931, Acc: 0.5075, Val Loss: 0.6932, Val Acc: 0.5007
Epoch 17/100, Loss: 0.6934, Acc: 0.4906, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 18/100, Loss: 0.6933, Acc: 0.4967, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 19/100, Loss: 0.6933, Acc: 0.4994, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 20/100, Loss: 0.6932, Acc: 0.5019, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 21/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6930, Val Acc: 0.5007
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4914, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 23/100, Loss: 0.6932, Acc: 0.5001, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 24/100, Loss: 0.6932, Acc: 0.4939, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 25/100, Loss: 0.6932, Acc: 0.5004, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 26/100, Loss: 0.6932, Acc: 0.4976, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 27/100, Loss: 0.6932, Acc: 0.4912, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 28/100, Loss: 0.6932, Acc: 0.4980, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 29/100, Loss: 0.6932, Acc: 0.4934, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 30/100, Loss: 0.6932, Acc: 0.4914, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 31/100, Loss: 0.6932, Acc: 0.4928, Val Loss: 0.6932, Val Acc: 0.4993
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.5020, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 33/100, Loss: 0.6932, Acc: 0.4956, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 34/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 35/100, Loss: 0.6932, Acc: 0.4999, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 36/100, Loss: 0.6932, Acc: 0.4919, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 37/100, Loss: 0.6932, Acc: 0.4903, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 38/100, Loss: 0.6932, Acc: 0.4937, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 39/100, Loss: 0.6932, Acc: 0.4969, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 40/100, Loss: 0.6932, Acc: 0.4927, Val Loss: 0.6932, Val Acc: 0.4978
Epoch 41/100, Loss: 0.6932, Acc: 0.5023, Val Loss: 0.6932, Val Acc: 0.4993
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.4999, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 43/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 44/100, Loss: 0.6932, Acc: 0.4968, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 45/100, Loss: 0.6932, Acc: 0.4995, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 46/100, Loss: 0.6932, Acc: 0.4905, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 47/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 48/100, Loss: 0.6931, Acc: 0.4926, Val Loss: 0.6937, Val Acc: 0.5007
Epoch 49/100, Loss: 0.6930, Acc: 0.5002, Val Loss: 0.6936, Val Acc: 0.4429
Epoch 50/100, Loss: 0.6930, Acc: 0.4975, Val Loss: 0.6941, Val Acc: 0.4437
Epoch 51/100, Loss: 0.6930, Acc: 0.4988, Val Loss: 0.6943, Val Acc: 0.4448
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6929, Acc: 0.4983, Val Loss: 0.6942, Val Acc: 0.4433
Epoch 53/100, Loss: 0.6929, Acc: 0.4962, Val Loss: 0.6940, Val Acc: 0.4518
Epoch 54/100, Loss: 0.6929, Acc: 0.5036, Val Loss: 0.6942, Val Acc: 0.4529
Epoch 55/100, Loss: 0.6929, Acc: 0.5011, Val Loss: 0.6943, Val Acc: 0.4466
Epoch 56/100, Loss: 0.6929, Acc: 0.5004, Val Loss: 0.6941, Val Acc: 0.4514
Epoch 57/100, Loss: 0.6929, Acc: 0.5022, Val Loss: 0.6942, Val Acc: 0.4518
Epoch 58/100, Loss: 0.6929, Acc: 0.5051, Val Loss: 0.6943, Val Acc: 0.4514
Epoch 59/100, Loss: 0.6929, Acc: 0.4989, Val Loss: 0.6943, Val Acc: 0.4510
Epoch 60/100, Loss: 0.6929, Acc: 0.5032, Val Loss: 0.6943, Val Acc: 0.4521
Epoch 61/100, Loss: 0.6929, Acc: 0.4998, Val Loss: 0.6944, Val Acc: 0.4485
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6929, Acc: 0.5017, Val Loss: 0.6944, Val Acc: 0.4525
Epoch 63/100, Loss: 0.6929, Acc: 0.5020, Val Loss: 0.6944, Val Acc: 0.4521
Epoch 64/100, Loss: 0.6929, Acc: 0.5013, Val Loss: 0.6943, Val Acc: 0.4514
Epoch 65/100, Loss: 0.6929, Acc: 0.5015, Val Loss: 0.6943, Val Acc: 0.4521
Epoch 66/100, Loss: 0.6929, Acc: 0.5041, Val Loss: 0.6944, Val Acc: 0.4514
Epoch 67/100, Loss: 0.6929, Acc: 0.5033, Val Loss: 0.6944, Val Acc: 0.4510
Epoch 68/100, Loss: 0.6929, Acc: 0.5035, Val Loss: 0.6944, Val Acc: 0.4532
Epoch 69/100, Loss: 0.6929, Acc: 0.5029, Val Loss: 0.6943, Val Acc: 0.4529
Epoch 70/100, Loss: 0.6928, Acc: 0.5016, Val Loss: 0.6943, Val Acc: 0.4566
Epoch 71/100, Loss: 0.6928, Acc: 0.5020, Val Loss: 0.6942, Val Acc: 0.4569
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6928, Acc: 0.5049, Val Loss: 0.6942, Val Acc: 0.4558
Epoch 73/100, Loss: 0.6928, Acc: 0.5047, Val Loss: 0.6944, Val Acc: 0.4521
Epoch 74/100, Loss: 0.6926, Acc: 0.5094, Val Loss: 0.6957, Val Acc: 0.4426
Epoch 75/100, Loss: 0.6919, Acc: 0.5278, Val Loss: 0.6974, Val Acc: 0.4584
Epoch 76/100, Loss: 0.6912, Acc: 0.5392, Val Loss: 0.6971, Val Acc: 0.4639
Epoch 77/100, Loss: 0.6910, Acc: 0.5415, Val Loss: 0.6968, Val Acc: 0.4628
Epoch 78/100, Loss: 0.6909, Acc: 0.5437, Val Loss: 0.6969, Val Acc: 0.4547
Epoch 79/100, Loss: 0.6908, Acc: 0.5453, Val Loss: 0.6968, Val Acc: 0.4606
Epoch 80/100, Loss: 0.6907, Acc: 0.5485, Val Loss: 0.6967, Val Acc: 0.4547
Epoch 81/100, Loss: 0.6906, Acc: 0.5451, Val Loss: 0.6968, Val Acc: 0.4595
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6905, Acc: 0.5453, Val Loss: 0.6968, Val Acc: 0.4562
Epoch 83/100, Loss: 0.6905, Acc: 0.5480, Val Loss: 0.6969, Val Acc: 0.4554
Epoch 84/100, Loss: 0.6904, Acc: 0.5462, Val Loss: 0.6969, Val Acc: 0.4591
Epoch 85/100, Loss: 0.6903, Acc: 0.5486, Val Loss: 0.6969, Val Acc: 0.4554
Epoch 86/100, Loss: 0.6903, Acc: 0.5451, Val Loss: 0.6971, Val Acc: 0.4595
Epoch 87/100, Loss: 0.6902, Acc: 0.5484, Val Loss: 0.6970, Val Acc: 0.4588
Epoch 88/100, Loss: 0.6902, Acc: 0.5469, Val Loss: 0.6972, Val Acc: 0.4551
Epoch 89/100, Loss: 0.6901, Acc: 0.5478, Val Loss: 0.6972, Val Acc: 0.4529
Epoch 90/100, Loss: 0.6901, Acc: 0.5500, Val Loss: 0.6973, Val Acc: 0.4584
Epoch 91/100, Loss: 0.6900, Acc: 0.5492, Val Loss: 0.6973, Val Acc: 0.4566
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6900, Acc: 0.5494, Val Loss: 0.6974, Val Acc: 0.4580
Epoch 93/100, Loss: 0.6900, Acc: 0.5481, Val Loss: 0.6974, Val Acc: 0.4540
Epoch 94/100, Loss: 0.6899, Acc: 0.5486, Val Loss: 0.6975, Val Acc: 0.4521
Epoch 95/100, Loss: 0.6899, Acc: 0.5481, Val Loss: 0.6976, Val Acc: 0.4518
Epoch 96/100, Loss: 0.6898, Acc: 0.5505, Val Loss: 0.6976, Val Acc: 0.4540
Epoch 97/100, Loss: 0.6898, Acc: 0.5482, Val Loss: 0.6976, Val Acc: 0.4514
Epoch 98/100, Loss: 0.6897, Acc: 0.5504, Val Loss: 0.6978, Val Acc: 0.4518
Epoch 99/100, Loss: 0.6897, Acc: 0.5509, Val Loss: 0.6978, Val Acc: 0.4496
Epoch 100/100, Loss: 0.6897, Acc: 0.5495, Val Loss: 0.6977, Val Acc: 0.4554

##############################
Resultados para principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5 
 {'training': [0.6896609975906715, 0.549466715704303, 0.5617227084292953, 0.44867549668874174, 0.4988750255676007], 'validate': [0.6977124131003092, 0.45544918998527245, 0.42379182156133827, 0.252212389380531, 0.31622746185852985], 'test': [0.6929774262286998, 0.5005889281507656, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  040  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  040  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6863, Acc: 0.5544, Val Loss: 0.6930, Val Acc: 0.5066
Mejor modelo guardado con Val Loss: 0.6930
Epoch 2/100, Loss: 0.6796, Acc: 0.5790, Val Loss: 0.6977, Val Acc: 0.4993
Epoch 3/100, Loss: 0.6875, Acc: 0.5576, Val Loss: 0.6936, Val Acc: 0.4989
Epoch 4/100, Loss: 0.6872, Acc: 0.5360, Val Loss: 0.6831, Val Acc: 0.5762
Mejor modelo guardado con Val Loss: 0.6831
Epoch 5/100, Loss: 0.6694, Acc: 0.5988, Val Loss: 0.6740, Val Acc: 0.5880
Mejor modelo guardado con Val Loss: 0.6740
Epoch 6/100, Loss: 0.6654, Acc: 0.6006, Val Loss: 0.6651, Val Acc: 0.6060
Mejor modelo guardado con Val Loss: 0.6651
Epoch 7/100, Loss: 0.6619, Acc: 0.6033, Val Loss: 0.6636, Val Acc: 0.6001
Mejor modelo guardado con Val Loss: 0.6636
Epoch 8/100, Loss: 0.6656, Acc: 0.6014, Val Loss: 0.6731, Val Acc: 0.5943
Epoch 9/100, Loss: 0.6584, Acc: 0.6089, Val Loss: 0.6643, Val Acc: 0.5917
Epoch 10/100, Loss: 0.6570, Acc: 0.6152, Val Loss: 0.6619, Val Acc: 0.6001
Mejor modelo guardado con Val Loss: 0.6619
Epoch 11/100, Loss: 0.6551, Acc: 0.6145, Val Loss: 0.6614, Val Acc: 0.6005
Mejor modelo guardado con Val Loss: 0.6614
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6554, Acc: 0.6142, Val Loss: 0.6653, Val Acc: 0.5906
Epoch 13/100, Loss: 0.6543, Acc: 0.6130, Val Loss: 0.6565, Val Acc: 0.6152
Mejor modelo guardado con Val Loss: 0.6565
Epoch 14/100, Loss: 0.6547, Acc: 0.6160, Val Loss: 0.6719, Val Acc: 0.5880
Epoch 15/100, Loss: 0.6545, Acc: 0.6119, Val Loss: 0.6649, Val Acc: 0.5880
Epoch 16/100, Loss: 0.6530, Acc: 0.6138, Val Loss: 0.6670, Val Acc: 0.5895
Epoch 17/100, Loss: 0.6513, Acc: 0.6193, Val Loss: 0.6585, Val Acc: 0.6064
Epoch 18/100, Loss: 0.6527, Acc: 0.6152, Val Loss: 0.6749, Val Acc: 0.5747
Epoch 19/100, Loss: 0.6536, Acc: 0.6111, Val Loss: 0.6561, Val Acc: 0.6130
Mejor modelo guardado con Val Loss: 0.6561
Epoch 20/100, Loss: 0.6524, Acc: 0.6135, Val Loss: 0.6618, Val Acc: 0.5939
Epoch 21/100, Loss: 0.6520, Acc: 0.6157, Val Loss: 0.6701, Val Acc: 0.5744
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6492, Acc: 0.6220, Val Loss: 0.6680, Val Acc: 0.5858
Epoch 23/100, Loss: 0.6493, Acc: 0.6182, Val Loss: 0.6587, Val Acc: 0.6075
Epoch 24/100, Loss: 0.6477, Acc: 0.6231, Val Loss: 0.6580, Val Acc: 0.6068
Epoch 25/100, Loss: 0.6483, Acc: 0.6204, Val Loss: 0.6656, Val Acc: 0.5880
Epoch 26/100, Loss: 0.6486, Acc: 0.6239, Val Loss: 0.6614, Val Acc: 0.5928
Epoch 27/100, Loss: 0.6484, Acc: 0.6230, Val Loss: 0.6619, Val Acc: 0.5917
Epoch 28/100, Loss: 0.6474, Acc: 0.6226, Val Loss: 0.6639, Val Acc: 0.5932
Epoch 29/100, Loss: 0.6484, Acc: 0.6218, Val Loss: 0.6651, Val Acc: 0.5884
Epoch 30/100, Loss: 0.6476, Acc: 0.6231, Val Loss: 0.6667, Val Acc: 0.5847
Epoch 31/100, Loss: 0.6480, Acc: 0.6237, Val Loss: 0.6613, Val Acc: 0.5946
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6467, Acc: 0.6244, Val Loss: 0.6592, Val Acc: 0.5987
Epoch 33/100, Loss: 0.6461, Acc: 0.6252, Val Loss: 0.6560, Val Acc: 0.6079
Mejor modelo guardado con Val Loss: 0.6560
Epoch 34/100, Loss: 0.6463, Acc: 0.6257, Val Loss: 0.6619, Val Acc: 0.5939
Epoch 35/100, Loss: 0.6474, Acc: 0.6206, Val Loss: 0.6575, Val Acc: 0.6046
Epoch 36/100, Loss: 0.6465, Acc: 0.6253, Val Loss: 0.6600, Val Acc: 0.5968
Epoch 37/100, Loss: 0.6465, Acc: 0.6244, Val Loss: 0.6624, Val Acc: 0.5913
Epoch 38/100, Loss: 0.6466, Acc: 0.6257, Val Loss: 0.6642, Val Acc: 0.5906
Epoch 39/100, Loss: 0.6464, Acc: 0.6276, Val Loss: 0.6546, Val Acc: 0.6145
Mejor modelo guardado con Val Loss: 0.6546
Epoch 40/100, Loss: 0.6464, Acc: 0.6250, Val Loss: 0.6576, Val Acc: 0.6042
Epoch 41/100, Loss: 0.6460, Acc: 0.6261, Val Loss: 0.6663, Val Acc: 0.5851
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6459, Acc: 0.6253, Val Loss: 0.6577, Val Acc: 0.6027
Epoch 43/100, Loss: 0.6453, Acc: 0.6272, Val Loss: 0.6587, Val Acc: 0.5994
Epoch 44/100, Loss: 0.6455, Acc: 0.6242, Val Loss: 0.6603, Val Acc: 0.5957
Epoch 45/100, Loss: 0.6454, Acc: 0.6264, Val Loss: 0.6596, Val Acc: 0.5972
Epoch 46/100, Loss: 0.6455, Acc: 0.6232, Val Loss: 0.6577, Val Acc: 0.6027
Epoch 47/100, Loss: 0.6457, Acc: 0.6234, Val Loss: 0.6600, Val Acc: 0.5946
Epoch 48/100, Loss: 0.6453, Acc: 0.6255, Val Loss: 0.6584, Val Acc: 0.6005
Epoch 49/100, Loss: 0.6454, Acc: 0.6265, Val Loss: 0.6632, Val Acc: 0.5913
Epoch 50/100, Loss: 0.6454, Acc: 0.6271, Val Loss: 0.6583, Val Acc: 0.6024
Epoch 51/100, Loss: 0.6453, Acc: 0.6259, Val Loss: 0.6595, Val Acc: 0.5968
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6449, Acc: 0.6261, Val Loss: 0.6605, Val Acc: 0.5957
Epoch 53/100, Loss: 0.6452, Acc: 0.6260, Val Loss: 0.6579, Val Acc: 0.6031
Epoch 54/100, Loss: 0.6451, Acc: 0.6271, Val Loss: 0.6598, Val Acc: 0.5954
Epoch 55/100, Loss: 0.6450, Acc: 0.6242, Val Loss: 0.6575, Val Acc: 0.6042
Epoch 56/100, Loss: 0.6451, Acc: 0.6273, Val Loss: 0.6584, Val Acc: 0.6013
Epoch 57/100, Loss: 0.6448, Acc: 0.6261, Val Loss: 0.6632, Val Acc: 0.5920
Epoch 58/100, Loss: 0.6451, Acc: 0.6259, Val Loss: 0.6584, Val Acc: 0.6031
Epoch 59/100, Loss: 0.6448, Acc: 0.6269, Val Loss: 0.6611, Val Acc: 0.5935
Epoch 60/100, Loss: 0.6451, Acc: 0.6272, Val Loss: 0.6585, Val Acc: 0.6013
Epoch 61/100, Loss: 0.6449, Acc: 0.6273, Val Loss: 0.6596, Val Acc: 0.5957
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6448, Acc: 0.6265, Val Loss: 0.6586, Val Acc: 0.6016
Epoch 63/100, Loss: 0.6447, Acc: 0.6258, Val Loss: 0.6587, Val Acc: 0.6005
Epoch 64/100, Loss: 0.6447, Acc: 0.6273, Val Loss: 0.6604, Val Acc: 0.5976
Epoch 65/100, Loss: 0.6447, Acc: 0.6273, Val Loss: 0.6601, Val Acc: 0.5961
Epoch 66/100, Loss: 0.6447, Acc: 0.6264, Val Loss: 0.6599, Val Acc: 0.5954
Epoch 67/100, Loss: 0.6446, Acc: 0.6268, Val Loss: 0.6599, Val Acc: 0.5954
Epoch 68/100, Loss: 0.6446, Acc: 0.6267, Val Loss: 0.6592, Val Acc: 0.5979
Epoch 69/100, Loss: 0.6445, Acc: 0.6263, Val Loss: 0.6596, Val Acc: 0.5957
Epoch 70/100, Loss: 0.6446, Acc: 0.6268, Val Loss: 0.6586, Val Acc: 0.6016
Epoch 71/100, Loss: 0.6446, Acc: 0.6270, Val Loss: 0.6585, Val Acc: 0.6031
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6444, Acc: 0.6260, Val Loss: 0.6597, Val Acc: 0.5957
Epoch 73/100, Loss: 0.6444, Acc: 0.6267, Val Loss: 0.6592, Val Acc: 0.5976
Epoch 74/100, Loss: 0.6444, Acc: 0.6281, Val Loss: 0.6593, Val Acc: 0.5965
Epoch 75/100, Loss: 0.6444, Acc: 0.6259, Val Loss: 0.6595, Val Acc: 0.5961
Epoch 76/100, Loss: 0.6443, Acc: 0.6272, Val Loss: 0.6588, Val Acc: 0.5998
Epoch 77/100, Loss: 0.6443, Acc: 0.6269, Val Loss: 0.6586, Val Acc: 0.6013
Epoch 78/100, Loss: 0.6442, Acc: 0.6276, Val Loss: 0.6586, Val Acc: 0.6009
Epoch 79/100, Loss: 0.6441, Acc: 0.6263, Val Loss: 0.6598, Val Acc: 0.5961
Epoch 80/100, Loss: 0.6442, Acc: 0.6276, Val Loss: 0.6595, Val Acc: 0.5979
Epoch 81/100, Loss: 0.6441, Acc: 0.6268, Val Loss: 0.6582, Val Acc: 0.6035
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6441, Acc: 0.6275, Val Loss: 0.6584, Val Acc: 0.6035
Epoch 83/100, Loss: 0.6441, Acc: 0.6278, Val Loss: 0.6584, Val Acc: 0.6020
Epoch 84/100, Loss: 0.6441, Acc: 0.6266, Val Loss: 0.6582, Val Acc: 0.6031
Epoch 85/100, Loss: 0.6440, Acc: 0.6279, Val Loss: 0.6595, Val Acc: 0.5976
Epoch 86/100, Loss: 0.6440, Acc: 0.6273, Val Loss: 0.6586, Val Acc: 0.5994
Epoch 87/100, Loss: 0.6440, Acc: 0.6265, Val Loss: 0.6583, Val Acc: 0.6027
Epoch 88/100, Loss: 0.6440, Acc: 0.6274, Val Loss: 0.6586, Val Acc: 0.5998
Epoch 89/100, Loss: 0.6440, Acc: 0.6275, Val Loss: 0.6586, Val Acc: 0.5998
Epoch 90/100, Loss: 0.6438, Acc: 0.6283, Val Loss: 0.6590, Val Acc: 0.6005
Epoch 91/100, Loss: 0.6437, Acc: 0.6275, Val Loss: 0.6585, Val Acc: 0.6031
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6437, Acc: 0.6273, Val Loss: 0.6586, Val Acc: 0.6016
Epoch 93/100, Loss: 0.6436, Acc: 0.6283, Val Loss: 0.6596, Val Acc: 0.5987
Epoch 94/100, Loss: 0.6436, Acc: 0.6284, Val Loss: 0.6588, Val Acc: 0.6020
Epoch 95/100, Loss: 0.6435, Acc: 0.6264, Val Loss: 0.6601, Val Acc: 0.5968
Epoch 96/100, Loss: 0.6435, Acc: 0.6282, Val Loss: 0.6601, Val Acc: 0.5972
Epoch 97/100, Loss: 0.6434, Acc: 0.6292, Val Loss: 0.6589, Val Acc: 0.6009
Epoch 98/100, Loss: 0.6434, Acc: 0.6279, Val Loss: 0.6594, Val Acc: 0.5990
Epoch 99/100, Loss: 0.6433, Acc: 0.6269, Val Loss: 0.6595, Val Acc: 0.5990
Epoch 100/100, Loss: 0.6433, Acc: 0.6284, Val Loss: 0.6594, Val Acc: 0.5994

##############################
Resultados para principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  5 
 {'training': [0.6432681357479131, 0.6284479588083854, 0.5964596874567833, 0.7934142752023546, 0.6809820794189626], 'validate': [0.6593680534251901, 0.5994108983799705, 0.5692148760330579, 0.8126843657817109, 0.669501822600243], 'test': [0.650311286802645, 0.6216136631330977, 0.5978105663969538, 0.7405660377358491, 0.6615749275744008]}

##############################
Resultados para window:  5 
 {'095:065:013:063:070:040': {'training': [0.6780150785039304, 0.585233541743288, 0.5818149655050415, 0.6050404709345106, 0.593200468933177], 'validate': [0.676568350126577, 0.5662739322533137, 0.5679389312977099, 0.5486725663716814, 0.5581395348837209], 'test': [0.6751403554722115, 0.6051236749116607, 0.6053412462908012, 0.6014150943396226, 0.6033717834960071]}, '065:095:013:063:070:040': {'training': [0.6841989412558521, 0.5809121000367782, 0.5698155216284987, 0.6591243561442237, 0.6112248379392698], 'validate': [0.6748212381850841, 0.6395434462444771, 0.6330275229357798, 0.661504424778761, 0.6469527587450414], 'test': [0.6786067529960915, 0.6148409893992933, 0.6133177570093458, 0.6191037735849056, 0.6161971830985915]}, '013:095:065:063:070:040': {'training': [0.6236035893532492, 0.6628356013240162, 0.6839259721355792, 0.6050404709345106, 0.6420693020985847], 'validate': [0.5610626246346984, 0.7415316642120766, 0.6894553881807648, 0.8775811209439528, 0.772225827384815], 'test': [0.8019351799179006, 0.4637809187279152, 0.4658283214871515, 0.5023584905660378, 0.48340425531914893]}, '063:095:065:013:070:040': {'training': [0.6918582623607317, 0.5325487311511585, 0.524155915454296, 0.7025386313465783, 0.6003772991667977], 'validate': [0.692907664664956, 0.5184094256259205, 0.5140350877192983, 0.6482300884955752, 0.5733855185909981], 'test': [0.693275017870797, 0.49322732626619553, 0.49506903353057197, 0.7399764150943396, 0.5932403687071615]}, '070:095:065:013:063:040': {'training': [0.6896609975906715, 0.549466715704303, 0.5617227084292953, 0.44867549668874174, 0.4988750255676007], 'validate': [0.6977124131003092, 0.45544918998527245, 0.42379182156133827, 0.252212389380531, 0.31622746185852985], 'test': [0.6929774262286998, 0.5005889281507656, 0.0, 0.0, 0.0]}, '040:095:065:013:063:070': {'training': [0.6432681357479131, 0.6284479588083854, 0.5964596874567833, 0.7934142752023546, 0.6809820794189626], 'validate': [0.6593680534251901, 0.5994108983799705, 0.5692148760330579, 0.8126843657817109, 0.669501822600243], 'test': [0.650311286802645, 0.6216136631330977, 0.5978105663969538, 0.7405660377358491, 0.6615749275744008]}}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  102  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  102  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6301, Acc: 0.6705, Val Loss: 0.4605, Val Acc: 0.8870
Mejor modelo guardado con Val Loss: 0.4605
Epoch 2/100, Loss: 0.5856, Acc: 0.7016, Val Loss: 0.3493, Val Acc: 0.9267
Mejor modelo guardado con Val Loss: 0.3493
Epoch 3/100, Loss: 0.5648, Acc: 0.7122, Val Loss: 0.3264, Val Acc: 0.9172
Mejor modelo guardado con Val Loss: 0.3264
Epoch 4/100, Loss: 0.5519, Acc: 0.7251, Val Loss: 0.3408, Val Acc: 0.8866
Epoch 5/100, Loss: 0.5460, Acc: 0.7293, Val Loss: 0.3132, Val Acc: 0.9378
Mejor modelo guardado con Val Loss: 0.3132
Epoch 6/100, Loss: 0.5449, Acc: 0.7306, Val Loss: 0.3554, Val Acc: 0.9260
Epoch 7/100, Loss: 0.5552, Acc: 0.7266, Val Loss: 0.3404, Val Acc: 0.8980
Epoch 8/100, Loss: 0.5453, Acc: 0.7274, Val Loss: 0.3120, Val Acc: 0.9297
Mejor modelo guardado con Val Loss: 0.3120
Epoch 9/100, Loss: 0.5408, Acc: 0.7312, Val Loss: 0.3025, Val Acc: 0.9282
Mejor modelo guardado con Val Loss: 0.3025
Epoch 10/100, Loss: 0.5394, Acc: 0.7322, Val Loss: 0.2799, Val Acc: 0.9083
Mejor modelo guardado con Val Loss: 0.2799
Epoch 11/100, Loss: 0.5320, Acc: 0.7352, Val Loss: 0.2459, Val Acc: 0.9374
Mejor modelo guardado con Val Loss: 0.2459
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5225, Acc: 0.7392, Val Loss: 0.2451, Val Acc: 0.9278
Mejor modelo guardado con Val Loss: 0.2451
Epoch 13/100, Loss: 0.5239, Acc: 0.7419, Val Loss: 0.2925, Val Acc: 0.9381
Epoch 14/100, Loss: 0.5165, Acc: 0.7437, Val Loss: 0.2624, Val Acc: 0.9304
Epoch 15/100, Loss: 0.5193, Acc: 0.7460, Val Loss: 0.2930, Val Acc: 0.8932
Epoch 16/100, Loss: 0.5188, Acc: 0.7420, Val Loss: 0.2570, Val Acc: 0.9238
Epoch 17/100, Loss: 0.5146, Acc: 0.7430, Val Loss: 0.2560, Val Acc: 0.9120
Epoch 18/100, Loss: 0.5178, Acc: 0.7427, Val Loss: 0.2537, Val Acc: 0.9359
Epoch 19/100, Loss: 0.5164, Acc: 0.7393, Val Loss: 0.2657, Val Acc: 0.9164
Epoch 20/100, Loss: 0.5172, Acc: 0.7417, Val Loss: 0.2463, Val Acc: 0.9227
Epoch 21/100, Loss: 0.5127, Acc: 0.7463, Val Loss: 0.2781, Val Acc: 0.9061
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5099, Acc: 0.7474, Val Loss: 0.2562, Val Acc: 0.9046
Epoch 23/100, Loss: 0.5090, Acc: 0.7494, Val Loss: 0.2535, Val Acc: 0.9164
Epoch 24/100, Loss: 0.5079, Acc: 0.7491, Val Loss: 0.2576, Val Acc: 0.9087
Epoch 25/100, Loss: 0.5064, Acc: 0.7495, Val Loss: 0.2508, Val Acc: 0.9227
Epoch 26/100, Loss: 0.5039, Acc: 0.7503, Val Loss: 0.2465, Val Acc: 0.9157
Epoch 27/100, Loss: 0.5038, Acc: 0.7520, Val Loss: 0.2414, Val Acc: 0.9179
Mejor modelo guardado con Val Loss: 0.2414
Epoch 28/100, Loss: 0.5014, Acc: 0.7532, Val Loss: 0.2306, Val Acc: 0.9245
Mejor modelo guardado con Val Loss: 0.2306
Epoch 29/100, Loss: 0.5031, Acc: 0.7496, Val Loss: 0.2374, Val Acc: 0.9370
Epoch 30/100, Loss: 0.5024, Acc: 0.7534, Val Loss: 0.2448, Val Acc: 0.9242
Epoch 31/100, Loss: 0.5010, Acc: 0.7519, Val Loss: 0.2380, Val Acc: 0.9201
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4976, Acc: 0.7540, Val Loss: 0.2361, Val Acc: 0.9260
Epoch 33/100, Loss: 0.4973, Acc: 0.7566, Val Loss: 0.2517, Val Acc: 0.9135
Epoch 34/100, Loss: 0.4968, Acc: 0.7530, Val Loss: 0.2446, Val Acc: 0.9216
Epoch 35/100, Loss: 0.4961, Acc: 0.7551, Val Loss: 0.2397, Val Acc: 0.9172
Epoch 36/100, Loss: 0.4957, Acc: 0.7536, Val Loss: 0.2494, Val Acc: 0.9153
Epoch 37/100, Loss: 0.4949, Acc: 0.7546, Val Loss: 0.2509, Val Acc: 0.9116
Epoch 38/100, Loss: 0.4947, Acc: 0.7564, Val Loss: 0.2495, Val Acc: 0.9113
Epoch 39/100, Loss: 0.4937, Acc: 0.7563, Val Loss: 0.2446, Val Acc: 0.9138
Epoch 40/100, Loss: 0.4932, Acc: 0.7540, Val Loss: 0.2320, Val Acc: 0.9197
Epoch 41/100, Loss: 0.4937, Acc: 0.7559, Val Loss: 0.2460, Val Acc: 0.9172
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4916, Acc: 0.7574, Val Loss: 0.2412, Val Acc: 0.9197
Epoch 43/100, Loss: 0.4916, Acc: 0.7563, Val Loss: 0.2441, Val Acc: 0.9194
Epoch 44/100, Loss: 0.4909, Acc: 0.7582, Val Loss: 0.2373, Val Acc: 0.9208
Epoch 45/100, Loss: 0.4905, Acc: 0.7570, Val Loss: 0.2435, Val Acc: 0.9172
Epoch 46/100, Loss: 0.4901, Acc: 0.7591, Val Loss: 0.2449, Val Acc: 0.9175
Epoch 47/100, Loss: 0.4897, Acc: 0.7570, Val Loss: 0.2370, Val Acc: 0.9186
Epoch 48/100, Loss: 0.4894, Acc: 0.7611, Val Loss: 0.2418, Val Acc: 0.9212
Epoch 49/100, Loss: 0.4892, Acc: 0.7589, Val Loss: 0.2434, Val Acc: 0.9153
Epoch 50/100, Loss: 0.4888, Acc: 0.7582, Val Loss: 0.2380, Val Acc: 0.9179
Epoch 51/100, Loss: 0.4893, Acc: 0.7601, Val Loss: 0.2457, Val Acc: 0.9157
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4879, Acc: 0.7607, Val Loss: 0.2409, Val Acc: 0.9183
Epoch 53/100, Loss: 0.4879, Acc: 0.7586, Val Loss: 0.2400, Val Acc: 0.9186
Epoch 54/100, Loss: 0.4877, Acc: 0.7608, Val Loss: 0.2369, Val Acc: 0.9186
Epoch 55/100, Loss: 0.4875, Acc: 0.7595, Val Loss: 0.2372, Val Acc: 0.9197
Epoch 56/100, Loss: 0.4873, Acc: 0.7590, Val Loss: 0.2363, Val Acc: 0.9194
Epoch 57/100, Loss: 0.4869, Acc: 0.7604, Val Loss: 0.2383, Val Acc: 0.9172
Epoch 58/100, Loss: 0.4871, Acc: 0.7600, Val Loss: 0.2399, Val Acc: 0.9168
Epoch 59/100, Loss: 0.4871, Acc: 0.7603, Val Loss: 0.2373, Val Acc: 0.9186
Epoch 60/100, Loss: 0.4866, Acc: 0.7606, Val Loss: 0.2408, Val Acc: 0.9172
Epoch 61/100, Loss: 0.4868, Acc: 0.7616, Val Loss: 0.2358, Val Acc: 0.9183
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4862, Acc: 0.7611, Val Loss: 0.2366, Val Acc: 0.9186
Epoch 63/100, Loss: 0.4860, Acc: 0.7615, Val Loss: 0.2408, Val Acc: 0.9153
Epoch 64/100, Loss: 0.4860, Acc: 0.7607, Val Loss: 0.2364, Val Acc: 0.9186
Epoch 65/100, Loss: 0.4859, Acc: 0.7608, Val Loss: 0.2404, Val Acc: 0.9183
Epoch 66/100, Loss: 0.4859, Acc: 0.7609, Val Loss: 0.2396, Val Acc: 0.9179
Epoch 67/100, Loss: 0.4856, Acc: 0.7612, Val Loss: 0.2397, Val Acc: 0.9157
Epoch 68/100, Loss: 0.4855, Acc: 0.7606, Val Loss: 0.2352, Val Acc: 0.9194
Epoch 69/100, Loss: 0.4852, Acc: 0.7615, Val Loss: 0.2319, Val Acc: 0.9212
Epoch 70/100, Loss: 0.4834, Acc: 0.7620, Val Loss: 0.2363, Val Acc: 0.9208
Epoch 71/100, Loss: 0.4826, Acc: 0.7640, Val Loss: 0.2377, Val Acc: 0.9172
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4823, Acc: 0.7635, Val Loss: 0.2354, Val Acc: 0.9190
Epoch 73/100, Loss: 0.4823, Acc: 0.7623, Val Loss: 0.2346, Val Acc: 0.9216
Epoch 74/100, Loss: 0.4820, Acc: 0.7631, Val Loss: 0.2353, Val Acc: 0.9223
Epoch 75/100, Loss: 0.4820, Acc: 0.7636, Val Loss: 0.2346, Val Acc: 0.9208
Epoch 76/100, Loss: 0.4821, Acc: 0.7620, Val Loss: 0.2356, Val Acc: 0.9201
Epoch 77/100, Loss: 0.4818, Acc: 0.7624, Val Loss: 0.2378, Val Acc: 0.9168
Epoch 78/100, Loss: 0.4818, Acc: 0.7632, Val Loss: 0.2324, Val Acc: 0.9253
Epoch 79/100, Loss: 0.4818, Acc: 0.7620, Val Loss: 0.2373, Val Acc: 0.9161
Epoch 80/100, Loss: 0.4816, Acc: 0.7626, Val Loss: 0.2328, Val Acc: 0.9227
Epoch 81/100, Loss: 0.4817, Acc: 0.7628, Val Loss: 0.2328, Val Acc: 0.9216
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4818, Acc: 0.7620, Val Loss: 0.2359, Val Acc: 0.9212
Epoch 83/100, Loss: 0.4816, Acc: 0.7633, Val Loss: 0.2353, Val Acc: 0.9208
Epoch 84/100, Loss: 0.4815, Acc: 0.7628, Val Loss: 0.2360, Val Acc: 0.9197
Epoch 85/100, Loss: 0.4813, Acc: 0.7627, Val Loss: 0.2363, Val Acc: 0.9168
Epoch 86/100, Loss: 0.4815, Acc: 0.7626, Val Loss: 0.2345, Val Acc: 0.9201
Epoch 87/100, Loss: 0.4813, Acc: 0.7636, Val Loss: 0.2356, Val Acc: 0.9197
Epoch 88/100, Loss: 0.4812, Acc: 0.7636, Val Loss: 0.2344, Val Acc: 0.9223
Epoch 89/100, Loss: 0.4812, Acc: 0.7634, Val Loss: 0.2337, Val Acc: 0.9223
Epoch 90/100, Loss: 0.4807, Acc: 0.7628, Val Loss: 0.2342, Val Acc: 0.9205
Epoch 91/100, Loss: 0.4805, Acc: 0.7633, Val Loss: 0.2331, Val Acc: 0.9190
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4806, Acc: 0.7635, Val Loss: 0.2325, Val Acc: 0.9216
Epoch 93/100, Loss: 0.4805, Acc: 0.7651, Val Loss: 0.2322, Val Acc: 0.9208
Epoch 94/100, Loss: 0.4803, Acc: 0.7634, Val Loss: 0.2360, Val Acc: 0.9186
Epoch 95/100, Loss: 0.4804, Acc: 0.7646, Val Loss: 0.2341, Val Acc: 0.9194
Epoch 96/100, Loss: 0.4805, Acc: 0.7642, Val Loss: 0.2316, Val Acc: 0.9227
Epoch 97/100, Loss: 0.4802, Acc: 0.7631, Val Loss: 0.2330, Val Acc: 0.9201
Epoch 98/100, Loss: 0.4802, Acc: 0.7645, Val Loss: 0.2333, Val Acc: 0.9208
Epoch 99/100, Loss: 0.4802, Acc: 0.7636, Val Loss: 0.2324, Val Acc: 0.9197
Epoch 100/100, Loss: 0.4801, Acc: 0.7643, Val Loss: 0.2336, Val Acc: 0.9168

##############################
Resultados para principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5 
 {'training': [0.4800841552933247, 0.7643435086428834, 0.8004601547793349, 0.7040103016924208, 0.7491435842223745], 'validate': [0.23363444027166033, 0.9167893961708394, 0.9788135593220338, 0.8517699115044248, 0.9108832807570978], 'test': [0.7017287228394438, 0.6428150765606596, 0.676923076923077, 0.5448113207547169, 0.6037242731133616]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  020  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  020  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6206, Acc: 0.6908, Val Loss: 0.7558, Val Acc: 0.4352
Mejor modelo guardado con Val Loss: 0.7558
Epoch 2/100, Loss: 0.5566, Acc: 0.7302, Val Loss: 0.8500, Val Acc: 0.4462
Epoch 3/100, Loss: 0.5332, Acc: 0.7381, Val Loss: 0.8904, Val Acc: 0.4566
Epoch 4/100, Loss: 0.5239, Acc: 0.7404, Val Loss: 0.9275, Val Acc: 0.4087
Epoch 5/100, Loss: 0.5090, Acc: 0.7526, Val Loss: 0.9654, Val Acc: 0.4621
Epoch 6/100, Loss: 0.5138, Acc: 0.7481, Val Loss: 0.7812, Val Acc: 0.3719
Epoch 7/100, Loss: 0.5106, Acc: 0.7510, Val Loss: 0.9026, Val Acc: 0.4683
Epoch 8/100, Loss: 0.5103, Acc: 0.7514, Val Loss: 0.9152, Val Acc: 0.4775
Epoch 9/100, Loss: 0.5025, Acc: 0.7553, Val Loss: 0.9278, Val Acc: 0.4584
Epoch 10/100, Loss: 0.4966, Acc: 0.7616, Val Loss: 0.9286, Val Acc: 0.4750
Epoch 11/100, Loss: 0.4996, Acc: 0.7588, Val Loss: 0.9091, Val Acc: 0.4856
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4899, Acc: 0.7601, Val Loss: 0.9609, Val Acc: 0.4400
Epoch 13/100, Loss: 0.4872, Acc: 0.7654, Val Loss: 0.9653, Val Acc: 0.4551
Epoch 14/100, Loss: 0.4849, Acc: 0.7692, Val Loss: 0.9743, Val Acc: 0.4606
Epoch 15/100, Loss: 0.4828, Acc: 0.7691, Val Loss: 0.9598, Val Acc: 0.4418
Epoch 16/100, Loss: 0.4833, Acc: 0.7685, Val Loss: 0.9635, Val Acc: 0.4532
Epoch 17/100, Loss: 0.4826, Acc: 0.7672, Val Loss: 0.9588, Val Acc: 0.4566
Epoch 18/100, Loss: 0.4799, Acc: 0.7700, Val Loss: 0.9386, Val Acc: 0.4728
Epoch 19/100, Loss: 0.4797, Acc: 0.7698, Val Loss: 0.9626, Val Acc: 0.4227
Epoch 20/100, Loss: 0.4781, Acc: 0.7721, Val Loss: 0.9738, Val Acc: 0.4297
Epoch 21/100, Loss: 0.4800, Acc: 0.7702, Val Loss: 0.9653, Val Acc: 0.4492
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4726, Acc: 0.7754, Val Loss: 0.9664, Val Acc: 0.4521
Epoch 23/100, Loss: 0.4729, Acc: 0.7759, Val Loss: 0.9644, Val Acc: 0.4348
Epoch 24/100, Loss: 0.4729, Acc: 0.7748, Val Loss: 0.9669, Val Acc: 0.4507
Epoch 25/100, Loss: 0.4688, Acc: 0.7769, Val Loss: 0.9518, Val Acc: 0.4599
Epoch 26/100, Loss: 0.4703, Acc: 0.7768, Val Loss: 0.9657, Val Acc: 0.4529
Epoch 27/100, Loss: 0.4683, Acc: 0.7742, Val Loss: 0.9681, Val Acc: 0.4683
Epoch 28/100, Loss: 0.4707, Acc: 0.7743, Val Loss: 0.9855, Val Acc: 0.4356
Epoch 29/100, Loss: 0.4682, Acc: 0.7787, Val Loss: 0.9551, Val Acc: 0.4602
Epoch 30/100, Loss: 0.4673, Acc: 0.7780, Val Loss: 0.9674, Val Acc: 0.4540
Epoch 31/100, Loss: 0.4675, Acc: 0.7805, Val Loss: 0.9693, Val Acc: 0.4532
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4640, Acc: 0.7819, Val Loss: 0.9843, Val Acc: 0.4492
Epoch 33/100, Loss: 0.4642, Acc: 0.7807, Val Loss: 0.9753, Val Acc: 0.4459
Epoch 34/100, Loss: 0.4630, Acc: 0.7828, Val Loss: 0.9648, Val Acc: 0.4632
Epoch 35/100, Loss: 0.4636, Acc: 0.7825, Val Loss: 0.9677, Val Acc: 0.4639
Epoch 36/100, Loss: 0.4630, Acc: 0.7835, Val Loss: 0.9650, Val Acc: 0.4595
Epoch 37/100, Loss: 0.4631, Acc: 0.7799, Val Loss: 0.9659, Val Acc: 0.4606
Epoch 38/100, Loss: 0.4611, Acc: 0.7828, Val Loss: 0.9813, Val Acc: 0.4444
Epoch 39/100, Loss: 0.4623, Acc: 0.7815, Val Loss: 0.9717, Val Acc: 0.4426
Epoch 40/100, Loss: 0.4615, Acc: 0.7829, Val Loss: 0.9661, Val Acc: 0.4709
Epoch 41/100, Loss: 0.4617, Acc: 0.7830, Val Loss: 0.9713, Val Acc: 0.4466
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4598, Acc: 0.7854, Val Loss: 0.9640, Val Acc: 0.4584
Epoch 43/100, Loss: 0.4597, Acc: 0.7852, Val Loss: 0.9653, Val Acc: 0.4577
Epoch 44/100, Loss: 0.4600, Acc: 0.7827, Val Loss: 0.9742, Val Acc: 0.4507
Epoch 45/100, Loss: 0.4595, Acc: 0.7858, Val Loss: 0.9769, Val Acc: 0.4525
Epoch 46/100, Loss: 0.4589, Acc: 0.7847, Val Loss: 0.9799, Val Acc: 0.4433
Epoch 47/100, Loss: 0.4591, Acc: 0.7856, Val Loss: 0.9675, Val Acc: 0.4499
Epoch 48/100, Loss: 0.4587, Acc: 0.7854, Val Loss: 0.9697, Val Acc: 0.4613
Epoch 49/100, Loss: 0.4588, Acc: 0.7838, Val Loss: 0.9700, Val Acc: 0.4529
Epoch 50/100, Loss: 0.4582, Acc: 0.7860, Val Loss: 0.9694, Val Acc: 0.4580
Epoch 51/100, Loss: 0.4586, Acc: 0.7848, Val Loss: 0.9701, Val Acc: 0.4617
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4574, Acc: 0.7842, Val Loss: 0.9779, Val Acc: 0.4518
Epoch 53/100, Loss: 0.4575, Acc: 0.7870, Val Loss: 0.9687, Val Acc: 0.4569
Epoch 54/100, Loss: 0.4574, Acc: 0.7860, Val Loss: 0.9660, Val Acc: 0.4551
Epoch 55/100, Loss: 0.4574, Acc: 0.7871, Val Loss: 0.9651, Val Acc: 0.4632
Epoch 56/100, Loss: 0.4571, Acc: 0.7851, Val Loss: 0.9776, Val Acc: 0.4507
Epoch 57/100, Loss: 0.4573, Acc: 0.7857, Val Loss: 0.9748, Val Acc: 0.4521
Epoch 58/100, Loss: 0.4574, Acc: 0.7851, Val Loss: 0.9746, Val Acc: 0.4543
Epoch 59/100, Loss: 0.4569, Acc: 0.7854, Val Loss: 0.9730, Val Acc: 0.4532
Epoch 60/100, Loss: 0.4570, Acc: 0.7860, Val Loss: 0.9721, Val Acc: 0.4584
Epoch 61/100, Loss: 0.4565, Acc: 0.7870, Val Loss: 0.9760, Val Acc: 0.4554
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4561, Acc: 0.7867, Val Loss: 0.9716, Val Acc: 0.4588
Epoch 63/100, Loss: 0.4561, Acc: 0.7870, Val Loss: 0.9740, Val Acc: 0.4532
Epoch 64/100, Loss: 0.4559, Acc: 0.7864, Val Loss: 0.9714, Val Acc: 0.4599
Epoch 65/100, Loss: 0.4560, Acc: 0.7877, Val Loss: 0.9780, Val Acc: 0.4499
Epoch 66/100, Loss: 0.4561, Acc: 0.7876, Val Loss: 0.9764, Val Acc: 0.4536
Epoch 67/100, Loss: 0.4559, Acc: 0.7868, Val Loss: 0.9756, Val Acc: 0.4551
Epoch 68/100, Loss: 0.4558, Acc: 0.7871, Val Loss: 0.9750, Val Acc: 0.4554
Epoch 69/100, Loss: 0.4558, Acc: 0.7866, Val Loss: 0.9753, Val Acc: 0.4554
Epoch 70/100, Loss: 0.4558, Acc: 0.7867, Val Loss: 0.9735, Val Acc: 0.4558
Epoch 71/100, Loss: 0.4560, Acc: 0.7859, Val Loss: 0.9706, Val Acc: 0.4595
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4558, Acc: 0.7874, Val Loss: 0.9758, Val Acc: 0.4540
Epoch 73/100, Loss: 0.4555, Acc: 0.7874, Val Loss: 0.9778, Val Acc: 0.4521
Epoch 74/100, Loss: 0.4555, Acc: 0.7871, Val Loss: 0.9788, Val Acc: 0.4503
Epoch 75/100, Loss: 0.4554, Acc: 0.7879, Val Loss: 0.9741, Val Acc: 0.4554
Epoch 76/100, Loss: 0.4551, Acc: 0.7873, Val Loss: 0.9806, Val Acc: 0.4492
Epoch 77/100, Loss: 0.4554, Acc: 0.7873, Val Loss: 0.9753, Val Acc: 0.4547
Epoch 78/100, Loss: 0.4552, Acc: 0.7868, Val Loss: 0.9732, Val Acc: 0.4591
Epoch 79/100, Loss: 0.4552, Acc: 0.7871, Val Loss: 0.9730, Val Acc: 0.4595
Epoch 80/100, Loss: 0.4554, Acc: 0.7867, Val Loss: 0.9756, Val Acc: 0.4562
Epoch 81/100, Loss: 0.4552, Acc: 0.7873, Val Loss: 0.9755, Val Acc: 0.4536
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4551, Acc: 0.7882, Val Loss: 0.9772, Val Acc: 0.4503
Epoch 83/100, Loss: 0.4552, Acc: 0.7884, Val Loss: 0.9740, Val Acc: 0.4551
Epoch 84/100, Loss: 0.4551, Acc: 0.7871, Val Loss: 0.9762, Val Acc: 0.4540
Epoch 85/100, Loss: 0.4551, Acc: 0.7878, Val Loss: 0.9752, Val Acc: 0.4551
Epoch 86/100, Loss: 0.4549, Acc: 0.7876, Val Loss: 0.9751, Val Acc: 0.4554
Epoch 87/100, Loss: 0.4549, Acc: 0.7872, Val Loss: 0.9729, Val Acc: 0.4584
Epoch 88/100, Loss: 0.4550, Acc: 0.7875, Val Loss: 0.9753, Val Acc: 0.4558
Epoch 89/100, Loss: 0.4549, Acc: 0.7868, Val Loss: 0.9749, Val Acc: 0.4551
Epoch 90/100, Loss: 0.4549, Acc: 0.7874, Val Loss: 0.9731, Val Acc: 0.4580
Epoch 91/100, Loss: 0.4548, Acc: 0.7874, Val Loss: 0.9742, Val Acc: 0.4558
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4549, Acc: 0.7862, Val Loss: 0.9744, Val Acc: 0.4551
Epoch 93/100, Loss: 0.4546, Acc: 0.7878, Val Loss: 0.9769, Val Acc: 0.4540
Epoch 94/100, Loss: 0.4547, Acc: 0.7881, Val Loss: 0.9774, Val Acc: 0.4543
Epoch 95/100, Loss: 0.4547, Acc: 0.7883, Val Loss: 0.9728, Val Acc: 0.4595
Epoch 96/100, Loss: 0.4549, Acc: 0.7872, Val Loss: 0.9768, Val Acc: 0.4547
Epoch 97/100, Loss: 0.4547, Acc: 0.7867, Val Loss: 0.9787, Val Acc: 0.4521
Epoch 98/100, Loss: 0.4546, Acc: 0.7875, Val Loss: 0.9767, Val Acc: 0.4529
Epoch 99/100, Loss: 0.4547, Acc: 0.7879, Val Loss: 0.9763, Val Acc: 0.4540
Epoch 100/100, Loss: 0.4546, Acc: 0.7871, Val Loss: 0.9772, Val Acc: 0.4536

##############################
Resultados para principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5 
 {'training': [0.4545723652743206, 0.787146009562339, 0.7382806535348908, 0.8894407652685798, 0.8068418856904463], 'validate': [0.9772447617941125, 0.4536082474226804, 0.4751937984496124, 0.9041297935103245, 0.6229674796747967], 'test': [0.626570098929935, 0.6719670200235571, 0.6303763440860215, 0.8295990566037735, 0.7163951120162932]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  125  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  125  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6924, Acc: 0.5139, Val Loss: 0.6851, Val Acc: 0.6186
Mejor modelo guardado con Val Loss: 0.6851
Epoch 2/100, Loss: 0.6913, Acc: 0.5311, Val Loss: 0.6774, Val Acc: 0.7235
Mejor modelo guardado con Val Loss: 0.6774
Epoch 3/100, Loss: 0.6901, Acc: 0.5375, Val Loss: 0.6673, Val Acc: 0.6535
Mejor modelo guardado con Val Loss: 0.6673
Epoch 4/100, Loss: 0.6904, Acc: 0.5290, Val Loss: 0.6694, Val Acc: 0.5007
Epoch 5/100, Loss: 0.6883, Acc: 0.5446, Val Loss: 0.6617, Val Acc: 0.7430
Mejor modelo guardado con Val Loss: 0.6617
Epoch 6/100, Loss: 0.6867, Acc: 0.5475, Val Loss: 0.6541, Val Acc: 0.7474
Mejor modelo guardado con Val Loss: 0.6541
Epoch 7/100, Loss: 0.6844, Acc: 0.5611, Val Loss: 0.6590, Val Acc: 0.5379
Epoch 8/100, Loss: 0.6850, Acc: 0.5556, Val Loss: 0.6411, Val Acc: 0.7485
Mejor modelo guardado con Val Loss: 0.6411
Epoch 9/100, Loss: 0.6844, Acc: 0.5589, Val Loss: 0.6401, Val Acc: 0.7349
Mejor modelo guardado con Val Loss: 0.6401
Epoch 10/100, Loss: 0.6821, Acc: 0.5645, Val Loss: 0.6351, Val Acc: 0.7382
Mejor modelo guardado con Val Loss: 0.6351
Epoch 11/100, Loss: 0.6820, Acc: 0.5647, Val Loss: 0.6304, Val Acc: 0.7555
Mejor modelo guardado con Val Loss: 0.6304
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6808, Acc: 0.5658, Val Loss: 0.6251, Val Acc: 0.7570
Mejor modelo guardado con Val Loss: 0.6251
Epoch 13/100, Loss: 0.6807, Acc: 0.5623, Val Loss: 0.6257, Val Acc: 0.7585
Epoch 14/100, Loss: 0.6799, Acc: 0.5652, Val Loss: 0.6255, Val Acc: 0.7478
Epoch 15/100, Loss: 0.6802, Acc: 0.5690, Val Loss: 0.6214, Val Acc: 0.7548
Mejor modelo guardado con Val Loss: 0.6214
Epoch 16/100, Loss: 0.6795, Acc: 0.5694, Val Loss: 0.6222, Val Acc: 0.7448
Epoch 17/100, Loss: 0.6797, Acc: 0.5689, Val Loss: 0.6230, Val Acc: 0.7415
Epoch 18/100, Loss: 0.6784, Acc: 0.5721, Val Loss: 0.6176, Val Acc: 0.7563
Mejor modelo guardado con Val Loss: 0.6176
Epoch 19/100, Loss: 0.6797, Acc: 0.5679, Val Loss: 0.6176, Val Acc: 0.7518
Epoch 20/100, Loss: 0.6791, Acc: 0.5681, Val Loss: 0.6172, Val Acc: 0.7515
Mejor modelo guardado con Val Loss: 0.6172
Epoch 21/100, Loss: 0.6787, Acc: 0.5689, Val Loss: 0.6385, Val Acc: 0.6874
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6783, Acc: 0.5732, Val Loss: 0.6137, Val Acc: 0.7559
Mejor modelo guardado con Val Loss: 0.6137
Epoch 23/100, Loss: 0.6776, Acc: 0.5729, Val Loss: 0.6144, Val Acc: 0.7526
Epoch 24/100, Loss: 0.6780, Acc: 0.5715, Val Loss: 0.6142, Val Acc: 0.7529
Epoch 25/100, Loss: 0.6773, Acc: 0.5757, Val Loss: 0.6134, Val Acc: 0.7511
Mejor modelo guardado con Val Loss: 0.6134
Epoch 26/100, Loss: 0.6771, Acc: 0.5739, Val Loss: 0.6125, Val Acc: 0.7529
Mejor modelo guardado con Val Loss: 0.6125
Epoch 27/100, Loss: 0.6770, Acc: 0.5738, Val Loss: 0.6165, Val Acc: 0.7404
Epoch 28/100, Loss: 0.6770, Acc: 0.5723, Val Loss: 0.6120, Val Acc: 0.7548
Mejor modelo guardado con Val Loss: 0.6120
Epoch 29/100, Loss: 0.6774, Acc: 0.5710, Val Loss: 0.6159, Val Acc: 0.7412
Epoch 30/100, Loss: 0.6769, Acc: 0.5745, Val Loss: 0.6144, Val Acc: 0.7430
Epoch 31/100, Loss: 0.6766, Acc: 0.5752, Val Loss: 0.6116, Val Acc: 0.7500
Mejor modelo guardado con Val Loss: 0.6116
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6767, Acc: 0.5734, Val Loss: 0.6128, Val Acc: 0.7467
Epoch 33/100, Loss: 0.6768, Acc: 0.5744, Val Loss: 0.6106, Val Acc: 0.7544
Mejor modelo guardado con Val Loss: 0.6106
Epoch 34/100, Loss: 0.6765, Acc: 0.5747, Val Loss: 0.6120, Val Acc: 0.7463
Epoch 35/100, Loss: 0.6763, Acc: 0.5756, Val Loss: 0.6097, Val Acc: 0.7507
Mejor modelo guardado con Val Loss: 0.6097
Epoch 36/100, Loss: 0.6762, Acc: 0.5746, Val Loss: 0.6131, Val Acc: 0.7419
Epoch 37/100, Loss: 0.6761, Acc: 0.5774, Val Loss: 0.6095, Val Acc: 0.7533
Mejor modelo guardado con Val Loss: 0.6095
Epoch 38/100, Loss: 0.6760, Acc: 0.5761, Val Loss: 0.6090, Val Acc: 0.7522
Mejor modelo guardado con Val Loss: 0.6090
Epoch 39/100, Loss: 0.6762, Acc: 0.5748, Val Loss: 0.6117, Val Acc: 0.7430
Epoch 40/100, Loss: 0.6764, Acc: 0.5753, Val Loss: 0.6089, Val Acc: 0.7522
Mejor modelo guardado con Val Loss: 0.6089
Epoch 41/100, Loss: 0.6761, Acc: 0.5748, Val Loss: 0.6097, Val Acc: 0.7467
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6756, Acc: 0.5780, Val Loss: 0.6082, Val Acc: 0.7533
Mejor modelo guardado con Val Loss: 0.6082
Epoch 43/100, Loss: 0.6760, Acc: 0.5764, Val Loss: 0.6095, Val Acc: 0.7471
Epoch 44/100, Loss: 0.6761, Acc: 0.5747, Val Loss: 0.6083, Val Acc: 0.7500
Epoch 45/100, Loss: 0.6758, Acc: 0.5758, Val Loss: 0.6109, Val Acc: 0.7445
Epoch 46/100, Loss: 0.6758, Acc: 0.5778, Val Loss: 0.6084, Val Acc: 0.7518
Epoch 47/100, Loss: 0.6757, Acc: 0.5754, Val Loss: 0.6093, Val Acc: 0.7474
Epoch 48/100, Loss: 0.6755, Acc: 0.5767, Val Loss: 0.6080, Val Acc: 0.7515
Mejor modelo guardado con Val Loss: 0.6080
Epoch 49/100, Loss: 0.6758, Acc: 0.5749, Val Loss: 0.6082, Val Acc: 0.7518
Epoch 50/100, Loss: 0.6758, Acc: 0.5754, Val Loss: 0.6092, Val Acc: 0.7459
Epoch 51/100, Loss: 0.6758, Acc: 0.5776, Val Loss: 0.6092, Val Acc: 0.7467
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6755, Acc: 0.5789, Val Loss: 0.6084, Val Acc: 0.7511
Epoch 53/100, Loss: 0.6755, Acc: 0.5747, Val Loss: 0.6102, Val Acc: 0.7459
Epoch 54/100, Loss: 0.6756, Acc: 0.5768, Val Loss: 0.6090, Val Acc: 0.7452
Epoch 55/100, Loss: 0.6755, Acc: 0.5770, Val Loss: 0.6079, Val Acc: 0.7526
Mejor modelo guardado con Val Loss: 0.6079
Epoch 56/100, Loss: 0.6757, Acc: 0.5753, Val Loss: 0.6079, Val Acc: 0.7537
Mejor modelo guardado con Val Loss: 0.6079
Epoch 57/100, Loss: 0.6755, Acc: 0.5747, Val Loss: 0.6096, Val Acc: 0.7459
Epoch 58/100, Loss: 0.6755, Acc: 0.5772, Val Loss: 0.6076, Val Acc: 0.7518
Mejor modelo guardado con Val Loss: 0.6076
Epoch 59/100, Loss: 0.6755, Acc: 0.5763, Val Loss: 0.6090, Val Acc: 0.7459
Epoch 60/100, Loss: 0.6754, Acc: 0.5788, Val Loss: 0.6083, Val Acc: 0.7478
Epoch 61/100, Loss: 0.6754, Acc: 0.5782, Val Loss: 0.6084, Val Acc: 0.7471
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6754, Acc: 0.5771, Val Loss: 0.6088, Val Acc: 0.7456
Epoch 63/100, Loss: 0.6754, Acc: 0.5778, Val Loss: 0.6079, Val Acc: 0.7504
Epoch 64/100, Loss: 0.6753, Acc: 0.5759, Val Loss: 0.6082, Val Acc: 0.7478
Epoch 65/100, Loss: 0.6754, Acc: 0.5760, Val Loss: 0.6085, Val Acc: 0.7456
Epoch 66/100, Loss: 0.6753, Acc: 0.5782, Val Loss: 0.6077, Val Acc: 0.7518
Epoch 67/100, Loss: 0.6753, Acc: 0.5771, Val Loss: 0.6091, Val Acc: 0.7459
Epoch 68/100, Loss: 0.6755, Acc: 0.5764, Val Loss: 0.6079, Val Acc: 0.7504
Epoch 69/100, Loss: 0.6753, Acc: 0.5759, Val Loss: 0.6085, Val Acc: 0.7452
Epoch 70/100, Loss: 0.6750, Acc: 0.5794, Val Loss: 0.6088, Val Acc: 0.7504
Epoch 71/100, Loss: 0.6746, Acc: 0.5767, Val Loss: 0.6095, Val Acc: 0.7478
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6745, Acc: 0.5763, Val Loss: 0.6097, Val Acc: 0.7441
Epoch 73/100, Loss: 0.6745, Acc: 0.5779, Val Loss: 0.6094, Val Acc: 0.7467
Epoch 74/100, Loss: 0.6745, Acc: 0.5760, Val Loss: 0.6093, Val Acc: 0.7471
Epoch 75/100, Loss: 0.6745, Acc: 0.5771, Val Loss: 0.6092, Val Acc: 0.7478
Epoch 76/100, Loss: 0.6745, Acc: 0.5767, Val Loss: 0.6091, Val Acc: 0.7471
Epoch 77/100, Loss: 0.6745, Acc: 0.5768, Val Loss: 0.6088, Val Acc: 0.7500
Epoch 78/100, Loss: 0.6744, Acc: 0.5771, Val Loss: 0.6089, Val Acc: 0.7485
Epoch 79/100, Loss: 0.6744, Acc: 0.5767, Val Loss: 0.6090, Val Acc: 0.7478
Epoch 80/100, Loss: 0.6744, Acc: 0.5764, Val Loss: 0.6088, Val Acc: 0.7485
Epoch 81/100, Loss: 0.6744, Acc: 0.5770, Val Loss: 0.6091, Val Acc: 0.7467
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6744, Acc: 0.5760, Val Loss: 0.6093, Val Acc: 0.7448
Epoch 83/100, Loss: 0.6743, Acc: 0.5777, Val Loss: 0.6091, Val Acc: 0.7463
Epoch 84/100, Loss: 0.6743, Acc: 0.5771, Val Loss: 0.6090, Val Acc: 0.7471
Epoch 85/100, Loss: 0.6743, Acc: 0.5770, Val Loss: 0.6091, Val Acc: 0.7452
Epoch 86/100, Loss: 0.6743, Acc: 0.5767, Val Loss: 0.6092, Val Acc: 0.7452
Epoch 87/100, Loss: 0.6742, Acc: 0.5774, Val Loss: 0.6088, Val Acc: 0.7467
Epoch 88/100, Loss: 0.6742, Acc: 0.5770, Val Loss: 0.6085, Val Acc: 0.7493
Epoch 89/100, Loss: 0.6742, Acc: 0.5772, Val Loss: 0.6085, Val Acc: 0.7467
Epoch 90/100, Loss: 0.6742, Acc: 0.5779, Val Loss: 0.6085, Val Acc: 0.7474
Epoch 91/100, Loss: 0.6742, Acc: 0.5760, Val Loss: 0.6088, Val Acc: 0.7459
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6741, Acc: 0.5778, Val Loss: 0.6087, Val Acc: 0.7471
Epoch 93/100, Loss: 0.6741, Acc: 0.5780, Val Loss: 0.6085, Val Acc: 0.7482
Epoch 94/100, Loss: 0.6741, Acc: 0.5774, Val Loss: 0.6083, Val Acc: 0.7504
Epoch 95/100, Loss: 0.6741, Acc: 0.5763, Val Loss: 0.6086, Val Acc: 0.7467
Epoch 96/100, Loss: 0.6741, Acc: 0.5769, Val Loss: 0.6086, Val Acc: 0.7452
Epoch 97/100, Loss: 0.6741, Acc: 0.5770, Val Loss: 0.6085, Val Acc: 0.7471
Epoch 98/100, Loss: 0.6741, Acc: 0.5782, Val Loss: 0.6089, Val Acc: 0.7448
Epoch 99/100, Loss: 0.6740, Acc: 0.5777, Val Loss: 0.6083, Val Acc: 0.7485
Epoch 100/100, Loss: 0.6740, Acc: 0.5773, Val Loss: 0.6087, Val Acc: 0.7459

##############################
Resultados para principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5 
 {'training': [0.6739904993638786, 0.5773262228760574, 0.5535144788876132, 0.7981972038263428, 0.6537099811676083], 'validate': [0.6086729799592218, 0.7459499263622975, 0.7860824742268041, 0.6747787610619469, 0.7261904761904762], 'test': [0.7313964929845598, 0.4305064782096584, 0.4587950138504155, 0.78125, 0.5780977312390925]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  011  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  011  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6939, Acc: 0.5035, Val Loss: 0.6939, Val Acc: 0.4643
Mejor modelo guardado con Val Loss: 0.6939
Epoch 2/100, Loss: 0.6930, Acc: 0.5053, Val Loss: 0.6891, Val Acc: 0.5026
Mejor modelo guardado con Val Loss: 0.6891
Epoch 3/100, Loss: 0.6938, Acc: 0.4977, Val Loss: 0.6946, Val Acc: 0.4993
Epoch 4/100, Loss: 0.6935, Acc: 0.5025, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 5/100, Loss: 0.6937, Acc: 0.4969, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 6/100, Loss: 0.6939, Acc: 0.4941, Val Loss: 0.6936, Val Acc: 0.4993
Epoch 7/100, Loss: 0.6935, Acc: 0.4983, Val Loss: 0.6940, Val Acc: 0.4993
Epoch 8/100, Loss: 0.6936, Acc: 0.4973, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 9/100, Loss: 0.6935, Acc: 0.5059, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 10/100, Loss: 0.6936, Acc: 0.4961, Val Loss: 0.6943, Val Acc: 0.4993
Epoch 11/100, Loss: 0.6936, Acc: 0.4983, Val Loss: 0.6934, Val Acc: 0.4993
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6934, Acc: 0.4937, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 13/100, Loss: 0.6934, Acc: 0.4983, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 14/100, Loss: 0.6932, Acc: 0.5039, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 15/100, Loss: 0.6931, Acc: 0.5073, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 16/100, Loss: 0.6935, Acc: 0.4905, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 17/100, Loss: 0.6934, Acc: 0.4956, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 18/100, Loss: 0.6935, Acc: 0.4925, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 19/100, Loss: 0.6933, Acc: 0.5044, Val Loss: 0.6936, Val Acc: 0.4993
Epoch 20/100, Loss: 0.6934, Acc: 0.4949, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 21/100, Loss: 0.6933, Acc: 0.4969, Val Loss: 0.6932, Val Acc: 0.4993
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.4961, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 23/100, Loss: 0.6932, Acc: 0.4991, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 24/100, Loss: 0.6932, Acc: 0.4952, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 25/100, Loss: 0.6932, Acc: 0.5004, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 26/100, Loss: 0.6930, Acc: 0.5055, Val Loss: 0.6913, Val Acc: 0.5600
Epoch 27/100, Loss: 0.6928, Acc: 0.5092, Val Loss: 0.6932, Val Acc: 0.5077
Epoch 28/100, Loss: 0.6922, Acc: 0.5268, Val Loss: 0.6900, Val Acc: 0.5891
Epoch 29/100, Loss: 0.6919, Acc: 0.5318, Val Loss: 0.6899, Val Acc: 0.5880
Epoch 30/100, Loss: 0.6915, Acc: 0.5341, Val Loss: 0.6885, Val Acc: 0.6038
Mejor modelo guardado con Val Loss: 0.6885
Epoch 31/100, Loss: 0.6911, Acc: 0.5417, Val Loss: 0.6899, Val Acc: 0.5858
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6906, Acc: 0.5548, Val Loss: 0.6872, Val Acc: 0.6127
Mejor modelo guardado con Val Loss: 0.6872
Epoch 33/100, Loss: 0.6902, Acc: 0.5548, Val Loss: 0.6905, Val Acc: 0.5515
Epoch 34/100, Loss: 0.6895, Acc: 0.5589, Val Loss: 0.6906, Val Acc: 0.5571
Epoch 35/100, Loss: 0.6887, Acc: 0.5646, Val Loss: 0.6942, Val Acc: 0.5011
Epoch 36/100, Loss: 0.6878, Acc: 0.5645, Val Loss: 0.6936, Val Acc: 0.5221
Epoch 37/100, Loss: 0.6867, Acc: 0.5710, Val Loss: 0.6960, Val Acc: 0.4875
Epoch 38/100, Loss: 0.6860, Acc: 0.5674, Val Loss: 0.6934, Val Acc: 0.5173
Epoch 39/100, Loss: 0.6851, Acc: 0.5736, Val Loss: 0.6952, Val Acc: 0.4989
Epoch 40/100, Loss: 0.6843, Acc: 0.5744, Val Loss: 0.6942, Val Acc: 0.5191
Epoch 41/100, Loss: 0.6834, Acc: 0.5757, Val Loss: 0.7007, Val Acc: 0.4433
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6826, Acc: 0.5791, Val Loss: 0.6971, Val Acc: 0.5092
Epoch 43/100, Loss: 0.6822, Acc: 0.5798, Val Loss: 0.6985, Val Acc: 0.5015
Epoch 44/100, Loss: 0.6814, Acc: 0.5862, Val Loss: 0.6998, Val Acc: 0.5346
Epoch 45/100, Loss: 0.6814, Acc: 0.5736, Val Loss: 0.6994, Val Acc: 0.4967
Epoch 46/100, Loss: 0.6808, Acc: 0.5811, Val Loss: 0.6983, Val Acc: 0.5103
Epoch 47/100, Loss: 0.6805, Acc: 0.5825, Val Loss: 0.6972, Val Acc: 0.5184
Epoch 48/100, Loss: 0.6799, Acc: 0.5850, Val Loss: 0.6986, Val Acc: 0.4827
Epoch 49/100, Loss: 0.6795, Acc: 0.5833, Val Loss: 0.6982, Val Acc: 0.5026
Epoch 50/100, Loss: 0.6791, Acc: 0.5840, Val Loss: 0.6970, Val Acc: 0.5254
Epoch 51/100, Loss: 0.6788, Acc: 0.5818, Val Loss: 0.6993, Val Acc: 0.5048
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6783, Acc: 0.5844, Val Loss: 0.6964, Val Acc: 0.5210
Epoch 53/100, Loss: 0.6781, Acc: 0.5847, Val Loss: 0.6967, Val Acc: 0.5155
Epoch 54/100, Loss: 0.6779, Acc: 0.5849, Val Loss: 0.6980, Val Acc: 0.5169
Epoch 55/100, Loss: 0.6776, Acc: 0.5834, Val Loss: 0.6971, Val Acc: 0.5151
Epoch 56/100, Loss: 0.6775, Acc: 0.5854, Val Loss: 0.6986, Val Acc: 0.4963
Epoch 57/100, Loss: 0.6772, Acc: 0.5881, Val Loss: 0.6992, Val Acc: 0.4959
Epoch 58/100, Loss: 0.6770, Acc: 0.5838, Val Loss: 0.6993, Val Acc: 0.5099
Epoch 59/100, Loss: 0.6768, Acc: 0.5853, Val Loss: 0.6964, Val Acc: 0.5339
Epoch 60/100, Loss: 0.6767, Acc: 0.5850, Val Loss: 0.6973, Val Acc: 0.5258
Epoch 61/100, Loss: 0.6764, Acc: 0.5866, Val Loss: 0.6971, Val Acc: 0.5331
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6763, Acc: 0.5849, Val Loss: 0.6981, Val Acc: 0.5236
Epoch 63/100, Loss: 0.6761, Acc: 0.5869, Val Loss: 0.6975, Val Acc: 0.5158
Epoch 64/100, Loss: 0.6760, Acc: 0.5883, Val Loss: 0.6975, Val Acc: 0.5166
Epoch 65/100, Loss: 0.6759, Acc: 0.5883, Val Loss: 0.6980, Val Acc: 0.5225
Epoch 66/100, Loss: 0.6758, Acc: 0.5869, Val Loss: 0.6974, Val Acc: 0.5144
Epoch 67/100, Loss: 0.6757, Acc: 0.5873, Val Loss: 0.6983, Val Acc: 0.5136
Epoch 68/100, Loss: 0.6756, Acc: 0.5866, Val Loss: 0.6981, Val Acc: 0.5118
Epoch 69/100, Loss: 0.6755, Acc: 0.5872, Val Loss: 0.6974, Val Acc: 0.5155
Epoch 70/100, Loss: 0.6754, Acc: 0.5862, Val Loss: 0.6978, Val Acc: 0.5155
Epoch 71/100, Loss: 0.6753, Acc: 0.5865, Val Loss: 0.6988, Val Acc: 0.5203
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6751, Acc: 0.5863, Val Loss: 0.6982, Val Acc: 0.5155
Epoch 73/100, Loss: 0.6751, Acc: 0.5880, Val Loss: 0.6984, Val Acc: 0.5173
Epoch 74/100, Loss: 0.6750, Acc: 0.5880, Val Loss: 0.6985, Val Acc: 0.5151
Epoch 75/100, Loss: 0.6750, Acc: 0.5877, Val Loss: 0.6978, Val Acc: 0.5151
Epoch 76/100, Loss: 0.6749, Acc: 0.5877, Val Loss: 0.6983, Val Acc: 0.5147
Epoch 77/100, Loss: 0.6748, Acc: 0.5873, Val Loss: 0.6977, Val Acc: 0.5147
Epoch 78/100, Loss: 0.6748, Acc: 0.5878, Val Loss: 0.6983, Val Acc: 0.5110
Epoch 79/100, Loss: 0.6747, Acc: 0.5872, Val Loss: 0.6985, Val Acc: 0.5166
Epoch 80/100, Loss: 0.6746, Acc: 0.5885, Val Loss: 0.6987, Val Acc: 0.5107
Epoch 81/100, Loss: 0.6745, Acc: 0.5885, Val Loss: 0.6988, Val Acc: 0.5125
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6743, Acc: 0.5881, Val Loss: 0.6985, Val Acc: 0.5099
Epoch 83/100, Loss: 0.6742, Acc: 0.5893, Val Loss: 0.6984, Val Acc: 0.5151
Epoch 84/100, Loss: 0.6741, Acc: 0.5896, Val Loss: 0.6991, Val Acc: 0.5103
Epoch 85/100, Loss: 0.6740, Acc: 0.5874, Val Loss: 0.6982, Val Acc: 0.5118
Epoch 86/100, Loss: 0.6739, Acc: 0.5900, Val Loss: 0.6982, Val Acc: 0.5122
Epoch 87/100, Loss: 0.6739, Acc: 0.5889, Val Loss: 0.6982, Val Acc: 0.5184
Epoch 88/100, Loss: 0.6738, Acc: 0.5889, Val Loss: 0.6982, Val Acc: 0.5133
Epoch 89/100, Loss: 0.6737, Acc: 0.5886, Val Loss: 0.6966, Val Acc: 0.5191
Epoch 90/100, Loss: 0.6730, Acc: 0.5910, Val Loss: 0.6862, Val Acc: 0.5703
Mejor modelo guardado con Val Loss: 0.6862
Epoch 91/100, Loss: 0.6725, Acc: 0.5908, Val Loss: 0.6851, Val Acc: 0.5722
Mejor modelo guardado con Val Loss: 0.6851
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6724, Acc: 0.5920, Val Loss: 0.6845, Val Acc: 0.5729
Mejor modelo guardado con Val Loss: 0.6845
Epoch 93/100, Loss: 0.6723, Acc: 0.5942, Val Loss: 0.6845, Val Acc: 0.5718
Epoch 94/100, Loss: 0.6722, Acc: 0.5934, Val Loss: 0.6847, Val Acc: 0.5714
Epoch 95/100, Loss: 0.6721, Acc: 0.5929, Val Loss: 0.6852, Val Acc: 0.5718
Epoch 96/100, Loss: 0.6720, Acc: 0.5936, Val Loss: 0.6851, Val Acc: 0.5707
Epoch 97/100, Loss: 0.6720, Acc: 0.5909, Val Loss: 0.6845, Val Acc: 0.5707
Epoch 98/100, Loss: 0.6719, Acc: 0.5940, Val Loss: 0.6840, Val Acc: 0.5718
Mejor modelo guardado con Val Loss: 0.6840
Epoch 99/100, Loss: 0.6718, Acc: 0.5933, Val Loss: 0.6848, Val Acc: 0.5670
Epoch 100/100, Loss: 0.6717, Acc: 0.5929, Val Loss: 0.6846, Val Acc: 0.5696

##############################
Resultados para principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5 
 {'training': [0.6717430287400078, 0.5928650239058477, 0.572123640526617, 0.7354672553348051, 0.6435930457179653], 'validate': [0.6846027332682942, 0.5695876288659794, 0.5599743425272611, 0.6438053097345132, 0.5989708404802745], 'test': [0.6737196931132564, 0.6183745583038869, 0.5898472596585804, 0.7741745283018868, 0.6695563488016318]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  021  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  021  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5862, Acc: 0.7218, Val Loss: 0.4591, Val Acc: 0.8380
Mejor modelo guardado con Val Loss: 0.4591
Epoch 2/100, Loss: 0.5390, Acc: 0.7413, Val Loss: 0.4216, Val Acc: 0.8630
Mejor modelo guardado con Val Loss: 0.4216
Epoch 3/100, Loss: 0.5352, Acc: 0.7398, Val Loss: 0.4854, Val Acc: 0.8236
Epoch 4/100, Loss: 0.5225, Acc: 0.7434, Val Loss: 0.5023, Val Acc: 0.7636
Epoch 5/100, Loss: 0.5155, Acc: 0.7461, Val Loss: 0.3736, Val Acc: 0.8579
Mejor modelo guardado con Val Loss: 0.3736
Epoch 6/100, Loss: 0.5113, Acc: 0.7492, Val Loss: 0.3999, Val Acc: 0.8778
Epoch 7/100, Loss: 0.5102, Acc: 0.7538, Val Loss: 0.3665, Val Acc: 0.8649
Mejor modelo guardado con Val Loss: 0.3665
Epoch 8/100, Loss: 0.5065, Acc: 0.7573, Val Loss: 0.3888, Val Acc: 0.8697
Epoch 9/100, Loss: 0.5031, Acc: 0.7588, Val Loss: 0.3564, Val Acc: 0.8656
Mejor modelo guardado con Val Loss: 0.3564
Epoch 10/100, Loss: 0.5048, Acc: 0.7550, Val Loss: 0.3624, Val Acc: 0.8844
Epoch 11/100, Loss: 0.5054, Acc: 0.7531, Val Loss: 0.3862, Val Acc: 0.8590
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4958, Acc: 0.7633, Val Loss: 0.3832, Val Acc: 0.8527
Epoch 13/100, Loss: 0.4962, Acc: 0.7618, Val Loss: 0.3997, Val Acc: 0.8579
Epoch 14/100, Loss: 0.4982, Acc: 0.7611, Val Loss: 0.3731, Val Acc: 0.8800
Epoch 15/100, Loss: 0.4915, Acc: 0.7654, Val Loss: 0.3807, Val Acc: 0.8409
Epoch 16/100, Loss: 0.4956, Acc: 0.7596, Val Loss: 0.4196, Val Acc: 0.8244
Epoch 17/100, Loss: 0.4942, Acc: 0.7601, Val Loss: 0.3707, Val Acc: 0.8741
Epoch 18/100, Loss: 0.4927, Acc: 0.7634, Val Loss: 0.3599, Val Acc: 0.8704
Epoch 19/100, Loss: 0.4910, Acc: 0.7650, Val Loss: 0.4269, Val Acc: 0.8108
Epoch 20/100, Loss: 0.4902, Acc: 0.7664, Val Loss: 0.3726, Val Acc: 0.8586
Epoch 21/100, Loss: 0.4891, Acc: 0.7626, Val Loss: 0.3706, Val Acc: 0.8759
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4891, Acc: 0.7656, Val Loss: 0.3571, Val Acc: 0.8689
Epoch 23/100, Loss: 0.4877, Acc: 0.7647, Val Loss: 0.3516, Val Acc: 0.8630
Mejor modelo guardado con Val Loss: 0.3516
Epoch 24/100, Loss: 0.4865, Acc: 0.7678, Val Loss: 0.3631, Val Acc: 0.8697
Epoch 25/100, Loss: 0.4842, Acc: 0.7673, Val Loss: 0.3748, Val Acc: 0.8575
Epoch 26/100, Loss: 0.4873, Acc: 0.7656, Val Loss: 0.3609, Val Acc: 0.8781
Epoch 27/100, Loss: 0.4842, Acc: 0.7648, Val Loss: 0.3778, Val Acc: 0.8472
Epoch 28/100, Loss: 0.4832, Acc: 0.7667, Val Loss: 0.3803, Val Acc: 0.8531
Epoch 29/100, Loss: 0.4837, Acc: 0.7669, Val Loss: 0.3632, Val Acc: 0.8756
Epoch 30/100, Loss: 0.4819, Acc: 0.7692, Val Loss: 0.3627, Val Acc: 0.8671
Epoch 31/100, Loss: 0.4822, Acc: 0.7686, Val Loss: 0.3613, Val Acc: 0.8601
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4802, Acc: 0.7690, Val Loss: 0.3722, Val Acc: 0.8542
Epoch 33/100, Loss: 0.4790, Acc: 0.7675, Val Loss: 0.3559, Val Acc: 0.8778
Epoch 34/100, Loss: 0.4794, Acc: 0.7714, Val Loss: 0.3659, Val Acc: 0.8726
Epoch 35/100, Loss: 0.4794, Acc: 0.7684, Val Loss: 0.3679, Val Acc: 0.8487
Epoch 36/100, Loss: 0.4793, Acc: 0.7695, Val Loss: 0.3704, Val Acc: 0.8752
Epoch 37/100, Loss: 0.4791, Acc: 0.7700, Val Loss: 0.3837, Val Acc: 0.8472
Epoch 38/100, Loss: 0.4784, Acc: 0.7694, Val Loss: 0.3753, Val Acc: 0.8435
Epoch 39/100, Loss: 0.4788, Acc: 0.7708, Val Loss: 0.3692, Val Acc: 0.8568
Epoch 40/100, Loss: 0.4780, Acc: 0.7685, Val Loss: 0.3853, Val Acc: 0.8406
Epoch 41/100, Loss: 0.4774, Acc: 0.7704, Val Loss: 0.3654, Val Acc: 0.8660
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4768, Acc: 0.7726, Val Loss: 0.3696, Val Acc: 0.8667
Epoch 43/100, Loss: 0.4765, Acc: 0.7697, Val Loss: 0.3576, Val Acc: 0.8848
Epoch 44/100, Loss: 0.4769, Acc: 0.7704, Val Loss: 0.3591, Val Acc: 0.8682
Epoch 45/100, Loss: 0.4761, Acc: 0.7693, Val Loss: 0.3637, Val Acc: 0.8708
Epoch 46/100, Loss: 0.4762, Acc: 0.7694, Val Loss: 0.3563, Val Acc: 0.8697
Epoch 47/100, Loss: 0.4761, Acc: 0.7719, Val Loss: 0.3651, Val Acc: 0.8601
Epoch 48/100, Loss: 0.4759, Acc: 0.7698, Val Loss: 0.3695, Val Acc: 0.8579
Epoch 49/100, Loss: 0.4761, Acc: 0.7708, Val Loss: 0.3582, Val Acc: 0.8700
Epoch 50/100, Loss: 0.4758, Acc: 0.7707, Val Loss: 0.3601, Val Acc: 0.8708
Epoch 51/100, Loss: 0.4757, Acc: 0.7706, Val Loss: 0.3669, Val Acc: 0.8645
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4747, Acc: 0.7720, Val Loss: 0.3674, Val Acc: 0.8590
Epoch 53/100, Loss: 0.4746, Acc: 0.7704, Val Loss: 0.3621, Val Acc: 0.8619
Epoch 54/100, Loss: 0.4741, Acc: 0.7717, Val Loss: 0.3662, Val Acc: 0.8630
Epoch 55/100, Loss: 0.4742, Acc: 0.7694, Val Loss: 0.3710, Val Acc: 0.8579
Epoch 56/100, Loss: 0.4741, Acc: 0.7710, Val Loss: 0.3669, Val Acc: 0.8623
Epoch 57/100, Loss: 0.4736, Acc: 0.7721, Val Loss: 0.3747, Val Acc: 0.8413
Epoch 58/100, Loss: 0.4742, Acc: 0.7723, Val Loss: 0.3648, Val Acc: 0.8652
Epoch 59/100, Loss: 0.4736, Acc: 0.7722, Val Loss: 0.3596, Val Acc: 0.8770
Epoch 60/100, Loss: 0.4738, Acc: 0.7706, Val Loss: 0.3648, Val Acc: 0.8582
Epoch 61/100, Loss: 0.4737, Acc: 0.7697, Val Loss: 0.3713, Val Acc: 0.8579
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4735, Acc: 0.7712, Val Loss: 0.3617, Val Acc: 0.8663
Epoch 63/100, Loss: 0.4732, Acc: 0.7708, Val Loss: 0.3649, Val Acc: 0.8630
Epoch 64/100, Loss: 0.4732, Acc: 0.7702, Val Loss: 0.3654, Val Acc: 0.8612
Epoch 65/100, Loss: 0.4731, Acc: 0.7700, Val Loss: 0.3656, Val Acc: 0.8605
Epoch 66/100, Loss: 0.4732, Acc: 0.7702, Val Loss: 0.3625, Val Acc: 0.8667
Epoch 67/100, Loss: 0.4730, Acc: 0.7705, Val Loss: 0.3690, Val Acc: 0.8542
Epoch 68/100, Loss: 0.4731, Acc: 0.7704, Val Loss: 0.3662, Val Acc: 0.8612
Epoch 69/100, Loss: 0.4731, Acc: 0.7711, Val Loss: 0.3710, Val Acc: 0.8542
Epoch 70/100, Loss: 0.4730, Acc: 0.7701, Val Loss: 0.3674, Val Acc: 0.8612
Epoch 71/100, Loss: 0.4729, Acc: 0.7711, Val Loss: 0.3601, Val Acc: 0.8682
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4728, Acc: 0.7698, Val Loss: 0.3637, Val Acc: 0.8627
Epoch 73/100, Loss: 0.4727, Acc: 0.7709, Val Loss: 0.3645, Val Acc: 0.8641
Epoch 74/100, Loss: 0.4727, Acc: 0.7702, Val Loss: 0.3656, Val Acc: 0.8623
Epoch 75/100, Loss: 0.4727, Acc: 0.7704, Val Loss: 0.3613, Val Acc: 0.8660
Epoch 76/100, Loss: 0.4726, Acc: 0.7701, Val Loss: 0.3672, Val Acc: 0.8608
Epoch 77/100, Loss: 0.4726, Acc: 0.7709, Val Loss: 0.3650, Val Acc: 0.8630
Epoch 78/100, Loss: 0.4726, Acc: 0.7710, Val Loss: 0.3653, Val Acc: 0.8627
Epoch 79/100, Loss: 0.4726, Acc: 0.7704, Val Loss: 0.3631, Val Acc: 0.8641
Epoch 80/100, Loss: 0.4725, Acc: 0.7711, Val Loss: 0.3616, Val Acc: 0.8656
Epoch 81/100, Loss: 0.4726, Acc: 0.7711, Val Loss: 0.3634, Val Acc: 0.8645
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4725, Acc: 0.7706, Val Loss: 0.3644, Val Acc: 0.8634
Epoch 83/100, Loss: 0.4724, Acc: 0.7702, Val Loss: 0.3642, Val Acc: 0.8630
Epoch 84/100, Loss: 0.4723, Acc: 0.7708, Val Loss: 0.3687, Val Acc: 0.8571
Epoch 85/100, Loss: 0.4724, Acc: 0.7707, Val Loss: 0.3619, Val Acc: 0.8656
Epoch 86/100, Loss: 0.4723, Acc: 0.7706, Val Loss: 0.3652, Val Acc: 0.8627
Epoch 87/100, Loss: 0.4723, Acc: 0.7712, Val Loss: 0.3644, Val Acc: 0.8627
Epoch 88/100, Loss: 0.4723, Acc: 0.7706, Val Loss: 0.3624, Val Acc: 0.8660
Epoch 89/100, Loss: 0.4723, Acc: 0.7708, Val Loss: 0.3649, Val Acc: 0.8634
Epoch 90/100, Loss: 0.4723, Acc: 0.7710, Val Loss: 0.3635, Val Acc: 0.8645
Epoch 91/100, Loss: 0.4722, Acc: 0.7706, Val Loss: 0.3613, Val Acc: 0.8652
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4722, Acc: 0.7710, Val Loss: 0.3626, Val Acc: 0.8638
Epoch 93/100, Loss: 0.4722, Acc: 0.7719, Val Loss: 0.3654, Val Acc: 0.8627
Epoch 94/100, Loss: 0.4722, Acc: 0.7700, Val Loss: 0.3626, Val Acc: 0.8641
Epoch 95/100, Loss: 0.4721, Acc: 0.7707, Val Loss: 0.3624, Val Acc: 0.8652
Epoch 96/100, Loss: 0.4720, Acc: 0.7707, Val Loss: 0.3654, Val Acc: 0.8619
Epoch 97/100, Loss: 0.4720, Acc: 0.7710, Val Loss: 0.3646, Val Acc: 0.8619
Epoch 98/100, Loss: 0.4720, Acc: 0.7712, Val Loss: 0.3629, Val Acc: 0.8667
Epoch 99/100, Loss: 0.4719, Acc: 0.7710, Val Loss: 0.3638, Val Acc: 0.8638
Epoch 100/100, Loss: 0.4718, Acc: 0.7717, Val Loss: 0.3656, Val Acc: 0.8616

##############################
Resultados para principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5 
 {'training': [0.4717862119938618, 0.7716991541007724, 0.7550526861288651, 0.8040838852097131, 0.7787973273942094], 'validate': [0.36558943605700206, 0.8615611192930781, 0.8035935563816605, 0.9564896755162242, 0.8734006734006734], 'test': [0.3919863024795497, 0.8430506478209658, 0.8111289459604066, 0.8938679245283019, 0.8504908835904629]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  008  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  008  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6921, Acc: 0.5249, Val Loss: 0.6945, Val Acc: 0.4974
Mejor modelo guardado con Val Loss: 0.6945
Epoch 2/100, Loss: 0.6935, Acc: 0.4966, Val Loss: 0.6936, Val Acc: 0.4978
Mejor modelo guardado con Val Loss: 0.6936
Epoch 3/100, Loss: 0.6935, Acc: 0.5057, Val Loss: 0.6930, Val Acc: 0.5052
Mejor modelo guardado con Val Loss: 0.6930
Epoch 4/100, Loss: 0.6935, Acc: 0.5025, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 5/100, Loss: 0.6933, Acc: 0.5093, Val Loss: 0.6931, Val Acc: 0.5011
Epoch 6/100, Loss: 0.6935, Acc: 0.5039, Val Loss: 0.6930, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6930
Epoch 7/100, Loss: 0.6932, Acc: 0.5017, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 8/100, Loss: 0.6935, Acc: 0.4969, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 9/100, Loss: 0.6937, Acc: 0.4982, Val Loss: 0.6940, Val Acc: 0.4993
Epoch 10/100, Loss: 0.6939, Acc: 0.4922, Val Loss: 0.6932, Val Acc: 0.5007
Epoch 11/100, Loss: 0.6935, Acc: 0.5011, Val Loss: 0.6936, Val Acc: 0.4993
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6932, Acc: 0.5032, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 13/100, Loss: 0.6933, Acc: 0.4984, Val Loss: 0.6930, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6930
Epoch 14/100, Loss: 0.6934, Acc: 0.4944, Val Loss: 0.6931, Val Acc: 0.5033
Epoch 15/100, Loss: 0.6933, Acc: 0.4982, Val Loss: 0.6938, Val Acc: 0.4993
Epoch 16/100, Loss: 0.6933, Acc: 0.5037, Val Loss: 0.6937, Val Acc: 0.4993
Epoch 17/100, Loss: 0.6933, Acc: 0.4910, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 18/100, Loss: 0.6933, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5029
Epoch 19/100, Loss: 0.6932, Acc: 0.5058, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 20/100, Loss: 0.6933, Acc: 0.4981, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 21/100, Loss: 0.6932, Acc: 0.5040, Val Loss: 0.6930, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6930
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6932, Acc: 0.5031, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 23/100, Loss: 0.6932, Acc: 0.5034, Val Loss: 0.6931, Val Acc: 0.5055
Epoch 24/100, Loss: 0.6932, Acc: 0.4971, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 25/100, Loss: 0.6932, Acc: 0.5011, Val Loss: 0.6931, Val Acc: 0.5029
Epoch 26/100, Loss: 0.6932, Acc: 0.5047, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 27/100, Loss: 0.6932, Acc: 0.5003, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 28/100, Loss: 0.6932, Acc: 0.4949, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 29/100, Loss: 0.6933, Acc: 0.4971, Val Loss: 0.6931, Val Acc: 0.5048
Epoch 30/100, Loss: 0.6931, Acc: 0.5049, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 31/100, Loss: 0.6931, Acc: 0.5040, Val Loss: 0.6933, Val Acc: 0.4993
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4925, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 33/100, Loss: 0.6932, Acc: 0.5008, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 34/100, Loss: 0.6932, Acc: 0.4949, Val Loss: 0.6931, Val Acc: 0.4993
Epoch 35/100, Loss: 0.6932, Acc: 0.4955, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 36/100, Loss: 0.6932, Acc: 0.5012, Val Loss: 0.6930, Val Acc: 0.5048
Epoch 37/100, Loss: 0.6931, Acc: 0.4935, Val Loss: 0.6929, Val Acc: 0.5066
Mejor modelo guardado con Val Loss: 0.6929
Epoch 38/100, Loss: 0.6930, Acc: 0.5003, Val Loss: 0.6926, Val Acc: 0.5096
Mejor modelo guardado con Val Loss: 0.6926
Epoch 39/100, Loss: 0.6929, Acc: 0.5006, Val Loss: 0.6927, Val Acc: 0.5081
Epoch 40/100, Loss: 0.6929, Acc: 0.4961, Val Loss: 0.6928, Val Acc: 0.5066
Epoch 41/100, Loss: 0.6930, Acc: 0.4962, Val Loss: 0.6927, Val Acc: 0.5085
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6929, Acc: 0.4994, Val Loss: 0.6927, Val Acc: 0.5085
Epoch 43/100, Loss: 0.6929, Acc: 0.5025, Val Loss: 0.6927, Val Acc: 0.4993
Epoch 44/100, Loss: 0.6929, Acc: 0.5002, Val Loss: 0.6927, Val Acc: 0.4993
Epoch 45/100, Loss: 0.6929, Acc: 0.4958, Val Loss: 0.6927, Val Acc: 0.4993
Epoch 46/100, Loss: 0.6929, Acc: 0.4995, Val Loss: 0.6926, Val Acc: 0.4993
Epoch 47/100, Loss: 0.6929, Acc: 0.4983, Val Loss: 0.6927, Val Acc: 0.5081
Epoch 48/100, Loss: 0.6929, Acc: 0.4920, Val Loss: 0.6926, Val Acc: 0.5077
Epoch 49/100, Loss: 0.6929, Acc: 0.5016, Val Loss: 0.6926, Val Acc: 0.5081
Epoch 50/100, Loss: 0.6928, Acc: 0.5035, Val Loss: 0.6927, Val Acc: 0.5070
Epoch 51/100, Loss: 0.6928, Acc: 0.5000, Val Loss: 0.6927, Val Acc: 0.5070
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6928, Acc: 0.5040, Val Loss: 0.6926, Val Acc: 0.5081
Epoch 53/100, Loss: 0.6928, Acc: 0.4965, Val Loss: 0.6926, Val Acc: 0.5074
Epoch 54/100, Loss: 0.6928, Acc: 0.4993, Val Loss: 0.6926, Val Acc: 0.5077
Epoch 55/100, Loss: 0.6928, Acc: 0.4953, Val Loss: 0.6927, Val Acc: 0.5092
Epoch 56/100, Loss: 0.6928, Acc: 0.5038, Val Loss: 0.6927, Val Acc: 0.5055
Epoch 57/100, Loss: 0.6928, Acc: 0.5062, Val Loss: 0.6935, Val Acc: 0.4786
Epoch 58/100, Loss: 0.6926, Acc: 0.5191, Val Loss: 0.6930, Val Acc: 0.5125
Epoch 59/100, Loss: 0.6924, Acc: 0.5228, Val Loss: 0.6928, Val Acc: 0.5092
Epoch 60/100, Loss: 0.6922, Acc: 0.5257, Val Loss: 0.6928, Val Acc: 0.5081
Epoch 61/100, Loss: 0.6922, Acc: 0.5337, Val Loss: 0.6928, Val Acc: 0.5077
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6921, Acc: 0.5315, Val Loss: 0.6926, Val Acc: 0.5122
Epoch 63/100, Loss: 0.6921, Acc: 0.5312, Val Loss: 0.6927, Val Acc: 0.5092
Epoch 64/100, Loss: 0.6920, Acc: 0.5315, Val Loss: 0.6926, Val Acc: 0.5110
Epoch 65/100, Loss: 0.6920, Acc: 0.5355, Val Loss: 0.6926, Val Acc: 0.5136
Epoch 66/100, Loss: 0.6920, Acc: 0.5335, Val Loss: 0.6925, Val Acc: 0.5151
Mejor modelo guardado con Val Loss: 0.6925
Epoch 67/100, Loss: 0.6919, Acc: 0.5391, Val Loss: 0.6920, Val Acc: 0.5258
Mejor modelo guardado con Val Loss: 0.6920
Epoch 68/100, Loss: 0.6918, Acc: 0.5400, Val Loss: 0.6919, Val Acc: 0.5265
Mejor modelo guardado con Val Loss: 0.6919
Epoch 69/100, Loss: 0.6918, Acc: 0.5402, Val Loss: 0.6919, Val Acc: 0.5276
Mejor modelo guardado con Val Loss: 0.6919
Epoch 70/100, Loss: 0.6918, Acc: 0.5406, Val Loss: 0.6918, Val Acc: 0.5287
Mejor modelo guardado con Val Loss: 0.6918
Epoch 71/100, Loss: 0.6917, Acc: 0.5423, Val Loss: 0.6918, Val Acc: 0.5309
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6917, Acc: 0.5417, Val Loss: 0.6918, Val Acc: 0.5328
Mejor modelo guardado con Val Loss: 0.6918
Epoch 73/100, Loss: 0.6917, Acc: 0.5450, Val Loss: 0.6917, Val Acc: 0.5328
Mejor modelo guardado con Val Loss: 0.6917
Epoch 74/100, Loss: 0.6917, Acc: 0.5434, Val Loss: 0.6917, Val Acc: 0.5335
Epoch 75/100, Loss: 0.6917, Acc: 0.5441, Val Loss: 0.6917, Val Acc: 0.5383
Mejor modelo guardado con Val Loss: 0.6917
Epoch 76/100, Loss: 0.6916, Acc: 0.5457, Val Loss: 0.6916, Val Acc: 0.5372
Mejor modelo guardado con Val Loss: 0.6916
Epoch 77/100, Loss: 0.6916, Acc: 0.5460, Val Loss: 0.6916, Val Acc: 0.5379
Mejor modelo guardado con Val Loss: 0.6916
Epoch 78/100, Loss: 0.6916, Acc: 0.5462, Val Loss: 0.6916, Val Acc: 0.5390
Mejor modelo guardado con Val Loss: 0.6916
Epoch 79/100, Loss: 0.6916, Acc: 0.5464, Val Loss: 0.6915, Val Acc: 0.5409
Mejor modelo guardado con Val Loss: 0.6915
Epoch 80/100, Loss: 0.6915, Acc: 0.5475, Val Loss: 0.6915, Val Acc: 0.5431
Mejor modelo guardado con Val Loss: 0.6915
Epoch 81/100, Loss: 0.6915, Acc: 0.5462, Val Loss: 0.6915, Val Acc: 0.5431
Mejor modelo guardado con Val Loss: 0.6915
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6915, Acc: 0.5479, Val Loss: 0.6914, Val Acc: 0.5446
Mejor modelo guardado con Val Loss: 0.6914
Epoch 83/100, Loss: 0.6915, Acc: 0.5464, Val Loss: 0.6914, Val Acc: 0.5416
Mejor modelo guardado con Val Loss: 0.6914
Epoch 84/100, Loss: 0.6915, Acc: 0.5473, Val Loss: 0.6914, Val Acc: 0.5457
Mejor modelo guardado con Val Loss: 0.6914
Epoch 85/100, Loss: 0.6914, Acc: 0.5471, Val Loss: 0.6913, Val Acc: 0.5468
Mejor modelo guardado con Val Loss: 0.6913
Epoch 86/100, Loss: 0.6914, Acc: 0.5480, Val Loss: 0.6913, Val Acc: 0.5486
Mejor modelo guardado con Val Loss: 0.6913
Epoch 87/100, Loss: 0.6914, Acc: 0.5476, Val Loss: 0.6913, Val Acc: 0.5457
Mejor modelo guardado con Val Loss: 0.6913
Epoch 88/100, Loss: 0.6914, Acc: 0.5474, Val Loss: 0.6912, Val Acc: 0.5490
Mejor modelo guardado con Val Loss: 0.6912
Epoch 89/100, Loss: 0.6913, Acc: 0.5504, Val Loss: 0.6920, Val Acc: 0.5372
Epoch 90/100, Loss: 0.6911, Acc: 0.5482, Val Loss: 0.6928, Val Acc: 0.5199
Epoch 91/100, Loss: 0.6910, Acc: 0.5511, Val Loss: 0.6935, Val Acc: 0.5092
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6909, Acc: 0.5519, Val Loss: 0.6951, Val Acc: 0.4948
Epoch 93/100, Loss: 0.6907, Acc: 0.5511, Val Loss: 0.6957, Val Acc: 0.4849
Epoch 94/100, Loss: 0.6906, Acc: 0.5542, Val Loss: 0.6956, Val Acc: 0.4849
Epoch 95/100, Loss: 0.6906, Acc: 0.5562, Val Loss: 0.6957, Val Acc: 0.4820
Epoch 96/100, Loss: 0.6906, Acc: 0.5542, Val Loss: 0.6958, Val Acc: 0.4838
Epoch 97/100, Loss: 0.6905, Acc: 0.5573, Val Loss: 0.6957, Val Acc: 0.4849
Epoch 98/100, Loss: 0.6905, Acc: 0.5555, Val Loss: 0.6957, Val Acc: 0.4845
Epoch 99/100, Loss: 0.6905, Acc: 0.5581, Val Loss: 0.6958, Val Acc: 0.4816
Epoch 100/100, Loss: 0.6904, Acc: 0.5560, Val Loss: 0.6958, Val Acc: 0.4812

##############################
Resultados para principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  5 
 {'training': [0.6904244313524154, 0.5559948510481795, 0.567369589345172, 0.47019867549668876, 0.5142339804848607], 'validate': [0.6957605370255404, 0.48122238586156113, 0.4751173708920188, 0.37315634218289084, 0.4180090871540686], 'test': [0.6904702208660267, 0.5556537102473498, 0.5723124516627996, 0.4363207547169811, 0.49514887922382067]}

##############################
Resultados para window:  5 
 {'102:020:125:011:021:008': {'training': [0.4800841552933247, 0.7643435086428834, 0.8004601547793349, 0.7040103016924208, 0.7491435842223745], 'validate': [0.23363444027166033, 0.9167893961708394, 0.9788135593220338, 0.8517699115044248, 0.9108832807570978], 'test': [0.7017287228394438, 0.6428150765606596, 0.676923076923077, 0.5448113207547169, 0.6037242731133616]}, '020:102:125:011:021:008': {'training': [0.4545723652743206, 0.787146009562339, 0.7382806535348908, 0.8894407652685798, 0.8068418856904463], 'validate': [0.9772447617941125, 0.4536082474226804, 0.4751937984496124, 0.9041297935103245, 0.6229674796747967], 'test': [0.626570098929935, 0.6719670200235571, 0.6303763440860215, 0.8295990566037735, 0.7163951120162932]}, '125:102:020:011:021:008': {'training': [0.6739904993638786, 0.5773262228760574, 0.5535144788876132, 0.7981972038263428, 0.6537099811676083], 'validate': [0.6086729799592218, 0.7459499263622975, 0.7860824742268041, 0.6747787610619469, 0.7261904761904762], 'test': [0.7313964929845598, 0.4305064782096584, 0.4587950138504155, 0.78125, 0.5780977312390925]}, '011:102:020:125:021:008': {'training': [0.6717430287400078, 0.5928650239058477, 0.572123640526617, 0.7354672553348051, 0.6435930457179653], 'validate': [0.6846027332682942, 0.5695876288659794, 0.5599743425272611, 0.6438053097345132, 0.5989708404802745], 'test': [0.6737196931132564, 0.6183745583038869, 0.5898472596585804, 0.7741745283018868, 0.6695563488016318]}, '021:102:020:125:011:008': {'training': [0.4717862119938618, 0.7716991541007724, 0.7550526861288651, 0.8040838852097131, 0.7787973273942094], 'validate': [0.36558943605700206, 0.8615611192930781, 0.8035935563816605, 0.9564896755162242, 0.8734006734006734], 'test': [0.3919863024795497, 0.8430506478209658, 0.8111289459604066, 0.8938679245283019, 0.8504908835904629]}, '008:102:020:125:011:021': {'training': [0.6904244313524154, 0.5559948510481795, 0.567369589345172, 0.47019867549668876, 0.5142339804848607], 'validate': [0.6957605370255404, 0.48122238586156113, 0.4751173708920188, 0.37315634218289084, 0.4180090871540686], 'test': [0.6904702208660267, 0.5556537102473498, 0.5723124516627996, 0.4363207547169811, 0.49514887922382067]}}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  036  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  036  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  036  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6909, Acc: 0.5261, Val Loss: 0.6859, Val Acc: 0.6016
Mejor modelo guardado con Val Loss: 0.6859
Epoch 2/100, Loss: 0.6913, Acc: 0.5208, Val Loss: 0.6892, Val Acc: 0.5007
Epoch 3/100, Loss: 0.6909, Acc: 0.5280, Val Loss: 0.6850, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6850
Epoch 4/100, Loss: 0.6902, Acc: 0.5320, Val Loss: 0.6818, Val Acc: 0.6465
Mejor modelo guardado con Val Loss: 0.6818
Epoch 5/100, Loss: 0.6899, Acc: 0.5156, Val Loss: 0.6675, Val Acc: 0.7761
Mejor modelo guardado con Val Loss: 0.6675
Epoch 6/100, Loss: 0.6894, Acc: 0.5163, Val Loss: 0.6934, Val Acc: 0.5092
Epoch 7/100, Loss: 0.6886, Acc: 0.5231, Val Loss: 0.6777, Val Acc: 0.7747
Epoch 8/100, Loss: 0.6877, Acc: 0.5166, Val Loss: 0.6885, Val Acc: 0.5007
Epoch 9/100, Loss: 0.6871, Acc: 0.5202, Val Loss: 0.6864, Val Acc: 0.5670
Epoch 10/100, Loss: 0.6879, Acc: 0.5212, Val Loss: 0.6823, Val Acc: 0.5740
Epoch 11/100, Loss: 0.6855, Acc: 0.5273, Val Loss: 0.6344, Val Acc: 0.8457
Mejor modelo guardado con Val Loss: 0.6344
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6848, Acc: 0.5359, Val Loss: 0.6828, Val Acc: 0.5884
Epoch 13/100, Loss: 0.6845, Acc: 0.5334, Val Loss: 0.6774, Val Acc: 0.6469
Epoch 14/100, Loss: 0.6841, Acc: 0.5401, Val Loss: 0.6621, Val Acc: 0.7482
Epoch 15/100, Loss: 0.6841, Acc: 0.5326, Val Loss: 0.6672, Val Acc: 0.7135
Epoch 16/100, Loss: 0.6835, Acc: 0.5304, Val Loss: 0.6615, Val Acc: 0.7198
Epoch 17/100, Loss: 0.6832, Acc: 0.5390, Val Loss: 0.6859, Val Acc: 0.5902
Epoch 18/100, Loss: 0.6829, Acc: 0.5160, Val Loss: 0.6695, Val Acc: 0.6370
Epoch 19/100, Loss: 0.6831, Acc: 0.5373, Val Loss: 0.6698, Val Acc: 0.6701
Epoch 20/100, Loss: 0.6828, Acc: 0.5314, Val Loss: 0.6923, Val Acc: 0.5133
Epoch 21/100, Loss: 0.6820, Acc: 0.5329, Val Loss: 0.6752, Val Acc: 0.6035
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6816, Acc: 0.5417, Val Loss: 0.6695, Val Acc: 0.6767
Epoch 23/100, Loss: 0.6814, Acc: 0.5311, Val Loss: 0.6675, Val Acc: 0.6753
Epoch 24/100, Loss: 0.6812, Acc: 0.5433, Val Loss: 0.6532, Val Acc: 0.7224
Epoch 25/100, Loss: 0.6811, Acc: 0.5344, Val Loss: 0.6380, Val Acc: 0.7728
Epoch 26/100, Loss: 0.6812, Acc: 0.5420, Val Loss: 0.6712, Val Acc: 0.6620
Epoch 27/100, Loss: 0.6807, Acc: 0.5429, Val Loss: 0.6645, Val Acc: 0.7062
Epoch 28/100, Loss: 0.6809, Acc: 0.5309, Val Loss: 0.6698, Val Acc: 0.6381
Epoch 29/100, Loss: 0.6806, Acc: 0.5412, Val Loss: 0.6748, Val Acc: 0.6119
Epoch 30/100, Loss: 0.6804, Acc: 0.5426, Val Loss: 0.6688, Val Acc: 0.6605
Epoch 31/100, Loss: 0.6803, Acc: 0.5420, Val Loss: 0.6570, Val Acc: 0.7250
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6802, Acc: 0.5429, Val Loss: 0.6541, Val Acc: 0.7367
Epoch 33/100, Loss: 0.6800, Acc: 0.5419, Val Loss: 0.6567, Val Acc: 0.7154
Epoch 34/100, Loss: 0.6799, Acc: 0.5419, Val Loss: 0.6589, Val Acc: 0.7066
Epoch 35/100, Loss: 0.6798, Acc: 0.5428, Val Loss: 0.6570, Val Acc: 0.7121
Epoch 36/100, Loss: 0.6797, Acc: 0.5419, Val Loss: 0.6532, Val Acc: 0.7187
Epoch 37/100, Loss: 0.6797, Acc: 0.5420, Val Loss: 0.6650, Val Acc: 0.6742
Epoch 38/100, Loss: 0.6797, Acc: 0.5422, Val Loss: 0.6628, Val Acc: 0.6672
Epoch 39/100, Loss: 0.6796, Acc: 0.5450, Val Loss: 0.6623, Val Acc: 0.6878
Epoch 40/100, Loss: 0.6795, Acc: 0.5411, Val Loss: 0.6686, Val Acc: 0.6388
Epoch 41/100, Loss: 0.6795, Acc: 0.5421, Val Loss: 0.6631, Val Acc: 0.6627
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6793, Acc: 0.5436, Val Loss: 0.6496, Val Acc: 0.7268
Epoch 43/100, Loss: 0.6792, Acc: 0.5427, Val Loss: 0.6555, Val Acc: 0.7095
Epoch 44/100, Loss: 0.6790, Acc: 0.5481, Val Loss: 0.6579, Val Acc: 0.6716
Epoch 45/100, Loss: 0.6788, Acc: 0.5483, Val Loss: 0.6620, Val Acc: 0.6429
Epoch 46/100, Loss: 0.6787, Acc: 0.5527, Val Loss: 0.6634, Val Acc: 0.6366
Epoch 47/100, Loss: 0.6788, Acc: 0.5414, Val Loss: 0.6548, Val Acc: 0.7018
Epoch 48/100, Loss: 0.6785, Acc: 0.5528, Val Loss: 0.6605, Val Acc: 0.6348
Epoch 49/100, Loss: 0.6784, Acc: 0.5531, Val Loss: 0.6495, Val Acc: 0.6988
Epoch 50/100, Loss: 0.6783, Acc: 0.5529, Val Loss: 0.6371, Val Acc: 0.7518
Epoch 51/100, Loss: 0.6780, Acc: 0.5514, Val Loss: 0.6568, Val Acc: 0.6745
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6777, Acc: 0.5537, Val Loss: 0.6604, Val Acc: 0.6436
Epoch 53/100, Loss: 0.6777, Acc: 0.5542, Val Loss: 0.6584, Val Acc: 0.6458
Epoch 54/100, Loss: 0.6776, Acc: 0.5554, Val Loss: 0.6547, Val Acc: 0.6811
Epoch 55/100, Loss: 0.6776, Acc: 0.5542, Val Loss: 0.6573, Val Acc: 0.6587
Epoch 56/100, Loss: 0.6775, Acc: 0.5567, Val Loss: 0.6550, Val Acc: 0.6734
Epoch 57/100, Loss: 0.6774, Acc: 0.5553, Val Loss: 0.6568, Val Acc: 0.6635
Epoch 58/100, Loss: 0.6774, Acc: 0.5563, Val Loss: 0.6545, Val Acc: 0.6697
Epoch 59/100, Loss: 0.6773, Acc: 0.5549, Val Loss: 0.6558, Val Acc: 0.6679
Epoch 60/100, Loss: 0.6772, Acc: 0.5577, Val Loss: 0.6568, Val Acc: 0.6649
Epoch 61/100, Loss: 0.6772, Acc: 0.5542, Val Loss: 0.6539, Val Acc: 0.6513
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6769, Acc: 0.5522, Val Loss: 0.6571, Val Acc: 0.6322
Epoch 63/100, Loss: 0.6768, Acc: 0.5605, Val Loss: 0.6574, Val Acc: 0.6285
Epoch 64/100, Loss: 0.6767, Acc: 0.5568, Val Loss: 0.6587, Val Acc: 0.6373
Epoch 65/100, Loss: 0.6766, Acc: 0.5621, Val Loss: 0.6567, Val Acc: 0.6410
Epoch 66/100, Loss: 0.6766, Acc: 0.5625, Val Loss: 0.6589, Val Acc: 0.6351
Epoch 67/100, Loss: 0.6766, Acc: 0.5625, Val Loss: 0.6585, Val Acc: 0.6403
Epoch 68/100, Loss: 0.6765, Acc: 0.5640, Val Loss: 0.6584, Val Acc: 0.6399
Epoch 69/100, Loss: 0.6765, Acc: 0.5616, Val Loss: 0.6583, Val Acc: 0.6377
Epoch 70/100, Loss: 0.6765, Acc: 0.5622, Val Loss: 0.6575, Val Acc: 0.6418
Epoch 71/100, Loss: 0.6764, Acc: 0.5611, Val Loss: 0.6592, Val Acc: 0.6344
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6764, Acc: 0.5627, Val Loss: 0.6586, Val Acc: 0.6362
Epoch 73/100, Loss: 0.6763, Acc: 0.5632, Val Loss: 0.6594, Val Acc: 0.6329
Epoch 74/100, Loss: 0.6763, Acc: 0.5641, Val Loss: 0.6590, Val Acc: 0.6325
Epoch 75/100, Loss: 0.6763, Acc: 0.5626, Val Loss: 0.6578, Val Acc: 0.6418
Epoch 76/100, Loss: 0.6762, Acc: 0.5604, Val Loss: 0.6580, Val Acc: 0.6395
Epoch 77/100, Loss: 0.6762, Acc: 0.5639, Val Loss: 0.6576, Val Acc: 0.6399
Epoch 78/100, Loss: 0.6762, Acc: 0.5635, Val Loss: 0.6574, Val Acc: 0.6406
Epoch 79/100, Loss: 0.6762, Acc: 0.5634, Val Loss: 0.6574, Val Acc: 0.6373
Epoch 80/100, Loss: 0.6762, Acc: 0.5634, Val Loss: 0.6567, Val Acc: 0.6440
Epoch 81/100, Loss: 0.6761, Acc: 0.5621, Val Loss: 0.6575, Val Acc: 0.6370
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6761, Acc: 0.5634, Val Loss: 0.6567, Val Acc: 0.6451
Epoch 83/100, Loss: 0.6761, Acc: 0.5633, Val Loss: 0.6575, Val Acc: 0.6366
Epoch 84/100, Loss: 0.6761, Acc: 0.5628, Val Loss: 0.6578, Val Acc: 0.6362
Epoch 85/100, Loss: 0.6760, Acc: 0.5636, Val Loss: 0.6580, Val Acc: 0.6351
Epoch 86/100, Loss: 0.6760, Acc: 0.5620, Val Loss: 0.6585, Val Acc: 0.6355
Epoch 87/100, Loss: 0.6760, Acc: 0.5638, Val Loss: 0.6592, Val Acc: 0.6325
Epoch 88/100, Loss: 0.6760, Acc: 0.5627, Val Loss: 0.6585, Val Acc: 0.6333
Epoch 89/100, Loss: 0.6760, Acc: 0.5642, Val Loss: 0.6571, Val Acc: 0.6406
Epoch 90/100, Loss: 0.6759, Acc: 0.5623, Val Loss: 0.6580, Val Acc: 0.6348
Epoch 91/100, Loss: 0.6759, Acc: 0.5641, Val Loss: 0.6581, Val Acc: 0.6333
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6759, Acc: 0.5635, Val Loss: 0.6574, Val Acc: 0.6384
Epoch 93/100, Loss: 0.6759, Acc: 0.5640, Val Loss: 0.6575, Val Acc: 0.6355
Epoch 94/100, Loss: 0.6758, Acc: 0.5632, Val Loss: 0.6567, Val Acc: 0.6403
Epoch 95/100, Loss: 0.6758, Acc: 0.5634, Val Loss: 0.6576, Val Acc: 0.6377
Epoch 96/100, Loss: 0.6758, Acc: 0.5647, Val Loss: 0.6579, Val Acc: 0.6314
Epoch 97/100, Loss: 0.6757, Acc: 0.5645, Val Loss: 0.6566, Val Acc: 0.6381
Epoch 98/100, Loss: 0.6757, Acc: 0.5622, Val Loss: 0.6570, Val Acc: 0.6395
Epoch 99/100, Loss: 0.6757, Acc: 0.5627, Val Loss: 0.6565, Val Acc: 0.6406
Epoch 100/100, Loss: 0.6756, Acc: 0.5621, Val Loss: 0.6574, Val Acc: 0.6359

##############################
Resultados para principal:  036  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5 
 {'training': [0.6756257329981482, 0.5620632585509379, 0.5407040038708116, 0.8222958057395143, 0.6524118806100854], 'validate': [0.6573685587838639, 0.635861561119293, 0.6037309214245337, 0.7876106194690266, 0.68352], 'test': [0.6859196115423132, 0.571849234393404, 0.5477883096366508, 0.8178066037735849, 0.6561021759697256]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  024  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  024  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  024  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6313, Acc: 0.6583, Val Loss: 0.7468, Val Acc: 0.4739
Mejor modelo guardado con Val Loss: 0.7468
Epoch 2/100, Loss: 0.5829, Acc: 0.6868, Val Loss: 0.7551, Val Acc: 0.4326
Epoch 3/100, Loss: 0.5809, Acc: 0.6875, Val Loss: 0.7918, Val Acc: 0.4334
Epoch 4/100, Loss: 0.5731, Acc: 0.6966, Val Loss: 0.7738, Val Acc: 0.4411
Epoch 5/100, Loss: 0.5578, Acc: 0.7023, Val Loss: 0.7616, Val Acc: 0.5041
Epoch 6/100, Loss: 0.5519, Acc: 0.7013, Val Loss: 0.7391, Val Acc: 0.5103
Mejor modelo guardado con Val Loss: 0.7391
Epoch 7/100, Loss: 0.5487, Acc: 0.7022, Val Loss: 0.7763, Val Acc: 0.5284
Epoch 8/100, Loss: 0.5462, Acc: 0.7125, Val Loss: 0.7500, Val Acc: 0.5221
Epoch 9/100, Loss: 0.5488, Acc: 0.7104, Val Loss: 0.7715, Val Acc: 0.5409
Epoch 10/100, Loss: 0.5461, Acc: 0.7047, Val Loss: 0.8319, Val Acc: 0.5055
Epoch 11/100, Loss: 0.5438, Acc: 0.7073, Val Loss: 0.7636, Val Acc: 0.5420
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5296, Acc: 0.7195, Val Loss: 0.8046, Val Acc: 0.5129
Epoch 13/100, Loss: 0.5298, Acc: 0.7199, Val Loss: 0.7884, Val Acc: 0.5088
Epoch 14/100, Loss: 0.5289, Acc: 0.7226, Val Loss: 0.7813, Val Acc: 0.5177
Epoch 15/100, Loss: 0.5247, Acc: 0.7259, Val Loss: 0.7337, Val Acc: 0.5361
Mejor modelo guardado con Val Loss: 0.7337
Epoch 16/100, Loss: 0.5241, Acc: 0.7235, Val Loss: 0.7518, Val Acc: 0.5302
Epoch 17/100, Loss: 0.5205, Acc: 0.7266, Val Loss: 0.7582, Val Acc: 0.5284
Epoch 18/100, Loss: 0.5203, Acc: 0.7283, Val Loss: 0.7898, Val Acc: 0.5103
Epoch 19/100, Loss: 0.5187, Acc: 0.7300, Val Loss: 0.7952, Val Acc: 0.5232
Epoch 20/100, Loss: 0.5179, Acc: 0.7273, Val Loss: 0.7716, Val Acc: 0.5306
Epoch 21/100, Loss: 0.5181, Acc: 0.7264, Val Loss: 0.7286, Val Acc: 0.5365
Mejor modelo guardado con Val Loss: 0.7286
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5159, Acc: 0.7357, Val Loss: 0.7924, Val Acc: 0.5387
Epoch 23/100, Loss: 0.5155, Acc: 0.7343, Val Loss: 0.7642, Val Acc: 0.5409
Epoch 24/100, Loss: 0.5137, Acc: 0.7374, Val Loss: 0.7957, Val Acc: 0.5431
Epoch 25/100, Loss: 0.5126, Acc: 0.7354, Val Loss: 0.7850, Val Acc: 0.5295
Epoch 26/100, Loss: 0.5150, Acc: 0.7337, Val Loss: 0.8073, Val Acc: 0.5018
Epoch 27/100, Loss: 0.5139, Acc: 0.7328, Val Loss: 0.8303, Val Acc: 0.4971
Epoch 28/100, Loss: 0.5112, Acc: 0.7380, Val Loss: 0.7898, Val Acc: 0.5574
Epoch 29/100, Loss: 0.5111, Acc: 0.7364, Val Loss: 0.8071, Val Acc: 0.5110
Epoch 30/100, Loss: 0.5100, Acc: 0.7380, Val Loss: 0.7590, Val Acc: 0.5585
Epoch 31/100, Loss: 0.5103, Acc: 0.7382, Val Loss: 0.7659, Val Acc: 0.5497
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5064, Acc: 0.7416, Val Loss: 0.8234, Val Acc: 0.5420
Epoch 33/100, Loss: 0.5057, Acc: 0.7389, Val Loss: 0.7745, Val Acc: 0.5291
Epoch 34/100, Loss: 0.5068, Acc: 0.7401, Val Loss: 0.7969, Val Acc: 0.5361
Epoch 35/100, Loss: 0.5046, Acc: 0.7427, Val Loss: 0.7613, Val Acc: 0.5460
Epoch 36/100, Loss: 0.5051, Acc: 0.7403, Val Loss: 0.7400, Val Acc: 0.5608
Epoch 37/100, Loss: 0.5048, Acc: 0.7403, Val Loss: 0.7691, Val Acc: 0.5475
Epoch 38/100, Loss: 0.5041, Acc: 0.7404, Val Loss: 0.7667, Val Acc: 0.5475
Epoch 39/100, Loss: 0.5034, Acc: 0.7409, Val Loss: 0.7646, Val Acc: 0.5515
Epoch 40/100, Loss: 0.5036, Acc: 0.7426, Val Loss: 0.7885, Val Acc: 0.5729
Epoch 41/100, Loss: 0.5033, Acc: 0.7418, Val Loss: 0.8037, Val Acc: 0.5272
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5021, Acc: 0.7435, Val Loss: 0.7861, Val Acc: 0.5457
Epoch 43/100, Loss: 0.5014, Acc: 0.7447, Val Loss: 0.7825, Val Acc: 0.5493
Epoch 44/100, Loss: 0.5016, Acc: 0.7442, Val Loss: 0.7855, Val Acc: 0.5648
Epoch 45/100, Loss: 0.5010, Acc: 0.7438, Val Loss: 0.7943, Val Acc: 0.5475
Epoch 46/100, Loss: 0.5013, Acc: 0.7456, Val Loss: 0.8078, Val Acc: 0.5512
Epoch 47/100, Loss: 0.5007, Acc: 0.7455, Val Loss: 0.7843, Val Acc: 0.5449
Epoch 48/100, Loss: 0.5004, Acc: 0.7445, Val Loss: 0.7838, Val Acc: 0.5486
Epoch 49/100, Loss: 0.5002, Acc: 0.7436, Val Loss: 0.7907, Val Acc: 0.5556
Epoch 50/100, Loss: 0.4999, Acc: 0.7450, Val Loss: 0.7967, Val Acc: 0.5523
Epoch 51/100, Loss: 0.4996, Acc: 0.7457, Val Loss: 0.7917, Val Acc: 0.5589
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4993, Acc: 0.7452, Val Loss: 0.7828, Val Acc: 0.5508
Epoch 53/100, Loss: 0.4991, Acc: 0.7458, Val Loss: 0.7875, Val Acc: 0.5501
Epoch 54/100, Loss: 0.4987, Acc: 0.7446, Val Loss: 0.7862, Val Acc: 0.5600
Epoch 55/100, Loss: 0.4988, Acc: 0.7461, Val Loss: 0.7958, Val Acc: 0.5501
Epoch 56/100, Loss: 0.4986, Acc: 0.7441, Val Loss: 0.7851, Val Acc: 0.5490
Epoch 57/100, Loss: 0.4986, Acc: 0.7453, Val Loss: 0.7944, Val Acc: 0.5490
Epoch 58/100, Loss: 0.4983, Acc: 0.7453, Val Loss: 0.8061, Val Acc: 0.5508
Epoch 59/100, Loss: 0.4984, Acc: 0.7442, Val Loss: 0.7880, Val Acc: 0.5475
Epoch 60/100, Loss: 0.4983, Acc: 0.7453, Val Loss: 0.7940, Val Acc: 0.5508
Epoch 61/100, Loss: 0.4982, Acc: 0.7457, Val Loss: 0.7914, Val Acc: 0.5519
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4977, Acc: 0.7464, Val Loss: 0.7886, Val Acc: 0.5501
Epoch 63/100, Loss: 0.4979, Acc: 0.7462, Val Loss: 0.7931, Val Acc: 0.5523
Epoch 64/100, Loss: 0.4977, Acc: 0.7465, Val Loss: 0.7916, Val Acc: 0.5490
Epoch 65/100, Loss: 0.4977, Acc: 0.7452, Val Loss: 0.7974, Val Acc: 0.5501
Epoch 66/100, Loss: 0.4976, Acc: 0.7463, Val Loss: 0.7918, Val Acc: 0.5512
Epoch 67/100, Loss: 0.4975, Acc: 0.7471, Val Loss: 0.7992, Val Acc: 0.5563
Epoch 68/100, Loss: 0.4976, Acc: 0.7455, Val Loss: 0.7896, Val Acc: 0.5515
Epoch 69/100, Loss: 0.4975, Acc: 0.7465, Val Loss: 0.7946, Val Acc: 0.5541
Epoch 70/100, Loss: 0.4974, Acc: 0.7459, Val Loss: 0.7948, Val Acc: 0.5534
Epoch 71/100, Loss: 0.4971, Acc: 0.7458, Val Loss: 0.7909, Val Acc: 0.5504
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4972, Acc: 0.7468, Val Loss: 0.7990, Val Acc: 0.5515
Epoch 73/100, Loss: 0.4970, Acc: 0.7460, Val Loss: 0.8010, Val Acc: 0.5508
Epoch 74/100, Loss: 0.4969, Acc: 0.7470, Val Loss: 0.8032, Val Acc: 0.5512
Epoch 75/100, Loss: 0.4970, Acc: 0.7471, Val Loss: 0.8019, Val Acc: 0.5519
Epoch 76/100, Loss: 0.4970, Acc: 0.7464, Val Loss: 0.8010, Val Acc: 0.5515
Epoch 77/100, Loss: 0.4969, Acc: 0.7460, Val Loss: 0.7989, Val Acc: 0.5519
Epoch 78/100, Loss: 0.4968, Acc: 0.7466, Val Loss: 0.8013, Val Acc: 0.5512
Epoch 79/100, Loss: 0.4968, Acc: 0.7462, Val Loss: 0.8018, Val Acc: 0.5512
Epoch 80/100, Loss: 0.4967, Acc: 0.7465, Val Loss: 0.7999, Val Acc: 0.5501
Epoch 81/100, Loss: 0.4967, Acc: 0.7475, Val Loss: 0.8005, Val Acc: 0.5512
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4967, Acc: 0.7465, Val Loss: 0.8007, Val Acc: 0.5519
Epoch 83/100, Loss: 0.4967, Acc: 0.7473, Val Loss: 0.7974, Val Acc: 0.5534
Epoch 84/100, Loss: 0.4967, Acc: 0.7466, Val Loss: 0.7961, Val Acc: 0.5504
Epoch 85/100, Loss: 0.4965, Acc: 0.7461, Val Loss: 0.7982, Val Acc: 0.5512
Epoch 86/100, Loss: 0.4965, Acc: 0.7471, Val Loss: 0.7973, Val Acc: 0.5515
Epoch 87/100, Loss: 0.4966, Acc: 0.7466, Val Loss: 0.8025, Val Acc: 0.5519
Epoch 88/100, Loss: 0.4964, Acc: 0.7479, Val Loss: 0.8023, Val Acc: 0.5508
Epoch 89/100, Loss: 0.4963, Acc: 0.7463, Val Loss: 0.8001, Val Acc: 0.5515
Epoch 90/100, Loss: 0.4962, Acc: 0.7471, Val Loss: 0.7995, Val Acc: 0.5523
Epoch 91/100, Loss: 0.4962, Acc: 0.7470, Val Loss: 0.7982, Val Acc: 0.5508
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4961, Acc: 0.7467, Val Loss: 0.7986, Val Acc: 0.5545
Epoch 93/100, Loss: 0.4961, Acc: 0.7463, Val Loss: 0.7986, Val Acc: 0.5549
Epoch 94/100, Loss: 0.4960, Acc: 0.7460, Val Loss: 0.7958, Val Acc: 0.5512
Epoch 95/100, Loss: 0.4960, Acc: 0.7469, Val Loss: 0.7977, Val Acc: 0.5530
Epoch 96/100, Loss: 0.4960, Acc: 0.7463, Val Loss: 0.7981, Val Acc: 0.5523
Epoch 97/100, Loss: 0.4960, Acc: 0.7462, Val Loss: 0.8014, Val Acc: 0.5530
Epoch 98/100, Loss: 0.4959, Acc: 0.7468, Val Loss: 0.8045, Val Acc: 0.5519
Epoch 99/100, Loss: 0.4958, Acc: 0.7471, Val Loss: 0.7977, Val Acc: 0.5512
Epoch 100/100, Loss: 0.4958, Acc: 0.7464, Val Loss: 0.8014, Val Acc: 0.5523

##############################
Resultados para principal:  024  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5 
 {'training': [0.49581907274706394, 0.7464141228392791, 0.7791909924937448, 0.6874540103016924, 0.730453479280688], 'validate': [0.8014367985170942, 0.5522827687776142, 0.554945054945055, 0.5213864306784661, 0.5376425855513308], 'test': [0.568354508943028, 0.691696113074205, 0.8001850138760407, 0.5100235849056604, 0.6229744328411956]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  100  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  100  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  100  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5758, Acc: 0.7408, Val Loss: 0.8340, Val Acc: 0.4120
Mejor modelo guardado con Val Loss: 0.8340
Epoch 2/100, Loss: 0.5113, Acc: 0.7622, Val Loss: 0.8711, Val Acc: 0.4775
Epoch 3/100, Loss: 0.4965, Acc: 0.7636, Val Loss: 0.8680, Val Acc: 0.4319
Epoch 4/100, Loss: 0.4834, Acc: 0.7734, Val Loss: 0.8648, Val Acc: 0.4311
Epoch 5/100, Loss: 0.4783, Acc: 0.7725, Val Loss: 0.8945, Val Acc: 0.4860
Epoch 6/100, Loss: 0.4773, Acc: 0.7724, Val Loss: 0.8743, Val Acc: 0.4989
Epoch 7/100, Loss: 0.4638, Acc: 0.7762, Val Loss: 0.8329, Val Acc: 0.5136
Mejor modelo guardado con Val Loss: 0.8329
Epoch 8/100, Loss: 0.4640, Acc: 0.7764, Val Loss: 0.8269, Val Acc: 0.4757
Mejor modelo guardado con Val Loss: 0.8269
Epoch 9/100, Loss: 0.4564, Acc: 0.7815, Val Loss: 0.8631, Val Acc: 0.4319
Epoch 10/100, Loss: 0.4664, Acc: 0.7793, Val Loss: 0.8605, Val Acc: 0.5000
Epoch 11/100, Loss: 0.4724, Acc: 0.7783, Val Loss: 0.8436, Val Acc: 0.4878
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4522, Acc: 0.7867, Val Loss: 0.7866, Val Acc: 0.4893
Mejor modelo guardado con Val Loss: 0.7866
Epoch 13/100, Loss: 0.4439, Acc: 0.7853, Val Loss: 0.8389, Val Acc: 0.5133
Epoch 14/100, Loss: 0.4447, Acc: 0.7853, Val Loss: 0.8626, Val Acc: 0.4948
Epoch 15/100, Loss: 0.4403, Acc: 0.7850, Val Loss: 0.9132, Val Acc: 0.5129
Epoch 16/100, Loss: 0.4375, Acc: 0.7868, Val Loss: 0.8296, Val Acc: 0.4680
Epoch 17/100, Loss: 0.4368, Acc: 0.7865, Val Loss: 0.9369, Val Acc: 0.4761
Epoch 18/100, Loss: 0.4381, Acc: 0.7844, Val Loss: 0.8584, Val Acc: 0.4915
Epoch 19/100, Loss: 0.4333, Acc: 0.7897, Val Loss: 0.8832, Val Acc: 0.4720
Epoch 20/100, Loss: 0.4328, Acc: 0.7869, Val Loss: 0.8731, Val Acc: 0.4753
Epoch 21/100, Loss: 0.4300, Acc: 0.7903, Val Loss: 0.8507, Val Acc: 0.4757
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4265, Acc: 0.7910, Val Loss: 0.8719, Val Acc: 0.4816
Epoch 23/100, Loss: 0.4249, Acc: 0.7917, Val Loss: 0.8901, Val Acc: 0.4867
Epoch 24/100, Loss: 0.4241, Acc: 0.7906, Val Loss: 0.9246, Val Acc: 0.4882
Epoch 25/100, Loss: 0.4240, Acc: 0.7917, Val Loss: 0.8651, Val Acc: 0.4930
Epoch 26/100, Loss: 0.4232, Acc: 0.7917, Val Loss: 0.8890, Val Acc: 0.5011
Epoch 27/100, Loss: 0.4239, Acc: 0.7905, Val Loss: 0.8921, Val Acc: 0.4982
Epoch 28/100, Loss: 0.4221, Acc: 0.7909, Val Loss: 0.9159, Val Acc: 0.4934
Epoch 29/100, Loss: 0.4213, Acc: 0.7921, Val Loss: 0.8711, Val Acc: 0.4989
Epoch 30/100, Loss: 0.4217, Acc: 0.7900, Val Loss: 0.8964, Val Acc: 0.4750
Epoch 31/100, Loss: 0.4198, Acc: 0.7921, Val Loss: 0.8888, Val Acc: 0.4812
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4179, Acc: 0.7944, Val Loss: 0.8537, Val Acc: 0.4864
Epoch 33/100, Loss: 0.4177, Acc: 0.7951, Val Loss: 0.8872, Val Acc: 0.4934
Epoch 34/100, Loss: 0.4170, Acc: 0.7943, Val Loss: 0.9113, Val Acc: 0.4923
Epoch 35/100, Loss: 0.4162, Acc: 0.7954, Val Loss: 0.8752, Val Acc: 0.5007
Epoch 36/100, Loss: 0.4171, Acc: 0.7938, Val Loss: 0.8842, Val Acc: 0.5029
Epoch 37/100, Loss: 0.4165, Acc: 0.7934, Val Loss: 0.8996, Val Acc: 0.4761
Epoch 38/100, Loss: 0.4171, Acc: 0.7929, Val Loss: 0.9018, Val Acc: 0.4886
Epoch 39/100, Loss: 0.4153, Acc: 0.7953, Val Loss: 0.9059, Val Acc: 0.4926
Epoch 40/100, Loss: 0.4167, Acc: 0.7939, Val Loss: 0.8906, Val Acc: 0.4867
Epoch 41/100, Loss: 0.4167, Acc: 0.7962, Val Loss: 0.8907, Val Acc: 0.4875
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4143, Acc: 0.7964, Val Loss: 0.8722, Val Acc: 0.4945
Epoch 43/100, Loss: 0.4133, Acc: 0.7962, Val Loss: 0.8648, Val Acc: 0.4919
Epoch 44/100, Loss: 0.4139, Acc: 0.7939, Val Loss: 0.8779, Val Acc: 0.4882
Epoch 45/100, Loss: 0.4133, Acc: 0.7954, Val Loss: 0.8852, Val Acc: 0.4890
Epoch 46/100, Loss: 0.4136, Acc: 0.7959, Val Loss: 0.8771, Val Acc: 0.4875
Epoch 47/100, Loss: 0.4134, Acc: 0.7944, Val Loss: 0.8804, Val Acc: 0.4882
Epoch 48/100, Loss: 0.4129, Acc: 0.7949, Val Loss: 0.8790, Val Acc: 0.4878
Epoch 49/100, Loss: 0.4123, Acc: 0.7967, Val Loss: 0.8976, Val Acc: 0.4871
Epoch 50/100, Loss: 0.4129, Acc: 0.7962, Val Loss: 0.9021, Val Acc: 0.4912
Epoch 51/100, Loss: 0.4135, Acc: 0.7948, Val Loss: 0.8870, Val Acc: 0.4849
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4117, Acc: 0.7968, Val Loss: 0.8797, Val Acc: 0.4904
Epoch 53/100, Loss: 0.4115, Acc: 0.7967, Val Loss: 0.8904, Val Acc: 0.4930
Epoch 54/100, Loss: 0.4115, Acc: 0.7959, Val Loss: 0.8954, Val Acc: 0.4934
Epoch 55/100, Loss: 0.4115, Acc: 0.7974, Val Loss: 0.8811, Val Acc: 0.4908
Epoch 56/100, Loss: 0.4113, Acc: 0.7962, Val Loss: 0.8841, Val Acc: 0.4912
Epoch 57/100, Loss: 0.4111, Acc: 0.7979, Val Loss: 0.8926, Val Acc: 0.4937
Epoch 58/100, Loss: 0.4112, Acc: 0.7962, Val Loss: 0.8846, Val Acc: 0.4915
Epoch 59/100, Loss: 0.4111, Acc: 0.7961, Val Loss: 0.8795, Val Acc: 0.4912
Epoch 60/100, Loss: 0.4106, Acc: 0.7972, Val Loss: 0.8826, Val Acc: 0.4912
Epoch 61/100, Loss: 0.4106, Acc: 0.7969, Val Loss: 0.8771, Val Acc: 0.4908
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4103, Acc: 0.7970, Val Loss: 0.8794, Val Acc: 0.4893
Epoch 63/100, Loss: 0.4102, Acc: 0.7961, Val Loss: 0.8782, Val Acc: 0.4912
Epoch 64/100, Loss: 0.4102, Acc: 0.7972, Val Loss: 0.8782, Val Acc: 0.4915
Epoch 65/100, Loss: 0.4101, Acc: 0.7965, Val Loss: 0.8819, Val Acc: 0.4912
Epoch 66/100, Loss: 0.4100, Acc: 0.7970, Val Loss: 0.8833, Val Acc: 0.4908
Epoch 67/100, Loss: 0.4101, Acc: 0.7971, Val Loss: 0.8875, Val Acc: 0.4893
Epoch 68/100, Loss: 0.4100, Acc: 0.7961, Val Loss: 0.8834, Val Acc: 0.4908
Epoch 69/100, Loss: 0.4099, Acc: 0.7962, Val Loss: 0.8846, Val Acc: 0.4890
Epoch 70/100, Loss: 0.4098, Acc: 0.7974, Val Loss: 0.8691, Val Acc: 0.4886
Epoch 71/100, Loss: 0.4099, Acc: 0.7970, Val Loss: 0.8768, Val Acc: 0.4908
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4097, Acc: 0.7967, Val Loss: 0.8759, Val Acc: 0.4893
Epoch 73/100, Loss: 0.4097, Acc: 0.7962, Val Loss: 0.8829, Val Acc: 0.4890
Epoch 74/100, Loss: 0.4098, Acc: 0.7981, Val Loss: 0.8828, Val Acc: 0.4897
Epoch 75/100, Loss: 0.4097, Acc: 0.7968, Val Loss: 0.8813, Val Acc: 0.4915
Epoch 76/100, Loss: 0.4097, Acc: 0.7968, Val Loss: 0.8792, Val Acc: 0.4912
Epoch 77/100, Loss: 0.4096, Acc: 0.7973, Val Loss: 0.8810, Val Acc: 0.4901
Epoch 78/100, Loss: 0.4096, Acc: 0.7968, Val Loss: 0.8815, Val Acc: 0.4901
Epoch 79/100, Loss: 0.4095, Acc: 0.7973, Val Loss: 0.8823, Val Acc: 0.4908
Epoch 80/100, Loss: 0.4096, Acc: 0.7963, Val Loss: 0.8799, Val Acc: 0.4901
Epoch 81/100, Loss: 0.4094, Acc: 0.7974, Val Loss: 0.8768, Val Acc: 0.4904
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4093, Acc: 0.7972, Val Loss: 0.8830, Val Acc: 0.4915
Epoch 83/100, Loss: 0.4095, Acc: 0.7967, Val Loss: 0.8794, Val Acc: 0.4908
Epoch 84/100, Loss: 0.4093, Acc: 0.7967, Val Loss: 0.8781, Val Acc: 0.4908
Epoch 85/100, Loss: 0.4093, Acc: 0.7968, Val Loss: 0.8786, Val Acc: 0.4919
Epoch 86/100, Loss: 0.4092, Acc: 0.7970, Val Loss: 0.8743, Val Acc: 0.4915
Epoch 87/100, Loss: 0.4092, Acc: 0.7973, Val Loss: 0.8759, Val Acc: 0.4908
Epoch 88/100, Loss: 0.4092, Acc: 0.7973, Val Loss: 0.8804, Val Acc: 0.4904
Epoch 89/100, Loss: 0.4090, Acc: 0.7978, Val Loss: 0.8783, Val Acc: 0.4878
Epoch 90/100, Loss: 0.4091, Acc: 0.7963, Val Loss: 0.8782, Val Acc: 0.4904
Epoch 91/100, Loss: 0.4092, Acc: 0.7965, Val Loss: 0.8769, Val Acc: 0.4904
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4092, Acc: 0.7966, Val Loss: 0.8839, Val Acc: 0.4915
Epoch 93/100, Loss: 0.4090, Acc: 0.7965, Val Loss: 0.8774, Val Acc: 0.4919
Epoch 94/100, Loss: 0.4090, Acc: 0.7971, Val Loss: 0.8775, Val Acc: 0.4912
Epoch 95/100, Loss: 0.4089, Acc: 0.7980, Val Loss: 0.8770, Val Acc: 0.4912
Epoch 96/100, Loss: 0.4089, Acc: 0.7970, Val Loss: 0.8775, Val Acc: 0.4915
Epoch 97/100, Loss: 0.4089, Acc: 0.7972, Val Loss: 0.8778, Val Acc: 0.4919
Epoch 98/100, Loss: 0.4089, Acc: 0.7967, Val Loss: 0.8824, Val Acc: 0.4915
Epoch 99/100, Loss: 0.4089, Acc: 0.7970, Val Loss: 0.8768, Val Acc: 0.4904
Epoch 100/100, Loss: 0.4089, Acc: 0.7973, Val Loss: 0.8798, Val Acc: 0.4915

##############################
Resultados para principal:  100  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5 
 {'training': [0.40885581043810915, 0.7972600220669364, 0.8624635404980929, 0.7071376011773363, 0.7771151319114525], 'validate': [0.8798153424678847, 0.49153166421207656, 0.4631268436578171, 0.11578171091445427, 0.18525073746312684], 'test': [0.5035747191696255, 0.7700235571260307, 0.7571669477234402, 0.7942216981132075, 0.7752517985611511]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  090  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  090  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  090  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6920, Acc: 0.5225, Val Loss: 0.6891, Val Acc: 0.5740
Mejor modelo guardado con Val Loss: 0.6891
Epoch 2/100, Loss: 0.6899, Acc: 0.5424, Val Loss: 0.6904, Val Acc: 0.5007
Epoch 3/100, Loss: 0.6918, Acc: 0.5250, Val Loss: 0.6862, Val Acc: 0.6966
Mejor modelo guardado con Val Loss: 0.6862
Epoch 4/100, Loss: 0.6903, Acc: 0.5499, Val Loss: 0.6864, Val Acc: 0.5007
Epoch 5/100, Loss: 0.6895, Acc: 0.5446, Val Loss: 0.6843, Val Acc: 0.7080
Mejor modelo guardado con Val Loss: 0.6843
Epoch 6/100, Loss: 0.6887, Acc: 0.5666, Val Loss: 0.6841, Val Acc: 0.6443
Mejor modelo guardado con Val Loss: 0.6841
Epoch 7/100, Loss: 0.6880, Acc: 0.5800, Val Loss: 0.6850, Val Acc: 0.6811
Epoch 8/100, Loss: 0.6868, Acc: 0.6067, Val Loss: 0.6782, Val Acc: 0.6683
Mejor modelo guardado con Val Loss: 0.6782
Epoch 9/100, Loss: 0.6865, Acc: 0.5808, Val Loss: 0.6792, Val Acc: 0.6631
Epoch 10/100, Loss: 0.6857, Acc: 0.5827, Val Loss: 0.6837, Val Acc: 0.6311
Epoch 11/100, Loss: 0.6850, Acc: 0.5935, Val Loss: 0.6748, Val Acc: 0.7194
Mejor modelo guardado con Val Loss: 0.6748
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6839, Acc: 0.6106, Val Loss: 0.6737, Val Acc: 0.7275
Mejor modelo guardado con Val Loss: 0.6737
Epoch 13/100, Loss: 0.6831, Acc: 0.5955, Val Loss: 0.6726, Val Acc: 0.7415
Mejor modelo guardado con Val Loss: 0.6726
Epoch 14/100, Loss: 0.6825, Acc: 0.5891, Val Loss: 0.6777, Val Acc: 0.6767
Epoch 15/100, Loss: 0.6826, Acc: 0.6077, Val Loss: 0.6733, Val Acc: 0.7437
Epoch 16/100, Loss: 0.6819, Acc: 0.5908, Val Loss: 0.6782, Val Acc: 0.6480
Epoch 17/100, Loss: 0.6814, Acc: 0.6157, Val Loss: 0.6710, Val Acc: 0.7183
Mejor modelo guardado con Val Loss: 0.6710
Epoch 18/100, Loss: 0.6810, Acc: 0.6158, Val Loss: 0.6690, Val Acc: 0.7242
Mejor modelo guardado con Val Loss: 0.6690
Epoch 19/100, Loss: 0.6805, Acc: 0.6192, Val Loss: 0.6679, Val Acc: 0.7250
Mejor modelo guardado con Val Loss: 0.6679
Epoch 20/100, Loss: 0.6805, Acc: 0.6152, Val Loss: 0.6702, Val Acc: 0.7054
Epoch 21/100, Loss: 0.6798, Acc: 0.6180, Val Loss: 0.6721, Val Acc: 0.6852
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6795, Acc: 0.6168, Val Loss: 0.6661, Val Acc: 0.7301
Mejor modelo guardado con Val Loss: 0.6661
Epoch 23/100, Loss: 0.6789, Acc: 0.6219, Val Loss: 0.6683, Val Acc: 0.7205
Epoch 24/100, Loss: 0.6789, Acc: 0.6205, Val Loss: 0.6679, Val Acc: 0.7169
Epoch 25/100, Loss: 0.6785, Acc: 0.6207, Val Loss: 0.6666, Val Acc: 0.7213
Epoch 26/100, Loss: 0.6782, Acc: 0.6217, Val Loss: 0.6645, Val Acc: 0.7242
Mejor modelo guardado con Val Loss: 0.6645
Epoch 27/100, Loss: 0.6781, Acc: 0.6220, Val Loss: 0.6639, Val Acc: 0.7246
Mejor modelo guardado con Val Loss: 0.6639
Epoch 28/100, Loss: 0.6778, Acc: 0.6234, Val Loss: 0.6651, Val Acc: 0.7180
Epoch 29/100, Loss: 0.6777, Acc: 0.6225, Val Loss: 0.6695, Val Acc: 0.6889
Epoch 30/100, Loss: 0.6777, Acc: 0.6199, Val Loss: 0.6633, Val Acc: 0.7235
Mejor modelo guardado con Val Loss: 0.6633
Epoch 31/100, Loss: 0.6773, Acc: 0.6209, Val Loss: 0.6671, Val Acc: 0.7102
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6771, Acc: 0.6220, Val Loss: 0.6645, Val Acc: 0.7139
Epoch 33/100, Loss: 0.6768, Acc: 0.6238, Val Loss: 0.6640, Val Acc: 0.7158
Epoch 34/100, Loss: 0.6768, Acc: 0.6231, Val Loss: 0.6629, Val Acc: 0.7224
Mejor modelo guardado con Val Loss: 0.6629
Epoch 35/100, Loss: 0.6765, Acc: 0.6227, Val Loss: 0.6610, Val Acc: 0.7242
Mejor modelo guardado con Val Loss: 0.6610
Epoch 36/100, Loss: 0.6765, Acc: 0.6227, Val Loss: 0.6636, Val Acc: 0.7117
Epoch 37/100, Loss: 0.6763, Acc: 0.6230, Val Loss: 0.6657, Val Acc: 0.7025
Epoch 38/100, Loss: 0.6760, Acc: 0.6240, Val Loss: 0.6657, Val Acc: 0.7021
Epoch 39/100, Loss: 0.6759, Acc: 0.6239, Val Loss: 0.6637, Val Acc: 0.7110
Epoch 40/100, Loss: 0.6758, Acc: 0.6231, Val Loss: 0.6618, Val Acc: 0.7209
Epoch 41/100, Loss: 0.6758, Acc: 0.6227, Val Loss: 0.6605, Val Acc: 0.7250
Mejor modelo guardado con Val Loss: 0.6605
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6756, Acc: 0.6230, Val Loss: 0.6632, Val Acc: 0.7113
Epoch 43/100, Loss: 0.6754, Acc: 0.6250, Val Loss: 0.6628, Val Acc: 0.7128
Epoch 44/100, Loss: 0.6754, Acc: 0.6244, Val Loss: 0.6623, Val Acc: 0.7139
Epoch 45/100, Loss: 0.6753, Acc: 0.6245, Val Loss: 0.6619, Val Acc: 0.7135
Epoch 46/100, Loss: 0.6753, Acc: 0.6227, Val Loss: 0.6599, Val Acc: 0.7224
Mejor modelo guardado con Val Loss: 0.6599
Epoch 47/100, Loss: 0.6751, Acc: 0.6227, Val Loss: 0.6593, Val Acc: 0.7220
Mejor modelo guardado con Val Loss: 0.6593
Epoch 48/100, Loss: 0.6749, Acc: 0.6237, Val Loss: 0.6567, Val Acc: 0.7360
Mejor modelo guardado con Val Loss: 0.6567
Epoch 49/100, Loss: 0.6748, Acc: 0.6231, Val Loss: 0.6597, Val Acc: 0.7169
Epoch 50/100, Loss: 0.6746, Acc: 0.6228, Val Loss: 0.6548, Val Acc: 0.7397
Mejor modelo guardado con Val Loss: 0.6548
Epoch 51/100, Loss: 0.6744, Acc: 0.6231, Val Loss: 0.6586, Val Acc: 0.7121
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6742, Acc: 0.6232, Val Loss: 0.6563, Val Acc: 0.7216
Epoch 53/100, Loss: 0.6741, Acc: 0.6229, Val Loss: 0.6559, Val Acc: 0.7231
Epoch 54/100, Loss: 0.6740, Acc: 0.6225, Val Loss: 0.6576, Val Acc: 0.7161
Epoch 55/100, Loss: 0.6739, Acc: 0.6233, Val Loss: 0.6577, Val Acc: 0.7154
Epoch 56/100, Loss: 0.6738, Acc: 0.6233, Val Loss: 0.6554, Val Acc: 0.7220
Epoch 57/100, Loss: 0.6737, Acc: 0.6227, Val Loss: 0.6557, Val Acc: 0.7213
Epoch 58/100, Loss: 0.6736, Acc: 0.6229, Val Loss: 0.6552, Val Acc: 0.7216
Epoch 59/100, Loss: 0.6735, Acc: 0.6239, Val Loss: 0.6553, Val Acc: 0.7209
Epoch 60/100, Loss: 0.6735, Acc: 0.6230, Val Loss: 0.6550, Val Acc: 0.7220
Epoch 61/100, Loss: 0.6734, Acc: 0.6226, Val Loss: 0.6562, Val Acc: 0.7158
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6733, Acc: 0.6226, Val Loss: 0.6546, Val Acc: 0.7231
Mejor modelo guardado con Val Loss: 0.6546
Epoch 63/100, Loss: 0.6732, Acc: 0.6228, Val Loss: 0.6561, Val Acc: 0.7158
Epoch 64/100, Loss: 0.6732, Acc: 0.6232, Val Loss: 0.6552, Val Acc: 0.7198
Epoch 65/100, Loss: 0.6719, Acc: 0.6233, Val Loss: 0.6580, Val Acc: 0.7080
Epoch 66/100, Loss: 0.6715, Acc: 0.6221, Val Loss: 0.6578, Val Acc: 0.7121
Epoch 67/100, Loss: 0.6713, Acc: 0.6235, Val Loss: 0.6577, Val Acc: 0.7121
Epoch 68/100, Loss: 0.6713, Acc: 0.6234, Val Loss: 0.6581, Val Acc: 0.7106
Epoch 69/100, Loss: 0.6711, Acc: 0.6251, Val Loss: 0.6579, Val Acc: 0.7135
Epoch 70/100, Loss: 0.6710, Acc: 0.6249, Val Loss: 0.6578, Val Acc: 0.7113
Epoch 71/100, Loss: 0.6709, Acc: 0.6254, Val Loss: 0.6577, Val Acc: 0.7121
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6708, Acc: 0.6259, Val Loss: 0.6571, Val Acc: 0.7124
Epoch 73/100, Loss: 0.6707, Acc: 0.6236, Val Loss: 0.6570, Val Acc: 0.7147
Epoch 74/100, Loss: 0.6706, Acc: 0.6229, Val Loss: 0.6576, Val Acc: 0.7132
Epoch 75/100, Loss: 0.6706, Acc: 0.6259, Val Loss: 0.6570, Val Acc: 0.7172
Epoch 76/100, Loss: 0.6705, Acc: 0.6243, Val Loss: 0.6568, Val Acc: 0.7124
Epoch 77/100, Loss: 0.6705, Acc: 0.6256, Val Loss: 0.6566, Val Acc: 0.7132
Epoch 78/100, Loss: 0.6704, Acc: 0.6238, Val Loss: 0.6567, Val Acc: 0.7143
Epoch 79/100, Loss: 0.6704, Acc: 0.6244, Val Loss: 0.6567, Val Acc: 0.7154
Epoch 80/100, Loss: 0.6703, Acc: 0.6245, Val Loss: 0.6568, Val Acc: 0.7161
Epoch 81/100, Loss: 0.6702, Acc: 0.6248, Val Loss: 0.6563, Val Acc: 0.7147
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6702, Acc: 0.6233, Val Loss: 0.6567, Val Acc: 0.7135
Epoch 83/100, Loss: 0.6701, Acc: 0.6261, Val Loss: 0.6562, Val Acc: 0.7147
Epoch 84/100, Loss: 0.6701, Acc: 0.6249, Val Loss: 0.6562, Val Acc: 0.7150
Epoch 85/100, Loss: 0.6701, Acc: 0.6250, Val Loss: 0.6562, Val Acc: 0.7150
Epoch 86/100, Loss: 0.6700, Acc: 0.6252, Val Loss: 0.6563, Val Acc: 0.7135
Epoch 87/100, Loss: 0.6700, Acc: 0.6235, Val Loss: 0.6562, Val Acc: 0.7143
Epoch 88/100, Loss: 0.6699, Acc: 0.6255, Val Loss: 0.6559, Val Acc: 0.7143
Epoch 89/100, Loss: 0.6698, Acc: 0.6261, Val Loss: 0.6554, Val Acc: 0.7143
Epoch 90/100, Loss: 0.6698, Acc: 0.6250, Val Loss: 0.6558, Val Acc: 0.7161
Epoch 91/100, Loss: 0.6697, Acc: 0.6251, Val Loss: 0.6558, Val Acc: 0.7135
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6697, Acc: 0.6261, Val Loss: 0.6555, Val Acc: 0.7158
Epoch 93/100, Loss: 0.6697, Acc: 0.6259, Val Loss: 0.6549, Val Acc: 0.7172
Epoch 94/100, Loss: 0.6696, Acc: 0.6244, Val Loss: 0.6553, Val Acc: 0.7147
Epoch 95/100, Loss: 0.6696, Acc: 0.6256, Val Loss: 0.6554, Val Acc: 0.7147
Epoch 96/100, Loss: 0.6695, Acc: 0.6252, Val Loss: 0.6555, Val Acc: 0.7128
Epoch 97/100, Loss: 0.6694, Acc: 0.6249, Val Loss: 0.6554, Val Acc: 0.7150
Epoch 98/100, Loss: 0.6687, Acc: 0.6318, Val Loss: 0.6570, Val Acc: 0.6996
Epoch 99/100, Loss: 0.6672, Acc: 0.6482, Val Loss: 0.6576, Val Acc: 0.7003
Epoch 100/100, Loss: 0.6671, Acc: 0.6469, Val Loss: 0.6576, Val Acc: 0.6988

##############################
Resultados para principal:  090  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5 
 {'training': [0.6671217756921993, 0.6469290180213314, 0.6197119711971197, 0.7599337748344371, 0.6826970748636589], 'validate': [0.6576429078745287, 0.698821796759941, 0.6632281553398058, 0.806047197640118, 0.7276964047936085], 'test': [0.671517343432815, 0.639281507656066, 0.5948449456302859, 0.870872641509434, 0.7068676716917923]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  091  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  091  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  091  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6430, Acc: 0.6749, Val Loss: 0.6721, Val Acc: 0.5803
Mejor modelo guardado con Val Loss: 0.6721
Epoch 2/100, Loss: 0.5816, Acc: 0.7273, Val Loss: 0.6584, Val Acc: 0.6079
Mejor modelo guardado con Val Loss: 0.6584
Epoch 3/100, Loss: 0.5558, Acc: 0.7368, Val Loss: 0.6801, Val Acc: 0.5928
Epoch 4/100, Loss: 0.5443, Acc: 0.7431, Val Loss: 0.6625, Val Acc: 0.6060
Epoch 5/100, Loss: 0.5391, Acc: 0.7460, Val Loss: 0.6678, Val Acc: 0.6094
Epoch 6/100, Loss: 0.5360, Acc: 0.7503, Val Loss: 0.6634, Val Acc: 0.6134
Epoch 7/100, Loss: 0.5330, Acc: 0.7558, Val Loss: 0.6691, Val Acc: 0.6167
Epoch 8/100, Loss: 0.5335, Acc: 0.7516, Val Loss: 0.6542, Val Acc: 0.6230
Mejor modelo guardado con Val Loss: 0.6542
Epoch 9/100, Loss: 0.5318, Acc: 0.7529, Val Loss: 0.6747, Val Acc: 0.6149
Epoch 10/100, Loss: 0.5242, Acc: 0.7590, Val Loss: 0.6627, Val Acc: 0.6211
Epoch 11/100, Loss: 0.5270, Acc: 0.7545, Val Loss: 0.6663, Val Acc: 0.6097
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5173, Acc: 0.7631, Val Loss: 0.6718, Val Acc: 0.6366
Epoch 13/100, Loss: 0.5126, Acc: 0.7666, Val Loss: 0.6503, Val Acc: 0.6366
Mejor modelo guardado con Val Loss: 0.6503
Epoch 14/100, Loss: 0.5136, Acc: 0.7669, Val Loss: 0.6547, Val Acc: 0.6322
Epoch 15/100, Loss: 0.5131, Acc: 0.7659, Val Loss: 0.6686, Val Acc: 0.6311
Epoch 16/100, Loss: 0.5067, Acc: 0.7685, Val Loss: 0.6660, Val Acc: 0.6399
Epoch 17/100, Loss: 0.5099, Acc: 0.7687, Val Loss: 0.6844, Val Acc: 0.6314
Epoch 18/100, Loss: 0.5074, Acc: 0.7699, Val Loss: 0.6636, Val Acc: 0.6381
Epoch 19/100, Loss: 0.5084, Acc: 0.7685, Val Loss: 0.6626, Val Acc: 0.6296
Epoch 20/100, Loss: 0.5067, Acc: 0.7685, Val Loss: 0.6495, Val Acc: 0.6348
Mejor modelo guardado con Val Loss: 0.6495
Epoch 21/100, Loss: 0.5062, Acc: 0.7686, Val Loss: 0.6412, Val Acc: 0.6513
Mejor modelo guardado con Val Loss: 0.6412
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5008, Acc: 0.7750, Val Loss: 0.6370, Val Acc: 0.6469
Mejor modelo guardado con Val Loss: 0.6370
Epoch 23/100, Loss: 0.4977, Acc: 0.7757, Val Loss: 0.6522, Val Acc: 0.6373
Epoch 24/100, Loss: 0.4988, Acc: 0.7745, Val Loss: 0.6672, Val Acc: 0.6414
Epoch 25/100, Loss: 0.4972, Acc: 0.7770, Val Loss: 0.6541, Val Acc: 0.6447
Epoch 26/100, Loss: 0.4977, Acc: 0.7786, Val Loss: 0.6439, Val Acc: 0.6495
Epoch 27/100, Loss: 0.4961, Acc: 0.7763, Val Loss: 0.6813, Val Acc: 0.6348
Epoch 28/100, Loss: 0.4967, Acc: 0.7754, Val Loss: 0.6614, Val Acc: 0.6436
Epoch 29/100, Loss: 0.4956, Acc: 0.7774, Val Loss: 0.6496, Val Acc: 0.6425
Epoch 30/100, Loss: 0.4947, Acc: 0.7766, Val Loss: 0.6446, Val Acc: 0.6414
Epoch 31/100, Loss: 0.4935, Acc: 0.7768, Val Loss: 0.6547, Val Acc: 0.6381
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4932, Acc: 0.7785, Val Loss: 0.6438, Val Acc: 0.6395
Epoch 33/100, Loss: 0.4921, Acc: 0.7802, Val Loss: 0.6504, Val Acc: 0.6473
Epoch 34/100, Loss: 0.4910, Acc: 0.7803, Val Loss: 0.6530, Val Acc: 0.6484
Epoch 35/100, Loss: 0.4922, Acc: 0.7774, Val Loss: 0.6400, Val Acc: 0.6440
Epoch 36/100, Loss: 0.4901, Acc: 0.7815, Val Loss: 0.6475, Val Acc: 0.6443
Epoch 37/100, Loss: 0.4906, Acc: 0.7789, Val Loss: 0.6436, Val Acc: 0.6414
Epoch 38/100, Loss: 0.4912, Acc: 0.7773, Val Loss: 0.6558, Val Acc: 0.6454
Epoch 39/100, Loss: 0.4899, Acc: 0.7811, Val Loss: 0.6432, Val Acc: 0.6480
Epoch 40/100, Loss: 0.4894, Acc: 0.7819, Val Loss: 0.6460, Val Acc: 0.6395
Epoch 41/100, Loss: 0.4884, Acc: 0.7810, Val Loss: 0.6444, Val Acc: 0.6454
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4879, Acc: 0.7806, Val Loss: 0.6508, Val Acc: 0.6447
Epoch 43/100, Loss: 0.4862, Acc: 0.7818, Val Loss: 0.6494, Val Acc: 0.6403
Epoch 44/100, Loss: 0.4863, Acc: 0.7826, Val Loss: 0.6584, Val Acc: 0.6436
Epoch 45/100, Loss: 0.4862, Acc: 0.7835, Val Loss: 0.6431, Val Acc: 0.6432
Epoch 46/100, Loss: 0.4855, Acc: 0.7825, Val Loss: 0.6488, Val Acc: 0.6421
Epoch 47/100, Loss: 0.4858, Acc: 0.7830, Val Loss: 0.6416, Val Acc: 0.6436
Epoch 48/100, Loss: 0.4861, Acc: 0.7827, Val Loss: 0.6472, Val Acc: 0.6414
Epoch 49/100, Loss: 0.4852, Acc: 0.7837, Val Loss: 0.6492, Val Acc: 0.6418
Epoch 50/100, Loss: 0.4855, Acc: 0.7825, Val Loss: 0.6464, Val Acc: 0.6447
Epoch 51/100, Loss: 0.4844, Acc: 0.7833, Val Loss: 0.6515, Val Acc: 0.6454
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4841, Acc: 0.7847, Val Loss: 0.6472, Val Acc: 0.6414
Epoch 53/100, Loss: 0.4839, Acc: 0.7834, Val Loss: 0.6449, Val Acc: 0.6421
Epoch 54/100, Loss: 0.4837, Acc: 0.7825, Val Loss: 0.6477, Val Acc: 0.6425
Epoch 55/100, Loss: 0.4836, Acc: 0.7829, Val Loss: 0.6475, Val Acc: 0.6410
Epoch 56/100, Loss: 0.4835, Acc: 0.7836, Val Loss: 0.6481, Val Acc: 0.6451
Epoch 57/100, Loss: 0.4834, Acc: 0.7846, Val Loss: 0.6453, Val Acc: 0.6432
Epoch 58/100, Loss: 0.4836, Acc: 0.7830, Val Loss: 0.6467, Val Acc: 0.6436
Epoch 59/100, Loss: 0.4834, Acc: 0.7836, Val Loss: 0.6464, Val Acc: 0.6465
Epoch 60/100, Loss: 0.4829, Acc: 0.7837, Val Loss: 0.6452, Val Acc: 0.6410
Epoch 61/100, Loss: 0.4830, Acc: 0.7835, Val Loss: 0.6487, Val Acc: 0.6465
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4825, Acc: 0.7846, Val Loss: 0.6470, Val Acc: 0.6443
Epoch 63/100, Loss: 0.4824, Acc: 0.7837, Val Loss: 0.6501, Val Acc: 0.6447
Epoch 64/100, Loss: 0.4826, Acc: 0.7832, Val Loss: 0.6476, Val Acc: 0.6440
Epoch 65/100, Loss: 0.4826, Acc: 0.7843, Val Loss: 0.6467, Val Acc: 0.6447
Epoch 66/100, Loss: 0.4823, Acc: 0.7848, Val Loss: 0.6451, Val Acc: 0.6425
Epoch 67/100, Loss: 0.4825, Acc: 0.7843, Val Loss: 0.6460, Val Acc: 0.6425
Epoch 68/100, Loss: 0.4822, Acc: 0.7848, Val Loss: 0.6469, Val Acc: 0.6443
Epoch 69/100, Loss: 0.4822, Acc: 0.7847, Val Loss: 0.6475, Val Acc: 0.6432
Epoch 70/100, Loss: 0.4821, Acc: 0.7842, Val Loss: 0.6468, Val Acc: 0.6410
Epoch 71/100, Loss: 0.4822, Acc: 0.7837, Val Loss: 0.6471, Val Acc: 0.6425
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4820, Acc: 0.7840, Val Loss: 0.6479, Val Acc: 0.6440
Epoch 73/100, Loss: 0.4820, Acc: 0.7845, Val Loss: 0.6464, Val Acc: 0.6432
Epoch 74/100, Loss: 0.4818, Acc: 0.7834, Val Loss: 0.6470, Val Acc: 0.6440
Epoch 75/100, Loss: 0.4817, Acc: 0.7837, Val Loss: 0.6472, Val Acc: 0.6436
Epoch 76/100, Loss: 0.4818, Acc: 0.7837, Val Loss: 0.6476, Val Acc: 0.6447
Epoch 77/100, Loss: 0.4817, Acc: 0.7844, Val Loss: 0.6468, Val Acc: 0.6436
Epoch 78/100, Loss: 0.4817, Acc: 0.7842, Val Loss: 0.6465, Val Acc: 0.6406
Epoch 79/100, Loss: 0.4817, Acc: 0.7846, Val Loss: 0.6471, Val Acc: 0.6447
Epoch 80/100, Loss: 0.4816, Acc: 0.7848, Val Loss: 0.6470, Val Acc: 0.6454
Epoch 81/100, Loss: 0.4815, Acc: 0.7842, Val Loss: 0.6476, Val Acc: 0.6443
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4815, Acc: 0.7835, Val Loss: 0.6481, Val Acc: 0.6432
Epoch 83/100, Loss: 0.4814, Acc: 0.7844, Val Loss: 0.6465, Val Acc: 0.6410
Epoch 84/100, Loss: 0.4815, Acc: 0.7837, Val Loss: 0.6470, Val Acc: 0.6443
Epoch 85/100, Loss: 0.4814, Acc: 0.7837, Val Loss: 0.6475, Val Acc: 0.6451
Epoch 86/100, Loss: 0.4814, Acc: 0.7848, Val Loss: 0.6463, Val Acc: 0.6443
Epoch 87/100, Loss: 0.4814, Acc: 0.7855, Val Loss: 0.6463, Val Acc: 0.6440
Epoch 88/100, Loss: 0.4813, Acc: 0.7841, Val Loss: 0.6472, Val Acc: 0.6443
Epoch 89/100, Loss: 0.4815, Acc: 0.7841, Val Loss: 0.6465, Val Acc: 0.6443
Epoch 90/100, Loss: 0.4812, Acc: 0.7849, Val Loss: 0.6457, Val Acc: 0.6414
Epoch 91/100, Loss: 0.4812, Acc: 0.7848, Val Loss: 0.6464, Val Acc: 0.6440
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4811, Acc: 0.7838, Val Loss: 0.6460, Val Acc: 0.6418
Epoch 93/100, Loss: 0.4811, Acc: 0.7844, Val Loss: 0.6465, Val Acc: 0.6443
Epoch 94/100, Loss: 0.4812, Acc: 0.7839, Val Loss: 0.6462, Val Acc: 0.6421
Epoch 95/100, Loss: 0.4811, Acc: 0.7836, Val Loss: 0.6468, Val Acc: 0.6429
Epoch 96/100, Loss: 0.4810, Acc: 0.7844, Val Loss: 0.6468, Val Acc: 0.6447
Epoch 97/100, Loss: 0.4810, Acc: 0.7838, Val Loss: 0.6469, Val Acc: 0.6432
Epoch 98/100, Loss: 0.4809, Acc: 0.7835, Val Loss: 0.6467, Val Acc: 0.6451
Epoch 99/100, Loss: 0.4810, Acc: 0.7856, Val Loss: 0.6475, Val Acc: 0.6425
Epoch 100/100, Loss: 0.4809, Acc: 0.7853, Val Loss: 0.6470, Val Acc: 0.6432

##############################
Resultados para principal:  091  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5 
 {'training': [0.48087000309785266, 0.7853070981978668, 0.7919412540011297, 0.7737306843267108, 0.7827300642039638], 'validate': [0.6469691489325013, 0.6432253313696613, 0.6399132321041214, 0.6526548672566371, 0.6462212486308871], 'test': [0.9463106860165242, 0.4502355712603062, 0.46645743428795605, 0.7010613207547169, 0.560188457008245]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  019  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  019  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  019  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6388, Acc: 0.6873, Val Loss: 0.6182, Val Acc: 0.7135
Mejor modelo guardado con Val Loss: 0.6182
Epoch 2/100, Loss: 0.5853, Acc: 0.7226, Val Loss: 0.5762, Val Acc: 0.7165
Mejor modelo guardado con Val Loss: 0.5762
Epoch 3/100, Loss: 0.5577, Acc: 0.7300, Val Loss: 0.5777, Val Acc: 0.7183
Epoch 4/100, Loss: 0.5550, Acc: 0.7255, Val Loss: 0.5633, Val Acc: 0.7257
Mejor modelo guardado con Val Loss: 0.5633
Epoch 5/100, Loss: 0.5497, Acc: 0.7282, Val Loss: 0.5810, Val Acc: 0.7305
Epoch 6/100, Loss: 0.5498, Acc: 0.7282, Val Loss: 0.5836, Val Acc: 0.6874
Epoch 7/100, Loss: 0.5408, Acc: 0.7362, Val Loss: 0.5578, Val Acc: 0.7176
Mejor modelo guardado con Val Loss: 0.5578
Epoch 8/100, Loss: 0.5360, Acc: 0.7402, Val Loss: 0.5459, Val Acc: 0.7371
Mejor modelo guardado con Val Loss: 0.5459
Epoch 9/100, Loss: 0.5301, Acc: 0.7418, Val Loss: 0.5571, Val Acc: 0.7305
Epoch 10/100, Loss: 0.5365, Acc: 0.7380, Val Loss: 0.5591, Val Acc: 0.7305
Epoch 11/100, Loss: 0.5268, Acc: 0.7467, Val Loss: 0.5945, Val Acc: 0.6918
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5166, Acc: 0.7527, Val Loss: 0.5763, Val Acc: 0.7235
Epoch 13/100, Loss: 0.5206, Acc: 0.7513, Val Loss: 0.5972, Val Acc: 0.7032
Epoch 14/100, Loss: 0.5174, Acc: 0.7537, Val Loss: 0.5648, Val Acc: 0.7294
Epoch 15/100, Loss: 0.5156, Acc: 0.7555, Val Loss: 0.5757, Val Acc: 0.7091
Epoch 16/100, Loss: 0.5194, Acc: 0.7466, Val Loss: 0.5631, Val Acc: 0.7275
Epoch 17/100, Loss: 0.5105, Acc: 0.7569, Val Loss: 0.5592, Val Acc: 0.7309
Epoch 18/100, Loss: 0.5119, Acc: 0.7577, Val Loss: 0.5478, Val Acc: 0.7437
Epoch 19/100, Loss: 0.5141, Acc: 0.7558, Val Loss: 0.5400, Val Acc: 0.7489
Mejor modelo guardado con Val Loss: 0.5400
Epoch 20/100, Loss: 0.5101, Acc: 0.7538, Val Loss: 0.5649, Val Acc: 0.7220
Epoch 21/100, Loss: 0.5129, Acc: 0.7563, Val Loss: 0.5405, Val Acc: 0.7459
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5049, Acc: 0.7619, Val Loss: 0.5495, Val Acc: 0.7404
Epoch 23/100, Loss: 0.5028, Acc: 0.7593, Val Loss: 0.5458, Val Acc: 0.7404
Epoch 24/100, Loss: 0.5020, Acc: 0.7623, Val Loss: 0.5772, Val Acc: 0.7095
Epoch 25/100, Loss: 0.5075, Acc: 0.7578, Val Loss: 0.5424, Val Acc: 0.7467
Epoch 26/100, Loss: 0.5037, Acc: 0.7613, Val Loss: 0.5708, Val Acc: 0.7158
Epoch 27/100, Loss: 0.5022, Acc: 0.7612, Val Loss: 0.5708, Val Acc: 0.7150
Epoch 28/100, Loss: 0.4999, Acc: 0.7641, Val Loss: 0.5774, Val Acc: 0.7091
Epoch 29/100, Loss: 0.5004, Acc: 0.7629, Val Loss: 0.5570, Val Acc: 0.7334
Epoch 30/100, Loss: 0.5003, Acc: 0.7645, Val Loss: 0.5698, Val Acc: 0.7158
Epoch 31/100, Loss: 0.4985, Acc: 0.7646, Val Loss: 0.5640, Val Acc: 0.7228
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4969, Acc: 0.7651, Val Loss: 0.5492, Val Acc: 0.7345
Epoch 33/100, Loss: 0.4969, Acc: 0.7650, Val Loss: 0.5578, Val Acc: 0.7290
Epoch 34/100, Loss: 0.4956, Acc: 0.7658, Val Loss: 0.5497, Val Acc: 0.7378
Epoch 35/100, Loss: 0.4958, Acc: 0.7649, Val Loss: 0.5694, Val Acc: 0.7191
Epoch 36/100, Loss: 0.4966, Acc: 0.7658, Val Loss: 0.5566, Val Acc: 0.7316
Epoch 37/100, Loss: 0.4953, Acc: 0.7661, Val Loss: 0.5335, Val Acc: 0.7515
Mejor modelo guardado con Val Loss: 0.5335
Epoch 38/100, Loss: 0.4959, Acc: 0.7661, Val Loss: 0.5441, Val Acc: 0.7430
Epoch 39/100, Loss: 0.4942, Acc: 0.7665, Val Loss: 0.5467, Val Acc: 0.7390
Epoch 40/100, Loss: 0.4941, Acc: 0.7664, Val Loss: 0.5726, Val Acc: 0.7213
Epoch 41/100, Loss: 0.4942, Acc: 0.7666, Val Loss: 0.5496, Val Acc: 0.7378
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4935, Acc: 0.7665, Val Loss: 0.5869, Val Acc: 0.6996
Epoch 43/100, Loss: 0.4933, Acc: 0.7651, Val Loss: 0.5560, Val Acc: 0.7342
Epoch 44/100, Loss: 0.4923, Acc: 0.7667, Val Loss: 0.5721, Val Acc: 0.7187
Epoch 45/100, Loss: 0.4923, Acc: 0.7677, Val Loss: 0.5514, Val Acc: 0.7401
Epoch 46/100, Loss: 0.4919, Acc: 0.7668, Val Loss: 0.5455, Val Acc: 0.7419
Epoch 47/100, Loss: 0.4920, Acc: 0.7666, Val Loss: 0.5962, Val Acc: 0.6940
Epoch 48/100, Loss: 0.4929, Acc: 0.7678, Val Loss: 0.5574, Val Acc: 0.7316
Epoch 49/100, Loss: 0.4916, Acc: 0.7681, Val Loss: 0.5418, Val Acc: 0.7485
Epoch 50/100, Loss: 0.4918, Acc: 0.7681, Val Loss: 0.5443, Val Acc: 0.7434
Epoch 51/100, Loss: 0.4925, Acc: 0.7680, Val Loss: 0.5663, Val Acc: 0.7235
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4911, Acc: 0.7670, Val Loss: 0.5566, Val Acc: 0.7349
Epoch 53/100, Loss: 0.4907, Acc: 0.7685, Val Loss: 0.5678, Val Acc: 0.7231
Epoch 54/100, Loss: 0.4910, Acc: 0.7691, Val Loss: 0.5594, Val Acc: 0.7305
Epoch 55/100, Loss: 0.4907, Acc: 0.7682, Val Loss: 0.5495, Val Acc: 0.7390
Epoch 56/100, Loss: 0.4910, Acc: 0.7685, Val Loss: 0.5572, Val Acc: 0.7349
Epoch 57/100, Loss: 0.4905, Acc: 0.7690, Val Loss: 0.5534, Val Acc: 0.7349
Epoch 58/100, Loss: 0.4905, Acc: 0.7682, Val Loss: 0.5610, Val Acc: 0.7290
Epoch 59/100, Loss: 0.4902, Acc: 0.7690, Val Loss: 0.5508, Val Acc: 0.7367
Epoch 60/100, Loss: 0.4902, Acc: 0.7683, Val Loss: 0.5657, Val Acc: 0.7246
Epoch 61/100, Loss: 0.4898, Acc: 0.7686, Val Loss: 0.5624, Val Acc: 0.7283
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4893, Acc: 0.7692, Val Loss: 0.5581, Val Acc: 0.7349
Epoch 63/100, Loss: 0.4896, Acc: 0.7692, Val Loss: 0.5542, Val Acc: 0.7349
Epoch 64/100, Loss: 0.4894, Acc: 0.7705, Val Loss: 0.5572, Val Acc: 0.7342
Epoch 65/100, Loss: 0.4893, Acc: 0.7688, Val Loss: 0.5601, Val Acc: 0.7309
Epoch 66/100, Loss: 0.4893, Acc: 0.7696, Val Loss: 0.5552, Val Acc: 0.7345
Epoch 67/100, Loss: 0.4892, Acc: 0.7700, Val Loss: 0.5612, Val Acc: 0.7290
Epoch 68/100, Loss: 0.4892, Acc: 0.7700, Val Loss: 0.5565, Val Acc: 0.7345
Epoch 69/100, Loss: 0.4891, Acc: 0.7718, Val Loss: 0.5622, Val Acc: 0.7283
Epoch 70/100, Loss: 0.4890, Acc: 0.7702, Val Loss: 0.5563, Val Acc: 0.7338
Epoch 71/100, Loss: 0.4889, Acc: 0.7700, Val Loss: 0.5600, Val Acc: 0.7323
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4888, Acc: 0.7695, Val Loss: 0.5583, Val Acc: 0.7345
Epoch 73/100, Loss: 0.4887, Acc: 0.7709, Val Loss: 0.5580, Val Acc: 0.7342
Epoch 74/100, Loss: 0.4887, Acc: 0.7705, Val Loss: 0.5588, Val Acc: 0.7334
Epoch 75/100, Loss: 0.4885, Acc: 0.7696, Val Loss: 0.5566, Val Acc: 0.7338
Epoch 76/100, Loss: 0.4886, Acc: 0.7708, Val Loss: 0.5591, Val Acc: 0.7334
Epoch 77/100, Loss: 0.4885, Acc: 0.7700, Val Loss: 0.5644, Val Acc: 0.7268
Epoch 78/100, Loss: 0.4885, Acc: 0.7691, Val Loss: 0.5615, Val Acc: 0.7316
Epoch 79/100, Loss: 0.4886, Acc: 0.7703, Val Loss: 0.5615, Val Acc: 0.7305
Epoch 80/100, Loss: 0.4886, Acc: 0.7692, Val Loss: 0.5564, Val Acc: 0.7334
Epoch 81/100, Loss: 0.4885, Acc: 0.7698, Val Loss: 0.5587, Val Acc: 0.7349
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4885, Acc: 0.7700, Val Loss: 0.5600, Val Acc: 0.7323
Epoch 83/100, Loss: 0.4883, Acc: 0.7708, Val Loss: 0.5633, Val Acc: 0.7286
Epoch 84/100, Loss: 0.4885, Acc: 0.7704, Val Loss: 0.5629, Val Acc: 0.7301
Epoch 85/100, Loss: 0.4883, Acc: 0.7711, Val Loss: 0.5606, Val Acc: 0.7323
Epoch 86/100, Loss: 0.4883, Acc: 0.7701, Val Loss: 0.5576, Val Acc: 0.7331
Epoch 87/100, Loss: 0.4882, Acc: 0.7706, Val Loss: 0.5586, Val Acc: 0.7334
Epoch 88/100, Loss: 0.4882, Acc: 0.7709, Val Loss: 0.5627, Val Acc: 0.7286
Epoch 89/100, Loss: 0.4880, Acc: 0.7708, Val Loss: 0.5565, Val Acc: 0.7334
Epoch 90/100, Loss: 0.4882, Acc: 0.7711, Val Loss: 0.5591, Val Acc: 0.7338
Epoch 91/100, Loss: 0.4881, Acc: 0.7712, Val Loss: 0.5553, Val Acc: 0.7342
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4881, Acc: 0.7714, Val Loss: 0.5596, Val Acc: 0.7334
Epoch 93/100, Loss: 0.4881, Acc: 0.7717, Val Loss: 0.5626, Val Acc: 0.7286
Epoch 94/100, Loss: 0.4881, Acc: 0.7711, Val Loss: 0.5603, Val Acc: 0.7316
Epoch 95/100, Loss: 0.4880, Acc: 0.7712, Val Loss: 0.5590, Val Acc: 0.7334
Epoch 96/100, Loss: 0.4880, Acc: 0.7719, Val Loss: 0.5573, Val Acc: 0.7334
Epoch 97/100, Loss: 0.4879, Acc: 0.7718, Val Loss: 0.5625, Val Acc: 0.7286
Epoch 98/100, Loss: 0.4879, Acc: 0.7708, Val Loss: 0.5593, Val Acc: 0.7331
Epoch 99/100, Loss: 0.4879, Acc: 0.7717, Val Loss: 0.5581, Val Acc: 0.7338
Epoch 100/100, Loss: 0.4879, Acc: 0.7705, Val Loss: 0.5594, Val Acc: 0.7331

##############################
Resultados para principal:  019  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  5 
 {'training': [0.48792234606802487, 0.7705038617138654, 0.7617521367521367, 0.7869757174392936, 0.7741585233441911], 'validate': [0.5593867298475531, 0.7330633284241531, 0.6924954240390482, 0.8370206489675516, 0.7579298831385642], 'test': [1.0701113078329298, 0.3878091872791519, 0.40867906533142584, 0.5053066037735849, 0.451885051410493]}

##############################
Resultados para window:  5 
 {'036:024:100:090:091:019': {'training': [0.6756257329981482, 0.5620632585509379, 0.5407040038708116, 0.8222958057395143, 0.6524118806100854], 'validate': [0.6573685587838639, 0.635861561119293, 0.6037309214245337, 0.7876106194690266, 0.68352], 'test': [0.6859196115423132, 0.571849234393404, 0.5477883096366508, 0.8178066037735849, 0.6561021759697256]}, '024:036:100:090:091:019': {'training': [0.49581907274706394, 0.7464141228392791, 0.7791909924937448, 0.6874540103016924, 0.730453479280688], 'validate': [0.8014367985170942, 0.5522827687776142, 0.554945054945055, 0.5213864306784661, 0.5376425855513308], 'test': [0.568354508943028, 0.691696113074205, 0.8001850138760407, 0.5100235849056604, 0.6229744328411956]}, '100:036:024:090:091:019': {'training': [0.40885581043810915, 0.7972600220669364, 0.8624635404980929, 0.7071376011773363, 0.7771151319114525], 'validate': [0.8798153424678847, 0.49153166421207656, 0.4631268436578171, 0.11578171091445427, 0.18525073746312684], 'test': [0.5035747191696255, 0.7700235571260307, 0.7571669477234402, 0.7942216981132075, 0.7752517985611511]}, '090:036:024:100:091:019': {'training': [0.6671217756921993, 0.6469290180213314, 0.6197119711971197, 0.7599337748344371, 0.6826970748636589], 'validate': [0.6576429078745287, 0.698821796759941, 0.6632281553398058, 0.806047197640118, 0.7276964047936085], 'test': [0.671517343432815, 0.639281507656066, 0.5948449456302859, 0.870872641509434, 0.7068676716917923]}, '091:036:024:100:090:019': {'training': [0.48087000309785266, 0.7853070981978668, 0.7919412540011297, 0.7737306843267108, 0.7827300642039638], 'validate': [0.6469691489325013, 0.6432253313696613, 0.6399132321041214, 0.6526548672566371, 0.6462212486308871], 'test': [0.9463106860165242, 0.4502355712603062, 0.46645743428795605, 0.7010613207547169, 0.560188457008245]}, '019:036:024:100:090:091': {'training': [0.48792234606802487, 0.7705038617138654, 0.7617521367521367, 0.7869757174392936, 0.7741585233441911], 'validate': [0.5593867298475531, 0.7330633284241531, 0.6924954240390482, 0.8370206489675516, 0.7579298831385642], 'test': [1.0701113078329298, 0.3878091872791519, 0.40867906533142584, 0.5053066037735849, 0.451885051410493]}}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  064  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  064  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  064  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6699, Acc: 0.5971, Val Loss: 0.6847, Val Acc: 0.5622
Mejor modelo guardado con Val Loss: 0.6847
Epoch 2/100, Loss: 0.6322, Acc: 0.6501, Val Loss: 0.7062, Val Acc: 0.5133
Epoch 3/100, Loss: 0.6244, Acc: 0.6497, Val Loss: 0.6888, Val Acc: 0.5405
Epoch 4/100, Loss: 0.6085, Acc: 0.6681, Val Loss: 0.6945, Val Acc: 0.5405
Epoch 5/100, Loss: 0.6032, Acc: 0.6668, Val Loss: 0.7045, Val Acc: 0.5261
Epoch 6/100, Loss: 0.5927, Acc: 0.6775, Val Loss: 0.6937, Val Acc: 0.5361
Epoch 7/100, Loss: 0.5878, Acc: 0.6754, Val Loss: 0.6947, Val Acc: 0.5501
Epoch 8/100, Loss: 0.5835, Acc: 0.6795, Val Loss: 0.7102, Val Acc: 0.5284
Epoch 9/100, Loss: 0.5874, Acc: 0.6738, Val Loss: 0.6906, Val Acc: 0.5644
Epoch 10/100, Loss: 0.5833, Acc: 0.6794, Val Loss: 0.6880, Val Acc: 0.5681
Epoch 11/100, Loss: 0.5833, Acc: 0.6797, Val Loss: 0.6950, Val Acc: 0.5582
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5749, Acc: 0.6837, Val Loss: 0.7168, Val Acc: 0.5258
Epoch 13/100, Loss: 0.5759, Acc: 0.6838, Val Loss: 0.7142, Val Acc: 0.5331
Epoch 14/100, Loss: 0.5746, Acc: 0.6840, Val Loss: 0.7172, Val Acc: 0.5280
Epoch 15/100, Loss: 0.5758, Acc: 0.6809, Val Loss: 0.7020, Val Acc: 0.5512
Epoch 16/100, Loss: 0.5757, Acc: 0.6828, Val Loss: 0.7133, Val Acc: 0.5420
Epoch 17/100, Loss: 0.5750, Acc: 0.6846, Val Loss: 0.7183, Val Acc: 0.5280
Epoch 18/100, Loss: 0.5734, Acc: 0.6857, Val Loss: 0.7080, Val Acc: 0.5423
Epoch 19/100, Loss: 0.5723, Acc: 0.6844, Val Loss: 0.7074, Val Acc: 0.5633
Epoch 20/100, Loss: 0.5735, Acc: 0.6848, Val Loss: 0.7070, Val Acc: 0.5641
Epoch 21/100, Loss: 0.5734, Acc: 0.6841, Val Loss: 0.7175, Val Acc: 0.5416
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5709, Acc: 0.6895, Val Loss: 0.7184, Val Acc: 0.5372
Epoch 23/100, Loss: 0.5688, Acc: 0.6898, Val Loss: 0.7143, Val Acc: 0.5379
Epoch 24/100, Loss: 0.5683, Acc: 0.6887, Val Loss: 0.7140, Val Acc: 0.5339
Epoch 25/100, Loss: 0.5683, Acc: 0.6897, Val Loss: 0.7174, Val Acc: 0.5284
Epoch 26/100, Loss: 0.5672, Acc: 0.6891, Val Loss: 0.7167, Val Acc: 0.5365
Epoch 27/100, Loss: 0.5674, Acc: 0.6878, Val Loss: 0.7141, Val Acc: 0.5339
Epoch 28/100, Loss: 0.5666, Acc: 0.6893, Val Loss: 0.7200, Val Acc: 0.5317
Epoch 29/100, Loss: 0.5656, Acc: 0.6908, Val Loss: 0.7192, Val Acc: 0.5361
Epoch 30/100, Loss: 0.5658, Acc: 0.6904, Val Loss: 0.7195, Val Acc: 0.5280
Epoch 31/100, Loss: 0.5660, Acc: 0.6877, Val Loss: 0.7205, Val Acc: 0.5276
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5640, Acc: 0.6893, Val Loss: 0.7177, Val Acc: 0.5328
Epoch 33/100, Loss: 0.5631, Acc: 0.6905, Val Loss: 0.7169, Val Acc: 0.5368
Epoch 34/100, Loss: 0.5629, Acc: 0.6909, Val Loss: 0.7249, Val Acc: 0.5228
Epoch 35/100, Loss: 0.5624, Acc: 0.6913, Val Loss: 0.7097, Val Acc: 0.5560
Epoch 36/100, Loss: 0.5624, Acc: 0.6911, Val Loss: 0.7155, Val Acc: 0.5387
Epoch 37/100, Loss: 0.5615, Acc: 0.6901, Val Loss: 0.7198, Val Acc: 0.5361
Epoch 38/100, Loss: 0.5618, Acc: 0.6911, Val Loss: 0.7196, Val Acc: 0.5401
Epoch 39/100, Loss: 0.5618, Acc: 0.6907, Val Loss: 0.7182, Val Acc: 0.5353
Epoch 40/100, Loss: 0.5611, Acc: 0.6906, Val Loss: 0.7222, Val Acc: 0.5328
Epoch 41/100, Loss: 0.5615, Acc: 0.6902, Val Loss: 0.7138, Val Acc: 0.5482
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5597, Acc: 0.6922, Val Loss: 0.7196, Val Acc: 0.5376
Epoch 43/100, Loss: 0.5596, Acc: 0.6912, Val Loss: 0.7185, Val Acc: 0.5361
Epoch 44/100, Loss: 0.5595, Acc: 0.6909, Val Loss: 0.7188, Val Acc: 0.5365
Epoch 45/100, Loss: 0.5592, Acc: 0.6916, Val Loss: 0.7177, Val Acc: 0.5372
Epoch 46/100, Loss: 0.5590, Acc: 0.6927, Val Loss: 0.7182, Val Acc: 0.5365
Epoch 47/100, Loss: 0.5589, Acc: 0.6904, Val Loss: 0.7185, Val Acc: 0.5376
Epoch 48/100, Loss: 0.5585, Acc: 0.6919, Val Loss: 0.7205, Val Acc: 0.5339
Epoch 49/100, Loss: 0.5578, Acc: 0.6932, Val Loss: 0.7223, Val Acc: 0.5339
Epoch 50/100, Loss: 0.5565, Acc: 0.6939, Val Loss: 0.7199, Val Acc: 0.5335
Epoch 51/100, Loss: 0.5559, Acc: 0.6944, Val Loss: 0.7236, Val Acc: 0.5335
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5552, Acc: 0.6925, Val Loss: 0.7223, Val Acc: 0.5346
Epoch 53/100, Loss: 0.5551, Acc: 0.6928, Val Loss: 0.7236, Val Acc: 0.5331
Epoch 54/100, Loss: 0.5549, Acc: 0.6937, Val Loss: 0.7223, Val Acc: 0.5331
Epoch 55/100, Loss: 0.5544, Acc: 0.6935, Val Loss: 0.7239, Val Acc: 0.5335
Epoch 56/100, Loss: 0.5544, Acc: 0.6943, Val Loss: 0.7231, Val Acc: 0.5357
Epoch 57/100, Loss: 0.5542, Acc: 0.6927, Val Loss: 0.7231, Val Acc: 0.5350
Epoch 58/100, Loss: 0.5540, Acc: 0.6928, Val Loss: 0.7232, Val Acc: 0.5342
Epoch 59/100, Loss: 0.5539, Acc: 0.6938, Val Loss: 0.7222, Val Acc: 0.5342
Epoch 60/100, Loss: 0.5535, Acc: 0.6936, Val Loss: 0.7252, Val Acc: 0.5339
Epoch 61/100, Loss: 0.5534, Acc: 0.6927, Val Loss: 0.7242, Val Acc: 0.5357
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5530, Acc: 0.6942, Val Loss: 0.7255, Val Acc: 0.5350
Epoch 63/100, Loss: 0.5529, Acc: 0.6935, Val Loss: 0.7245, Val Acc: 0.5346
Epoch 64/100, Loss: 0.5529, Acc: 0.6941, Val Loss: 0.7246, Val Acc: 0.5350
Epoch 65/100, Loss: 0.5527, Acc: 0.6944, Val Loss: 0.7243, Val Acc: 0.5339
Epoch 66/100, Loss: 0.5526, Acc: 0.6935, Val Loss: 0.7242, Val Acc: 0.5342
Epoch 67/100, Loss: 0.5525, Acc: 0.6934, Val Loss: 0.7231, Val Acc: 0.5350
Epoch 68/100, Loss: 0.5523, Acc: 0.6933, Val Loss: 0.7247, Val Acc: 0.5339
Epoch 69/100, Loss: 0.5521, Acc: 0.6935, Val Loss: 0.7242, Val Acc: 0.5357
Epoch 70/100, Loss: 0.5522, Acc: 0.6940, Val Loss: 0.7252, Val Acc: 0.5350
Epoch 71/100, Loss: 0.5520, Acc: 0.6939, Val Loss: 0.7249, Val Acc: 0.5339
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5518, Acc: 0.6941, Val Loss: 0.7241, Val Acc: 0.5353
Epoch 73/100, Loss: 0.5516, Acc: 0.6931, Val Loss: 0.7236, Val Acc: 0.5335
Epoch 74/100, Loss: 0.5516, Acc: 0.6940, Val Loss: 0.7242, Val Acc: 0.5353
Epoch 75/100, Loss: 0.5515, Acc: 0.6936, Val Loss: 0.7247, Val Acc: 0.5346
Epoch 76/100, Loss: 0.5514, Acc: 0.6928, Val Loss: 0.7255, Val Acc: 0.5335
Epoch 77/100, Loss: 0.5514, Acc: 0.6941, Val Loss: 0.7245, Val Acc: 0.5342
Epoch 78/100, Loss: 0.5513, Acc: 0.6937, Val Loss: 0.7247, Val Acc: 0.5350
Epoch 79/100, Loss: 0.5512, Acc: 0.6940, Val Loss: 0.7249, Val Acc: 0.5353
Epoch 80/100, Loss: 0.5512, Acc: 0.6934, Val Loss: 0.7249, Val Acc: 0.5342
Epoch 81/100, Loss: 0.5510, Acc: 0.6942, Val Loss: 0.7260, Val Acc: 0.5346
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5509, Acc: 0.6940, Val Loss: 0.7254, Val Acc: 0.5350
Epoch 83/100, Loss: 0.5509, Acc: 0.6945, Val Loss: 0.7253, Val Acc: 0.5339
Epoch 84/100, Loss: 0.5509, Acc: 0.6932, Val Loss: 0.7259, Val Acc: 0.5346
Epoch 85/100, Loss: 0.5508, Acc: 0.6927, Val Loss: 0.7254, Val Acc: 0.5350
Epoch 86/100, Loss: 0.5506, Acc: 0.6935, Val Loss: 0.7255, Val Acc: 0.5339
Epoch 87/100, Loss: 0.5505, Acc: 0.6938, Val Loss: 0.7251, Val Acc: 0.5350
Epoch 88/100, Loss: 0.5504, Acc: 0.6944, Val Loss: 0.7263, Val Acc: 0.5331
Epoch 89/100, Loss: 0.5504, Acc: 0.6940, Val Loss: 0.7260, Val Acc: 0.5346
Epoch 90/100, Loss: 0.5502, Acc: 0.6930, Val Loss: 0.7270, Val Acc: 0.5350
Epoch 91/100, Loss: 0.5503, Acc: 0.6944, Val Loss: 0.7261, Val Acc: 0.5342
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5502, Acc: 0.6941, Val Loss: 0.7263, Val Acc: 0.5339
Epoch 93/100, Loss: 0.5502, Acc: 0.6931, Val Loss: 0.7262, Val Acc: 0.5339
Epoch 94/100, Loss: 0.5501, Acc: 0.6950, Val Loss: 0.7263, Val Acc: 0.5342
Epoch 95/100, Loss: 0.5500, Acc: 0.6932, Val Loss: 0.7267, Val Acc: 0.5346
Epoch 96/100, Loss: 0.5499, Acc: 0.6943, Val Loss: 0.7263, Val Acc: 0.5346
Epoch 97/100, Loss: 0.5498, Acc: 0.6951, Val Loss: 0.7276, Val Acc: 0.5342
Epoch 98/100, Loss: 0.5499, Acc: 0.6936, Val Loss: 0.7268, Val Acc: 0.5342
Epoch 99/100, Loss: 0.5497, Acc: 0.6943, Val Loss: 0.7266, Val Acc: 0.5342
Epoch 100/100, Loss: 0.5496, Acc: 0.6944, Val Loss: 0.7271, Val Acc: 0.5342

##############################
Resultados para principal:  064  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5 
 {'training': [0.5496446349551547, 0.694372931224715, 0.6361175560711524, 0.9078366445916115, 0.7480673033196907], 'validate': [0.7270892491174299, 0.5342415316642121, 0.5193534666099532, 0.9004424778761062, 0.658753709198813], 'test': [0.7637698782814873, 0.30241460541813897, 0.3519577650681918, 0.4716981132075472, 0.4031242126480222]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  060  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  060  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  060  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6265, Acc: 0.6800, Val Loss: 0.7501, Val Acc: 0.4219
Mejor modelo guardado con Val Loss: 0.7501
Epoch 2/100, Loss: 0.5784, Acc: 0.7094, Val Loss: 0.7758, Val Acc: 0.4510
Epoch 3/100, Loss: 0.5621, Acc: 0.7153, Val Loss: 0.7862, Val Acc: 0.4499
Epoch 4/100, Loss: 0.5494, Acc: 0.7160, Val Loss: 0.8297, Val Acc: 0.4477
Epoch 5/100, Loss: 0.5482, Acc: 0.7143, Val Loss: 0.8347, Val Acc: 0.4300
Epoch 6/100, Loss: 0.5469, Acc: 0.7148, Val Loss: 0.8053, Val Acc: 0.4849
Epoch 7/100, Loss: 0.5429, Acc: 0.7227, Val Loss: 0.8098, Val Acc: 0.4624
Epoch 8/100, Loss: 0.5398, Acc: 0.7260, Val Loss: 0.8167, Val Acc: 0.4558
Epoch 9/100, Loss: 0.5348, Acc: 0.7236, Val Loss: 0.8293, Val Acc: 0.4507
Epoch 10/100, Loss: 0.5484, Acc: 0.7197, Val Loss: 0.8110, Val Acc: 0.4768
Epoch 11/100, Loss: 0.5397, Acc: 0.7226, Val Loss: 0.8294, Val Acc: 0.4750
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5321, Acc: 0.7279, Val Loss: 0.8230, Val Acc: 0.4761
Epoch 13/100, Loss: 0.5257, Acc: 0.7325, Val Loss: 0.7753, Val Acc: 0.4786
Epoch 14/100, Loss: 0.5242, Acc: 0.7314, Val Loss: 0.7857, Val Acc: 0.4790
Epoch 15/100, Loss: 0.5211, Acc: 0.7344, Val Loss: 0.7969, Val Acc: 0.4768
Epoch 16/100, Loss: 0.5184, Acc: 0.7334, Val Loss: 0.7853, Val Acc: 0.4624
Epoch 17/100, Loss: 0.5192, Acc: 0.7333, Val Loss: 0.8074, Val Acc: 0.4591
Epoch 18/100, Loss: 0.5185, Acc: 0.7319, Val Loss: 0.7988, Val Acc: 0.4680
Epoch 19/100, Loss: 0.5161, Acc: 0.7359, Val Loss: 0.8092, Val Acc: 0.4797
Epoch 20/100, Loss: 0.5157, Acc: 0.7354, Val Loss: 0.7743, Val Acc: 0.4650
Epoch 21/100, Loss: 0.5139, Acc: 0.7347, Val Loss: 0.7675, Val Acc: 0.4728
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5100, Acc: 0.7406, Val Loss: 0.7816, Val Acc: 0.4757
Epoch 23/100, Loss: 0.5086, Acc: 0.7383, Val Loss: 0.7814, Val Acc: 0.4812
Epoch 24/100, Loss: 0.5096, Acc: 0.7392, Val Loss: 0.7733, Val Acc: 0.4809
Epoch 25/100, Loss: 0.5083, Acc: 0.7410, Val Loss: 0.7809, Val Acc: 0.4831
Epoch 26/100, Loss: 0.5093, Acc: 0.7383, Val Loss: 0.7650, Val Acc: 0.4812
Epoch 27/100, Loss: 0.5057, Acc: 0.7410, Val Loss: 0.7946, Val Acc: 0.4801
Epoch 28/100, Loss: 0.5064, Acc: 0.7392, Val Loss: 0.7868, Val Acc: 0.4746
Epoch 29/100, Loss: 0.5057, Acc: 0.7413, Val Loss: 0.7921, Val Acc: 0.4742
Epoch 30/100, Loss: 0.5047, Acc: 0.7419, Val Loss: 0.7929, Val Acc: 0.4801
Epoch 31/100, Loss: 0.5042, Acc: 0.7416, Val Loss: 0.8075, Val Acc: 0.4783
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5026, Acc: 0.7426, Val Loss: 0.7907, Val Acc: 0.4794
Epoch 33/100, Loss: 0.5015, Acc: 0.7431, Val Loss: 0.7886, Val Acc: 0.4849
Epoch 34/100, Loss: 0.5009, Acc: 0.7448, Val Loss: 0.7682, Val Acc: 0.4812
Epoch 35/100, Loss: 0.5013, Acc: 0.7452, Val Loss: 0.7897, Val Acc: 0.4779
Epoch 36/100, Loss: 0.5011, Acc: 0.7445, Val Loss: 0.7740, Val Acc: 0.4820
Epoch 37/100, Loss: 0.5008, Acc: 0.7426, Val Loss: 0.7917, Val Acc: 0.4801
Epoch 38/100, Loss: 0.5001, Acc: 0.7446, Val Loss: 0.7858, Val Acc: 0.4812
Epoch 39/100, Loss: 0.4998, Acc: 0.7453, Val Loss: 0.7923, Val Acc: 0.4775
Epoch 40/100, Loss: 0.4996, Acc: 0.7452, Val Loss: 0.7851, Val Acc: 0.4783
Epoch 41/100, Loss: 0.4995, Acc: 0.7426, Val Loss: 0.7908, Val Acc: 0.4853
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4983, Acc: 0.7460, Val Loss: 0.7903, Val Acc: 0.4790
Epoch 43/100, Loss: 0.4978, Acc: 0.7464, Val Loss: 0.7814, Val Acc: 0.4820
Epoch 44/100, Loss: 0.4976, Acc: 0.7455, Val Loss: 0.7870, Val Acc: 0.4809
Epoch 45/100, Loss: 0.4976, Acc: 0.7456, Val Loss: 0.7891, Val Acc: 0.4831
Epoch 46/100, Loss: 0.4975, Acc: 0.7455, Val Loss: 0.7885, Val Acc: 0.4816
Epoch 47/100, Loss: 0.4975, Acc: 0.7461, Val Loss: 0.7806, Val Acc: 0.4827
Epoch 48/100, Loss: 0.4971, Acc: 0.7455, Val Loss: 0.7854, Val Acc: 0.4805
Epoch 49/100, Loss: 0.4968, Acc: 0.7453, Val Loss: 0.7833, Val Acc: 0.4790
Epoch 50/100, Loss: 0.4967, Acc: 0.7472, Val Loss: 0.7847, Val Acc: 0.4834
Epoch 51/100, Loss: 0.4972, Acc: 0.7449, Val Loss: 0.7734, Val Acc: 0.4809
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4963, Acc: 0.7469, Val Loss: 0.7902, Val Acc: 0.4809
Epoch 53/100, Loss: 0.4956, Acc: 0.7471, Val Loss: 0.7798, Val Acc: 0.4838
Epoch 54/100, Loss: 0.4952, Acc: 0.7471, Val Loss: 0.7785, Val Acc: 0.4838
Epoch 55/100, Loss: 0.4947, Acc: 0.7467, Val Loss: 0.7817, Val Acc: 0.4834
Epoch 56/100, Loss: 0.4951, Acc: 0.7478, Val Loss: 0.7817, Val Acc: 0.4823
Epoch 57/100, Loss: 0.4948, Acc: 0.7471, Val Loss: 0.7836, Val Acc: 0.4805
Epoch 58/100, Loss: 0.4946, Acc: 0.7474, Val Loss: 0.7859, Val Acc: 0.4812
Epoch 59/100, Loss: 0.4945, Acc: 0.7481, Val Loss: 0.7897, Val Acc: 0.4838
Epoch 60/100, Loss: 0.4945, Acc: 0.7478, Val Loss: 0.7910, Val Acc: 0.4794
Epoch 61/100, Loss: 0.4941, Acc: 0.7486, Val Loss: 0.7806, Val Acc: 0.4823
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4935, Acc: 0.7485, Val Loss: 0.7856, Val Acc: 0.4827
Epoch 63/100, Loss: 0.4935, Acc: 0.7486, Val Loss: 0.7864, Val Acc: 0.4842
Epoch 64/100, Loss: 0.4935, Acc: 0.7480, Val Loss: 0.7865, Val Acc: 0.4823
Epoch 65/100, Loss: 0.4934, Acc: 0.7483, Val Loss: 0.7840, Val Acc: 0.4834
Epoch 66/100, Loss: 0.4932, Acc: 0.7489, Val Loss: 0.7852, Val Acc: 0.4831
Epoch 67/100, Loss: 0.4932, Acc: 0.7467, Val Loss: 0.7820, Val Acc: 0.4809
Epoch 68/100, Loss: 0.4931, Acc: 0.7476, Val Loss: 0.7839, Val Acc: 0.4823
Epoch 69/100, Loss: 0.4931, Acc: 0.7489, Val Loss: 0.7848, Val Acc: 0.4834
Epoch 70/100, Loss: 0.4930, Acc: 0.7485, Val Loss: 0.7848, Val Acc: 0.4827
Epoch 71/100, Loss: 0.4928, Acc: 0.7483, Val Loss: 0.7871, Val Acc: 0.4823
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4928, Acc: 0.7483, Val Loss: 0.7839, Val Acc: 0.4823
Epoch 73/100, Loss: 0.4926, Acc: 0.7492, Val Loss: 0.7856, Val Acc: 0.4827
Epoch 74/100, Loss: 0.4926, Acc: 0.7477, Val Loss: 0.7864, Val Acc: 0.4820
Epoch 75/100, Loss: 0.4925, Acc: 0.7483, Val Loss: 0.7867, Val Acc: 0.4831
Epoch 76/100, Loss: 0.4925, Acc: 0.7487, Val Loss: 0.7843, Val Acc: 0.4838
Epoch 77/100, Loss: 0.4924, Acc: 0.7475, Val Loss: 0.7847, Val Acc: 0.4823
Epoch 78/100, Loss: 0.4924, Acc: 0.7481, Val Loss: 0.7841, Val Acc: 0.4831
Epoch 79/100, Loss: 0.4923, Acc: 0.7480, Val Loss: 0.7850, Val Acc: 0.4823
Epoch 80/100, Loss: 0.4923, Acc: 0.7485, Val Loss: 0.7846, Val Acc: 0.4827
Epoch 81/100, Loss: 0.4923, Acc: 0.7482, Val Loss: 0.7836, Val Acc: 0.4820
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4923, Acc: 0.7483, Val Loss: 0.7839, Val Acc: 0.4820
Epoch 83/100, Loss: 0.4922, Acc: 0.7490, Val Loss: 0.7838, Val Acc: 0.4834
Epoch 84/100, Loss: 0.4922, Acc: 0.7482, Val Loss: 0.7854, Val Acc: 0.4834
Epoch 85/100, Loss: 0.4921, Acc: 0.7482, Val Loss: 0.7840, Val Acc: 0.4838
Epoch 86/100, Loss: 0.4921, Acc: 0.7480, Val Loss: 0.7845, Val Acc: 0.4823
Epoch 87/100, Loss: 0.4921, Acc: 0.7489, Val Loss: 0.7870, Val Acc: 0.4827
Epoch 88/100, Loss: 0.4920, Acc: 0.7483, Val Loss: 0.7849, Val Acc: 0.4823
Epoch 89/100, Loss: 0.4920, Acc: 0.7486, Val Loss: 0.7841, Val Acc: 0.4831
Epoch 90/100, Loss: 0.4919, Acc: 0.7492, Val Loss: 0.7855, Val Acc: 0.4827
Epoch 91/100, Loss: 0.4919, Acc: 0.7493, Val Loss: 0.7860, Val Acc: 0.4831
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4918, Acc: 0.7484, Val Loss: 0.7842, Val Acc: 0.4827
Epoch 93/100, Loss: 0.4917, Acc: 0.7484, Val Loss: 0.7858, Val Acc: 0.4831
Epoch 94/100, Loss: 0.4917, Acc: 0.7483, Val Loss: 0.7845, Val Acc: 0.4827
Epoch 95/100, Loss: 0.4917, Acc: 0.7484, Val Loss: 0.7860, Val Acc: 0.4831
Epoch 96/100, Loss: 0.4916, Acc: 0.7494, Val Loss: 0.7869, Val Acc: 0.4823
Epoch 97/100, Loss: 0.4917, Acc: 0.7485, Val Loss: 0.7863, Val Acc: 0.4823
Epoch 98/100, Loss: 0.4914, Acc: 0.7493, Val Loss: 0.7857, Val Acc: 0.4820
Epoch 99/100, Loss: 0.4917, Acc: 0.7489, Val Loss: 0.7858, Val Acc: 0.4816
Epoch 100/100, Loss: 0.4915, Acc: 0.7496, Val Loss: 0.7852, Val Acc: 0.4838

##############################
Resultados para principal:  060  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5 
 {'training': [0.49151333823454824, 0.7496322177271055, 0.8209131771942276, 0.6383370125091979, 0.7182034564834937], 'validate': [0.7852163675219513, 0.48379970544919, 0.4201388888888889, 0.08923303834808259, 0.14720194647201945], 'test': [0.7885431586592285, 0.4366902237926973, 0.46389351081530783, 0.8219339622641509, 0.5930653052542012]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  028  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  028  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  028  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5191, Acc: 0.7988, Val Loss: 0.3971, Val Acc: 0.8579
Mejor modelo guardado con Val Loss: 0.3971
Epoch 2/100, Loss: 0.3837, Acc: 0.8435, Val Loss: 0.3447, Val Acc: 0.8660
Mejor modelo guardado con Val Loss: 0.3447
Epoch 3/100, Loss: 0.3514, Acc: 0.8513, Val Loss: 0.3876, Val Acc: 0.8454
Epoch 4/100, Loss: 0.3383, Acc: 0.8515, Val Loss: 0.3482, Val Acc: 0.8667
Epoch 5/100, Loss: 0.3369, Acc: 0.8544, Val Loss: 0.3798, Val Acc: 0.8531
Epoch 6/100, Loss: 0.3341, Acc: 0.8539, Val Loss: 0.3785, Val Acc: 0.8490
Epoch 7/100, Loss: 0.3411, Acc: 0.8493, Val Loss: 0.3321, Val Acc: 0.8645
Mejor modelo guardado con Val Loss: 0.3321
Epoch 8/100, Loss: 0.3219, Acc: 0.8586, Val Loss: 0.3667, Val Acc: 0.8568
Epoch 9/100, Loss: 0.3260, Acc: 0.8589, Val Loss: 0.3699, Val Acc: 0.8483
Epoch 10/100, Loss: 0.3290, Acc: 0.8569, Val Loss: 0.4324, Val Acc: 0.8240
Epoch 11/100, Loss: 0.3304, Acc: 0.8554, Val Loss: 0.4256, Val Acc: 0.8277
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3188, Acc: 0.8615, Val Loss: 0.3942, Val Acc: 0.8409
Epoch 13/100, Loss: 0.3147, Acc: 0.8627, Val Loss: 0.3570, Val Acc: 0.8638
Epoch 14/100, Loss: 0.3147, Acc: 0.8606, Val Loss: 0.3368, Val Acc: 0.8700
Epoch 15/100, Loss: 0.3117, Acc: 0.8631, Val Loss: 0.4211, Val Acc: 0.8325
Epoch 16/100, Loss: 0.3136, Acc: 0.8623, Val Loss: 0.3577, Val Acc: 0.8527
Epoch 17/100, Loss: 0.3150, Acc: 0.8609, Val Loss: 0.4161, Val Acc: 0.8406
Epoch 18/100, Loss: 0.3141, Acc: 0.8659, Val Loss: 0.3696, Val Acc: 0.8693
Epoch 19/100, Loss: 0.3084, Acc: 0.8630, Val Loss: 0.3763, Val Acc: 0.8608
Epoch 20/100, Loss: 0.3107, Acc: 0.8636, Val Loss: 0.3873, Val Acc: 0.8398
Epoch 21/100, Loss: 0.3084, Acc: 0.8671, Val Loss: 0.3387, Val Acc: 0.8667
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3058, Acc: 0.8664, Val Loss: 0.3381, Val Acc: 0.8682
Epoch 23/100, Loss: 0.3061, Acc: 0.8650, Val Loss: 0.3483, Val Acc: 0.8641
Epoch 24/100, Loss: 0.3031, Acc: 0.8660, Val Loss: 0.4178, Val Acc: 0.8273
Epoch 25/100, Loss: 0.3057, Acc: 0.8673, Val Loss: 0.3829, Val Acc: 0.8501
Epoch 26/100, Loss: 0.3031, Acc: 0.8683, Val Loss: 0.3455, Val Acc: 0.8649
Epoch 27/100, Loss: 0.3014, Acc: 0.8685, Val Loss: 0.3379, Val Acc: 0.8700
Epoch 28/100, Loss: 0.3025, Acc: 0.8671, Val Loss: 0.3663, Val Acc: 0.8601
Epoch 29/100, Loss: 0.3004, Acc: 0.8680, Val Loss: 0.3678, Val Acc: 0.8582
Epoch 30/100, Loss: 0.3001, Acc: 0.8670, Val Loss: 0.3615, Val Acc: 0.8616
Epoch 31/100, Loss: 0.2994, Acc: 0.8697, Val Loss: 0.3720, Val Acc: 0.8594
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2972, Acc: 0.8690, Val Loss: 0.3516, Val Acc: 0.8652
Epoch 33/100, Loss: 0.2960, Acc: 0.8700, Val Loss: 0.3659, Val Acc: 0.8612
Epoch 34/100, Loss: 0.2959, Acc: 0.8707, Val Loss: 0.3287, Val Acc: 0.8759
Mejor modelo guardado con Val Loss: 0.3287
Epoch 35/100, Loss: 0.2951, Acc: 0.8718, Val Loss: 0.3819, Val Acc: 0.8527
Epoch 36/100, Loss: 0.2960, Acc: 0.8704, Val Loss: 0.3667, Val Acc: 0.8645
Epoch 37/100, Loss: 0.2941, Acc: 0.8712, Val Loss: 0.3605, Val Acc: 0.8638
Epoch 38/100, Loss: 0.2953, Acc: 0.8697, Val Loss: 0.3619, Val Acc: 0.8608
Epoch 39/100, Loss: 0.2953, Acc: 0.8709, Val Loss: 0.3630, Val Acc: 0.8634
Epoch 40/100, Loss: 0.2944, Acc: 0.8709, Val Loss: 0.3768, Val Acc: 0.8616
Epoch 41/100, Loss: 0.2943, Acc: 0.8713, Val Loss: 0.3709, Val Acc: 0.8612
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2924, Acc: 0.8716, Val Loss: 0.3747, Val Acc: 0.8612
Epoch 43/100, Loss: 0.2929, Acc: 0.8706, Val Loss: 0.3746, Val Acc: 0.8605
Epoch 44/100, Loss: 0.2917, Acc: 0.8728, Val Loss: 0.3631, Val Acc: 0.8663
Epoch 45/100, Loss: 0.2928, Acc: 0.8725, Val Loss: 0.3694, Val Acc: 0.8619
Epoch 46/100, Loss: 0.2922, Acc: 0.8707, Val Loss: 0.3656, Val Acc: 0.8623
Epoch 47/100, Loss: 0.2922, Acc: 0.8727, Val Loss: 0.3765, Val Acc: 0.8605
Epoch 48/100, Loss: 0.2916, Acc: 0.8716, Val Loss: 0.3756, Val Acc: 0.8605
Epoch 49/100, Loss: 0.2917, Acc: 0.8726, Val Loss: 0.3590, Val Acc: 0.8663
Epoch 50/100, Loss: 0.2911, Acc: 0.8735, Val Loss: 0.3615, Val Acc: 0.8678
Epoch 51/100, Loss: 0.2918, Acc: 0.8725, Val Loss: 0.3741, Val Acc: 0.8623
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2907, Acc: 0.8732, Val Loss: 0.3784, Val Acc: 0.8601
Epoch 53/100, Loss: 0.2903, Acc: 0.8749, Val Loss: 0.3597, Val Acc: 0.8652
Epoch 54/100, Loss: 0.2907, Acc: 0.8728, Val Loss: 0.3723, Val Acc: 0.8619
Epoch 55/100, Loss: 0.2901, Acc: 0.8722, Val Loss: 0.3865, Val Acc: 0.8568
Epoch 56/100, Loss: 0.2906, Acc: 0.8730, Val Loss: 0.3769, Val Acc: 0.8608
Epoch 57/100, Loss: 0.2901, Acc: 0.8732, Val Loss: 0.3661, Val Acc: 0.8656
Epoch 58/100, Loss: 0.2899, Acc: 0.8735, Val Loss: 0.3590, Val Acc: 0.8671
Epoch 59/100, Loss: 0.2903, Acc: 0.8739, Val Loss: 0.3749, Val Acc: 0.8612
Epoch 60/100, Loss: 0.2899, Acc: 0.8719, Val Loss: 0.3720, Val Acc: 0.8619
Epoch 61/100, Loss: 0.2899, Acc: 0.8726, Val Loss: 0.3712, Val Acc: 0.8623
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2894, Acc: 0.8731, Val Loss: 0.3730, Val Acc: 0.8619
Epoch 63/100, Loss: 0.2892, Acc: 0.8720, Val Loss: 0.3800, Val Acc: 0.8601
Epoch 64/100, Loss: 0.2895, Acc: 0.8728, Val Loss: 0.3762, Val Acc: 0.8612
Epoch 65/100, Loss: 0.2893, Acc: 0.8727, Val Loss: 0.3733, Val Acc: 0.8619
Epoch 66/100, Loss: 0.2894, Acc: 0.8727, Val Loss: 0.3725, Val Acc: 0.8627
Epoch 67/100, Loss: 0.2893, Acc: 0.8737, Val Loss: 0.3661, Val Acc: 0.8649
Epoch 68/100, Loss: 0.2893, Acc: 0.8736, Val Loss: 0.3684, Val Acc: 0.8630
Epoch 69/100, Loss: 0.2892, Acc: 0.8739, Val Loss: 0.3759, Val Acc: 0.8612
Epoch 70/100, Loss: 0.2893, Acc: 0.8733, Val Loss: 0.3748, Val Acc: 0.8608
Epoch 71/100, Loss: 0.2892, Acc: 0.8736, Val Loss: 0.3737, Val Acc: 0.8616
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2889, Acc: 0.8729, Val Loss: 0.3712, Val Acc: 0.8627
Epoch 73/100, Loss: 0.2891, Acc: 0.8726, Val Loss: 0.3743, Val Acc: 0.8619
Epoch 74/100, Loss: 0.2890, Acc: 0.8734, Val Loss: 0.3724, Val Acc: 0.8630
Epoch 75/100, Loss: 0.2889, Acc: 0.8739, Val Loss: 0.3670, Val Acc: 0.8641
Epoch 76/100, Loss: 0.2889, Acc: 0.8729, Val Loss: 0.3721, Val Acc: 0.8627
Epoch 77/100, Loss: 0.2889, Acc: 0.8741, Val Loss: 0.3741, Val Acc: 0.8619
Epoch 78/100, Loss: 0.2888, Acc: 0.8738, Val Loss: 0.3716, Val Acc: 0.8630
Epoch 79/100, Loss: 0.2888, Acc: 0.8733, Val Loss: 0.3752, Val Acc: 0.8616
Epoch 80/100, Loss: 0.2887, Acc: 0.8734, Val Loss: 0.3736, Val Acc: 0.8616
Epoch 81/100, Loss: 0.2887, Acc: 0.8736, Val Loss: 0.3682, Val Acc: 0.8645
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2886, Acc: 0.8731, Val Loss: 0.3723, Val Acc: 0.8630
Epoch 83/100, Loss: 0.2887, Acc: 0.8736, Val Loss: 0.3699, Val Acc: 0.8627
Epoch 84/100, Loss: 0.2886, Acc: 0.8740, Val Loss: 0.3678, Val Acc: 0.8645
Epoch 85/100, Loss: 0.2887, Acc: 0.8734, Val Loss: 0.3733, Val Acc: 0.8619
Epoch 86/100, Loss: 0.2886, Acc: 0.8731, Val Loss: 0.3721, Val Acc: 0.8627
Epoch 87/100, Loss: 0.2884, Acc: 0.8734, Val Loss: 0.3775, Val Acc: 0.8608
Epoch 88/100, Loss: 0.2885, Acc: 0.8736, Val Loss: 0.3707, Val Acc: 0.8634
Epoch 89/100, Loss: 0.2885, Acc: 0.8739, Val Loss: 0.3742, Val Acc: 0.8616
Epoch 90/100, Loss: 0.2884, Acc: 0.8734, Val Loss: 0.3672, Val Acc: 0.8649
Epoch 91/100, Loss: 0.2885, Acc: 0.8733, Val Loss: 0.3723, Val Acc: 0.8627
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2884, Acc: 0.8742, Val Loss: 0.3773, Val Acc: 0.8608
Epoch 93/100, Loss: 0.2884, Acc: 0.8732, Val Loss: 0.3707, Val Acc: 0.8638
Epoch 94/100, Loss: 0.2883, Acc: 0.8738, Val Loss: 0.3737, Val Acc: 0.8627
Epoch 95/100, Loss: 0.2881, Acc: 0.8731, Val Loss: 0.3714, Val Acc: 0.8634
Epoch 96/100, Loss: 0.2880, Acc: 0.8732, Val Loss: 0.3706, Val Acc: 0.8641
Epoch 97/100, Loss: 0.2880, Acc: 0.8737, Val Loss: 0.3664, Val Acc: 0.8649
Epoch 98/100, Loss: 0.2880, Acc: 0.8734, Val Loss: 0.3734, Val Acc: 0.8623
Epoch 99/100, Loss: 0.2880, Acc: 0.8740, Val Loss: 0.3700, Val Acc: 0.8634
Epoch 100/100, Loss: 0.2879, Acc: 0.8738, Val Loss: 0.3685, Val Acc: 0.8638

##############################
Resultados para principal:  028  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5 
 {'training': [0.28788046887930197, 0.8737587348289813, 0.8916522074416812, 0.8508094186902134, 0.8707521415795915], 'validate': [0.36848759180108126, 0.8637702503681886, 0.9833333333333333, 0.7396755162241888, 0.8442760942760943], 'test': [0.7532972903163345, 0.6663722025912838, 0.8893499308437067, 0.37912735849056606, 0.5316246382802811]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  033  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  033  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  033  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6629, Acc: 0.6210, Val Loss: 0.6502, Val Acc: 0.6591
Mejor modelo guardado con Val Loss: 0.6502
Epoch 2/100, Loss: 0.6377, Acc: 0.6365, Val Loss: 0.6405, Val Acc: 0.6576
Mejor modelo guardado con Val Loss: 0.6405
Epoch 3/100, Loss: 0.6255, Acc: 0.6562, Val Loss: 0.6513, Val Acc: 0.6406
Epoch 4/100, Loss: 0.6233, Acc: 0.6459, Val Loss: 0.6306, Val Acc: 0.6661
Mejor modelo guardado con Val Loss: 0.6306
Epoch 5/100, Loss: 0.6266, Acc: 0.6427, Val Loss: 0.6348, Val Acc: 0.6845
Epoch 6/100, Loss: 0.6132, Acc: 0.6523, Val Loss: 0.6400, Val Acc: 0.6576
Epoch 7/100, Loss: 0.6071, Acc: 0.6643, Val Loss: 0.6307, Val Acc: 0.6613
Epoch 8/100, Loss: 0.6074, Acc: 0.6550, Val Loss: 0.6268, Val Acc: 0.6753
Mejor modelo guardado con Val Loss: 0.6268
Epoch 9/100, Loss: 0.6005, Acc: 0.6643, Val Loss: 0.6377, Val Acc: 0.6517
Epoch 10/100, Loss: 0.6023, Acc: 0.6627, Val Loss: 0.6513, Val Acc: 0.6616
Epoch 11/100, Loss: 0.6007, Acc: 0.6638, Val Loss: 0.6471, Val Acc: 0.5943
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5921, Acc: 0.6715, Val Loss: 0.6245, Val Acc: 0.6690
Mejor modelo guardado con Val Loss: 0.6245
Epoch 13/100, Loss: 0.5883, Acc: 0.6697, Val Loss: 0.6382, Val Acc: 0.6307
Epoch 14/100, Loss: 0.5903, Acc: 0.6673, Val Loss: 0.6339, Val Acc: 0.6649
Epoch 15/100, Loss: 0.5859, Acc: 0.6696, Val Loss: 0.6264, Val Acc: 0.6620
Epoch 16/100, Loss: 0.5810, Acc: 0.6802, Val Loss: 0.6351, Val Acc: 0.6580
Epoch 17/100, Loss: 0.5827, Acc: 0.6781, Val Loss: 0.6356, Val Acc: 0.6513
Epoch 18/100, Loss: 0.5827, Acc: 0.6787, Val Loss: 0.6480, Val Acc: 0.6348
Epoch 19/100, Loss: 0.5819, Acc: 0.6784, Val Loss: 0.6484, Val Acc: 0.6583
Epoch 20/100, Loss: 0.5818, Acc: 0.6826, Val Loss: 0.6281, Val Acc: 0.6443
Epoch 21/100, Loss: 0.5845, Acc: 0.6771, Val Loss: 0.6587, Val Acc: 0.6767
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5788, Acc: 0.6850, Val Loss: 0.6413, Val Acc: 0.6524
Epoch 23/100, Loss: 0.5769, Acc: 0.6851, Val Loss: 0.6415, Val Acc: 0.6605
Epoch 24/100, Loss: 0.5760, Acc: 0.6843, Val Loss: 0.6342, Val Acc: 0.6476
Epoch 25/100, Loss: 0.5764, Acc: 0.6841, Val Loss: 0.6367, Val Acc: 0.6395
Epoch 26/100, Loss: 0.5748, Acc: 0.6861, Val Loss: 0.6454, Val Acc: 0.6550
Epoch 27/100, Loss: 0.5744, Acc: 0.6889, Val Loss: 0.6275, Val Acc: 0.6904
Epoch 28/100, Loss: 0.5745, Acc: 0.6856, Val Loss: 0.6344, Val Acc: 0.6565
Epoch 29/100, Loss: 0.5743, Acc: 0.6851, Val Loss: 0.6346, Val Acc: 0.6609
Epoch 30/100, Loss: 0.5726, Acc: 0.6886, Val Loss: 0.6555, Val Acc: 0.6705
Epoch 31/100, Loss: 0.5734, Acc: 0.6866, Val Loss: 0.6304, Val Acc: 0.6756
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5700, Acc: 0.6901, Val Loss: 0.6437, Val Acc: 0.6458
Epoch 33/100, Loss: 0.5701, Acc: 0.6904, Val Loss: 0.6439, Val Acc: 0.6532
Epoch 34/100, Loss: 0.5704, Acc: 0.6875, Val Loss: 0.6397, Val Acc: 0.6513
Epoch 35/100, Loss: 0.5692, Acc: 0.6912, Val Loss: 0.6488, Val Acc: 0.6546
Epoch 36/100, Loss: 0.5692, Acc: 0.6880, Val Loss: 0.6299, Val Acc: 0.6598
Epoch 37/100, Loss: 0.5684, Acc: 0.6920, Val Loss: 0.6291, Val Acc: 0.6734
Epoch 38/100, Loss: 0.5684, Acc: 0.6936, Val Loss: 0.6436, Val Acc: 0.6616
Epoch 39/100, Loss: 0.5687, Acc: 0.6901, Val Loss: 0.6449, Val Acc: 0.6620
Epoch 40/100, Loss: 0.5681, Acc: 0.6898, Val Loss: 0.6388, Val Acc: 0.6646
Epoch 41/100, Loss: 0.5672, Acc: 0.6943, Val Loss: 0.6433, Val Acc: 0.6624
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5667, Acc: 0.6961, Val Loss: 0.6445, Val Acc: 0.6609
Epoch 43/100, Loss: 0.5659, Acc: 0.6958, Val Loss: 0.6459, Val Acc: 0.6465
Epoch 44/100, Loss: 0.5664, Acc: 0.6937, Val Loss: 0.6369, Val Acc: 0.6624
Epoch 45/100, Loss: 0.5663, Acc: 0.6953, Val Loss: 0.6326, Val Acc: 0.6683
Epoch 46/100, Loss: 0.5655, Acc: 0.6946, Val Loss: 0.6441, Val Acc: 0.6535
Epoch 47/100, Loss: 0.5655, Acc: 0.6951, Val Loss: 0.6382, Val Acc: 0.6620
Epoch 48/100, Loss: 0.5657, Acc: 0.6956, Val Loss: 0.6388, Val Acc: 0.6561
Epoch 49/100, Loss: 0.5655, Acc: 0.6960, Val Loss: 0.6333, Val Acc: 0.6712
Epoch 50/100, Loss: 0.5649, Acc: 0.6956, Val Loss: 0.6315, Val Acc: 0.6613
Epoch 51/100, Loss: 0.5651, Acc: 0.6966, Val Loss: 0.6432, Val Acc: 0.6690
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5644, Acc: 0.6949, Val Loss: 0.6334, Val Acc: 0.6694
Epoch 53/100, Loss: 0.5642, Acc: 0.6953, Val Loss: 0.6330, Val Acc: 0.6664
Epoch 54/100, Loss: 0.5643, Acc: 0.6970, Val Loss: 0.6361, Val Acc: 0.6631
Epoch 55/100, Loss: 0.5642, Acc: 0.6953, Val Loss: 0.6411, Val Acc: 0.6557
Epoch 56/100, Loss: 0.5638, Acc: 0.6969, Val Loss: 0.6461, Val Acc: 0.6613
Epoch 57/100, Loss: 0.5640, Acc: 0.6960, Val Loss: 0.6384, Val Acc: 0.6605
Epoch 58/100, Loss: 0.5638, Acc: 0.6967, Val Loss: 0.6386, Val Acc: 0.6638
Epoch 59/100, Loss: 0.5637, Acc: 0.6988, Val Loss: 0.6387, Val Acc: 0.6591
Epoch 60/100, Loss: 0.5637, Acc: 0.6952, Val Loss: 0.6430, Val Acc: 0.6580
Epoch 61/100, Loss: 0.5633, Acc: 0.6994, Val Loss: 0.6338, Val Acc: 0.6679
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5632, Acc: 0.6973, Val Loss: 0.6381, Val Acc: 0.6649
Epoch 63/100, Loss: 0.5633, Acc: 0.6977, Val Loss: 0.6376, Val Acc: 0.6646
Epoch 64/100, Loss: 0.5630, Acc: 0.6979, Val Loss: 0.6439, Val Acc: 0.6620
Epoch 65/100, Loss: 0.5632, Acc: 0.6972, Val Loss: 0.6401, Val Acc: 0.6668
Epoch 66/100, Loss: 0.5631, Acc: 0.6972, Val Loss: 0.6411, Val Acc: 0.6642
Epoch 67/100, Loss: 0.5630, Acc: 0.6961, Val Loss: 0.6362, Val Acc: 0.6646
Epoch 68/100, Loss: 0.5629, Acc: 0.6981, Val Loss: 0.6412, Val Acc: 0.6649
Epoch 69/100, Loss: 0.5629, Acc: 0.6978, Val Loss: 0.6420, Val Acc: 0.6646
Epoch 70/100, Loss: 0.5628, Acc: 0.6976, Val Loss: 0.6399, Val Acc: 0.6649
Epoch 71/100, Loss: 0.5628, Acc: 0.6982, Val Loss: 0.6360, Val Acc: 0.6664
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5626, Acc: 0.6993, Val Loss: 0.6400, Val Acc: 0.6653
Epoch 73/100, Loss: 0.5625, Acc: 0.6991, Val Loss: 0.6422, Val Acc: 0.6657
Epoch 74/100, Loss: 0.5625, Acc: 0.6975, Val Loss: 0.6386, Val Acc: 0.6635
Epoch 75/100, Loss: 0.5625, Acc: 0.6988, Val Loss: 0.6394, Val Acc: 0.6638
Epoch 76/100, Loss: 0.5625, Acc: 0.6992, Val Loss: 0.6369, Val Acc: 0.6649
Epoch 77/100, Loss: 0.5625, Acc: 0.6999, Val Loss: 0.6391, Val Acc: 0.6642
Epoch 78/100, Loss: 0.5624, Acc: 0.6993, Val Loss: 0.6378, Val Acc: 0.6646
Epoch 79/100, Loss: 0.5623, Acc: 0.7005, Val Loss: 0.6381, Val Acc: 0.6635
Epoch 80/100, Loss: 0.5624, Acc: 0.6992, Val Loss: 0.6376, Val Acc: 0.6661
Epoch 81/100, Loss: 0.5623, Acc: 0.6992, Val Loss: 0.6376, Val Acc: 0.6646
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5623, Acc: 0.6992, Val Loss: 0.6380, Val Acc: 0.6635
Epoch 83/100, Loss: 0.5623, Acc: 0.6989, Val Loss: 0.6403, Val Acc: 0.6638
Epoch 84/100, Loss: 0.5622, Acc: 0.6984, Val Loss: 0.6386, Val Acc: 0.6649
Epoch 85/100, Loss: 0.5621, Acc: 0.6989, Val Loss: 0.6372, Val Acc: 0.6649
Epoch 86/100, Loss: 0.5622, Acc: 0.6986, Val Loss: 0.6381, Val Acc: 0.6646
Epoch 87/100, Loss: 0.5621, Acc: 0.7005, Val Loss: 0.6397, Val Acc: 0.6635
Epoch 88/100, Loss: 0.5623, Acc: 0.6996, Val Loss: 0.6405, Val Acc: 0.6627
Epoch 89/100, Loss: 0.5621, Acc: 0.6997, Val Loss: 0.6370, Val Acc: 0.6646
Epoch 90/100, Loss: 0.5621, Acc: 0.6992, Val Loss: 0.6381, Val Acc: 0.6646
Epoch 91/100, Loss: 0.5619, Acc: 0.6971, Val Loss: 0.6414, Val Acc: 0.6642
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5620, Acc: 0.7015, Val Loss: 0.6377, Val Acc: 0.6638
Epoch 93/100, Loss: 0.5619, Acc: 0.6992, Val Loss: 0.6391, Val Acc: 0.6646
Epoch 94/100, Loss: 0.5619, Acc: 0.6992, Val Loss: 0.6381, Val Acc: 0.6635
Epoch 95/100, Loss: 0.5620, Acc: 0.6977, Val Loss: 0.6393, Val Acc: 0.6631
Epoch 96/100, Loss: 0.5619, Acc: 0.6993, Val Loss: 0.6386, Val Acc: 0.6646
Epoch 97/100, Loss: 0.5618, Acc: 0.7001, Val Loss: 0.6370, Val Acc: 0.6627
Epoch 98/100, Loss: 0.5618, Acc: 0.6994, Val Loss: 0.6374, Val Acc: 0.6624
Epoch 99/100, Loss: 0.5618, Acc: 0.6997, Val Loss: 0.6419, Val Acc: 0.6638
Epoch 100/100, Loss: 0.5618, Acc: 0.7000, Val Loss: 0.6389, Val Acc: 0.6646

##############################
Resultados para principal:  033  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5 
 {'training': [0.5617811425331104, 0.6999816108863552, 0.7198947581461242, 0.6543414275202355, 0.6855545918859015], 'validate': [0.6389419970124267, 0.664580265095729, 0.660187185025198, 0.6762536873156342, 0.6681238615664845], 'test': [0.6517424608270327, 0.607773851590106, 0.6123456790123457, 0.5849056603773585, 0.5983112183353438]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  026  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  026  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  026  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6879, Acc: 0.5555, Val Loss: 0.6804, Val Acc: 0.5711
Mejor modelo guardado con Val Loss: 0.6804
Epoch 2/100, Loss: 0.6783, Acc: 0.5887, Val Loss: 0.6755, Val Acc: 0.6193
Mejor modelo guardado con Val Loss: 0.6755
Epoch 3/100, Loss: 0.6704, Acc: 0.6110, Val Loss: 0.6710, Val Acc: 0.5394
Mejor modelo guardado con Val Loss: 0.6710
Epoch 4/100, Loss: 0.6593, Acc: 0.6227, Val Loss: 0.6717, Val Acc: 0.5306
Epoch 5/100, Loss: 0.6513, Acc: 0.6318, Val Loss: 0.6851, Val Acc: 0.5228
Epoch 6/100, Loss: 0.6414, Acc: 0.6421, Val Loss: 0.6484, Val Acc: 0.5902
Mejor modelo guardado con Val Loss: 0.6484
Epoch 7/100, Loss: 0.6386, Acc: 0.6287, Val Loss: 0.6504, Val Acc: 0.5788
Epoch 8/100, Loss: 0.6361, Acc: 0.6430, Val Loss: 0.6741, Val Acc: 0.5166
Epoch 9/100, Loss: 0.6275, Acc: 0.6527, Val Loss: 0.6697, Val Acc: 0.5379
Epoch 10/100, Loss: 0.6265, Acc: 0.6562, Val Loss: 0.6677, Val Acc: 0.5740
Epoch 11/100, Loss: 0.6177, Acc: 0.6605, Val Loss: 0.6716, Val Acc: 0.5571
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6156, Acc: 0.6621, Val Loss: 0.6842, Val Acc: 0.5136
Epoch 13/100, Loss: 0.6121, Acc: 0.6657, Val Loss: 0.6766, Val Acc: 0.5420
Epoch 14/100, Loss: 0.6117, Acc: 0.6617, Val Loss: 0.6913, Val Acc: 0.5096
Epoch 15/100, Loss: 0.6080, Acc: 0.6685, Val Loss: 0.7022, Val Acc: 0.4982
Epoch 16/100, Loss: 0.6095, Acc: 0.6644, Val Loss: 0.6964, Val Acc: 0.5390
Epoch 17/100, Loss: 0.6079, Acc: 0.6651, Val Loss: 0.7019, Val Acc: 0.4963
Epoch 18/100, Loss: 0.6083, Acc: 0.6625, Val Loss: 0.6776, Val Acc: 0.5225
Epoch 19/100, Loss: 0.6050, Acc: 0.6680, Val Loss: 0.6876, Val Acc: 0.5018
Epoch 20/100, Loss: 0.6035, Acc: 0.6707, Val Loss: 0.6821, Val Acc: 0.5368
Epoch 21/100, Loss: 0.6014, Acc: 0.6700, Val Loss: 0.7006, Val Acc: 0.4831
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5993, Acc: 0.6708, Val Loss: 0.6937, Val Acc: 0.4937
Epoch 23/100, Loss: 0.5978, Acc: 0.6743, Val Loss: 0.7043, Val Acc: 0.4867
Epoch 24/100, Loss: 0.5986, Acc: 0.6678, Val Loss: 0.7134, Val Acc: 0.4838
Epoch 25/100, Loss: 0.5982, Acc: 0.6708, Val Loss: 0.7067, Val Acc: 0.5037
Epoch 26/100, Loss: 0.5965, Acc: 0.6766, Val Loss: 0.7116, Val Acc: 0.4963
Epoch 27/100, Loss: 0.5967, Acc: 0.6762, Val Loss: 0.7125, Val Acc: 0.4886
Epoch 28/100, Loss: 0.5948, Acc: 0.6785, Val Loss: 0.7095, Val Acc: 0.4934
Epoch 29/100, Loss: 0.5940, Acc: 0.6734, Val Loss: 0.7320, Val Acc: 0.4720
Epoch 30/100, Loss: 0.5945, Acc: 0.6735, Val Loss: 0.7009, Val Acc: 0.5180
Epoch 31/100, Loss: 0.5936, Acc: 0.6772, Val Loss: 0.7112, Val Acc: 0.4923
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5924, Acc: 0.6793, Val Loss: 0.7162, Val Acc: 0.4993
Epoch 33/100, Loss: 0.5924, Acc: 0.6806, Val Loss: 0.7158, Val Acc: 0.4882
Epoch 34/100, Loss: 0.5917, Acc: 0.6768, Val Loss: 0.7153, Val Acc: 0.4963
Epoch 35/100, Loss: 0.5913, Acc: 0.6798, Val Loss: 0.7234, Val Acc: 0.4886
Epoch 36/100, Loss: 0.5917, Acc: 0.6793, Val Loss: 0.7020, Val Acc: 0.5015
Epoch 37/100, Loss: 0.5912, Acc: 0.6812, Val Loss: 0.7142, Val Acc: 0.4904
Epoch 38/100, Loss: 0.5909, Acc: 0.6761, Val Loss: 0.7182, Val Acc: 0.4904
Epoch 39/100, Loss: 0.5914, Acc: 0.6789, Val Loss: 0.7160, Val Acc: 0.4937
Epoch 40/100, Loss: 0.5906, Acc: 0.6806, Val Loss: 0.7123, Val Acc: 0.4915
Epoch 41/100, Loss: 0.5906, Acc: 0.6817, Val Loss: 0.7150, Val Acc: 0.4890
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5894, Acc: 0.6802, Val Loss: 0.7234, Val Acc: 0.4790
Epoch 43/100, Loss: 0.5893, Acc: 0.6823, Val Loss: 0.7160, Val Acc: 0.4860
Epoch 44/100, Loss: 0.5892, Acc: 0.6826, Val Loss: 0.7213, Val Acc: 0.4838
Epoch 45/100, Loss: 0.5890, Acc: 0.6834, Val Loss: 0.7179, Val Acc: 0.4864
Epoch 46/100, Loss: 0.5884, Acc: 0.6792, Val Loss: 0.7149, Val Acc: 0.5103
Epoch 47/100, Loss: 0.5891, Acc: 0.6827, Val Loss: 0.7214, Val Acc: 0.4842
Epoch 48/100, Loss: 0.5889, Acc: 0.6832, Val Loss: 0.7129, Val Acc: 0.4908
Epoch 49/100, Loss: 0.5889, Acc: 0.6834, Val Loss: 0.7181, Val Acc: 0.4842
Epoch 50/100, Loss: 0.5884, Acc: 0.6832, Val Loss: 0.7150, Val Acc: 0.4897
Epoch 51/100, Loss: 0.5885, Acc: 0.6810, Val Loss: 0.7194, Val Acc: 0.4867
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5883, Acc: 0.6822, Val Loss: 0.7152, Val Acc: 0.4845
Epoch 53/100, Loss: 0.5876, Acc: 0.6835, Val Loss: 0.7178, Val Acc: 0.4845
Epoch 54/100, Loss: 0.5878, Acc: 0.6825, Val Loss: 0.7217, Val Acc: 0.4827
Epoch 55/100, Loss: 0.5875, Acc: 0.6812, Val Loss: 0.7181, Val Acc: 0.4867
Epoch 56/100, Loss: 0.5874, Acc: 0.6839, Val Loss: 0.7208, Val Acc: 0.4831
Epoch 57/100, Loss: 0.5877, Acc: 0.6801, Val Loss: 0.7180, Val Acc: 0.4845
Epoch 58/100, Loss: 0.5875, Acc: 0.6816, Val Loss: 0.7206, Val Acc: 0.4845
Epoch 59/100, Loss: 0.5875, Acc: 0.6849, Val Loss: 0.7176, Val Acc: 0.4856
Epoch 60/100, Loss: 0.5876, Acc: 0.6815, Val Loss: 0.7205, Val Acc: 0.4864
Epoch 61/100, Loss: 0.5871, Acc: 0.6831, Val Loss: 0.7161, Val Acc: 0.4930
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5869, Acc: 0.6821, Val Loss: 0.7196, Val Acc: 0.4860
Epoch 63/100, Loss: 0.5869, Acc: 0.6818, Val Loss: 0.7202, Val Acc: 0.4860
Epoch 64/100, Loss: 0.5868, Acc: 0.6826, Val Loss: 0.7185, Val Acc: 0.4860
Epoch 65/100, Loss: 0.5868, Acc: 0.6826, Val Loss: 0.7164, Val Acc: 0.4904
Epoch 66/100, Loss: 0.5869, Acc: 0.6813, Val Loss: 0.7205, Val Acc: 0.4842
Epoch 67/100, Loss: 0.5868, Acc: 0.6829, Val Loss: 0.7177, Val Acc: 0.4901
Epoch 68/100, Loss: 0.5866, Acc: 0.6813, Val Loss: 0.7208, Val Acc: 0.4849
Epoch 69/100, Loss: 0.5868, Acc: 0.6834, Val Loss: 0.7208, Val Acc: 0.4853
Epoch 70/100, Loss: 0.5867, Acc: 0.6834, Val Loss: 0.7202, Val Acc: 0.4831
Epoch 71/100, Loss: 0.5866, Acc: 0.6830, Val Loss: 0.7162, Val Acc: 0.4934
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5867, Acc: 0.6833, Val Loss: 0.7183, Val Acc: 0.4849
Epoch 73/100, Loss: 0.5866, Acc: 0.6837, Val Loss: 0.7184, Val Acc: 0.4853
Epoch 74/100, Loss: 0.5865, Acc: 0.6822, Val Loss: 0.7186, Val Acc: 0.4831
Epoch 75/100, Loss: 0.5865, Acc: 0.6812, Val Loss: 0.7175, Val Acc: 0.4886
Epoch 76/100, Loss: 0.5864, Acc: 0.6827, Val Loss: 0.7194, Val Acc: 0.4838
Epoch 77/100, Loss: 0.5864, Acc: 0.6830, Val Loss: 0.7193, Val Acc: 0.4845
Epoch 78/100, Loss: 0.5864, Acc: 0.6827, Val Loss: 0.7210, Val Acc: 0.4842
Epoch 79/100, Loss: 0.5865, Acc: 0.6833, Val Loss: 0.7200, Val Acc: 0.4823
Epoch 80/100, Loss: 0.5864, Acc: 0.6825, Val Loss: 0.7184, Val Acc: 0.4864
Epoch 81/100, Loss: 0.5864, Acc: 0.6824, Val Loss: 0.7195, Val Acc: 0.4842
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5863, Acc: 0.6836, Val Loss: 0.7182, Val Acc: 0.4867
Epoch 83/100, Loss: 0.5863, Acc: 0.6834, Val Loss: 0.7192, Val Acc: 0.4845
Epoch 84/100, Loss: 0.5863, Acc: 0.6820, Val Loss: 0.7187, Val Acc: 0.4853
Epoch 85/100, Loss: 0.5863, Acc: 0.6829, Val Loss: 0.7189, Val Acc: 0.4849
Epoch 86/100, Loss: 0.5862, Acc: 0.6827, Val Loss: 0.7175, Val Acc: 0.4886
Epoch 87/100, Loss: 0.5863, Acc: 0.6832, Val Loss: 0.7186, Val Acc: 0.4864
Epoch 88/100, Loss: 0.5863, Acc: 0.6838, Val Loss: 0.7199, Val Acc: 0.4831
Epoch 89/100, Loss: 0.5863, Acc: 0.6822, Val Loss: 0.7197, Val Acc: 0.4849
Epoch 90/100, Loss: 0.5861, Acc: 0.6825, Val Loss: 0.7181, Val Acc: 0.4875
Epoch 91/100, Loss: 0.5862, Acc: 0.6821, Val Loss: 0.7184, Val Acc: 0.4871
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5862, Acc: 0.6814, Val Loss: 0.7205, Val Acc: 0.4823
Epoch 93/100, Loss: 0.5860, Acc: 0.6837, Val Loss: 0.7188, Val Acc: 0.4856
Epoch 94/100, Loss: 0.5860, Acc: 0.6831, Val Loss: 0.7205, Val Acc: 0.4827
Epoch 95/100, Loss: 0.5860, Acc: 0.6831, Val Loss: 0.7181, Val Acc: 0.4882
Epoch 96/100, Loss: 0.5860, Acc: 0.6826, Val Loss: 0.7196, Val Acc: 0.4834
Epoch 97/100, Loss: 0.5859, Acc: 0.6832, Val Loss: 0.7195, Val Acc: 0.4853
Epoch 98/100, Loss: 0.5860, Acc: 0.6828, Val Loss: 0.7197, Val Acc: 0.4838
Epoch 99/100, Loss: 0.5859, Acc: 0.6834, Val Loss: 0.7207, Val Acc: 0.4849
Epoch 100/100, Loss: 0.5859, Acc: 0.6838, Val Loss: 0.7188, Val Acc: 0.4856

##############################
Resultados para principal:  026  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5 
 {'training': [0.5859328260663766, 0.6837991908789997, 0.6651232015875641, 0.7398822663723326, 0.7005138030131499], 'validate': [0.7188061697538509, 0.48564064801178203, 0.48379446640316204, 0.45132743362831856, 0.46699732926363985], 'test': [0.7252959156477893, 0.5020612485276796, 0.5011526048870447, 0.6409198113207547, 0.56248382923674]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  110  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  110  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  110  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5636, Acc: 0.7434, Val Loss: 0.6343, Val Acc: 0.6609
Mejor modelo guardado con Val Loss: 0.6343
Epoch 2/100, Loss: 0.4713, Acc: 0.7840, Val Loss: 0.6504, Val Acc: 0.6712
Epoch 3/100, Loss: 0.4532, Acc: 0.7883, Val Loss: 0.6465, Val Acc: 0.6543
Epoch 4/100, Loss: 0.4593, Acc: 0.7883, Val Loss: 0.6546, Val Acc: 0.6406
Epoch 5/100, Loss: 0.4528, Acc: 0.7879, Val Loss: 0.6426, Val Acc: 0.6594
Epoch 6/100, Loss: 0.4383, Acc: 0.7988, Val Loss: 0.6792, Val Acc: 0.6256
Epoch 7/100, Loss: 0.4410, Acc: 0.7890, Val Loss: 0.6666, Val Acc: 0.6535
Epoch 8/100, Loss: 0.4306, Acc: 0.8039, Val Loss: 0.6854, Val Acc: 0.6410
Epoch 9/100, Loss: 0.4260, Acc: 0.7997, Val Loss: 0.6614, Val Acc: 0.6568
Epoch 10/100, Loss: 0.4219, Acc: 0.8026, Val Loss: 0.6842, Val Acc: 0.6506
Epoch 11/100, Loss: 0.4149, Acc: 0.8105, Val Loss: 0.6731, Val Acc: 0.6694
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4081, Acc: 0.8097, Val Loss: 0.7312, Val Acc: 0.6314
Epoch 13/100, Loss: 0.4049, Acc: 0.8167, Val Loss: 0.6862, Val Acc: 0.6524
Epoch 14/100, Loss: 0.4025, Acc: 0.8182, Val Loss: 0.6863, Val Acc: 0.6613
Epoch 15/100, Loss: 0.4038, Acc: 0.8153, Val Loss: 0.7582, Val Acc: 0.6406
Epoch 16/100, Loss: 0.3994, Acc: 0.8153, Val Loss: 0.6831, Val Acc: 0.6281
Epoch 17/100, Loss: 0.3990, Acc: 0.8144, Val Loss: 0.6907, Val Acc: 0.6624
Epoch 18/100, Loss: 0.3975, Acc: 0.8162, Val Loss: 0.6854, Val Acc: 0.6638
Epoch 19/100, Loss: 0.4045, Acc: 0.8129, Val Loss: 0.6801, Val Acc: 0.6546
Epoch 20/100, Loss: 0.3994, Acc: 0.8177, Val Loss: 0.6895, Val Acc: 0.6683
Epoch 21/100, Loss: 0.3997, Acc: 0.8166, Val Loss: 0.6908, Val Acc: 0.6627
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3946, Acc: 0.8215, Val Loss: 0.7259, Val Acc: 0.6296
Epoch 23/100, Loss: 0.3931, Acc: 0.8218, Val Loss: 0.7056, Val Acc: 0.6653
Epoch 24/100, Loss: 0.3965, Acc: 0.8205, Val Loss: 0.7138, Val Acc: 0.6510
Epoch 25/100, Loss: 0.3943, Acc: 0.8196, Val Loss: 0.7068, Val Acc: 0.6583
Epoch 26/100, Loss: 0.3913, Acc: 0.8219, Val Loss: 0.7380, Val Acc: 0.6377
Epoch 27/100, Loss: 0.3944, Acc: 0.8201, Val Loss: 0.7665, Val Acc: 0.6432
Epoch 28/100, Loss: 0.3919, Acc: 0.8221, Val Loss: 0.7304, Val Acc: 0.6469
Epoch 29/100, Loss: 0.3905, Acc: 0.8225, Val Loss: 0.7162, Val Acc: 0.6576
Epoch 30/100, Loss: 0.3916, Acc: 0.8188, Val Loss: 0.7232, Val Acc: 0.6296
Epoch 31/100, Loss: 0.3918, Acc: 0.8230, Val Loss: 0.7107, Val Acc: 0.6565
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3890, Acc: 0.8202, Val Loss: 0.7226, Val Acc: 0.6484
Epoch 33/100, Loss: 0.3880, Acc: 0.8209, Val Loss: 0.7087, Val Acc: 0.6557
Epoch 34/100, Loss: 0.3889, Acc: 0.8223, Val Loss: 0.7309, Val Acc: 0.6484
Epoch 35/100, Loss: 0.3872, Acc: 0.8257, Val Loss: 0.6976, Val Acc: 0.6528
Epoch 36/100, Loss: 0.3865, Acc: 0.8239, Val Loss: 0.7210, Val Acc: 0.6440
Epoch 37/100, Loss: 0.3869, Acc: 0.8222, Val Loss: 0.6943, Val Acc: 0.6638
Epoch 38/100, Loss: 0.3869, Acc: 0.8217, Val Loss: 0.7095, Val Acc: 0.6440
Epoch 39/100, Loss: 0.3864, Acc: 0.8222, Val Loss: 0.7027, Val Acc: 0.6605
Epoch 40/100, Loss: 0.3853, Acc: 0.8236, Val Loss: 0.7025, Val Acc: 0.6591
Epoch 41/100, Loss: 0.3858, Acc: 0.8248, Val Loss: 0.7432, Val Acc: 0.6554
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3855, Acc: 0.8252, Val Loss: 0.7186, Val Acc: 0.6642
Epoch 43/100, Loss: 0.3843, Acc: 0.8241, Val Loss: 0.7325, Val Acc: 0.6605
Epoch 44/100, Loss: 0.3851, Acc: 0.8236, Val Loss: 0.7216, Val Acc: 0.6535
Epoch 45/100, Loss: 0.3835, Acc: 0.8240, Val Loss: 0.7003, Val Acc: 0.6572
Epoch 46/100, Loss: 0.3834, Acc: 0.8239, Val Loss: 0.7177, Val Acc: 0.6539
Epoch 47/100, Loss: 0.3839, Acc: 0.8244, Val Loss: 0.7256, Val Acc: 0.6473
Epoch 48/100, Loss: 0.3832, Acc: 0.8242, Val Loss: 0.7178, Val Acc: 0.6616
Epoch 49/100, Loss: 0.3834, Acc: 0.8247, Val Loss: 0.7172, Val Acc: 0.6532
Epoch 50/100, Loss: 0.3829, Acc: 0.8252, Val Loss: 0.7198, Val Acc: 0.6436
Epoch 51/100, Loss: 0.3827, Acc: 0.8223, Val Loss: 0.7258, Val Acc: 0.6554
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3821, Acc: 0.8248, Val Loss: 0.7193, Val Acc: 0.6532
Epoch 53/100, Loss: 0.3818, Acc: 0.8252, Val Loss: 0.7238, Val Acc: 0.6495
Epoch 54/100, Loss: 0.3815, Acc: 0.8244, Val Loss: 0.7157, Val Acc: 0.6587
Epoch 55/100, Loss: 0.3818, Acc: 0.8257, Val Loss: 0.7157, Val Acc: 0.6565
Epoch 56/100, Loss: 0.3814, Acc: 0.8240, Val Loss: 0.7183, Val Acc: 0.6583
Epoch 57/100, Loss: 0.3815, Acc: 0.8264, Val Loss: 0.7261, Val Acc: 0.6513
Epoch 58/100, Loss: 0.3814, Acc: 0.8254, Val Loss: 0.7101, Val Acc: 0.6627
Epoch 59/100, Loss: 0.3816, Acc: 0.8264, Val Loss: 0.7181, Val Acc: 0.6583
Epoch 60/100, Loss: 0.3815, Acc: 0.8241, Val Loss: 0.7181, Val Acc: 0.6543
Epoch 61/100, Loss: 0.3814, Acc: 0.8233, Val Loss: 0.7313, Val Acc: 0.6484
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3812, Acc: 0.8259, Val Loss: 0.7282, Val Acc: 0.6502
Epoch 63/100, Loss: 0.3808, Acc: 0.8244, Val Loss: 0.7225, Val Acc: 0.6524
Epoch 64/100, Loss: 0.3808, Acc: 0.8250, Val Loss: 0.7176, Val Acc: 0.6550
Epoch 65/100, Loss: 0.3807, Acc: 0.8251, Val Loss: 0.7173, Val Acc: 0.6557
Epoch 66/100, Loss: 0.3805, Acc: 0.8251, Val Loss: 0.7200, Val Acc: 0.6539
Epoch 67/100, Loss: 0.3806, Acc: 0.8247, Val Loss: 0.7229, Val Acc: 0.6550
Epoch 68/100, Loss: 0.3804, Acc: 0.8251, Val Loss: 0.7238, Val Acc: 0.6550
Epoch 69/100, Loss: 0.3806, Acc: 0.8253, Val Loss: 0.7236, Val Acc: 0.6543
Epoch 70/100, Loss: 0.3805, Acc: 0.8255, Val Loss: 0.7282, Val Acc: 0.6513
Epoch 71/100, Loss: 0.3804, Acc: 0.8249, Val Loss: 0.7251, Val Acc: 0.6513
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3802, Acc: 0.8255, Val Loss: 0.7207, Val Acc: 0.6572
Epoch 73/100, Loss: 0.3801, Acc: 0.8253, Val Loss: 0.7179, Val Acc: 0.6572
Epoch 74/100, Loss: 0.3802, Acc: 0.8253, Val Loss: 0.7230, Val Acc: 0.6539
Epoch 75/100, Loss: 0.3802, Acc: 0.8244, Val Loss: 0.7220, Val Acc: 0.6557
Epoch 76/100, Loss: 0.3803, Acc: 0.8253, Val Loss: 0.7207, Val Acc: 0.6565
Epoch 77/100, Loss: 0.3801, Acc: 0.8257, Val Loss: 0.7215, Val Acc: 0.6557
Epoch 78/100, Loss: 0.3800, Acc: 0.8259, Val Loss: 0.7243, Val Acc: 0.6510
Epoch 79/100, Loss: 0.3801, Acc: 0.8249, Val Loss: 0.7222, Val Acc: 0.6554
Epoch 80/100, Loss: 0.3800, Acc: 0.8259, Val Loss: 0.7222, Val Acc: 0.6550
Epoch 81/100, Loss: 0.3800, Acc: 0.8254, Val Loss: 0.7220, Val Acc: 0.6543
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3800, Acc: 0.8251, Val Loss: 0.7199, Val Acc: 0.6565
Epoch 83/100, Loss: 0.3799, Acc: 0.8248, Val Loss: 0.7178, Val Acc: 0.6561
Epoch 84/100, Loss: 0.3799, Acc: 0.8259, Val Loss: 0.7220, Val Acc: 0.6554
Epoch 85/100, Loss: 0.3799, Acc: 0.8255, Val Loss: 0.7214, Val Acc: 0.6557
Epoch 86/100, Loss: 0.3800, Acc: 0.8255, Val Loss: 0.7220, Val Acc: 0.6554
Epoch 87/100, Loss: 0.3799, Acc: 0.8250, Val Loss: 0.7213, Val Acc: 0.6554
Epoch 88/100, Loss: 0.3799, Acc: 0.8258, Val Loss: 0.7209, Val Acc: 0.6557
Epoch 89/100, Loss: 0.3798, Acc: 0.8248, Val Loss: 0.7232, Val Acc: 0.6528
Epoch 90/100, Loss: 0.3798, Acc: 0.8256, Val Loss: 0.7219, Val Acc: 0.6568
Epoch 91/100, Loss: 0.3797, Acc: 0.8254, Val Loss: 0.7227, Val Acc: 0.6557
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3796, Acc: 0.8259, Val Loss: 0.7226, Val Acc: 0.6561
Epoch 93/100, Loss: 0.3796, Acc: 0.8258, Val Loss: 0.7200, Val Acc: 0.6568
Epoch 94/100, Loss: 0.3795, Acc: 0.8259, Val Loss: 0.7252, Val Acc: 0.6543
Epoch 95/100, Loss: 0.3795, Acc: 0.8262, Val Loss: 0.7253, Val Acc: 0.6521
Epoch 96/100, Loss: 0.3794, Acc: 0.8263, Val Loss: 0.7218, Val Acc: 0.6568
Epoch 97/100, Loss: 0.3795, Acc: 0.8257, Val Loss: 0.7251, Val Acc: 0.6528
Epoch 98/100, Loss: 0.3796, Acc: 0.8259, Val Loss: 0.7268, Val Acc: 0.6506
Epoch 99/100, Loss: 0.3794, Acc: 0.8256, Val Loss: 0.7227, Val Acc: 0.6576
Epoch 100/100, Loss: 0.3794, Acc: 0.8256, Val Loss: 0.7216, Val Acc: 0.6565

##############################
Resultados para principal:  110  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  5 
 {'training': [0.37941271780211505, 0.8255792570798087, 0.8193466883234073, 0.8351729212656365, 0.8271841122346725], 'validate': [0.7215645013507023, 0.656480117820324, 0.660105980317941, 0.6430678466076696, 0.6514755323122898], 'test': [0.5018798653726224, 0.7924028268551236, 0.7682728749323227, 0.8366745283018868, 0.8010160880609652]}

##############################
Resultados para window:  5 
 {'064:060:028:033:026:110': {'training': [0.5496446349551547, 0.694372931224715, 0.6361175560711524, 0.9078366445916115, 0.7480673033196907], 'validate': [0.7270892491174299, 0.5342415316642121, 0.5193534666099532, 0.9004424778761062, 0.658753709198813], 'test': [0.7637698782814873, 0.30241460541813897, 0.3519577650681918, 0.4716981132075472, 0.4031242126480222]}, '060:064:028:033:026:110': {'training': [0.49151333823454824, 0.7496322177271055, 0.8209131771942276, 0.6383370125091979, 0.7182034564834937], 'validate': [0.7852163675219513, 0.48379970544919, 0.4201388888888889, 0.08923303834808259, 0.14720194647201945], 'test': [0.7885431586592285, 0.4366902237926973, 0.46389351081530783, 0.8219339622641509, 0.5930653052542012]}, '028:064:060:033:026:110': {'training': [0.28788046887930197, 0.8737587348289813, 0.8916522074416812, 0.8508094186902134, 0.8707521415795915], 'validate': [0.36848759180108126, 0.8637702503681886, 0.9833333333333333, 0.7396755162241888, 0.8442760942760943], 'test': [0.7532972903163345, 0.6663722025912838, 0.8893499308437067, 0.37912735849056606, 0.5316246382802811]}, '033:064:060:028:026:110': {'training': [0.5617811425331104, 0.6999816108863552, 0.7198947581461242, 0.6543414275202355, 0.6855545918859015], 'validate': [0.6389419970124267, 0.664580265095729, 0.660187185025198, 0.6762536873156342, 0.6681238615664845], 'test': [0.6517424608270327, 0.607773851590106, 0.6123456790123457, 0.5849056603773585, 0.5983112183353438]}, '026:064:060:028:033:110': {'training': [0.5859328260663766, 0.6837991908789997, 0.6651232015875641, 0.7398822663723326, 0.7005138030131499], 'validate': [0.7188061697538509, 0.48564064801178203, 0.48379446640316204, 0.45132743362831856, 0.46699732926363985], 'test': [0.7252959156477893, 0.5020612485276796, 0.5011526048870447, 0.6409198113207547, 0.56248382923674]}, '110:064:060:028:033:026': {'training': [0.37941271780211505, 0.8255792570798087, 0.8193466883234073, 0.8351729212656365, 0.8271841122346725], 'validate': [0.7215645013507023, 0.656480117820324, 0.660105980317941, 0.6430678466076696, 0.6514755323122898], 'test': [0.5018798653726224, 0.7924028268551236, 0.7682728749323227, 0.8366745283018868, 0.8010160880609652]}}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  104  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  104  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  104  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6911, Acc: 0.5315, Val Loss: 0.6808, Val Acc: 0.5383
Mejor modelo guardado con Val Loss: 0.6808
Epoch 2/100, Loss: 0.6883, Acc: 0.5558, Val Loss: 0.6657, Val Acc: 0.7614
Mejor modelo guardado con Val Loss: 0.6657
Epoch 3/100, Loss: 0.6835, Acc: 0.5777, Val Loss: 0.6620, Val Acc: 0.6469
Mejor modelo guardado con Val Loss: 0.6620
Epoch 4/100, Loss: 0.6830, Acc: 0.5681, Val Loss: 0.6611, Val Acc: 0.7235
Mejor modelo guardado con Val Loss: 0.6611
Epoch 5/100, Loss: 0.6814, Acc: 0.5829, Val Loss: 0.6517, Val Acc: 0.6683
Mejor modelo guardado con Val Loss: 0.6517
Epoch 6/100, Loss: 0.6761, Acc: 0.5822, Val Loss: 0.6691, Val Acc: 0.5434
Epoch 7/100, Loss: 0.6843, Acc: 0.5741, Val Loss: 0.6527, Val Acc: 0.7338
Epoch 8/100, Loss: 0.6773, Acc: 0.5858, Val Loss: 0.6126, Val Acc: 0.7231
Mejor modelo guardado con Val Loss: 0.6126
Epoch 9/100, Loss: 0.6726, Acc: 0.5811, Val Loss: 0.6222, Val Acc: 0.6841
Epoch 10/100, Loss: 0.6677, Acc: 0.5949, Val Loss: 0.6068, Val Acc: 0.7471
Mejor modelo guardado con Val Loss: 0.6068
Epoch 11/100, Loss: 0.6680, Acc: 0.5890, Val Loss: 0.6297, Val Acc: 0.5788
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6634, Acc: 0.6016, Val Loss: 0.6172, Val Acc: 0.6915
Epoch 13/100, Loss: 0.6640, Acc: 0.6005, Val Loss: 0.5835, Val Acc: 0.7710
Mejor modelo guardado con Val Loss: 0.5835
Epoch 14/100, Loss: 0.6617, Acc: 0.6071, Val Loss: 0.6235, Val Acc: 0.6664
Epoch 15/100, Loss: 0.6621, Acc: 0.6088, Val Loss: 0.6037, Val Acc: 0.7080
Epoch 16/100, Loss: 0.6623, Acc: 0.6046, Val Loss: 0.6110, Val Acc: 0.6668
Epoch 17/100, Loss: 0.6604, Acc: 0.6091, Val Loss: 0.5851, Val Acc: 0.7371
Epoch 18/100, Loss: 0.6617, Acc: 0.6066, Val Loss: 0.5869, Val Acc: 0.7220
Epoch 19/100, Loss: 0.6616, Acc: 0.6059, Val Loss: 0.5985, Val Acc: 0.7051
Epoch 20/100, Loss: 0.6607, Acc: 0.6065, Val Loss: 0.5904, Val Acc: 0.7169
Epoch 21/100, Loss: 0.6608, Acc: 0.6046, Val Loss: 0.5741, Val Acc: 0.7629
Mejor modelo guardado con Val Loss: 0.5741
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6592, Acc: 0.6115, Val Loss: 0.5726, Val Acc: 0.7588
Mejor modelo guardado con Val Loss: 0.5726
Epoch 23/100, Loss: 0.6599, Acc: 0.6093, Val Loss: 0.5804, Val Acc: 0.7345
Epoch 24/100, Loss: 0.6592, Acc: 0.6094, Val Loss: 0.6085, Val Acc: 0.6830
Epoch 25/100, Loss: 0.6600, Acc: 0.6056, Val Loss: 0.6074, Val Acc: 0.6915
Epoch 26/100, Loss: 0.6592, Acc: 0.6091, Val Loss: 0.5937, Val Acc: 0.7102
Epoch 27/100, Loss: 0.6599, Acc: 0.6045, Val Loss: 0.5641, Val Acc: 0.7688
Mejor modelo guardado con Val Loss: 0.5641
Epoch 28/100, Loss: 0.6589, Acc: 0.6103, Val Loss: 0.5805, Val Acc: 0.7286
Epoch 29/100, Loss: 0.6591, Acc: 0.6089, Val Loss: 0.5775, Val Acc: 0.7404
Epoch 30/100, Loss: 0.6599, Acc: 0.6085, Val Loss: 0.5993, Val Acc: 0.7036
Epoch 31/100, Loss: 0.6588, Acc: 0.6102, Val Loss: 0.5799, Val Acc: 0.7386
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6579, Acc: 0.6125, Val Loss: 0.5890, Val Acc: 0.7124
Epoch 33/100, Loss: 0.6576, Acc: 0.6126, Val Loss: 0.5886, Val Acc: 0.7128
Epoch 34/100, Loss: 0.6573, Acc: 0.6107, Val Loss: 0.5847, Val Acc: 0.7165
Epoch 35/100, Loss: 0.6574, Acc: 0.6124, Val Loss: 0.5697, Val Acc: 0.7566
Epoch 36/100, Loss: 0.6573, Acc: 0.6103, Val Loss: 0.6016, Val Acc: 0.6804
Epoch 37/100, Loss: 0.6579, Acc: 0.6114, Val Loss: 0.5881, Val Acc: 0.7139
Epoch 38/100, Loss: 0.6578, Acc: 0.6104, Val Loss: 0.5811, Val Acc: 0.7209
Epoch 39/100, Loss: 0.6566, Acc: 0.6146, Val Loss: 0.5907, Val Acc: 0.7062
Epoch 40/100, Loss: 0.6570, Acc: 0.6123, Val Loss: 0.6045, Val Acc: 0.6753
Epoch 41/100, Loss: 0.6572, Acc: 0.6127, Val Loss: 0.5865, Val Acc: 0.7091
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6566, Acc: 0.6121, Val Loss: 0.5854, Val Acc: 0.7135
Epoch 43/100, Loss: 0.6564, Acc: 0.6127, Val Loss: 0.5739, Val Acc: 0.7375
Epoch 44/100, Loss: 0.6564, Acc: 0.6137, Val Loss: 0.5796, Val Acc: 0.7231
Epoch 45/100, Loss: 0.6566, Acc: 0.6123, Val Loss: 0.5788, Val Acc: 0.7246
Epoch 46/100, Loss: 0.6563, Acc: 0.6146, Val Loss: 0.5789, Val Acc: 0.7246
Epoch 47/100, Loss: 0.6564, Acc: 0.6121, Val Loss: 0.5849, Val Acc: 0.7128
Epoch 48/100, Loss: 0.6563, Acc: 0.6105, Val Loss: 0.5822, Val Acc: 0.7183
Epoch 49/100, Loss: 0.6565, Acc: 0.6118, Val Loss: 0.5932, Val Acc: 0.6970
Epoch 50/100, Loss: 0.6563, Acc: 0.6133, Val Loss: 0.5912, Val Acc: 0.6977
Epoch 51/100, Loss: 0.6561, Acc: 0.6121, Val Loss: 0.5824, Val Acc: 0.7180
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6559, Acc: 0.6125, Val Loss: 0.5977, Val Acc: 0.6962
Epoch 53/100, Loss: 0.6561, Acc: 0.6126, Val Loss: 0.5816, Val Acc: 0.7172
Epoch 54/100, Loss: 0.6560, Acc: 0.6136, Val Loss: 0.5860, Val Acc: 0.7084
Epoch 55/100, Loss: 0.6559, Acc: 0.6141, Val Loss: 0.5906, Val Acc: 0.7047
Epoch 56/100, Loss: 0.6560, Acc: 0.6137, Val Loss: 0.5864, Val Acc: 0.7102
Epoch 57/100, Loss: 0.6560, Acc: 0.6145, Val Loss: 0.5863, Val Acc: 0.7084
Epoch 58/100, Loss: 0.6559, Acc: 0.6134, Val Loss: 0.5893, Val Acc: 0.7051
Epoch 59/100, Loss: 0.6559, Acc: 0.6128, Val Loss: 0.5806, Val Acc: 0.7209
Epoch 60/100, Loss: 0.6560, Acc: 0.6130, Val Loss: 0.5855, Val Acc: 0.7106
Epoch 61/100, Loss: 0.6560, Acc: 0.6132, Val Loss: 0.5840, Val Acc: 0.7113
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6558, Acc: 0.6136, Val Loss: 0.5848, Val Acc: 0.7113
Epoch 63/100, Loss: 0.6557, Acc: 0.6136, Val Loss: 0.5859, Val Acc: 0.7091
Epoch 64/100, Loss: 0.6558, Acc: 0.6130, Val Loss: 0.5834, Val Acc: 0.7124
Epoch 65/100, Loss: 0.6557, Acc: 0.6150, Val Loss: 0.5851, Val Acc: 0.7099
Epoch 66/100, Loss: 0.6557, Acc: 0.6141, Val Loss: 0.5850, Val Acc: 0.7106
Epoch 67/100, Loss: 0.6557, Acc: 0.6135, Val Loss: 0.5824, Val Acc: 0.7150
Epoch 68/100, Loss: 0.6557, Acc: 0.6136, Val Loss: 0.5852, Val Acc: 0.7095
Epoch 69/100, Loss: 0.6557, Acc: 0.6138, Val Loss: 0.5818, Val Acc: 0.7158
Epoch 70/100, Loss: 0.6557, Acc: 0.6145, Val Loss: 0.5847, Val Acc: 0.7110
Epoch 71/100, Loss: 0.6557, Acc: 0.6141, Val Loss: 0.5823, Val Acc: 0.7158
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6556, Acc: 0.6141, Val Loss: 0.5829, Val Acc: 0.7139
Epoch 73/100, Loss: 0.6557, Acc: 0.6135, Val Loss: 0.5837, Val Acc: 0.7124
Epoch 74/100, Loss: 0.6556, Acc: 0.6150, Val Loss: 0.5834, Val Acc: 0.7128
Epoch 75/100, Loss: 0.6556, Acc: 0.6150, Val Loss: 0.5848, Val Acc: 0.7095
Epoch 76/100, Loss: 0.6556, Acc: 0.6148, Val Loss: 0.5838, Val Acc: 0.7124
Epoch 77/100, Loss: 0.6556, Acc: 0.6144, Val Loss: 0.5842, Val Acc: 0.7113
Epoch 78/100, Loss: 0.6556, Acc: 0.6133, Val Loss: 0.5848, Val Acc: 0.7095
Epoch 79/100, Loss: 0.6556, Acc: 0.6145, Val Loss: 0.5846, Val Acc: 0.7099
Epoch 80/100, Loss: 0.6557, Acc: 0.6140, Val Loss: 0.5837, Val Acc: 0.7121
Epoch 81/100, Loss: 0.6556, Acc: 0.6143, Val Loss: 0.5829, Val Acc: 0.7135
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6555, Acc: 0.6150, Val Loss: 0.5846, Val Acc: 0.7099
Epoch 83/100, Loss: 0.6555, Acc: 0.6145, Val Loss: 0.5830, Val Acc: 0.7135
Epoch 84/100, Loss: 0.6555, Acc: 0.6153, Val Loss: 0.5843, Val Acc: 0.7106
Epoch 85/100, Loss: 0.6555, Acc: 0.6149, Val Loss: 0.5845, Val Acc: 0.7106
Epoch 86/100, Loss: 0.6556, Acc: 0.6144, Val Loss: 0.5837, Val Acc: 0.7121
Epoch 87/100, Loss: 0.6556, Acc: 0.6144, Val Loss: 0.5824, Val Acc: 0.7150
Epoch 88/100, Loss: 0.6556, Acc: 0.6143, Val Loss: 0.5833, Val Acc: 0.7135
Epoch 89/100, Loss: 0.6555, Acc: 0.6139, Val Loss: 0.5830, Val Acc: 0.7139
Epoch 90/100, Loss: 0.6556, Acc: 0.6139, Val Loss: 0.5833, Val Acc: 0.7124
Epoch 91/100, Loss: 0.6555, Acc: 0.6144, Val Loss: 0.5837, Val Acc: 0.7117
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6556, Acc: 0.6154, Val Loss: 0.5841, Val Acc: 0.7110
Epoch 93/100, Loss: 0.6555, Acc: 0.6145, Val Loss: 0.5832, Val Acc: 0.7124
Epoch 94/100, Loss: 0.6555, Acc: 0.6148, Val Loss: 0.5843, Val Acc: 0.7110
Epoch 95/100, Loss: 0.6555, Acc: 0.6137, Val Loss: 0.5826, Val Acc: 0.7132
Epoch 96/100, Loss: 0.6555, Acc: 0.6147, Val Loss: 0.5834, Val Acc: 0.7117
Epoch 97/100, Loss: 0.6555, Acc: 0.6148, Val Loss: 0.5850, Val Acc: 0.7084
Epoch 98/100, Loss: 0.6554, Acc: 0.6145, Val Loss: 0.5814, Val Acc: 0.7169
Epoch 99/100, Loss: 0.6555, Acc: 0.6146, Val Loss: 0.5829, Val Acc: 0.7121
Epoch 100/100, Loss: 0.6554, Acc: 0.6142, Val Loss: 0.5830, Val Acc: 0.7124

##############################
Resultados para principal:  104  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5 
 {'training': [0.6554273192651924, 0.6141963957337256, 0.5941676792223572, 0.7196467991169978, 0.6509151414309484], 'validate': [0.5829831763755443, 0.7124447717231223, 0.7918781725888325, 0.5752212389380531, 0.6663818880820163], 'test': [0.5839393166480241, 0.730565371024735, 0.7024364955935718, 0.7989386792452831, 0.7475862068965518]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  093  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  093  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  093  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6689, Acc: 0.6239, Val Loss: 0.7328, Val Acc: 0.3877
Mejor modelo guardado con Val Loss: 0.7328
Epoch 2/100, Loss: 0.6541, Acc: 0.6367, Val Loss: 0.7355, Val Acc: 0.4194
Epoch 3/100, Loss: 0.6410, Acc: 0.6488, Val Loss: 0.7613, Val Acc: 0.4323
Epoch 4/100, Loss: 0.6247, Acc: 0.6668, Val Loss: 0.7749, Val Acc: 0.4194
Epoch 5/100, Loss: 0.6203, Acc: 0.6670, Val Loss: 0.7972, Val Acc: 0.4488
Epoch 6/100, Loss: 0.6088, Acc: 0.6755, Val Loss: 0.8059, Val Acc: 0.4330
Epoch 7/100, Loss: 0.6084, Acc: 0.6795, Val Loss: 0.8219, Val Acc: 0.4153
Epoch 8/100, Loss: 0.6030, Acc: 0.6823, Val Loss: 0.8177, Val Acc: 0.4142
Epoch 9/100, Loss: 0.5960, Acc: 0.6859, Val Loss: 0.8711, Val Acc: 0.4091
Epoch 10/100, Loss: 0.6048, Acc: 0.6792, Val Loss: 0.8377, Val Acc: 0.4363
Epoch 11/100, Loss: 0.5936, Acc: 0.6925, Val Loss: 0.8305, Val Acc: 0.4234
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5920, Acc: 0.6933, Val Loss: 0.9077, Val Acc: 0.3899
Epoch 13/100, Loss: 0.5894, Acc: 0.6962, Val Loss: 0.9271, Val Acc: 0.4043
Epoch 14/100, Loss: 0.5885, Acc: 0.6939, Val Loss: 0.8832, Val Acc: 0.4109
Epoch 15/100, Loss: 0.5926, Acc: 0.6942, Val Loss: 0.9103, Val Acc: 0.4444
Epoch 16/100, Loss: 0.5889, Acc: 0.6932, Val Loss: 0.8894, Val Acc: 0.4161
Epoch 17/100, Loss: 0.5886, Acc: 0.6992, Val Loss: 0.8958, Val Acc: 0.4168
Epoch 18/100, Loss: 0.5882, Acc: 0.6958, Val Loss: 0.8747, Val Acc: 0.4183
Epoch 19/100, Loss: 0.5855, Acc: 0.7008, Val Loss: 0.8934, Val Acc: 0.4529
Epoch 20/100, Loss: 0.5899, Acc: 0.6922, Val Loss: 0.8694, Val Acc: 0.4102
Epoch 21/100, Loss: 0.5873, Acc: 0.6969, Val Loss: 0.9238, Val Acc: 0.4352
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5816, Acc: 0.7000, Val Loss: 0.8877, Val Acc: 0.4138
Epoch 23/100, Loss: 0.5817, Acc: 0.7022, Val Loss: 0.8795, Val Acc: 0.4105
Epoch 24/100, Loss: 0.5819, Acc: 0.7012, Val Loss: 0.8958, Val Acc: 0.4194
Epoch 25/100, Loss: 0.5800, Acc: 0.7047, Val Loss: 0.8924, Val Acc: 0.4234
Epoch 26/100, Loss: 0.5800, Acc: 0.7038, Val Loss: 0.8897, Val Acc: 0.4230
Epoch 27/100, Loss: 0.5805, Acc: 0.7016, Val Loss: 0.8900, Val Acc: 0.4315
Epoch 28/100, Loss: 0.5794, Acc: 0.7033, Val Loss: 0.8814, Val Acc: 0.4065
Epoch 29/100, Loss: 0.5787, Acc: 0.7049, Val Loss: 0.8992, Val Acc: 0.4179
Epoch 30/100, Loss: 0.5789, Acc: 0.7023, Val Loss: 0.8831, Val Acc: 0.4087
Epoch 31/100, Loss: 0.5787, Acc: 0.7046, Val Loss: 0.8960, Val Acc: 0.4326
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5774, Acc: 0.7063, Val Loss: 0.9076, Val Acc: 0.4311
Epoch 33/100, Loss: 0.5770, Acc: 0.7054, Val Loss: 0.8938, Val Acc: 0.4205
Epoch 34/100, Loss: 0.5766, Acc: 0.7052, Val Loss: 0.8914, Val Acc: 0.4230
Epoch 35/100, Loss: 0.5772, Acc: 0.7046, Val Loss: 0.8970, Val Acc: 0.4227
Epoch 36/100, Loss: 0.5764, Acc: 0.7066, Val Loss: 0.8991, Val Acc: 0.4275
Epoch 37/100, Loss: 0.5766, Acc: 0.7076, Val Loss: 0.9132, Val Acc: 0.4293
Epoch 38/100, Loss: 0.5766, Acc: 0.7082, Val Loss: 0.8984, Val Acc: 0.4234
Epoch 39/100, Loss: 0.5757, Acc: 0.7080, Val Loss: 0.8942, Val Acc: 0.4124
Epoch 40/100, Loss: 0.5762, Acc: 0.7068, Val Loss: 0.9059, Val Acc: 0.4186
Epoch 41/100, Loss: 0.5756, Acc: 0.7077, Val Loss: 0.9022, Val Acc: 0.4205
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5748, Acc: 0.7099, Val Loss: 0.9014, Val Acc: 0.4212
Epoch 43/100, Loss: 0.5748, Acc: 0.7078, Val Loss: 0.9013, Val Acc: 0.4223
Epoch 44/100, Loss: 0.5751, Acc: 0.7061, Val Loss: 0.9002, Val Acc: 0.4219
Epoch 45/100, Loss: 0.5748, Acc: 0.7105, Val Loss: 0.8999, Val Acc: 0.4197
Epoch 46/100, Loss: 0.5748, Acc: 0.7093, Val Loss: 0.9003, Val Acc: 0.4216
Epoch 47/100, Loss: 0.5744, Acc: 0.7094, Val Loss: 0.8975, Val Acc: 0.4186
Epoch 48/100, Loss: 0.5751, Acc: 0.7096, Val Loss: 0.8984, Val Acc: 0.4201
Epoch 49/100, Loss: 0.5747, Acc: 0.7096, Val Loss: 0.9015, Val Acc: 0.4205
Epoch 50/100, Loss: 0.5743, Acc: 0.7095, Val Loss: 0.9012, Val Acc: 0.4264
Epoch 51/100, Loss: 0.5744, Acc: 0.7089, Val Loss: 0.9021, Val Acc: 0.4223
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5740, Acc: 0.7089, Val Loss: 0.9018, Val Acc: 0.4208
Epoch 53/100, Loss: 0.5737, Acc: 0.7083, Val Loss: 0.9015, Val Acc: 0.4105
Epoch 54/100, Loss: 0.5741, Acc: 0.7087, Val Loss: 0.9019, Val Acc: 0.4242
Epoch 55/100, Loss: 0.5738, Acc: 0.7106, Val Loss: 0.8992, Val Acc: 0.4212
Epoch 56/100, Loss: 0.5740, Acc: 0.7109, Val Loss: 0.9031, Val Acc: 0.4216
Epoch 57/100, Loss: 0.5739, Acc: 0.7092, Val Loss: 0.9001, Val Acc: 0.4275
Epoch 58/100, Loss: 0.5738, Acc: 0.7096, Val Loss: 0.8991, Val Acc: 0.4212
Epoch 59/100, Loss: 0.5737, Acc: 0.7104, Val Loss: 0.9003, Val Acc: 0.4227
Epoch 60/100, Loss: 0.5739, Acc: 0.7103, Val Loss: 0.9020, Val Acc: 0.4197
Epoch 61/100, Loss: 0.5739, Acc: 0.7079, Val Loss: 0.9012, Val Acc: 0.4223
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5736, Acc: 0.7085, Val Loss: 0.9013, Val Acc: 0.4227
Epoch 63/100, Loss: 0.5734, Acc: 0.7111, Val Loss: 0.9017, Val Acc: 0.4234
Epoch 64/100, Loss: 0.5734, Acc: 0.7101, Val Loss: 0.9030, Val Acc: 0.4227
Epoch 65/100, Loss: 0.5733, Acc: 0.7099, Val Loss: 0.9029, Val Acc: 0.4223
Epoch 66/100, Loss: 0.5733, Acc: 0.7086, Val Loss: 0.9014, Val Acc: 0.4227
Epoch 67/100, Loss: 0.5733, Acc: 0.7110, Val Loss: 0.9020, Val Acc: 0.4219
Epoch 68/100, Loss: 0.5733, Acc: 0.7097, Val Loss: 0.9017, Val Acc: 0.4216
Epoch 69/100, Loss: 0.5734, Acc: 0.7106, Val Loss: 0.9016, Val Acc: 0.4216
Epoch 70/100, Loss: 0.5732, Acc: 0.7104, Val Loss: 0.9016, Val Acc: 0.4245
Epoch 71/100, Loss: 0.5733, Acc: 0.7107, Val Loss: 0.9030, Val Acc: 0.4208
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5732, Acc: 0.7098, Val Loss: 0.9028, Val Acc: 0.4230
Epoch 73/100, Loss: 0.5731, Acc: 0.7097, Val Loss: 0.9027, Val Acc: 0.4208
Epoch 74/100, Loss: 0.5731, Acc: 0.7104, Val Loss: 0.9029, Val Acc: 0.4208
Epoch 75/100, Loss: 0.5732, Acc: 0.7105, Val Loss: 0.9028, Val Acc: 0.4216
Epoch 76/100, Loss: 0.5730, Acc: 0.7104, Val Loss: 0.9026, Val Acc: 0.4216
Epoch 77/100, Loss: 0.5731, Acc: 0.7106, Val Loss: 0.9024, Val Acc: 0.4212
Epoch 78/100, Loss: 0.5730, Acc: 0.7096, Val Loss: 0.9024, Val Acc: 0.4219
Epoch 79/100, Loss: 0.5729, Acc: 0.7094, Val Loss: 0.9028, Val Acc: 0.4227
Epoch 80/100, Loss: 0.5731, Acc: 0.7106, Val Loss: 0.9022, Val Acc: 0.4219
Epoch 81/100, Loss: 0.5730, Acc: 0.7120, Val Loss: 0.9026, Val Acc: 0.4223
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5730, Acc: 0.7097, Val Loss: 0.9030, Val Acc: 0.4223
Epoch 83/100, Loss: 0.5730, Acc: 0.7105, Val Loss: 0.9031, Val Acc: 0.4219
Epoch 84/100, Loss: 0.5730, Acc: 0.7104, Val Loss: 0.9026, Val Acc: 0.4219
Epoch 85/100, Loss: 0.5730, Acc: 0.7100, Val Loss: 0.9028, Val Acc: 0.4223
Epoch 86/100, Loss: 0.5729, Acc: 0.7109, Val Loss: 0.9024, Val Acc: 0.4219
Epoch 87/100, Loss: 0.5729, Acc: 0.7098, Val Loss: 0.9028, Val Acc: 0.4208
Epoch 88/100, Loss: 0.5729, Acc: 0.7106, Val Loss: 0.9030, Val Acc: 0.4197
Epoch 89/100, Loss: 0.5730, Acc: 0.7102, Val Loss: 0.9024, Val Acc: 0.4201
Epoch 90/100, Loss: 0.5729, Acc: 0.7096, Val Loss: 0.9028, Val Acc: 0.4223
Epoch 91/100, Loss: 0.5731, Acc: 0.7106, Val Loss: 0.9029, Val Acc: 0.4219
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5727, Acc: 0.7104, Val Loss: 0.9039, Val Acc: 0.4230
Epoch 93/100, Loss: 0.5729, Acc: 0.7101, Val Loss: 0.9031, Val Acc: 0.4205
Epoch 94/100, Loss: 0.5729, Acc: 0.7109, Val Loss: 0.9038, Val Acc: 0.4219
Epoch 95/100, Loss: 0.5729, Acc: 0.7108, Val Loss: 0.9030, Val Acc: 0.4212
Epoch 96/100, Loss: 0.5728, Acc: 0.7117, Val Loss: 0.9025, Val Acc: 0.4208
Epoch 97/100, Loss: 0.5728, Acc: 0.7105, Val Loss: 0.9028, Val Acc: 0.4219
Epoch 98/100, Loss: 0.5728, Acc: 0.7101, Val Loss: 0.9029, Val Acc: 0.4219
Epoch 99/100, Loss: 0.5728, Acc: 0.7108, Val Loss: 0.9029, Val Acc: 0.4216
Epoch 100/100, Loss: 0.5728, Acc: 0.7110, Val Loss: 0.9038, Val Acc: 0.4223

##############################
Resultados para principal:  093  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5 
 {'training': [0.5728162776770597, 0.7110150790731887, 0.7253784155690977, 0.6788079470198676, 0.701320916088568], 'validate': [0.9038460566553959, 0.4223122238586156, 0.4402021336327906, 0.5781710914454278, 0.499840612049729], 'test': [0.7911586573830357, 0.21643109540636044, 0.26814031715521386, 0.3290094339622642, 0.29547259729944403]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  088  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  088  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  088  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6930, Acc: 0.5139, Val Loss: 0.6932, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6932
Epoch 2/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6921, Val Acc: 0.5736
Mejor modelo guardado con Val Loss: 0.6921
Epoch 3/100, Loss: 0.6938, Acc: 0.4936, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 4/100, Loss: 0.6934, Acc: 0.4946, Val Loss: 0.6931, Val Acc: 0.4982
Epoch 5/100, Loss: 0.6933, Acc: 0.5067, Val Loss: 0.6932, Val Acc: 0.5007
Epoch 6/100, Loss: 0.6934, Acc: 0.4939, Val Loss: 0.6946, Val Acc: 0.4993
Epoch 7/100, Loss: 0.6935, Acc: 0.5009, Val Loss: 0.6943, Val Acc: 0.4993
Epoch 8/100, Loss: 0.6937, Acc: 0.4925, Val Loss: 0.6931, Val Acc: 0.5004
Epoch 9/100, Loss: 0.6935, Acc: 0.4986, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 10/100, Loss: 0.6933, Acc: 0.4993, Val Loss: 0.6916, Val Acc: 0.5582
Mejor modelo guardado con Val Loss: 0.6916
Epoch 11/100, Loss: 0.6935, Acc: 0.4949, Val Loss: 0.6933, Val Acc: 0.4993
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4956, Val Loss: 0.6934, Val Acc: 0.4993
Epoch 13/100, Loss: 0.6934, Acc: 0.5046, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 14/100, Loss: 0.6932, Acc: 0.5053, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 15/100, Loss: 0.6933, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 16/100, Loss: 0.6933, Acc: 0.4914, Val Loss: 0.6849, Val Acc: 0.7161
Mejor modelo guardado con Val Loss: 0.6849
Epoch 17/100, Loss: 0.6934, Acc: 0.4950, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 18/100, Loss: 0.6933, Acc: 0.4998, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 19/100, Loss: 0.6934, Acc: 0.4989, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 20/100, Loss: 0.6933, Acc: 0.4937, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 21/100, Loss: 0.6932, Acc: 0.5037, Val Loss: 0.6931, Val Acc: 0.5007
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4884, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 23/100, Loss: 0.6933, Acc: 0.4956, Val Loss: 0.6933, Val Acc: 0.4996
Epoch 24/100, Loss: 0.6932, Acc: 0.4929, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 25/100, Loss: 0.6932, Acc: 0.4969, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 26/100, Loss: 0.6933, Acc: 0.4958, Val Loss: 0.6932, Val Acc: 0.4996
Epoch 27/100, Loss: 0.6932, Acc: 0.4862, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 28/100, Loss: 0.6933, Acc: 0.4951, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 29/100, Loss: 0.6932, Acc: 0.4974, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 30/100, Loss: 0.6932, Acc: 0.4998, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 31/100, Loss: 0.6933, Acc: 0.4961, Val Loss: 0.6931, Val Acc: 0.5007
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4936, Val Loss: 0.6931, Val Acc: 0.5254
Epoch 33/100, Loss: 0.6932, Acc: 0.5038, Val Loss: 0.6932, Val Acc: 0.5004
Epoch 34/100, Loss: 0.6932, Acc: 0.4998, Val Loss: 0.6931, Val Acc: 0.5103
Epoch 35/100, Loss: 0.6933, Acc: 0.4995, Val Loss: 0.6935, Val Acc: 0.5007
Epoch 36/100, Loss: 0.6935, Acc: 0.5002, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 37/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 38/100, Loss: 0.6932, Acc: 0.4967, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 39/100, Loss: 0.6932, Acc: 0.4905, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 40/100, Loss: 0.6932, Acc: 0.4996, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 41/100, Loss: 0.6932, Acc: 0.4912, Val Loss: 0.6931, Val Acc: 0.5007
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.4948, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 43/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 44/100, Loss: 0.6932, Acc: 0.4953, Val Loss: 0.6931, Val Acc: 0.5000
Epoch 45/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 46/100, Loss: 0.6932, Acc: 0.4943, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 47/100, Loss: 0.6932, Acc: 0.4945, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 48/100, Loss: 0.6932, Acc: 0.4979, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 49/100, Loss: 0.6932, Acc: 0.4956, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 50/100, Loss: 0.6932, Acc: 0.4980, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 51/100, Loss: 0.6932, Acc: 0.4922, Val Loss: 0.6931, Val Acc: 0.4996
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6932, Acc: 0.4965, Val Loss: 0.6931, Val Acc: 0.4996
Epoch 53/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6930, Val Acc: 0.4956
Epoch 54/100, Loss: 0.6932, Acc: 0.4953, Val Loss: 0.6920, Val Acc: 0.4937
Epoch 55/100, Loss: 0.6932, Acc: 0.4917, Val Loss: 0.6898, Val Acc: 0.4930
Epoch 56/100, Loss: 0.6931, Acc: 0.4960, Val Loss: 0.6892, Val Acc: 0.5004
Epoch 57/100, Loss: 0.6931, Acc: 0.4982, Val Loss: 0.6853, Val Acc: 0.5004
Epoch 58/100, Loss: 0.6930, Acc: 0.4944, Val Loss: 0.6850, Val Acc: 0.5670
Epoch 59/100, Loss: 0.6930, Acc: 0.4961, Val Loss: 0.6854, Val Acc: 0.7051
Epoch 60/100, Loss: 0.6930, Acc: 0.5040, Val Loss: 0.6849, Val Acc: 0.7110
Epoch 61/100, Loss: 0.6930, Acc: 0.5006, Val Loss: 0.6850, Val Acc: 0.7378
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6929, Acc: 0.5052, Val Loss: 0.6846, Val Acc: 0.7286
Mejor modelo guardado con Val Loss: 0.6846
Epoch 63/100, Loss: 0.6929, Acc: 0.5057, Val Loss: 0.6845, Val Acc: 0.7342
Mejor modelo guardado con Val Loss: 0.6845
Epoch 64/100, Loss: 0.6929, Acc: 0.5059, Val Loss: 0.6843, Val Acc: 0.7316
Mejor modelo guardado con Val Loss: 0.6843
Epoch 65/100, Loss: 0.6929, Acc: 0.5056, Val Loss: 0.6841, Val Acc: 0.7180
Mejor modelo guardado con Val Loss: 0.6841
Epoch 66/100, Loss: 0.6929, Acc: 0.5017, Val Loss: 0.6843, Val Acc: 0.7390
Epoch 67/100, Loss: 0.6929, Acc: 0.5059, Val Loss: 0.6841, Val Acc: 0.7312
Mejor modelo guardado con Val Loss: 0.6841
Epoch 68/100, Loss: 0.6929, Acc: 0.5079, Val Loss: 0.6841, Val Acc: 0.7401
Mejor modelo guardado con Val Loss: 0.6841
Epoch 69/100, Loss: 0.6929, Acc: 0.5092, Val Loss: 0.6839, Val Acc: 0.7378
Mejor modelo guardado con Val Loss: 0.6839
Epoch 70/100, Loss: 0.6929, Acc: 0.5074, Val Loss: 0.6838, Val Acc: 0.7353
Mejor modelo guardado con Val Loss: 0.6838
Epoch 71/100, Loss: 0.6929, Acc: 0.5072, Val Loss: 0.6837, Val Acc: 0.7294
Mejor modelo guardado con Val Loss: 0.6837
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6929, Acc: 0.5053, Val Loss: 0.6837, Val Acc: 0.7323
Mejor modelo guardado con Val Loss: 0.6837
Epoch 73/100, Loss: 0.6929, Acc: 0.5062, Val Loss: 0.6836, Val Acc: 0.7305
Mejor modelo guardado con Val Loss: 0.6836
Epoch 74/100, Loss: 0.6929, Acc: 0.5076, Val Loss: 0.6836, Val Acc: 0.7360
Epoch 75/100, Loss: 0.6929, Acc: 0.5063, Val Loss: 0.6836, Val Acc: 0.7401
Mejor modelo guardado con Val Loss: 0.6836
Epoch 76/100, Loss: 0.6929, Acc: 0.5081, Val Loss: 0.6835, Val Acc: 0.7378
Mejor modelo guardado con Val Loss: 0.6835
Epoch 77/100, Loss: 0.6929, Acc: 0.5086, Val Loss: 0.6835, Val Acc: 0.7408
Mejor modelo guardado con Val Loss: 0.6835
Epoch 78/100, Loss: 0.6929, Acc: 0.5062, Val Loss: 0.6835, Val Acc: 0.7390
Mejor modelo guardado con Val Loss: 0.6835
Epoch 79/100, Loss: 0.6929, Acc: 0.5073, Val Loss: 0.6834, Val Acc: 0.7412
Mejor modelo guardado con Val Loss: 0.6834
Epoch 80/100, Loss: 0.6929, Acc: 0.5102, Val Loss: 0.6834, Val Acc: 0.7430
Mejor modelo guardado con Val Loss: 0.6834
Epoch 81/100, Loss: 0.6928, Acc: 0.5073, Val Loss: 0.6834, Val Acc: 0.7437
Mejor modelo guardado con Val Loss: 0.6834
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6928, Acc: 0.5108, Val Loss: 0.6833, Val Acc: 0.7415
Mejor modelo guardado con Val Loss: 0.6833
Epoch 83/100, Loss: 0.6928, Acc: 0.5101, Val Loss: 0.6832, Val Acc: 0.7404
Mejor modelo guardado con Val Loss: 0.6832
Epoch 84/100, Loss: 0.6928, Acc: 0.5092, Val Loss: 0.6832, Val Acc: 0.7430
Mejor modelo guardado con Val Loss: 0.6832
Epoch 85/100, Loss: 0.6928, Acc: 0.5060, Val Loss: 0.6831, Val Acc: 0.7382
Mejor modelo guardado con Val Loss: 0.6831
Epoch 86/100, Loss: 0.6928, Acc: 0.5084, Val Loss: 0.6830, Val Acc: 0.7382
Mejor modelo guardado con Val Loss: 0.6830
Epoch 87/100, Loss: 0.6928, Acc: 0.5087, Val Loss: 0.6829, Val Acc: 0.7349
Mejor modelo guardado con Val Loss: 0.6829
Epoch 88/100, Loss: 0.6928, Acc: 0.5067, Val Loss: 0.6829, Val Acc: 0.7393
Mejor modelo guardado con Val Loss: 0.6829
Epoch 89/100, Loss: 0.6928, Acc: 0.5093, Val Loss: 0.6829, Val Acc: 0.7430
Mejor modelo guardado con Val Loss: 0.6829
Epoch 90/100, Loss: 0.6928, Acc: 0.5098, Val Loss: 0.6828, Val Acc: 0.7419
Mejor modelo guardado con Val Loss: 0.6828
Epoch 91/100, Loss: 0.6928, Acc: 0.5098, Val Loss: 0.6827, Val Acc: 0.7397
Mejor modelo guardado con Val Loss: 0.6827
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6928, Acc: 0.5100, Val Loss: 0.6826, Val Acc: 0.7419
Mejor modelo guardado con Val Loss: 0.6826
Epoch 93/100, Loss: 0.6928, Acc: 0.5091, Val Loss: 0.6825, Val Acc: 0.7437
Mejor modelo guardado con Val Loss: 0.6825
Epoch 94/100, Loss: 0.6928, Acc: 0.5086, Val Loss: 0.6824, Val Acc: 0.7375
Mejor modelo guardado con Val Loss: 0.6824
Epoch 95/100, Loss: 0.6927, Acc: 0.5088, Val Loss: 0.6822, Val Acc: 0.7445
Mejor modelo guardado con Val Loss: 0.6822
Epoch 96/100, Loss: 0.6927, Acc: 0.5106, Val Loss: 0.6820, Val Acc: 0.7459
Mejor modelo guardado con Val Loss: 0.6820
Epoch 97/100, Loss: 0.6926, Acc: 0.5144, Val Loss: 0.6817, Val Acc: 0.7430
Mejor modelo guardado con Val Loss: 0.6817
Epoch 98/100, Loss: 0.6926, Acc: 0.5095, Val Loss: 0.6816, Val Acc: 0.7474
Mejor modelo guardado con Val Loss: 0.6816
Epoch 99/100, Loss: 0.6926, Acc: 0.5123, Val Loss: 0.6815, Val Acc: 0.7537
Mejor modelo guardado con Val Loss: 0.6815
Epoch 100/100, Loss: 0.6926, Acc: 0.5135, Val Loss: 0.6813, Val Acc: 0.7529
Mejor modelo guardado con Val Loss: 0.6813

##############################
Resultados para principal:  088  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5 
 {'training': [0.6925793409829808, 0.5135159985288709, 0.5086217148293495, 0.7867917586460633, 0.6178403755868545], 'validate': [0.6813269077345382, 0.7529455081001473, 0.790008467400508, 0.6880530973451328, 0.7355143870713441], 'test': [0.6890201458224544, 0.60924617196702, 0.5818908122503329, 0.7729952830188679, 0.6639655609014941]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  055  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  055  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  055  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6829, Acc: 0.5645, Val Loss: 0.6283, Val Acc: 0.7198
Mejor modelo guardado con Val Loss: 0.6283
Epoch 2/100, Loss: 0.6755, Acc: 0.5873, Val Loss: 0.6078, Val Acc: 0.7364
Mejor modelo guardado con Val Loss: 0.6078
Epoch 3/100, Loss: 0.6770, Acc: 0.5773, Val Loss: 0.6152, Val Acc: 0.8189
Epoch 4/100, Loss: 0.6708, Acc: 0.5961, Val Loss: 0.5606, Val Acc: 0.8564
Mejor modelo guardado con Val Loss: 0.5606
Epoch 5/100, Loss: 0.6748, Acc: 0.5841, Val Loss: 0.5819, Val Acc: 0.8225
Epoch 6/100, Loss: 0.6692, Acc: 0.5903, Val Loss: 0.5572, Val Acc: 0.8538
Mejor modelo guardado con Val Loss: 0.5572
Epoch 7/100, Loss: 0.6720, Acc: 0.5756, Val Loss: 0.5415, Val Acc: 0.8557
Mejor modelo guardado con Val Loss: 0.5415
Epoch 8/100, Loss: 0.6694, Acc: 0.5853, Val Loss: 0.5299, Val Acc: 0.8663
Mejor modelo guardado con Val Loss: 0.5299
Epoch 9/100, Loss: 0.6625, Acc: 0.5983, Val Loss: 0.5154, Val Acc: 0.8494
Mejor modelo guardado con Val Loss: 0.5154
Epoch 10/100, Loss: 0.6630, Acc: 0.6022, Val Loss: 0.5085, Val Acc: 0.8538
Mejor modelo guardado con Val Loss: 0.5085
Epoch 11/100, Loss: 0.6613, Acc: 0.5945, Val Loss: 0.5322, Val Acc: 0.8715
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6575, Acc: 0.6035, Val Loss: 0.5351, Val Acc: 0.7367
Epoch 13/100, Loss: 0.6596, Acc: 0.5996, Val Loss: 0.5218, Val Acc: 0.7953
Epoch 14/100, Loss: 0.6603, Acc: 0.5945, Val Loss: 0.4938, Val Acc: 0.8527
Mejor modelo guardado con Val Loss: 0.4938
Epoch 15/100, Loss: 0.6580, Acc: 0.6008, Val Loss: 0.5028, Val Acc: 0.8391
Epoch 16/100, Loss: 0.6559, Acc: 0.5975, Val Loss: 0.5172, Val Acc: 0.8126
Epoch 17/100, Loss: 0.6548, Acc: 0.6076, Val Loss: 0.5197, Val Acc: 0.7610
Epoch 18/100, Loss: 0.6542, Acc: 0.6022, Val Loss: 0.5087, Val Acc: 0.7809
Epoch 19/100, Loss: 0.6551, Acc: 0.6003, Val Loss: 0.4873, Val Acc: 0.8321
Mejor modelo guardado con Val Loss: 0.4873
Epoch 20/100, Loss: 0.6557, Acc: 0.5994, Val Loss: 0.4732, Val Acc: 0.8660
Mejor modelo guardado con Val Loss: 0.4732
Epoch 21/100, Loss: 0.6566, Acc: 0.6085, Val Loss: 0.5150, Val Acc: 0.8049
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6540, Acc: 0.6052, Val Loss: 0.5251, Val Acc: 0.8417
Epoch 23/100, Loss: 0.6533, Acc: 0.6047, Val Loss: 0.4996, Val Acc: 0.8082
Epoch 24/100, Loss: 0.6521, Acc: 0.6090, Val Loss: 0.4935, Val Acc: 0.8174
Epoch 25/100, Loss: 0.6526, Acc: 0.6074, Val Loss: 0.5062, Val Acc: 0.7739
Epoch 26/100, Loss: 0.6526, Acc: 0.6086, Val Loss: 0.5044, Val Acc: 0.7839
Epoch 27/100, Loss: 0.6525, Acc: 0.6084, Val Loss: 0.5188, Val Acc: 0.7861
Epoch 28/100, Loss: 0.6520, Acc: 0.6117, Val Loss: 0.5236, Val Acc: 0.7032
Epoch 29/100, Loss: 0.6527, Acc: 0.6074, Val Loss: 0.4892, Val Acc: 0.8240
Epoch 30/100, Loss: 0.6495, Acc: 0.6082, Val Loss: 0.4834, Val Acc: 0.8063
Epoch 31/100, Loss: 0.6517, Acc: 0.6090, Val Loss: 0.4945, Val Acc: 0.7500
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6493, Acc: 0.6079, Val Loss: 0.4897, Val Acc: 0.7835
Epoch 33/100, Loss: 0.6481, Acc: 0.6133, Val Loss: 0.4733, Val Acc: 0.8192
Epoch 34/100, Loss: 0.6488, Acc: 0.6102, Val Loss: 0.4804, Val Acc: 0.8152
Epoch 35/100, Loss: 0.6487, Acc: 0.6095, Val Loss: 0.4929, Val Acc: 0.7765
Epoch 36/100, Loss: 0.6483, Acc: 0.6141, Val Loss: 0.4723, Val Acc: 0.8170
Mejor modelo guardado con Val Loss: 0.4723
Epoch 37/100, Loss: 0.6485, Acc: 0.6119, Val Loss: 0.5002, Val Acc: 0.7500
Epoch 38/100, Loss: 0.6479, Acc: 0.6135, Val Loss: 0.4730, Val Acc: 0.8181
Epoch 39/100, Loss: 0.6479, Acc: 0.6102, Val Loss: 0.4874, Val Acc: 0.7813
Epoch 40/100, Loss: 0.6481, Acc: 0.6112, Val Loss: 0.4791, Val Acc: 0.7975
Epoch 41/100, Loss: 0.6478, Acc: 0.6139, Val Loss: 0.4882, Val Acc: 0.7772
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6473, Acc: 0.6146, Val Loss: 0.4908, Val Acc: 0.7636
Epoch 43/100, Loss: 0.6473, Acc: 0.6137, Val Loss: 0.4844, Val Acc: 0.7839
Epoch 44/100, Loss: 0.6475, Acc: 0.6123, Val Loss: 0.4824, Val Acc: 0.7828
Epoch 45/100, Loss: 0.6474, Acc: 0.6147, Val Loss: 0.4792, Val Acc: 0.7949
Epoch 46/100, Loss: 0.6470, Acc: 0.6128, Val Loss: 0.4879, Val Acc: 0.7758
Epoch 47/100, Loss: 0.6470, Acc: 0.6162, Val Loss: 0.4868, Val Acc: 0.7736
Epoch 48/100, Loss: 0.6470, Acc: 0.6141, Val Loss: 0.4832, Val Acc: 0.7769
Epoch 49/100, Loss: 0.6469, Acc: 0.6116, Val Loss: 0.4800, Val Acc: 0.7957
Epoch 50/100, Loss: 0.6469, Acc: 0.6154, Val Loss: 0.4872, Val Acc: 0.7791
Epoch 51/100, Loss: 0.6471, Acc: 0.6153, Val Loss: 0.4895, Val Acc: 0.7732
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6467, Acc: 0.6149, Val Loss: 0.4859, Val Acc: 0.7754
Epoch 53/100, Loss: 0.6467, Acc: 0.6155, Val Loss: 0.4872, Val Acc: 0.7772
Epoch 54/100, Loss: 0.6466, Acc: 0.6158, Val Loss: 0.4865, Val Acc: 0.7754
Epoch 55/100, Loss: 0.6465, Acc: 0.6159, Val Loss: 0.4808, Val Acc: 0.7850
Epoch 56/100, Loss: 0.6466, Acc: 0.6143, Val Loss: 0.4857, Val Acc: 0.7776
Epoch 57/100, Loss: 0.6465, Acc: 0.6170, Val Loss: 0.4857, Val Acc: 0.7750
Epoch 58/100, Loss: 0.6463, Acc: 0.6158, Val Loss: 0.4840, Val Acc: 0.7780
Epoch 59/100, Loss: 0.6463, Acc: 0.6148, Val Loss: 0.4820, Val Acc: 0.7787
Epoch 60/100, Loss: 0.6464, Acc: 0.6152, Val Loss: 0.4815, Val Acc: 0.7817
Epoch 61/100, Loss: 0.6464, Acc: 0.6168, Val Loss: 0.4784, Val Acc: 0.7894
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6462, Acc: 0.6159, Val Loss: 0.4822, Val Acc: 0.7795
Epoch 63/100, Loss: 0.6460, Acc: 0.6145, Val Loss: 0.4801, Val Acc: 0.7784
Epoch 64/100, Loss: 0.6458, Acc: 0.6149, Val Loss: 0.4812, Val Acc: 0.7776
Epoch 65/100, Loss: 0.6458, Acc: 0.6143, Val Loss: 0.4793, Val Acc: 0.7795
Epoch 66/100, Loss: 0.6458, Acc: 0.6137, Val Loss: 0.4781, Val Acc: 0.7839
Epoch 67/100, Loss: 0.6458, Acc: 0.6140, Val Loss: 0.4796, Val Acc: 0.7787
Epoch 68/100, Loss: 0.6458, Acc: 0.6143, Val Loss: 0.4796, Val Acc: 0.7791
Epoch 69/100, Loss: 0.6458, Acc: 0.6151, Val Loss: 0.4797, Val Acc: 0.7787
Epoch 70/100, Loss: 0.6458, Acc: 0.6137, Val Loss: 0.4823, Val Acc: 0.7765
Epoch 71/100, Loss: 0.6457, Acc: 0.6131, Val Loss: 0.4822, Val Acc: 0.7750
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6456, Acc: 0.6151, Val Loss: 0.4794, Val Acc: 0.7784
Epoch 73/100, Loss: 0.6456, Acc: 0.6155, Val Loss: 0.4775, Val Acc: 0.7817
Epoch 74/100, Loss: 0.6456, Acc: 0.6147, Val Loss: 0.4776, Val Acc: 0.7817
Epoch 75/100, Loss: 0.6456, Acc: 0.6150, Val Loss: 0.4792, Val Acc: 0.7791
Epoch 76/100, Loss: 0.6456, Acc: 0.6148, Val Loss: 0.4788, Val Acc: 0.7787
Epoch 77/100, Loss: 0.6456, Acc: 0.6150, Val Loss: 0.4771, Val Acc: 0.7835
Epoch 78/100, Loss: 0.6456, Acc: 0.6160, Val Loss: 0.4788, Val Acc: 0.7791
Epoch 79/100, Loss: 0.6455, Acc: 0.6146, Val Loss: 0.4790, Val Acc: 0.7791
Epoch 80/100, Loss: 0.6456, Acc: 0.6154, Val Loss: 0.4793, Val Acc: 0.7784
Epoch 81/100, Loss: 0.6455, Acc: 0.6137, Val Loss: 0.4784, Val Acc: 0.7806
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6455, Acc: 0.6150, Val Loss: 0.4798, Val Acc: 0.7780
Epoch 83/100, Loss: 0.6455, Acc: 0.6157, Val Loss: 0.4796, Val Acc: 0.7780
Epoch 84/100, Loss: 0.6455, Acc: 0.6141, Val Loss: 0.4782, Val Acc: 0.7798
Epoch 85/100, Loss: 0.6455, Acc: 0.6148, Val Loss: 0.4784, Val Acc: 0.7791
Epoch 86/100, Loss: 0.6455, Acc: 0.6155, Val Loss: 0.4792, Val Acc: 0.7772
Epoch 87/100, Loss: 0.6455, Acc: 0.6153, Val Loss: 0.4796, Val Acc: 0.7772
Epoch 88/100, Loss: 0.6455, Acc: 0.6150, Val Loss: 0.4771, Val Acc: 0.7806
Epoch 89/100, Loss: 0.6454, Acc: 0.6151, Val Loss: 0.4779, Val Acc: 0.7798
Epoch 90/100, Loss: 0.6454, Acc: 0.6150, Val Loss: 0.4786, Val Acc: 0.7791
Epoch 91/100, Loss: 0.6454, Acc: 0.6136, Val Loss: 0.4788, Val Acc: 0.7795
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6454, Acc: 0.6166, Val Loss: 0.4777, Val Acc: 0.7802
Epoch 93/100, Loss: 0.6454, Acc: 0.6148, Val Loss: 0.4786, Val Acc: 0.7795
Epoch 94/100, Loss: 0.6454, Acc: 0.6147, Val Loss: 0.4780, Val Acc: 0.7795
Epoch 95/100, Loss: 0.6454, Acc: 0.6162, Val Loss: 0.4779, Val Acc: 0.7795
Epoch 96/100, Loss: 0.6454, Acc: 0.6151, Val Loss: 0.4781, Val Acc: 0.7795
Epoch 97/100, Loss: 0.6454, Acc: 0.6143, Val Loss: 0.4780, Val Acc: 0.7795
Epoch 98/100, Loss: 0.6454, Acc: 0.6165, Val Loss: 0.4792, Val Acc: 0.7780
Epoch 99/100, Loss: 0.6453, Acc: 0.6145, Val Loss: 0.4784, Val Acc: 0.7795
Epoch 100/100, Loss: 0.6454, Acc: 0.6154, Val Loss: 0.4786, Val Acc: 0.7784

##############################
Resultados para principal:  055  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5 
 {'training': [0.6453599353930932, 0.6153916881206326, 0.6064209274673008, 0.6567328918322296, 0.6305749359710324], 'validate': [0.4785616283499917, 0.7783505154639175, 0.9170353982300885, 0.6113569321533924, 0.7336283185840708], 'test': [0.4616675230639952, 0.8259717314487632, 0.9694137638062872, 0.6727594339622641, 0.7942916811695092]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  045  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  045  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  045  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5046, Acc: 0.8096, Val Loss: 0.3031, Val Acc: 0.9219
Mejor modelo guardado con Val Loss: 0.3031
Epoch 2/100, Loss: 0.3910, Acc: 0.8407, Val Loss: 0.2645, Val Acc: 0.9190
Mejor modelo guardado con Val Loss: 0.2645
Epoch 3/100, Loss: 0.3704, Acc: 0.8479, Val Loss: 0.2226, Val Acc: 0.9337
Mejor modelo guardado con Val Loss: 0.2226
Epoch 4/100, Loss: 0.3552, Acc: 0.8511, Val Loss: 0.2296, Val Acc: 0.9172
Epoch 5/100, Loss: 0.3484, Acc: 0.8501, Val Loss: 0.1940, Val Acc: 0.9345
Mejor modelo guardado con Val Loss: 0.1940
Epoch 6/100, Loss: 0.3397, Acc: 0.8593, Val Loss: 0.2051, Val Acc: 0.9341
Epoch 7/100, Loss: 0.3366, Acc: 0.8579, Val Loss: 0.2488, Val Acc: 0.9135
Epoch 8/100, Loss: 0.3378, Acc: 0.8556, Val Loss: 0.2063, Val Acc: 0.9267
Epoch 9/100, Loss: 0.3313, Acc: 0.8584, Val Loss: 0.2127, Val Acc: 0.9433
Epoch 10/100, Loss: 0.3257, Acc: 0.8577, Val Loss: 0.2204, Val Acc: 0.9172
Epoch 11/100, Loss: 0.3242, Acc: 0.8621, Val Loss: 0.1937, Val Acc: 0.9197
Mejor modelo guardado con Val Loss: 0.1937
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3203, Acc: 0.8647, Val Loss: 0.1833, Val Acc: 0.9345
Mejor modelo guardado con Val Loss: 0.1833
Epoch 13/100, Loss: 0.3108, Acc: 0.8673, Val Loss: 0.1889, Val Acc: 0.9315
Epoch 14/100, Loss: 0.3176, Acc: 0.8638, Val Loss: 0.1873, Val Acc: 0.9264
Epoch 15/100, Loss: 0.3127, Acc: 0.8665, Val Loss: 0.1860, Val Acc: 0.9278
Epoch 16/100, Loss: 0.3120, Acc: 0.8659, Val Loss: 0.2150, Val Acc: 0.9164
Epoch 17/100, Loss: 0.3144, Acc: 0.8657, Val Loss: 0.2251, Val Acc: 0.9102
Epoch 18/100, Loss: 0.3127, Acc: 0.8665, Val Loss: 0.1794, Val Acc: 0.9348
Mejor modelo guardado con Val Loss: 0.1794
Epoch 19/100, Loss: 0.3074, Acc: 0.8711, Val Loss: 0.1876, Val Acc: 0.9278
Epoch 20/100, Loss: 0.3092, Acc: 0.8686, Val Loss: 0.2087, Val Acc: 0.9153
Epoch 21/100, Loss: 0.3110, Acc: 0.8673, Val Loss: 0.1784, Val Acc: 0.9341
Mejor modelo guardado con Val Loss: 0.1784
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3011, Acc: 0.8698, Val Loss: 0.1809, Val Acc: 0.9352
Epoch 23/100, Loss: 0.3005, Acc: 0.8739, Val Loss: 0.2063, Val Acc: 0.9186
Epoch 24/100, Loss: 0.3000, Acc: 0.8739, Val Loss: 0.1830, Val Acc: 0.9297
Epoch 25/100, Loss: 0.3024, Acc: 0.8716, Val Loss: 0.1987, Val Acc: 0.9227
Epoch 26/100, Loss: 0.2974, Acc: 0.8745, Val Loss: 0.1801, Val Acc: 0.9319
Epoch 27/100, Loss: 0.2974, Acc: 0.8739, Val Loss: 0.1932, Val Acc: 0.9234
Epoch 28/100, Loss: 0.2962, Acc: 0.8719, Val Loss: 0.1996, Val Acc: 0.9289
Epoch 29/100, Loss: 0.2971, Acc: 0.8741, Val Loss: 0.1685, Val Acc: 0.9392
Mejor modelo guardado con Val Loss: 0.1685
Epoch 30/100, Loss: 0.2935, Acc: 0.8727, Val Loss: 0.1812, Val Acc: 0.9300
Epoch 31/100, Loss: 0.2950, Acc: 0.8752, Val Loss: 0.1763, Val Acc: 0.9363
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2902, Acc: 0.8757, Val Loss: 0.1803, Val Acc: 0.9352
Epoch 33/100, Loss: 0.2904, Acc: 0.8770, Val Loss: 0.1799, Val Acc: 0.9341
Epoch 34/100, Loss: 0.2887, Acc: 0.8757, Val Loss: 0.1861, Val Acc: 0.9304
Epoch 35/100, Loss: 0.2892, Acc: 0.8753, Val Loss: 0.1818, Val Acc: 0.9356
Epoch 36/100, Loss: 0.2883, Acc: 0.8770, Val Loss: 0.1637, Val Acc: 0.9370
Mejor modelo guardado con Val Loss: 0.1637
Epoch 37/100, Loss: 0.2886, Acc: 0.8774, Val Loss: 0.1831, Val Acc: 0.9297
Epoch 38/100, Loss: 0.2883, Acc: 0.8784, Val Loss: 0.1746, Val Acc: 0.9330
Epoch 39/100, Loss: 0.2866, Acc: 0.8787, Val Loss: 0.1845, Val Acc: 0.9315
Epoch 40/100, Loss: 0.2867, Acc: 0.8782, Val Loss: 0.1683, Val Acc: 0.9367
Epoch 41/100, Loss: 0.2873, Acc: 0.8778, Val Loss: 0.1702, Val Acc: 0.9381
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2853, Acc: 0.8779, Val Loss: 0.1815, Val Acc: 0.9304
Epoch 43/100, Loss: 0.2847, Acc: 0.8775, Val Loss: 0.1744, Val Acc: 0.9334
Epoch 44/100, Loss: 0.2839, Acc: 0.8796, Val Loss: 0.1789, Val Acc: 0.9337
Epoch 45/100, Loss: 0.2840, Acc: 0.8784, Val Loss: 0.1691, Val Acc: 0.9385
Epoch 46/100, Loss: 0.2841, Acc: 0.8789, Val Loss: 0.1714, Val Acc: 0.9341
Epoch 47/100, Loss: 0.2834, Acc: 0.8787, Val Loss: 0.1827, Val Acc: 0.9308
Epoch 48/100, Loss: 0.2831, Acc: 0.8803, Val Loss: 0.1694, Val Acc: 0.9370
Epoch 49/100, Loss: 0.2826, Acc: 0.8789, Val Loss: 0.1752, Val Acc: 0.9363
Epoch 50/100, Loss: 0.2831, Acc: 0.8775, Val Loss: 0.1803, Val Acc: 0.9323
Epoch 51/100, Loss: 0.2824, Acc: 0.8792, Val Loss: 0.1821, Val Acc: 0.9341
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2823, Acc: 0.8790, Val Loss: 0.1722, Val Acc: 0.9381
Epoch 53/100, Loss: 0.2818, Acc: 0.8785, Val Loss: 0.1768, Val Acc: 0.9323
Epoch 54/100, Loss: 0.2814, Acc: 0.8798, Val Loss: 0.1733, Val Acc: 0.9345
Epoch 55/100, Loss: 0.2812, Acc: 0.8805, Val Loss: 0.1735, Val Acc: 0.9348
Epoch 56/100, Loss: 0.2813, Acc: 0.8800, Val Loss: 0.1745, Val Acc: 0.9337
Epoch 57/100, Loss: 0.2812, Acc: 0.8796, Val Loss: 0.1797, Val Acc: 0.9297
Epoch 58/100, Loss: 0.2810, Acc: 0.8802, Val Loss: 0.1775, Val Acc: 0.9319
Epoch 59/100, Loss: 0.2809, Acc: 0.8807, Val Loss: 0.1811, Val Acc: 0.9297
Epoch 60/100, Loss: 0.2808, Acc: 0.8796, Val Loss: 0.1768, Val Acc: 0.9315
Epoch 61/100, Loss: 0.2808, Acc: 0.8805, Val Loss: 0.1774, Val Acc: 0.9311
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2802, Acc: 0.8805, Val Loss: 0.1787, Val Acc: 0.9286
Epoch 63/100, Loss: 0.2801, Acc: 0.8815, Val Loss: 0.1763, Val Acc: 0.9315
Epoch 64/100, Loss: 0.2801, Acc: 0.8810, Val Loss: 0.1734, Val Acc: 0.9330
Epoch 65/100, Loss: 0.2799, Acc: 0.8804, Val Loss: 0.1745, Val Acc: 0.9337
Epoch 66/100, Loss: 0.2799, Acc: 0.8807, Val Loss: 0.1751, Val Acc: 0.9323
Epoch 67/100, Loss: 0.2801, Acc: 0.8805, Val Loss: 0.1759, Val Acc: 0.9311
Epoch 68/100, Loss: 0.2800, Acc: 0.8803, Val Loss: 0.1810, Val Acc: 0.9297
Epoch 69/100, Loss: 0.2793, Acc: 0.8811, Val Loss: 0.1728, Val Acc: 0.9367
Epoch 70/100, Loss: 0.2797, Acc: 0.8821, Val Loss: 0.1737, Val Acc: 0.9330
Epoch 71/100, Loss: 0.2797, Acc: 0.8807, Val Loss: 0.1740, Val Acc: 0.9330
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2794, Acc: 0.8809, Val Loss: 0.1763, Val Acc: 0.9315
Epoch 73/100, Loss: 0.2794, Acc: 0.8812, Val Loss: 0.1758, Val Acc: 0.9311
Epoch 74/100, Loss: 0.2793, Acc: 0.8813, Val Loss: 0.1752, Val Acc: 0.9319
Epoch 75/100, Loss: 0.2793, Acc: 0.8810, Val Loss: 0.1758, Val Acc: 0.9311
Epoch 76/100, Loss: 0.2794, Acc: 0.8809, Val Loss: 0.1790, Val Acc: 0.9297
Epoch 77/100, Loss: 0.2793, Acc: 0.8810, Val Loss: 0.1758, Val Acc: 0.9311
Epoch 78/100, Loss: 0.2792, Acc: 0.8806, Val Loss: 0.1785, Val Acc: 0.9297
Epoch 79/100, Loss: 0.2793, Acc: 0.8811, Val Loss: 0.1758, Val Acc: 0.9311
Epoch 80/100, Loss: 0.2788, Acc: 0.8809, Val Loss: 0.1768, Val Acc: 0.9289
Epoch 81/100, Loss: 0.2788, Acc: 0.8806, Val Loss: 0.1750, Val Acc: 0.9308
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2786, Acc: 0.8808, Val Loss: 0.1729, Val Acc: 0.9330
Epoch 83/100, Loss: 0.2786, Acc: 0.8809, Val Loss: 0.1734, Val Acc: 0.9326
Epoch 84/100, Loss: 0.2786, Acc: 0.8807, Val Loss: 0.1733, Val Acc: 0.9319
Epoch 85/100, Loss: 0.2785, Acc: 0.8799, Val Loss: 0.1755, Val Acc: 0.9293
Epoch 86/100, Loss: 0.2785, Acc: 0.8797, Val Loss: 0.1758, Val Acc: 0.9293
Epoch 87/100, Loss: 0.2785, Acc: 0.8813, Val Loss: 0.1734, Val Acc: 0.9326
Epoch 88/100, Loss: 0.2783, Acc: 0.8807, Val Loss: 0.1746, Val Acc: 0.9308
Epoch 89/100, Loss: 0.2782, Acc: 0.8817, Val Loss: 0.1734, Val Acc: 0.9315
Epoch 90/100, Loss: 0.2781, Acc: 0.8823, Val Loss: 0.1762, Val Acc: 0.9300
Epoch 91/100, Loss: 0.2780, Acc: 0.8807, Val Loss: 0.1752, Val Acc: 0.9308
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2781, Acc: 0.8813, Val Loss: 0.1777, Val Acc: 0.9293
Epoch 93/100, Loss: 0.2780, Acc: 0.8813, Val Loss: 0.1732, Val Acc: 0.9356
Epoch 94/100, Loss: 0.2778, Acc: 0.8816, Val Loss: 0.1747, Val Acc: 0.9311
Epoch 95/100, Loss: 0.2779, Acc: 0.8814, Val Loss: 0.1753, Val Acc: 0.9308
Epoch 96/100, Loss: 0.2778, Acc: 0.8817, Val Loss: 0.1772, Val Acc: 0.9282
Epoch 97/100, Loss: 0.2777, Acc: 0.8807, Val Loss: 0.1815, Val Acc: 0.9282
Epoch 98/100, Loss: 0.2780, Acc: 0.8820, Val Loss: 0.1774, Val Acc: 0.9286
Epoch 99/100, Loss: 0.2778, Acc: 0.8814, Val Loss: 0.1775, Val Acc: 0.9282
Epoch 100/100, Loss: 0.2777, Acc: 0.8818, Val Loss: 0.1719, Val Acc: 0.9367

##############################
Resultados para principal:  045  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5 
 {'training': [0.27769191157581086, 0.8818499448326591, 0.8990578734858681, 0.8601913171449596, 0.8791952618219423], 'validate': [0.1718898041087181, 0.9366715758468336, 0.9289855072463769, 0.9454277286135693, 0.9371345029239766], 'test': [1.4072165376058332, 0.5368080094228505, 0.5247087183607875, 0.7700471698113207, 0.6241338112305854]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  022  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  022  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  022  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5934, Acc: 0.7360, Val Loss: 0.3587, Val Acc: 0.9510
Mejor modelo guardado con Val Loss: 0.3587
Epoch 2/100, Loss: 0.4755, Acc: 0.7907, Val Loss: 0.2601, Val Acc: 0.9437
Mejor modelo guardado con Val Loss: 0.2601
Epoch 3/100, Loss: 0.4624, Acc: 0.7885, Val Loss: 0.2078, Val Acc: 0.9746
Mejor modelo guardado con Val Loss: 0.2078
Epoch 4/100, Loss: 0.4438, Acc: 0.7965, Val Loss: 0.2044, Val Acc: 0.9683
Mejor modelo guardado con Val Loss: 0.2044
Epoch 5/100, Loss: 0.4310, Acc: 0.8027, Val Loss: 0.1769, Val Acc: 0.9735
Mejor modelo guardado con Val Loss: 0.1769
Epoch 6/100, Loss: 0.4271, Acc: 0.8078, Val Loss: 0.2293, Val Acc: 0.9753
Epoch 7/100, Loss: 0.4246, Acc: 0.8077, Val Loss: 0.1764, Val Acc: 0.9543
Mejor modelo guardado con Val Loss: 0.1764
Epoch 8/100, Loss: 0.4178, Acc: 0.8106, Val Loss: 0.1305, Val Acc: 0.9739
Mejor modelo guardado con Val Loss: 0.1305
Epoch 9/100, Loss: 0.4139, Acc: 0.8147, Val Loss: 0.1289, Val Acc: 0.9720
Mejor modelo guardado con Val Loss: 0.1289
Epoch 10/100, Loss: 0.4142, Acc: 0.8106, Val Loss: 0.1425, Val Acc: 0.9772
Epoch 11/100, Loss: 0.4111, Acc: 0.8161, Val Loss: 0.1783, Val Acc: 0.9606
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4051, Acc: 0.8165, Val Loss: 0.1352, Val Acc: 0.9757
Epoch 13/100, Loss: 0.4025, Acc: 0.8197, Val Loss: 0.1347, Val Acc: 0.9786
Epoch 14/100, Loss: 0.4033, Acc: 0.8167, Val Loss: 0.1314, Val Acc: 0.9739
Epoch 15/100, Loss: 0.4031, Acc: 0.8191, Val Loss: 0.1208, Val Acc: 0.9812
Mejor modelo guardado con Val Loss: 0.1208
Epoch 16/100, Loss: 0.3982, Acc: 0.8214, Val Loss: 0.1244, Val Acc: 0.9757
Epoch 17/100, Loss: 0.3980, Acc: 0.8212, Val Loss: 0.1478, Val Acc: 0.9742
Epoch 18/100, Loss: 0.3971, Acc: 0.8232, Val Loss: 0.1397, Val Acc: 0.9768
Epoch 19/100, Loss: 0.3952, Acc: 0.8238, Val Loss: 0.1384, Val Acc: 0.9728
Epoch 20/100, Loss: 0.3960, Acc: 0.8225, Val Loss: 0.1275, Val Acc: 0.9757
Epoch 21/100, Loss: 0.3945, Acc: 0.8219, Val Loss: 0.1292, Val Acc: 0.9775
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3912, Acc: 0.8232, Val Loss: 0.1247, Val Acc: 0.9753
Epoch 23/100, Loss: 0.3888, Acc: 0.8270, Val Loss: 0.1284, Val Acc: 0.9713
Epoch 24/100, Loss: 0.3869, Acc: 0.8264, Val Loss: 0.1353, Val Acc: 0.9750
Epoch 25/100, Loss: 0.3892, Acc: 0.8235, Val Loss: 0.1345, Val Acc: 0.9720
Epoch 26/100, Loss: 0.3867, Acc: 0.8258, Val Loss: 0.1240, Val Acc: 0.9742
Epoch 27/100, Loss: 0.3870, Acc: 0.8256, Val Loss: 0.1389, Val Acc: 0.9702
Epoch 28/100, Loss: 0.3878, Acc: 0.8233, Val Loss: 0.1178, Val Acc: 0.9775
Mejor modelo guardado con Val Loss: 0.1178
Epoch 29/100, Loss: 0.3867, Acc: 0.8230, Val Loss: 0.1246, Val Acc: 0.9750
Epoch 30/100, Loss: 0.3852, Acc: 0.8271, Val Loss: 0.1327, Val Acc: 0.9742
Epoch 31/100, Loss: 0.3845, Acc: 0.8261, Val Loss: 0.1207, Val Acc: 0.9716
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3821, Acc: 0.8287, Val Loss: 0.1256, Val Acc: 0.9750
Epoch 33/100, Loss: 0.3811, Acc: 0.8297, Val Loss: 0.1154, Val Acc: 0.9775
Mejor modelo guardado con Val Loss: 0.1154
Epoch 34/100, Loss: 0.3816, Acc: 0.8270, Val Loss: 0.1209, Val Acc: 0.9742
Epoch 35/100, Loss: 0.3812, Acc: 0.8305, Val Loss: 0.1121, Val Acc: 0.9768
Mejor modelo guardado con Val Loss: 0.1121
Epoch 36/100, Loss: 0.3811, Acc: 0.8309, Val Loss: 0.1251, Val Acc: 0.9768
Epoch 37/100, Loss: 0.3806, Acc: 0.8313, Val Loss: 0.1267, Val Acc: 0.9753
Epoch 38/100, Loss: 0.3803, Acc: 0.8303, Val Loss: 0.1209, Val Acc: 0.9746
Epoch 39/100, Loss: 0.3797, Acc: 0.8305, Val Loss: 0.1174, Val Acc: 0.9742
Epoch 40/100, Loss: 0.3791, Acc: 0.8302, Val Loss: 0.1172, Val Acc: 0.9764
Epoch 41/100, Loss: 0.3801, Acc: 0.8325, Val Loss: 0.1193, Val Acc: 0.9750
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3781, Acc: 0.8347, Val Loss: 0.1218, Val Acc: 0.9753
Epoch 43/100, Loss: 0.3774, Acc: 0.8324, Val Loss: 0.1191, Val Acc: 0.9757
Epoch 44/100, Loss: 0.3781, Acc: 0.8306, Val Loss: 0.1190, Val Acc: 0.9750
Epoch 45/100, Loss: 0.3776, Acc: 0.8314, Val Loss: 0.1107, Val Acc: 0.9753
Mejor modelo guardado con Val Loss: 0.1107
Epoch 46/100, Loss: 0.3777, Acc: 0.8315, Val Loss: 0.1192, Val Acc: 0.9757
Epoch 47/100, Loss: 0.3772, Acc: 0.8316, Val Loss: 0.1227, Val Acc: 0.9746
Epoch 48/100, Loss: 0.3774, Acc: 0.8333, Val Loss: 0.1132, Val Acc: 0.9764
Epoch 49/100, Loss: 0.3776, Acc: 0.8299, Val Loss: 0.1117, Val Acc: 0.9757
Epoch 50/100, Loss: 0.3766, Acc: 0.8334, Val Loss: 0.1216, Val Acc: 0.9750
Epoch 51/100, Loss: 0.3770, Acc: 0.8322, Val Loss: 0.1183, Val Acc: 0.9742
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3760, Acc: 0.8345, Val Loss: 0.1217, Val Acc: 0.9750
Epoch 53/100, Loss: 0.3760, Acc: 0.8324, Val Loss: 0.1185, Val Acc: 0.9772
Epoch 54/100, Loss: 0.3761, Acc: 0.8331, Val Loss: 0.1142, Val Acc: 0.9761
Epoch 55/100, Loss: 0.3758, Acc: 0.8316, Val Loss: 0.1201, Val Acc: 0.9772
Epoch 56/100, Loss: 0.3756, Acc: 0.8328, Val Loss: 0.1202, Val Acc: 0.9768
Epoch 57/100, Loss: 0.3756, Acc: 0.8329, Val Loss: 0.1195, Val Acc: 0.9750
Epoch 58/100, Loss: 0.3756, Acc: 0.8329, Val Loss: 0.1162, Val Acc: 0.9761
Epoch 59/100, Loss: 0.3757, Acc: 0.8333, Val Loss: 0.1159, Val Acc: 0.9757
Epoch 60/100, Loss: 0.3756, Acc: 0.8331, Val Loss: 0.1190, Val Acc: 0.9742
Epoch 61/100, Loss: 0.3753, Acc: 0.8344, Val Loss: 0.1198, Val Acc: 0.9753
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3748, Acc: 0.8329, Val Loss: 0.1181, Val Acc: 0.9750
Epoch 63/100, Loss: 0.3747, Acc: 0.8329, Val Loss: 0.1188, Val Acc: 0.9750
Epoch 64/100, Loss: 0.3747, Acc: 0.8316, Val Loss: 0.1207, Val Acc: 0.9764
Epoch 65/100, Loss: 0.3748, Acc: 0.8339, Val Loss: 0.1179, Val Acc: 0.9750
Epoch 66/100, Loss: 0.3748, Acc: 0.8322, Val Loss: 0.1151, Val Acc: 0.9750
Epoch 67/100, Loss: 0.3748, Acc: 0.8341, Val Loss: 0.1165, Val Acc: 0.9750
Epoch 68/100, Loss: 0.3746, Acc: 0.8343, Val Loss: 0.1176, Val Acc: 0.9753
Epoch 69/100, Loss: 0.3746, Acc: 0.8336, Val Loss: 0.1159, Val Acc: 0.9746
Epoch 70/100, Loss: 0.3745, Acc: 0.8324, Val Loss: 0.1159, Val Acc: 0.9750
Epoch 71/100, Loss: 0.3746, Acc: 0.8341, Val Loss: 0.1163, Val Acc: 0.9742
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3744, Acc: 0.8337, Val Loss: 0.1170, Val Acc: 0.9753
Epoch 73/100, Loss: 0.3743, Acc: 0.8339, Val Loss: 0.1156, Val Acc: 0.9746
Epoch 74/100, Loss: 0.3742, Acc: 0.8343, Val Loss: 0.1165, Val Acc: 0.9742
Epoch 75/100, Loss: 0.3743, Acc: 0.8338, Val Loss: 0.1181, Val Acc: 0.9757
Epoch 76/100, Loss: 0.3742, Acc: 0.8337, Val Loss: 0.1181, Val Acc: 0.9753
Epoch 77/100, Loss: 0.3742, Acc: 0.8342, Val Loss: 0.1169, Val Acc: 0.9750
Epoch 78/100, Loss: 0.3742, Acc: 0.8343, Val Loss: 0.1163, Val Acc: 0.9742
Epoch 79/100, Loss: 0.3742, Acc: 0.8348, Val Loss: 0.1162, Val Acc: 0.9750
Epoch 80/100, Loss: 0.3742, Acc: 0.8330, Val Loss: 0.1164, Val Acc: 0.9746
Epoch 81/100, Loss: 0.3740, Acc: 0.8335, Val Loss: 0.1162, Val Acc: 0.9742
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3740, Acc: 0.8333, Val Loss: 0.1168, Val Acc: 0.9750
Epoch 83/100, Loss: 0.3741, Acc: 0.8329, Val Loss: 0.1162, Val Acc: 0.9750
Epoch 84/100, Loss: 0.3741, Acc: 0.8340, Val Loss: 0.1175, Val Acc: 0.9753
Epoch 85/100, Loss: 0.3740, Acc: 0.8332, Val Loss: 0.1181, Val Acc: 0.9750
Epoch 86/100, Loss: 0.3741, Acc: 0.8332, Val Loss: 0.1172, Val Acc: 0.9757
Epoch 87/100, Loss: 0.3740, Acc: 0.8343, Val Loss: 0.1162, Val Acc: 0.9750
Epoch 88/100, Loss: 0.3740, Acc: 0.8336, Val Loss: 0.1157, Val Acc: 0.9750
Epoch 89/100, Loss: 0.3739, Acc: 0.8347, Val Loss: 0.1175, Val Acc: 0.9753
Epoch 90/100, Loss: 0.3739, Acc: 0.8341, Val Loss: 0.1162, Val Acc: 0.9742
Epoch 91/100, Loss: 0.3739, Acc: 0.8334, Val Loss: 0.1157, Val Acc: 0.9750
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3738, Acc: 0.8335, Val Loss: 0.1155, Val Acc: 0.9746
Epoch 93/100, Loss: 0.3740, Acc: 0.8339, Val Loss: 0.1167, Val Acc: 0.9753
Epoch 94/100, Loss: 0.3739, Acc: 0.8341, Val Loss: 0.1171, Val Acc: 0.9750
Epoch 95/100, Loss: 0.3739, Acc: 0.8340, Val Loss: 0.1162, Val Acc: 0.9746
Epoch 96/100, Loss: 0.3738, Acc: 0.8340, Val Loss: 0.1159, Val Acc: 0.9742
Epoch 97/100, Loss: 0.3739, Acc: 0.8341, Val Loss: 0.1166, Val Acc: 0.9746
Epoch 98/100, Loss: 0.3737, Acc: 0.8339, Val Loss: 0.1159, Val Acc: 0.9742
Epoch 99/100, Loss: 0.3738, Acc: 0.8335, Val Loss: 0.1164, Val Acc: 0.9750
Epoch 100/100, Loss: 0.3737, Acc: 0.8340, Val Loss: 0.1161, Val Acc: 0.9750

##############################
Resultados para principal:  022  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  5 
 {'training': [0.373685063575725, 0.834038249356381, 0.8604327972999801, 0.7972774098601914, 0.8276520576721093], 'validate': [0.11605026226404101, 0.9749631811487481, 0.9763313609467456, 0.9734513274336283, 0.9748892171344166], 'test': [2.0265237347705773, 0.3707302709069494, 0.40143048725972286, 0.5294811320754716, 0.45664886854818204]}

##############################
Resultados para window:  5 
 {'104:093:088:055:045:022': {'training': [0.6554273192651924, 0.6141963957337256, 0.5941676792223572, 0.7196467991169978, 0.6509151414309484], 'validate': [0.5829831763755443, 0.7124447717231223, 0.7918781725888325, 0.5752212389380531, 0.6663818880820163], 'test': [0.5839393166480241, 0.730565371024735, 0.7024364955935718, 0.7989386792452831, 0.7475862068965518]}, '093:104:088:055:045:022': {'training': [0.5728162776770597, 0.7110150790731887, 0.7253784155690977, 0.6788079470198676, 0.701320916088568], 'validate': [0.9038460566553959, 0.4223122238586156, 0.4402021336327906, 0.5781710914454278, 0.499840612049729], 'test': [0.7911586573830357, 0.21643109540636044, 0.26814031715521386, 0.3290094339622642, 0.29547259729944403]}, '088:104:093:055:045:022': {'training': [0.6925793409829808, 0.5135159985288709, 0.5086217148293495, 0.7867917586460633, 0.6178403755868545], 'validate': [0.6813269077345382, 0.7529455081001473, 0.790008467400508, 0.6880530973451328, 0.7355143870713441], 'test': [0.6890201458224544, 0.60924617196702, 0.5818908122503329, 0.7729952830188679, 0.6639655609014941]}, '055:104:093:088:045:022': {'training': [0.6453599353930932, 0.6153916881206326, 0.6064209274673008, 0.6567328918322296, 0.6305749359710324], 'validate': [0.4785616283499917, 0.7783505154639175, 0.9170353982300885, 0.6113569321533924, 0.7336283185840708], 'test': [0.4616675230639952, 0.8259717314487632, 0.9694137638062872, 0.6727594339622641, 0.7942916811695092]}, '045:104:093:088:055:022': {'training': [0.27769191157581086, 0.8818499448326591, 0.8990578734858681, 0.8601913171449596, 0.8791952618219423], 'validate': [0.1718898041087181, 0.9366715758468336, 0.9289855072463769, 0.9454277286135693, 0.9371345029239766], 'test': [1.4072165376058332, 0.5368080094228505, 0.5247087183607875, 0.7700471698113207, 0.6241338112305854]}, '022:104:093:088:055:045': {'training': [0.373685063575725, 0.834038249356381, 0.8604327972999801, 0.7972774098601914, 0.8276520576721093], 'validate': [0.11605026226404101, 0.9749631811487481, 0.9763313609467456, 0.9734513274336283, 0.9748892171344166], 'test': [2.0265237347705773, 0.3707302709069494, 0.40143048725972286, 0.5294811320754716, 0.45664886854818204]}}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  062  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  062  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  062  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.3964, Acc: 0.8604, Val Loss: 0.6828, Val Acc: 0.6097
Mejor modelo guardado con Val Loss: 0.6828
Epoch 2/100, Loss: 0.3037, Acc: 0.8784, Val Loss: 0.7215, Val Acc: 0.5869
Epoch 3/100, Loss: 0.2898, Acc: 0.8838, Val Loss: 0.7560, Val Acc: 0.5961
Epoch 4/100, Loss: 0.2850, Acc: 0.8815, Val Loss: 0.7489, Val Acc: 0.6027
Epoch 5/100, Loss: 0.2724, Acc: 0.8876, Val Loss: 0.7438, Val Acc: 0.6108
Epoch 6/100, Loss: 0.2740, Acc: 0.8863, Val Loss: 0.7970, Val Acc: 0.6193
Epoch 7/100, Loss: 0.2720, Acc: 0.8866, Val Loss: 0.7487, Val Acc: 0.6141
Epoch 8/100, Loss: 0.2680, Acc: 0.8884, Val Loss: 0.7828, Val Acc: 0.6186
Epoch 9/100, Loss: 0.2645, Acc: 0.8903, Val Loss: 0.7852, Val Acc: 0.6123
Epoch 10/100, Loss: 0.2601, Acc: 0.8904, Val Loss: 0.7947, Val Acc: 0.6075
Epoch 11/100, Loss: 0.2605, Acc: 0.8930, Val Loss: 0.8298, Val Acc: 0.6116
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2489, Acc: 0.8950, Val Loss: 0.7595, Val Acc: 0.6182
Epoch 13/100, Loss: 0.2481, Acc: 0.8951, Val Loss: 0.7619, Val Acc: 0.6163
Epoch 14/100, Loss: 0.2514, Acc: 0.8932, Val Loss: 0.7572, Val Acc: 0.6145
Epoch 15/100, Loss: 0.2465, Acc: 0.8971, Val Loss: 0.8130, Val Acc: 0.6204
Epoch 16/100, Loss: 0.2441, Acc: 0.8974, Val Loss: 0.7862, Val Acc: 0.6167
Epoch 17/100, Loss: 0.2468, Acc: 0.8968, Val Loss: 0.8071, Val Acc: 0.6175
Epoch 18/100, Loss: 0.2457, Acc: 0.8949, Val Loss: 0.7555, Val Acc: 0.6171
Epoch 19/100, Loss: 0.2482, Acc: 0.8947, Val Loss: 0.8191, Val Acc: 0.6149
Epoch 20/100, Loss: 0.2442, Acc: 0.8970, Val Loss: 0.7808, Val Acc: 0.6211
Epoch 21/100, Loss: 0.2463, Acc: 0.8956, Val Loss: 0.8268, Val Acc: 0.6193
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2386, Acc: 0.8967, Val Loss: 0.8035, Val Acc: 0.6112
Epoch 23/100, Loss: 0.2371, Acc: 0.8992, Val Loss: 0.8292, Val Acc: 0.6204
Epoch 24/100, Loss: 0.2364, Acc: 0.9007, Val Loss: 0.7609, Val Acc: 0.6149
Epoch 25/100, Loss: 0.2356, Acc: 0.8997, Val Loss: 0.8642, Val Acc: 0.6167
Epoch 26/100, Loss: 0.2370, Acc: 0.8983, Val Loss: 0.8497, Val Acc: 0.6127
Epoch 27/100, Loss: 0.2350, Acc: 0.8991, Val Loss: 0.8506, Val Acc: 0.6138
Epoch 28/100, Loss: 0.2360, Acc: 0.8987, Val Loss: 0.8438, Val Acc: 0.6163
Epoch 29/100, Loss: 0.2374, Acc: 0.8973, Val Loss: 0.8027, Val Acc: 0.6112
Epoch 30/100, Loss: 0.2368, Acc: 0.8979, Val Loss: 0.7598, Val Acc: 0.6160
Epoch 31/100, Loss: 0.2343, Acc: 0.8985, Val Loss: 0.8189, Val Acc: 0.6156
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2314, Acc: 0.9008, Val Loss: 0.8213, Val Acc: 0.6152
Epoch 33/100, Loss: 0.2307, Acc: 0.9008, Val Loss: 0.8245, Val Acc: 0.6145
Epoch 34/100, Loss: 0.2298, Acc: 0.9007, Val Loss: 0.8527, Val Acc: 0.6156
Epoch 35/100, Loss: 0.2291, Acc: 0.9012, Val Loss: 0.8284, Val Acc: 0.6178
Epoch 36/100, Loss: 0.2319, Acc: 0.8992, Val Loss: 0.8340, Val Acc: 0.6175
Epoch 37/100, Loss: 0.2297, Acc: 0.9014, Val Loss: 0.8493, Val Acc: 0.6101
Epoch 38/100, Loss: 0.2304, Acc: 0.9014, Val Loss: 0.7882, Val Acc: 0.6141
Epoch 39/100, Loss: 0.2290, Acc: 0.9013, Val Loss: 0.8375, Val Acc: 0.6134
Epoch 40/100, Loss: 0.2288, Acc: 0.9016, Val Loss: 0.8430, Val Acc: 0.6160
Epoch 41/100, Loss: 0.2282, Acc: 0.9021, Val Loss: 0.8034, Val Acc: 0.6134
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2276, Acc: 0.9021, Val Loss: 0.8365, Val Acc: 0.6130
Epoch 43/100, Loss: 0.2265, Acc: 0.9024, Val Loss: 0.8289, Val Acc: 0.6130
Epoch 44/100, Loss: 0.2274, Acc: 0.9016, Val Loss: 0.8310, Val Acc: 0.6119
Epoch 45/100, Loss: 0.2274, Acc: 0.9015, Val Loss: 0.8364, Val Acc: 0.6141
Epoch 46/100, Loss: 0.2273, Acc: 0.9014, Val Loss: 0.8647, Val Acc: 0.6127
Epoch 47/100, Loss: 0.2260, Acc: 0.9012, Val Loss: 0.8321, Val Acc: 0.6167
Epoch 48/100, Loss: 0.2265, Acc: 0.9013, Val Loss: 0.8274, Val Acc: 0.6134
Epoch 49/100, Loss: 0.2262, Acc: 0.9024, Val Loss: 0.8616, Val Acc: 0.6134
Epoch 50/100, Loss: 0.2257, Acc: 0.9024, Val Loss: 0.8257, Val Acc: 0.6119
Epoch 51/100, Loss: 0.2263, Acc: 0.9023, Val Loss: 0.8661, Val Acc: 0.6152
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2251, Acc: 0.9021, Val Loss: 0.8684, Val Acc: 0.6145
Epoch 53/100, Loss: 0.2250, Acc: 0.9024, Val Loss: 0.8499, Val Acc: 0.6134
Epoch 54/100, Loss: 0.2244, Acc: 0.9036, Val Loss: 0.8464, Val Acc: 0.6127
Epoch 55/100, Loss: 0.2246, Acc: 0.9033, Val Loss: 0.8511, Val Acc: 0.6149
Epoch 56/100, Loss: 0.2244, Acc: 0.9020, Val Loss: 0.8497, Val Acc: 0.6138
Epoch 57/100, Loss: 0.2248, Acc: 0.9017, Val Loss: 0.8555, Val Acc: 0.6119
Epoch 58/100, Loss: 0.2247, Acc: 0.9030, Val Loss: 0.8697, Val Acc: 0.6156
Epoch 59/100, Loss: 0.2245, Acc: 0.9023, Val Loss: 0.8587, Val Acc: 0.6134
Epoch 60/100, Loss: 0.2242, Acc: 0.9034, Val Loss: 0.8495, Val Acc: 0.6152
Epoch 61/100, Loss: 0.2242, Acc: 0.9030, Val Loss: 0.8461, Val Acc: 0.6138
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2237, Acc: 0.9028, Val Loss: 0.8553, Val Acc: 0.6130
Epoch 63/100, Loss: 0.2235, Acc: 0.9035, Val Loss: 0.8498, Val Acc: 0.6163
Epoch 64/100, Loss: 0.2234, Acc: 0.9027, Val Loss: 0.8680, Val Acc: 0.6123
Epoch 65/100, Loss: 0.2236, Acc: 0.9030, Val Loss: 0.8551, Val Acc: 0.6119
Epoch 66/100, Loss: 0.2235, Acc: 0.9024, Val Loss: 0.8520, Val Acc: 0.6127
Epoch 67/100, Loss: 0.2235, Acc: 0.9035, Val Loss: 0.8478, Val Acc: 0.6156
Epoch 68/100, Loss: 0.2236, Acc: 0.9036, Val Loss: 0.8552, Val Acc: 0.6152
Epoch 69/100, Loss: 0.2233, Acc: 0.9021, Val Loss: 0.8611, Val Acc: 0.6119
Epoch 70/100, Loss: 0.2232, Acc: 0.9029, Val Loss: 0.8429, Val Acc: 0.6112
Epoch 71/100, Loss: 0.2233, Acc: 0.9030, Val Loss: 0.8582, Val Acc: 0.6175
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2231, Acc: 0.9029, Val Loss: 0.8573, Val Acc: 0.6127
Epoch 73/100, Loss: 0.2230, Acc: 0.9026, Val Loss: 0.8478, Val Acc: 0.6163
Epoch 74/100, Loss: 0.2230, Acc: 0.9035, Val Loss: 0.8469, Val Acc: 0.6152
Epoch 75/100, Loss: 0.2230, Acc: 0.9023, Val Loss: 0.8510, Val Acc: 0.6138
Epoch 76/100, Loss: 0.2228, Acc: 0.9032, Val Loss: 0.8542, Val Acc: 0.6160
Epoch 77/100, Loss: 0.2230, Acc: 0.9019, Val Loss: 0.8559, Val Acc: 0.6145
Epoch 78/100, Loss: 0.2229, Acc: 0.9028, Val Loss: 0.8523, Val Acc: 0.6160
Epoch 79/100, Loss: 0.2228, Acc: 0.9026, Val Loss: 0.8479, Val Acc: 0.6127
Epoch 80/100, Loss: 0.2230, Acc: 0.9027, Val Loss: 0.8524, Val Acc: 0.6145
Epoch 81/100, Loss: 0.2229, Acc: 0.9025, Val Loss: 0.8559, Val Acc: 0.6130
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2228, Acc: 0.9031, Val Loss: 0.8546, Val Acc: 0.6141
Epoch 83/100, Loss: 0.2228, Acc: 0.9026, Val Loss: 0.8537, Val Acc: 0.6127
Epoch 84/100, Loss: 0.2227, Acc: 0.9027, Val Loss: 0.8460, Val Acc: 0.6149
Epoch 85/100, Loss: 0.2228, Acc: 0.9020, Val Loss: 0.8586, Val Acc: 0.6123
Epoch 86/100, Loss: 0.2228, Acc: 0.9029, Val Loss: 0.8533, Val Acc: 0.6141
Epoch 87/100, Loss: 0.2227, Acc: 0.9026, Val Loss: 0.8610, Val Acc: 0.6119
Epoch 88/100, Loss: 0.2226, Acc: 0.9033, Val Loss: 0.8533, Val Acc: 0.6163
Epoch 89/100, Loss: 0.2226, Acc: 0.9032, Val Loss: 0.8564, Val Acc: 0.6134
Epoch 90/100, Loss: 0.2227, Acc: 0.9026, Val Loss: 0.8597, Val Acc: 0.6119
Epoch 91/100, Loss: 0.2227, Acc: 0.9029, Val Loss: 0.8594, Val Acc: 0.6123
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2224, Acc: 0.9032, Val Loss: 0.8534, Val Acc: 0.6123
Epoch 93/100, Loss: 0.2226, Acc: 0.9030, Val Loss: 0.8557, Val Acc: 0.6138
Epoch 94/100, Loss: 0.2226, Acc: 0.9028, Val Loss: 0.8562, Val Acc: 0.6145
Epoch 95/100, Loss: 0.2225, Acc: 0.9031, Val Loss: 0.8530, Val Acc: 0.6145
Epoch 96/100, Loss: 0.2226, Acc: 0.9024, Val Loss: 0.8486, Val Acc: 0.6152
Epoch 97/100, Loss: 0.2225, Acc: 0.9028, Val Loss: 0.8568, Val Acc: 0.6145
Epoch 98/100, Loss: 0.2225, Acc: 0.9028, Val Loss: 0.8518, Val Acc: 0.6163
Epoch 99/100, Loss: 0.2224, Acc: 0.9030, Val Loss: 0.8565, Val Acc: 0.6119
Epoch 100/100, Loss: 0.2225, Acc: 0.9028, Val Loss: 0.8599, Val Acc: 0.6127

##############################
Resultados para principal:  062  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5 
 {'training': [0.22248316389337627, 0.9028135343876426, 0.8996167183792663, 0.9067328918322296, 0.9031607879065506], 'validate': [0.8599225731436596, 0.6126656848306333, 0.6461538461538462, 0.49557522123893805, 0.5609348914858097], 'test': [0.3440843806774528, 0.8851590106007067, 0.8868483412322274, 0.8826650943396226, 0.8847517730496454]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  035  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  035  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  035  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6528, Acc: 0.6668, Val Loss: 0.6568, Val Acc: 0.5493
Mejor modelo guardado con Val Loss: 0.6568
Epoch 2/100, Loss: 0.5706, Acc: 0.7437, Val Loss: 0.5086, Val Acc: 0.7964
Mejor modelo guardado con Val Loss: 0.5086
Epoch 3/100, Loss: 0.5209, Acc: 0.7685, Val Loss: 0.4707, Val Acc: 0.8295
Mejor modelo guardado con Val Loss: 0.4707
Epoch 4/100, Loss: 0.5058, Acc: 0.7714, Val Loss: 0.4249, Val Acc: 0.8288
Mejor modelo guardado con Val Loss: 0.4249
Epoch 5/100, Loss: 0.4789, Acc: 0.7870, Val Loss: 0.4361, Val Acc: 0.8104
Epoch 6/100, Loss: 0.4808, Acc: 0.7790, Val Loss: 0.4281, Val Acc: 0.8196
Epoch 7/100, Loss: 0.4979, Acc: 0.7783, Val Loss: 0.4327, Val Acc: 0.8406
Epoch 8/100, Loss: 0.4801, Acc: 0.7872, Val Loss: 0.4295, Val Acc: 0.8229
Epoch 9/100, Loss: 0.4758, Acc: 0.7828, Val Loss: 0.4837, Val Acc: 0.7618
Epoch 10/100, Loss: 0.4679, Acc: 0.7898, Val Loss: 0.4666, Val Acc: 0.7853
Epoch 11/100, Loss: 0.4619, Acc: 0.7971, Val Loss: 0.4320, Val Acc: 0.8258
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4536, Acc: 0.7977, Val Loss: 0.4424, Val Acc: 0.8049
Epoch 13/100, Loss: 0.4501, Acc: 0.7978, Val Loss: 0.4788, Val Acc: 0.7717
Epoch 14/100, Loss: 0.4499, Acc: 0.7986, Val Loss: 0.4301, Val Acc: 0.8096
Epoch 15/100, Loss: 0.4475, Acc: 0.8008, Val Loss: 0.4819, Val Acc: 0.7607
Epoch 16/100, Loss: 0.4411, Acc: 0.8041, Val Loss: 0.4252, Val Acc: 0.8181
Epoch 17/100, Loss: 0.4450, Acc: 0.7989, Val Loss: 0.5596, Val Acc: 0.6981
Epoch 18/100, Loss: 0.4444, Acc: 0.7999, Val Loss: 0.4149, Val Acc: 0.8270
Mejor modelo guardado con Val Loss: 0.4149
Epoch 19/100, Loss: 0.4433, Acc: 0.7991, Val Loss: 0.4107, Val Acc: 0.8281
Mejor modelo guardado con Val Loss: 0.4107
Epoch 20/100, Loss: 0.4414, Acc: 0.7987, Val Loss: 0.4123, Val Acc: 0.8247
Epoch 21/100, Loss: 0.4375, Acc: 0.8019, Val Loss: 0.4104, Val Acc: 0.8288
Mejor modelo guardado con Val Loss: 0.4104
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4349, Acc: 0.8011, Val Loss: 0.4294, Val Acc: 0.8052
Epoch 23/100, Loss: 0.4323, Acc: 0.8042, Val Loss: 0.4520, Val Acc: 0.7802
Epoch 24/100, Loss: 0.4321, Acc: 0.8046, Val Loss: 0.4306, Val Acc: 0.8056
Epoch 25/100, Loss: 0.4331, Acc: 0.8054, Val Loss: 0.4293, Val Acc: 0.8074
Epoch 26/100, Loss: 0.4300, Acc: 0.8060, Val Loss: 0.4645, Val Acc: 0.7772
Epoch 27/100, Loss: 0.4305, Acc: 0.8067, Val Loss: 0.4370, Val Acc: 0.7949
Epoch 28/100, Loss: 0.4314, Acc: 0.8064, Val Loss: 0.4424, Val Acc: 0.7912
Epoch 29/100, Loss: 0.4301, Acc: 0.8029, Val Loss: 0.4478, Val Acc: 0.7872
Epoch 30/100, Loss: 0.4298, Acc: 0.8066, Val Loss: 0.4342, Val Acc: 0.7986
Epoch 31/100, Loss: 0.4299, Acc: 0.8049, Val Loss: 0.4526, Val Acc: 0.7846
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4256, Acc: 0.8064, Val Loss: 0.4218, Val Acc: 0.8122
Epoch 33/100, Loss: 0.4259, Acc: 0.8079, Val Loss: 0.4383, Val Acc: 0.7968
Epoch 34/100, Loss: 0.4250, Acc: 0.8074, Val Loss: 0.4190, Val Acc: 0.8119
Epoch 35/100, Loss: 0.4253, Acc: 0.8085, Val Loss: 0.4732, Val Acc: 0.7680
Epoch 36/100, Loss: 0.4243, Acc: 0.8087, Val Loss: 0.4386, Val Acc: 0.7934
Epoch 37/100, Loss: 0.4244, Acc: 0.8076, Val Loss: 0.4346, Val Acc: 0.7964
Epoch 38/100, Loss: 0.4229, Acc: 0.8092, Val Loss: 0.4211, Val Acc: 0.8089
Epoch 39/100, Loss: 0.4235, Acc: 0.8088, Val Loss: 0.4614, Val Acc: 0.7795
Epoch 40/100, Loss: 0.4229, Acc: 0.8062, Val Loss: 0.4339, Val Acc: 0.7997
Epoch 41/100, Loss: 0.4235, Acc: 0.8076, Val Loss: 0.4120, Val Acc: 0.8225
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4220, Acc: 0.8065, Val Loss: 0.4637, Val Acc: 0.7728
Epoch 43/100, Loss: 0.4216, Acc: 0.8066, Val Loss: 0.4113, Val Acc: 0.8196
Epoch 44/100, Loss: 0.4214, Acc: 0.8052, Val Loss: 0.4311, Val Acc: 0.7979
Epoch 45/100, Loss: 0.4210, Acc: 0.8084, Val Loss: 0.4342, Val Acc: 0.7982
Epoch 46/100, Loss: 0.4207, Acc: 0.8080, Val Loss: 0.4336, Val Acc: 0.7975
Epoch 47/100, Loss: 0.4206, Acc: 0.8073, Val Loss: 0.4199, Val Acc: 0.8115
Epoch 48/100, Loss: 0.4203, Acc: 0.8065, Val Loss: 0.4477, Val Acc: 0.7861
Epoch 49/100, Loss: 0.4201, Acc: 0.8091, Val Loss: 0.4139, Val Acc: 0.8177
Epoch 50/100, Loss: 0.4205, Acc: 0.8077, Val Loss: 0.4344, Val Acc: 0.7971
Epoch 51/100, Loss: 0.4189, Acc: 0.8072, Val Loss: 0.4234, Val Acc: 0.8085
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4193, Acc: 0.8073, Val Loss: 0.4250, Val Acc: 0.8030
Epoch 53/100, Loss: 0.4189, Acc: 0.8085, Val Loss: 0.4458, Val Acc: 0.7857
Epoch 54/100, Loss: 0.4186, Acc: 0.8076, Val Loss: 0.4239, Val Acc: 0.8045
Epoch 55/100, Loss: 0.4186, Acc: 0.8078, Val Loss: 0.4342, Val Acc: 0.7975
Epoch 56/100, Loss: 0.4185, Acc: 0.8081, Val Loss: 0.4218, Val Acc: 0.8052
Epoch 57/100, Loss: 0.4183, Acc: 0.8073, Val Loss: 0.4325, Val Acc: 0.7982
Epoch 58/100, Loss: 0.4188, Acc: 0.8088, Val Loss: 0.4300, Val Acc: 0.7986
Epoch 59/100, Loss: 0.4185, Acc: 0.8090, Val Loss: 0.4366, Val Acc: 0.7938
Epoch 60/100, Loss: 0.4184, Acc: 0.8076, Val Loss: 0.4363, Val Acc: 0.7946
Epoch 61/100, Loss: 0.4184, Acc: 0.8076, Val Loss: 0.4312, Val Acc: 0.7979
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4176, Acc: 0.8074, Val Loss: 0.4233, Val Acc: 0.8041
Epoch 63/100, Loss: 0.4175, Acc: 0.8087, Val Loss: 0.4378, Val Acc: 0.7923
Epoch 64/100, Loss: 0.4175, Acc: 0.8078, Val Loss: 0.4238, Val Acc: 0.8038
Epoch 65/100, Loss: 0.4175, Acc: 0.8083, Val Loss: 0.4307, Val Acc: 0.7986
Epoch 66/100, Loss: 0.4174, Acc: 0.8080, Val Loss: 0.4222, Val Acc: 0.8056
Epoch 67/100, Loss: 0.4175, Acc: 0.8072, Val Loss: 0.4277, Val Acc: 0.8004
Epoch 68/100, Loss: 0.4175, Acc: 0.8065, Val Loss: 0.4279, Val Acc: 0.8004
Epoch 69/100, Loss: 0.4174, Acc: 0.8083, Val Loss: 0.4246, Val Acc: 0.8023
Epoch 70/100, Loss: 0.4172, Acc: 0.8079, Val Loss: 0.4266, Val Acc: 0.8008
Epoch 71/100, Loss: 0.4172, Acc: 0.8080, Val Loss: 0.4320, Val Acc: 0.7975
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4171, Acc: 0.8077, Val Loss: 0.4304, Val Acc: 0.7986
Epoch 73/100, Loss: 0.4170, Acc: 0.8077, Val Loss: 0.4354, Val Acc: 0.7964
Epoch 74/100, Loss: 0.4171, Acc: 0.8082, Val Loss: 0.4308, Val Acc: 0.7990
Epoch 75/100, Loss: 0.4171, Acc: 0.8076, Val Loss: 0.4324, Val Acc: 0.7975
Epoch 76/100, Loss: 0.4173, Acc: 0.8077, Val Loss: 0.4310, Val Acc: 0.7982
Epoch 77/100, Loss: 0.4169, Acc: 0.8084, Val Loss: 0.4277, Val Acc: 0.7997
Epoch 78/100, Loss: 0.4169, Acc: 0.8082, Val Loss: 0.4279, Val Acc: 0.7990
Epoch 79/100, Loss: 0.4170, Acc: 0.8073, Val Loss: 0.4341, Val Acc: 0.7968
Epoch 80/100, Loss: 0.4169, Acc: 0.8083, Val Loss: 0.4294, Val Acc: 0.7997
Epoch 81/100, Loss: 0.4170, Acc: 0.8083, Val Loss: 0.4299, Val Acc: 0.7990
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4169, Acc: 0.8080, Val Loss: 0.4327, Val Acc: 0.7979
Epoch 83/100, Loss: 0.4168, Acc: 0.8081, Val Loss: 0.4295, Val Acc: 0.7993
Epoch 84/100, Loss: 0.4169, Acc: 0.8088, Val Loss: 0.4309, Val Acc: 0.7986
Epoch 85/100, Loss: 0.4168, Acc: 0.8076, Val Loss: 0.4231, Val Acc: 0.8041
Epoch 86/100, Loss: 0.4167, Acc: 0.8085, Val Loss: 0.4329, Val Acc: 0.7979
Epoch 87/100, Loss: 0.4169, Acc: 0.8079, Val Loss: 0.4325, Val Acc: 0.7975
Epoch 88/100, Loss: 0.4168, Acc: 0.8082, Val Loss: 0.4272, Val Acc: 0.8004
Epoch 89/100, Loss: 0.4169, Acc: 0.8080, Val Loss: 0.4311, Val Acc: 0.7964
Epoch 90/100, Loss: 0.4167, Acc: 0.8078, Val Loss: 0.4267, Val Acc: 0.8001
Epoch 91/100, Loss: 0.4168, Acc: 0.8085, Val Loss: 0.4263, Val Acc: 0.8008
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4167, Acc: 0.8080, Val Loss: 0.4336, Val Acc: 0.7968
Epoch 93/100, Loss: 0.4167, Acc: 0.8086, Val Loss: 0.4252, Val Acc: 0.8019
Epoch 94/100, Loss: 0.4167, Acc: 0.8086, Val Loss: 0.4251, Val Acc: 0.8012
Epoch 95/100, Loss: 0.4166, Acc: 0.8082, Val Loss: 0.4314, Val Acc: 0.7975
Epoch 96/100, Loss: 0.4167, Acc: 0.8077, Val Loss: 0.4273, Val Acc: 0.7997
Epoch 97/100, Loss: 0.4166, Acc: 0.8080, Val Loss: 0.4271, Val Acc: 0.8004
Epoch 98/100, Loss: 0.4165, Acc: 0.8090, Val Loss: 0.4271, Val Acc: 0.8004
Epoch 99/100, Loss: 0.4164, Acc: 0.8085, Val Loss: 0.4223, Val Acc: 0.8045
Epoch 100/100, Loss: 0.4166, Acc: 0.8074, Val Loss: 0.4276, Val Acc: 0.7993

##############################
Resultados para principal:  035  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5 
 {'training': [0.4166343723447413, 0.8073740345715337, 0.7907745865970409, 0.8357247976453275, 0.8126285663178606], 'validate': [0.42764521667430566, 0.7993372606774669, 0.7412254610350981, 0.9188790560471977, 0.8205465920316102], 'test': [0.509074445951868, 0.7553003533568905, 0.6961451247165533, 0.9050707547169812, 0.7869776980261471]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  002  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  002  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  002  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6851, Acc: 0.5556, Val Loss: 0.6911, Val Acc: 0.5479
Mejor modelo guardado con Val Loss: 0.6911
Epoch 2/100, Loss: 0.6875, Acc: 0.5386, Val Loss: 0.6913, Val Acc: 0.5368
Epoch 3/100, Loss: 0.6896, Acc: 0.5398, Val Loss: 0.6919, Val Acc: 0.5007
Epoch 4/100, Loss: 0.6865, Acc: 0.5611, Val Loss: 0.6917, Val Acc: 0.5306
Epoch 5/100, Loss: 0.6850, Acc: 0.5674, Val Loss: 0.6909, Val Acc: 0.5309
Mejor modelo guardado con Val Loss: 0.6909
Epoch 6/100, Loss: 0.6822, Acc: 0.5788, Val Loss: 0.6910, Val Acc: 0.5306
Epoch 7/100, Loss: 0.6827, Acc: 0.5705, Val Loss: 0.6897, Val Acc: 0.5486
Mejor modelo guardado con Val Loss: 0.6897
Epoch 8/100, Loss: 0.6809, Acc: 0.5736, Val Loss: 0.6928, Val Acc: 0.5210
Epoch 9/100, Loss: 0.6802, Acc: 0.5790, Val Loss: 0.6954, Val Acc: 0.5099
Epoch 10/100, Loss: 0.6788, Acc: 0.5772, Val Loss: 0.6902, Val Acc: 0.5493
Epoch 11/100, Loss: 0.6779, Acc: 0.5759, Val Loss: 0.6915, Val Acc: 0.5394
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6764, Acc: 0.5794, Val Loss: 0.6934, Val Acc: 0.5280
Epoch 13/100, Loss: 0.6753, Acc: 0.5885, Val Loss: 0.6930, Val Acc: 0.5225
Epoch 14/100, Loss: 0.6739, Acc: 0.5885, Val Loss: 0.6927, Val Acc: 0.5243
Epoch 15/100, Loss: 0.6743, Acc: 0.5862, Val Loss: 0.6929, Val Acc: 0.5265
Epoch 16/100, Loss: 0.6738, Acc: 0.5898, Val Loss: 0.6927, Val Acc: 0.5247
Epoch 17/100, Loss: 0.6730, Acc: 0.5910, Val Loss: 0.6925, Val Acc: 0.5372
Epoch 18/100, Loss: 0.6723, Acc: 0.5901, Val Loss: 0.6921, Val Acc: 0.5427
Epoch 19/100, Loss: 0.6736, Acc: 0.5877, Val Loss: 0.6924, Val Acc: 0.5409
Epoch 20/100, Loss: 0.6728, Acc: 0.5890, Val Loss: 0.6929, Val Acc: 0.5379
Epoch 21/100, Loss: 0.6721, Acc: 0.5908, Val Loss: 0.6940, Val Acc: 0.5287
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6712, Acc: 0.5906, Val Loss: 0.6930, Val Acc: 0.5280
Epoch 23/100, Loss: 0.6708, Acc: 0.5943, Val Loss: 0.6938, Val Acc: 0.5284
Epoch 24/100, Loss: 0.6706, Acc: 0.5940, Val Loss: 0.6933, Val Acc: 0.5339
Epoch 25/100, Loss: 0.6701, Acc: 0.5945, Val Loss: 0.6933, Val Acc: 0.5398
Epoch 26/100, Loss: 0.6703, Acc: 0.5933, Val Loss: 0.6943, Val Acc: 0.5284
Epoch 27/100, Loss: 0.6710, Acc: 0.5916, Val Loss: 0.6938, Val Acc: 0.5291
Epoch 28/100, Loss: 0.6698, Acc: 0.5934, Val Loss: 0.6939, Val Acc: 0.5324
Epoch 29/100, Loss: 0.6699, Acc: 0.5916, Val Loss: 0.6962, Val Acc: 0.5302
Epoch 30/100, Loss: 0.6685, Acc: 0.5915, Val Loss: 0.6942, Val Acc: 0.5379
Epoch 31/100, Loss: 0.6690, Acc: 0.5913, Val Loss: 0.6931, Val Acc: 0.5284
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6697, Acc: 0.5951, Val Loss: 0.6937, Val Acc: 0.5357
Epoch 33/100, Loss: 0.6689, Acc: 0.5970, Val Loss: 0.6939, Val Acc: 0.5339
Epoch 34/100, Loss: 0.6693, Acc: 0.5951, Val Loss: 0.6942, Val Acc: 0.5401
Epoch 35/100, Loss: 0.6689, Acc: 0.5966, Val Loss: 0.6942, Val Acc: 0.5331
Epoch 36/100, Loss: 0.6686, Acc: 0.5956, Val Loss: 0.6942, Val Acc: 0.5280
Epoch 37/100, Loss: 0.6687, Acc: 0.5959, Val Loss: 0.6941, Val Acc: 0.5280
Epoch 38/100, Loss: 0.6690, Acc: 0.5948, Val Loss: 0.6943, Val Acc: 0.5280
Epoch 39/100, Loss: 0.6692, Acc: 0.5929, Val Loss: 0.6944, Val Acc: 0.5276
Epoch 40/100, Loss: 0.6686, Acc: 0.5959, Val Loss: 0.6944, Val Acc: 0.5401
Epoch 41/100, Loss: 0.6689, Acc: 0.5930, Val Loss: 0.6943, Val Acc: 0.5353
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6685, Acc: 0.5952, Val Loss: 0.6943, Val Acc: 0.5284
Epoch 43/100, Loss: 0.6682, Acc: 0.5966, Val Loss: 0.6944, Val Acc: 0.5365
Epoch 44/100, Loss: 0.6684, Acc: 0.5947, Val Loss: 0.6945, Val Acc: 0.5368
Epoch 45/100, Loss: 0.6682, Acc: 0.5979, Val Loss: 0.6947, Val Acc: 0.5365
Epoch 46/100, Loss: 0.6683, Acc: 0.5963, Val Loss: 0.6945, Val Acc: 0.5339
Epoch 47/100, Loss: 0.6682, Acc: 0.5976, Val Loss: 0.6946, Val Acc: 0.5350
Epoch 48/100, Loss: 0.6682, Acc: 0.5964, Val Loss: 0.6945, Val Acc: 0.5376
Epoch 49/100, Loss: 0.6680, Acc: 0.5972, Val Loss: 0.6945, Val Acc: 0.5361
Epoch 50/100, Loss: 0.6680, Acc: 0.5975, Val Loss: 0.6945, Val Acc: 0.5302
Epoch 51/100, Loss: 0.6681, Acc: 0.5968, Val Loss: 0.6946, Val Acc: 0.5335
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6677, Acc: 0.5975, Val Loss: 0.6947, Val Acc: 0.5357
Epoch 53/100, Loss: 0.6679, Acc: 0.5967, Val Loss: 0.6946, Val Acc: 0.5339
Epoch 54/100, Loss: 0.6678, Acc: 0.5970, Val Loss: 0.6946, Val Acc: 0.5298
Epoch 55/100, Loss: 0.6674, Acc: 0.5963, Val Loss: 0.6946, Val Acc: 0.5368
Epoch 56/100, Loss: 0.6666, Acc: 0.5976, Val Loss: 0.6940, Val Acc: 0.5324
Epoch 57/100, Loss: 0.6656, Acc: 0.5974, Val Loss: 0.6940, Val Acc: 0.5298
Epoch 58/100, Loss: 0.6655, Acc: 0.5976, Val Loss: 0.6941, Val Acc: 0.5276
Epoch 59/100, Loss: 0.6652, Acc: 0.5973, Val Loss: 0.6942, Val Acc: 0.5284
Epoch 60/100, Loss: 0.6651, Acc: 0.5977, Val Loss: 0.6943, Val Acc: 0.5291
Epoch 61/100, Loss: 0.6649, Acc: 0.5973, Val Loss: 0.6946, Val Acc: 0.5295
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6648, Acc: 0.5970, Val Loss: 0.6945, Val Acc: 0.5298
Epoch 63/100, Loss: 0.6646, Acc: 0.5981, Val Loss: 0.6945, Val Acc: 0.5339
Epoch 64/100, Loss: 0.6646, Acc: 0.5986, Val Loss: 0.6945, Val Acc: 0.5335
Epoch 65/100, Loss: 0.6645, Acc: 0.5986, Val Loss: 0.6945, Val Acc: 0.5317
Epoch 66/100, Loss: 0.6644, Acc: 0.5978, Val Loss: 0.6946, Val Acc: 0.5287
Epoch 67/100, Loss: 0.6644, Acc: 0.5971, Val Loss: 0.6947, Val Acc: 0.5287
Epoch 68/100, Loss: 0.6643, Acc: 0.5971, Val Loss: 0.6946, Val Acc: 0.5309
Epoch 69/100, Loss: 0.6642, Acc: 0.5987, Val Loss: 0.6946, Val Acc: 0.5328
Epoch 70/100, Loss: 0.6641, Acc: 0.5987, Val Loss: 0.6947, Val Acc: 0.5298
Epoch 71/100, Loss: 0.6641, Acc: 0.5982, Val Loss: 0.6947, Val Acc: 0.5350
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6640, Acc: 0.5984, Val Loss: 0.6947, Val Acc: 0.5284
Epoch 73/100, Loss: 0.6640, Acc: 0.5970, Val Loss: 0.6947, Val Acc: 0.5302
Epoch 74/100, Loss: 0.6639, Acc: 0.5986, Val Loss: 0.6947, Val Acc: 0.5306
Epoch 75/100, Loss: 0.6639, Acc: 0.5977, Val Loss: 0.6947, Val Acc: 0.5295
Epoch 76/100, Loss: 0.6639, Acc: 0.5984, Val Loss: 0.6947, Val Acc: 0.5309
Epoch 77/100, Loss: 0.6638, Acc: 0.5984, Val Loss: 0.6947, Val Acc: 0.5324
Epoch 78/100, Loss: 0.6638, Acc: 0.5985, Val Loss: 0.6948, Val Acc: 0.5328
Epoch 79/100, Loss: 0.6638, Acc: 0.5987, Val Loss: 0.6948, Val Acc: 0.5302
Epoch 80/100, Loss: 0.6637, Acc: 0.5976, Val Loss: 0.6948, Val Acc: 0.5313
Epoch 81/100, Loss: 0.6636, Acc: 0.5985, Val Loss: 0.6948, Val Acc: 0.5335
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6637, Acc: 0.5979, Val Loss: 0.6948, Val Acc: 0.5317
Epoch 83/100, Loss: 0.6635, Acc: 0.5983, Val Loss: 0.6948, Val Acc: 0.5350
Epoch 84/100, Loss: 0.6636, Acc: 0.5977, Val Loss: 0.6948, Val Acc: 0.5320
Epoch 85/100, Loss: 0.6635, Acc: 0.5975, Val Loss: 0.6949, Val Acc: 0.5298
Epoch 86/100, Loss: 0.6635, Acc: 0.5978, Val Loss: 0.6949, Val Acc: 0.5302
Epoch 87/100, Loss: 0.6634, Acc: 0.5986, Val Loss: 0.6949, Val Acc: 0.5272
Epoch 88/100, Loss: 0.6634, Acc: 0.5993, Val Loss: 0.6949, Val Acc: 0.5284
Epoch 89/100, Loss: 0.6632, Acc: 0.5983, Val Loss: 0.6948, Val Acc: 0.5328
Epoch 90/100, Loss: 0.6633, Acc: 0.5988, Val Loss: 0.6948, Val Acc: 0.5342
Epoch 91/100, Loss: 0.6632, Acc: 0.5987, Val Loss: 0.6949, Val Acc: 0.5298
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6631, Acc: 0.5981, Val Loss: 0.6948, Val Acc: 0.5295
Epoch 93/100, Loss: 0.6631, Acc: 0.5988, Val Loss: 0.6948, Val Acc: 0.5295
Epoch 94/100, Loss: 0.6630, Acc: 0.5980, Val Loss: 0.6948, Val Acc: 0.5306
Epoch 95/100, Loss: 0.6630, Acc: 0.5976, Val Loss: 0.6948, Val Acc: 0.5313
Epoch 96/100, Loss: 0.6629, Acc: 0.5993, Val Loss: 0.6949, Val Acc: 0.5280
Epoch 97/100, Loss: 0.6629, Acc: 0.5987, Val Loss: 0.6948, Val Acc: 0.5302
Epoch 98/100, Loss: 0.6628, Acc: 0.5976, Val Loss: 0.6948, Val Acc: 0.5295
Epoch 99/100, Loss: 0.6627, Acc: 0.5984, Val Loss: 0.6948, Val Acc: 0.5309
Epoch 100/100, Loss: 0.6627, Acc: 0.5987, Val Loss: 0.6949, Val Acc: 0.5298

##############################
Resultados para principal:  002  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5 
 {'training': [0.6627478295058264, 0.5987495402721589, 0.5704521556256572, 0.7983811626195733, 0.6654400490647041], 'validate': [0.6948596142059149, 0.5298232695139912, 0.5198992443324937, 0.7610619469026548, 0.6177791080514816], 'test': [0.6663873537823006, 0.6339811542991755, 0.6287663445139283, 0.652122641509434, 0.640231548480463]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  043  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  043  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  043  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5286, Acc: 0.7928, Val Loss: 0.6175, Val Acc: 0.6432
Mejor modelo guardado con Val Loss: 0.6175
Epoch 2/100, Loss: 0.4101, Acc: 0.8271, Val Loss: 0.6139, Val Acc: 0.6734
Mejor modelo guardado con Val Loss: 0.6139
Epoch 3/100, Loss: 0.3714, Acc: 0.8396, Val Loss: 0.6778, Val Acc: 0.6362
Epoch 4/100, Loss: 0.3597, Acc: 0.8441, Val Loss: 0.6455, Val Acc: 0.6480
Epoch 5/100, Loss: 0.3534, Acc: 0.8465, Val Loss: 0.6229, Val Acc: 0.7025
Epoch 6/100, Loss: 0.3464, Acc: 0.8483, Val Loss: 0.5992, Val Acc: 0.6955
Mejor modelo guardado con Val Loss: 0.5992
Epoch 7/100, Loss: 0.3446, Acc: 0.8469, Val Loss: 0.6807, Val Acc: 0.6300
Epoch 8/100, Loss: 0.3437, Acc: 0.8508, Val Loss: 0.6197, Val Acc: 0.6819
Epoch 9/100, Loss: 0.3529, Acc: 0.8419, Val Loss: 0.6218, Val Acc: 0.6955
Epoch 10/100, Loss: 0.3406, Acc: 0.8529, Val Loss: 0.6222, Val Acc: 0.6775
Epoch 11/100, Loss: 0.3351, Acc: 0.8533, Val Loss: 0.6335, Val Acc: 0.6661
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3291, Acc: 0.8545, Val Loss: 0.6462, Val Acc: 0.6697
Epoch 13/100, Loss: 0.3238, Acc: 0.8577, Val Loss: 0.6925, Val Acc: 0.6649
Epoch 14/100, Loss: 0.3245, Acc: 0.8584, Val Loss: 0.6524, Val Acc: 0.6749
Epoch 15/100, Loss: 0.3261, Acc: 0.8570, Val Loss: 0.6071, Val Acc: 0.6940
Epoch 16/100, Loss: 0.3208, Acc: 0.8579, Val Loss: 0.6789, Val Acc: 0.6502
Epoch 17/100, Loss: 0.3206, Acc: 0.8579, Val Loss: 0.6496, Val Acc: 0.6668
Epoch 18/100, Loss: 0.3197, Acc: 0.8571, Val Loss: 0.6262, Val Acc: 0.6800
Epoch 19/100, Loss: 0.3167, Acc: 0.8594, Val Loss: 0.6119, Val Acc: 0.6926
Epoch 20/100, Loss: 0.3273, Acc: 0.8536, Val Loss: 0.6078, Val Acc: 0.7047
Epoch 21/100, Loss: 0.3182, Acc: 0.8603, Val Loss: 0.6253, Val Acc: 0.6775
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3218, Acc: 0.8575, Val Loss: 0.5950, Val Acc: 0.6915
Mejor modelo guardado con Val Loss: 0.5950
Epoch 23/100, Loss: 0.3146, Acc: 0.8619, Val Loss: 0.6253, Val Acc: 0.6808
Epoch 24/100, Loss: 0.3124, Acc: 0.8615, Val Loss: 0.6604, Val Acc: 0.6719
Epoch 25/100, Loss: 0.3140, Acc: 0.8593, Val Loss: 0.6282, Val Acc: 0.6962
Epoch 26/100, Loss: 0.3097, Acc: 0.8624, Val Loss: 0.6326, Val Acc: 0.6981
Epoch 27/100, Loss: 0.3099, Acc: 0.8615, Val Loss: 0.6489, Val Acc: 0.6918
Epoch 28/100, Loss: 0.3100, Acc: 0.8625, Val Loss: 0.6145, Val Acc: 0.6852
Epoch 29/100, Loss: 0.3096, Acc: 0.8613, Val Loss: 0.6212, Val Acc: 0.6992
Epoch 30/100, Loss: 0.3069, Acc: 0.8619, Val Loss: 0.6185, Val Acc: 0.6992
Epoch 31/100, Loss: 0.3071, Acc: 0.8660, Val Loss: 0.6585, Val Acc: 0.6830
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3039, Acc: 0.8657, Val Loss: 0.6526, Val Acc: 0.6870
Epoch 33/100, Loss: 0.3036, Acc: 0.8653, Val Loss: 0.6510, Val Acc: 0.6742
Epoch 34/100, Loss: 0.3035, Acc: 0.8663, Val Loss: 0.6596, Val Acc: 0.6778
Epoch 35/100, Loss: 0.3018, Acc: 0.8650, Val Loss: 0.6425, Val Acc: 0.6815
Epoch 36/100, Loss: 0.3016, Acc: 0.8691, Val Loss: 0.6438, Val Acc: 0.6867
Epoch 37/100, Loss: 0.3005, Acc: 0.8674, Val Loss: 0.6573, Val Acc: 0.6708
Epoch 38/100, Loss: 0.3011, Acc: 0.8671, Val Loss: 0.6245, Val Acc: 0.6985
Epoch 39/100, Loss: 0.3018, Acc: 0.8667, Val Loss: 0.6437, Val Acc: 0.6892
Epoch 40/100, Loss: 0.3005, Acc: 0.8670, Val Loss: 0.6559, Val Acc: 0.6734
Epoch 41/100, Loss: 0.3004, Acc: 0.8657, Val Loss: 0.6314, Val Acc: 0.6837
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2984, Acc: 0.8675, Val Loss: 0.6502, Val Acc: 0.6808
Epoch 43/100, Loss: 0.2979, Acc: 0.8679, Val Loss: 0.6349, Val Acc: 0.6996
Epoch 44/100, Loss: 0.2982, Acc: 0.8679, Val Loss: 0.6411, Val Acc: 0.6848
Epoch 45/100, Loss: 0.2976, Acc: 0.8682, Val Loss: 0.6479, Val Acc: 0.6996
Epoch 46/100, Loss: 0.2973, Acc: 0.8698, Val Loss: 0.6502, Val Acc: 0.6797
Epoch 47/100, Loss: 0.2974, Acc: 0.8683, Val Loss: 0.6460, Val Acc: 0.7051
Epoch 48/100, Loss: 0.2972, Acc: 0.8685, Val Loss: 0.6326, Val Acc: 0.6996
Epoch 49/100, Loss: 0.2968, Acc: 0.8698, Val Loss: 0.6396, Val Acc: 0.6841
Epoch 50/100, Loss: 0.2970, Acc: 0.8709, Val Loss: 0.6644, Val Acc: 0.6800
Epoch 51/100, Loss: 0.2966, Acc: 0.8693, Val Loss: 0.6250, Val Acc: 0.6996
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2958, Acc: 0.8693, Val Loss: 0.6349, Val Acc: 0.6955
Epoch 53/100, Loss: 0.2955, Acc: 0.8699, Val Loss: 0.6506, Val Acc: 0.6775
Epoch 54/100, Loss: 0.2950, Acc: 0.8690, Val Loss: 0.6405, Val Acc: 0.6841
Epoch 55/100, Loss: 0.2954, Acc: 0.8687, Val Loss: 0.6462, Val Acc: 0.6889
Epoch 56/100, Loss: 0.2955, Acc: 0.8693, Val Loss: 0.6322, Val Acc: 0.6985
Epoch 57/100, Loss: 0.2949, Acc: 0.8696, Val Loss: 0.6404, Val Acc: 0.6926
Epoch 58/100, Loss: 0.2947, Acc: 0.8696, Val Loss: 0.6442, Val Acc: 0.7003
Epoch 59/100, Loss: 0.2950, Acc: 0.8693, Val Loss: 0.6353, Val Acc: 0.6870
Epoch 60/100, Loss: 0.2948, Acc: 0.8693, Val Loss: 0.6347, Val Acc: 0.6929
Epoch 61/100, Loss: 0.2944, Acc: 0.8689, Val Loss: 0.6383, Val Acc: 0.6811
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2940, Acc: 0.8702, Val Loss: 0.6444, Val Acc: 0.6940
Epoch 63/100, Loss: 0.2942, Acc: 0.8686, Val Loss: 0.6388, Val Acc: 0.6937
Epoch 64/100, Loss: 0.2940, Acc: 0.8694, Val Loss: 0.6406, Val Acc: 0.6937
Epoch 65/100, Loss: 0.2938, Acc: 0.8696, Val Loss: 0.6412, Val Acc: 0.6977
Epoch 66/100, Loss: 0.2939, Acc: 0.8701, Val Loss: 0.6334, Val Acc: 0.6962
Epoch 67/100, Loss: 0.2939, Acc: 0.8700, Val Loss: 0.6396, Val Acc: 0.6859
Epoch 68/100, Loss: 0.2939, Acc: 0.8693, Val Loss: 0.6389, Val Acc: 0.6915
Epoch 69/100, Loss: 0.2938, Acc: 0.8696, Val Loss: 0.6423, Val Acc: 0.6907
Epoch 70/100, Loss: 0.2936, Acc: 0.8698, Val Loss: 0.6336, Val Acc: 0.7003
Epoch 71/100, Loss: 0.2937, Acc: 0.8699, Val Loss: 0.6349, Val Acc: 0.6981
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2937, Acc: 0.8698, Val Loss: 0.6426, Val Acc: 0.6863
Epoch 73/100, Loss: 0.2934, Acc: 0.8694, Val Loss: 0.6356, Val Acc: 0.6970
Epoch 74/100, Loss: 0.2934, Acc: 0.8696, Val Loss: 0.6420, Val Acc: 0.6878
Epoch 75/100, Loss: 0.2935, Acc: 0.8694, Val Loss: 0.6419, Val Acc: 0.6870
Epoch 76/100, Loss: 0.2932, Acc: 0.8697, Val Loss: 0.6404, Val Acc: 0.6962
Epoch 77/100, Loss: 0.2932, Acc: 0.8702, Val Loss: 0.6375, Val Acc: 0.6944
Epoch 78/100, Loss: 0.2934, Acc: 0.8705, Val Loss: 0.6419, Val Acc: 0.6834
Epoch 79/100, Loss: 0.2933, Acc: 0.8695, Val Loss: 0.6414, Val Acc: 0.6870
Epoch 80/100, Loss: 0.2932, Acc: 0.8696, Val Loss: 0.6427, Val Acc: 0.6892
Epoch 81/100, Loss: 0.2932, Acc: 0.8696, Val Loss: 0.6402, Val Acc: 0.6944
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2932, Acc: 0.8700, Val Loss: 0.6384, Val Acc: 0.6966
Epoch 83/100, Loss: 0.2932, Acc: 0.8691, Val Loss: 0.6423, Val Acc: 0.6915
Epoch 84/100, Loss: 0.2931, Acc: 0.8694, Val Loss: 0.6395, Val Acc: 0.6970
Epoch 85/100, Loss: 0.2932, Acc: 0.8704, Val Loss: 0.6404, Val Acc: 0.6889
Epoch 86/100, Loss: 0.2930, Acc: 0.8695, Val Loss: 0.6379, Val Acc: 0.6951
Epoch 87/100, Loss: 0.2930, Acc: 0.8706, Val Loss: 0.6406, Val Acc: 0.6870
Epoch 88/100, Loss: 0.2931, Acc: 0.8698, Val Loss: 0.6418, Val Acc: 0.6845
Epoch 89/100, Loss: 0.2930, Acc: 0.8692, Val Loss: 0.6415, Val Acc: 0.6907
Epoch 90/100, Loss: 0.2928, Acc: 0.8697, Val Loss: 0.6400, Val Acc: 0.6926
Epoch 91/100, Loss: 0.2930, Acc: 0.8698, Val Loss: 0.6422, Val Acc: 0.6881
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2929, Acc: 0.8701, Val Loss: 0.6426, Val Acc: 0.6911
Epoch 93/100, Loss: 0.2928, Acc: 0.8702, Val Loss: 0.6434, Val Acc: 0.6845
Epoch 94/100, Loss: 0.2927, Acc: 0.8697, Val Loss: 0.6440, Val Acc: 0.6856
Epoch 95/100, Loss: 0.2927, Acc: 0.8708, Val Loss: 0.6416, Val Acc: 0.6892
Epoch 96/100, Loss: 0.2929, Acc: 0.8709, Val Loss: 0.6403, Val Acc: 0.6955
Epoch 97/100, Loss: 0.2926, Acc: 0.8696, Val Loss: 0.6422, Val Acc: 0.6830
Epoch 98/100, Loss: 0.2928, Acc: 0.8705, Val Loss: 0.6429, Val Acc: 0.6878
Epoch 99/100, Loss: 0.2926, Acc: 0.8713, Val Loss: 0.6414, Val Acc: 0.6881
Epoch 100/100, Loss: 0.2928, Acc: 0.8699, Val Loss: 0.6409, Val Acc: 0.6874

##############################
Resultados para principal:  043  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5 
 {'training': [0.2927814944674312, 0.8698970209635896, 0.8785539446431934, 0.8583517292126563, 0.8683353493998325], 'validate': [0.6409224729205287, 0.6874079528718704, 0.716852010265184, 0.6179941002949852, 0.6637623762376238], 'test': [0.3955574367471315, 0.8077149587750294, 0.7552618697993148, 0.9097877358490566, 0.8253543728269591]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  073  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  073  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  073  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6761, Acc: 0.5683, Val Loss: 0.7185, Val Acc: 0.4536
Mejor modelo guardado con Val Loss: 0.7185
Epoch 2/100, Loss: 0.6857, Acc: 0.5285, Val Loss: 0.7236, Val Acc: 0.3689
Epoch 3/100, Loss: 0.6730, Acc: 0.5848, Val Loss: 0.7165, Val Acc: 0.4308
Mejor modelo guardado con Val Loss: 0.7165
Epoch 4/100, Loss: 0.6691, Acc: 0.5912, Val Loss: 0.7751, Val Acc: 0.3152
Epoch 5/100, Loss: 0.6577, Acc: 0.6079, Val Loss: 0.7021, Val Acc: 0.4982
Mejor modelo guardado con Val Loss: 0.7021
Epoch 6/100, Loss: 0.6618, Acc: 0.5902, Val Loss: 0.7046, Val Acc: 0.4930
Epoch 7/100, Loss: 0.6465, Acc: 0.6169, Val Loss: 0.7284, Val Acc: 0.4525
Epoch 8/100, Loss: 0.6454, Acc: 0.6133, Val Loss: 0.7061, Val Acc: 0.4912
Epoch 9/100, Loss: 0.6415, Acc: 0.6113, Val Loss: 0.7045, Val Acc: 0.4945
Epoch 10/100, Loss: 0.6384, Acc: 0.6167, Val Loss: 0.7564, Val Acc: 0.4345
Epoch 11/100, Loss: 0.6386, Acc: 0.6200, Val Loss: 0.7151, Val Acc: 0.4812
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6309, Acc: 0.6208, Val Loss: 0.7094, Val Acc: 0.4893
Epoch 13/100, Loss: 0.6345, Acc: 0.6169, Val Loss: 0.7412, Val Acc: 0.4580
Epoch 14/100, Loss: 0.6312, Acc: 0.6228, Val Loss: 0.7159, Val Acc: 0.4849
Epoch 15/100, Loss: 0.6273, Acc: 0.6252, Val Loss: 0.7186, Val Acc: 0.4809
Epoch 16/100, Loss: 0.6293, Acc: 0.6220, Val Loss: 0.7218, Val Acc: 0.4809
Epoch 17/100, Loss: 0.6272, Acc: 0.6233, Val Loss: 0.7833, Val Acc: 0.4183
Epoch 18/100, Loss: 0.6273, Acc: 0.6222, Val Loss: 0.7405, Val Acc: 0.4635
Epoch 19/100, Loss: 0.6262, Acc: 0.6251, Val Loss: 0.8481, Val Acc: 0.3708
Epoch 20/100, Loss: 0.6288, Acc: 0.6188, Val Loss: 0.7223, Val Acc: 0.4735
Epoch 21/100, Loss: 0.6279, Acc: 0.6252, Val Loss: 0.7183, Val Acc: 0.4786
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6249, Acc: 0.6268, Val Loss: 0.7750, Val Acc: 0.4404
Epoch 23/100, Loss: 0.6249, Acc: 0.6248, Val Loss: 0.7269, Val Acc: 0.4739
Epoch 24/100, Loss: 0.6226, Acc: 0.6284, Val Loss: 0.7357, Val Acc: 0.4728
Epoch 25/100, Loss: 0.6228, Acc: 0.6288, Val Loss: 0.7317, Val Acc: 0.4742
Epoch 26/100, Loss: 0.6218, Acc: 0.6257, Val Loss: 0.7214, Val Acc: 0.4827
Epoch 27/100, Loss: 0.6212, Acc: 0.6268, Val Loss: 0.7319, Val Acc: 0.4750
Epoch 28/100, Loss: 0.6217, Acc: 0.6264, Val Loss: 0.7269, Val Acc: 0.4779
Epoch 29/100, Loss: 0.6202, Acc: 0.6296, Val Loss: 0.7646, Val Acc: 0.4455
Epoch 30/100, Loss: 0.6187, Acc: 0.6308, Val Loss: 0.7460, Val Acc: 0.4654
Epoch 31/100, Loss: 0.6195, Acc: 0.6294, Val Loss: 0.7414, Val Acc: 0.4676
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6190, Acc: 0.6294, Val Loss: 0.7241, Val Acc: 0.4794
Epoch 33/100, Loss: 0.6187, Acc: 0.6287, Val Loss: 0.7252, Val Acc: 0.4809
Epoch 34/100, Loss: 0.6179, Acc: 0.6298, Val Loss: 0.7536, Val Acc: 0.4566
Epoch 35/100, Loss: 0.6184, Acc: 0.6294, Val Loss: 0.7219, Val Acc: 0.4820
Epoch 36/100, Loss: 0.6187, Acc: 0.6274, Val Loss: 0.7264, Val Acc: 0.4768
Epoch 37/100, Loss: 0.6190, Acc: 0.6270, Val Loss: 0.7229, Val Acc: 0.4823
Epoch 38/100, Loss: 0.6189, Acc: 0.6277, Val Loss: 0.7239, Val Acc: 0.4820
Epoch 39/100, Loss: 0.6180, Acc: 0.6288, Val Loss: 0.7210, Val Acc: 0.4849
Epoch 40/100, Loss: 0.6194, Acc: 0.6261, Val Loss: 0.7344, Val Acc: 0.4709
Epoch 41/100, Loss: 0.6180, Acc: 0.6298, Val Loss: 0.7262, Val Acc: 0.4816
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6175, Acc: 0.6302, Val Loss: 0.7329, Val Acc: 0.4728
Epoch 43/100, Loss: 0.6175, Acc: 0.6294, Val Loss: 0.7325, Val Acc: 0.4742
Epoch 44/100, Loss: 0.6176, Acc: 0.6308, Val Loss: 0.7269, Val Acc: 0.4794
Epoch 45/100, Loss: 0.6172, Acc: 0.6307, Val Loss: 0.7256, Val Acc: 0.4812
Epoch 46/100, Loss: 0.6170, Acc: 0.6304, Val Loss: 0.7354, Val Acc: 0.4713
Epoch 47/100, Loss: 0.6171, Acc: 0.6288, Val Loss: 0.7290, Val Acc: 0.4757
Epoch 48/100, Loss: 0.6172, Acc: 0.6294, Val Loss: 0.7361, Val Acc: 0.4713
Epoch 49/100, Loss: 0.6175, Acc: 0.6308, Val Loss: 0.7341, Val Acc: 0.4720
Epoch 50/100, Loss: 0.6170, Acc: 0.6303, Val Loss: 0.7290, Val Acc: 0.4772
Epoch 51/100, Loss: 0.6171, Acc: 0.6296, Val Loss: 0.7352, Val Acc: 0.4724
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6168, Acc: 0.6311, Val Loss: 0.7347, Val Acc: 0.4724
Epoch 53/100, Loss: 0.6167, Acc: 0.6306, Val Loss: 0.7334, Val Acc: 0.4728
Epoch 54/100, Loss: 0.6165, Acc: 0.6309, Val Loss: 0.7358, Val Acc: 0.4716
Epoch 55/100, Loss: 0.6165, Acc: 0.6301, Val Loss: 0.7297, Val Acc: 0.4761
Epoch 56/100, Loss: 0.6164, Acc: 0.6309, Val Loss: 0.7336, Val Acc: 0.4728
Epoch 57/100, Loss: 0.6166, Acc: 0.6292, Val Loss: 0.7306, Val Acc: 0.4757
Epoch 58/100, Loss: 0.6168, Acc: 0.6307, Val Loss: 0.7255, Val Acc: 0.4812
Epoch 59/100, Loss: 0.6167, Acc: 0.6288, Val Loss: 0.7292, Val Acc: 0.4764
Epoch 60/100, Loss: 0.6163, Acc: 0.6296, Val Loss: 0.7302, Val Acc: 0.4757
Epoch 61/100, Loss: 0.6165, Acc: 0.6300, Val Loss: 0.7274, Val Acc: 0.4786
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6163, Acc: 0.6305, Val Loss: 0.7290, Val Acc: 0.4764
Epoch 63/100, Loss: 0.6163, Acc: 0.6307, Val Loss: 0.7300, Val Acc: 0.4761
Epoch 64/100, Loss: 0.6163, Acc: 0.6310, Val Loss: 0.7301, Val Acc: 0.4757
Epoch 65/100, Loss: 0.6161, Acc: 0.6307, Val Loss: 0.7308, Val Acc: 0.4739
Epoch 66/100, Loss: 0.6162, Acc: 0.6300, Val Loss: 0.7336, Val Acc: 0.4728
Epoch 67/100, Loss: 0.6161, Acc: 0.6309, Val Loss: 0.7287, Val Acc: 0.4775
Epoch 68/100, Loss: 0.6161, Acc: 0.6310, Val Loss: 0.7283, Val Acc: 0.4779
Epoch 69/100, Loss: 0.6161, Acc: 0.6300, Val Loss: 0.7334, Val Acc: 0.4728
Epoch 70/100, Loss: 0.6161, Acc: 0.6313, Val Loss: 0.7305, Val Acc: 0.4761
Epoch 71/100, Loss: 0.6161, Acc: 0.6298, Val Loss: 0.7312, Val Acc: 0.4739
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6160, Acc: 0.6310, Val Loss: 0.7312, Val Acc: 0.4742
Epoch 73/100, Loss: 0.6160, Acc: 0.6309, Val Loss: 0.7316, Val Acc: 0.4739
Epoch 74/100, Loss: 0.6160, Acc: 0.6308, Val Loss: 0.7306, Val Acc: 0.4757
Epoch 75/100, Loss: 0.6160, Acc: 0.6305, Val Loss: 0.7317, Val Acc: 0.4735
Epoch 76/100, Loss: 0.6160, Acc: 0.6304, Val Loss: 0.7300, Val Acc: 0.4761
Epoch 77/100, Loss: 0.6160, Acc: 0.6314, Val Loss: 0.7301, Val Acc: 0.4761
Epoch 78/100, Loss: 0.6160, Acc: 0.6307, Val Loss: 0.7307, Val Acc: 0.4753
Epoch 79/100, Loss: 0.6159, Acc: 0.6300, Val Loss: 0.7320, Val Acc: 0.4735
Epoch 80/100, Loss: 0.6160, Acc: 0.6313, Val Loss: 0.7315, Val Acc: 0.4739
Epoch 81/100, Loss: 0.6160, Acc: 0.6308, Val Loss: 0.7320, Val Acc: 0.4735
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6159, Acc: 0.6309, Val Loss: 0.7294, Val Acc: 0.4768
Epoch 83/100, Loss: 0.6159, Acc: 0.6300, Val Loss: 0.7313, Val Acc: 0.4742
Epoch 84/100, Loss: 0.6159, Acc: 0.6311, Val Loss: 0.7314, Val Acc: 0.4742
Epoch 85/100, Loss: 0.6159, Acc: 0.6313, Val Loss: 0.7317, Val Acc: 0.4735
Epoch 86/100, Loss: 0.6160, Acc: 0.6305, Val Loss: 0.7310, Val Acc: 0.4742
Epoch 87/100, Loss: 0.6159, Acc: 0.6311, Val Loss: 0.7315, Val Acc: 0.4735
Epoch 88/100, Loss: 0.6159, Acc: 0.6308, Val Loss: 0.7319, Val Acc: 0.4735
Epoch 89/100, Loss: 0.6159, Acc: 0.6315, Val Loss: 0.7319, Val Acc: 0.4735
Epoch 90/100, Loss: 0.6159, Acc: 0.6309, Val Loss: 0.7309, Val Acc: 0.4750
Epoch 91/100, Loss: 0.6158, Acc: 0.6304, Val Loss: 0.7296, Val Acc: 0.4772
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6159, Acc: 0.6312, Val Loss: 0.7302, Val Acc: 0.4761
Epoch 93/100, Loss: 0.6159, Acc: 0.6304, Val Loss: 0.7324, Val Acc: 0.4735
Epoch 94/100, Loss: 0.6158, Acc: 0.6311, Val Loss: 0.7323, Val Acc: 0.4735
Epoch 95/100, Loss: 0.6159, Acc: 0.6307, Val Loss: 0.7314, Val Acc: 0.4742
Epoch 96/100, Loss: 0.6159, Acc: 0.6308, Val Loss: 0.7307, Val Acc: 0.4753
Epoch 97/100, Loss: 0.6158, Acc: 0.6312, Val Loss: 0.7314, Val Acc: 0.4739
Epoch 98/100, Loss: 0.6159, Acc: 0.6305, Val Loss: 0.7321, Val Acc: 0.4735
Epoch 99/100, Loss: 0.6158, Acc: 0.6307, Val Loss: 0.7329, Val Acc: 0.4735
Epoch 100/100, Loss: 0.6158, Acc: 0.6311, Val Loss: 0.7307, Val Acc: 0.4753

##############################
Resultados para principal:  073  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5 
 {'training': [0.6157953777528941, 0.6311143802868702, 0.5788133717068851, 0.9619205298013245, 0.7227366966136834], 'validate': [0.730695437553317, 0.47533136966126655, 0.48698604300264053, 0.9520648967551623, 0.644372348390317], 'test': [0.7021348045931922, 0.4994110718492344, 0.4994110718492344, 1.0, 0.6661429693637078]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  109  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  109  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  109  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6555, Acc: 0.6227, Val Loss: 0.7244, Val Acc: 0.4853
Mejor modelo guardado con Val Loss: 0.7244
Epoch 2/100, Loss: 0.6173, Acc: 0.6658, Val Loss: 0.7335, Val Acc: 0.4856
Epoch 3/100, Loss: 0.5999, Acc: 0.6719, Val Loss: 0.7601, Val Acc: 0.4768
Epoch 4/100, Loss: 0.5902, Acc: 0.6822, Val Loss: 0.7522, Val Acc: 0.4746
Epoch 5/100, Loss: 0.5830, Acc: 0.6823, Val Loss: 0.7590, Val Acc: 0.4775
Epoch 6/100, Loss: 0.5798, Acc: 0.6843, Val Loss: 0.7457, Val Acc: 0.4797
Epoch 7/100, Loss: 0.5746, Acc: 0.6796, Val Loss: 0.7550, Val Acc: 0.4871
Epoch 8/100, Loss: 0.5725, Acc: 0.6811, Val Loss: 0.7816, Val Acc: 0.4639
Epoch 9/100, Loss: 0.5648, Acc: 0.6874, Val Loss: 0.7720, Val Acc: 0.4820
Epoch 10/100, Loss: 0.5637, Acc: 0.6875, Val Loss: 0.7637, Val Acc: 0.4930
Epoch 11/100, Loss: 0.5637, Acc: 0.6939, Val Loss: 0.7654, Val Acc: 0.4974
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5521, Acc: 0.6900, Val Loss: 0.7679, Val Acc: 0.4890
Epoch 13/100, Loss: 0.5492, Acc: 0.6931, Val Loss: 0.7838, Val Acc: 0.4772
Epoch 14/100, Loss: 0.5510, Acc: 0.6923, Val Loss: 0.7646, Val Acc: 0.5055
Epoch 15/100, Loss: 0.5482, Acc: 0.7114, Val Loss: 0.7702, Val Acc: 0.4993
Epoch 16/100, Loss: 0.5463, Acc: 0.7178, Val Loss: 0.7788, Val Acc: 0.4831
Epoch 17/100, Loss: 0.5436, Acc: 0.7224, Val Loss: 0.7773, Val Acc: 0.4912
Epoch 18/100, Loss: 0.5408, Acc: 0.7252, Val Loss: 0.7883, Val Acc: 0.4536
Epoch 19/100, Loss: 0.5437, Acc: 0.7209, Val Loss: 0.7793, Val Acc: 0.4775
Epoch 20/100, Loss: 0.5432, Acc: 0.7254, Val Loss: 0.7741, Val Acc: 0.4941
Epoch 21/100, Loss: 0.5379, Acc: 0.7292, Val Loss: 0.7753, Val Acc: 0.4816
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5353, Acc: 0.7334, Val Loss: 0.7789, Val Acc: 0.4853
Epoch 23/100, Loss: 0.5335, Acc: 0.7335, Val Loss: 0.7832, Val Acc: 0.4926
Epoch 24/100, Loss: 0.5337, Acc: 0.7336, Val Loss: 0.7855, Val Acc: 0.4882
Epoch 25/100, Loss: 0.5329, Acc: 0.7324, Val Loss: 0.7857, Val Acc: 0.4919
Epoch 26/100, Loss: 0.5316, Acc: 0.7363, Val Loss: 0.7767, Val Acc: 0.4952
Epoch 27/100, Loss: 0.5319, Acc: 0.7362, Val Loss: 0.7786, Val Acc: 0.4956
Epoch 28/100, Loss: 0.5344, Acc: 0.7311, Val Loss: 0.7765, Val Acc: 0.4971
Epoch 29/100, Loss: 0.5310, Acc: 0.7375, Val Loss: 0.7846, Val Acc: 0.4761
Epoch 30/100, Loss: 0.5302, Acc: 0.7374, Val Loss: 0.7914, Val Acc: 0.4779
Epoch 31/100, Loss: 0.5297, Acc: 0.7373, Val Loss: 0.7916, Val Acc: 0.4820
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5273, Acc: 0.7407, Val Loss: 0.7878, Val Acc: 0.4945
Epoch 33/100, Loss: 0.5268, Acc: 0.7402, Val Loss: 0.7879, Val Acc: 0.4930
Epoch 34/100, Loss: 0.5276, Acc: 0.7379, Val Loss: 0.7896, Val Acc: 0.4890
Epoch 35/100, Loss: 0.5267, Acc: 0.7381, Val Loss: 0.7876, Val Acc: 0.4923
Epoch 36/100, Loss: 0.5258, Acc: 0.7409, Val Loss: 0.7875, Val Acc: 0.4945
Epoch 37/100, Loss: 0.5262, Acc: 0.7421, Val Loss: 0.7852, Val Acc: 0.4996
Epoch 38/100, Loss: 0.5240, Acc: 0.7426, Val Loss: 0.7902, Val Acc: 0.4845
Epoch 39/100, Loss: 0.5258, Acc: 0.7409, Val Loss: 0.7909, Val Acc: 0.4912
Epoch 40/100, Loss: 0.5253, Acc: 0.7417, Val Loss: 0.7917, Val Acc: 0.4794
Epoch 41/100, Loss: 0.5243, Acc: 0.7422, Val Loss: 0.7924, Val Acc: 0.4816
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5235, Acc: 0.7428, Val Loss: 0.7895, Val Acc: 0.4963
Epoch 43/100, Loss: 0.5232, Acc: 0.7423, Val Loss: 0.7927, Val Acc: 0.4823
Epoch 44/100, Loss: 0.5230, Acc: 0.7428, Val Loss: 0.7883, Val Acc: 0.5000
Epoch 45/100, Loss: 0.5232, Acc: 0.7410, Val Loss: 0.7905, Val Acc: 0.4897
Epoch 46/100, Loss: 0.5226, Acc: 0.7439, Val Loss: 0.7941, Val Acc: 0.4842
Epoch 47/100, Loss: 0.5228, Acc: 0.7423, Val Loss: 0.7914, Val Acc: 0.4967
Epoch 48/100, Loss: 0.5221, Acc: 0.7425, Val Loss: 0.8000, Val Acc: 0.4812
Epoch 49/100, Loss: 0.5223, Acc: 0.7415, Val Loss: 0.7961, Val Acc: 0.4926
Epoch 50/100, Loss: 0.5220, Acc: 0.7424, Val Loss: 0.7978, Val Acc: 0.4878
Epoch 51/100, Loss: 0.5216, Acc: 0.7459, Val Loss: 0.8044, Val Acc: 0.4746
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5211, Acc: 0.7447, Val Loss: 0.7989, Val Acc: 0.4882
Epoch 53/100, Loss: 0.5209, Acc: 0.7437, Val Loss: 0.8019, Val Acc: 0.4820
Epoch 54/100, Loss: 0.5209, Acc: 0.7439, Val Loss: 0.8013, Val Acc: 0.4794
Epoch 55/100, Loss: 0.5206, Acc: 0.7431, Val Loss: 0.8002, Val Acc: 0.4838
Epoch 56/100, Loss: 0.5203, Acc: 0.7447, Val Loss: 0.7994, Val Acc: 0.4849
Epoch 57/100, Loss: 0.5204, Acc: 0.7440, Val Loss: 0.7991, Val Acc: 0.4886
Epoch 58/100, Loss: 0.5206, Acc: 0.7436, Val Loss: 0.8004, Val Acc: 0.4856
Epoch 59/100, Loss: 0.5203, Acc: 0.7420, Val Loss: 0.7982, Val Acc: 0.4982
Epoch 60/100, Loss: 0.5197, Acc: 0.7438, Val Loss: 0.7984, Val Acc: 0.4963
Epoch 61/100, Loss: 0.5200, Acc: 0.7440, Val Loss: 0.8004, Val Acc: 0.4915
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5198, Acc: 0.7452, Val Loss: 0.8010, Val Acc: 0.4878
Epoch 63/100, Loss: 0.5196, Acc: 0.7433, Val Loss: 0.8004, Val Acc: 0.4904
Epoch 64/100, Loss: 0.5196, Acc: 0.7439, Val Loss: 0.8013, Val Acc: 0.4867
Epoch 65/100, Loss: 0.5197, Acc: 0.7429, Val Loss: 0.8029, Val Acc: 0.4849
Epoch 66/100, Loss: 0.5197, Acc: 0.7433, Val Loss: 0.8013, Val Acc: 0.4893
Epoch 67/100, Loss: 0.5195, Acc: 0.7449, Val Loss: 0.8012, Val Acc: 0.4897
Epoch 68/100, Loss: 0.5195, Acc: 0.7446, Val Loss: 0.8003, Val Acc: 0.4930
Epoch 69/100, Loss: 0.5195, Acc: 0.7447, Val Loss: 0.8010, Val Acc: 0.4919
Epoch 70/100, Loss: 0.5193, Acc: 0.7443, Val Loss: 0.8022, Val Acc: 0.4871
Epoch 71/100, Loss: 0.5192, Acc: 0.7454, Val Loss: 0.8028, Val Acc: 0.4856
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5193, Acc: 0.7429, Val Loss: 0.8020, Val Acc: 0.4875
Epoch 73/100, Loss: 0.5192, Acc: 0.7436, Val Loss: 0.8019, Val Acc: 0.4893
Epoch 74/100, Loss: 0.5191, Acc: 0.7448, Val Loss: 0.8029, Val Acc: 0.4860
Epoch 75/100, Loss: 0.5191, Acc: 0.7439, Val Loss: 0.8019, Val Acc: 0.4912
Epoch 76/100, Loss: 0.5192, Acc: 0.7441, Val Loss: 0.8019, Val Acc: 0.4890
Epoch 77/100, Loss: 0.5191, Acc: 0.7437, Val Loss: 0.8027, Val Acc: 0.4867
Epoch 78/100, Loss: 0.5190, Acc: 0.7447, Val Loss: 0.8021, Val Acc: 0.4864
Epoch 79/100, Loss: 0.5190, Acc: 0.7447, Val Loss: 0.8020, Val Acc: 0.4890
Epoch 80/100, Loss: 0.5190, Acc: 0.7437, Val Loss: 0.8026, Val Acc: 0.4882
Epoch 81/100, Loss: 0.5189, Acc: 0.7438, Val Loss: 0.8027, Val Acc: 0.4867
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5190, Acc: 0.7440, Val Loss: 0.8029, Val Acc: 0.4867
Epoch 83/100, Loss: 0.5189, Acc: 0.7437, Val Loss: 0.8021, Val Acc: 0.4886
Epoch 84/100, Loss: 0.5188, Acc: 0.7449, Val Loss: 0.8024, Val Acc: 0.4893
Epoch 85/100, Loss: 0.5189, Acc: 0.7438, Val Loss: 0.8029, Val Acc: 0.4871
Epoch 86/100, Loss: 0.5189, Acc: 0.7429, Val Loss: 0.8028, Val Acc: 0.4867
Epoch 87/100, Loss: 0.5188, Acc: 0.7443, Val Loss: 0.8032, Val Acc: 0.4871
Epoch 88/100, Loss: 0.5188, Acc: 0.7431, Val Loss: 0.8030, Val Acc: 0.4875
Epoch 89/100, Loss: 0.5189, Acc: 0.7448, Val Loss: 0.8030, Val Acc: 0.4867
Epoch 90/100, Loss: 0.5189, Acc: 0.7436, Val Loss: 0.8024, Val Acc: 0.4890
Epoch 91/100, Loss: 0.5187, Acc: 0.7447, Val Loss: 0.8027, Val Acc: 0.4886
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5186, Acc: 0.7435, Val Loss: 0.8034, Val Acc: 0.4878
Epoch 93/100, Loss: 0.5187, Acc: 0.7453, Val Loss: 0.8042, Val Acc: 0.4860
Epoch 94/100, Loss: 0.5185, Acc: 0.7452, Val Loss: 0.8036, Val Acc: 0.4890
Epoch 95/100, Loss: 0.5186, Acc: 0.7452, Val Loss: 0.8034, Val Acc: 0.4875
Epoch 96/100, Loss: 0.5185, Acc: 0.7452, Val Loss: 0.8038, Val Acc: 0.4871
Epoch 97/100, Loss: 0.5186, Acc: 0.7447, Val Loss: 0.8029, Val Acc: 0.4886
Epoch 98/100, Loss: 0.5186, Acc: 0.7442, Val Loss: 0.8034, Val Acc: 0.4867
Epoch 99/100, Loss: 0.5185, Acc: 0.7449, Val Loss: 0.8041, Val Acc: 0.4860
Epoch 100/100, Loss: 0.5182, Acc: 0.7432, Val Loss: 0.8045, Val Acc: 0.4860

##############################
Resultados para principal:  109  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  5 
 {'training': [0.518247346342728, 0.7431960279514528, 0.7021569527306104, 0.8443708609271523, 0.7667251315459784], 'validate': [0.804478736810906, 0.48600883652430044, 0.49158957106812445, 0.862094395280236, 0.6261381896089984], 'test': [0.7019360451786606, 0.5206124852767963, 0.5119047619047619, 0.8620283018867925, 0.6423550087873462]}

##############################
Resultados para window:  5 
 {'062:035:002:043:073:109': {'training': [0.22248316389337627, 0.9028135343876426, 0.8996167183792663, 0.9067328918322296, 0.9031607879065506], 'validate': [0.8599225731436596, 0.6126656848306333, 0.6461538461538462, 0.49557522123893805, 0.5609348914858097], 'test': [0.3440843806774528, 0.8851590106007067, 0.8868483412322274, 0.8826650943396226, 0.8847517730496454]}, '035:062:002:043:073:109': {'training': [0.4166343723447413, 0.8073740345715337, 0.7907745865970409, 0.8357247976453275, 0.8126285663178606], 'validate': [0.42764521667430566, 0.7993372606774669, 0.7412254610350981, 0.9188790560471977, 0.8205465920316102], 'test': [0.509074445951868, 0.7553003533568905, 0.6961451247165533, 0.9050707547169812, 0.7869776980261471]}, '002:062:035:043:073:109': {'training': [0.6627478295058264, 0.5987495402721589, 0.5704521556256572, 0.7983811626195733, 0.6654400490647041], 'validate': [0.6948596142059149, 0.5298232695139912, 0.5198992443324937, 0.7610619469026548, 0.6177791080514816], 'test': [0.6663873537823006, 0.6339811542991755, 0.6287663445139283, 0.652122641509434, 0.640231548480463]}, '043:062:035:002:073:109': {'training': [0.2927814944674312, 0.8698970209635896, 0.8785539446431934, 0.8583517292126563, 0.8683353493998325], 'validate': [0.6409224729205287, 0.6874079528718704, 0.716852010265184, 0.6179941002949852, 0.6637623762376238], 'test': [0.3955574367471315, 0.8077149587750294, 0.7552618697993148, 0.9097877358490566, 0.8253543728269591]}, '073:062:035:002:043:109': {'training': [0.6157953777528941, 0.6311143802868702, 0.5788133717068851, 0.9619205298013245, 0.7227366966136834], 'validate': [0.730695437553317, 0.47533136966126655, 0.48698604300264053, 0.9520648967551623, 0.644372348390317], 'test': [0.7021348045931922, 0.4994110718492344, 0.4994110718492344, 1.0, 0.6661429693637078]}, '109:062:035:002:043:073': {'training': [0.518247346342728, 0.7431960279514528, 0.7021569527306104, 0.8443708609271523, 0.7667251315459784], 'validate': [0.804478736810906, 0.48600883652430044, 0.49158957106812445, 0.862094395280236, 0.6261381896089984], 'test': [0.7019360451786606, 0.5206124852767963, 0.5119047619047619, 0.8620283018867925, 0.6423550087873462]}}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  098  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  098  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  098  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6409, Acc: 0.6387, Val Loss: 0.5219, Val Acc: 0.8660
Mejor modelo guardado con Val Loss: 0.5219
Epoch 2/100, Loss: 0.6024, Acc: 0.6534, Val Loss: 0.5280, Val Acc: 0.8472
Epoch 3/100, Loss: 0.5835, Acc: 0.6675, Val Loss: 0.4607, Val Acc: 0.8586
Mejor modelo guardado con Val Loss: 0.4607
Epoch 4/100, Loss: 0.5684, Acc: 0.6811, Val Loss: 0.4547, Val Acc: 0.8428
Mejor modelo guardado con Val Loss: 0.4547
Epoch 5/100, Loss: 0.5606, Acc: 0.7079, Val Loss: 0.4987, Val Acc: 0.8262
Epoch 6/100, Loss: 0.5566, Acc: 0.7155, Val Loss: 0.4098, Val Acc: 0.8594
Mejor modelo guardado con Val Loss: 0.4098
Epoch 7/100, Loss: 0.5490, Acc: 0.7287, Val Loss: 0.4080, Val Acc: 0.8513
Mejor modelo guardado con Val Loss: 0.4080
Epoch 8/100, Loss: 0.5403, Acc: 0.7306, Val Loss: 0.4524, Val Acc: 0.8096
Epoch 9/100, Loss: 0.5410, Acc: 0.7249, Val Loss: 0.4370, Val Acc: 0.8270
Epoch 10/100, Loss: 0.5381, Acc: 0.7313, Val Loss: 0.3988, Val Acc: 0.8417
Mejor modelo guardado con Val Loss: 0.3988
Epoch 11/100, Loss: 0.5338, Acc: 0.7347, Val Loss: 0.4086, Val Acc: 0.8432
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5240, Acc: 0.7406, Val Loss: 0.3891, Val Acc: 0.8428
Mejor modelo guardado con Val Loss: 0.3891
Epoch 13/100, Loss: 0.5240, Acc: 0.7399, Val Loss: 0.3622, Val Acc: 0.8822
Mejor modelo guardado con Val Loss: 0.3622
Epoch 14/100, Loss: 0.5222, Acc: 0.7412, Val Loss: 0.3779, Val Acc: 0.8465
Epoch 15/100, Loss: 0.5214, Acc: 0.7405, Val Loss: 0.3979, Val Acc: 0.8457
Epoch 16/100, Loss: 0.5189, Acc: 0.7428, Val Loss: 0.4162, Val Acc: 0.8185
Epoch 17/100, Loss: 0.5170, Acc: 0.7458, Val Loss: 0.3972, Val Acc: 0.8365
Epoch 18/100, Loss: 0.5201, Acc: 0.7414, Val Loss: 0.3745, Val Acc: 0.8594
Epoch 19/100, Loss: 0.5157, Acc: 0.7415, Val Loss: 0.3995, Val Acc: 0.8443
Epoch 20/100, Loss: 0.5165, Acc: 0.7458, Val Loss: 0.3632, Val Acc: 0.8675
Epoch 21/100, Loss: 0.5156, Acc: 0.7416, Val Loss: 0.3864, Val Acc: 0.8461
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5128, Acc: 0.7434, Val Loss: 0.3855, Val Acc: 0.8513
Epoch 23/100, Loss: 0.5118, Acc: 0.7476, Val Loss: 0.4100, Val Acc: 0.8325
Epoch 24/100, Loss: 0.5115, Acc: 0.7464, Val Loss: 0.4123, Val Acc: 0.8339
Epoch 25/100, Loss: 0.5111, Acc: 0.7452, Val Loss: 0.3692, Val Acc: 0.8748
Epoch 26/100, Loss: 0.5104, Acc: 0.7471, Val Loss: 0.3781, Val Acc: 0.8630
Epoch 27/100, Loss: 0.5093, Acc: 0.7497, Val Loss: 0.4005, Val Acc: 0.8339
Epoch 28/100, Loss: 0.5089, Acc: 0.7483, Val Loss: 0.3710, Val Acc: 0.8594
Epoch 29/100, Loss: 0.5108, Acc: 0.7471, Val Loss: 0.3733, Val Acc: 0.8708
Epoch 30/100, Loss: 0.5088, Acc: 0.7495, Val Loss: 0.3834, Val Acc: 0.8601
Epoch 31/100, Loss: 0.5108, Acc: 0.7456, Val Loss: 0.3993, Val Acc: 0.8443
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5067, Acc: 0.7483, Val Loss: 0.3983, Val Acc: 0.8391
Epoch 33/100, Loss: 0.5057, Acc: 0.7511, Val Loss: 0.3784, Val Acc: 0.8586
Epoch 34/100, Loss: 0.5061, Acc: 0.7493, Val Loss: 0.3808, Val Acc: 0.8538
Epoch 35/100, Loss: 0.5050, Acc: 0.7508, Val Loss: 0.3730, Val Acc: 0.8645
Epoch 36/100, Loss: 0.5057, Acc: 0.7507, Val Loss: 0.3675, Val Acc: 0.8682
Epoch 37/100, Loss: 0.5057, Acc: 0.7517, Val Loss: 0.3761, Val Acc: 0.8590
Epoch 38/100, Loss: 0.5049, Acc: 0.7491, Val Loss: 0.3872, Val Acc: 0.8420
Epoch 39/100, Loss: 0.5043, Acc: 0.7517, Val Loss: 0.3836, Val Acc: 0.8461
Epoch 40/100, Loss: 0.5046, Acc: 0.7507, Val Loss: 0.3835, Val Acc: 0.8516
Epoch 41/100, Loss: 0.5044, Acc: 0.7503, Val Loss: 0.3918, Val Acc: 0.8465
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5032, Acc: 0.7514, Val Loss: 0.3726, Val Acc: 0.8627
Epoch 43/100, Loss: 0.5029, Acc: 0.7509, Val Loss: 0.3831, Val Acc: 0.8509
Epoch 44/100, Loss: 0.5025, Acc: 0.7519, Val Loss: 0.3756, Val Acc: 0.8605
Epoch 45/100, Loss: 0.5025, Acc: 0.7513, Val Loss: 0.3736, Val Acc: 0.8612
Epoch 46/100, Loss: 0.5026, Acc: 0.7518, Val Loss: 0.3752, Val Acc: 0.8616
Epoch 47/100, Loss: 0.5023, Acc: 0.7526, Val Loss: 0.3799, Val Acc: 0.8571
Epoch 48/100, Loss: 0.5019, Acc: 0.7547, Val Loss: 0.3817, Val Acc: 0.8509
Epoch 49/100, Loss: 0.5020, Acc: 0.7522, Val Loss: 0.3742, Val Acc: 0.8623
Epoch 50/100, Loss: 0.5018, Acc: 0.7522, Val Loss: 0.3814, Val Acc: 0.8553
Epoch 51/100, Loss: 0.5019, Acc: 0.7505, Val Loss: 0.3775, Val Acc: 0.8571
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5009, Acc: 0.7520, Val Loss: 0.3780, Val Acc: 0.8597
Epoch 53/100, Loss: 0.5013, Acc: 0.7516, Val Loss: 0.3804, Val Acc: 0.8557
Epoch 54/100, Loss: 0.5009, Acc: 0.7539, Val Loss: 0.3824, Val Acc: 0.8501
Epoch 55/100, Loss: 0.5007, Acc: 0.7532, Val Loss: 0.3824, Val Acc: 0.8524
Epoch 56/100, Loss: 0.5008, Acc: 0.7528, Val Loss: 0.3789, Val Acc: 0.8586
Epoch 57/100, Loss: 0.5008, Acc: 0.7522, Val Loss: 0.3753, Val Acc: 0.8612
Epoch 58/100, Loss: 0.5005, Acc: 0.7531, Val Loss: 0.3790, Val Acc: 0.8571
Epoch 59/100, Loss: 0.5005, Acc: 0.7538, Val Loss: 0.3797, Val Acc: 0.8557
Epoch 60/100, Loss: 0.5005, Acc: 0.7531, Val Loss: 0.3809, Val Acc: 0.8568
Epoch 61/100, Loss: 0.5006, Acc: 0.7530, Val Loss: 0.3809, Val Acc: 0.8553
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5000, Acc: 0.7526, Val Loss: 0.3787, Val Acc: 0.8586
Epoch 63/100, Loss: 0.5000, Acc: 0.7540, Val Loss: 0.3797, Val Acc: 0.8571
Epoch 64/100, Loss: 0.4999, Acc: 0.7537, Val Loss: 0.3784, Val Acc: 0.8586
Epoch 65/100, Loss: 0.4999, Acc: 0.7531, Val Loss: 0.3766, Val Acc: 0.8605
Epoch 66/100, Loss: 0.4998, Acc: 0.7535, Val Loss: 0.3774, Val Acc: 0.8594
Epoch 67/100, Loss: 0.4998, Acc: 0.7541, Val Loss: 0.3805, Val Acc: 0.8549
Epoch 68/100, Loss: 0.4998, Acc: 0.7540, Val Loss: 0.3791, Val Acc: 0.8568
Epoch 69/100, Loss: 0.4997, Acc: 0.7542, Val Loss: 0.3806, Val Acc: 0.8549
Epoch 70/100, Loss: 0.4998, Acc: 0.7527, Val Loss: 0.3791, Val Acc: 0.8582
Epoch 71/100, Loss: 0.4998, Acc: 0.7540, Val Loss: 0.3800, Val Acc: 0.8553
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4995, Acc: 0.7547, Val Loss: 0.3784, Val Acc: 0.8582
Epoch 73/100, Loss: 0.4995, Acc: 0.7540, Val Loss: 0.3803, Val Acc: 0.8538
Epoch 74/100, Loss: 0.4995, Acc: 0.7540, Val Loss: 0.3791, Val Acc: 0.8586
Epoch 75/100, Loss: 0.4995, Acc: 0.7537, Val Loss: 0.3791, Val Acc: 0.8579
Epoch 76/100, Loss: 0.4994, Acc: 0.7549, Val Loss: 0.3795, Val Acc: 0.8568
Epoch 77/100, Loss: 0.4995, Acc: 0.7534, Val Loss: 0.3777, Val Acc: 0.8582
Epoch 78/100, Loss: 0.4994, Acc: 0.7540, Val Loss: 0.3777, Val Acc: 0.8586
Epoch 79/100, Loss: 0.4994, Acc: 0.7543, Val Loss: 0.3786, Val Acc: 0.8571
Epoch 80/100, Loss: 0.4995, Acc: 0.7543, Val Loss: 0.3791, Val Acc: 0.8579
Epoch 81/100, Loss: 0.4993, Acc: 0.7545, Val Loss: 0.3785, Val Acc: 0.8582
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4993, Acc: 0.7542, Val Loss: 0.3786, Val Acc: 0.8579
Epoch 83/100, Loss: 0.4993, Acc: 0.7542, Val Loss: 0.3788, Val Acc: 0.8568
Epoch 84/100, Loss: 0.4993, Acc: 0.7542, Val Loss: 0.3788, Val Acc: 0.8582
Epoch 85/100, Loss: 0.4993, Acc: 0.7535, Val Loss: 0.3787, Val Acc: 0.8568
Epoch 86/100, Loss: 0.4992, Acc: 0.7553, Val Loss: 0.3783, Val Acc: 0.8568
Epoch 87/100, Loss: 0.4993, Acc: 0.7536, Val Loss: 0.3771, Val Acc: 0.8590
Epoch 88/100, Loss: 0.4992, Acc: 0.7541, Val Loss: 0.3785, Val Acc: 0.8586
Epoch 89/100, Loss: 0.4992, Acc: 0.7545, Val Loss: 0.3784, Val Acc: 0.8575
Epoch 90/100, Loss: 0.4992, Acc: 0.7548, Val Loss: 0.3771, Val Acc: 0.8597
Epoch 91/100, Loss: 0.4992, Acc: 0.7540, Val Loss: 0.3789, Val Acc: 0.8571
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4991, Acc: 0.7532, Val Loss: 0.3795, Val Acc: 0.8557
Epoch 93/100, Loss: 0.4992, Acc: 0.7536, Val Loss: 0.3785, Val Acc: 0.8579
Epoch 94/100, Loss: 0.4991, Acc: 0.7549, Val Loss: 0.3794, Val Acc: 0.8553
Epoch 95/100, Loss: 0.4991, Acc: 0.7536, Val Loss: 0.3809, Val Acc: 0.8505
Epoch 96/100, Loss: 0.4992, Acc: 0.7551, Val Loss: 0.3775, Val Acc: 0.8590
Epoch 97/100, Loss: 0.4990, Acc: 0.7541, Val Loss: 0.3791, Val Acc: 0.8568
Epoch 98/100, Loss: 0.4990, Acc: 0.7537, Val Loss: 0.3782, Val Acc: 0.8575
Epoch 99/100, Loss: 0.4990, Acc: 0.7535, Val Loss: 0.3777, Val Acc: 0.8582
Epoch 100/100, Loss: 0.4990, Acc: 0.7548, Val Loss: 0.3776, Val Acc: 0.8582

##############################
Resultados para principal:  098  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5 
 {'training': [0.49903186946372946, 0.7547811695476278, 0.6988938370923717, 0.8949595290654894, 0.784867306606437], 'validate': [0.3776466553207747, 0.8582474226804123, 0.8416608022519353, 0.8820058997050148, 0.8613611811307166], 'test': [0.5662600243533099, 0.6884570082449941, 0.6306306306306306, 0.9080188679245284, 0.7443209279845336]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  025  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  025  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  025  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6715, Acc: 0.6093, Val Loss: 0.6131, Val Acc: 0.8693
Mejor modelo guardado con Val Loss: 0.6131
Epoch 2/100, Loss: 0.6536, Acc: 0.6195, Val Loss: 0.5491, Val Acc: 0.8958
Mejor modelo guardado con Val Loss: 0.5491
Epoch 3/100, Loss: 0.6289, Acc: 0.6455, Val Loss: 0.5056, Val Acc: 0.9010
Mejor modelo guardado con Val Loss: 0.5056
Epoch 4/100, Loss: 0.6148, Acc: 0.6418, Val Loss: 0.4843, Val Acc: 0.9006
Mejor modelo guardado con Val Loss: 0.4843
Epoch 5/100, Loss: 0.6034, Acc: 0.6433, Val Loss: 0.4774, Val Acc: 0.9061
Mejor modelo guardado con Val Loss: 0.4774
Epoch 6/100, Loss: 0.5944, Acc: 0.6478, Val Loss: 0.4171, Val Acc: 0.9109
Mejor modelo guardado con Val Loss: 0.4171
Epoch 7/100, Loss: 0.5852, Acc: 0.6553, Val Loss: 0.4340, Val Acc: 0.8207
Epoch 8/100, Loss: 0.5821, Acc: 0.7014, Val Loss: 0.4419, Val Acc: 0.8800
Epoch 9/100, Loss: 0.5835, Acc: 0.7035, Val Loss: 0.4228, Val Acc: 0.8778
Epoch 10/100, Loss: 0.5798, Acc: 0.7083, Val Loss: 0.4496, Val Acc: 0.7552
Epoch 11/100, Loss: 0.5768, Acc: 0.7094, Val Loss: 0.4202, Val Acc: 0.8413
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5633, Acc: 0.7256, Val Loss: 0.4181, Val Acc: 0.7868
Epoch 13/100, Loss: 0.5609, Acc: 0.7253, Val Loss: 0.4085, Val Acc: 0.8299
Mejor modelo guardado con Val Loss: 0.4085
Epoch 14/100, Loss: 0.5599, Acc: 0.7269, Val Loss: 0.4009, Val Acc: 0.8354
Mejor modelo guardado con Val Loss: 0.4009
Epoch 15/100, Loss: 0.5573, Acc: 0.7281, Val Loss: 0.4441, Val Acc: 0.7390
Epoch 16/100, Loss: 0.5579, Acc: 0.7242, Val Loss: 0.3590, Val Acc: 0.8855
Mejor modelo guardado con Val Loss: 0.3590
Epoch 17/100, Loss: 0.5535, Acc: 0.7283, Val Loss: 0.4031, Val Acc: 0.7798
Epoch 18/100, Loss: 0.5529, Acc: 0.7267, Val Loss: 0.3885, Val Acc: 0.8159
Epoch 19/100, Loss: 0.5532, Acc: 0.7266, Val Loss: 0.4275, Val Acc: 0.7728
Epoch 20/100, Loss: 0.5501, Acc: 0.7286, Val Loss: 0.4423, Val Acc: 0.7139
Epoch 21/100, Loss: 0.5505, Acc: 0.7263, Val Loss: 0.3882, Val Acc: 0.8082
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5449, Acc: 0.7332, Val Loss: 0.3841, Val Acc: 0.8295
Epoch 23/100, Loss: 0.5415, Acc: 0.7361, Val Loss: 0.3818, Val Acc: 0.8174
Epoch 24/100, Loss: 0.5418, Acc: 0.7362, Val Loss: 0.4017, Val Acc: 0.7846
Epoch 25/100, Loss: 0.5438, Acc: 0.7317, Val Loss: 0.4016, Val Acc: 0.8019
Epoch 26/100, Loss: 0.5420, Acc: 0.7330, Val Loss: 0.4029, Val Acc: 0.7905
Epoch 27/100, Loss: 0.5400, Acc: 0.7352, Val Loss: 0.3887, Val Acc: 0.8041
Epoch 28/100, Loss: 0.5401, Acc: 0.7369, Val Loss: 0.4064, Val Acc: 0.7669
Epoch 29/100, Loss: 0.5401, Acc: 0.7377, Val Loss: 0.3899, Val Acc: 0.8082
Epoch 30/100, Loss: 0.5394, Acc: 0.7376, Val Loss: 0.4042, Val Acc: 0.8001
Epoch 31/100, Loss: 0.5385, Acc: 0.7366, Val Loss: 0.3864, Val Acc: 0.8034
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5366, Acc: 0.7390, Val Loss: 0.3903, Val Acc: 0.8060
Epoch 33/100, Loss: 0.5358, Acc: 0.7390, Val Loss: 0.3848, Val Acc: 0.8104
Epoch 34/100, Loss: 0.5354, Acc: 0.7380, Val Loss: 0.3913, Val Acc: 0.8045
Epoch 35/100, Loss: 0.5351, Acc: 0.7386, Val Loss: 0.3897, Val Acc: 0.8034
Epoch 36/100, Loss: 0.5354, Acc: 0.7368, Val Loss: 0.3892, Val Acc: 0.7968
Epoch 37/100, Loss: 0.5347, Acc: 0.7362, Val Loss: 0.3872, Val Acc: 0.7990
Epoch 38/100, Loss: 0.5344, Acc: 0.7381, Val Loss: 0.4050, Val Acc: 0.7743
Epoch 39/100, Loss: 0.5339, Acc: 0.7357, Val Loss: 0.4167, Val Acc: 0.7537
Epoch 40/100, Loss: 0.5344, Acc: 0.7382, Val Loss: 0.3833, Val Acc: 0.8089
Epoch 41/100, Loss: 0.5336, Acc: 0.7374, Val Loss: 0.4079, Val Acc: 0.7680
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5328, Acc: 0.7380, Val Loss: 0.4016, Val Acc: 0.7784
Epoch 43/100, Loss: 0.5326, Acc: 0.7404, Val Loss: 0.4078, Val Acc: 0.7684
Epoch 44/100, Loss: 0.5321, Acc: 0.7409, Val Loss: 0.3846, Val Acc: 0.8038
Epoch 45/100, Loss: 0.5321, Acc: 0.7388, Val Loss: 0.4000, Val Acc: 0.7784
Epoch 46/100, Loss: 0.5319, Acc: 0.7395, Val Loss: 0.3897, Val Acc: 0.8004
Epoch 47/100, Loss: 0.5317, Acc: 0.7398, Val Loss: 0.3908, Val Acc: 0.7920
Epoch 48/100, Loss: 0.5316, Acc: 0.7394, Val Loss: 0.3926, Val Acc: 0.7942
Epoch 49/100, Loss: 0.5313, Acc: 0.7401, Val Loss: 0.3894, Val Acc: 0.8023
Epoch 50/100, Loss: 0.5312, Acc: 0.7396, Val Loss: 0.3995, Val Acc: 0.7861
Epoch 51/100, Loss: 0.5309, Acc: 0.7403, Val Loss: 0.3908, Val Acc: 0.7982
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5306, Acc: 0.7403, Val Loss: 0.4002, Val Acc: 0.7824
Epoch 53/100, Loss: 0.5307, Acc: 0.7403, Val Loss: 0.3976, Val Acc: 0.7861
Epoch 54/100, Loss: 0.5304, Acc: 0.7401, Val Loss: 0.3871, Val Acc: 0.8030
Epoch 55/100, Loss: 0.5302, Acc: 0.7403, Val Loss: 0.3972, Val Acc: 0.7828
Epoch 56/100, Loss: 0.5300, Acc: 0.7413, Val Loss: 0.3993, Val Acc: 0.7776
Epoch 57/100, Loss: 0.5299, Acc: 0.7410, Val Loss: 0.3866, Val Acc: 0.8004
Epoch 58/100, Loss: 0.5298, Acc: 0.7403, Val Loss: 0.3985, Val Acc: 0.7802
Epoch 59/100, Loss: 0.5295, Acc: 0.7407, Val Loss: 0.3980, Val Acc: 0.7806
Epoch 60/100, Loss: 0.5299, Acc: 0.7408, Val Loss: 0.4052, Val Acc: 0.7736
Epoch 61/100, Loss: 0.5295, Acc: 0.7405, Val Loss: 0.3961, Val Acc: 0.7813
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5293, Acc: 0.7403, Val Loss: 0.3921, Val Acc: 0.7934
Epoch 63/100, Loss: 0.5291, Acc: 0.7407, Val Loss: 0.3991, Val Acc: 0.7802
Epoch 64/100, Loss: 0.5291, Acc: 0.7407, Val Loss: 0.3944, Val Acc: 0.7909
Epoch 65/100, Loss: 0.5291, Acc: 0.7413, Val Loss: 0.3888, Val Acc: 0.8001
Epoch 66/100, Loss: 0.5291, Acc: 0.7395, Val Loss: 0.3940, Val Acc: 0.7923
Epoch 67/100, Loss: 0.5289, Acc: 0.7404, Val Loss: 0.3973, Val Acc: 0.7879
Epoch 68/100, Loss: 0.5289, Acc: 0.7393, Val Loss: 0.3917, Val Acc: 0.7938
Epoch 69/100, Loss: 0.5289, Acc: 0.7403, Val Loss: 0.3954, Val Acc: 0.7887
Epoch 70/100, Loss: 0.5288, Acc: 0.7404, Val Loss: 0.3895, Val Acc: 0.7957
Epoch 71/100, Loss: 0.5288, Acc: 0.7412, Val Loss: 0.3936, Val Acc: 0.7923
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5286, Acc: 0.7404, Val Loss: 0.3931, Val Acc: 0.7931
Epoch 73/100, Loss: 0.5285, Acc: 0.7404, Val Loss: 0.3947, Val Acc: 0.7898
Epoch 74/100, Loss: 0.5285, Acc: 0.7403, Val Loss: 0.3938, Val Acc: 0.7912
Epoch 75/100, Loss: 0.5285, Acc: 0.7407, Val Loss: 0.3934, Val Acc: 0.7927
Epoch 76/100, Loss: 0.5285, Acc: 0.7411, Val Loss: 0.3932, Val Acc: 0.7923
Epoch 77/100, Loss: 0.5285, Acc: 0.7411, Val Loss: 0.3936, Val Acc: 0.7923
Epoch 78/100, Loss: 0.5284, Acc: 0.7418, Val Loss: 0.3914, Val Acc: 0.7957
Epoch 79/100, Loss: 0.5284, Acc: 0.7403, Val Loss: 0.3947, Val Acc: 0.7905
Epoch 80/100, Loss: 0.5283, Acc: 0.7407, Val Loss: 0.3935, Val Acc: 0.7927
Epoch 81/100, Loss: 0.5283, Acc: 0.7415, Val Loss: 0.3920, Val Acc: 0.7942
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5283, Acc: 0.7402, Val Loss: 0.3942, Val Acc: 0.7912
Epoch 83/100, Loss: 0.5282, Acc: 0.7403, Val Loss: 0.3937, Val Acc: 0.7923
Epoch 84/100, Loss: 0.5282, Acc: 0.7405, Val Loss: 0.3949, Val Acc: 0.7901
Epoch 85/100, Loss: 0.5280, Acc: 0.7415, Val Loss: 0.3978, Val Acc: 0.7876
Epoch 86/100, Loss: 0.5281, Acc: 0.7403, Val Loss: 0.3935, Val Acc: 0.7927
Epoch 87/100, Loss: 0.5281, Acc: 0.7407, Val Loss: 0.3939, Val Acc: 0.7931
Epoch 88/100, Loss: 0.5281, Acc: 0.7409, Val Loss: 0.3964, Val Acc: 0.7876
Epoch 89/100, Loss: 0.5281, Acc: 0.7417, Val Loss: 0.3970, Val Acc: 0.7857
Epoch 90/100, Loss: 0.5281, Acc: 0.7408, Val Loss: 0.3961, Val Acc: 0.7879
Epoch 91/100, Loss: 0.5280, Acc: 0.7406, Val Loss: 0.3964, Val Acc: 0.7879
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5279, Acc: 0.7413, Val Loss: 0.3931, Val Acc: 0.7938
Epoch 93/100, Loss: 0.5279, Acc: 0.7403, Val Loss: 0.3960, Val Acc: 0.7905
Epoch 94/100, Loss: 0.5278, Acc: 0.7405, Val Loss: 0.3968, Val Acc: 0.7861
Epoch 95/100, Loss: 0.5279, Acc: 0.7411, Val Loss: 0.3936, Val Acc: 0.7934
Epoch 96/100, Loss: 0.5279, Acc: 0.7412, Val Loss: 0.3936, Val Acc: 0.7931
Epoch 97/100, Loss: 0.5277, Acc: 0.7406, Val Loss: 0.3953, Val Acc: 0.7901
Epoch 98/100, Loss: 0.5277, Acc: 0.7409, Val Loss: 0.3966, Val Acc: 0.7887
Epoch 99/100, Loss: 0.5277, Acc: 0.7414, Val Loss: 0.3939, Val Acc: 0.7923
Epoch 100/100, Loss: 0.5277, Acc: 0.7411, Val Loss: 0.3929, Val Acc: 0.7942

##############################
Resultados para principal:  025  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5 
 {'training': [0.52771352853526, 0.7410812798823097, 0.7077386615921345, 0.8210080941869021, 0.7601771418838358], 'validate': [0.3928791057578353, 0.7941826215022091, 0.8700092850510678, 0.6910029498525073, 0.770242498972462], 'test': [0.6563433016891833, 0.6089517078916372, 0.5684523809523809, 0.9009433962264151, 0.6970802919708029]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  059  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  059  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  059  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5940, Acc: 0.7144, Val Loss: 0.3870, Val Acc: 0.9242
Mejor modelo guardado con Val Loss: 0.3870
Epoch 2/100, Loss: 0.5584, Acc: 0.7215, Val Loss: 0.3496, Val Acc: 0.9190
Mejor modelo guardado con Val Loss: 0.3496
Epoch 3/100, Loss: 0.5467, Acc: 0.7224, Val Loss: 0.3359, Val Acc: 0.9238
Mejor modelo guardado con Val Loss: 0.3359
Epoch 4/100, Loss: 0.5394, Acc: 0.7344, Val Loss: 0.3588, Val Acc: 0.9102
Epoch 5/100, Loss: 0.5324, Acc: 0.7322, Val Loss: 0.2775, Val Acc: 0.9311
Mejor modelo guardado con Val Loss: 0.2775
Epoch 6/100, Loss: 0.5263, Acc: 0.7359, Val Loss: 0.2692, Val Acc: 0.9381
Mejor modelo guardado con Val Loss: 0.2692
Epoch 7/100, Loss: 0.5238, Acc: 0.7391, Val Loss: 0.2845, Val Acc: 0.9120
Epoch 8/100, Loss: 0.5218, Acc: 0.7392, Val Loss: 0.3154, Val Acc: 0.9091
Epoch 9/100, Loss: 0.5182, Acc: 0.7470, Val Loss: 0.2826, Val Acc: 0.9102
Epoch 10/100, Loss: 0.5152, Acc: 0.7431, Val Loss: 0.2863, Val Acc: 0.9172
Epoch 11/100, Loss: 0.5087, Acc: 0.7474, Val Loss: 0.2873, Val Acc: 0.9135
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5040, Acc: 0.7506, Val Loss: 0.2628, Val Acc: 0.9127
Mejor modelo guardado con Val Loss: 0.2628
Epoch 13/100, Loss: 0.4988, Acc: 0.7522, Val Loss: 0.2593, Val Acc: 0.9146
Mejor modelo guardado con Val Loss: 0.2593
Epoch 14/100, Loss: 0.5018, Acc: 0.7486, Val Loss: 0.2485, Val Acc: 0.9234
Mejor modelo guardado con Val Loss: 0.2485
Epoch 15/100, Loss: 0.5002, Acc: 0.7518, Val Loss: 0.2701, Val Acc: 0.9153
Epoch 16/100, Loss: 0.4979, Acc: 0.7552, Val Loss: 0.2314, Val Acc: 0.9271
Mejor modelo guardado con Val Loss: 0.2314
Epoch 17/100, Loss: 0.4959, Acc: 0.7556, Val Loss: 0.2295, Val Acc: 0.9341
Mejor modelo guardado con Val Loss: 0.2295
Epoch 18/100, Loss: 0.4965, Acc: 0.7539, Val Loss: 0.2355, Val Acc: 0.9201
Epoch 19/100, Loss: 0.4963, Acc: 0.7550, Val Loss: 0.2433, Val Acc: 0.9153
Epoch 20/100, Loss: 0.4956, Acc: 0.7519, Val Loss: 0.2348, Val Acc: 0.9172
Epoch 21/100, Loss: 0.4967, Acc: 0.7512, Val Loss: 0.2301, Val Acc: 0.9197
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4940, Acc: 0.7537, Val Loss: 0.2235, Val Acc: 0.9227
Mejor modelo guardado con Val Loss: 0.2235
Epoch 23/100, Loss: 0.4930, Acc: 0.7541, Val Loss: 0.2254, Val Acc: 0.9315
Epoch 24/100, Loss: 0.4891, Acc: 0.7586, Val Loss: 0.2304, Val Acc: 0.9172
Epoch 25/100, Loss: 0.4888, Acc: 0.7581, Val Loss: 0.2384, Val Acc: 0.9116
Epoch 26/100, Loss: 0.4896, Acc: 0.7567, Val Loss: 0.2342, Val Acc: 0.9138
Epoch 27/100, Loss: 0.4872, Acc: 0.7571, Val Loss: 0.2280, Val Acc: 0.9179
Epoch 28/100, Loss: 0.4855, Acc: 0.7584, Val Loss: 0.2210, Val Acc: 0.9249
Mejor modelo guardado con Val Loss: 0.2210
Epoch 29/100, Loss: 0.4865, Acc: 0.7593, Val Loss: 0.2208, Val Acc: 0.9212
Mejor modelo guardado con Val Loss: 0.2208
Epoch 30/100, Loss: 0.4889, Acc: 0.7582, Val Loss: 0.2332, Val Acc: 0.9234
Epoch 31/100, Loss: 0.4865, Acc: 0.7559, Val Loss: 0.2140, Val Acc: 0.9293
Mejor modelo guardado con Val Loss: 0.2140
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4847, Acc: 0.7597, Val Loss: 0.2334, Val Acc: 0.9161
Epoch 33/100, Loss: 0.4839, Acc: 0.7606, Val Loss: 0.2147, Val Acc: 0.9219
Epoch 34/100, Loss: 0.4841, Acc: 0.7604, Val Loss: 0.2275, Val Acc: 0.9168
Epoch 35/100, Loss: 0.4826, Acc: 0.7606, Val Loss: 0.2274, Val Acc: 0.9175
Epoch 36/100, Loss: 0.4825, Acc: 0.7586, Val Loss: 0.2214, Val Acc: 0.9212
Epoch 37/100, Loss: 0.4834, Acc: 0.7587, Val Loss: 0.2267, Val Acc: 0.9197
Epoch 38/100, Loss: 0.4836, Acc: 0.7619, Val Loss: 0.2432, Val Acc: 0.9105
Epoch 39/100, Loss: 0.4824, Acc: 0.7623, Val Loss: 0.2225, Val Acc: 0.9179
Epoch 40/100, Loss: 0.4822, Acc: 0.7576, Val Loss: 0.2359, Val Acc: 0.9142
Epoch 41/100, Loss: 0.4828, Acc: 0.7584, Val Loss: 0.2211, Val Acc: 0.9219
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4806, Acc: 0.7604, Val Loss: 0.2188, Val Acc: 0.9201
Epoch 43/100, Loss: 0.4800, Acc: 0.7604, Val Loss: 0.2172, Val Acc: 0.9208
Epoch 44/100, Loss: 0.4792, Acc: 0.7627, Val Loss: 0.2246, Val Acc: 0.9172
Epoch 45/100, Loss: 0.4796, Acc: 0.7618, Val Loss: 0.2223, Val Acc: 0.9186
Epoch 46/100, Loss: 0.4793, Acc: 0.7620, Val Loss: 0.2242, Val Acc: 0.9175
Epoch 47/100, Loss: 0.4787, Acc: 0.7628, Val Loss: 0.2254, Val Acc: 0.9172
Epoch 48/100, Loss: 0.4795, Acc: 0.7616, Val Loss: 0.2187, Val Acc: 0.9227
Epoch 49/100, Loss: 0.4788, Acc: 0.7618, Val Loss: 0.2174, Val Acc: 0.9216
Epoch 50/100, Loss: 0.4782, Acc: 0.7625, Val Loss: 0.2246, Val Acc: 0.9175
Epoch 51/100, Loss: 0.4787, Acc: 0.7620, Val Loss: 0.2264, Val Acc: 0.9190
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4778, Acc: 0.7616, Val Loss: 0.2170, Val Acc: 0.9201
Epoch 53/100, Loss: 0.4773, Acc: 0.7619, Val Loss: 0.2218, Val Acc: 0.9179
Epoch 54/100, Loss: 0.4773, Acc: 0.7648, Val Loss: 0.2222, Val Acc: 0.9186
Epoch 55/100, Loss: 0.4772, Acc: 0.7617, Val Loss: 0.2202, Val Acc: 0.9186
Epoch 56/100, Loss: 0.4773, Acc: 0.7627, Val Loss: 0.2184, Val Acc: 0.9201
Epoch 57/100, Loss: 0.4770, Acc: 0.7632, Val Loss: 0.2224, Val Acc: 0.9183
Epoch 58/100, Loss: 0.4770, Acc: 0.7621, Val Loss: 0.2236, Val Acc: 0.9175
Epoch 59/100, Loss: 0.4768, Acc: 0.7626, Val Loss: 0.2146, Val Acc: 0.9208
Epoch 60/100, Loss: 0.4771, Acc: 0.7629, Val Loss: 0.2182, Val Acc: 0.9183
Epoch 61/100, Loss: 0.4768, Acc: 0.7643, Val Loss: 0.2178, Val Acc: 0.9197
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4763, Acc: 0.7635, Val Loss: 0.2184, Val Acc: 0.9190
Epoch 63/100, Loss: 0.4764, Acc: 0.7632, Val Loss: 0.2175, Val Acc: 0.9197
Epoch 64/100, Loss: 0.4762, Acc: 0.7628, Val Loss: 0.2207, Val Acc: 0.9190
Epoch 65/100, Loss: 0.4763, Acc: 0.7628, Val Loss: 0.2188, Val Acc: 0.9194
Epoch 66/100, Loss: 0.4762, Acc: 0.7637, Val Loss: 0.2191, Val Acc: 0.9190
Epoch 67/100, Loss: 0.4761, Acc: 0.7625, Val Loss: 0.2203, Val Acc: 0.9186
Epoch 68/100, Loss: 0.4761, Acc: 0.7627, Val Loss: 0.2219, Val Acc: 0.9179
Epoch 69/100, Loss: 0.4762, Acc: 0.7630, Val Loss: 0.2188, Val Acc: 0.9190
Epoch 70/100, Loss: 0.4761, Acc: 0.7617, Val Loss: 0.2182, Val Acc: 0.9194
Epoch 71/100, Loss: 0.4760, Acc: 0.7632, Val Loss: 0.2168, Val Acc: 0.9201
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4759, Acc: 0.7631, Val Loss: 0.2185, Val Acc: 0.9190
Epoch 73/100, Loss: 0.4758, Acc: 0.7640, Val Loss: 0.2172, Val Acc: 0.9197
Epoch 74/100, Loss: 0.4757, Acc: 0.7632, Val Loss: 0.2176, Val Acc: 0.9197
Epoch 75/100, Loss: 0.4758, Acc: 0.7634, Val Loss: 0.2178, Val Acc: 0.9194
Epoch 76/100, Loss: 0.4757, Acc: 0.7630, Val Loss: 0.2178, Val Acc: 0.9194
Epoch 77/100, Loss: 0.4757, Acc: 0.7629, Val Loss: 0.2182, Val Acc: 0.9190
Epoch 78/100, Loss: 0.4757, Acc: 0.7633, Val Loss: 0.2187, Val Acc: 0.9190
Epoch 79/100, Loss: 0.4757, Acc: 0.7632, Val Loss: 0.2183, Val Acc: 0.9190
Epoch 80/100, Loss: 0.4756, Acc: 0.7638, Val Loss: 0.2173, Val Acc: 0.9194
Epoch 81/100, Loss: 0.4756, Acc: 0.7631, Val Loss: 0.2175, Val Acc: 0.9190
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4756, Acc: 0.7630, Val Loss: 0.2169, Val Acc: 0.9194
Epoch 83/100, Loss: 0.4756, Acc: 0.7637, Val Loss: 0.2180, Val Acc: 0.9190
Epoch 84/100, Loss: 0.4755, Acc: 0.7629, Val Loss: 0.2173, Val Acc: 0.9190
Epoch 85/100, Loss: 0.4755, Acc: 0.7623, Val Loss: 0.2170, Val Acc: 0.9190
Epoch 86/100, Loss: 0.4755, Acc: 0.7639, Val Loss: 0.2189, Val Acc: 0.9190
Epoch 87/100, Loss: 0.4755, Acc: 0.7637, Val Loss: 0.2181, Val Acc: 0.9190
Epoch 88/100, Loss: 0.4755, Acc: 0.7630, Val Loss: 0.2183, Val Acc: 0.9190
Epoch 89/100, Loss: 0.4754, Acc: 0.7631, Val Loss: 0.2180, Val Acc: 0.9190
Epoch 90/100, Loss: 0.4753, Acc: 0.7633, Val Loss: 0.2186, Val Acc: 0.9190
Epoch 91/100, Loss: 0.4753, Acc: 0.7632, Val Loss: 0.2184, Val Acc: 0.9190
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4752, Acc: 0.7642, Val Loss: 0.2185, Val Acc: 0.9190
Epoch 93/100, Loss: 0.4753, Acc: 0.7645, Val Loss: 0.2174, Val Acc: 0.9194
Epoch 94/100, Loss: 0.4752, Acc: 0.7633, Val Loss: 0.2172, Val Acc: 0.9190
Epoch 95/100, Loss: 0.4751, Acc: 0.7635, Val Loss: 0.2170, Val Acc: 0.9194
Epoch 96/100, Loss: 0.4752, Acc: 0.7635, Val Loss: 0.2195, Val Acc: 0.9186
Epoch 97/100, Loss: 0.4751, Acc: 0.7639, Val Loss: 0.2172, Val Acc: 0.9190
Epoch 98/100, Loss: 0.4751, Acc: 0.7638, Val Loss: 0.2180, Val Acc: 0.9190
Epoch 99/100, Loss: 0.4751, Acc: 0.7633, Val Loss: 0.2191, Val Acc: 0.9190
Epoch 100/100, Loss: 0.4750, Acc: 0.7639, Val Loss: 0.2171, Val Acc: 0.9190

##############################
Resultados para principal:  059  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5 
 {'training': [0.4750342961180162, 0.7638837808017653, 0.7769409038238703, 0.7400662251655629, 0.7580553985302431], 'validate': [0.217097332831039, 0.9189985272459499, 1.0, 0.8377581120943953, 0.9117174959871589], 'test': [0.5383025131843708, 0.7326266195524146, 0.6790909090909091, 0.8808962264150944, 0.7669404517453798]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  121  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  121  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  121  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4231, Acc: 0.8913, Val Loss: 0.9935, Val Acc: 0.4971
Mejor modelo guardado con Val Loss: 0.9935
Epoch 2/100, Loss: 0.2787, Acc: 0.9091, Val Loss: 1.0698, Val Acc: 0.5088
Epoch 3/100, Loss: 0.2571, Acc: 0.9103, Val Loss: 1.1129, Val Acc: 0.4915
Epoch 4/100, Loss: 0.2515, Acc: 0.9107, Val Loss: 1.1277, Val Acc: 0.4930
Epoch 5/100, Loss: 0.2457, Acc: 0.9129, Val Loss: 1.1975, Val Acc: 0.4919
Epoch 6/100, Loss: 0.2419, Acc: 0.9109, Val Loss: 1.1325, Val Acc: 0.5125
Epoch 7/100, Loss: 0.2369, Acc: 0.9144, Val Loss: 1.3606, Val Acc: 0.4886
Epoch 8/100, Loss: 0.2305, Acc: 0.9183, Val Loss: 1.0713, Val Acc: 0.4945
Epoch 9/100, Loss: 0.2319, Acc: 0.9156, Val Loss: 1.3774, Val Acc: 0.4967
Epoch 10/100, Loss: 0.2303, Acc: 0.9177, Val Loss: 1.2963, Val Acc: 0.4948
Epoch 11/100, Loss: 0.2291, Acc: 0.9173, Val Loss: 1.1786, Val Acc: 0.4978
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2220, Acc: 0.9206, Val Loss: 1.3316, Val Acc: 0.4959
Epoch 13/100, Loss: 0.2232, Acc: 0.9196, Val Loss: 1.3014, Val Acc: 0.4919
Epoch 14/100, Loss: 0.2219, Acc: 0.9207, Val Loss: 1.3308, Val Acc: 0.4908
Epoch 15/100, Loss: 0.2222, Acc: 0.9207, Val Loss: 1.2117, Val Acc: 0.4926
Epoch 16/100, Loss: 0.2205, Acc: 0.9202, Val Loss: 1.1098, Val Acc: 0.4948
Epoch 17/100, Loss: 0.2167, Acc: 0.9215, Val Loss: 1.1513, Val Acc: 0.5015
Epoch 18/100, Loss: 0.2210, Acc: 0.9206, Val Loss: 1.3419, Val Acc: 0.5018
Epoch 19/100, Loss: 0.2185, Acc: 0.9207, Val Loss: 1.3559, Val Acc: 0.4908
Epoch 20/100, Loss: 0.2208, Acc: 0.9192, Val Loss: 1.2976, Val Acc: 0.4971
Epoch 21/100, Loss: 0.2186, Acc: 0.9217, Val Loss: 1.1656, Val Acc: 0.5129
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2145, Acc: 0.9227, Val Loss: 1.3076, Val Acc: 0.4930
Epoch 23/100, Loss: 0.2137, Acc: 0.9222, Val Loss: 1.2293, Val Acc: 0.4937
Epoch 24/100, Loss: 0.2114, Acc: 0.9245, Val Loss: 1.2941, Val Acc: 0.4915
Epoch 25/100, Loss: 0.2110, Acc: 0.9257, Val Loss: 1.3229, Val Acc: 0.4963
Epoch 26/100, Loss: 0.2112, Acc: 0.9241, Val Loss: 1.3656, Val Acc: 0.4978
Epoch 27/100, Loss: 0.2094, Acc: 0.9237, Val Loss: 1.3112, Val Acc: 0.4959
Epoch 28/100, Loss: 0.2099, Acc: 0.9254, Val Loss: 1.2584, Val Acc: 0.4978
Epoch 29/100, Loss: 0.2112, Acc: 0.9230, Val Loss: 1.3248, Val Acc: 0.4926
Epoch 30/100, Loss: 0.2107, Acc: 0.9241, Val Loss: 1.1951, Val Acc: 0.4985
Epoch 31/100, Loss: 0.2108, Acc: 0.9247, Val Loss: 1.3741, Val Acc: 0.4908
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2065, Acc: 0.9255, Val Loss: 1.3177, Val Acc: 0.4926
Epoch 33/100, Loss: 0.2065, Acc: 0.9246, Val Loss: 1.3145, Val Acc: 0.4993
Epoch 34/100, Loss: 0.2055, Acc: 0.9255, Val Loss: 1.2910, Val Acc: 0.4959
Epoch 35/100, Loss: 0.2056, Acc: 0.9259, Val Loss: 1.2471, Val Acc: 0.4934
Epoch 36/100, Loss: 0.2056, Acc: 0.9255, Val Loss: 1.2999, Val Acc: 0.4963
Epoch 37/100, Loss: 0.2050, Acc: 0.9256, Val Loss: 1.3060, Val Acc: 0.4956
Epoch 38/100, Loss: 0.2058, Acc: 0.9252, Val Loss: 1.3750, Val Acc: 0.4959
Epoch 39/100, Loss: 0.2043, Acc: 0.9252, Val Loss: 1.2421, Val Acc: 0.4945
Epoch 40/100, Loss: 0.2051, Acc: 0.9260, Val Loss: 1.1981, Val Acc: 0.5041
Epoch 41/100, Loss: 0.2051, Acc: 0.9255, Val Loss: 1.2952, Val Acc: 0.4963
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2037, Acc: 0.9249, Val Loss: 1.2999, Val Acc: 0.4952
Epoch 43/100, Loss: 0.2036, Acc: 0.9255, Val Loss: 1.3642, Val Acc: 0.4937
Epoch 44/100, Loss: 0.2034, Acc: 0.9254, Val Loss: 1.3004, Val Acc: 0.4956
Epoch 45/100, Loss: 0.2031, Acc: 0.9252, Val Loss: 1.2951, Val Acc: 0.4945
Epoch 46/100, Loss: 0.2032, Acc: 0.9260, Val Loss: 1.2680, Val Acc: 0.4978
Epoch 47/100, Loss: 0.2036, Acc: 0.9256, Val Loss: 1.3126, Val Acc: 0.4971
Epoch 48/100, Loss: 0.2030, Acc: 0.9266, Val Loss: 1.3346, Val Acc: 0.4930
Epoch 49/100, Loss: 0.2026, Acc: 0.9256, Val Loss: 1.2967, Val Acc: 0.4937
Epoch 50/100, Loss: 0.2026, Acc: 0.9260, Val Loss: 1.3071, Val Acc: 0.4952
Epoch 51/100, Loss: 0.2026, Acc: 0.9265, Val Loss: 1.2686, Val Acc: 0.4971
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2019, Acc: 0.9259, Val Loss: 1.3118, Val Acc: 0.4930
Epoch 53/100, Loss: 0.2016, Acc: 0.9263, Val Loss: 1.2890, Val Acc: 0.4959
Epoch 54/100, Loss: 0.2018, Acc: 0.9247, Val Loss: 1.3092, Val Acc: 0.4959
Epoch 55/100, Loss: 0.2014, Acc: 0.9268, Val Loss: 1.3275, Val Acc: 0.4923
Epoch 56/100, Loss: 0.2016, Acc: 0.9274, Val Loss: 1.2906, Val Acc: 0.4974
Epoch 57/100, Loss: 0.2014, Acc: 0.9262, Val Loss: 1.3123, Val Acc: 0.4934
Epoch 58/100, Loss: 0.2015, Acc: 0.9267, Val Loss: 1.3167, Val Acc: 0.4959
Epoch 59/100, Loss: 0.2011, Acc: 0.9262, Val Loss: 1.2976, Val Acc: 0.4967
Epoch 60/100, Loss: 0.2010, Acc: 0.9267, Val Loss: 1.3297, Val Acc: 0.4945
Epoch 61/100, Loss: 0.2011, Acc: 0.9260, Val Loss: 1.2996, Val Acc: 0.4974
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2007, Acc: 0.9266, Val Loss: 1.3199, Val Acc: 0.4934
Epoch 63/100, Loss: 0.2007, Acc: 0.9264, Val Loss: 1.3150, Val Acc: 0.4956
Epoch 64/100, Loss: 0.2007, Acc: 0.9261, Val Loss: 1.2985, Val Acc: 0.4974
Epoch 65/100, Loss: 0.2007, Acc: 0.9261, Val Loss: 1.3040, Val Acc: 0.4974
Epoch 66/100, Loss: 0.2007, Acc: 0.9268, Val Loss: 1.3118, Val Acc: 0.4945
Epoch 67/100, Loss: 0.2005, Acc: 0.9263, Val Loss: 1.3171, Val Acc: 0.4967
Epoch 68/100, Loss: 0.2006, Acc: 0.9261, Val Loss: 1.3207, Val Acc: 0.4941
Epoch 69/100, Loss: 0.2005, Acc: 0.9262, Val Loss: 1.2999, Val Acc: 0.4967
Epoch 70/100, Loss: 0.2007, Acc: 0.9268, Val Loss: 1.3335, Val Acc: 0.4948
Epoch 71/100, Loss: 0.2007, Acc: 0.9262, Val Loss: 1.3058, Val Acc: 0.4963
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2005, Acc: 0.9266, Val Loss: 1.3075, Val Acc: 0.4971
Epoch 73/100, Loss: 0.2003, Acc: 0.9264, Val Loss: 1.3090, Val Acc: 0.4956
Epoch 74/100, Loss: 0.2002, Acc: 0.9268, Val Loss: 1.3158, Val Acc: 0.4956
Epoch 75/100, Loss: 0.2002, Acc: 0.9267, Val Loss: 1.3050, Val Acc: 0.4974
Epoch 76/100, Loss: 0.2003, Acc: 0.9264, Val Loss: 1.3158, Val Acc: 0.4945
Epoch 77/100, Loss: 0.2002, Acc: 0.9266, Val Loss: 1.3160, Val Acc: 0.4945
Epoch 78/100, Loss: 0.2001, Acc: 0.9266, Val Loss: 1.3028, Val Acc: 0.4974
Epoch 79/100, Loss: 0.2001, Acc: 0.9269, Val Loss: 1.3042, Val Acc: 0.4974
Epoch 80/100, Loss: 0.2001, Acc: 0.9267, Val Loss: 1.3211, Val Acc: 0.4948
Epoch 81/100, Loss: 0.2001, Acc: 0.9266, Val Loss: 1.3141, Val Acc: 0.4952
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2002, Acc: 0.9267, Val Loss: 1.3158, Val Acc: 0.4948
Epoch 83/100, Loss: 0.2001, Acc: 0.9260, Val Loss: 1.3113, Val Acc: 0.4959
Epoch 84/100, Loss: 0.2000, Acc: 0.9264, Val Loss: 1.3061, Val Acc: 0.4967
Epoch 85/100, Loss: 0.2001, Acc: 0.9264, Val Loss: 1.3109, Val Acc: 0.4956
Epoch 86/100, Loss: 0.2001, Acc: 0.9264, Val Loss: 1.3098, Val Acc: 0.4963
Epoch 87/100, Loss: 0.2000, Acc: 0.9265, Val Loss: 1.3123, Val Acc: 0.4971
Epoch 88/100, Loss: 0.2002, Acc: 0.9268, Val Loss: 1.3213, Val Acc: 0.4956
Epoch 89/100, Loss: 0.2003, Acc: 0.9266, Val Loss: 1.3204, Val Acc: 0.4956
Epoch 90/100, Loss: 0.2000, Acc: 0.9264, Val Loss: 1.3146, Val Acc: 0.4971
Epoch 91/100, Loss: 0.2001, Acc: 0.9260, Val Loss: 1.3092, Val Acc: 0.4974
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2002, Acc: 0.9261, Val Loss: 1.3199, Val Acc: 0.4956
Epoch 93/100, Loss: 0.2001, Acc: 0.9263, Val Loss: 1.3152, Val Acc: 0.4956
Epoch 94/100, Loss: 0.2001, Acc: 0.9269, Val Loss: 1.3152, Val Acc: 0.4971
Epoch 95/100, Loss: 0.2001, Acc: 0.9264, Val Loss: 1.3168, Val Acc: 0.4967
Epoch 96/100, Loss: 0.2000, Acc: 0.9267, Val Loss: 1.3165, Val Acc: 0.4971
Epoch 97/100, Loss: 0.2000, Acc: 0.9266, Val Loss: 1.3227, Val Acc: 0.4948
Epoch 98/100, Loss: 0.2000, Acc: 0.9269, Val Loss: 1.3131, Val Acc: 0.4959
Epoch 99/100, Loss: 0.1995, Acc: 0.9258, Val Loss: 1.3164, Val Acc: 0.4978
Epoch 100/100, Loss: 0.1994, Acc: 0.9264, Val Loss: 1.3211, Val Acc: 0.4963

##############################
Resultados para principal:  121  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5 
 {'training': [0.1994431510967733, 0.9263515998528871, 0.9035347379418422, 0.9545621780721119, 0.9283477949727167], 'validate': [1.3211297487276932, 0.4963181148748159, 0.4976689976689977, 0.9446902654867256, 0.6519083969465649], 'test': [0.45856943395402694, 0.78150765606596, 0.726280834914611, 0.9027122641509434, 0.8049421661409043]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  107  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  107  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  107  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5013, Acc: 0.8372, Val Loss: 0.9814, Val Acc: 0.4345
Mejor modelo guardado con Val Loss: 0.9814
Epoch 2/100, Loss: 0.3521, Acc: 0.8712, Val Loss: 1.1542, Val Acc: 0.4591
Epoch 3/100, Loss: 0.3243, Acc: 0.8736, Val Loss: 1.2543, Val Acc: 0.4334
Epoch 4/100, Loss: 0.3164, Acc: 0.8760, Val Loss: 1.2873, Val Acc: 0.4433
Epoch 5/100, Loss: 0.3057, Acc: 0.8804, Val Loss: 1.2597, Val Acc: 0.4219
Epoch 6/100, Loss: 0.3121, Acc: 0.8756, Val Loss: 1.3085, Val Acc: 0.4573
Epoch 7/100, Loss: 0.2994, Acc: 0.8815, Val Loss: 1.2951, Val Acc: 0.4613
Epoch 8/100, Loss: 0.2983, Acc: 0.8831, Val Loss: 1.3409, Val Acc: 0.4554
Epoch 9/100, Loss: 0.2985, Acc: 0.8814, Val Loss: 1.3163, Val Acc: 0.4422
Epoch 10/100, Loss: 0.2991, Acc: 0.8827, Val Loss: 1.3625, Val Acc: 0.3774
Epoch 11/100, Loss: 0.2973, Acc: 0.8818, Val Loss: 1.1721, Val Acc: 0.4385
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2910, Acc: 0.8843, Val Loss: 1.3211, Val Acc: 0.4172
Epoch 13/100, Loss: 0.2891, Acc: 0.8856, Val Loss: 1.3057, Val Acc: 0.4470
Epoch 14/100, Loss: 0.2857, Acc: 0.8876, Val Loss: 1.3444, Val Acc: 0.4462
Epoch 15/100, Loss: 0.2897, Acc: 0.8862, Val Loss: 1.2923, Val Acc: 0.4205
Epoch 16/100, Loss: 0.2866, Acc: 0.8901, Val Loss: 1.3535, Val Acc: 0.4473
Epoch 17/100, Loss: 0.2844, Acc: 0.8908, Val Loss: 1.2861, Val Acc: 0.4540
Epoch 18/100, Loss: 0.2829, Acc: 0.8897, Val Loss: 1.3383, Val Acc: 0.4566
Epoch 19/100, Loss: 0.2824, Acc: 0.8893, Val Loss: 1.2942, Val Acc: 0.4558
Epoch 20/100, Loss: 0.2815, Acc: 0.8898, Val Loss: 1.3301, Val Acc: 0.4540
Epoch 21/100, Loss: 0.2815, Acc: 0.8891, Val Loss: 1.2812, Val Acc: 0.4381
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2772, Acc: 0.8912, Val Loss: 1.3538, Val Acc: 0.4319
Epoch 23/100, Loss: 0.2788, Acc: 0.8906, Val Loss: 1.3181, Val Acc: 0.4558
Epoch 24/100, Loss: 0.2756, Acc: 0.8909, Val Loss: 1.3156, Val Acc: 0.4470
Epoch 25/100, Loss: 0.2750, Acc: 0.8915, Val Loss: 1.3637, Val Acc: 0.4057
Epoch 26/100, Loss: 0.2778, Acc: 0.8912, Val Loss: 1.2604, Val Acc: 0.4300
Epoch 27/100, Loss: 0.2740, Acc: 0.8942, Val Loss: 1.3397, Val Acc: 0.4208
Epoch 28/100, Loss: 0.2746, Acc: 0.8934, Val Loss: 1.3386, Val Acc: 0.4448
Epoch 29/100, Loss: 0.2747, Acc: 0.8930, Val Loss: 1.3103, Val Acc: 0.4238
Epoch 30/100, Loss: 0.2744, Acc: 0.8922, Val Loss: 1.3433, Val Acc: 0.4271
Epoch 31/100, Loss: 0.2715, Acc: 0.8944, Val Loss: 1.3408, Val Acc: 0.4120
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2710, Acc: 0.8922, Val Loss: 1.2931, Val Acc: 0.4367
Epoch 33/100, Loss: 0.2709, Acc: 0.8934, Val Loss: 1.3225, Val Acc: 0.4308
Epoch 34/100, Loss: 0.2685, Acc: 0.8951, Val Loss: 1.3217, Val Acc: 0.4404
Epoch 35/100, Loss: 0.2694, Acc: 0.8947, Val Loss: 1.3100, Val Acc: 0.4433
Epoch 36/100, Loss: 0.2684, Acc: 0.8953, Val Loss: 1.3205, Val Acc: 0.4411
Epoch 37/100, Loss: 0.2691, Acc: 0.8944, Val Loss: 1.3067, Val Acc: 0.4444
Epoch 38/100, Loss: 0.2679, Acc: 0.8945, Val Loss: 1.3054, Val Acc: 0.4466
Epoch 39/100, Loss: 0.2696, Acc: 0.8933, Val Loss: 1.3028, Val Acc: 0.4352
Epoch 40/100, Loss: 0.2691, Acc: 0.8923, Val Loss: 1.3210, Val Acc: 0.4370
Epoch 41/100, Loss: 0.2679, Acc: 0.8969, Val Loss: 1.2979, Val Acc: 0.4374
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2661, Acc: 0.8946, Val Loss: 1.3148, Val Acc: 0.4319
Epoch 43/100, Loss: 0.2653, Acc: 0.8957, Val Loss: 1.3144, Val Acc: 0.4389
Epoch 44/100, Loss: 0.2656, Acc: 0.8957, Val Loss: 1.2990, Val Acc: 0.4404
Epoch 45/100, Loss: 0.2658, Acc: 0.8958, Val Loss: 1.3044, Val Acc: 0.4437
Epoch 46/100, Loss: 0.2652, Acc: 0.8955, Val Loss: 1.3031, Val Acc: 0.4433
Epoch 47/100, Loss: 0.2650, Acc: 0.8967, Val Loss: 1.3149, Val Acc: 0.4352
Epoch 48/100, Loss: 0.2655, Acc: 0.8946, Val Loss: 1.3200, Val Acc: 0.4293
Epoch 49/100, Loss: 0.2652, Acc: 0.8958, Val Loss: 1.2971, Val Acc: 0.4451
Epoch 50/100, Loss: 0.2651, Acc: 0.8966, Val Loss: 1.3249, Val Acc: 0.4356
Epoch 51/100, Loss: 0.2652, Acc: 0.8955, Val Loss: 1.3251, Val Acc: 0.4566
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2642, Acc: 0.8968, Val Loss: 1.3077, Val Acc: 0.4415
Epoch 53/100, Loss: 0.2634, Acc: 0.8967, Val Loss: 1.3098, Val Acc: 0.4378
Epoch 54/100, Loss: 0.2636, Acc: 0.8961, Val Loss: 1.3044, Val Acc: 0.4444
Epoch 55/100, Loss: 0.2633, Acc: 0.8974, Val Loss: 1.2963, Val Acc: 0.4451
Epoch 56/100, Loss: 0.2632, Acc: 0.8967, Val Loss: 1.3147, Val Acc: 0.4345
Epoch 57/100, Loss: 0.2632, Acc: 0.8974, Val Loss: 1.3091, Val Acc: 0.4348
Epoch 58/100, Loss: 0.2631, Acc: 0.8965, Val Loss: 1.2958, Val Acc: 0.4392
Epoch 59/100, Loss: 0.2630, Acc: 0.8965, Val Loss: 1.2944, Val Acc: 0.4367
Epoch 60/100, Loss: 0.2630, Acc: 0.8972, Val Loss: 1.2995, Val Acc: 0.4323
Epoch 61/100, Loss: 0.2633, Acc: 0.8959, Val Loss: 1.2934, Val Acc: 0.4345
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2625, Acc: 0.8967, Val Loss: 1.2986, Val Acc: 0.4422
Epoch 63/100, Loss: 0.2622, Acc: 0.8980, Val Loss: 1.3034, Val Acc: 0.4374
Epoch 64/100, Loss: 0.2620, Acc: 0.8968, Val Loss: 1.3008, Val Acc: 0.4466
Epoch 65/100, Loss: 0.2624, Acc: 0.8982, Val Loss: 1.3021, Val Acc: 0.4422
Epoch 66/100, Loss: 0.2620, Acc: 0.8972, Val Loss: 1.3013, Val Acc: 0.4473
Epoch 67/100, Loss: 0.2623, Acc: 0.8972, Val Loss: 1.3047, Val Acc: 0.4363
Epoch 68/100, Loss: 0.2622, Acc: 0.8970, Val Loss: 1.3065, Val Acc: 0.4378
Epoch 69/100, Loss: 0.2621, Acc: 0.8973, Val Loss: 1.3021, Val Acc: 0.4374
Epoch 70/100, Loss: 0.2619, Acc: 0.8978, Val Loss: 1.2996, Val Acc: 0.4363
Epoch 71/100, Loss: 0.2616, Acc: 0.8973, Val Loss: 1.3032, Val Acc: 0.4466
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2618, Acc: 0.8980, Val Loss: 1.3047, Val Acc: 0.4348
Epoch 73/100, Loss: 0.2617, Acc: 0.8971, Val Loss: 1.3038, Val Acc: 0.4385
Epoch 74/100, Loss: 0.2615, Acc: 0.8972, Val Loss: 1.3034, Val Acc: 0.4415
Epoch 75/100, Loss: 0.2616, Acc: 0.8974, Val Loss: 1.3053, Val Acc: 0.4381
Epoch 76/100, Loss: 0.2615, Acc: 0.8975, Val Loss: 1.3049, Val Acc: 0.4392
Epoch 77/100, Loss: 0.2615, Acc: 0.8972, Val Loss: 1.3054, Val Acc: 0.4359
Epoch 78/100, Loss: 0.2615, Acc: 0.8973, Val Loss: 1.2996, Val Acc: 0.4385
Epoch 79/100, Loss: 0.2612, Acc: 0.8978, Val Loss: 1.3023, Val Acc: 0.4407
Epoch 80/100, Loss: 0.2615, Acc: 0.8974, Val Loss: 1.3015, Val Acc: 0.4418
Epoch 81/100, Loss: 0.2615, Acc: 0.8978, Val Loss: 1.3042, Val Acc: 0.4385
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2613, Acc: 0.8977, Val Loss: 1.3053, Val Acc: 0.4330
Epoch 83/100, Loss: 0.2613, Acc: 0.8969, Val Loss: 1.3050, Val Acc: 0.4378
Epoch 84/100, Loss: 0.2613, Acc: 0.8971, Val Loss: 1.3026, Val Acc: 0.4448
Epoch 85/100, Loss: 0.2614, Acc: 0.8977, Val Loss: 1.2984, Val Acc: 0.4437
Epoch 86/100, Loss: 0.2612, Acc: 0.8977, Val Loss: 1.3053, Val Acc: 0.4367
Epoch 87/100, Loss: 0.2612, Acc: 0.8980, Val Loss: 1.3052, Val Acc: 0.4392
Epoch 88/100, Loss: 0.2611, Acc: 0.8977, Val Loss: 1.3004, Val Acc: 0.4411
Epoch 89/100, Loss: 0.2612, Acc: 0.8974, Val Loss: 1.3035, Val Acc: 0.4348
Epoch 90/100, Loss: 0.2611, Acc: 0.8976, Val Loss: 1.3024, Val Acc: 0.4356
Epoch 91/100, Loss: 0.2611, Acc: 0.8975, Val Loss: 1.3019, Val Acc: 0.4341
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2610, Acc: 0.8975, Val Loss: 1.3045, Val Acc: 0.4370
Epoch 93/100, Loss: 0.2611, Acc: 0.8970, Val Loss: 1.3041, Val Acc: 0.4374
Epoch 94/100, Loss: 0.2609, Acc: 0.8976, Val Loss: 1.3025, Val Acc: 0.4378
Epoch 95/100, Loss: 0.2610, Acc: 0.8977, Val Loss: 1.3030, Val Acc: 0.4367
Epoch 96/100, Loss: 0.2609, Acc: 0.8977, Val Loss: 1.3018, Val Acc: 0.4407
Epoch 97/100, Loss: 0.2609, Acc: 0.8972, Val Loss: 1.3064, Val Acc: 0.4370
Epoch 98/100, Loss: 0.2610, Acc: 0.8978, Val Loss: 1.3007, Val Acc: 0.4392
Epoch 99/100, Loss: 0.2608, Acc: 0.8970, Val Loss: 1.3031, Val Acc: 0.4374
Epoch 100/100, Loss: 0.2607, Acc: 0.8977, Val Loss: 1.3013, Val Acc: 0.4426

##############################
Resultados para principal:  107  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5 
 {'training': [0.2607191895552969, 0.8976645825671202, 0.8751952785974657, 0.9275202354672554, 0.9005983745646156], 'validate': [1.3013350823244383, 0.4425625920471281, 0.4664685908319185, 0.81047197640118, 0.5921336206896551], 'test': [0.4120100008116828, 0.8551236749116607, 0.8155136268343816, 0.9174528301886793, 0.8634850166481687]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  086  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  086  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  086  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6324, Acc: 0.6816, Val Loss: 0.8487, Val Acc: 0.3189
Mejor modelo guardado con Val Loss: 0.8487
Epoch 2/100, Loss: 0.5755, Acc: 0.7334, Val Loss: 0.8378, Val Acc: 0.3855
Mejor modelo guardado con Val Loss: 0.8378
Epoch 3/100, Loss: 0.5507, Acc: 0.7413, Val Loss: 0.9410, Val Acc: 0.4021
Epoch 4/100, Loss: 0.5448, Acc: 0.7406, Val Loss: 0.9076, Val Acc: 0.4455
Epoch 5/100, Loss: 0.5321, Acc: 0.7485, Val Loss: 1.0414, Val Acc: 0.3546
Epoch 6/100, Loss: 0.5331, Acc: 0.7443, Val Loss: 0.9615, Val Acc: 0.3719
Epoch 7/100, Loss: 0.5275, Acc: 0.7522, Val Loss: 1.0757, Val Acc: 0.3468
Epoch 8/100, Loss: 0.5165, Acc: 0.7586, Val Loss: 1.1398, Val Acc: 0.3251
Epoch 9/100, Loss: 0.5165, Acc: 0.7528, Val Loss: 1.0343, Val Acc: 0.3840
Epoch 10/100, Loss: 0.5130, Acc: 0.7557, Val Loss: 1.0139, Val Acc: 0.3954
Epoch 11/100, Loss: 0.5135, Acc: 0.7576, Val Loss: 1.1557, Val Acc: 0.3045
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5039, Acc: 0.7621, Val Loss: 1.0826, Val Acc: 0.3575
Epoch 13/100, Loss: 0.5016, Acc: 0.7670, Val Loss: 1.0937, Val Acc: 0.3568
Epoch 14/100, Loss: 0.5013, Acc: 0.7661, Val Loss: 1.1115, Val Acc: 0.3339
Epoch 15/100, Loss: 0.4980, Acc: 0.7651, Val Loss: 1.1421, Val Acc: 0.3317
Epoch 16/100, Loss: 0.5005, Acc: 0.7660, Val Loss: 1.1165, Val Acc: 0.3443
Epoch 17/100, Loss: 0.5027, Acc: 0.7646, Val Loss: 1.0411, Val Acc: 0.3951
Epoch 18/100, Loss: 0.5028, Acc: 0.7633, Val Loss: 1.1265, Val Acc: 0.3211
Epoch 19/100, Loss: 0.4993, Acc: 0.7643, Val Loss: 1.1227, Val Acc: 0.3258
Epoch 20/100, Loss: 0.5015, Acc: 0.7648, Val Loss: 1.1019, Val Acc: 0.3384
Epoch 21/100, Loss: 0.5016, Acc: 0.7649, Val Loss: 1.0608, Val Acc: 0.3737
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4980, Acc: 0.7684, Val Loss: 1.0931, Val Acc: 0.3594
Epoch 23/100, Loss: 0.4951, Acc: 0.7666, Val Loss: 1.1591, Val Acc: 0.3052
Epoch 24/100, Loss: 0.4950, Acc: 0.7678, Val Loss: 1.1088, Val Acc: 0.3498
Epoch 25/100, Loss: 0.4956, Acc: 0.7677, Val Loss: 1.1297, Val Acc: 0.3277
Epoch 26/100, Loss: 0.4923, Acc: 0.7712, Val Loss: 1.1158, Val Acc: 0.3516
Epoch 27/100, Loss: 0.4938, Acc: 0.7696, Val Loss: 1.0875, Val Acc: 0.3833
Epoch 28/100, Loss: 0.4946, Acc: 0.7696, Val Loss: 1.0775, Val Acc: 0.3763
Epoch 29/100, Loss: 0.4952, Acc: 0.7693, Val Loss: 1.1127, Val Acc: 0.3457
Epoch 30/100, Loss: 0.4947, Acc: 0.7703, Val Loss: 1.0734, Val Acc: 0.3884
Epoch 31/100, Loss: 0.4916, Acc: 0.7709, Val Loss: 1.0896, Val Acc: 0.3424
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4906, Acc: 0.7733, Val Loss: 1.1454, Val Acc: 0.3277
Epoch 33/100, Loss: 0.4898, Acc: 0.7757, Val Loss: 1.1184, Val Acc: 0.3395
Epoch 34/100, Loss: 0.4901, Acc: 0.7740, Val Loss: 1.1249, Val Acc: 0.3376
Epoch 35/100, Loss: 0.4900, Acc: 0.7744, Val Loss: 1.1093, Val Acc: 0.3479
Epoch 36/100, Loss: 0.4894, Acc: 0.7766, Val Loss: 1.1004, Val Acc: 0.3557
Epoch 37/100, Loss: 0.4896, Acc: 0.7771, Val Loss: 1.1079, Val Acc: 0.3535
Epoch 38/100, Loss: 0.4895, Acc: 0.7743, Val Loss: 1.1274, Val Acc: 0.3325
Epoch 39/100, Loss: 0.4894, Acc: 0.7762, Val Loss: 1.1299, Val Acc: 0.3317
Epoch 40/100, Loss: 0.4894, Acc: 0.7745, Val Loss: 1.0785, Val Acc: 0.3472
Epoch 41/100, Loss: 0.4897, Acc: 0.7725, Val Loss: 1.1140, Val Acc: 0.3553
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4875, Acc: 0.7746, Val Loss: 1.1100, Val Acc: 0.3432
Epoch 43/100, Loss: 0.4878, Acc: 0.7764, Val Loss: 1.1254, Val Acc: 0.3384
Epoch 44/100, Loss: 0.4879, Acc: 0.7753, Val Loss: 1.1215, Val Acc: 0.3398
Epoch 45/100, Loss: 0.4872, Acc: 0.7775, Val Loss: 1.1219, Val Acc: 0.3439
Epoch 46/100, Loss: 0.4874, Acc: 0.7768, Val Loss: 1.1124, Val Acc: 0.3424
Epoch 47/100, Loss: 0.4876, Acc: 0.7752, Val Loss: 1.1186, Val Acc: 0.3454
Epoch 48/100, Loss: 0.4876, Acc: 0.7766, Val Loss: 1.1202, Val Acc: 0.3424
Epoch 49/100, Loss: 0.4875, Acc: 0.7763, Val Loss: 1.0976, Val Acc: 0.3608
Epoch 50/100, Loss: 0.4867, Acc: 0.7769, Val Loss: 1.1312, Val Acc: 0.3428
Epoch 51/100, Loss: 0.4865, Acc: 0.7768, Val Loss: 1.1068, Val Acc: 0.3398
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4850, Acc: 0.7778, Val Loss: 1.0893, Val Acc: 0.3435
Epoch 53/100, Loss: 0.4849, Acc: 0.7783, Val Loss: 1.1073, Val Acc: 0.3398
Epoch 54/100, Loss: 0.4850, Acc: 0.7799, Val Loss: 1.0950, Val Acc: 0.3454
Epoch 55/100, Loss: 0.4845, Acc: 0.7777, Val Loss: 1.0830, Val Acc: 0.3579
Epoch 56/100, Loss: 0.4846, Acc: 0.7786, Val Loss: 1.1053, Val Acc: 0.3387
Epoch 57/100, Loss: 0.4844, Acc: 0.7767, Val Loss: 1.0885, Val Acc: 0.3542
Epoch 58/100, Loss: 0.4844, Acc: 0.7775, Val Loss: 1.0824, Val Acc: 0.3546
Epoch 59/100, Loss: 0.4844, Acc: 0.7773, Val Loss: 1.1025, Val Acc: 0.3424
Epoch 60/100, Loss: 0.4840, Acc: 0.7773, Val Loss: 1.0987, Val Acc: 0.3465
Epoch 61/100, Loss: 0.4841, Acc: 0.7779, Val Loss: 1.0863, Val Acc: 0.3524
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4837, Acc: 0.7780, Val Loss: 1.1039, Val Acc: 0.3417
Epoch 63/100, Loss: 0.4837, Acc: 0.7779, Val Loss: 1.0984, Val Acc: 0.3454
Epoch 64/100, Loss: 0.4836, Acc: 0.7782, Val Loss: 1.0940, Val Acc: 0.3494
Epoch 65/100, Loss: 0.4836, Acc: 0.7781, Val Loss: 1.0947, Val Acc: 0.3490
Epoch 66/100, Loss: 0.4835, Acc: 0.7772, Val Loss: 1.0907, Val Acc: 0.3494
Epoch 67/100, Loss: 0.4836, Acc: 0.7779, Val Loss: 1.0957, Val Acc: 0.3490
Epoch 68/100, Loss: 0.4836, Acc: 0.7784, Val Loss: 1.0927, Val Acc: 0.3494
Epoch 69/100, Loss: 0.4836, Acc: 0.7782, Val Loss: 1.0936, Val Acc: 0.3490
Epoch 70/100, Loss: 0.4834, Acc: 0.7781, Val Loss: 1.1005, Val Acc: 0.3432
Epoch 71/100, Loss: 0.4834, Acc: 0.7778, Val Loss: 1.0916, Val Acc: 0.3524
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4833, Acc: 0.7789, Val Loss: 1.0979, Val Acc: 0.3494
Epoch 73/100, Loss: 0.4831, Acc: 0.7782, Val Loss: 1.1030, Val Acc: 0.3435
Epoch 74/100, Loss: 0.4831, Acc: 0.7785, Val Loss: 1.1000, Val Acc: 0.3443
Epoch 75/100, Loss: 0.4831, Acc: 0.7787, Val Loss: 1.0968, Val Acc: 0.3465
Epoch 76/100, Loss: 0.4831, Acc: 0.7791, Val Loss: 1.0940, Val Acc: 0.3501
Epoch 77/100, Loss: 0.4829, Acc: 0.7779, Val Loss: 1.1029, Val Acc: 0.3420
Epoch 78/100, Loss: 0.4832, Acc: 0.7786, Val Loss: 1.1011, Val Acc: 0.3435
Epoch 79/100, Loss: 0.4830, Acc: 0.7785, Val Loss: 1.0942, Val Acc: 0.3501
Epoch 80/100, Loss: 0.4830, Acc: 0.7780, Val Loss: 1.0969, Val Acc: 0.3461
Epoch 81/100, Loss: 0.4829, Acc: 0.7781, Val Loss: 1.0966, Val Acc: 0.3465
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4829, Acc: 0.7783, Val Loss: 1.0988, Val Acc: 0.3461
Epoch 83/100, Loss: 0.4830, Acc: 0.7782, Val Loss: 1.0994, Val Acc: 0.3457
Epoch 84/100, Loss: 0.4829, Acc: 0.7788, Val Loss: 1.0965, Val Acc: 0.3483
Epoch 85/100, Loss: 0.4827, Acc: 0.7785, Val Loss: 1.0895, Val Acc: 0.3553
Epoch 86/100, Loss: 0.4827, Acc: 0.7773, Val Loss: 1.0916, Val Acc: 0.3524
Epoch 87/100, Loss: 0.4826, Acc: 0.7777, Val Loss: 1.0959, Val Acc: 0.3487
Epoch 88/100, Loss: 0.4825, Acc: 0.7787, Val Loss: 1.1004, Val Acc: 0.3457
Epoch 89/100, Loss: 0.4824, Acc: 0.7787, Val Loss: 1.0990, Val Acc: 0.3457
Epoch 90/100, Loss: 0.4823, Acc: 0.7790, Val Loss: 1.1025, Val Acc: 0.3450
Epoch 91/100, Loss: 0.4823, Acc: 0.7795, Val Loss: 1.0985, Val Acc: 0.3468
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4823, Acc: 0.7783, Val Loss: 1.1010, Val Acc: 0.3450
Epoch 93/100, Loss: 0.4820, Acc: 0.7783, Val Loss: 1.0912, Val Acc: 0.3527
Epoch 94/100, Loss: 0.4822, Acc: 0.7776, Val Loss: 1.0985, Val Acc: 0.3465
Epoch 95/100, Loss: 0.4823, Acc: 0.7796, Val Loss: 1.0957, Val Acc: 0.3494
Epoch 96/100, Loss: 0.4821, Acc: 0.7784, Val Loss: 1.1004, Val Acc: 0.3454
Epoch 97/100, Loss: 0.4821, Acc: 0.7784, Val Loss: 1.0987, Val Acc: 0.3454
Epoch 98/100, Loss: 0.4821, Acc: 0.7786, Val Loss: 1.0938, Val Acc: 0.3498
Epoch 99/100, Loss: 0.4821, Acc: 0.7782, Val Loss: 1.0970, Val Acc: 0.3483
Epoch 100/100, Loss: 0.4821, Acc: 0.7786, Val Loss: 1.0957, Val Acc: 0.3483

##############################
Resultados para principal:  086  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  5 
 {'training': [0.48212103438798276, 0.7785950717175432, 0.744272345918038, 0.8486019131714496, 0.7930204572803851], 'validate': [1.0957118813381639, 0.3483063328424153, 0.40913081650570676, 0.6873156342182891, 0.5129334067143644], 'test': [0.8028917423001042, 0.4202002355712603, 0.4554939680469514, 0.8237028301886793, 0.5866050808314087]}

##############################
Resultados para window:  5 
 {'098:025:059:121:107:086': {'training': [0.49903186946372946, 0.7547811695476278, 0.6988938370923717, 0.8949595290654894, 0.784867306606437], 'validate': [0.3776466553207747, 0.8582474226804123, 0.8416608022519353, 0.8820058997050148, 0.8613611811307166], 'test': [0.5662600243533099, 0.6884570082449941, 0.6306306306306306, 0.9080188679245284, 0.7443209279845336]}, '025:098:059:121:107:086': {'training': [0.52771352853526, 0.7410812798823097, 0.7077386615921345, 0.8210080941869021, 0.7601771418838358], 'validate': [0.3928791057578353, 0.7941826215022091, 0.8700092850510678, 0.6910029498525073, 0.770242498972462], 'test': [0.6563433016891833, 0.6089517078916372, 0.5684523809523809, 0.9009433962264151, 0.6970802919708029]}, '059:098:025:121:107:086': {'training': [0.4750342961180162, 0.7638837808017653, 0.7769409038238703, 0.7400662251655629, 0.7580553985302431], 'validate': [0.217097332831039, 0.9189985272459499, 1.0, 0.8377581120943953, 0.9117174959871589], 'test': [0.5383025131843708, 0.7326266195524146, 0.6790909090909091, 0.8808962264150944, 0.7669404517453798]}, '121:098:025:059:107:086': {'training': [0.1994431510967733, 0.9263515998528871, 0.9035347379418422, 0.9545621780721119, 0.9283477949727167], 'validate': [1.3211297487276932, 0.4963181148748159, 0.4976689976689977, 0.9446902654867256, 0.6519083969465649], 'test': [0.45856943395402694, 0.78150765606596, 0.726280834914611, 0.9027122641509434, 0.8049421661409043]}, '107:098:025:059:121:086': {'training': [0.2607191895552969, 0.8976645825671202, 0.8751952785974657, 0.9275202354672554, 0.9005983745646156], 'validate': [1.3013350823244383, 0.4425625920471281, 0.4664685908319185, 0.81047197640118, 0.5921336206896551], 'test': [0.4120100008116828, 0.8551236749116607, 0.8155136268343816, 0.9174528301886793, 0.8634850166481687]}, '086:098:025:059:121:107': {'training': [0.48212103438798276, 0.7785950717175432, 0.744272345918038, 0.8486019131714496, 0.7930204572803851], 'validate': [1.0957118813381639, 0.3483063328424153, 0.40913081650570676, 0.6873156342182891, 0.5129334067143644], 'test': [0.8028917423001042, 0.4202002355712603, 0.4554939680469514, 0.8237028301886793, 0.5866050808314087]}}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  031  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  031  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  031  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6919, Acc: 0.5225, Val Loss: 0.6934, Val Acc: 0.5059
Mejor modelo guardado con Val Loss: 0.6934
Epoch 2/100, Loss: 0.6897, Acc: 0.5578, Val Loss: 0.6932, Val Acc: 0.5033
Mejor modelo guardado con Val Loss: 0.6932
Epoch 3/100, Loss: 0.6889, Acc: 0.5533, Val Loss: 0.6943, Val Acc: 0.4959
Epoch 4/100, Loss: 0.6870, Acc: 0.5622, Val Loss: 0.6959, Val Acc: 0.4989
Epoch 5/100, Loss: 0.6853, Acc: 0.5649, Val Loss: 0.6971, Val Acc: 0.4967
Epoch 6/100, Loss: 0.6828, Acc: 0.5782, Val Loss: 0.6981, Val Acc: 0.4945
Epoch 7/100, Loss: 0.6815, Acc: 0.5781, Val Loss: 0.6978, Val Acc: 0.5026
Epoch 8/100, Loss: 0.6819, Acc: 0.5738, Val Loss: 0.6994, Val Acc: 0.4959
Epoch 9/100, Loss: 0.6797, Acc: 0.5802, Val Loss: 0.7018, Val Acc: 0.5015
Epoch 10/100, Loss: 0.6795, Acc: 0.5798, Val Loss: 0.7054, Val Acc: 0.4982
Epoch 11/100, Loss: 0.6780, Acc: 0.5810, Val Loss: 0.7039, Val Acc: 0.4993
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6754, Acc: 0.5894, Val Loss: 0.7052, Val Acc: 0.4945
Epoch 13/100, Loss: 0.6747, Acc: 0.5925, Val Loss: 0.7053, Val Acc: 0.4878
Epoch 14/100, Loss: 0.6739, Acc: 0.5931, Val Loss: 0.7061, Val Acc: 0.4974
Epoch 15/100, Loss: 0.6730, Acc: 0.5942, Val Loss: 0.7073, Val Acc: 0.5048
Epoch 16/100, Loss: 0.6736, Acc: 0.5926, Val Loss: 0.7076, Val Acc: 0.4941
Epoch 17/100, Loss: 0.6729, Acc: 0.5924, Val Loss: 0.7092, Val Acc: 0.4996
Epoch 18/100, Loss: 0.6741, Acc: 0.5880, Val Loss: 0.7078, Val Acc: 0.5052
Epoch 19/100, Loss: 0.6736, Acc: 0.5924, Val Loss: 0.7084, Val Acc: 0.4926
Epoch 20/100, Loss: 0.6725, Acc: 0.5966, Val Loss: 0.7076, Val Acc: 0.5077
Epoch 21/100, Loss: 0.6728, Acc: 0.5914, Val Loss: 0.7083, Val Acc: 0.4996
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6716, Acc: 0.5942, Val Loss: 0.7099, Val Acc: 0.5026
Epoch 23/100, Loss: 0.6717, Acc: 0.5929, Val Loss: 0.7116, Val Acc: 0.4926
Epoch 24/100, Loss: 0.6705, Acc: 0.5960, Val Loss: 0.7115, Val Acc: 0.4937
Epoch 25/100, Loss: 0.6709, Acc: 0.5984, Val Loss: 0.7111, Val Acc: 0.4974
Epoch 26/100, Loss: 0.6708, Acc: 0.5951, Val Loss: 0.7123, Val Acc: 0.4934
Epoch 27/100, Loss: 0.6703, Acc: 0.5992, Val Loss: 0.7131, Val Acc: 0.4930
Epoch 28/100, Loss: 0.6713, Acc: 0.5965, Val Loss: 0.7117, Val Acc: 0.4989
Epoch 29/100, Loss: 0.6705, Acc: 0.5987, Val Loss: 0.7126, Val Acc: 0.4934
Epoch 30/100, Loss: 0.6705, Acc: 0.5984, Val Loss: 0.7117, Val Acc: 0.4985
Epoch 31/100, Loss: 0.6699, Acc: 0.6006, Val Loss: 0.7128, Val Acc: 0.4948
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6694, Acc: 0.6010, Val Loss: 0.7131, Val Acc: 0.4941
Epoch 33/100, Loss: 0.6697, Acc: 0.5997, Val Loss: 0.7135, Val Acc: 0.4930
Epoch 34/100, Loss: 0.6695, Acc: 0.5988, Val Loss: 0.7145, Val Acc: 0.5011
Epoch 35/100, Loss: 0.6699, Acc: 0.5960, Val Loss: 0.7127, Val Acc: 0.4996
Epoch 36/100, Loss: 0.6700, Acc: 0.5956, Val Loss: 0.7141, Val Acc: 0.4937
Epoch 37/100, Loss: 0.6697, Acc: 0.5980, Val Loss: 0.7145, Val Acc: 0.4948
Epoch 38/100, Loss: 0.6695, Acc: 0.5985, Val Loss: 0.7140, Val Acc: 0.4948
Epoch 39/100, Loss: 0.6690, Acc: 0.6001, Val Loss: 0.7141, Val Acc: 0.4948
Epoch 40/100, Loss: 0.6693, Acc: 0.5988, Val Loss: 0.7145, Val Acc: 0.4923
Epoch 41/100, Loss: 0.6696, Acc: 0.6014, Val Loss: 0.7139, Val Acc: 0.4963
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6692, Acc: 0.5983, Val Loss: 0.7143, Val Acc: 0.4941
Epoch 43/100, Loss: 0.6687, Acc: 0.6014, Val Loss: 0.7147, Val Acc: 0.4930
Epoch 44/100, Loss: 0.6689, Acc: 0.6012, Val Loss: 0.7146, Val Acc: 0.4937
Epoch 45/100, Loss: 0.6687, Acc: 0.6024, Val Loss: 0.7137, Val Acc: 0.4996
Epoch 46/100, Loss: 0.6689, Acc: 0.6016, Val Loss: 0.7145, Val Acc: 0.4948
Epoch 47/100, Loss: 0.6687, Acc: 0.6010, Val Loss: 0.7147, Val Acc: 0.4948
Epoch 48/100, Loss: 0.6687, Acc: 0.6023, Val Loss: 0.7145, Val Acc: 0.4945
Epoch 49/100, Loss: 0.6687, Acc: 0.6030, Val Loss: 0.7148, Val Acc: 0.4945
Epoch 50/100, Loss: 0.6688, Acc: 0.5997, Val Loss: 0.7145, Val Acc: 0.4971
Epoch 51/100, Loss: 0.6686, Acc: 0.6022, Val Loss: 0.7143, Val Acc: 0.4996
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6685, Acc: 0.6001, Val Loss: 0.7147, Val Acc: 0.4956
Epoch 53/100, Loss: 0.6684, Acc: 0.6024, Val Loss: 0.7146, Val Acc: 0.4952
Epoch 54/100, Loss: 0.6685, Acc: 0.6015, Val Loss: 0.7150, Val Acc: 0.4930
Epoch 55/100, Loss: 0.6684, Acc: 0.6036, Val Loss: 0.7151, Val Acc: 0.4923
Epoch 56/100, Loss: 0.6684, Acc: 0.6030, Val Loss: 0.7149, Val Acc: 0.4956
Epoch 57/100, Loss: 0.6684, Acc: 0.6024, Val Loss: 0.7152, Val Acc: 0.4923
Epoch 58/100, Loss: 0.6684, Acc: 0.6022, Val Loss: 0.7150, Val Acc: 0.4937
Epoch 59/100, Loss: 0.6684, Acc: 0.6021, Val Loss: 0.7150, Val Acc: 0.4956
Epoch 60/100, Loss: 0.6683, Acc: 0.6029, Val Loss: 0.7148, Val Acc: 0.4967
Epoch 61/100, Loss: 0.6683, Acc: 0.6020, Val Loss: 0.7154, Val Acc: 0.4937
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6683, Acc: 0.6011, Val Loss: 0.7150, Val Acc: 0.4948
Epoch 63/100, Loss: 0.6681, Acc: 0.6030, Val Loss: 0.7153, Val Acc: 0.4941
Epoch 64/100, Loss: 0.6680, Acc: 0.6024, Val Loss: 0.7152, Val Acc: 0.4941
Epoch 65/100, Loss: 0.6681, Acc: 0.6031, Val Loss: 0.7153, Val Acc: 0.4937
Epoch 66/100, Loss: 0.6680, Acc: 0.6012, Val Loss: 0.7153, Val Acc: 0.4926
Epoch 67/100, Loss: 0.6680, Acc: 0.6032, Val Loss: 0.7155, Val Acc: 0.4941
Epoch 68/100, Loss: 0.6680, Acc: 0.6033, Val Loss: 0.7154, Val Acc: 0.4919
Epoch 69/100, Loss: 0.6680, Acc: 0.6020, Val Loss: 0.7155, Val Acc: 0.4919
Epoch 70/100, Loss: 0.6679, Acc: 0.6017, Val Loss: 0.7156, Val Acc: 0.4912
Epoch 71/100, Loss: 0.6679, Acc: 0.6020, Val Loss: 0.7155, Val Acc: 0.4937
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6679, Acc: 0.6029, Val Loss: 0.7156, Val Acc: 0.4915
Epoch 73/100, Loss: 0.6679, Acc: 0.6013, Val Loss: 0.7156, Val Acc: 0.4930
Epoch 74/100, Loss: 0.6679, Acc: 0.6039, Val Loss: 0.7154, Val Acc: 0.4945
Epoch 75/100, Loss: 0.6680, Acc: 0.6030, Val Loss: 0.7155, Val Acc: 0.4915
Epoch 76/100, Loss: 0.6679, Acc: 0.6035, Val Loss: 0.7155, Val Acc: 0.4915
Epoch 77/100, Loss: 0.6679, Acc: 0.6035, Val Loss: 0.7156, Val Acc: 0.4915
Epoch 78/100, Loss: 0.6678, Acc: 0.6028, Val Loss: 0.7156, Val Acc: 0.4937
Epoch 79/100, Loss: 0.6679, Acc: 0.6018, Val Loss: 0.7157, Val Acc: 0.4923
Epoch 80/100, Loss: 0.6679, Acc: 0.6032, Val Loss: 0.7157, Val Acc: 0.4923
Epoch 81/100, Loss: 0.6678, Acc: 0.6024, Val Loss: 0.7157, Val Acc: 0.4919
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6678, Acc: 0.6027, Val Loss: 0.7157, Val Acc: 0.4919
Epoch 83/100, Loss: 0.6678, Acc: 0.6010, Val Loss: 0.7157, Val Acc: 0.4919
Epoch 84/100, Loss: 0.6678, Acc: 0.6026, Val Loss: 0.7158, Val Acc: 0.4923
Epoch 85/100, Loss: 0.6678, Acc: 0.6027, Val Loss: 0.7156, Val Acc: 0.4923
Epoch 86/100, Loss: 0.6678, Acc: 0.6024, Val Loss: 0.7158, Val Acc: 0.4919
Epoch 87/100, Loss: 0.6678, Acc: 0.6026, Val Loss: 0.7157, Val Acc: 0.4934
Epoch 88/100, Loss: 0.6678, Acc: 0.6025, Val Loss: 0.7157, Val Acc: 0.4919
Epoch 89/100, Loss: 0.6678, Acc: 0.6022, Val Loss: 0.7157, Val Acc: 0.4919
Epoch 90/100, Loss: 0.6677, Acc: 0.6022, Val Loss: 0.7159, Val Acc: 0.4934
Epoch 91/100, Loss: 0.6677, Acc: 0.6020, Val Loss: 0.7161, Val Acc: 0.4930
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6677, Acc: 0.6025, Val Loss: 0.7162, Val Acc: 0.4915
Epoch 93/100, Loss: 0.6676, Acc: 0.6027, Val Loss: 0.7163, Val Acc: 0.4919
Epoch 94/100, Loss: 0.6676, Acc: 0.6026, Val Loss: 0.7163, Val Acc: 0.4930
Epoch 95/100, Loss: 0.6676, Acc: 0.6024, Val Loss: 0.7164, Val Acc: 0.4915
Epoch 96/100, Loss: 0.6676, Acc: 0.6025, Val Loss: 0.7164, Val Acc: 0.4934
Epoch 97/100, Loss: 0.6675, Acc: 0.6024, Val Loss: 0.7165, Val Acc: 0.4912
Epoch 98/100, Loss: 0.6676, Acc: 0.6020, Val Loss: 0.7165, Val Acc: 0.4930
Epoch 99/100, Loss: 0.6675, Acc: 0.6033, Val Loss: 0.7164, Val Acc: 0.4926
Epoch 100/100, Loss: 0.6676, Acc: 0.6028, Val Loss: 0.7165, Val Acc: 0.4926

##############################
Resultados para principal:  031  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5 
 {'training': [0.6675575805438183, 0.6027951452739978, 0.6111111111111112, 0.5645695364238411, 0.5869191049913941], 'validate': [0.7165400316548902, 0.49263622974963184, 0.4930817610062893, 0.5781710914454278, 0.5322471147318398], 'test': [0.6936160270814542, 0.5026501766784452, 0.5021432945499081, 0.4834905660377358, 0.49264043256233103]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  051  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  051  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  051  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6666, Acc: 0.6177, Val Loss: 0.6630, Val Acc: 0.6351
Mejor modelo guardado con Val Loss: 0.6630
Epoch 2/100, Loss: 0.6377, Acc: 0.6585, Val Loss: 0.6521, Val Acc: 0.5983
Mejor modelo guardado con Val Loss: 0.6521
Epoch 3/100, Loss: 0.6163, Acc: 0.6715, Val Loss: 0.6686, Val Acc: 0.5873
Epoch 4/100, Loss: 0.5978, Acc: 0.6920, Val Loss: 0.6267, Val Acc: 0.6487
Mejor modelo guardado con Val Loss: 0.6267
Epoch 5/100, Loss: 0.5882, Acc: 0.6943, Val Loss: 0.6294, Val Acc: 0.6881
Epoch 6/100, Loss: 0.6000, Acc: 0.6985, Val Loss: 0.6001, Val Acc: 0.6955
Mejor modelo guardado con Val Loss: 0.6001
Epoch 7/100, Loss: 0.6022, Acc: 0.6805, Val Loss: 0.6304, Val Acc: 0.6495
Epoch 8/100, Loss: 0.5959, Acc: 0.6949, Val Loss: 0.6213, Val Acc: 0.6476
Epoch 9/100, Loss: 0.6048, Acc: 0.6873, Val Loss: 0.6034, Val Acc: 0.6918
Epoch 10/100, Loss: 0.6018, Acc: 0.6894, Val Loss: 0.6345, Val Acc: 0.6469
Epoch 11/100, Loss: 0.5987, Acc: 0.7060, Val Loss: 0.6510, Val Acc: 0.6351
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5960, Acc: 0.7015, Val Loss: 0.6641, Val Acc: 0.6351
Epoch 13/100, Loss: 0.5863, Acc: 0.7060, Val Loss: 0.5991, Val Acc: 0.7018
Mejor modelo guardado con Val Loss: 0.5991
Epoch 14/100, Loss: 0.5798, Acc: 0.7148, Val Loss: 0.6507, Val Acc: 0.6244
Epoch 15/100, Loss: 0.5840, Acc: 0.7064, Val Loss: 0.6133, Val Acc: 0.6793
Epoch 16/100, Loss: 0.5773, Acc: 0.7132, Val Loss: 0.6062, Val Acc: 0.6837
Epoch 17/100, Loss: 0.5720, Acc: 0.7203, Val Loss: 0.6023, Val Acc: 0.6878
Epoch 18/100, Loss: 0.5762, Acc: 0.7109, Val Loss: 0.6137, Val Acc: 0.6598
Epoch 19/100, Loss: 0.5700, Acc: 0.7210, Val Loss: 0.6287, Val Acc: 0.6484
Epoch 20/100, Loss: 0.5746, Acc: 0.7107, Val Loss: 0.6388, Val Acc: 0.6340
Epoch 21/100, Loss: 0.5807, Acc: 0.7106, Val Loss: 0.6307, Val Acc: 0.6583
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5680, Acc: 0.7223, Val Loss: 0.6219, Val Acc: 0.6499
Epoch 23/100, Loss: 0.5682, Acc: 0.7210, Val Loss: 0.6134, Val Acc: 0.6775
Epoch 24/100, Loss: 0.5705, Acc: 0.7171, Val Loss: 0.6023, Val Acc: 0.6900
Epoch 25/100, Loss: 0.5648, Acc: 0.7261, Val Loss: 0.6184, Val Acc: 0.6760
Epoch 26/100, Loss: 0.5670, Acc: 0.7248, Val Loss: 0.6025, Val Acc: 0.6959
Epoch 27/100, Loss: 0.5714, Acc: 0.7186, Val Loss: 0.6340, Val Acc: 0.6219
Epoch 28/100, Loss: 0.5706, Acc: 0.7140, Val Loss: 0.6008, Val Acc: 0.7010
Epoch 29/100, Loss: 0.5663, Acc: 0.7262, Val Loss: 0.6046, Val Acc: 0.6999
Epoch 30/100, Loss: 0.5636, Acc: 0.7276, Val Loss: 0.6222, Val Acc: 0.6624
Epoch 31/100, Loss: 0.5655, Acc: 0.7248, Val Loss: 0.6016, Val Acc: 0.6988
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5617, Acc: 0.7291, Val Loss: 0.6113, Val Acc: 0.6823
Epoch 33/100, Loss: 0.5635, Acc: 0.7273, Val Loss: 0.6018, Val Acc: 0.6962
Epoch 34/100, Loss: 0.5623, Acc: 0.7279, Val Loss: 0.6087, Val Acc: 0.6826
Epoch 35/100, Loss: 0.5647, Acc: 0.7258, Val Loss: 0.6186, Val Acc: 0.6760
Epoch 36/100, Loss: 0.5613, Acc: 0.7281, Val Loss: 0.6055, Val Acc: 0.6900
Epoch 37/100, Loss: 0.5630, Acc: 0.7249, Val Loss: 0.6162, Val Acc: 0.6778
Epoch 38/100, Loss: 0.5609, Acc: 0.7287, Val Loss: 0.6024, Val Acc: 0.6959
Epoch 39/100, Loss: 0.5621, Acc: 0.7268, Val Loss: 0.6125, Val Acc: 0.6800
Epoch 40/100, Loss: 0.5612, Acc: 0.7289, Val Loss: 0.6094, Val Acc: 0.6826
Epoch 41/100, Loss: 0.5616, Acc: 0.7273, Val Loss: 0.6028, Val Acc: 0.6962
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5601, Acc: 0.7299, Val Loss: 0.6114, Val Acc: 0.6800
Epoch 43/100, Loss: 0.5609, Acc: 0.7290, Val Loss: 0.6039, Val Acc: 0.6944
Epoch 44/100, Loss: 0.5598, Acc: 0.7291, Val Loss: 0.6050, Val Acc: 0.6933
Epoch 45/100, Loss: 0.5599, Acc: 0.7277, Val Loss: 0.6009, Val Acc: 0.6966
Epoch 46/100, Loss: 0.5597, Acc: 0.7303, Val Loss: 0.6008, Val Acc: 0.6988
Epoch 47/100, Loss: 0.5594, Acc: 0.7289, Val Loss: 0.6013, Val Acc: 0.6955
Epoch 48/100, Loss: 0.5584, Acc: 0.7305, Val Loss: 0.6035, Val Acc: 0.6966
Epoch 49/100, Loss: 0.5606, Acc: 0.7289, Val Loss: 0.6006, Val Acc: 0.7018
Epoch 50/100, Loss: 0.5594, Acc: 0.7300, Val Loss: 0.6066, Val Acc: 0.6911
Epoch 51/100, Loss: 0.5587, Acc: 0.7305, Val Loss: 0.6007, Val Acc: 0.6988
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5581, Acc: 0.7311, Val Loss: 0.6039, Val Acc: 0.6948
Epoch 53/100, Loss: 0.5585, Acc: 0.7316, Val Loss: 0.6034, Val Acc: 0.6962
Epoch 54/100, Loss: 0.5576, Acc: 0.7320, Val Loss: 0.6077, Val Acc: 0.6892
Epoch 55/100, Loss: 0.5588, Acc: 0.7310, Val Loss: 0.6081, Val Acc: 0.6885
Epoch 56/100, Loss: 0.5581, Acc: 0.7329, Val Loss: 0.6092, Val Acc: 0.6852
Epoch 57/100, Loss: 0.5582, Acc: 0.7310, Val Loss: 0.6025, Val Acc: 0.6962
Epoch 58/100, Loss: 0.5575, Acc: 0.7325, Val Loss: 0.6116, Val Acc: 0.6819
Epoch 59/100, Loss: 0.5579, Acc: 0.7316, Val Loss: 0.6024, Val Acc: 0.6955
Epoch 60/100, Loss: 0.5577, Acc: 0.7311, Val Loss: 0.6034, Val Acc: 0.6959
Epoch 61/100, Loss: 0.5581, Acc: 0.7305, Val Loss: 0.6009, Val Acc: 0.6988
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5575, Acc: 0.7317, Val Loss: 0.6050, Val Acc: 0.6948
Epoch 63/100, Loss: 0.5573, Acc: 0.7315, Val Loss: 0.6040, Val Acc: 0.6955
Epoch 64/100, Loss: 0.5570, Acc: 0.7324, Val Loss: 0.6071, Val Acc: 0.6929
Epoch 65/100, Loss: 0.5570, Acc: 0.7334, Val Loss: 0.6016, Val Acc: 0.6966
Epoch 66/100, Loss: 0.5576, Acc: 0.7316, Val Loss: 0.6026, Val Acc: 0.6959
Epoch 67/100, Loss: 0.5571, Acc: 0.7324, Val Loss: 0.6036, Val Acc: 0.6955
Epoch 68/100, Loss: 0.5570, Acc: 0.7314, Val Loss: 0.6017, Val Acc: 0.6962
Epoch 69/100, Loss: 0.5571, Acc: 0.7334, Val Loss: 0.6051, Val Acc: 0.6951
Epoch 70/100, Loss: 0.5572, Acc: 0.7328, Val Loss: 0.6019, Val Acc: 0.6966
Epoch 71/100, Loss: 0.5570, Acc: 0.7316, Val Loss: 0.6025, Val Acc: 0.6959
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5569, Acc: 0.7331, Val Loss: 0.6036, Val Acc: 0.6955
Epoch 73/100, Loss: 0.5568, Acc: 0.7325, Val Loss: 0.6033, Val Acc: 0.6955
Epoch 74/100, Loss: 0.5568, Acc: 0.7321, Val Loss: 0.6029, Val Acc: 0.6959
Epoch 75/100, Loss: 0.5569, Acc: 0.7330, Val Loss: 0.6040, Val Acc: 0.6959
Epoch 76/100, Loss: 0.5568, Acc: 0.7319, Val Loss: 0.6037, Val Acc: 0.6959
Epoch 77/100, Loss: 0.5569, Acc: 0.7329, Val Loss: 0.6022, Val Acc: 0.6973
Epoch 78/100, Loss: 0.5569, Acc: 0.7316, Val Loss: 0.6027, Val Acc: 0.6962
Epoch 79/100, Loss: 0.5569, Acc: 0.7318, Val Loss: 0.6050, Val Acc: 0.6948
Epoch 80/100, Loss: 0.5561, Acc: 0.7328, Val Loss: 0.6025, Val Acc: 0.6962
Epoch 81/100, Loss: 0.5540, Acc: 0.7327, Val Loss: 0.6014, Val Acc: 0.6970
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5538, Acc: 0.7320, Val Loss: 0.6003, Val Acc: 0.6977
Epoch 83/100, Loss: 0.5537, Acc: 0.7320, Val Loss: 0.6008, Val Acc: 0.6977
Epoch 84/100, Loss: 0.5535, Acc: 0.7321, Val Loss: 0.6018, Val Acc: 0.6966
Epoch 85/100, Loss: 0.5535, Acc: 0.7323, Val Loss: 0.5997, Val Acc: 0.6985
Epoch 86/100, Loss: 0.5535, Acc: 0.7325, Val Loss: 0.6009, Val Acc: 0.6977
Epoch 87/100, Loss: 0.5535, Acc: 0.7322, Val Loss: 0.6003, Val Acc: 0.6973
Epoch 88/100, Loss: 0.5536, Acc: 0.7327, Val Loss: 0.5997, Val Acc: 0.6988
Epoch 89/100, Loss: 0.5535, Acc: 0.7326, Val Loss: 0.5998, Val Acc: 0.6988
Epoch 90/100, Loss: 0.5533, Acc: 0.7330, Val Loss: 0.6009, Val Acc: 0.6970
Epoch 91/100, Loss: 0.5533, Acc: 0.7319, Val Loss: 0.5998, Val Acc: 0.6977
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5532, Acc: 0.7324, Val Loss: 0.6007, Val Acc: 0.6977
Epoch 93/100, Loss: 0.5531, Acc: 0.7329, Val Loss: 0.6013, Val Acc: 0.6962
Epoch 94/100, Loss: 0.5531, Acc: 0.7325, Val Loss: 0.6005, Val Acc: 0.6977
Epoch 95/100, Loss: 0.5530, Acc: 0.7319, Val Loss: 0.6032, Val Acc: 0.6944
Epoch 96/100, Loss: 0.5533, Acc: 0.7324, Val Loss: 0.6008, Val Acc: 0.6981
Epoch 97/100, Loss: 0.5529, Acc: 0.7327, Val Loss: 0.5997, Val Acc: 0.6981
Epoch 98/100, Loss: 0.5530, Acc: 0.7326, Val Loss: 0.6000, Val Acc: 0.6981
Epoch 99/100, Loss: 0.5529, Acc: 0.7333, Val Loss: 0.6002, Val Acc: 0.6981
Epoch 100/100, Loss: 0.5527, Acc: 0.7330, Val Loss: 0.5989, Val Acc: 0.6992
Mejor modelo guardado con Val Loss: 0.5989

##############################
Resultados para principal:  051  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5 
 {'training': [0.5527157937835884, 0.7329900698786318, 0.7479435957696827, 0.7025386313465783, 0.7245304496300512], 'validate': [0.598920768083528, 0.6991899852724595, 0.7185725871857259, 0.6533923303834809, 0.6844341444573194], 'test': [0.678119832166919, 0.6351590106007067, 0.6223888591322978, 0.6851415094339622, 0.6522593320235757]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  096  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  096  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  096  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6921, Acc: 0.5159, Val Loss: 0.6941, Val Acc: 0.4543
Mejor modelo guardado con Val Loss: 0.6941
Epoch 2/100, Loss: 0.6927, Acc: 0.5124, Val Loss: 0.6930, Val Acc: 0.5004
Mejor modelo guardado con Val Loss: 0.6930
Epoch 3/100, Loss: 0.6926, Acc: 0.5108, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 4/100, Loss: 0.6933, Acc: 0.5116, Val Loss: 0.6933, Val Acc: 0.5007
Epoch 5/100, Loss: 0.6933, Acc: 0.5018, Val Loss: 0.6934, Val Acc: 0.5007
Epoch 6/100, Loss: 0.6935, Acc: 0.4945, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 7/100, Loss: 0.6936, Acc: 0.4978, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 8/100, Loss: 0.6934, Acc: 0.5046, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 9/100, Loss: 0.6933, Acc: 0.4993, Val Loss: 0.6935, Val Acc: 0.5007
Epoch 10/100, Loss: 0.6932, Acc: 0.5029, Val Loss: 0.6938, Val Acc: 0.5007
Epoch 11/100, Loss: 0.6933, Acc: 0.5026, Val Loss: 0.6932, Val Acc: 0.4993
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4994, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 13/100, Loss: 0.6933, Acc: 0.5048, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 14/100, Loss: 0.6934, Acc: 0.4980, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 15/100, Loss: 0.6933, Acc: 0.4925, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 16/100, Loss: 0.6933, Acc: 0.4954, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 17/100, Loss: 0.6933, Acc: 0.4974, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 18/100, Loss: 0.6934, Acc: 0.4962, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 19/100, Loss: 0.6934, Acc: 0.4950, Val Loss: 0.6933, Val Acc: 0.4993
Epoch 20/100, Loss: 0.6933, Acc: 0.4950, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 21/100, Loss: 0.6932, Acc: 0.5074, Val Loss: 0.6945, Val Acc: 0.4993
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4984, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 23/100, Loss: 0.6932, Acc: 0.4976, Val Loss: 0.6930, Val Acc: 0.5007
Epoch 24/100, Loss: 0.6933, Acc: 0.4961, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 25/100, Loss: 0.6933, Acc: 0.4962, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 26/100, Loss: 0.6933, Acc: 0.4961, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 27/100, Loss: 0.6932, Acc: 0.4947, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 28/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 29/100, Loss: 0.6932, Acc: 0.4978, Val Loss: 0.6935, Val Acc: 0.4993
Epoch 30/100, Loss: 0.6932, Acc: 0.5000, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 31/100, Loss: 0.6933, Acc: 0.4945, Val Loss: 0.6931, Val Acc: 0.5007
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 33/100, Loss: 0.6932, Acc: 0.4941, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 34/100, Loss: 0.6932, Acc: 0.4908, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 35/100, Loss: 0.6932, Acc: 0.4971, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 36/100, Loss: 0.6932, Acc: 0.5007, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 37/100, Loss: 0.6932, Acc: 0.4996, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 38/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 39/100, Loss: 0.6932, Acc: 0.4936, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 40/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 41/100, Loss: 0.6932, Acc: 0.4989, Val Loss: 0.6932, Val Acc: 0.4993
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 43/100, Loss: 0.6932, Acc: 0.4961, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 44/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 45/100, Loss: 0.6932, Acc: 0.4998, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 46/100, Loss: 0.6932, Acc: 0.4961, Val Loss: 0.6931, Val Acc: 0.5007
Epoch 47/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6932, Val Acc: 0.4993
Epoch 48/100, Loss: 0.6932, Acc: 0.4916, Val Loss: 0.6931, Val Acc: 0.4989
Epoch 49/100, Loss: 0.6931, Acc: 0.5004, Val Loss: 0.6934, Val Acc: 0.4462
Epoch 50/100, Loss: 0.6929, Acc: 0.5291, Val Loss: 0.6935, Val Acc: 0.4540
Epoch 51/100, Loss: 0.6929, Acc: 0.5283, Val Loss: 0.6935, Val Acc: 0.4514
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6929, Acc: 0.5311, Val Loss: 0.6934, Val Acc: 0.4577
Epoch 53/100, Loss: 0.6929, Acc: 0.5363, Val Loss: 0.6935, Val Acc: 0.4551
Epoch 54/100, Loss: 0.6929, Acc: 0.5217, Val Loss: 0.6934, Val Acc: 0.4577
Epoch 55/100, Loss: 0.6929, Acc: 0.5355, Val Loss: 0.6935, Val Acc: 0.4621
Epoch 56/100, Loss: 0.6929, Acc: 0.5348, Val Loss: 0.6934, Val Acc: 0.4647
Epoch 57/100, Loss: 0.6928, Acc: 0.5348, Val Loss: 0.6934, Val Acc: 0.4643
Epoch 58/100, Loss: 0.6926, Acc: 0.5375, Val Loss: 0.6929, Val Acc: 0.5059
Mejor modelo guardado con Val Loss: 0.6929
Epoch 59/100, Loss: 0.6915, Acc: 0.5594, Val Loss: 0.6927, Val Acc: 0.5158
Mejor modelo guardado con Val Loss: 0.6927
Epoch 60/100, Loss: 0.6912, Acc: 0.5575, Val Loss: 0.6926, Val Acc: 0.5306
Mejor modelo guardado con Val Loss: 0.6926
Epoch 61/100, Loss: 0.6911, Acc: 0.5654, Val Loss: 0.6924, Val Acc: 0.5331
Mejor modelo guardado con Val Loss: 0.6924
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6909, Acc: 0.5656, Val Loss: 0.6924, Val Acc: 0.5331
Mejor modelo guardado con Val Loss: 0.6924
Epoch 63/100, Loss: 0.6909, Acc: 0.5688, Val Loss: 0.6924, Val Acc: 0.5353
Mejor modelo guardado con Val Loss: 0.6924
Epoch 64/100, Loss: 0.6908, Acc: 0.5680, Val Loss: 0.6923, Val Acc: 0.5353
Mejor modelo guardado con Val Loss: 0.6923
Epoch 65/100, Loss: 0.6908, Acc: 0.5678, Val Loss: 0.6923, Val Acc: 0.5353
Mejor modelo guardado con Val Loss: 0.6923
Epoch 66/100, Loss: 0.6907, Acc: 0.5685, Val Loss: 0.6922, Val Acc: 0.5368
Mejor modelo guardado con Val Loss: 0.6922
Epoch 67/100, Loss: 0.6906, Acc: 0.5687, Val Loss: 0.6922, Val Acc: 0.5346
Mejor modelo guardado con Val Loss: 0.6922
Epoch 68/100, Loss: 0.6906, Acc: 0.5703, Val Loss: 0.6922, Val Acc: 0.5353
Mejor modelo guardado con Val Loss: 0.6922
Epoch 69/100, Loss: 0.6905, Acc: 0.5685, Val Loss: 0.6921, Val Acc: 0.5313
Mejor modelo guardado con Val Loss: 0.6921
Epoch 70/100, Loss: 0.6905, Acc: 0.5717, Val Loss: 0.6921, Val Acc: 0.5306
Mejor modelo guardado con Val Loss: 0.6921
Epoch 71/100, Loss: 0.6904, Acc: 0.5703, Val Loss: 0.6920, Val Acc: 0.5361
Mejor modelo guardado con Val Loss: 0.6920
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6904, Acc: 0.5710, Val Loss: 0.6920, Val Acc: 0.5317
Mejor modelo guardado con Val Loss: 0.6920
Epoch 73/100, Loss: 0.6903, Acc: 0.5709, Val Loss: 0.6920, Val Acc: 0.5335
Mejor modelo guardado con Val Loss: 0.6920
Epoch 74/100, Loss: 0.6903, Acc: 0.5719, Val Loss: 0.6920, Val Acc: 0.5339
Mejor modelo guardado con Val Loss: 0.6920
Epoch 75/100, Loss: 0.6903, Acc: 0.5711, Val Loss: 0.6920, Val Acc: 0.5350
Mejor modelo guardado con Val Loss: 0.6920
Epoch 76/100, Loss: 0.6902, Acc: 0.5723, Val Loss: 0.6919, Val Acc: 0.5372
Mejor modelo guardado con Val Loss: 0.6919
Epoch 77/100, Loss: 0.6902, Acc: 0.5697, Val Loss: 0.6919, Val Acc: 0.5328
Mejor modelo guardado con Val Loss: 0.6919
Epoch 78/100, Loss: 0.6902, Acc: 0.5718, Val Loss: 0.6919, Val Acc: 0.5339
Mejor modelo guardado con Val Loss: 0.6919
Epoch 79/100, Loss: 0.6901, Acc: 0.5713, Val Loss: 0.6919, Val Acc: 0.5309
Mejor modelo guardado con Val Loss: 0.6919
Epoch 80/100, Loss: 0.6901, Acc: 0.5713, Val Loss: 0.6919, Val Acc: 0.5331
Mejor modelo guardado con Val Loss: 0.6919
Epoch 81/100, Loss: 0.6901, Acc: 0.5719, Val Loss: 0.6918, Val Acc: 0.5357
Mejor modelo guardado con Val Loss: 0.6918
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6901, Acc: 0.5718, Val Loss: 0.6918, Val Acc: 0.5342
Mejor modelo guardado con Val Loss: 0.6918
Epoch 83/100, Loss: 0.6900, Acc: 0.5712, Val Loss: 0.6918, Val Acc: 0.5317
Mejor modelo guardado con Val Loss: 0.6918
Epoch 84/100, Loss: 0.6900, Acc: 0.5727, Val Loss: 0.6918, Val Acc: 0.5368
Mejor modelo guardado con Val Loss: 0.6918
Epoch 85/100, Loss: 0.6900, Acc: 0.5730, Val Loss: 0.6918, Val Acc: 0.5328
Mejor modelo guardado con Val Loss: 0.6918
Epoch 86/100, Loss: 0.6899, Acc: 0.5721, Val Loss: 0.6917, Val Acc: 0.5353
Mejor modelo guardado con Val Loss: 0.6917
Epoch 87/100, Loss: 0.6899, Acc: 0.5725, Val Loss: 0.6917, Val Acc: 0.5365
Mejor modelo guardado con Val Loss: 0.6917
Epoch 88/100, Loss: 0.6899, Acc: 0.5703, Val Loss: 0.6917, Val Acc: 0.5346
Mejor modelo guardado con Val Loss: 0.6917
Epoch 89/100, Loss: 0.6898, Acc: 0.5719, Val Loss: 0.6917, Val Acc: 0.5324
Mejor modelo guardado con Val Loss: 0.6917
Epoch 90/100, Loss: 0.6898, Acc: 0.5728, Val Loss: 0.6916, Val Acc: 0.5379
Mejor modelo guardado con Val Loss: 0.6916
Epoch 91/100, Loss: 0.6898, Acc: 0.5733, Val Loss: 0.6916, Val Acc: 0.5387
Mejor modelo guardado con Val Loss: 0.6916
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6897, Acc: 0.5728, Val Loss: 0.6916, Val Acc: 0.5390
Mejor modelo guardado con Val Loss: 0.6916
Epoch 93/100, Loss: 0.6897, Acc: 0.5722, Val Loss: 0.6915, Val Acc: 0.5342
Mejor modelo guardado con Val Loss: 0.6915
Epoch 94/100, Loss: 0.6897, Acc: 0.5729, Val Loss: 0.6915, Val Acc: 0.5401
Mejor modelo guardado con Val Loss: 0.6915
Epoch 95/100, Loss: 0.6896, Acc: 0.5717, Val Loss: 0.6915, Val Acc: 0.5342
Mejor modelo guardado con Val Loss: 0.6915
Epoch 96/100, Loss: 0.6896, Acc: 0.5731, Val Loss: 0.6914, Val Acc: 0.5398
Mejor modelo guardado con Val Loss: 0.6914
Epoch 97/100, Loss: 0.6896, Acc: 0.5730, Val Loss: 0.6914, Val Acc: 0.5394
Mejor modelo guardado con Val Loss: 0.6914
Epoch 98/100, Loss: 0.6895, Acc: 0.5706, Val Loss: 0.6914, Val Acc: 0.5387
Mejor modelo guardado con Val Loss: 0.6914
Epoch 99/100, Loss: 0.6895, Acc: 0.5736, Val Loss: 0.6913, Val Acc: 0.5405
Mejor modelo guardado con Val Loss: 0.6913
Epoch 100/100, Loss: 0.6883, Acc: 0.5790, Val Loss: 0.6894, Val Acc: 0.5361
Mejor modelo guardado con Val Loss: 0.6894

##############################
Resultados para principal:  096  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5 
 {'training': [0.6883216239635276, 0.5789812431040824, 0.5981222807419281, 0.48050036791758644, 0.5328980924206875], 'validate': [0.6893933803536171, 0.5360824742268041, 0.5556844547563805, 0.3532448377581121, 0.43192064923354373], 'test': [0.690951328586649, 0.5076560659599529, 0.5096463022508039, 0.3738207547169811, 0.4312925170068027]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  034  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  034  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  034  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6880, Acc: 0.5454, Val Loss: 0.6979, Val Acc: 0.4967
Mejor modelo guardado con Val Loss: 0.6979
Epoch 2/100, Loss: 0.6920, Acc: 0.5200, Val Loss: 0.6946, Val Acc: 0.4993
Mejor modelo guardado con Val Loss: 0.6946
Epoch 3/100, Loss: 0.6930, Acc: 0.5002, Val Loss: 0.6941, Val Acc: 0.4978
Mejor modelo guardado con Val Loss: 0.6941
Epoch 4/100, Loss: 0.6911, Acc: 0.5337, Val Loss: 0.7121, Val Acc: 0.2905
Epoch 5/100, Loss: 0.6893, Acc: 0.5343, Val Loss: 0.6943, Val Acc: 0.4816
Epoch 6/100, Loss: 0.6923, Acc: 0.5138, Val Loss: 0.6947, Val Acc: 0.5000
Epoch 7/100, Loss: 0.6905, Acc: 0.5293, Val Loss: 0.6939, Val Acc: 0.4974
Mejor modelo guardado con Val Loss: 0.6939
Epoch 8/100, Loss: 0.6891, Acc: 0.5337, Val Loss: 0.7076, Val Acc: 0.3899
Epoch 9/100, Loss: 0.6830, Acc: 0.5774, Val Loss: 0.7244, Val Acc: 0.3619
Epoch 10/100, Loss: 0.6839, Acc: 0.5698, Val Loss: 0.7166, Val Acc: 0.4249
Epoch 11/100, Loss: 0.6799, Acc: 0.5838, Val Loss: 0.7234, Val Acc: 0.3781
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6758, Acc: 0.5920, Val Loss: 0.7274, Val Acc: 0.3789
Epoch 13/100, Loss: 0.6747, Acc: 0.5933, Val Loss: 0.7405, Val Acc: 0.3461
Epoch 14/100, Loss: 0.6731, Acc: 0.5951, Val Loss: 0.7310, Val Acc: 0.3903
Epoch 15/100, Loss: 0.6726, Acc: 0.5979, Val Loss: 0.7177, Val Acc: 0.4525
Epoch 16/100, Loss: 0.6724, Acc: 0.5929, Val Loss: 0.7264, Val Acc: 0.4153
Epoch 17/100, Loss: 0.6711, Acc: 0.5972, Val Loss: 0.7162, Val Acc: 0.4477
Epoch 18/100, Loss: 0.6699, Acc: 0.5970, Val Loss: 0.7346, Val Acc: 0.3940
Epoch 19/100, Loss: 0.6706, Acc: 0.5952, Val Loss: 0.7466, Val Acc: 0.3752
Epoch 20/100, Loss: 0.6692, Acc: 0.5969, Val Loss: 0.7346, Val Acc: 0.4153
Epoch 21/100, Loss: 0.6687, Acc: 0.6021, Val Loss: 0.7393, Val Acc: 0.4138
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6677, Acc: 0.6009, Val Loss: 0.7579, Val Acc: 0.3638
Epoch 23/100, Loss: 0.6671, Acc: 0.6022, Val Loss: 0.7500, Val Acc: 0.3756
Epoch 24/100, Loss: 0.6667, Acc: 0.6016, Val Loss: 0.7472, Val Acc: 0.3936
Epoch 25/100, Loss: 0.6646, Acc: 0.6026, Val Loss: 0.7702, Val Acc: 0.3715
Epoch 26/100, Loss: 0.6619, Acc: 0.6048, Val Loss: 0.7625, Val Acc: 0.3881
Epoch 27/100, Loss: 0.6610, Acc: 0.6051, Val Loss: 0.7725, Val Acc: 0.3675
Epoch 28/100, Loss: 0.6613, Acc: 0.6041, Val Loss: 0.7641, Val Acc: 0.3756
Epoch 29/100, Loss: 0.6601, Acc: 0.6090, Val Loss: 0.7961, Val Acc: 0.3321
Epoch 30/100, Loss: 0.6596, Acc: 0.6056, Val Loss: 0.7671, Val Acc: 0.3881
Epoch 31/100, Loss: 0.6592, Acc: 0.6056, Val Loss: 0.7761, Val Acc: 0.3752
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6584, Acc: 0.6075, Val Loss: 0.7619, Val Acc: 0.4006
Epoch 33/100, Loss: 0.6585, Acc: 0.6096, Val Loss: 0.7777, Val Acc: 0.3693
Epoch 34/100, Loss: 0.6582, Acc: 0.6039, Val Loss: 0.7976, Val Acc: 0.3373
Epoch 35/100, Loss: 0.6578, Acc: 0.6090, Val Loss: 0.7673, Val Acc: 0.3895
Epoch 36/100, Loss: 0.6576, Acc: 0.6086, Val Loss: 0.7830, Val Acc: 0.3597
Epoch 37/100, Loss: 0.6577, Acc: 0.6067, Val Loss: 0.7759, Val Acc: 0.3756
Epoch 38/100, Loss: 0.6575, Acc: 0.6069, Val Loss: 0.7811, Val Acc: 0.3649
Epoch 39/100, Loss: 0.6573, Acc: 0.6076, Val Loss: 0.7772, Val Acc: 0.3722
Epoch 40/100, Loss: 0.6568, Acc: 0.6096, Val Loss: 0.7811, Val Acc: 0.3630
Epoch 41/100, Loss: 0.6569, Acc: 0.6056, Val Loss: 0.7793, Val Acc: 0.3682
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6564, Acc: 0.6089, Val Loss: 0.7784, Val Acc: 0.3737
Epoch 43/100, Loss: 0.6564, Acc: 0.6077, Val Loss: 0.7718, Val Acc: 0.3873
Epoch 44/100, Loss: 0.6562, Acc: 0.6085, Val Loss: 0.7843, Val Acc: 0.3616
Epoch 45/100, Loss: 0.6562, Acc: 0.6091, Val Loss: 0.7844, Val Acc: 0.3656
Epoch 46/100, Loss: 0.6563, Acc: 0.6071, Val Loss: 0.7818, Val Acc: 0.3675
Epoch 47/100, Loss: 0.6561, Acc: 0.6078, Val Loss: 0.7833, Val Acc: 0.3656
Epoch 48/100, Loss: 0.6561, Acc: 0.6073, Val Loss: 0.7780, Val Acc: 0.3774
Epoch 49/100, Loss: 0.6558, Acc: 0.6090, Val Loss: 0.7776, Val Acc: 0.3774
Epoch 50/100, Loss: 0.6559, Acc: 0.6088, Val Loss: 0.7799, Val Acc: 0.3722
Epoch 51/100, Loss: 0.6556, Acc: 0.6095, Val Loss: 0.7890, Val Acc: 0.3594
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6554, Acc: 0.6096, Val Loss: 0.7710, Val Acc: 0.3932
Epoch 53/100, Loss: 0.6554, Acc: 0.6075, Val Loss: 0.7813, Val Acc: 0.3711
Epoch 54/100, Loss: 0.6552, Acc: 0.6090, Val Loss: 0.7888, Val Acc: 0.3608
Epoch 55/100, Loss: 0.6552, Acc: 0.6085, Val Loss: 0.7841, Val Acc: 0.3737
Epoch 56/100, Loss: 0.6549, Acc: 0.6083, Val Loss: 0.7848, Val Acc: 0.3730
Epoch 57/100, Loss: 0.6548, Acc: 0.6093, Val Loss: 0.7870, Val Acc: 0.3704
Epoch 58/100, Loss: 0.6548, Acc: 0.6079, Val Loss: 0.7828, Val Acc: 0.3744
Epoch 59/100, Loss: 0.6546, Acc: 0.6085, Val Loss: 0.7837, Val Acc: 0.3733
Epoch 60/100, Loss: 0.6546, Acc: 0.6095, Val Loss: 0.7799, Val Acc: 0.3785
Epoch 61/100, Loss: 0.6547, Acc: 0.6090, Val Loss: 0.7818, Val Acc: 0.3763
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6544, Acc: 0.6102, Val Loss: 0.7809, Val Acc: 0.3774
Epoch 63/100, Loss: 0.6543, Acc: 0.6095, Val Loss: 0.7819, Val Acc: 0.3752
Epoch 64/100, Loss: 0.6543, Acc: 0.6091, Val Loss: 0.7804, Val Acc: 0.3774
Epoch 65/100, Loss: 0.6542, Acc: 0.6093, Val Loss: 0.7835, Val Acc: 0.3715
Epoch 66/100, Loss: 0.6543, Acc: 0.6081, Val Loss: 0.7814, Val Acc: 0.3752
Epoch 67/100, Loss: 0.6542, Acc: 0.6106, Val Loss: 0.7816, Val Acc: 0.3756
Epoch 68/100, Loss: 0.6542, Acc: 0.6095, Val Loss: 0.7810, Val Acc: 0.3752
Epoch 69/100, Loss: 0.6541, Acc: 0.6090, Val Loss: 0.7829, Val Acc: 0.3741
Epoch 70/100, Loss: 0.6541, Acc: 0.6115, Val Loss: 0.7835, Val Acc: 0.3722
Epoch 71/100, Loss: 0.6540, Acc: 0.6106, Val Loss: 0.7786, Val Acc: 0.3800
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6540, Acc: 0.6097, Val Loss: 0.7787, Val Acc: 0.3789
Epoch 73/100, Loss: 0.6540, Acc: 0.6097, Val Loss: 0.7810, Val Acc: 0.3756
Epoch 74/100, Loss: 0.6540, Acc: 0.6101, Val Loss: 0.7804, Val Acc: 0.3767
Epoch 75/100, Loss: 0.6539, Acc: 0.6104, Val Loss: 0.7823, Val Acc: 0.3748
Epoch 76/100, Loss: 0.6539, Acc: 0.6101, Val Loss: 0.7786, Val Acc: 0.3789
Epoch 77/100, Loss: 0.6539, Acc: 0.6106, Val Loss: 0.7801, Val Acc: 0.3767
Epoch 78/100, Loss: 0.6539, Acc: 0.6090, Val Loss: 0.7819, Val Acc: 0.3756
Epoch 79/100, Loss: 0.6538, Acc: 0.6095, Val Loss: 0.7826, Val Acc: 0.3730
Epoch 80/100, Loss: 0.6539, Acc: 0.6099, Val Loss: 0.7808, Val Acc: 0.3752
Epoch 81/100, Loss: 0.6538, Acc: 0.6114, Val Loss: 0.7802, Val Acc: 0.3763
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6538, Acc: 0.6110, Val Loss: 0.7835, Val Acc: 0.3708
Epoch 83/100, Loss: 0.6538, Acc: 0.6108, Val Loss: 0.7810, Val Acc: 0.3767
Epoch 84/100, Loss: 0.6538, Acc: 0.6101, Val Loss: 0.7810, Val Acc: 0.3759
Epoch 85/100, Loss: 0.6537, Acc: 0.6100, Val Loss: 0.7848, Val Acc: 0.3744
Epoch 86/100, Loss: 0.6535, Acc: 0.6102, Val Loss: 0.7844, Val Acc: 0.3781
Epoch 87/100, Loss: 0.6535, Acc: 0.6102, Val Loss: 0.7886, Val Acc: 0.3730
Epoch 88/100, Loss: 0.6535, Acc: 0.6101, Val Loss: 0.7876, Val Acc: 0.3744
Epoch 89/100, Loss: 0.6534, Acc: 0.6105, Val Loss: 0.7866, Val Acc: 0.3752
Epoch 90/100, Loss: 0.6534, Acc: 0.6091, Val Loss: 0.7877, Val Acc: 0.3748
Epoch 91/100, Loss: 0.6533, Acc: 0.6090, Val Loss: 0.7889, Val Acc: 0.3730
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6534, Acc: 0.6102, Val Loss: 0.7860, Val Acc: 0.3748
Epoch 93/100, Loss: 0.6533, Acc: 0.6109, Val Loss: 0.7872, Val Acc: 0.3737
Epoch 94/100, Loss: 0.6533, Acc: 0.6099, Val Loss: 0.7854, Val Acc: 0.3774
Epoch 95/100, Loss: 0.6533, Acc: 0.6100, Val Loss: 0.7867, Val Acc: 0.3752
Epoch 96/100, Loss: 0.6532, Acc: 0.6096, Val Loss: 0.7888, Val Acc: 0.3741
Epoch 97/100, Loss: 0.6530, Acc: 0.6102, Val Loss: 0.7894, Val Acc: 0.3752
Epoch 98/100, Loss: 0.6530, Acc: 0.6091, Val Loss: 0.7907, Val Acc: 0.3741
Epoch 99/100, Loss: 0.6529, Acc: 0.6097, Val Loss: 0.7914, Val Acc: 0.3730
Epoch 100/100, Loss: 0.6529, Acc: 0.6094, Val Loss: 0.7878, Val Acc: 0.3781

##############################
Resultados para principal:  034  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5 
 {'training': [0.6528732072522246, 0.6094152261860978, 0.5820441988950277, 0.7752023546725534, 0.6648785105711581], 'validate': [0.7877859244512957, 0.37812960235640647, 0.41305483028720624, 0.5833333333333334, 0.48364414552124735], 'test': [0.6986576009679724, 0.4552414605418139, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  014  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  014  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  014  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6437, Acc: 0.6477, Val Loss: 0.6558, Val Acc: 0.6141
Mejor modelo guardado con Val Loss: 0.6558
Epoch 2/100, Loss: 0.6044, Acc: 0.6821, Val Loss: 0.6829, Val Acc: 0.5593
Epoch 3/100, Loss: 0.5900, Acc: 0.6834, Val Loss: 0.6996, Val Acc: 0.5608
Epoch 4/100, Loss: 0.5818, Acc: 0.6943, Val Loss: 0.6760, Val Acc: 0.5733
Epoch 5/100, Loss: 0.5811, Acc: 0.6935, Val Loss: 0.6383, Val Acc: 0.6616
Mejor modelo guardado con Val Loss: 0.6383
Epoch 6/100, Loss: 0.5726, Acc: 0.6992, Val Loss: 0.6644, Val Acc: 0.6108
Epoch 7/100, Loss: 0.5770, Acc: 0.6995, Val Loss: 0.6370, Val Acc: 0.6598
Mejor modelo guardado con Val Loss: 0.6370
Epoch 8/100, Loss: 0.5731, Acc: 0.6983, Val Loss: 0.6595, Val Acc: 0.6373
Epoch 9/100, Loss: 0.5787, Acc: 0.6969, Val Loss: 0.6718, Val Acc: 0.6123
Epoch 10/100, Loss: 0.5715, Acc: 0.7043, Val Loss: 0.6530, Val Acc: 0.6359
Epoch 11/100, Loss: 0.5701, Acc: 0.7050, Val Loss: 0.6588, Val Acc: 0.6208
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5625, Acc: 0.7054, Val Loss: 0.6619, Val Acc: 0.6340
Epoch 13/100, Loss: 0.5564, Acc: 0.7094, Val Loss: 0.6596, Val Acc: 0.6189
Epoch 14/100, Loss: 0.5563, Acc: 0.7103, Val Loss: 0.6710, Val Acc: 0.6035
Epoch 15/100, Loss: 0.5550, Acc: 0.7083, Val Loss: 0.6653, Val Acc: 0.6189
Epoch 16/100, Loss: 0.5513, Acc: 0.7114, Val Loss: 0.6500, Val Acc: 0.6517
Epoch 17/100, Loss: 0.5535, Acc: 0.7113, Val Loss: 0.6529, Val Acc: 0.6429
Epoch 18/100, Loss: 0.5599, Acc: 0.7051, Val Loss: 0.6673, Val Acc: 0.6355
Epoch 19/100, Loss: 0.5567, Acc: 0.7091, Val Loss: 0.6558, Val Acc: 0.6436
Epoch 20/100, Loss: 0.5604, Acc: 0.7072, Val Loss: 0.6612, Val Acc: 0.6406
Epoch 21/100, Loss: 0.5534, Acc: 0.7064, Val Loss: 0.6748, Val Acc: 0.6248
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5545, Acc: 0.7112, Val Loss: 0.6391, Val Acc: 0.6432
Epoch 23/100, Loss: 0.5480, Acc: 0.7110, Val Loss: 0.6505, Val Acc: 0.6451
Epoch 24/100, Loss: 0.5454, Acc: 0.7164, Val Loss: 0.6653, Val Acc: 0.6123
Epoch 25/100, Loss: 0.5453, Acc: 0.7148, Val Loss: 0.6629, Val Acc: 0.6248
Epoch 26/100, Loss: 0.5438, Acc: 0.7196, Val Loss: 0.6685, Val Acc: 0.6219
Epoch 27/100, Loss: 0.5447, Acc: 0.7155, Val Loss: 0.6737, Val Acc: 0.6226
Epoch 28/100, Loss: 0.5418, Acc: 0.7182, Val Loss: 0.6939, Val Acc: 0.5932
Epoch 29/100, Loss: 0.5420, Acc: 0.7169, Val Loss: 0.6550, Val Acc: 0.6395
Epoch 30/100, Loss: 0.5445, Acc: 0.7143, Val Loss: 0.6795, Val Acc: 0.6270
Epoch 31/100, Loss: 0.5396, Acc: 0.7175, Val Loss: 0.6914, Val Acc: 0.6171
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5386, Acc: 0.7196, Val Loss: 0.6623, Val Acc: 0.6384
Epoch 33/100, Loss: 0.5380, Acc: 0.7214, Val Loss: 0.6704, Val Acc: 0.6204
Epoch 34/100, Loss: 0.5381, Acc: 0.7198, Val Loss: 0.6605, Val Acc: 0.6307
Epoch 35/100, Loss: 0.5369, Acc: 0.7182, Val Loss: 0.6585, Val Acc: 0.6355
Epoch 36/100, Loss: 0.5373, Acc: 0.7204, Val Loss: 0.6958, Val Acc: 0.6035
Epoch 37/100, Loss: 0.5362, Acc: 0.7209, Val Loss: 0.6668, Val Acc: 0.6156
Epoch 38/100, Loss: 0.5374, Acc: 0.7204, Val Loss: 0.6700, Val Acc: 0.6160
Epoch 39/100, Loss: 0.5352, Acc: 0.7214, Val Loss: 0.6675, Val Acc: 0.6211
Epoch 40/100, Loss: 0.5353, Acc: 0.7175, Val Loss: 0.6555, Val Acc: 0.6259
Epoch 41/100, Loss: 0.5344, Acc: 0.7224, Val Loss: 0.6682, Val Acc: 0.6071
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5339, Acc: 0.7225, Val Loss: 0.6692, Val Acc: 0.6208
Epoch 43/100, Loss: 0.5333, Acc: 0.7220, Val Loss: 0.6809, Val Acc: 0.6119
Epoch 44/100, Loss: 0.5335, Acc: 0.7206, Val Loss: 0.6779, Val Acc: 0.6167
Epoch 45/100, Loss: 0.5332, Acc: 0.7223, Val Loss: 0.6601, Val Acc: 0.6303
Epoch 46/100, Loss: 0.5332, Acc: 0.7223, Val Loss: 0.6740, Val Acc: 0.6267
Epoch 47/100, Loss: 0.5334, Acc: 0.7211, Val Loss: 0.6639, Val Acc: 0.6182
Epoch 48/100, Loss: 0.5329, Acc: 0.7238, Val Loss: 0.6666, Val Acc: 0.6193
Epoch 49/100, Loss: 0.5327, Acc: 0.7223, Val Loss: 0.6758, Val Acc: 0.6141
Epoch 50/100, Loss: 0.5326, Acc: 0.7221, Val Loss: 0.6724, Val Acc: 0.6119
Epoch 51/100, Loss: 0.5323, Acc: 0.7239, Val Loss: 0.6737, Val Acc: 0.6296
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5320, Acc: 0.7214, Val Loss: 0.6768, Val Acc: 0.6112
Epoch 53/100, Loss: 0.5313, Acc: 0.7235, Val Loss: 0.6871, Val Acc: 0.6053
Epoch 54/100, Loss: 0.5315, Acc: 0.7235, Val Loss: 0.6720, Val Acc: 0.6211
Epoch 55/100, Loss: 0.5312, Acc: 0.7233, Val Loss: 0.6822, Val Acc: 0.6094
Epoch 56/100, Loss: 0.5312, Acc: 0.7226, Val Loss: 0.6757, Val Acc: 0.6171
Epoch 57/100, Loss: 0.5307, Acc: 0.7218, Val Loss: 0.6629, Val Acc: 0.6175
Epoch 58/100, Loss: 0.5312, Acc: 0.7229, Val Loss: 0.6743, Val Acc: 0.6145
Epoch 59/100, Loss: 0.5307, Acc: 0.7232, Val Loss: 0.6762, Val Acc: 0.6112
Epoch 60/100, Loss: 0.5307, Acc: 0.7227, Val Loss: 0.6776, Val Acc: 0.6101
Epoch 61/100, Loss: 0.5306, Acc: 0.7228, Val Loss: 0.6736, Val Acc: 0.6090
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5306, Acc: 0.7245, Val Loss: 0.6770, Val Acc: 0.6123
Epoch 63/100, Loss: 0.5304, Acc: 0.7248, Val Loss: 0.6691, Val Acc: 0.6233
Epoch 64/100, Loss: 0.5305, Acc: 0.7220, Val Loss: 0.6772, Val Acc: 0.6112
Epoch 65/100, Loss: 0.5300, Acc: 0.7235, Val Loss: 0.6691, Val Acc: 0.6211
Epoch 66/100, Loss: 0.5301, Acc: 0.7236, Val Loss: 0.6823, Val Acc: 0.6097
Epoch 67/100, Loss: 0.5303, Acc: 0.7243, Val Loss: 0.6746, Val Acc: 0.6152
Epoch 68/100, Loss: 0.5301, Acc: 0.7239, Val Loss: 0.6754, Val Acc: 0.6160
Epoch 69/100, Loss: 0.5302, Acc: 0.7224, Val Loss: 0.6744, Val Acc: 0.6167
Epoch 70/100, Loss: 0.5300, Acc: 0.7237, Val Loss: 0.6773, Val Acc: 0.6123
Epoch 71/100, Loss: 0.5300, Acc: 0.7241, Val Loss: 0.6762, Val Acc: 0.6163
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5298, Acc: 0.7222, Val Loss: 0.6772, Val Acc: 0.6130
Epoch 73/100, Loss: 0.5298, Acc: 0.7226, Val Loss: 0.6785, Val Acc: 0.6097
Epoch 74/100, Loss: 0.5298, Acc: 0.7246, Val Loss: 0.6785, Val Acc: 0.6108
Epoch 75/100, Loss: 0.5299, Acc: 0.7245, Val Loss: 0.6783, Val Acc: 0.6101
Epoch 76/100, Loss: 0.5298, Acc: 0.7236, Val Loss: 0.6780, Val Acc: 0.6101
Epoch 77/100, Loss: 0.5297, Acc: 0.7240, Val Loss: 0.6788, Val Acc: 0.6116
Epoch 78/100, Loss: 0.5298, Acc: 0.7243, Val Loss: 0.6768, Val Acc: 0.6138
Epoch 79/100, Loss: 0.5297, Acc: 0.7245, Val Loss: 0.6754, Val Acc: 0.6130
Epoch 80/100, Loss: 0.5297, Acc: 0.7248, Val Loss: 0.6737, Val Acc: 0.6167
Epoch 81/100, Loss: 0.5297, Acc: 0.7240, Val Loss: 0.6752, Val Acc: 0.6156
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5295, Acc: 0.7232, Val Loss: 0.6777, Val Acc: 0.6123
Epoch 83/100, Loss: 0.5295, Acc: 0.7250, Val Loss: 0.6736, Val Acc: 0.6163
Epoch 84/100, Loss: 0.5297, Acc: 0.7234, Val Loss: 0.6761, Val Acc: 0.6149
Epoch 85/100, Loss: 0.5295, Acc: 0.7242, Val Loss: 0.6782, Val Acc: 0.6127
Epoch 86/100, Loss: 0.5295, Acc: 0.7226, Val Loss: 0.6814, Val Acc: 0.6064
Epoch 87/100, Loss: 0.5295, Acc: 0.7253, Val Loss: 0.6763, Val Acc: 0.6130
Epoch 88/100, Loss: 0.5295, Acc: 0.7235, Val Loss: 0.6762, Val Acc: 0.6116
Epoch 89/100, Loss: 0.5295, Acc: 0.7247, Val Loss: 0.6810, Val Acc: 0.6082
Epoch 90/100, Loss: 0.5295, Acc: 0.7243, Val Loss: 0.6769, Val Acc: 0.6134
Epoch 91/100, Loss: 0.5294, Acc: 0.7235, Val Loss: 0.6791, Val Acc: 0.6119
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5294, Acc: 0.7242, Val Loss: 0.6786, Val Acc: 0.6112
Epoch 93/100, Loss: 0.5293, Acc: 0.7248, Val Loss: 0.6740, Val Acc: 0.6160
Epoch 94/100, Loss: 0.5293, Acc: 0.7226, Val Loss: 0.6769, Val Acc: 0.6138
Epoch 95/100, Loss: 0.5293, Acc: 0.7237, Val Loss: 0.6758, Val Acc: 0.6138
Epoch 96/100, Loss: 0.5292, Acc: 0.7243, Val Loss: 0.6763, Val Acc: 0.6119
Epoch 97/100, Loss: 0.5291, Acc: 0.7245, Val Loss: 0.6769, Val Acc: 0.6116
Epoch 98/100, Loss: 0.5289, Acc: 0.7242, Val Loss: 0.6801, Val Acc: 0.6134
Epoch 99/100, Loss: 0.5289, Acc: 0.7254, Val Loss: 0.6783, Val Acc: 0.6138
Epoch 100/100, Loss: 0.5288, Acc: 0.7231, Val Loss: 0.6824, Val Acc: 0.6079

##############################
Resultados para principal:  014  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5 
 {'training': [0.5287643973333689, 0.7230599485104818, 0.7388648009459993, 0.6896615158204562, 0.7134157944814462], 'validate': [0.6824196124839228, 0.6078792341678939, 0.6742514970059881, 0.41519174041297935, 0.5139205842081241], 'test': [0.7741706371307373, 0.5332744405182568, 0.5217732444095724, 0.7841981132075472, 0.6266195524146054]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  092  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  092  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  092  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6767, Acc: 0.5820, Val Loss: 0.6864, Val Acc: 0.5534
Mejor modelo guardado con Val Loss: 0.6864
Epoch 2/100, Loss: 0.6720, Acc: 0.5905, Val Loss: 0.6854, Val Acc: 0.5574
Mejor modelo guardado con Val Loss: 0.6854
Epoch 3/100, Loss: 0.6599, Acc: 0.6056, Val Loss: 0.6923, Val Acc: 0.5280
Epoch 4/100, Loss: 0.6608, Acc: 0.6042, Val Loss: 0.6953, Val Acc: 0.5342
Epoch 5/100, Loss: 0.6586, Acc: 0.6151, Val Loss: 0.6944, Val Acc: 0.5136
Epoch 6/100, Loss: 0.6559, Acc: 0.6168, Val Loss: 0.7020, Val Acc: 0.5243
Epoch 7/100, Loss: 0.6555, Acc: 0.6068, Val Loss: 0.6928, Val Acc: 0.5044
Epoch 8/100, Loss: 0.6605, Acc: 0.6003, Val Loss: 0.6960, Val Acc: 0.5195
Epoch 9/100, Loss: 0.6612, Acc: 0.6096, Val Loss: 0.6961, Val Acc: 0.5317
Epoch 10/100, Loss: 0.6544, Acc: 0.6222, Val Loss: 0.7034, Val Acc: 0.5387
Epoch 11/100, Loss: 0.6493, Acc: 0.6276, Val Loss: 0.7076, Val Acc: 0.5265
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6465, Acc: 0.6262, Val Loss: 0.7102, Val Acc: 0.5302
Epoch 13/100, Loss: 0.6445, Acc: 0.6247, Val Loss: 0.7163, Val Acc: 0.5210
Epoch 14/100, Loss: 0.6450, Acc: 0.6245, Val Loss: 0.7153, Val Acc: 0.5265
Epoch 15/100, Loss: 0.6419, Acc: 0.6279, Val Loss: 0.7087, Val Acc: 0.5099
Epoch 16/100, Loss: 0.6402, Acc: 0.6272, Val Loss: 0.7237, Val Acc: 0.5228
Epoch 17/100, Loss: 0.6414, Acc: 0.6277, Val Loss: 0.7104, Val Acc: 0.5217
Epoch 18/100, Loss: 0.6438, Acc: 0.6284, Val Loss: 0.7191, Val Acc: 0.5265
Epoch 19/100, Loss: 0.6426, Acc: 0.6270, Val Loss: 0.7093, Val Acc: 0.5173
Epoch 20/100, Loss: 0.6405, Acc: 0.6302, Val Loss: 0.7136, Val Acc: 0.5133
Epoch 21/100, Loss: 0.6403, Acc: 0.6263, Val Loss: 0.7216, Val Acc: 0.5088
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6394, Acc: 0.6354, Val Loss: 0.7163, Val Acc: 0.5099
Epoch 23/100, Loss: 0.6386, Acc: 0.6328, Val Loss: 0.7182, Val Acc: 0.5074
Epoch 24/100, Loss: 0.6373, Acc: 0.6324, Val Loss: 0.7137, Val Acc: 0.5199
Epoch 25/100, Loss: 0.6373, Acc: 0.6318, Val Loss: 0.7173, Val Acc: 0.5059
Epoch 26/100, Loss: 0.6380, Acc: 0.6339, Val Loss: 0.7282, Val Acc: 0.5184
Epoch 27/100, Loss: 0.6385, Acc: 0.6307, Val Loss: 0.7158, Val Acc: 0.5037
Epoch 28/100, Loss: 0.6372, Acc: 0.6322, Val Loss: 0.7168, Val Acc: 0.5125
Epoch 29/100, Loss: 0.6377, Acc: 0.6335, Val Loss: 0.7170, Val Acc: 0.5107
Epoch 30/100, Loss: 0.6369, Acc: 0.6343, Val Loss: 0.7260, Val Acc: 0.5125
Epoch 31/100, Loss: 0.6356, Acc: 0.6344, Val Loss: 0.7094, Val Acc: 0.5199
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6348, Acc: 0.6358, Val Loss: 0.7107, Val Acc: 0.5320
Epoch 33/100, Loss: 0.6247, Acc: 0.6478, Val Loss: 0.7231, Val Acc: 0.5099
Epoch 34/100, Loss: 0.6238, Acc: 0.6517, Val Loss: 0.7328, Val Acc: 0.5074
Epoch 35/100, Loss: 0.6243, Acc: 0.6535, Val Loss: 0.7239, Val Acc: 0.5166
Epoch 36/100, Loss: 0.6240, Acc: 0.6504, Val Loss: 0.7272, Val Acc: 0.5107
Epoch 37/100, Loss: 0.6238, Acc: 0.6506, Val Loss: 0.7264, Val Acc: 0.5074
Epoch 38/100, Loss: 0.6235, Acc: 0.6532, Val Loss: 0.7270, Val Acc: 0.5129
Epoch 39/100, Loss: 0.6232, Acc: 0.6513, Val Loss: 0.7255, Val Acc: 0.5066
Epoch 40/100, Loss: 0.6227, Acc: 0.6524, Val Loss: 0.7280, Val Acc: 0.5096
Epoch 41/100, Loss: 0.6223, Acc: 0.6506, Val Loss: 0.7486, Val Acc: 0.5029
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6215, Acc: 0.6535, Val Loss: 0.7305, Val Acc: 0.5107
Epoch 43/100, Loss: 0.6212, Acc: 0.6534, Val Loss: 0.7362, Val Acc: 0.5085
Epoch 44/100, Loss: 0.6206, Acc: 0.6546, Val Loss: 0.7342, Val Acc: 0.5074
Epoch 45/100, Loss: 0.6208, Acc: 0.6563, Val Loss: 0.7323, Val Acc: 0.5074
Epoch 46/100, Loss: 0.6205, Acc: 0.6566, Val Loss: 0.7362, Val Acc: 0.5063
Epoch 47/100, Loss: 0.6200, Acc: 0.6549, Val Loss: 0.7312, Val Acc: 0.5037
Epoch 48/100, Loss: 0.6202, Acc: 0.6552, Val Loss: 0.7361, Val Acc: 0.5044
Epoch 49/100, Loss: 0.6204, Acc: 0.6566, Val Loss: 0.7323, Val Acc: 0.5026
Epoch 50/100, Loss: 0.6201, Acc: 0.6544, Val Loss: 0.7325, Val Acc: 0.5052
Epoch 51/100, Loss: 0.6198, Acc: 0.6560, Val Loss: 0.7346, Val Acc: 0.5022
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6192, Acc: 0.6564, Val Loss: 0.7340, Val Acc: 0.5037
Epoch 53/100, Loss: 0.6193, Acc: 0.6573, Val Loss: 0.7346, Val Acc: 0.5022
Epoch 54/100, Loss: 0.6195, Acc: 0.6552, Val Loss: 0.7326, Val Acc: 0.5026
Epoch 55/100, Loss: 0.6192, Acc: 0.6565, Val Loss: 0.7327, Val Acc: 0.5011
Epoch 56/100, Loss: 0.6192, Acc: 0.6570, Val Loss: 0.7333, Val Acc: 0.5015
Epoch 57/100, Loss: 0.6191, Acc: 0.6567, Val Loss: 0.7322, Val Acc: 0.4996
Epoch 58/100, Loss: 0.6191, Acc: 0.6571, Val Loss: 0.7331, Val Acc: 0.5004
Epoch 59/100, Loss: 0.6192, Acc: 0.6559, Val Loss: 0.7321, Val Acc: 0.5000
Epoch 60/100, Loss: 0.6189, Acc: 0.6580, Val Loss: 0.7325, Val Acc: 0.5004
Epoch 61/100, Loss: 0.6188, Acc: 0.6576, Val Loss: 0.7299, Val Acc: 0.4993
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6186, Acc: 0.6580, Val Loss: 0.7320, Val Acc: 0.4993
Epoch 63/100, Loss: 0.6183, Acc: 0.6574, Val Loss: 0.7330, Val Acc: 0.5007
Epoch 64/100, Loss: 0.6183, Acc: 0.6570, Val Loss: 0.7321, Val Acc: 0.5011
Epoch 65/100, Loss: 0.6183, Acc: 0.6581, Val Loss: 0.7319, Val Acc: 0.5015
Epoch 66/100, Loss: 0.6181, Acc: 0.6583, Val Loss: 0.7319, Val Acc: 0.4996
Epoch 67/100, Loss: 0.6181, Acc: 0.6579, Val Loss: 0.7321, Val Acc: 0.4996
Epoch 68/100, Loss: 0.6180, Acc: 0.6574, Val Loss: 0.7320, Val Acc: 0.5000
Epoch 69/100, Loss: 0.6181, Acc: 0.6592, Val Loss: 0.7314, Val Acc: 0.5004
Epoch 70/100, Loss: 0.6179, Acc: 0.6569, Val Loss: 0.7309, Val Acc: 0.4993
Epoch 71/100, Loss: 0.6180, Acc: 0.6569, Val Loss: 0.7318, Val Acc: 0.5007
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6179, Acc: 0.6565, Val Loss: 0.7317, Val Acc: 0.5007
Epoch 73/100, Loss: 0.6179, Acc: 0.6572, Val Loss: 0.7315, Val Acc: 0.5007
Epoch 74/100, Loss: 0.6178, Acc: 0.6581, Val Loss: 0.7318, Val Acc: 0.5004
Epoch 75/100, Loss: 0.6178, Acc: 0.6572, Val Loss: 0.7317, Val Acc: 0.5011
Epoch 76/100, Loss: 0.6177, Acc: 0.6588, Val Loss: 0.7319, Val Acc: 0.5000
Epoch 77/100, Loss: 0.6178, Acc: 0.6569, Val Loss: 0.7314, Val Acc: 0.5000
Epoch 78/100, Loss: 0.6177, Acc: 0.6567, Val Loss: 0.7319, Val Acc: 0.5007
Epoch 79/100, Loss: 0.6178, Acc: 0.6564, Val Loss: 0.7318, Val Acc: 0.5007
Epoch 80/100, Loss: 0.6177, Acc: 0.6571, Val Loss: 0.7317, Val Acc: 0.5007
Epoch 81/100, Loss: 0.6177, Acc: 0.6584, Val Loss: 0.7316, Val Acc: 0.5004
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6176, Acc: 0.6577, Val Loss: 0.7318, Val Acc: 0.5004
Epoch 83/100, Loss: 0.6176, Acc: 0.6575, Val Loss: 0.7320, Val Acc: 0.5011
Epoch 84/100, Loss: 0.6176, Acc: 0.6578, Val Loss: 0.7324, Val Acc: 0.5004
Epoch 85/100, Loss: 0.6176, Acc: 0.6576, Val Loss: 0.7325, Val Acc: 0.5004
Epoch 86/100, Loss: 0.6175, Acc: 0.6573, Val Loss: 0.7341, Val Acc: 0.5000
Epoch 87/100, Loss: 0.6171, Acc: 0.6586, Val Loss: 0.7354, Val Acc: 0.5000
Epoch 88/100, Loss: 0.6169, Acc: 0.6576, Val Loss: 0.7348, Val Acc: 0.5000
Epoch 89/100, Loss: 0.6168, Acc: 0.6585, Val Loss: 0.7355, Val Acc: 0.4982
Epoch 90/100, Loss: 0.6168, Acc: 0.6584, Val Loss: 0.7347, Val Acc: 0.4993
Epoch 91/100, Loss: 0.6168, Acc: 0.6577, Val Loss: 0.7342, Val Acc: 0.5004
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6168, Acc: 0.6570, Val Loss: 0.7343, Val Acc: 0.4996
Epoch 93/100, Loss: 0.6166, Acc: 0.6579, Val Loss: 0.7341, Val Acc: 0.4982
Epoch 94/100, Loss: 0.6167, Acc: 0.6572, Val Loss: 0.7338, Val Acc: 0.5004
Epoch 95/100, Loss: 0.6166, Acc: 0.6583, Val Loss: 0.7348, Val Acc: 0.4996
Epoch 96/100, Loss: 0.6160, Acc: 0.6572, Val Loss: 0.7350, Val Acc: 0.5000
Epoch 97/100, Loss: 0.6159, Acc: 0.6572, Val Loss: 0.7358, Val Acc: 0.5007
Epoch 98/100, Loss: 0.6158, Acc: 0.6566, Val Loss: 0.7347, Val Acc: 0.5004
Epoch 99/100, Loss: 0.6158, Acc: 0.6586, Val Loss: 0.7355, Val Acc: 0.5022
Epoch 100/100, Loss: 0.6158, Acc: 0.6566, Val Loss: 0.7362, Val Acc: 0.5011

##############################
Resultados para principal:  092  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  5 
 {'training': [0.6158064924079121, 0.6565833026848106, 0.6863905325443787, 0.5761589403973509, 0.6264626462646264], 'validate': [0.7361889093421227, 0.5011045655375552, 0.5005302226935313, 0.3480825958702065, 0.41061331013484126], 'test': [0.7400926594380979, 0.42638398115429915, 0.44568965517241377, 0.6096698113207547, 0.5149402390438247]}

##############################
Resultados para window:  5 
 {'031:051:096:034:014:092': {'training': [0.6675575805438183, 0.6027951452739978, 0.6111111111111112, 0.5645695364238411, 0.5869191049913941], 'validate': [0.7165400316548902, 0.49263622974963184, 0.4930817610062893, 0.5781710914454278, 0.5322471147318398], 'test': [0.6936160270814542, 0.5026501766784452, 0.5021432945499081, 0.4834905660377358, 0.49264043256233103]}, '051:031:096:034:014:092': {'training': [0.5527157937835884, 0.7329900698786318, 0.7479435957696827, 0.7025386313465783, 0.7245304496300512], 'validate': [0.598920768083528, 0.6991899852724595, 0.7185725871857259, 0.6533923303834809, 0.6844341444573194], 'test': [0.678119832166919, 0.6351590106007067, 0.6223888591322978, 0.6851415094339622, 0.6522593320235757]}, '096:031:051:034:014:092': {'training': [0.6883216239635276, 0.5789812431040824, 0.5981222807419281, 0.48050036791758644, 0.5328980924206875], 'validate': [0.6893933803536171, 0.5360824742268041, 0.5556844547563805, 0.3532448377581121, 0.43192064923354373], 'test': [0.690951328586649, 0.5076560659599529, 0.5096463022508039, 0.3738207547169811, 0.4312925170068027]}, '034:031:051:096:014:092': {'training': [0.6528732072522246, 0.6094152261860978, 0.5820441988950277, 0.7752023546725534, 0.6648785105711581], 'validate': [0.7877859244512957, 0.37812960235640647, 0.41305483028720624, 0.5833333333333334, 0.48364414552124735], 'test': [0.6986576009679724, 0.4552414605418139, 0.0, 0.0, 0.0]}, '014:031:051:096:034:092': {'training': [0.5287643973333689, 0.7230599485104818, 0.7388648009459993, 0.6896615158204562, 0.7134157944814462], 'validate': [0.6824196124839228, 0.6078792341678939, 0.6742514970059881, 0.41519174041297935, 0.5139205842081241], 'test': [0.7741706371307373, 0.5332744405182568, 0.5217732444095724, 0.7841981132075472, 0.6266195524146054]}, '092:031:051:096:034:014': {'training': [0.6158064924079121, 0.6565833026848106, 0.6863905325443787, 0.5761589403973509, 0.6264626462646264], 'validate': [0.7361889093421227, 0.5011045655375552, 0.5005302226935313, 0.3480825958702065, 0.41061331013484126], 'test': [0.7400926594380979, 0.42638398115429915, 0.44568965517241377, 0.6096698113207547, 0.5149402390438247]}}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  007  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  007  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  007  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4173, Acc: 0.8759, Val Loss: 0.2437, Val Acc: 0.9429
Mejor modelo guardado con Val Loss: 0.2437
Epoch 2/100, Loss: 0.2646, Acc: 0.9051, Val Loss: 0.3121, Val Acc: 0.8597
Epoch 3/100, Loss: 0.2326, Acc: 0.9127, Val Loss: 0.3120, Val Acc: 0.8428
Epoch 4/100, Loss: 0.2302, Acc: 0.9082, Val Loss: 0.3982, Val Acc: 0.7990
Epoch 5/100, Loss: 0.2210, Acc: 0.9146, Val Loss: 0.4125, Val Acc: 0.7946
Epoch 6/100, Loss: 0.2154, Acc: 0.9120, Val Loss: 0.2234, Val Acc: 0.9002
Mejor modelo guardado con Val Loss: 0.2234
Epoch 7/100, Loss: 0.2142, Acc: 0.9124, Val Loss: 0.4004, Val Acc: 0.7946
Epoch 8/100, Loss: 0.2086, Acc: 0.9170, Val Loss: 0.2945, Val Acc: 0.8689
Epoch 9/100, Loss: 0.2147, Acc: 0.9138, Val Loss: 0.4487, Val Acc: 0.7817
Epoch 10/100, Loss: 0.2076, Acc: 0.9154, Val Loss: 0.5080, Val Acc: 0.7327
Epoch 11/100, Loss: 0.2133, Acc: 0.9111, Val Loss: 0.2758, Val Acc: 0.8564
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.1970, Acc: 0.9236, Val Loss: 0.3904, Val Acc: 0.7890
Epoch 13/100, Loss: 0.1958, Acc: 0.9211, Val Loss: 0.2550, Val Acc: 0.8906
Epoch 14/100, Loss: 0.1910, Acc: 0.9247, Val Loss: 0.3698, Val Acc: 0.8152
Epoch 15/100, Loss: 0.1963, Acc: 0.9218, Val Loss: 0.3481, Val Acc: 0.8258
Epoch 16/100, Loss: 0.1904, Acc: 0.9242, Val Loss: 0.2313, Val Acc: 0.8940
Epoch 17/100, Loss: 0.1896, Acc: 0.9230, Val Loss: 0.3779, Val Acc: 0.8321
Epoch 18/100, Loss: 0.1895, Acc: 0.9229, Val Loss: 0.2926, Val Acc: 0.8594
Epoch 19/100, Loss: 0.1935, Acc: 0.9205, Val Loss: 0.4618, Val Acc: 0.7750
Epoch 20/100, Loss: 0.1914, Acc: 0.9228, Val Loss: 0.4790, Val Acc: 0.7577
Epoch 21/100, Loss: 0.1878, Acc: 0.9256, Val Loss: 0.3457, Val Acc: 0.8266
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.1846, Acc: 0.9277, Val Loss: 0.3188, Val Acc: 0.8575
Epoch 23/100, Loss: 0.1823, Acc: 0.9264, Val Loss: 0.3459, Val Acc: 0.8384
Epoch 24/100, Loss: 0.1801, Acc: 0.9275, Val Loss: 0.3370, Val Acc: 0.8362
Epoch 25/100, Loss: 0.1795, Acc: 0.9258, Val Loss: 0.4137, Val Acc: 0.8211
Epoch 26/100, Loss: 0.1798, Acc: 0.9270, Val Loss: 0.3450, Val Acc: 0.8347
Epoch 27/100, Loss: 0.1823, Acc: 0.9284, Val Loss: 0.3514, Val Acc: 0.8373
Epoch 28/100, Loss: 0.1782, Acc: 0.9276, Val Loss: 0.3867, Val Acc: 0.8292
Epoch 29/100, Loss: 0.1799, Acc: 0.9266, Val Loss: 0.3030, Val Acc: 0.8612
Epoch 30/100, Loss: 0.1789, Acc: 0.9292, Val Loss: 0.2590, Val Acc: 0.8818
Epoch 31/100, Loss: 0.1794, Acc: 0.9283, Val Loss: 0.3065, Val Acc: 0.8498
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.1765, Acc: 0.9282, Val Loss: 0.2665, Val Acc: 0.8756
Epoch 33/100, Loss: 0.1752, Acc: 0.9290, Val Loss: 0.3678, Val Acc: 0.8299
Epoch 34/100, Loss: 0.1738, Acc: 0.9299, Val Loss: 0.3168, Val Acc: 0.8535
Epoch 35/100, Loss: 0.1734, Acc: 0.9309, Val Loss: 0.3878, Val Acc: 0.8255
Epoch 36/100, Loss: 0.1744, Acc: 0.9295, Val Loss: 0.3571, Val Acc: 0.8314
Epoch 37/100, Loss: 0.1731, Acc: 0.9303, Val Loss: 0.3068, Val Acc: 0.8630
Epoch 38/100, Loss: 0.1728, Acc: 0.9312, Val Loss: 0.3183, Val Acc: 0.8560
Epoch 39/100, Loss: 0.1723, Acc: 0.9316, Val Loss: 0.3308, Val Acc: 0.8457
Epoch 40/100, Loss: 0.1722, Acc: 0.9323, Val Loss: 0.3995, Val Acc: 0.8155
Epoch 41/100, Loss: 0.1716, Acc: 0.9309, Val Loss: 0.3304, Val Acc: 0.8413
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.1705, Acc: 0.9330, Val Loss: 0.2968, Val Acc: 0.8627
Epoch 43/100, Loss: 0.1694, Acc: 0.9320, Val Loss: 0.3826, Val Acc: 0.8317
Epoch 44/100, Loss: 0.1701, Acc: 0.9319, Val Loss: 0.3313, Val Acc: 0.8524
Epoch 45/100, Loss: 0.1695, Acc: 0.9320, Val Loss: 0.3339, Val Acc: 0.8509
Epoch 46/100, Loss: 0.1689, Acc: 0.9320, Val Loss: 0.3315, Val Acc: 0.8450
Epoch 47/100, Loss: 0.1690, Acc: 0.9314, Val Loss: 0.3791, Val Acc: 0.8303
Epoch 48/100, Loss: 0.1690, Acc: 0.9320, Val Loss: 0.3915, Val Acc: 0.8277
Epoch 49/100, Loss: 0.1689, Acc: 0.9324, Val Loss: 0.3200, Val Acc: 0.8531
Epoch 50/100, Loss: 0.1686, Acc: 0.9318, Val Loss: 0.3215, Val Acc: 0.8564
Epoch 51/100, Loss: 0.1682, Acc: 0.9324, Val Loss: 0.3138, Val Acc: 0.8568
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.1677, Acc: 0.9332, Val Loss: 0.3373, Val Acc: 0.8465
Epoch 53/100, Loss: 0.1671, Acc: 0.9320, Val Loss: 0.3405, Val Acc: 0.8428
Epoch 54/100, Loss: 0.1672, Acc: 0.9329, Val Loss: 0.3530, Val Acc: 0.8384
Epoch 55/100, Loss: 0.1671, Acc: 0.9330, Val Loss: 0.3434, Val Acc: 0.8406
Epoch 56/100, Loss: 0.1668, Acc: 0.9332, Val Loss: 0.3439, Val Acc: 0.8435
Epoch 57/100, Loss: 0.1669, Acc: 0.9333, Val Loss: 0.3453, Val Acc: 0.8417
Epoch 58/100, Loss: 0.1668, Acc: 0.9322, Val Loss: 0.3621, Val Acc: 0.8369
Epoch 59/100, Loss: 0.1669, Acc: 0.9328, Val Loss: 0.3592, Val Acc: 0.8343
Epoch 60/100, Loss: 0.1667, Acc: 0.9322, Val Loss: 0.3736, Val Acc: 0.8314
Epoch 61/100, Loss: 0.1668, Acc: 0.9327, Val Loss: 0.3355, Val Acc: 0.8465
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.1663, Acc: 0.9329, Val Loss: 0.3436, Val Acc: 0.8413
Epoch 63/100, Loss: 0.1661, Acc: 0.9335, Val Loss: 0.3524, Val Acc: 0.8391
Epoch 64/100, Loss: 0.1659, Acc: 0.9332, Val Loss: 0.3603, Val Acc: 0.8369
Epoch 65/100, Loss: 0.1659, Acc: 0.9322, Val Loss: 0.3605, Val Acc: 0.8369
Epoch 66/100, Loss: 0.1658, Acc: 0.9326, Val Loss: 0.3363, Val Acc: 0.8490
Epoch 67/100, Loss: 0.1659, Acc: 0.9322, Val Loss: 0.3430, Val Acc: 0.8420
Epoch 68/100, Loss: 0.1656, Acc: 0.9334, Val Loss: 0.3554, Val Acc: 0.8376
Epoch 69/100, Loss: 0.1657, Acc: 0.9318, Val Loss: 0.3376, Val Acc: 0.8472
Epoch 70/100, Loss: 0.1657, Acc: 0.9327, Val Loss: 0.3460, Val Acc: 0.8413
Epoch 71/100, Loss: 0.1656, Acc: 0.9332, Val Loss: 0.3448, Val Acc: 0.8439
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.1656, Acc: 0.9331, Val Loss: 0.3559, Val Acc: 0.8373
Epoch 73/100, Loss: 0.1654, Acc: 0.9326, Val Loss: 0.3372, Val Acc: 0.8476
Epoch 74/100, Loss: 0.1654, Acc: 0.9330, Val Loss: 0.3536, Val Acc: 0.8384
Epoch 75/100, Loss: 0.1653, Acc: 0.9322, Val Loss: 0.3381, Val Acc: 0.8468
Epoch 76/100, Loss: 0.1653, Acc: 0.9325, Val Loss: 0.3505, Val Acc: 0.8398
Epoch 77/100, Loss: 0.1654, Acc: 0.9330, Val Loss: 0.3536, Val Acc: 0.8384
Epoch 78/100, Loss: 0.1653, Acc: 0.9321, Val Loss: 0.3368, Val Acc: 0.8476
Epoch 79/100, Loss: 0.1652, Acc: 0.9330, Val Loss: 0.3335, Val Acc: 0.8479
Epoch 80/100, Loss: 0.1652, Acc: 0.9327, Val Loss: 0.3436, Val Acc: 0.8428
Epoch 81/100, Loss: 0.1653, Acc: 0.9335, Val Loss: 0.3477, Val Acc: 0.8413
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.1652, Acc: 0.9329, Val Loss: 0.3503, Val Acc: 0.8395
Epoch 83/100, Loss: 0.1651, Acc: 0.9330, Val Loss: 0.3534, Val Acc: 0.8387
Epoch 84/100, Loss: 0.1652, Acc: 0.9330, Val Loss: 0.3493, Val Acc: 0.8398
Epoch 85/100, Loss: 0.1650, Acc: 0.9328, Val Loss: 0.3598, Val Acc: 0.8373
Epoch 86/100, Loss: 0.1650, Acc: 0.9332, Val Loss: 0.3427, Val Acc: 0.8435
Epoch 87/100, Loss: 0.1650, Acc: 0.9330, Val Loss: 0.3537, Val Acc: 0.8387
Epoch 88/100, Loss: 0.1650, Acc: 0.9326, Val Loss: 0.3457, Val Acc: 0.8420
Epoch 89/100, Loss: 0.1649, Acc: 0.9330, Val Loss: 0.3534, Val Acc: 0.8395
Epoch 90/100, Loss: 0.1649, Acc: 0.9323, Val Loss: 0.3493, Val Acc: 0.8406
Epoch 91/100, Loss: 0.1649, Acc: 0.9325, Val Loss: 0.3482, Val Acc: 0.8409
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.1648, Acc: 0.9326, Val Loss: 0.3600, Val Acc: 0.8369
Epoch 93/100, Loss: 0.1648, Acc: 0.9328, Val Loss: 0.3467, Val Acc: 0.8420
Epoch 94/100, Loss: 0.1648, Acc: 0.9330, Val Loss: 0.3576, Val Acc: 0.8380
Epoch 95/100, Loss: 0.1647, Acc: 0.9325, Val Loss: 0.3365, Val Acc: 0.8479
Epoch 96/100, Loss: 0.1647, Acc: 0.9330, Val Loss: 0.3679, Val Acc: 0.8351
Epoch 97/100, Loss: 0.1646, Acc: 0.9332, Val Loss: 0.3369, Val Acc: 0.8487
Epoch 98/100, Loss: 0.1646, Acc: 0.9322, Val Loss: 0.3456, Val Acc: 0.8420
Epoch 99/100, Loss: 0.1645, Acc: 0.9324, Val Loss: 0.3451, Val Acc: 0.8424
Epoch 100/100, Loss: 0.1646, Acc: 0.9332, Val Loss: 0.3381, Val Acc: 0.8479

##############################
Resultados para principal:  007  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5 
 {'training': [0.16462616112224315, 0.9331555719014344, 0.9284804367606916, 0.9385577630610743, 0.9334919037599487], 'validate': [0.33805460867277065, 0.8479381443298969, 0.7668364459535937, 0.9992625368731564, 0.8677553634325968], 'test': [0.09146094915491564, 0.9749705535924618, 1.0, 0.9498820754716981, 0.9742969458723919]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  111  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  111  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  111  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4933, Acc: 0.8101, Val Loss: 0.3456, Val Acc: 0.9057
Mejor modelo guardado con Val Loss: 0.3456
Epoch 2/100, Loss: 0.3867, Acc: 0.8411, Val Loss: 0.1979, Val Acc: 0.9521
Mejor modelo guardado con Val Loss: 0.1979
Epoch 3/100, Loss: 0.3557, Acc: 0.8498, Val Loss: 0.1952, Val Acc: 0.9392
Mejor modelo guardado con Val Loss: 0.1952
Epoch 4/100, Loss: 0.3403, Acc: 0.8536, Val Loss: 0.1752, Val Acc: 0.9473
Mejor modelo guardado con Val Loss: 0.1752
Epoch 5/100, Loss: 0.3528, Acc: 0.8420, Val Loss: 0.2093, Val Acc: 0.9245
Epoch 6/100, Loss: 0.3416, Acc: 0.8519, Val Loss: 0.1767, Val Acc: 0.9352
Epoch 7/100, Loss: 0.3324, Acc: 0.8523, Val Loss: 0.1925, Val Acc: 0.9367
Epoch 8/100, Loss: 0.3284, Acc: 0.8550, Val Loss: 0.1611, Val Acc: 0.9466
Mejor modelo guardado con Val Loss: 0.1611
Epoch 9/100, Loss: 0.3227, Acc: 0.8611, Val Loss: 0.2243, Val Acc: 0.9087
Epoch 10/100, Loss: 0.3283, Acc: 0.8532, Val Loss: 0.1692, Val Acc: 0.9470
Epoch 11/100, Loss: 0.3265, Acc: 0.8558, Val Loss: 0.1917, Val Acc: 0.9208
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3196, Acc: 0.8600, Val Loss: 0.1332, Val Acc: 0.9613
Mejor modelo guardado con Val Loss: 0.1332
Epoch 13/100, Loss: 0.3173, Acc: 0.8611, Val Loss: 0.1489, Val Acc: 0.9481
Epoch 14/100, Loss: 0.3161, Acc: 0.8644, Val Loss: 0.1295, Val Acc: 0.9621
Mejor modelo guardado con Val Loss: 0.1295
Epoch 15/100, Loss: 0.3163, Acc: 0.8624, Val Loss: 0.1762, Val Acc: 0.9359
Epoch 16/100, Loss: 0.3174, Acc: 0.8627, Val Loss: 0.1868, Val Acc: 0.9341
Epoch 17/100, Loss: 0.3127, Acc: 0.8636, Val Loss: 0.2171, Val Acc: 0.9102
Epoch 18/100, Loss: 0.3116, Acc: 0.8640, Val Loss: 0.1861, Val Acc: 0.9249
Epoch 19/100, Loss: 0.3125, Acc: 0.8607, Val Loss: 0.1691, Val Acc: 0.9396
Epoch 20/100, Loss: 0.3111, Acc: 0.8626, Val Loss: 0.2190, Val Acc: 0.9260
Epoch 21/100, Loss: 0.3083, Acc: 0.8663, Val Loss: 0.1713, Val Acc: 0.9374
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3067, Acc: 0.8668, Val Loss: 0.1636, Val Acc: 0.9433
Epoch 23/100, Loss: 0.3022, Acc: 0.8678, Val Loss: 0.1595, Val Acc: 0.9459
Epoch 24/100, Loss: 0.3022, Acc: 0.8675, Val Loss: 0.1903, Val Acc: 0.9323
Epoch 25/100, Loss: 0.3017, Acc: 0.8662, Val Loss: 0.2012, Val Acc: 0.9157
Epoch 26/100, Loss: 0.3023, Acc: 0.8688, Val Loss: 0.1640, Val Acc: 0.9407
Epoch 27/100, Loss: 0.3010, Acc: 0.8682, Val Loss: 0.1719, Val Acc: 0.9363
Epoch 28/100, Loss: 0.2996, Acc: 0.8660, Val Loss: 0.1632, Val Acc: 0.9400
Epoch 29/100, Loss: 0.3002, Acc: 0.8691, Val Loss: 0.1592, Val Acc: 0.9389
Epoch 30/100, Loss: 0.3009, Acc: 0.8684, Val Loss: 0.1497, Val Acc: 0.9481
Epoch 31/100, Loss: 0.3008, Acc: 0.8679, Val Loss: 0.1689, Val Acc: 0.9378
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2954, Acc: 0.8710, Val Loss: 0.1476, Val Acc: 0.9466
Epoch 33/100, Loss: 0.2947, Acc: 0.8706, Val Loss: 0.1648, Val Acc: 0.9392
Epoch 34/100, Loss: 0.2942, Acc: 0.8717, Val Loss: 0.1666, Val Acc: 0.9352
Epoch 35/100, Loss: 0.2945, Acc: 0.8721, Val Loss: 0.1629, Val Acc: 0.9404
Epoch 36/100, Loss: 0.2950, Acc: 0.8713, Val Loss: 0.1938, Val Acc: 0.9289
Epoch 37/100, Loss: 0.2939, Acc: 0.8707, Val Loss: 0.1556, Val Acc: 0.9418
Epoch 38/100, Loss: 0.2946, Acc: 0.8712, Val Loss: 0.1827, Val Acc: 0.9297
Epoch 39/100, Loss: 0.2923, Acc: 0.8718, Val Loss: 0.1678, Val Acc: 0.9378
Epoch 40/100, Loss: 0.2934, Acc: 0.8704, Val Loss: 0.1692, Val Acc: 0.9385
Epoch 41/100, Loss: 0.2936, Acc: 0.8716, Val Loss: 0.1538, Val Acc: 0.9404
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2915, Acc: 0.8721, Val Loss: 0.1761, Val Acc: 0.9311
Epoch 43/100, Loss: 0.2900, Acc: 0.8723, Val Loss: 0.1513, Val Acc: 0.9444
Epoch 44/100, Loss: 0.2913, Acc: 0.8723, Val Loss: 0.1768, Val Acc: 0.9304
Epoch 45/100, Loss: 0.2905, Acc: 0.8728, Val Loss: 0.1798, Val Acc: 0.9334
Epoch 46/100, Loss: 0.2904, Acc: 0.8730, Val Loss: 0.1727, Val Acc: 0.9348
Epoch 47/100, Loss: 0.2901, Acc: 0.8734, Val Loss: 0.1738, Val Acc: 0.9341
Epoch 48/100, Loss: 0.2903, Acc: 0.8728, Val Loss: 0.1763, Val Acc: 0.9345
Epoch 49/100, Loss: 0.2905, Acc: 0.8732, Val Loss: 0.1677, Val Acc: 0.9359
Epoch 50/100, Loss: 0.2897, Acc: 0.8714, Val Loss: 0.1690, Val Acc: 0.9348
Epoch 51/100, Loss: 0.2899, Acc: 0.8721, Val Loss: 0.1775, Val Acc: 0.9330
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2887, Acc: 0.8739, Val Loss: 0.1697, Val Acc: 0.9356
Epoch 53/100, Loss: 0.2887, Acc: 0.8748, Val Loss: 0.1726, Val Acc: 0.9352
Epoch 54/100, Loss: 0.2888, Acc: 0.8730, Val Loss: 0.1693, Val Acc: 0.9359
Epoch 55/100, Loss: 0.2890, Acc: 0.8737, Val Loss: 0.1702, Val Acc: 0.9356
Epoch 56/100, Loss: 0.2887, Acc: 0.8722, Val Loss: 0.1680, Val Acc: 0.9374
Epoch 57/100, Loss: 0.2885, Acc: 0.8747, Val Loss: 0.1683, Val Acc: 0.9356
Epoch 58/100, Loss: 0.2884, Acc: 0.8730, Val Loss: 0.1698, Val Acc: 0.9356
Epoch 59/100, Loss: 0.2882, Acc: 0.8728, Val Loss: 0.1739, Val Acc: 0.9341
Epoch 60/100, Loss: 0.2883, Acc: 0.8727, Val Loss: 0.1682, Val Acc: 0.9359
Epoch 61/100, Loss: 0.2883, Acc: 0.8733, Val Loss: 0.1692, Val Acc: 0.9378
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2876, Acc: 0.8741, Val Loss: 0.1670, Val Acc: 0.9374
Epoch 63/100, Loss: 0.2878, Acc: 0.8745, Val Loss: 0.1692, Val Acc: 0.9356
Epoch 64/100, Loss: 0.2877, Acc: 0.8739, Val Loss: 0.1680, Val Acc: 0.9374
Epoch 65/100, Loss: 0.2875, Acc: 0.8747, Val Loss: 0.1736, Val Acc: 0.9334
Epoch 66/100, Loss: 0.2874, Acc: 0.8740, Val Loss: 0.1722, Val Acc: 0.9337
Epoch 67/100, Loss: 0.2876, Acc: 0.8733, Val Loss: 0.1703, Val Acc: 0.9359
Epoch 68/100, Loss: 0.2875, Acc: 0.8740, Val Loss: 0.1680, Val Acc: 0.9367
Epoch 69/100, Loss: 0.2872, Acc: 0.8732, Val Loss: 0.1575, Val Acc: 0.9422
Epoch 70/100, Loss: 0.2876, Acc: 0.8733, Val Loss: 0.1671, Val Acc: 0.9378
Epoch 71/100, Loss: 0.2873, Acc: 0.8739, Val Loss: 0.1692, Val Acc: 0.9359
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2871, Acc: 0.8742, Val Loss: 0.1667, Val Acc: 0.9374
Epoch 73/100, Loss: 0.2870, Acc: 0.8746, Val Loss: 0.1705, Val Acc: 0.9359
Epoch 74/100, Loss: 0.2871, Acc: 0.8748, Val Loss: 0.1677, Val Acc: 0.9370
Epoch 75/100, Loss: 0.2871, Acc: 0.8742, Val Loss: 0.1656, Val Acc: 0.9381
Epoch 76/100, Loss: 0.2872, Acc: 0.8744, Val Loss: 0.1645, Val Acc: 0.9381
Epoch 77/100, Loss: 0.2870, Acc: 0.8744, Val Loss: 0.1697, Val Acc: 0.9359
Epoch 78/100, Loss: 0.2871, Acc: 0.8744, Val Loss: 0.1649, Val Acc: 0.9378
Epoch 79/100, Loss: 0.2869, Acc: 0.8748, Val Loss: 0.1730, Val Acc: 0.9337
Epoch 80/100, Loss: 0.2870, Acc: 0.8747, Val Loss: 0.1699, Val Acc: 0.9348
Epoch 81/100, Loss: 0.2870, Acc: 0.8739, Val Loss: 0.1716, Val Acc: 0.9352
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2869, Acc: 0.8745, Val Loss: 0.1683, Val Acc: 0.9359
Epoch 83/100, Loss: 0.2869, Acc: 0.8749, Val Loss: 0.1685, Val Acc: 0.9370
Epoch 84/100, Loss: 0.2869, Acc: 0.8737, Val Loss: 0.1689, Val Acc: 0.9367
Epoch 85/100, Loss: 0.2869, Acc: 0.8741, Val Loss: 0.1684, Val Acc: 0.9363
Epoch 86/100, Loss: 0.2868, Acc: 0.8743, Val Loss: 0.1633, Val Acc: 0.9389
Epoch 87/100, Loss: 0.2869, Acc: 0.8743, Val Loss: 0.1644, Val Acc: 0.9385
Epoch 88/100, Loss: 0.2868, Acc: 0.8746, Val Loss: 0.1659, Val Acc: 0.9381
Epoch 89/100, Loss: 0.2868, Acc: 0.8746, Val Loss: 0.1711, Val Acc: 0.9352
Epoch 90/100, Loss: 0.2869, Acc: 0.8744, Val Loss: 0.1677, Val Acc: 0.9370
Epoch 91/100, Loss: 0.2867, Acc: 0.8748, Val Loss: 0.1639, Val Acc: 0.9389
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2867, Acc: 0.8744, Val Loss: 0.1671, Val Acc: 0.9381
Epoch 93/100, Loss: 0.2865, Acc: 0.8744, Val Loss: 0.1726, Val Acc: 0.9345
Epoch 94/100, Loss: 0.2868, Acc: 0.8739, Val Loss: 0.1695, Val Acc: 0.9363
Epoch 95/100, Loss: 0.2867, Acc: 0.8738, Val Loss: 0.1671, Val Acc: 0.9381
Epoch 96/100, Loss: 0.2866, Acc: 0.8740, Val Loss: 0.1702, Val Acc: 0.9352
Epoch 97/100, Loss: 0.2866, Acc: 0.8748, Val Loss: 0.1690, Val Acc: 0.9363
Epoch 98/100, Loss: 0.2864, Acc: 0.8747, Val Loss: 0.1734, Val Acc: 0.9341
Epoch 99/100, Loss: 0.2867, Acc: 0.8745, Val Loss: 0.1682, Val Acc: 0.9367
Epoch 100/100, Loss: 0.2865, Acc: 0.8745, Val Loss: 0.1678, Val Acc: 0.9378

##############################
Resultados para principal:  111  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5 
 {'training': [0.2865416484968151, 0.8744942993747702, 0.8723248582403512, 0.8772994849153789, 0.8748050995138953], 'validate': [0.16784759517759085, 0.9377761413843888, 0.8975217682518419, 0.9882005899705014, 0.9406809406809407], 'test': [1.6081577173813626, 0.36012956419316844, 0.39957894736842103, 0.5595518867924528, 0.46622451486121347]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  001  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  001  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  001  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6371, Acc: 0.6877, Val Loss: 0.6927, Val Acc: 0.5339
Mejor modelo guardado con Val Loss: 0.6927
Epoch 2/100, Loss: 0.5562, Acc: 0.7353, Val Loss: 0.6738, Val Acc: 0.5560
Mejor modelo guardado con Val Loss: 0.6738
Epoch 3/100, Loss: 0.5074, Acc: 0.7597, Val Loss: 0.7101, Val Acc: 0.5637
Epoch 4/100, Loss: 0.4815, Acc: 0.7688, Val Loss: 0.7240, Val Acc: 0.6130
Epoch 5/100, Loss: 0.4730, Acc: 0.7714, Val Loss: 0.7145, Val Acc: 0.5545
Epoch 6/100, Loss: 0.4672, Acc: 0.7745, Val Loss: 0.7120, Val Acc: 0.5446
Epoch 7/100, Loss: 0.4563, Acc: 0.7826, Val Loss: 0.8222, Val Acc: 0.5199
Epoch 8/100, Loss: 0.4584, Acc: 0.7809, Val Loss: 0.7989, Val Acc: 0.5401
Epoch 9/100, Loss: 0.4502, Acc: 0.7836, Val Loss: 0.7491, Val Acc: 0.5468
Epoch 10/100, Loss: 0.4484, Acc: 0.7901, Val Loss: 0.7370, Val Acc: 0.5998
Epoch 11/100, Loss: 0.4458, Acc: 0.7892, Val Loss: 0.7575, Val Acc: 0.5534
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4366, Acc: 0.7925, Val Loss: 0.7902, Val Acc: 0.5357
Epoch 13/100, Loss: 0.4330, Acc: 0.7973, Val Loss: 0.7741, Val Acc: 0.5582
Epoch 14/100, Loss: 0.4316, Acc: 0.7922, Val Loss: 0.8570, Val Acc: 0.5191
Epoch 15/100, Loss: 0.4287, Acc: 0.7938, Val Loss: 0.8722, Val Acc: 0.5133
Epoch 16/100, Loss: 0.4273, Acc: 0.7988, Val Loss: 0.7987, Val Acc: 0.5751
Epoch 17/100, Loss: 0.4258, Acc: 0.7977, Val Loss: 0.8860, Val Acc: 0.5136
Epoch 18/100, Loss: 0.4249, Acc: 0.7994, Val Loss: 0.8977, Val Acc: 0.5092
Epoch 19/100, Loss: 0.4212, Acc: 0.8017, Val Loss: 0.8276, Val Acc: 0.5324
Epoch 20/100, Loss: 0.4195, Acc: 0.8019, Val Loss: 0.8374, Val Acc: 0.5703
Epoch 21/100, Loss: 0.4188, Acc: 0.8003, Val Loss: 0.9334, Val Acc: 0.5254
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4127, Acc: 0.8053, Val Loss: 0.8549, Val Acc: 0.5346
Epoch 23/100, Loss: 0.4115, Acc: 0.8014, Val Loss: 0.8454, Val Acc: 0.5195
Epoch 24/100, Loss: 0.4114, Acc: 0.8066, Val Loss: 0.8025, Val Acc: 0.5331
Epoch 25/100, Loss: 0.4084, Acc: 0.8078, Val Loss: 0.8263, Val Acc: 0.5560
Epoch 26/100, Loss: 0.4071, Acc: 0.8080, Val Loss: 0.8647, Val Acc: 0.5302
Epoch 27/100, Loss: 0.4058, Acc: 0.8111, Val Loss: 0.8101, Val Acc: 0.5357
Epoch 28/100, Loss: 0.4052, Acc: 0.8096, Val Loss: 0.8911, Val Acc: 0.5232
Epoch 29/100, Loss: 0.4080, Acc: 0.8068, Val Loss: 0.8160, Val Acc: 0.5556
Epoch 30/100, Loss: 0.4042, Acc: 0.8096, Val Loss: 0.8019, Val Acc: 0.5596
Epoch 31/100, Loss: 0.4049, Acc: 0.8091, Val Loss: 0.8576, Val Acc: 0.5250
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4012, Acc: 0.8112, Val Loss: 0.8104, Val Acc: 0.5479
Epoch 33/100, Loss: 0.4000, Acc: 0.8117, Val Loss: 0.8634, Val Acc: 0.5272
Epoch 34/100, Loss: 0.4007, Acc: 0.8101, Val Loss: 0.8523, Val Acc: 0.5287
Epoch 35/100, Loss: 0.3990, Acc: 0.8121, Val Loss: 0.8316, Val Acc: 0.5372
Epoch 36/100, Loss: 0.3982, Acc: 0.8137, Val Loss: 0.8309, Val Acc: 0.5416
Epoch 37/100, Loss: 0.3972, Acc: 0.8122, Val Loss: 0.8457, Val Acc: 0.5328
Epoch 38/100, Loss: 0.3973, Acc: 0.8122, Val Loss: 0.7987, Val Acc: 0.5523
Epoch 39/100, Loss: 0.3975, Acc: 0.8117, Val Loss: 0.8264, Val Acc: 0.5453
Epoch 40/100, Loss: 0.3972, Acc: 0.8136, Val Loss: 0.8671, Val Acc: 0.5180
Epoch 41/100, Loss: 0.3971, Acc: 0.8117, Val Loss: 0.8569, Val Acc: 0.5199
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3950, Acc: 0.8132, Val Loss: 0.8671, Val Acc: 0.5254
Epoch 43/100, Loss: 0.3939, Acc: 0.8145, Val Loss: 0.8343, Val Acc: 0.5416
Epoch 44/100, Loss: 0.3941, Acc: 0.8135, Val Loss: 0.8601, Val Acc: 0.5269
Epoch 45/100, Loss: 0.3939, Acc: 0.8144, Val Loss: 0.8375, Val Acc: 0.5390
Epoch 46/100, Loss: 0.3939, Acc: 0.8145, Val Loss: 0.8533, Val Acc: 0.5331
Epoch 47/100, Loss: 0.3939, Acc: 0.8142, Val Loss: 0.8465, Val Acc: 0.5390
Epoch 48/100, Loss: 0.3932, Acc: 0.8135, Val Loss: 0.8576, Val Acc: 0.5309
Epoch 49/100, Loss: 0.3933, Acc: 0.8146, Val Loss: 0.8675, Val Acc: 0.5276
Epoch 50/100, Loss: 0.3928, Acc: 0.8147, Val Loss: 0.8727, Val Acc: 0.5357
Epoch 51/100, Loss: 0.3934, Acc: 0.8135, Val Loss: 0.8655, Val Acc: 0.5280
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3918, Acc: 0.8152, Val Loss: 0.8313, Val Acc: 0.5398
Epoch 53/100, Loss: 0.3912, Acc: 0.8147, Val Loss: 0.8286, Val Acc: 0.5457
Epoch 54/100, Loss: 0.3916, Acc: 0.8164, Val Loss: 0.8345, Val Acc: 0.5412
Epoch 55/100, Loss: 0.3914, Acc: 0.8151, Val Loss: 0.8484, Val Acc: 0.5379
Epoch 56/100, Loss: 0.3915, Acc: 0.8146, Val Loss: 0.8558, Val Acc: 0.5258
Epoch 57/100, Loss: 0.3915, Acc: 0.8144, Val Loss: 0.8449, Val Acc: 0.5394
Epoch 58/100, Loss: 0.3911, Acc: 0.8153, Val Loss: 0.8581, Val Acc: 0.5309
Epoch 59/100, Loss: 0.3912, Acc: 0.8148, Val Loss: 0.8505, Val Acc: 0.5331
Epoch 60/100, Loss: 0.3917, Acc: 0.8150, Val Loss: 0.8352, Val Acc: 0.5398
Epoch 61/100, Loss: 0.3909, Acc: 0.8147, Val Loss: 0.8360, Val Acc: 0.5449
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3905, Acc: 0.8158, Val Loss: 0.8487, Val Acc: 0.5342
Epoch 63/100, Loss: 0.3902, Acc: 0.8156, Val Loss: 0.8497, Val Acc: 0.5339
Epoch 64/100, Loss: 0.3903, Acc: 0.8156, Val Loss: 0.8512, Val Acc: 0.5328
Epoch 65/100, Loss: 0.3902, Acc: 0.8168, Val Loss: 0.8466, Val Acc: 0.5361
Epoch 66/100, Loss: 0.3902, Acc: 0.8168, Val Loss: 0.8453, Val Acc: 0.5372
Epoch 67/100, Loss: 0.3901, Acc: 0.8156, Val Loss: 0.8510, Val Acc: 0.5335
Epoch 68/100, Loss: 0.3901, Acc: 0.8159, Val Loss: 0.8490, Val Acc: 0.5350
Epoch 69/100, Loss: 0.3899, Acc: 0.8162, Val Loss: 0.8529, Val Acc: 0.5335
Epoch 70/100, Loss: 0.3899, Acc: 0.8162, Val Loss: 0.8450, Val Acc: 0.5361
Epoch 71/100, Loss: 0.3899, Acc: 0.8171, Val Loss: 0.8492, Val Acc: 0.5346
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3897, Acc: 0.8156, Val Loss: 0.8453, Val Acc: 0.5368
Epoch 73/100, Loss: 0.3895, Acc: 0.8157, Val Loss: 0.8461, Val Acc: 0.5365
Epoch 74/100, Loss: 0.3897, Acc: 0.8167, Val Loss: 0.8430, Val Acc: 0.5383
Epoch 75/100, Loss: 0.3896, Acc: 0.8155, Val Loss: 0.8485, Val Acc: 0.5342
Epoch 76/100, Loss: 0.3895, Acc: 0.8172, Val Loss: 0.8505, Val Acc: 0.5342
Epoch 77/100, Loss: 0.3898, Acc: 0.8173, Val Loss: 0.8462, Val Acc: 0.5357
Epoch 78/100, Loss: 0.3895, Acc: 0.8166, Val Loss: 0.8452, Val Acc: 0.5350
Epoch 79/100, Loss: 0.3895, Acc: 0.8156, Val Loss: 0.8486, Val Acc: 0.5342
Epoch 80/100, Loss: 0.3894, Acc: 0.8157, Val Loss: 0.8405, Val Acc: 0.5379
Epoch 81/100, Loss: 0.3894, Acc: 0.8168, Val Loss: 0.8390, Val Acc: 0.5412
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3895, Acc: 0.8160, Val Loss: 0.8503, Val Acc: 0.5342
Epoch 83/100, Loss: 0.3892, Acc: 0.8172, Val Loss: 0.8476, Val Acc: 0.5353
Epoch 84/100, Loss: 0.3893, Acc: 0.8178, Val Loss: 0.8538, Val Acc: 0.5339
Epoch 85/100, Loss: 0.3894, Acc: 0.8159, Val Loss: 0.8459, Val Acc: 0.5357
Epoch 86/100, Loss: 0.3892, Acc: 0.8170, Val Loss: 0.8417, Val Acc: 0.5379
Epoch 87/100, Loss: 0.3890, Acc: 0.8176, Val Loss: 0.8514, Val Acc: 0.5342
Epoch 88/100, Loss: 0.3893, Acc: 0.8170, Val Loss: 0.8476, Val Acc: 0.5357
Epoch 89/100, Loss: 0.3891, Acc: 0.8173, Val Loss: 0.8479, Val Acc: 0.5342
Epoch 90/100, Loss: 0.3891, Acc: 0.8164, Val Loss: 0.8505, Val Acc: 0.5328
Epoch 91/100, Loss: 0.3891, Acc: 0.8162, Val Loss: 0.8438, Val Acc: 0.5390
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3892, Acc: 0.8166, Val Loss: 0.8475, Val Acc: 0.5353
Epoch 93/100, Loss: 0.3888, Acc: 0.8168, Val Loss: 0.8582, Val Acc: 0.5276
Epoch 94/100, Loss: 0.3891, Acc: 0.8160, Val Loss: 0.8469, Val Acc: 0.5353
Epoch 95/100, Loss: 0.3889, Acc: 0.8170, Val Loss: 0.8466, Val Acc: 0.5353
Epoch 96/100, Loss: 0.3890, Acc: 0.8164, Val Loss: 0.8500, Val Acc: 0.5342
Epoch 97/100, Loss: 0.3889, Acc: 0.8178, Val Loss: 0.8504, Val Acc: 0.5346
Epoch 98/100, Loss: 0.3889, Acc: 0.8161, Val Loss: 0.8467, Val Acc: 0.5353
Epoch 99/100, Loss: 0.3888, Acc: 0.8169, Val Loss: 0.8488, Val Acc: 0.5350
Epoch 100/100, Loss: 0.3887, Acc: 0.8167, Val Loss: 0.8487, Val Acc: 0.5350

##############################
Resultados para principal:  001  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5 
 {'training': [0.38873389309581124, 0.8166605369621184, 0.7977508650519031, 0.8482339955849889, 0.8222182596291013], 'validate': [0.8486862610592398, 0.5349779086892489, 0.5218823529411765, 0.8178466076696165, 0.6371732260844585], 'test': [0.5898630260317413, 0.6413427561837456, 0.6697443181818182, 0.5560141509433962, 0.6076030927835051]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  082  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  082  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  082  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6833, Acc: 0.5682, Val Loss: 0.6940, Val Acc: 0.4945
Mejor modelo guardado con Val Loss: 0.6940
Epoch 2/100, Loss: 0.6725, Acc: 0.6194, Val Loss: 0.6841, Val Acc: 0.5416
Mejor modelo guardado con Val Loss: 0.6841
Epoch 3/100, Loss: 0.6599, Acc: 0.6405, Val Loss: 0.6985, Val Acc: 0.4753
Epoch 4/100, Loss: 0.6795, Acc: 0.5737, Val Loss: 0.6960, Val Acc: 0.4996
Epoch 5/100, Loss: 0.6832, Acc: 0.5531, Val Loss: 0.6988, Val Acc: 0.4772
Epoch 6/100, Loss: 0.6795, Acc: 0.5651, Val Loss: 0.7003, Val Acc: 0.4845
Epoch 7/100, Loss: 0.6774, Acc: 0.5687, Val Loss: 0.7036, Val Acc: 0.5460
Epoch 8/100, Loss: 0.6744, Acc: 0.5779, Val Loss: 0.6948, Val Acc: 0.4952
Epoch 9/100, Loss: 0.6744, Acc: 0.5854, Val Loss: 0.6965, Val Acc: 0.5007
Epoch 10/100, Loss: 0.6736, Acc: 0.5797, Val Loss: 0.6913, Val Acc: 0.5353
Epoch 11/100, Loss: 0.6723, Acc: 0.5993, Val Loss: 0.6924, Val Acc: 0.5151
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6702, Acc: 0.5969, Val Loss: 0.6960, Val Acc: 0.5000
Epoch 13/100, Loss: 0.6676, Acc: 0.5699, Val Loss: 0.6961, Val Acc: 0.5085
Epoch 14/100, Loss: 0.6664, Acc: 0.5751, Val Loss: 0.6969, Val Acc: 0.5022
Epoch 15/100, Loss: 0.6658, Acc: 0.5795, Val Loss: 0.6915, Val Acc: 0.5041
Epoch 16/100, Loss: 0.6664, Acc: 0.5974, Val Loss: 0.6979, Val Acc: 0.5015
Epoch 17/100, Loss: 0.6647, Acc: 0.5669, Val Loss: 0.6941, Val Acc: 0.5015
Epoch 18/100, Loss: 0.6634, Acc: 0.5701, Val Loss: 0.6983, Val Acc: 0.5041
Epoch 19/100, Loss: 0.6628, Acc: 0.5796, Val Loss: 0.6991, Val Acc: 0.5018
Epoch 20/100, Loss: 0.6621, Acc: 0.5765, Val Loss: 0.6928, Val Acc: 0.5018
Epoch 21/100, Loss: 0.6612, Acc: 0.5827, Val Loss: 0.6972, Val Acc: 0.5055
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6599, Acc: 0.5666, Val Loss: 0.6933, Val Acc: 0.5070
Epoch 23/100, Loss: 0.6597, Acc: 0.5689, Val Loss: 0.6991, Val Acc: 0.5070
Epoch 24/100, Loss: 0.6590, Acc: 0.5876, Val Loss: 0.6929, Val Acc: 0.5077
Epoch 25/100, Loss: 0.6588, Acc: 0.6157, Val Loss: 0.6934, Val Acc: 0.5070
Epoch 26/100, Loss: 0.6576, Acc: 0.5795, Val Loss: 0.6930, Val Acc: 0.5029
Epoch 27/100, Loss: 0.6588, Acc: 0.5987, Val Loss: 0.6934, Val Acc: 0.5383
Epoch 28/100, Loss: 0.6571, Acc: 0.6338, Val Loss: 0.6959, Val Acc: 0.5085
Epoch 29/100, Loss: 0.6571, Acc: 0.6412, Val Loss: 0.6936, Val Acc: 0.5048
Epoch 30/100, Loss: 0.6562, Acc: 0.6490, Val Loss: 0.6942, Val Acc: 0.5059
Epoch 31/100, Loss: 0.6559, Acc: 0.6563, Val Loss: 0.6950, Val Acc: 0.5044
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6548, Acc: 0.6025, Val Loss: 0.6936, Val Acc: 0.5077
Epoch 33/100, Loss: 0.6541, Acc: 0.6452, Val Loss: 0.6959, Val Acc: 0.5232
Epoch 34/100, Loss: 0.6534, Acc: 0.6893, Val Loss: 0.6927, Val Acc: 0.5280
Epoch 35/100, Loss: 0.6532, Acc: 0.6674, Val Loss: 0.7029, Val Acc: 0.5320
Epoch 36/100, Loss: 0.6520, Acc: 0.6802, Val Loss: 0.6944, Val Acc: 0.5261
Epoch 37/100, Loss: 0.6509, Acc: 0.6863, Val Loss: 0.6912, Val Acc: 0.5416
Epoch 38/100, Loss: 0.6502, Acc: 0.6892, Val Loss: 0.6945, Val Acc: 0.5372
Epoch 39/100, Loss: 0.6489, Acc: 0.6933, Val Loss: 0.6993, Val Acc: 0.5295
Epoch 40/100, Loss: 0.6475, Acc: 0.6974, Val Loss: 0.6901, Val Acc: 0.5398
Epoch 41/100, Loss: 0.6469, Acc: 0.7021, Val Loss: 0.6966, Val Acc: 0.5346
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6454, Acc: 0.7042, Val Loss: 0.6940, Val Acc: 0.5438
Epoch 43/100, Loss: 0.6448, Acc: 0.7031, Val Loss: 0.6923, Val Acc: 0.5538
Epoch 44/100, Loss: 0.6442, Acc: 0.7033, Val Loss: 0.6950, Val Acc: 0.5460
Epoch 45/100, Loss: 0.6439, Acc: 0.7048, Val Loss: 0.6937, Val Acc: 0.5471
Epoch 46/100, Loss: 0.6432, Acc: 0.7048, Val Loss: 0.6933, Val Acc: 0.5471
Epoch 47/100, Loss: 0.6429, Acc: 0.7042, Val Loss: 0.6925, Val Acc: 0.5523
Epoch 48/100, Loss: 0.6421, Acc: 0.7045, Val Loss: 0.6933, Val Acc: 0.5515
Epoch 49/100, Loss: 0.6414, Acc: 0.7061, Val Loss: 0.6946, Val Acc: 0.5446
Epoch 50/100, Loss: 0.6409, Acc: 0.7049, Val Loss: 0.6948, Val Acc: 0.5431
Epoch 51/100, Loss: 0.6403, Acc: 0.7075, Val Loss: 0.6932, Val Acc: 0.5530
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6394, Acc: 0.7074, Val Loss: 0.6920, Val Acc: 0.5582
Epoch 53/100, Loss: 0.6390, Acc: 0.7069, Val Loss: 0.6938, Val Acc: 0.5512
Epoch 54/100, Loss: 0.6383, Acc: 0.7068, Val Loss: 0.6961, Val Acc: 0.5416
Epoch 55/100, Loss: 0.6378, Acc: 0.7071, Val Loss: 0.6955, Val Acc: 0.5431
Epoch 56/100, Loss: 0.6373, Acc: 0.7066, Val Loss: 0.6948, Val Acc: 0.5468
Epoch 57/100, Loss: 0.6370, Acc: 0.7078, Val Loss: 0.6945, Val Acc: 0.5479
Epoch 58/100, Loss: 0.6356, Acc: 0.7074, Val Loss: 0.6933, Val Acc: 0.5578
Epoch 59/100, Loss: 0.6349, Acc: 0.7095, Val Loss: 0.6969, Val Acc: 0.5409
Epoch 60/100, Loss: 0.6344, Acc: 0.7078, Val Loss: 0.6954, Val Acc: 0.5486
Epoch 61/100, Loss: 0.6339, Acc: 0.7081, Val Loss: 0.6963, Val Acc: 0.5453
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6334, Acc: 0.7089, Val Loss: 0.6950, Val Acc: 0.5512
Epoch 63/100, Loss: 0.6332, Acc: 0.7078, Val Loss: 0.6956, Val Acc: 0.5482
Epoch 64/100, Loss: 0.6329, Acc: 0.7082, Val Loss: 0.6961, Val Acc: 0.5464
Epoch 65/100, Loss: 0.6327, Acc: 0.7095, Val Loss: 0.6952, Val Acc: 0.5519
Epoch 66/100, Loss: 0.6325, Acc: 0.7084, Val Loss: 0.6961, Val Acc: 0.5475
Epoch 67/100, Loss: 0.6322, Acc: 0.7085, Val Loss: 0.6960, Val Acc: 0.5486
Epoch 68/100, Loss: 0.6319, Acc: 0.7106, Val Loss: 0.6971, Val Acc: 0.5423
Epoch 69/100, Loss: 0.6317, Acc: 0.7102, Val Loss: 0.6963, Val Acc: 0.5453
Epoch 70/100, Loss: 0.6315, Acc: 0.7085, Val Loss: 0.6962, Val Acc: 0.5460
Epoch 71/100, Loss: 0.6312, Acc: 0.7095, Val Loss: 0.6961, Val Acc: 0.5457
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6307, Acc: 0.7101, Val Loss: 0.6963, Val Acc: 0.5471
Epoch 73/100, Loss: 0.6305, Acc: 0.7088, Val Loss: 0.6967, Val Acc: 0.5446
Epoch 74/100, Loss: 0.6304, Acc: 0.7093, Val Loss: 0.6962, Val Acc: 0.5464
Epoch 75/100, Loss: 0.6302, Acc: 0.7095, Val Loss: 0.6967, Val Acc: 0.5446
Epoch 76/100, Loss: 0.6300, Acc: 0.7109, Val Loss: 0.6962, Val Acc: 0.5468
Epoch 77/100, Loss: 0.6299, Acc: 0.7093, Val Loss: 0.6966, Val Acc: 0.5457
Epoch 78/100, Loss: 0.6297, Acc: 0.7088, Val Loss: 0.6960, Val Acc: 0.5475
Epoch 79/100, Loss: 0.6296, Acc: 0.7106, Val Loss: 0.6969, Val Acc: 0.5438
Epoch 80/100, Loss: 0.6295, Acc: 0.7105, Val Loss: 0.6964, Val Acc: 0.5453
Epoch 81/100, Loss: 0.6293, Acc: 0.7088, Val Loss: 0.6964, Val Acc: 0.5464
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6291, Acc: 0.7098, Val Loss: 0.6965, Val Acc: 0.5490
Epoch 83/100, Loss: 0.6290, Acc: 0.7095, Val Loss: 0.6964, Val Acc: 0.5471
Epoch 84/100, Loss: 0.6288, Acc: 0.7105, Val Loss: 0.6963, Val Acc: 0.5468
Epoch 85/100, Loss: 0.6287, Acc: 0.7089, Val Loss: 0.6959, Val Acc: 0.5464
Epoch 86/100, Loss: 0.6285, Acc: 0.7096, Val Loss: 0.6960, Val Acc: 0.5460
Epoch 87/100, Loss: 0.6283, Acc: 0.7094, Val Loss: 0.6962, Val Acc: 0.5457
Epoch 88/100, Loss: 0.6283, Acc: 0.7096, Val Loss: 0.6964, Val Acc: 0.5460
Epoch 89/100, Loss: 0.6280, Acc: 0.7100, Val Loss: 0.6958, Val Acc: 0.5479
Epoch 90/100, Loss: 0.6279, Acc: 0.7106, Val Loss: 0.6965, Val Acc: 0.5457
Epoch 91/100, Loss: 0.6278, Acc: 0.7102, Val Loss: 0.6960, Val Acc: 0.5457
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6276, Acc: 0.7091, Val Loss: 0.6961, Val Acc: 0.5453
Epoch 93/100, Loss: 0.6274, Acc: 0.7099, Val Loss: 0.6956, Val Acc: 0.5482
Epoch 94/100, Loss: 0.6241, Acc: 0.7099, Val Loss: 0.6917, Val Acc: 0.5549
Epoch 95/100, Loss: 0.6181, Acc: 0.7066, Val Loss: 0.6954, Val Acc: 0.5482
Epoch 96/100, Loss: 0.6175, Acc: 0.7092, Val Loss: 0.6960, Val Acc: 0.5486
Epoch 97/100, Loss: 0.6172, Acc: 0.7092, Val Loss: 0.6955, Val Acc: 0.5493
Epoch 98/100, Loss: 0.6169, Acc: 0.7089, Val Loss: 0.6941, Val Acc: 0.5515
Epoch 99/100, Loss: 0.6166, Acc: 0.7083, Val Loss: 0.6945, Val Acc: 0.5534
Epoch 100/100, Loss: 0.6163, Acc: 0.7095, Val Loss: 0.6952, Val Acc: 0.5527

##############################
Resultados para principal:  082  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5 
 {'training': [0.6162980340473263, 0.7095439499816109, 0.6764842660052705, 0.8027961736571008, 0.7342474972659208], 'validate': [0.6951758417972299, 0.5526509572901326, 0.5334598955861415, 0.8289085545722714, 0.6491481374530753], 'test': [0.6368897601410195, 0.7629564193168433, 0.7197829304390725, 0.8602594339622641, 0.7837765243083534]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  103  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  103  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  103  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6450, Acc: 0.6549, Val Loss: 0.6757, Val Acc: 0.5792
Mejor modelo guardado con Val Loss: 0.6757
Epoch 2/100, Loss: 0.5733, Acc: 0.7403, Val Loss: 0.7051, Val Acc: 0.5254
Epoch 3/100, Loss: 0.5394, Acc: 0.7433, Val Loss: 0.6946, Val Acc: 0.5460
Epoch 4/100, Loss: 0.5226, Acc: 0.7473, Val Loss: 0.7026, Val Acc: 0.5416
Epoch 5/100, Loss: 0.5062, Acc: 0.7570, Val Loss: 0.7456, Val Acc: 0.5258
Epoch 6/100, Loss: 0.4983, Acc: 0.7575, Val Loss: 0.7293, Val Acc: 0.5254
Epoch 7/100, Loss: 0.4901, Acc: 0.7590, Val Loss: 0.7457, Val Acc: 0.5140
Epoch 8/100, Loss: 0.4864, Acc: 0.7594, Val Loss: 0.7551, Val Acc: 0.5033
Epoch 9/100, Loss: 0.4897, Acc: 0.7571, Val Loss: 0.7656, Val Acc: 0.5228
Epoch 10/100, Loss: 0.4899, Acc: 0.7577, Val Loss: 0.7234, Val Acc: 0.5295
Epoch 11/100, Loss: 0.4844, Acc: 0.7593, Val Loss: 0.7700, Val Acc: 0.5236
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4778, Acc: 0.7640, Val Loss: 0.7792, Val Acc: 0.5155
Epoch 13/100, Loss: 0.4779, Acc: 0.7631, Val Loss: 0.7353, Val Acc: 0.5335
Epoch 14/100, Loss: 0.4727, Acc: 0.7647, Val Loss: 0.7629, Val Acc: 0.5210
Epoch 15/100, Loss: 0.4733, Acc: 0.7680, Val Loss: 0.7607, Val Acc: 0.5317
Epoch 16/100, Loss: 0.4697, Acc: 0.7679, Val Loss: 0.7292, Val Acc: 0.5272
Epoch 17/100, Loss: 0.4690, Acc: 0.7676, Val Loss: 0.7682, Val Acc: 0.5258
Epoch 18/100, Loss: 0.4721, Acc: 0.7658, Val Loss: 0.7575, Val Acc: 0.5184
Epoch 19/100, Loss: 0.4679, Acc: 0.7688, Val Loss: 0.7621, Val Acc: 0.5236
Epoch 20/100, Loss: 0.4669, Acc: 0.7705, Val Loss: 0.7472, Val Acc: 0.5306
Epoch 21/100, Loss: 0.4684, Acc: 0.7686, Val Loss: 0.7581, Val Acc: 0.5309
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4626, Acc: 0.7716, Val Loss: 0.7246, Val Acc: 0.5497
Epoch 23/100, Loss: 0.4627, Acc: 0.7720, Val Loss: 0.7619, Val Acc: 0.5217
Epoch 24/100, Loss: 0.4643, Acc: 0.7718, Val Loss: 0.7732, Val Acc: 0.5254
Epoch 25/100, Loss: 0.4613, Acc: 0.7722, Val Loss: 0.7325, Val Acc: 0.5549
Epoch 26/100, Loss: 0.4623, Acc: 0.7727, Val Loss: 0.7311, Val Acc: 0.5313
Epoch 27/100, Loss: 0.4604, Acc: 0.7734, Val Loss: 0.7823, Val Acc: 0.5221
Epoch 28/100, Loss: 0.4608, Acc: 0.7718, Val Loss: 0.7722, Val Acc: 0.5309
Epoch 29/100, Loss: 0.4606, Acc: 0.7729, Val Loss: 0.7540, Val Acc: 0.5372
Epoch 30/100, Loss: 0.4572, Acc: 0.7759, Val Loss: 0.7369, Val Acc: 0.5508
Epoch 31/100, Loss: 0.4594, Acc: 0.7739, Val Loss: 0.7481, Val Acc: 0.5368
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4569, Acc: 0.7732, Val Loss: 0.7417, Val Acc: 0.5361
Epoch 33/100, Loss: 0.4562, Acc: 0.7768, Val Loss: 0.7512, Val Acc: 0.5353
Epoch 34/100, Loss: 0.4561, Acc: 0.7772, Val Loss: 0.7477, Val Acc: 0.5342
Epoch 35/100, Loss: 0.4557, Acc: 0.7753, Val Loss: 0.7549, Val Acc: 0.5390
Epoch 36/100, Loss: 0.4562, Acc: 0.7751, Val Loss: 0.7522, Val Acc: 0.5368
Epoch 37/100, Loss: 0.4554, Acc: 0.7766, Val Loss: 0.7410, Val Acc: 0.5365
Epoch 38/100, Loss: 0.4554, Acc: 0.7766, Val Loss: 0.7525, Val Acc: 0.5309
Epoch 39/100, Loss: 0.4549, Acc: 0.7761, Val Loss: 0.7559, Val Acc: 0.5365
Epoch 40/100, Loss: 0.4545, Acc: 0.7768, Val Loss: 0.7212, Val Acc: 0.5449
Epoch 41/100, Loss: 0.4555, Acc: 0.7747, Val Loss: 0.7370, Val Acc: 0.5365
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4534, Acc: 0.7760, Val Loss: 0.7665, Val Acc: 0.5335
Epoch 43/100, Loss: 0.4529, Acc: 0.7780, Val Loss: 0.7569, Val Acc: 0.5379
Epoch 44/100, Loss: 0.4531, Acc: 0.7774, Val Loss: 0.7423, Val Acc: 0.5475
Epoch 45/100, Loss: 0.4531, Acc: 0.7776, Val Loss: 0.7501, Val Acc: 0.5387
Epoch 46/100, Loss: 0.4525, Acc: 0.7773, Val Loss: 0.7479, Val Acc: 0.5376
Epoch 47/100, Loss: 0.4523, Acc: 0.7762, Val Loss: 0.7553, Val Acc: 0.5376
Epoch 48/100, Loss: 0.4525, Acc: 0.7770, Val Loss: 0.7513, Val Acc: 0.5379
Epoch 49/100, Loss: 0.4527, Acc: 0.7764, Val Loss: 0.7501, Val Acc: 0.5398
Epoch 50/100, Loss: 0.4523, Acc: 0.7776, Val Loss: 0.7521, Val Acc: 0.5357
Epoch 51/100, Loss: 0.4521, Acc: 0.7778, Val Loss: 0.7601, Val Acc: 0.5368
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4513, Acc: 0.7794, Val Loss: 0.7488, Val Acc: 0.5387
Epoch 53/100, Loss: 0.4515, Acc: 0.7787, Val Loss: 0.7552, Val Acc: 0.5372
Epoch 54/100, Loss: 0.4513, Acc: 0.7785, Val Loss: 0.7553, Val Acc: 0.5365
Epoch 55/100, Loss: 0.4512, Acc: 0.7787, Val Loss: 0.7485, Val Acc: 0.5376
Epoch 56/100, Loss: 0.4511, Acc: 0.7786, Val Loss: 0.7509, Val Acc: 0.5390
Epoch 57/100, Loss: 0.4510, Acc: 0.7793, Val Loss: 0.7507, Val Acc: 0.5353
Epoch 58/100, Loss: 0.4511, Acc: 0.7791, Val Loss: 0.7480, Val Acc: 0.5383
Epoch 59/100, Loss: 0.4508, Acc: 0.7787, Val Loss: 0.7504, Val Acc: 0.5353
Epoch 60/100, Loss: 0.4510, Acc: 0.7793, Val Loss: 0.7551, Val Acc: 0.5331
Epoch 61/100, Loss: 0.4508, Acc: 0.7787, Val Loss: 0.7516, Val Acc: 0.5401
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4506, Acc: 0.7798, Val Loss: 0.7531, Val Acc: 0.5353
Epoch 63/100, Loss: 0.4505, Acc: 0.7786, Val Loss: 0.7528, Val Acc: 0.5368
Epoch 64/100, Loss: 0.4504, Acc: 0.7787, Val Loss: 0.7496, Val Acc: 0.5383
Epoch 65/100, Loss: 0.4503, Acc: 0.7812, Val Loss: 0.7454, Val Acc: 0.5405
Epoch 66/100, Loss: 0.4504, Acc: 0.7795, Val Loss: 0.7547, Val Acc: 0.5379
Epoch 67/100, Loss: 0.4501, Acc: 0.7791, Val Loss: 0.7480, Val Acc: 0.5401
Epoch 68/100, Loss: 0.4504, Acc: 0.7783, Val Loss: 0.7489, Val Acc: 0.5387
Epoch 69/100, Loss: 0.4503, Acc: 0.7791, Val Loss: 0.7481, Val Acc: 0.5394
Epoch 70/100, Loss: 0.4502, Acc: 0.7791, Val Loss: 0.7501, Val Acc: 0.5383
Epoch 71/100, Loss: 0.4501, Acc: 0.7792, Val Loss: 0.7485, Val Acc: 0.5409
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4500, Acc: 0.7803, Val Loss: 0.7501, Val Acc: 0.5398
Epoch 73/100, Loss: 0.4500, Acc: 0.7794, Val Loss: 0.7502, Val Acc: 0.5379
Epoch 74/100, Loss: 0.4500, Acc: 0.7801, Val Loss: 0.7498, Val Acc: 0.5387
Epoch 75/100, Loss: 0.4500, Acc: 0.7796, Val Loss: 0.7488, Val Acc: 0.5401
Epoch 76/100, Loss: 0.4499, Acc: 0.7788, Val Loss: 0.7505, Val Acc: 0.5383
Epoch 77/100, Loss: 0.4500, Acc: 0.7796, Val Loss: 0.7526, Val Acc: 0.5372
Epoch 78/100, Loss: 0.4498, Acc: 0.7797, Val Loss: 0.7493, Val Acc: 0.5390
Epoch 79/100, Loss: 0.4500, Acc: 0.7803, Val Loss: 0.7515, Val Acc: 0.5372
Epoch 80/100, Loss: 0.4499, Acc: 0.7794, Val Loss: 0.7525, Val Acc: 0.5342
Epoch 81/100, Loss: 0.4499, Acc: 0.7800, Val Loss: 0.7493, Val Acc: 0.5387
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4499, Acc: 0.7796, Val Loss: 0.7519, Val Acc: 0.5365
Epoch 83/100, Loss: 0.4498, Acc: 0.7800, Val Loss: 0.7506, Val Acc: 0.5379
Epoch 84/100, Loss: 0.4497, Acc: 0.7796, Val Loss: 0.7496, Val Acc: 0.5394
Epoch 85/100, Loss: 0.4498, Acc: 0.7795, Val Loss: 0.7507, Val Acc: 0.5372
Epoch 86/100, Loss: 0.4497, Acc: 0.7799, Val Loss: 0.7494, Val Acc: 0.5394
Epoch 87/100, Loss: 0.4497, Acc: 0.7801, Val Loss: 0.7537, Val Acc: 0.5376
Epoch 88/100, Loss: 0.4497, Acc: 0.7792, Val Loss: 0.7517, Val Acc: 0.5368
Epoch 89/100, Loss: 0.4497, Acc: 0.7797, Val Loss: 0.7520, Val Acc: 0.5372
Epoch 90/100, Loss: 0.4497, Acc: 0.7800, Val Loss: 0.7519, Val Acc: 0.5368
Epoch 91/100, Loss: 0.4496, Acc: 0.7797, Val Loss: 0.7520, Val Acc: 0.5350
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4496, Acc: 0.7797, Val Loss: 0.7487, Val Acc: 0.5405
Epoch 93/100, Loss: 0.4496, Acc: 0.7792, Val Loss: 0.7512, Val Acc: 0.5383
Epoch 94/100, Loss: 0.4495, Acc: 0.7795, Val Loss: 0.7497, Val Acc: 0.5387
Epoch 95/100, Loss: 0.4496, Acc: 0.7792, Val Loss: 0.7512, Val Acc: 0.5368
Epoch 96/100, Loss: 0.4495, Acc: 0.7797, Val Loss: 0.7514, Val Acc: 0.5376
Epoch 97/100, Loss: 0.4495, Acc: 0.7796, Val Loss: 0.7523, Val Acc: 0.5368
Epoch 98/100, Loss: 0.4495, Acc: 0.7797, Val Loss: 0.7537, Val Acc: 0.5353
Epoch 99/100, Loss: 0.4495, Acc: 0.7797, Val Loss: 0.7517, Val Acc: 0.5379
Epoch 100/100, Loss: 0.4495, Acc: 0.7797, Val Loss: 0.7526, Val Acc: 0.5372

##############################
Resultados para principal:  103  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5 
 {'training': [0.44945554158493806, 0.7796984185362266, 0.7134831460674157, 0.9345106696100074, 0.809174896463842], 'validate': [0.7525841136311375, 0.5371870397643593, 0.5208421052631579, 0.9122418879056047, 0.6630930045564192], 'test': [0.5448615275047444, 0.8571849234393404, 0.8584961515689757, 0.8549528301886793, 0.8567208271787297]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  117  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  117  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  117  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6289, Acc: 0.6533, Val Loss: 0.6077, Val Acc: 0.7496
Mejor modelo guardado con Val Loss: 0.6077
Epoch 2/100, Loss: 0.5955, Acc: 0.6696, Val Loss: 0.6326, Val Acc: 0.6071
Epoch 3/100, Loss: 0.5878, Acc: 0.6674, Val Loss: 0.5841, Val Acc: 0.7091
Mejor modelo guardado con Val Loss: 0.5841
Epoch 4/100, Loss: 0.5753, Acc: 0.6817, Val Loss: 0.6303, Val Acc: 0.6392
Epoch 5/100, Loss: 0.5705, Acc: 0.6805, Val Loss: 0.6275, Val Acc: 0.6046
Epoch 6/100, Loss: 0.5595, Acc: 0.6912, Val Loss: 0.6300, Val Acc: 0.5884
Epoch 7/100, Loss: 0.5633, Acc: 0.6902, Val Loss: 0.6223, Val Acc: 0.6513
Epoch 8/100, Loss: 0.5567, Acc: 0.6994, Val Loss: 0.5975, Val Acc: 0.6528
Epoch 9/100, Loss: 0.5547, Acc: 0.6938, Val Loss: 0.6371, Val Acc: 0.6182
Epoch 10/100, Loss: 0.5486, Acc: 0.7018, Val Loss: 0.6524, Val Acc: 0.5666
Epoch 11/100, Loss: 0.5437, Acc: 0.7054, Val Loss: 0.6671, Val Acc: 0.5792
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5341, Acc: 0.7119, Val Loss: 0.6438, Val Acc: 0.5836
Epoch 13/100, Loss: 0.5318, Acc: 0.7094, Val Loss: 0.5801, Val Acc: 0.6591
Mejor modelo guardado con Val Loss: 0.5801
Epoch 14/100, Loss: 0.5312, Acc: 0.7108, Val Loss: 0.6133, Val Acc: 0.6130
Epoch 15/100, Loss: 0.5298, Acc: 0.7121, Val Loss: 0.6449, Val Acc: 0.5711
Epoch 16/100, Loss: 0.5312, Acc: 0.7117, Val Loss: 0.6364, Val Acc: 0.5832
Epoch 17/100, Loss: 0.5286, Acc: 0.7093, Val Loss: 0.6267, Val Acc: 0.5847
Epoch 18/100, Loss: 0.5254, Acc: 0.7128, Val Loss: 0.6562, Val Acc: 0.5659
Epoch 19/100, Loss: 0.5252, Acc: 0.7144, Val Loss: 0.6248, Val Acc: 0.5814
Epoch 20/100, Loss: 0.5243, Acc: 0.7119, Val Loss: 0.6630, Val Acc: 0.5468
Epoch 21/100, Loss: 0.5246, Acc: 0.7133, Val Loss: 0.6627, Val Acc: 0.5711
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5197, Acc: 0.7161, Val Loss: 0.6285, Val Acc: 0.5814
Epoch 23/100, Loss: 0.5212, Acc: 0.7156, Val Loss: 0.6515, Val Acc: 0.5530
Epoch 24/100, Loss: 0.5185, Acc: 0.7197, Val Loss: 0.6391, Val Acc: 0.5733
Epoch 25/100, Loss: 0.5172, Acc: 0.7194, Val Loss: 0.6344, Val Acc: 0.5644
Epoch 26/100, Loss: 0.5168, Acc: 0.7191, Val Loss: 0.6402, Val Acc: 0.5659
Epoch 27/100, Loss: 0.5176, Acc: 0.7158, Val Loss: 0.6423, Val Acc: 0.5604
Epoch 28/100, Loss: 0.5155, Acc: 0.7200, Val Loss: 0.6313, Val Acc: 0.5722
Epoch 29/100, Loss: 0.5158, Acc: 0.7183, Val Loss: 0.6257, Val Acc: 0.5876
Epoch 30/100, Loss: 0.5166, Acc: 0.7184, Val Loss: 0.6297, Val Acc: 0.5792
Epoch 31/100, Loss: 0.5147, Acc: 0.7171, Val Loss: 0.6417, Val Acc: 0.5655
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5124, Acc: 0.7194, Val Loss: 0.6421, Val Acc: 0.5596
Epoch 33/100, Loss: 0.5120, Acc: 0.7219, Val Loss: 0.6421, Val Acc: 0.5578
Epoch 34/100, Loss: 0.5130, Acc: 0.7194, Val Loss: 0.6352, Val Acc: 0.5633
Epoch 35/100, Loss: 0.5123, Acc: 0.7199, Val Loss: 0.6284, Val Acc: 0.5626
Epoch 36/100, Loss: 0.5111, Acc: 0.7204, Val Loss: 0.6286, Val Acc: 0.5814
Epoch 37/100, Loss: 0.5116, Acc: 0.7193, Val Loss: 0.6386, Val Acc: 0.5626
Epoch 38/100, Loss: 0.5103, Acc: 0.7196, Val Loss: 0.6426, Val Acc: 0.5515
Epoch 39/100, Loss: 0.5103, Acc: 0.7216, Val Loss: 0.6340, Val Acc: 0.5582
Epoch 40/100, Loss: 0.5112, Acc: 0.7210, Val Loss: 0.6363, Val Acc: 0.5574
Epoch 41/100, Loss: 0.5102, Acc: 0.7204, Val Loss: 0.6361, Val Acc: 0.5714
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5098, Acc: 0.7205, Val Loss: 0.6388, Val Acc: 0.5633
Epoch 43/100, Loss: 0.5085, Acc: 0.7226, Val Loss: 0.6386, Val Acc: 0.5530
Epoch 44/100, Loss: 0.5083, Acc: 0.7210, Val Loss: 0.6348, Val Acc: 0.5655
Epoch 45/100, Loss: 0.5079, Acc: 0.7209, Val Loss: 0.6374, Val Acc: 0.5641
Epoch 46/100, Loss: 0.5076, Acc: 0.7225, Val Loss: 0.6333, Val Acc: 0.5593
Epoch 47/100, Loss: 0.5075, Acc: 0.7229, Val Loss: 0.6331, Val Acc: 0.5600
Epoch 48/100, Loss: 0.5075, Acc: 0.7216, Val Loss: 0.6307, Val Acc: 0.5644
Epoch 49/100, Loss: 0.5069, Acc: 0.7226, Val Loss: 0.6248, Val Acc: 0.5692
Epoch 50/100, Loss: 0.5073, Acc: 0.7230, Val Loss: 0.6333, Val Acc: 0.5637
Epoch 51/100, Loss: 0.5070, Acc: 0.7214, Val Loss: 0.6453, Val Acc: 0.5541
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5063, Acc: 0.7227, Val Loss: 0.6341, Val Acc: 0.5626
Epoch 53/100, Loss: 0.5059, Acc: 0.7242, Val Loss: 0.6323, Val Acc: 0.5677
Epoch 54/100, Loss: 0.5060, Acc: 0.7234, Val Loss: 0.6364, Val Acc: 0.5608
Epoch 55/100, Loss: 0.5058, Acc: 0.7229, Val Loss: 0.6379, Val Acc: 0.5600
Epoch 56/100, Loss: 0.5058, Acc: 0.7217, Val Loss: 0.6336, Val Acc: 0.5677
Epoch 57/100, Loss: 0.5056, Acc: 0.7225, Val Loss: 0.6319, Val Acc: 0.5652
Epoch 58/100, Loss: 0.5055, Acc: 0.7224, Val Loss: 0.6398, Val Acc: 0.5604
Epoch 59/100, Loss: 0.5054, Acc: 0.7238, Val Loss: 0.6407, Val Acc: 0.5589
Epoch 60/100, Loss: 0.5055, Acc: 0.7235, Val Loss: 0.6365, Val Acc: 0.5630
Epoch 61/100, Loss: 0.5052, Acc: 0.7236, Val Loss: 0.6355, Val Acc: 0.5622
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5050, Acc: 0.7240, Val Loss: 0.6385, Val Acc: 0.5630
Epoch 63/100, Loss: 0.5049, Acc: 0.7237, Val Loss: 0.6375, Val Acc: 0.5596
Epoch 64/100, Loss: 0.5049, Acc: 0.7231, Val Loss: 0.6326, Val Acc: 0.5674
Epoch 65/100, Loss: 0.5047, Acc: 0.7246, Val Loss: 0.6379, Val Acc: 0.5593
Epoch 66/100, Loss: 0.5047, Acc: 0.7232, Val Loss: 0.6407, Val Acc: 0.5585
Epoch 67/100, Loss: 0.5045, Acc: 0.7240, Val Loss: 0.6341, Val Acc: 0.5655
Epoch 68/100, Loss: 0.5049, Acc: 0.7238, Val Loss: 0.6441, Val Acc: 0.5527
Epoch 69/100, Loss: 0.5044, Acc: 0.7245, Val Loss: 0.6441, Val Acc: 0.5504
Epoch 70/100, Loss: 0.5043, Acc: 0.7239, Val Loss: 0.6435, Val Acc: 0.5552
Epoch 71/100, Loss: 0.5042, Acc: 0.7239, Val Loss: 0.6438, Val Acc: 0.5519
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5041, Acc: 0.7246, Val Loss: 0.6422, Val Acc: 0.5552
Epoch 73/100, Loss: 0.5039, Acc: 0.7248, Val Loss: 0.6458, Val Acc: 0.5482
Epoch 74/100, Loss: 0.5039, Acc: 0.7255, Val Loss: 0.6438, Val Acc: 0.5538
Epoch 75/100, Loss: 0.5039, Acc: 0.7243, Val Loss: 0.6451, Val Acc: 0.5482
Epoch 76/100, Loss: 0.5039, Acc: 0.7245, Val Loss: 0.6447, Val Acc: 0.5486
Epoch 77/100, Loss: 0.5038, Acc: 0.7250, Val Loss: 0.6459, Val Acc: 0.5482
Epoch 78/100, Loss: 0.5037, Acc: 0.7246, Val Loss: 0.6462, Val Acc: 0.5468
Epoch 79/100, Loss: 0.5039, Acc: 0.7253, Val Loss: 0.6454, Val Acc: 0.5486
Epoch 80/100, Loss: 0.5037, Acc: 0.7243, Val Loss: 0.6432, Val Acc: 0.5538
Epoch 81/100, Loss: 0.5037, Acc: 0.7243, Val Loss: 0.6462, Val Acc: 0.5490
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5037, Acc: 0.7249, Val Loss: 0.6436, Val Acc: 0.5538
Epoch 83/100, Loss: 0.5036, Acc: 0.7253, Val Loss: 0.6447, Val Acc: 0.5490
Epoch 84/100, Loss: 0.5036, Acc: 0.7250, Val Loss: 0.6449, Val Acc: 0.5493
Epoch 85/100, Loss: 0.5036, Acc: 0.7254, Val Loss: 0.6459, Val Acc: 0.5479
Epoch 86/100, Loss: 0.5036, Acc: 0.7252, Val Loss: 0.6453, Val Acc: 0.5493
Epoch 87/100, Loss: 0.5036, Acc: 0.7241, Val Loss: 0.6439, Val Acc: 0.5519
Epoch 88/100, Loss: 0.5035, Acc: 0.7246, Val Loss: 0.6438, Val Acc: 0.5501
Epoch 89/100, Loss: 0.5032, Acc: 0.7245, Val Loss: 0.6409, Val Acc: 0.5527
Epoch 90/100, Loss: 0.5032, Acc: 0.7253, Val Loss: 0.6437, Val Acc: 0.5475
Epoch 91/100, Loss: 0.5033, Acc: 0.7251, Val Loss: 0.6440, Val Acc: 0.5479
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5032, Acc: 0.7249, Val Loss: 0.6441, Val Acc: 0.5479
Epoch 93/100, Loss: 0.5032, Acc: 0.7243, Val Loss: 0.6430, Val Acc: 0.5508
Epoch 94/100, Loss: 0.5032, Acc: 0.7255, Val Loss: 0.6429, Val Acc: 0.5504
Epoch 95/100, Loss: 0.5032, Acc: 0.7248, Val Loss: 0.6426, Val Acc: 0.5501
Epoch 96/100, Loss: 0.5031, Acc: 0.7248, Val Loss: 0.6423, Val Acc: 0.5530
Epoch 97/100, Loss: 0.5030, Acc: 0.7252, Val Loss: 0.6439, Val Acc: 0.5479
Epoch 98/100, Loss: 0.5030, Acc: 0.7255, Val Loss: 0.6444, Val Acc: 0.5493
Epoch 99/100, Loss: 0.5031, Acc: 0.7251, Val Loss: 0.6442, Val Acc: 0.5515
Epoch 100/100, Loss: 0.5029, Acc: 0.7257, Val Loss: 0.6434, Val Acc: 0.5504

##############################
Resultados para principal:  117  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  5 
 {'training': [0.5029065506933541, 0.7257263699889666, 0.6585239757011762, 0.9372700515084621, 0.7735519623472253], 'validate': [0.6433622015770092, 0.5504418262150221, 0.5286138194150064, 0.9196165191740413, 0.6713324360699865], 'test': [0.3946539769294085, 0.8730859835100118, 0.8344791115811739, 0.9304245283018868, 0.8798438806802342]}

##############################
Resultados para window:  5 
 {'007:111:001:082:103:117': {'training': [0.16462616112224315, 0.9331555719014344, 0.9284804367606916, 0.9385577630610743, 0.9334919037599487], 'validate': [0.33805460867277065, 0.8479381443298969, 0.7668364459535937, 0.9992625368731564, 0.8677553634325968], 'test': [0.09146094915491564, 0.9749705535924618, 1.0, 0.9498820754716981, 0.9742969458723919]}, '111:007:001:082:103:117': {'training': [0.2865416484968151, 0.8744942993747702, 0.8723248582403512, 0.8772994849153789, 0.8748050995138953], 'validate': [0.16784759517759085, 0.9377761413843888, 0.8975217682518419, 0.9882005899705014, 0.9406809406809407], 'test': [1.6081577173813626, 0.36012956419316844, 0.39957894736842103, 0.5595518867924528, 0.46622451486121347]}, '001:007:111:082:103:117': {'training': [0.38873389309581124, 0.8166605369621184, 0.7977508650519031, 0.8482339955849889, 0.8222182596291013], 'validate': [0.8486862610592398, 0.5349779086892489, 0.5218823529411765, 0.8178466076696165, 0.6371732260844585], 'test': [0.5898630260317413, 0.6413427561837456, 0.6697443181818182, 0.5560141509433962, 0.6076030927835051]}, '082:007:111:001:103:117': {'training': [0.6162980340473263, 0.7095439499816109, 0.6764842660052705, 0.8027961736571008, 0.7342474972659208], 'validate': [0.6951758417972299, 0.5526509572901326, 0.5334598955861415, 0.8289085545722714, 0.6491481374530753], 'test': [0.6368897601410195, 0.7629564193168433, 0.7197829304390725, 0.8602594339622641, 0.7837765243083534]}, '103:007:111:001:082:117': {'training': [0.44945554158493806, 0.7796984185362266, 0.7134831460674157, 0.9345106696100074, 0.809174896463842], 'validate': [0.7525841136311375, 0.5371870397643593, 0.5208421052631579, 0.9122418879056047, 0.6630930045564192], 'test': [0.5448615275047444, 0.8571849234393404, 0.8584961515689757, 0.8549528301886793, 0.8567208271787297]}, '117:007:111:001:082:103': {'training': [0.5029065506933541, 0.7257263699889666, 0.6585239757011762, 0.9372700515084621, 0.7735519623472253], 'validate': [0.6433622015770092, 0.5504418262150221, 0.5286138194150064, 0.9196165191740413, 0.6713324360699865], 'test': [0.3946539769294085, 0.8730859835100118, 0.8344791115811739, 0.9304245283018868, 0.8798438806802342]}}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  067  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  067  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  067  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5585, Acc: 0.7703, Val Loss: 0.4663, Val Acc: 0.8351
Mejor modelo guardado con Val Loss: 0.4663
Epoch 2/100, Loss: 0.4729, Acc: 0.7953, Val Loss: 0.4356, Val Acc: 0.8203
Mejor modelo guardado con Val Loss: 0.4356
Epoch 3/100, Loss: 0.4565, Acc: 0.7964, Val Loss: 0.4479, Val Acc: 0.8417
Epoch 4/100, Loss: 0.4549, Acc: 0.7964, Val Loss: 0.4399, Val Acc: 0.8671
Epoch 5/100, Loss: 0.4525, Acc: 0.7942, Val Loss: 0.4181, Val Acc: 0.8424
Mejor modelo guardado con Val Loss: 0.4181
Epoch 6/100, Loss: 0.4468, Acc: 0.7985, Val Loss: 0.4232, Val Acc: 0.8457
Epoch 7/100, Loss: 0.4469, Acc: 0.8007, Val Loss: 0.3698, Val Acc: 0.8722
Mejor modelo guardado con Val Loss: 0.3698
Epoch 8/100, Loss: 0.4507, Acc: 0.7938, Val Loss: 0.4483, Val Acc: 0.7927
Epoch 9/100, Loss: 0.4457, Acc: 0.7982, Val Loss: 0.4206, Val Acc: 0.8247
Epoch 10/100, Loss: 0.4455, Acc: 0.8006, Val Loss: 0.3733, Val Acc: 0.8564
Epoch 11/100, Loss: 0.4423, Acc: 0.8013, Val Loss: 0.4399, Val Acc: 0.8004
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4331, Acc: 0.8058, Val Loss: 0.3877, Val Acc: 0.8428
Epoch 13/100, Loss: 0.4355, Acc: 0.8019, Val Loss: 0.3612, Val Acc: 0.8686
Mejor modelo guardado con Val Loss: 0.3612
Epoch 14/100, Loss: 0.4342, Acc: 0.8042, Val Loss: 0.4058, Val Acc: 0.8351
Epoch 15/100, Loss: 0.4309, Acc: 0.8061, Val Loss: 0.3791, Val Acc: 0.8767
Epoch 16/100, Loss: 0.4345, Acc: 0.8035, Val Loss: 0.4016, Val Acc: 0.8181
Epoch 17/100, Loss: 0.4342, Acc: 0.8037, Val Loss: 0.4053, Val Acc: 0.8339
Epoch 18/100, Loss: 0.4302, Acc: 0.8048, Val Loss: 0.3765, Val Acc: 0.8505
Epoch 19/100, Loss: 0.4327, Acc: 0.8027, Val Loss: 0.4100, Val Acc: 0.8284
Epoch 20/100, Loss: 0.4265, Acc: 0.8073, Val Loss: 0.3899, Val Acc: 0.8365
Epoch 21/100, Loss: 0.4243, Acc: 0.8108, Val Loss: 0.4629, Val Acc: 0.7850
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4221, Acc: 0.8093, Val Loss: 0.4026, Val Acc: 0.8468
Epoch 23/100, Loss: 0.4221, Acc: 0.8085, Val Loss: 0.4318, Val Acc: 0.8192
Epoch 24/100, Loss: 0.4200, Acc: 0.8087, Val Loss: 0.4170, Val Acc: 0.8200
Epoch 25/100, Loss: 0.4223, Acc: 0.8077, Val Loss: 0.4223, Val Acc: 0.8108
Epoch 26/100, Loss: 0.4190, Acc: 0.8113, Val Loss: 0.3727, Val Acc: 0.8490
Epoch 27/100, Loss: 0.4174, Acc: 0.8102, Val Loss: 0.4102, Val Acc: 0.8328
Epoch 28/100, Loss: 0.4163, Acc: 0.8134, Val Loss: 0.4003, Val Acc: 0.8420
Epoch 29/100, Loss: 0.4160, Acc: 0.8143, Val Loss: 0.3882, Val Acc: 0.8538
Epoch 30/100, Loss: 0.4173, Acc: 0.8088, Val Loss: 0.4122, Val Acc: 0.8310
Epoch 31/100, Loss: 0.4171, Acc: 0.8118, Val Loss: 0.3960, Val Acc: 0.8358
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4132, Acc: 0.8148, Val Loss: 0.3989, Val Acc: 0.8336
Epoch 33/100, Loss: 0.4130, Acc: 0.8134, Val Loss: 0.3977, Val Acc: 0.8373
Epoch 34/100, Loss: 0.4125, Acc: 0.8145, Val Loss: 0.3924, Val Acc: 0.8406
Epoch 35/100, Loss: 0.4113, Acc: 0.8154, Val Loss: 0.3874, Val Acc: 0.8417
Epoch 36/100, Loss: 0.4113, Acc: 0.8169, Val Loss: 0.4226, Val Acc: 0.8174
Epoch 37/100, Loss: 0.4111, Acc: 0.8153, Val Loss: 0.4176, Val Acc: 0.8251
Epoch 38/100, Loss: 0.4115, Acc: 0.8121, Val Loss: 0.4104, Val Acc: 0.8292
Epoch 39/100, Loss: 0.4113, Acc: 0.8142, Val Loss: 0.4304, Val Acc: 0.8108
Epoch 40/100, Loss: 0.4103, Acc: 0.8133, Val Loss: 0.4005, Val Acc: 0.8328
Epoch 41/100, Loss: 0.4097, Acc: 0.8155, Val Loss: 0.4002, Val Acc: 0.8347
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4086, Acc: 0.8150, Val Loss: 0.4034, Val Acc: 0.8376
Epoch 43/100, Loss: 0.4095, Acc: 0.8141, Val Loss: 0.3996, Val Acc: 0.8384
Epoch 44/100, Loss: 0.4082, Acc: 0.8166, Val Loss: 0.3984, Val Acc: 0.8417
Epoch 45/100, Loss: 0.4080, Acc: 0.8164, Val Loss: 0.3985, Val Acc: 0.8376
Epoch 46/100, Loss: 0.4078, Acc: 0.8164, Val Loss: 0.4054, Val Acc: 0.8303
Epoch 47/100, Loss: 0.4081, Acc: 0.8156, Val Loss: 0.3975, Val Acc: 0.8384
Epoch 48/100, Loss: 0.4075, Acc: 0.8153, Val Loss: 0.3927, Val Acc: 0.8409
Epoch 49/100, Loss: 0.4072, Acc: 0.8155, Val Loss: 0.3978, Val Acc: 0.8391
Epoch 50/100, Loss: 0.4076, Acc: 0.8152, Val Loss: 0.3972, Val Acc: 0.8395
Epoch 51/100, Loss: 0.4071, Acc: 0.8164, Val Loss: 0.3912, Val Acc: 0.8395
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4067, Acc: 0.8160, Val Loss: 0.4059, Val Acc: 0.8328
Epoch 53/100, Loss: 0.4066, Acc: 0.8151, Val Loss: 0.3963, Val Acc: 0.8387
Epoch 54/100, Loss: 0.4063, Acc: 0.8167, Val Loss: 0.3975, Val Acc: 0.8369
Epoch 55/100, Loss: 0.4064, Acc: 0.8156, Val Loss: 0.3995, Val Acc: 0.8358
Epoch 56/100, Loss: 0.4064, Acc: 0.8171, Val Loss: 0.3963, Val Acc: 0.8384
Epoch 57/100, Loss: 0.4061, Acc: 0.8154, Val Loss: 0.4048, Val Acc: 0.8325
Epoch 58/100, Loss: 0.4063, Acc: 0.8167, Val Loss: 0.3987, Val Acc: 0.8380
Epoch 59/100, Loss: 0.4058, Acc: 0.8172, Val Loss: 0.3966, Val Acc: 0.8409
Epoch 60/100, Loss: 0.4060, Acc: 0.8151, Val Loss: 0.4010, Val Acc: 0.8362
Epoch 61/100, Loss: 0.4055, Acc: 0.8181, Val Loss: 0.3951, Val Acc: 0.8406
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4055, Acc: 0.8174, Val Loss: 0.4056, Val Acc: 0.8328
Epoch 63/100, Loss: 0.4054, Acc: 0.8165, Val Loss: 0.4019, Val Acc: 0.8358
Epoch 64/100, Loss: 0.4053, Acc: 0.8167, Val Loss: 0.4000, Val Acc: 0.8380
Epoch 65/100, Loss: 0.4051, Acc: 0.8169, Val Loss: 0.4000, Val Acc: 0.8387
Epoch 66/100, Loss: 0.4051, Acc: 0.8167, Val Loss: 0.4023, Val Acc: 0.8373
Epoch 67/100, Loss: 0.4050, Acc: 0.8166, Val Loss: 0.4017, Val Acc: 0.8376
Epoch 68/100, Loss: 0.4051, Acc: 0.8171, Val Loss: 0.4043, Val Acc: 0.8351
Epoch 69/100, Loss: 0.4050, Acc: 0.8168, Val Loss: 0.3980, Val Acc: 0.8376
Epoch 70/100, Loss: 0.4051, Acc: 0.8165, Val Loss: 0.3970, Val Acc: 0.8380
Epoch 71/100, Loss: 0.4049, Acc: 0.8169, Val Loss: 0.4041, Val Acc: 0.8354
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4048, Acc: 0.8174, Val Loss: 0.3989, Val Acc: 0.8384
Epoch 73/100, Loss: 0.4048, Acc: 0.8171, Val Loss: 0.3985, Val Acc: 0.8380
Epoch 74/100, Loss: 0.4047, Acc: 0.8172, Val Loss: 0.4053, Val Acc: 0.8339
Epoch 75/100, Loss: 0.4046, Acc: 0.8167, Val Loss: 0.3956, Val Acc: 0.8402
Epoch 76/100, Loss: 0.4048, Acc: 0.8170, Val Loss: 0.3988, Val Acc: 0.8380
Epoch 77/100, Loss: 0.4046, Acc: 0.8175, Val Loss: 0.3997, Val Acc: 0.8384
Epoch 78/100, Loss: 0.4046, Acc: 0.8175, Val Loss: 0.3994, Val Acc: 0.8376
Epoch 79/100, Loss: 0.4046, Acc: 0.8168, Val Loss: 0.4007, Val Acc: 0.8373
Epoch 80/100, Loss: 0.4046, Acc: 0.8174, Val Loss: 0.4009, Val Acc: 0.8369
Epoch 81/100, Loss: 0.4046, Acc: 0.8173, Val Loss: 0.4025, Val Acc: 0.8362
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4045, Acc: 0.8171, Val Loss: 0.4021, Val Acc: 0.8373
Epoch 83/100, Loss: 0.4046, Acc: 0.8165, Val Loss: 0.4000, Val Acc: 0.8380
Epoch 84/100, Loss: 0.4045, Acc: 0.8170, Val Loss: 0.4012, Val Acc: 0.8369
Epoch 85/100, Loss: 0.4045, Acc: 0.8169, Val Loss: 0.4008, Val Acc: 0.8373
Epoch 86/100, Loss: 0.4045, Acc: 0.8163, Val Loss: 0.4019, Val Acc: 0.8358
Epoch 87/100, Loss: 0.4044, Acc: 0.8171, Val Loss: 0.3992, Val Acc: 0.8380
Epoch 88/100, Loss: 0.4044, Acc: 0.8167, Val Loss: 0.4031, Val Acc: 0.8358
Epoch 89/100, Loss: 0.4043, Acc: 0.8178, Val Loss: 0.3996, Val Acc: 0.8376
Epoch 90/100, Loss: 0.4044, Acc: 0.8167, Val Loss: 0.3997, Val Acc: 0.8380
Epoch 91/100, Loss: 0.4043, Acc: 0.8175, Val Loss: 0.4043, Val Acc: 0.8365
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4044, Acc: 0.8168, Val Loss: 0.4032, Val Acc: 0.8358
Epoch 93/100, Loss: 0.4042, Acc: 0.8168, Val Loss: 0.4012, Val Acc: 0.8376
Epoch 94/100, Loss: 0.4042, Acc: 0.8160, Val Loss: 0.3985, Val Acc: 0.8380
Epoch 95/100, Loss: 0.4042, Acc: 0.8172, Val Loss: 0.3997, Val Acc: 0.8380
Epoch 96/100, Loss: 0.4042, Acc: 0.8173, Val Loss: 0.3972, Val Acc: 0.8380
Epoch 97/100, Loss: 0.4042, Acc: 0.8176, Val Loss: 0.4031, Val Acc: 0.8362
Epoch 98/100, Loss: 0.4041, Acc: 0.8176, Val Loss: 0.4052, Val Acc: 0.8343
Epoch 99/100, Loss: 0.4041, Acc: 0.8173, Val Loss: 0.4039, Val Acc: 0.8358
Epoch 100/100, Loss: 0.4041, Acc: 0.8166, Val Loss: 0.4050, Val Acc: 0.8351

##############################
Resultados para principal:  067  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5 
 {'training': [0.40409018946027175, 0.8165685913938948, 0.8473652331920049, 0.772075055187638, 0.8079699682356338], 'validate': [0.405043731248656, 0.8350515463917526, 0.7959582790091264, 0.9004424778761062, 0.8449826989619377], 'test': [0.805612392378626, 0.6604829210836278, 0.6850715746421268, 0.5925707547169812, 0.6354726525450521]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  124  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  124  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  124  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6825, Acc: 0.5837, Val Loss: 0.6744, Val Acc: 0.5007
Mejor modelo guardado con Val Loss: 0.6744
Epoch 2/100, Loss: 0.6654, Acc: 0.6398, Val Loss: 0.6536, Val Acc: 0.6999
Mejor modelo guardado con Val Loss: 0.6536
Epoch 3/100, Loss: 0.6376, Acc: 0.6901, Val Loss: 0.6414, Val Acc: 0.6517
Mejor modelo guardado con Val Loss: 0.6414
Epoch 4/100, Loss: 0.6142, Acc: 0.7101, Val Loss: 0.6670, Val Acc: 0.5976
Epoch 5/100, Loss: 0.5914, Acc: 0.7263, Val Loss: 0.6203, Val Acc: 0.6727
Mejor modelo guardado con Val Loss: 0.6203
Epoch 6/100, Loss: 0.5791, Acc: 0.7266, Val Loss: 0.6500, Val Acc: 0.6208
Epoch 7/100, Loss: 0.5673, Acc: 0.7329, Val Loss: 0.6297, Val Acc: 0.6421
Epoch 8/100, Loss: 0.5654, Acc: 0.7253, Val Loss: 0.6314, Val Acc: 0.6506
Epoch 9/100, Loss: 0.5614, Acc: 0.7289, Val Loss: 0.6924, Val Acc: 0.5777
Epoch 10/100, Loss: 0.5565, Acc: 0.7277, Val Loss: 0.6446, Val Acc: 0.6366
Epoch 11/100, Loss: 0.5504, Acc: 0.7334, Val Loss: 0.7091, Val Acc: 0.5744
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5396, Acc: 0.7414, Val Loss: 0.6351, Val Acc: 0.6499
Epoch 13/100, Loss: 0.5371, Acc: 0.7408, Val Loss: 0.7234, Val Acc: 0.5648
Epoch 14/100, Loss: 0.5342, Acc: 0.7424, Val Loss: 0.6885, Val Acc: 0.5854
Epoch 15/100, Loss: 0.5373, Acc: 0.7408, Val Loss: 0.6200, Val Acc: 0.6535
Mejor modelo guardado con Val Loss: 0.6200
Epoch 16/100, Loss: 0.5276, Acc: 0.7460, Val Loss: 0.6666, Val Acc: 0.6248
Epoch 17/100, Loss: 0.5185, Acc: 0.7507, Val Loss: 0.6554, Val Acc: 0.6256
Epoch 18/100, Loss: 0.5191, Acc: 0.7476, Val Loss: 0.7637, Val Acc: 0.5324
Epoch 19/100, Loss: 0.5160, Acc: 0.7535, Val Loss: 0.6773, Val Acc: 0.6215
Epoch 20/100, Loss: 0.5153, Acc: 0.7550, Val Loss: 0.6888, Val Acc: 0.6005
Epoch 21/100, Loss: 0.5133, Acc: 0.7525, Val Loss: 0.6836, Val Acc: 0.6138
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5062, Acc: 0.7574, Val Loss: 0.7065, Val Acc: 0.5935
Epoch 23/100, Loss: 0.5063, Acc: 0.7596, Val Loss: 0.7240, Val Acc: 0.5733
Epoch 24/100, Loss: 0.5056, Acc: 0.7586, Val Loss: 0.7275, Val Acc: 0.5773
Epoch 25/100, Loss: 0.5048, Acc: 0.7579, Val Loss: 0.7129, Val Acc: 0.5920
Epoch 26/100, Loss: 0.5034, Acc: 0.7596, Val Loss: 0.6812, Val Acc: 0.6141
Epoch 27/100, Loss: 0.5042, Acc: 0.7586, Val Loss: 0.7326, Val Acc: 0.5847
Epoch 28/100, Loss: 0.5023, Acc: 0.7620, Val Loss: 0.7805, Val Acc: 0.5302
Epoch 29/100, Loss: 0.5024, Acc: 0.7601, Val Loss: 0.7066, Val Acc: 0.5950
Epoch 30/100, Loss: 0.5003, Acc: 0.7629, Val Loss: 0.6837, Val Acc: 0.6145
Epoch 31/100, Loss: 0.4996, Acc: 0.7622, Val Loss: 0.6705, Val Acc: 0.6259
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4963, Acc: 0.7662, Val Loss: 0.7351, Val Acc: 0.5832
Epoch 33/100, Loss: 0.4966, Acc: 0.7655, Val Loss: 0.7496, Val Acc: 0.5596
Epoch 34/100, Loss: 0.4957, Acc: 0.7646, Val Loss: 0.6998, Val Acc: 0.6097
Epoch 35/100, Loss: 0.4955, Acc: 0.7639, Val Loss: 0.7507, Val Acc: 0.5648
Epoch 36/100, Loss: 0.4945, Acc: 0.7645, Val Loss: 0.7180, Val Acc: 0.5983
Epoch 37/100, Loss: 0.4937, Acc: 0.7658, Val Loss: 0.7100, Val Acc: 0.6053
Epoch 38/100, Loss: 0.4943, Acc: 0.7655, Val Loss: 0.7354, Val Acc: 0.5758
Epoch 39/100, Loss: 0.4940, Acc: 0.7663, Val Loss: 0.7218, Val Acc: 0.5990
Epoch 40/100, Loss: 0.4941, Acc: 0.7654, Val Loss: 0.7596, Val Acc: 0.5677
Epoch 41/100, Loss: 0.4926, Acc: 0.7660, Val Loss: 0.7276, Val Acc: 0.5961
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4916, Acc: 0.7685, Val Loss: 0.7138, Val Acc: 0.6016
Epoch 43/100, Loss: 0.4914, Acc: 0.7693, Val Loss: 0.7102, Val Acc: 0.6031
Epoch 44/100, Loss: 0.4908, Acc: 0.7671, Val Loss: 0.7574, Val Acc: 0.5696
Epoch 45/100, Loss: 0.4915, Acc: 0.7669, Val Loss: 0.7483, Val Acc: 0.5677
Epoch 46/100, Loss: 0.4908, Acc: 0.7672, Val Loss: 0.7368, Val Acc: 0.5718
Epoch 47/100, Loss: 0.4902, Acc: 0.7684, Val Loss: 0.7401, Val Acc: 0.5873
Epoch 48/100, Loss: 0.4907, Acc: 0.7677, Val Loss: 0.7158, Val Acc: 0.6001
Epoch 49/100, Loss: 0.4904, Acc: 0.7676, Val Loss: 0.7380, Val Acc: 0.5777
Epoch 50/100, Loss: 0.4897, Acc: 0.7667, Val Loss: 0.7513, Val Acc: 0.5641
Epoch 51/100, Loss: 0.4895, Acc: 0.7684, Val Loss: 0.7281, Val Acc: 0.5968
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4893, Acc: 0.7688, Val Loss: 0.7199, Val Acc: 0.5972
Epoch 53/100, Loss: 0.4887, Acc: 0.7685, Val Loss: 0.7299, Val Acc: 0.5847
Epoch 54/100, Loss: 0.4883, Acc: 0.7677, Val Loss: 0.7312, Val Acc: 0.5869
Epoch 55/100, Loss: 0.4882, Acc: 0.7695, Val Loss: 0.7187, Val Acc: 0.5987
Epoch 56/100, Loss: 0.4881, Acc: 0.7692, Val Loss: 0.7245, Val Acc: 0.5928
Epoch 57/100, Loss: 0.4878, Acc: 0.7699, Val Loss: 0.7410, Val Acc: 0.5858
Epoch 58/100, Loss: 0.4881, Acc: 0.7699, Val Loss: 0.7338, Val Acc: 0.5847
Epoch 59/100, Loss: 0.4883, Acc: 0.7693, Val Loss: 0.7436, Val Acc: 0.5828
Epoch 60/100, Loss: 0.4874, Acc: 0.7695, Val Loss: 0.7252, Val Acc: 0.5902
Epoch 61/100, Loss: 0.4876, Acc: 0.7700, Val Loss: 0.7368, Val Acc: 0.5788
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4874, Acc: 0.7686, Val Loss: 0.7379, Val Acc: 0.5792
Epoch 63/100, Loss: 0.4872, Acc: 0.7682, Val Loss: 0.7388, Val Acc: 0.5828
Epoch 64/100, Loss: 0.4872, Acc: 0.7702, Val Loss: 0.7288, Val Acc: 0.5917
Epoch 65/100, Loss: 0.4872, Acc: 0.7696, Val Loss: 0.7270, Val Acc: 0.5928
Epoch 66/100, Loss: 0.4871, Acc: 0.7686, Val Loss: 0.7226, Val Acc: 0.5965
Epoch 67/100, Loss: 0.4870, Acc: 0.7690, Val Loss: 0.7382, Val Acc: 0.5814
Epoch 68/100, Loss: 0.4870, Acc: 0.7701, Val Loss: 0.7329, Val Acc: 0.5851
Epoch 69/100, Loss: 0.4868, Acc: 0.7694, Val Loss: 0.7261, Val Acc: 0.5961
Epoch 70/100, Loss: 0.4869, Acc: 0.7685, Val Loss: 0.7325, Val Acc: 0.5873
Epoch 71/100, Loss: 0.4868, Acc: 0.7691, Val Loss: 0.7354, Val Acc: 0.5880
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4867, Acc: 0.7698, Val Loss: 0.7324, Val Acc: 0.5876
Epoch 73/100, Loss: 0.4866, Acc: 0.7686, Val Loss: 0.7310, Val Acc: 0.5891
Epoch 74/100, Loss: 0.4866, Acc: 0.7688, Val Loss: 0.7305, Val Acc: 0.5898
Epoch 75/100, Loss: 0.4865, Acc: 0.7696, Val Loss: 0.7317, Val Acc: 0.5869
Epoch 76/100, Loss: 0.4866, Acc: 0.7688, Val Loss: 0.7340, Val Acc: 0.5873
Epoch 77/100, Loss: 0.4864, Acc: 0.7686, Val Loss: 0.7396, Val Acc: 0.5803
Epoch 78/100, Loss: 0.4864, Acc: 0.7692, Val Loss: 0.7342, Val Acc: 0.5862
Epoch 79/100, Loss: 0.4864, Acc: 0.7691, Val Loss: 0.7348, Val Acc: 0.5851
Epoch 80/100, Loss: 0.4862, Acc: 0.7707, Val Loss: 0.7415, Val Acc: 0.5806
Epoch 81/100, Loss: 0.4863, Acc: 0.7696, Val Loss: 0.7397, Val Acc: 0.5803
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4861, Acc: 0.7683, Val Loss: 0.7372, Val Acc: 0.5832
Epoch 83/100, Loss: 0.4860, Acc: 0.7689, Val Loss: 0.7400, Val Acc: 0.5806
Epoch 84/100, Loss: 0.4860, Acc: 0.7693, Val Loss: 0.7354, Val Acc: 0.5836
Epoch 85/100, Loss: 0.4859, Acc: 0.7688, Val Loss: 0.7371, Val Acc: 0.5828
Epoch 86/100, Loss: 0.4858, Acc: 0.7698, Val Loss: 0.7325, Val Acc: 0.5876
Epoch 87/100, Loss: 0.4858, Acc: 0.7684, Val Loss: 0.7293, Val Acc: 0.5898
Epoch 88/100, Loss: 0.4858, Acc: 0.7699, Val Loss: 0.7379, Val Acc: 0.5825
Epoch 89/100, Loss: 0.4859, Acc: 0.7687, Val Loss: 0.7347, Val Acc: 0.5851
Epoch 90/100, Loss: 0.4857, Acc: 0.7701, Val Loss: 0.7372, Val Acc: 0.5832
Epoch 91/100, Loss: 0.4858, Acc: 0.7694, Val Loss: 0.7379, Val Acc: 0.5821
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4857, Acc: 0.7700, Val Loss: 0.7329, Val Acc: 0.5865
Epoch 93/100, Loss: 0.4855, Acc: 0.7691, Val Loss: 0.7381, Val Acc: 0.5836
Epoch 94/100, Loss: 0.4854, Acc: 0.7698, Val Loss: 0.7477, Val Acc: 0.5762
Epoch 95/100, Loss: 0.4856, Acc: 0.7696, Val Loss: 0.7342, Val Acc: 0.5858
Epoch 96/100, Loss: 0.4854, Acc: 0.7686, Val Loss: 0.7372, Val Acc: 0.5821
Epoch 97/100, Loss: 0.4855, Acc: 0.7692, Val Loss: 0.7313, Val Acc: 0.5887
Epoch 98/100, Loss: 0.4854, Acc: 0.7689, Val Loss: 0.7401, Val Acc: 0.5821
Epoch 99/100, Loss: 0.4853, Acc: 0.7705, Val Loss: 0.7371, Val Acc: 0.5832
Epoch 100/100, Loss: 0.4854, Acc: 0.7711, Val Loss: 0.7388, Val Acc: 0.5821

##############################
Resultados para principal:  124  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5 
 {'training': [0.4853527890535434, 0.7711474806914307, 0.7511505028123402, 0.8107064017660044, 0.7797929753162877], 'validate': [0.7387869468955106, 0.5821060382916053, 0.5598915989159892, 0.7617994100294986, 0.6454233052171197], 'test': [0.7776274250613319, 0.5082449941107184, 0.504590395480226, 0.8425707547169812, 0.6311837455830389]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  010  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  010  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  010  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6149, Acc: 0.6740, Val Loss: 0.7492, Val Acc: 0.4429
Mejor modelo guardado con Val Loss: 0.7492
Epoch 2/100, Loss: 0.5763, Acc: 0.7014, Val Loss: 0.7399, Val Acc: 0.4499
Mejor modelo guardado con Val Loss: 0.7399
Epoch 3/100, Loss: 0.5555, Acc: 0.7141, Val Loss: 0.8101, Val Acc: 0.4521
Epoch 4/100, Loss: 0.5536, Acc: 0.7146, Val Loss: 0.8171, Val Acc: 0.4823
Epoch 5/100, Loss: 0.5520, Acc: 0.7127, Val Loss: 0.7850, Val Acc: 0.4750
Epoch 6/100, Loss: 0.5484, Acc: 0.7210, Val Loss: 0.7932, Val Acc: 0.4728
Epoch 7/100, Loss: 0.5461, Acc: 0.7175, Val Loss: 0.7853, Val Acc: 0.4562
Epoch 8/100, Loss: 0.5473, Acc: 0.7159, Val Loss: 0.7691, Val Acc: 0.4532
Epoch 9/100, Loss: 0.5429, Acc: 0.7183, Val Loss: 0.7877, Val Acc: 0.4665
Epoch 10/100, Loss: 0.5419, Acc: 0.7192, Val Loss: 0.7952, Val Acc: 0.5361
Epoch 11/100, Loss: 0.5432, Acc: 0.7198, Val Loss: 0.8451, Val Acc: 0.4448
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5330, Acc: 0.7251, Val Loss: 0.8274, Val Acc: 0.4606
Epoch 13/100, Loss: 0.5309, Acc: 0.7276, Val Loss: 0.8884, Val Acc: 0.4904
Epoch 14/100, Loss: 0.5284, Acc: 0.7279, Val Loss: 0.8816, Val Acc: 0.4731
Epoch 15/100, Loss: 0.5309, Acc: 0.7243, Val Loss: 0.8250, Val Acc: 0.4746
Epoch 16/100, Loss: 0.5250, Acc: 0.7300, Val Loss: 0.8920, Val Acc: 0.4742
Epoch 17/100, Loss: 0.5308, Acc: 0.7227, Val Loss: 0.7953, Val Acc: 0.4562
Epoch 18/100, Loss: 0.5268, Acc: 0.7248, Val Loss: 0.8808, Val Acc: 0.5162
Epoch 19/100, Loss: 0.5261, Acc: 0.7292, Val Loss: 0.8715, Val Acc: 0.4989
Epoch 20/100, Loss: 0.5256, Acc: 0.7256, Val Loss: 0.8756, Val Acc: 0.4635
Epoch 21/100, Loss: 0.5225, Acc: 0.7292, Val Loss: 0.8713, Val Acc: 0.5007
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5213, Acc: 0.7299, Val Loss: 0.8511, Val Acc: 0.5037
Epoch 23/100, Loss: 0.5176, Acc: 0.7316, Val Loss: 0.9043, Val Acc: 0.4926
Epoch 24/100, Loss: 0.5186, Acc: 0.7300, Val Loss: 0.8788, Val Acc: 0.4908
Epoch 25/100, Loss: 0.5191, Acc: 0.7289, Val Loss: 0.8784, Val Acc: 0.4842
Epoch 26/100, Loss: 0.5181, Acc: 0.7309, Val Loss: 0.8568, Val Acc: 0.4834
Epoch 27/100, Loss: 0.5172, Acc: 0.7321, Val Loss: 0.8867, Val Acc: 0.5026
Epoch 28/100, Loss: 0.5183, Acc: 0.7285, Val Loss: 0.8981, Val Acc: 0.4823
Epoch 29/100, Loss: 0.5170, Acc: 0.7316, Val Loss: 0.8731, Val Acc: 0.4805
Epoch 30/100, Loss: 0.5161, Acc: 0.7325, Val Loss: 0.8876, Val Acc: 0.4886
Epoch 31/100, Loss: 0.5165, Acc: 0.7331, Val Loss: 0.8699, Val Acc: 0.5033
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5141, Acc: 0.7339, Val Loss: 0.8841, Val Acc: 0.5085
Epoch 33/100, Loss: 0.5139, Acc: 0.7308, Val Loss: 0.8551, Val Acc: 0.4794
Epoch 34/100, Loss: 0.5134, Acc: 0.7336, Val Loss: 0.8951, Val Acc: 0.4934
Epoch 35/100, Loss: 0.5127, Acc: 0.7320, Val Loss: 0.8838, Val Acc: 0.4853
Epoch 36/100, Loss: 0.5133, Acc: 0.7340, Val Loss: 0.8928, Val Acc: 0.4923
Epoch 37/100, Loss: 0.5121, Acc: 0.7343, Val Loss: 0.8681, Val Acc: 0.4831
Epoch 38/100, Loss: 0.5129, Acc: 0.7330, Val Loss: 0.8631, Val Acc: 0.4864
Epoch 39/100, Loss: 0.5121, Acc: 0.7351, Val Loss: 0.8684, Val Acc: 0.4838
Epoch 40/100, Loss: 0.5117, Acc: 0.7356, Val Loss: 0.9014, Val Acc: 0.4967
Epoch 41/100, Loss: 0.5118, Acc: 0.7326, Val Loss: 0.9067, Val Acc: 0.5011
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5104, Acc: 0.7341, Val Loss: 0.8844, Val Acc: 0.4786
Epoch 43/100, Loss: 0.5111, Acc: 0.7345, Val Loss: 0.8823, Val Acc: 0.4871
Epoch 44/100, Loss: 0.5104, Acc: 0.7343, Val Loss: 0.8959, Val Acc: 0.4912
Epoch 45/100, Loss: 0.5106, Acc: 0.7344, Val Loss: 0.8922, Val Acc: 0.5033
Epoch 46/100, Loss: 0.5100, Acc: 0.7352, Val Loss: 0.8901, Val Acc: 0.4812
Epoch 47/100, Loss: 0.5103, Acc: 0.7336, Val Loss: 0.8937, Val Acc: 0.4978
Epoch 48/100, Loss: 0.5099, Acc: 0.7342, Val Loss: 0.8798, Val Acc: 0.4831
Epoch 49/100, Loss: 0.5100, Acc: 0.7352, Val Loss: 0.8704, Val Acc: 0.4820
Epoch 50/100, Loss: 0.5099, Acc: 0.7345, Val Loss: 0.8755, Val Acc: 0.4948
Epoch 51/100, Loss: 0.5090, Acc: 0.7355, Val Loss: 0.8675, Val Acc: 0.4864
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5087, Acc: 0.7353, Val Loss: 0.9013, Val Acc: 0.4974
Epoch 53/100, Loss: 0.5090, Acc: 0.7335, Val Loss: 0.8849, Val Acc: 0.4860
Epoch 54/100, Loss: 0.5087, Acc: 0.7339, Val Loss: 0.8902, Val Acc: 0.4956
Epoch 55/100, Loss: 0.5084, Acc: 0.7354, Val Loss: 0.8847, Val Acc: 0.4867
Epoch 56/100, Loss: 0.5088, Acc: 0.7342, Val Loss: 0.8904, Val Acc: 0.4878
Epoch 57/100, Loss: 0.5085, Acc: 0.7354, Val Loss: 0.8796, Val Acc: 0.4915
Epoch 58/100, Loss: 0.5083, Acc: 0.7358, Val Loss: 0.9083, Val Acc: 0.5033
Epoch 59/100, Loss: 0.5083, Acc: 0.7357, Val Loss: 0.8958, Val Acc: 0.4941
Epoch 60/100, Loss: 0.5083, Acc: 0.7353, Val Loss: 0.8870, Val Acc: 0.5018
Epoch 61/100, Loss: 0.5084, Acc: 0.7362, Val Loss: 0.8853, Val Acc: 0.4956
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5079, Acc: 0.7351, Val Loss: 0.8828, Val Acc: 0.4930
Epoch 63/100, Loss: 0.5077, Acc: 0.7366, Val Loss: 0.8865, Val Acc: 0.4978
Epoch 64/100, Loss: 0.5078, Acc: 0.7360, Val Loss: 0.8856, Val Acc: 0.4934
Epoch 65/100, Loss: 0.5078, Acc: 0.7361, Val Loss: 0.8893, Val Acc: 0.4948
Epoch 66/100, Loss: 0.5077, Acc: 0.7363, Val Loss: 0.8842, Val Acc: 0.4915
Epoch 67/100, Loss: 0.5077, Acc: 0.7356, Val Loss: 0.8818, Val Acc: 0.4908
Epoch 68/100, Loss: 0.5077, Acc: 0.7361, Val Loss: 0.8856, Val Acc: 0.4930
Epoch 69/100, Loss: 0.5077, Acc: 0.7357, Val Loss: 0.8934, Val Acc: 0.4963
Epoch 70/100, Loss: 0.5077, Acc: 0.7356, Val Loss: 0.8854, Val Acc: 0.4908
Epoch 71/100, Loss: 0.5075, Acc: 0.7363, Val Loss: 0.8864, Val Acc: 0.4926
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5075, Acc: 0.7364, Val Loss: 0.8780, Val Acc: 0.4882
Epoch 73/100, Loss: 0.5074, Acc: 0.7357, Val Loss: 0.8873, Val Acc: 0.4912
Epoch 74/100, Loss: 0.5073, Acc: 0.7357, Val Loss: 0.8861, Val Acc: 0.4890
Epoch 75/100, Loss: 0.5074, Acc: 0.7359, Val Loss: 0.8864, Val Acc: 0.4901
Epoch 76/100, Loss: 0.5073, Acc: 0.7365, Val Loss: 0.8884, Val Acc: 0.4919
Epoch 77/100, Loss: 0.5069, Acc: 0.7357, Val Loss: 0.8897, Val Acc: 0.4923
Epoch 78/100, Loss: 0.5056, Acc: 0.7358, Val Loss: 0.8923, Val Acc: 0.4993
Epoch 79/100, Loss: 0.5056, Acc: 0.7362, Val Loss: 0.8901, Val Acc: 0.4982
Epoch 80/100, Loss: 0.5055, Acc: 0.7357, Val Loss: 0.8869, Val Acc: 0.4930
Epoch 81/100, Loss: 0.5054, Acc: 0.7357, Val Loss: 0.8877, Val Acc: 0.4956
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5054, Acc: 0.7370, Val Loss: 0.8842, Val Acc: 0.4901
Epoch 83/100, Loss: 0.5052, Acc: 0.7362, Val Loss: 0.8831, Val Acc: 0.4923
Epoch 84/100, Loss: 0.5053, Acc: 0.7365, Val Loss: 0.8879, Val Acc: 0.4948
Epoch 85/100, Loss: 0.5053, Acc: 0.7364, Val Loss: 0.8881, Val Acc: 0.4959
Epoch 86/100, Loss: 0.5051, Acc: 0.7361, Val Loss: 0.8857, Val Acc: 0.4948
Epoch 87/100, Loss: 0.5051, Acc: 0.7376, Val Loss: 0.8903, Val Acc: 0.4948
Epoch 88/100, Loss: 0.5051, Acc: 0.7363, Val Loss: 0.8930, Val Acc: 0.4989
Epoch 89/100, Loss: 0.5050, Acc: 0.7368, Val Loss: 0.8919, Val Acc: 0.4937
Epoch 90/100, Loss: 0.5050, Acc: 0.7372, Val Loss: 0.8889, Val Acc: 0.4948
Epoch 91/100, Loss: 0.5050, Acc: 0.7370, Val Loss: 0.8890, Val Acc: 0.4971
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5049, Acc: 0.7380, Val Loss: 0.8887, Val Acc: 0.4963
Epoch 93/100, Loss: 0.5049, Acc: 0.7371, Val Loss: 0.8878, Val Acc: 0.4959
Epoch 94/100, Loss: 0.5049, Acc: 0.7369, Val Loss: 0.8894, Val Acc: 0.4941
Epoch 95/100, Loss: 0.5048, Acc: 0.7370, Val Loss: 0.8871, Val Acc: 0.4945
Epoch 96/100, Loss: 0.5048, Acc: 0.7368, Val Loss: 0.8868, Val Acc: 0.4878
Epoch 97/100, Loss: 0.5048, Acc: 0.7369, Val Loss: 0.8898, Val Acc: 0.4956
Epoch 98/100, Loss: 0.5047, Acc: 0.7373, Val Loss: 0.8836, Val Acc: 0.4908
Epoch 99/100, Loss: 0.5046, Acc: 0.7371, Val Loss: 0.8929, Val Acc: 0.5000
Epoch 100/100, Loss: 0.5047, Acc: 0.7369, Val Loss: 0.8878, Val Acc: 0.4971

##############################
Resultados para principal:  010  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5 
 {'training': [0.5046593377961969, 0.7369437293122472, 0.6908821349147517, 0.8572479764532744, 0.7651260159264428], 'validate': [0.8878178582635037, 0.49705449189985274, 0.4966931216931217, 0.553834808259587, 0.5237099023709902], 'test': [0.6562125064708568, 0.6154299175500589, 0.5771971496437055, 0.8596698113207547, 0.6906679298910469]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  009  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  009  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  009  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.3729, Acc: 0.8909, Val Loss: 0.2973, Val Acc: 0.9002
Mejor modelo guardado con Val Loss: 0.2973
Epoch 2/100, Loss: 0.2339, Acc: 0.9128, Val Loss: 0.1586, Val Acc: 0.9551
Mejor modelo guardado con Val Loss: 0.1586
Epoch 3/100, Loss: 0.2038, Acc: 0.9195, Val Loss: 0.2675, Val Acc: 0.8969
Epoch 4/100, Loss: 0.1907, Acc: 0.9224, Val Loss: 0.1562, Val Acc: 0.9492
Mejor modelo guardado con Val Loss: 0.1562
Epoch 5/100, Loss: 0.1884, Acc: 0.9203, Val Loss: 0.2069, Val Acc: 0.9194
Epoch 6/100, Loss: 0.1855, Acc: 0.9242, Val Loss: 0.1790, Val Acc: 0.9370
Epoch 7/100, Loss: 0.1801, Acc: 0.9254, Val Loss: 0.1812, Val Acc: 0.9326
Epoch 8/100, Loss: 0.1702, Acc: 0.9293, Val Loss: 0.2081, Val Acc: 0.9212
Epoch 9/100, Loss: 0.1747, Acc: 0.9260, Val Loss: 0.1791, Val Acc: 0.9337
Epoch 10/100, Loss: 0.1681, Acc: 0.9270, Val Loss: 0.1802, Val Acc: 0.9385
Epoch 11/100, Loss: 0.1662, Acc: 0.9305, Val Loss: 0.1388, Val Acc: 0.9492
Mejor modelo guardado con Val Loss: 0.1388
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.1602, Acc: 0.9336, Val Loss: 0.2673, Val Acc: 0.8781
Epoch 13/100, Loss: 0.1565, Acc: 0.9324, Val Loss: 0.1679, Val Acc: 0.9356
Epoch 14/100, Loss: 0.1548, Acc: 0.9344, Val Loss: 0.1995, Val Acc: 0.9113
Epoch 15/100, Loss: 0.1557, Acc: 0.9361, Val Loss: 0.1763, Val Acc: 0.9308
Epoch 16/100, Loss: 0.1526, Acc: 0.9390, Val Loss: 0.1775, Val Acc: 0.9234
Epoch 17/100, Loss: 0.1521, Acc: 0.9364, Val Loss: 0.1917, Val Acc: 0.9205
Epoch 18/100, Loss: 0.1537, Acc: 0.9349, Val Loss: 0.1722, Val Acc: 0.9334
Epoch 19/100, Loss: 0.1575, Acc: 0.9311, Val Loss: 0.2181, Val Acc: 0.8947
Epoch 20/100, Loss: 0.1501, Acc: 0.9389, Val Loss: 0.2271, Val Acc: 0.8862
Epoch 21/100, Loss: 0.1460, Acc: 0.9375, Val Loss: 0.1871, Val Acc: 0.9249
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.1418, Acc: 0.9393, Val Loss: 0.1942, Val Acc: 0.9157
Epoch 23/100, Loss: 0.1405, Acc: 0.9414, Val Loss: 0.1866, Val Acc: 0.9208
Epoch 24/100, Loss: 0.1402, Acc: 0.9396, Val Loss: 0.2418, Val Acc: 0.8877
Epoch 25/100, Loss: 0.1388, Acc: 0.9414, Val Loss: 0.1938, Val Acc: 0.9208
Epoch 26/100, Loss: 0.1397, Acc: 0.9424, Val Loss: 0.2081, Val Acc: 0.9120
Epoch 27/100, Loss: 0.1390, Acc: 0.9424, Val Loss: 0.1935, Val Acc: 0.9242
Epoch 28/100, Loss: 0.1387, Acc: 0.9404, Val Loss: 0.1908, Val Acc: 0.9194
Epoch 29/100, Loss: 0.1378, Acc: 0.9405, Val Loss: 0.2245, Val Acc: 0.9002
Epoch 30/100, Loss: 0.1378, Acc: 0.9434, Val Loss: 0.1684, Val Acc: 0.9374
Epoch 31/100, Loss: 0.1393, Acc: 0.9417, Val Loss: 0.2167, Val Acc: 0.9083
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.1330, Acc: 0.9439, Val Loss: 0.2369, Val Acc: 0.8995
Epoch 33/100, Loss: 0.1338, Acc: 0.9455, Val Loss: 0.1978, Val Acc: 0.9208
Epoch 34/100, Loss: 0.1328, Acc: 0.9437, Val Loss: 0.2006, Val Acc: 0.9183
Epoch 35/100, Loss: 0.1324, Acc: 0.9439, Val Loss: 0.2313, Val Acc: 0.8969
Epoch 36/100, Loss: 0.1332, Acc: 0.9448, Val Loss: 0.1911, Val Acc: 0.9208
Epoch 37/100, Loss: 0.1341, Acc: 0.9430, Val Loss: 0.2001, Val Acc: 0.9179
Epoch 38/100, Loss: 0.1321, Acc: 0.9441, Val Loss: 0.1823, Val Acc: 0.9278
Epoch 39/100, Loss: 0.1319, Acc: 0.9439, Val Loss: 0.1951, Val Acc: 0.9223
Epoch 40/100, Loss: 0.1314, Acc: 0.9447, Val Loss: 0.2090, Val Acc: 0.9109
Epoch 41/100, Loss: 0.1321, Acc: 0.9435, Val Loss: 0.2019, Val Acc: 0.9190
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.1297, Acc: 0.9455, Val Loss: 0.2067, Val Acc: 0.9157
Epoch 43/100, Loss: 0.1296, Acc: 0.9446, Val Loss: 0.2062, Val Acc: 0.9164
Epoch 44/100, Loss: 0.1295, Acc: 0.9459, Val Loss: 0.2017, Val Acc: 0.9190
Epoch 45/100, Loss: 0.1291, Acc: 0.9452, Val Loss: 0.1993, Val Acc: 0.9186
Epoch 46/100, Loss: 0.1293, Acc: 0.9454, Val Loss: 0.2195, Val Acc: 0.9057
Epoch 47/100, Loss: 0.1289, Acc: 0.9446, Val Loss: 0.1987, Val Acc: 0.9201
Epoch 48/100, Loss: 0.1295, Acc: 0.9449, Val Loss: 0.2038, Val Acc: 0.9175
Epoch 49/100, Loss: 0.1291, Acc: 0.9435, Val Loss: 0.2325, Val Acc: 0.9028
Epoch 50/100, Loss: 0.1294, Acc: 0.9450, Val Loss: 0.2060, Val Acc: 0.9135
Epoch 51/100, Loss: 0.1283, Acc: 0.9449, Val Loss: 0.2013, Val Acc: 0.9197
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.1279, Acc: 0.9451, Val Loss: 0.2048, Val Acc: 0.9157
Epoch 53/100, Loss: 0.1278, Acc: 0.9451, Val Loss: 0.1980, Val Acc: 0.9230
Epoch 54/100, Loss: 0.1279, Acc: 0.9463, Val Loss: 0.1962, Val Acc: 0.9227
Epoch 55/100, Loss: 0.1277, Acc: 0.9457, Val Loss: 0.2095, Val Acc: 0.9124
Epoch 56/100, Loss: 0.1276, Acc: 0.9457, Val Loss: 0.2104, Val Acc: 0.9116
Epoch 57/100, Loss: 0.1275, Acc: 0.9458, Val Loss: 0.2113, Val Acc: 0.9113
Epoch 58/100, Loss: 0.1275, Acc: 0.9452, Val Loss: 0.2032, Val Acc: 0.9186
Epoch 59/100, Loss: 0.1272, Acc: 0.9459, Val Loss: 0.2201, Val Acc: 0.9068
Epoch 60/100, Loss: 0.1271, Acc: 0.9452, Val Loss: 0.2103, Val Acc: 0.9135
Epoch 61/100, Loss: 0.1267, Acc: 0.9456, Val Loss: 0.2077, Val Acc: 0.9149
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.1265, Acc: 0.9458, Val Loss: 0.2016, Val Acc: 0.9186
Epoch 63/100, Loss: 0.1262, Acc: 0.9462, Val Loss: 0.2110, Val Acc: 0.9113
Epoch 64/100, Loss: 0.1263, Acc: 0.9461, Val Loss: 0.2065, Val Acc: 0.9164
Epoch 65/100, Loss: 0.1263, Acc: 0.9466, Val Loss: 0.2016, Val Acc: 0.9190
Epoch 66/100, Loss: 0.1263, Acc: 0.9462, Val Loss: 0.2090, Val Acc: 0.9138
Epoch 67/100, Loss: 0.1261, Acc: 0.9458, Val Loss: 0.2053, Val Acc: 0.9175
Epoch 68/100, Loss: 0.1262, Acc: 0.9467, Val Loss: 0.2004, Val Acc: 0.9201
Epoch 69/100, Loss: 0.1263, Acc: 0.9458, Val Loss: 0.2047, Val Acc: 0.9172
Epoch 70/100, Loss: 0.1261, Acc: 0.9458, Val Loss: 0.2020, Val Acc: 0.9186
Epoch 71/100, Loss: 0.1262, Acc: 0.9465, Val Loss: 0.2089, Val Acc: 0.9131
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.1257, Acc: 0.9471, Val Loss: 0.2022, Val Acc: 0.9186
Epoch 73/100, Loss: 0.1254, Acc: 0.9476, Val Loss: 0.1987, Val Acc: 0.9219
Epoch 74/100, Loss: 0.1255, Acc: 0.9473, Val Loss: 0.2010, Val Acc: 0.9197
Epoch 75/100, Loss: 0.1254, Acc: 0.9471, Val Loss: 0.1951, Val Acc: 0.9238
Epoch 76/100, Loss: 0.1256, Acc: 0.9475, Val Loss: 0.2024, Val Acc: 0.9183
Epoch 77/100, Loss: 0.1254, Acc: 0.9471, Val Loss: 0.2000, Val Acc: 0.9201
Epoch 78/100, Loss: 0.1254, Acc: 0.9473, Val Loss: 0.1989, Val Acc: 0.9219
Epoch 79/100, Loss: 0.1253, Acc: 0.9476, Val Loss: 0.1999, Val Acc: 0.9208
Epoch 80/100, Loss: 0.1254, Acc: 0.9470, Val Loss: 0.2028, Val Acc: 0.9175
Epoch 81/100, Loss: 0.1253, Acc: 0.9476, Val Loss: 0.2057, Val Acc: 0.9161
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.1254, Acc: 0.9474, Val Loss: 0.2020, Val Acc: 0.9194
Epoch 83/100, Loss: 0.1253, Acc: 0.9472, Val Loss: 0.2075, Val Acc: 0.9149
Epoch 84/100, Loss: 0.1253, Acc: 0.9473, Val Loss: 0.2033, Val Acc: 0.9172
Epoch 85/100, Loss: 0.1253, Acc: 0.9477, Val Loss: 0.2063, Val Acc: 0.9161
Epoch 86/100, Loss: 0.1254, Acc: 0.9475, Val Loss: 0.2028, Val Acc: 0.9179
Epoch 87/100, Loss: 0.1251, Acc: 0.9471, Val Loss: 0.2137, Val Acc: 0.9091
Epoch 88/100, Loss: 0.1253, Acc: 0.9478, Val Loss: 0.2080, Val Acc: 0.9153
Epoch 89/100, Loss: 0.1251, Acc: 0.9469, Val Loss: 0.1983, Val Acc: 0.9223
Epoch 90/100, Loss: 0.1251, Acc: 0.9468, Val Loss: 0.2017, Val Acc: 0.9201
Epoch 91/100, Loss: 0.1250, Acc: 0.9477, Val Loss: 0.1986, Val Acc: 0.9219
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.1251, Acc: 0.9475, Val Loss: 0.2031, Val Acc: 0.9183
Epoch 93/100, Loss: 0.1251, Acc: 0.9476, Val Loss: 0.2025, Val Acc: 0.9186
Epoch 94/100, Loss: 0.1250, Acc: 0.9475, Val Loss: 0.2005, Val Acc: 0.9212
Epoch 95/100, Loss: 0.1250, Acc: 0.9478, Val Loss: 0.2009, Val Acc: 0.9201
Epoch 96/100, Loss: 0.1250, Acc: 0.9476, Val Loss: 0.2008, Val Acc: 0.9205
Epoch 97/100, Loss: 0.1250, Acc: 0.9473, Val Loss: 0.2058, Val Acc: 0.9161
Epoch 98/100, Loss: 0.1249, Acc: 0.9475, Val Loss: 0.2055, Val Acc: 0.9161
Epoch 99/100, Loss: 0.1249, Acc: 0.9477, Val Loss: 0.2018, Val Acc: 0.9197
Epoch 100/100, Loss: 0.1250, Acc: 0.9477, Val Loss: 0.2024, Val Acc: 0.9194

##############################
Resultados para principal:  009  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5 
 {'training': [0.12496375474214291, 0.947682971680765, 0.9382315865298038, 0.9584253127299485, 0.9482209482209483], 'validate': [0.20243084430153113, 0.9193667157584683, 0.875743555849306, 0.9771386430678466, 0.9236667828511677], 'test': [0.20692744092256934, 0.9169611307420494, 0.9158823529411765, 0.9180424528301887, 0.9169611307420494]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  118  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  118  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  118  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6851, Acc: 0.5569, Val Loss: 0.6351, Val Acc: 0.7412
Mejor modelo guardado con Val Loss: 0.6351
Epoch 2/100, Loss: 0.6729, Acc: 0.6089, Val Loss: 0.5851, Val Acc: 0.7728
Mejor modelo guardado con Val Loss: 0.5851
Epoch 3/100, Loss: 0.6513, Acc: 0.6468, Val Loss: 0.5316, Val Acc: 0.8789
Mejor modelo guardado con Val Loss: 0.5316
Epoch 4/100, Loss: 0.6355, Acc: 0.6671, Val Loss: 0.5276, Val Acc: 0.7728
Mejor modelo guardado con Val Loss: 0.5276
Epoch 5/100, Loss: 0.6220, Acc: 0.6729, Val Loss: 0.4911, Val Acc: 0.8398
Mejor modelo guardado con Val Loss: 0.4911
Epoch 6/100, Loss: 0.6120, Acc: 0.6774, Val Loss: 0.4803, Val Acc: 0.8531
Mejor modelo guardado con Val Loss: 0.4803
Epoch 7/100, Loss: 0.6057, Acc: 0.6792, Val Loss: 0.5085, Val Acc: 0.7736
Epoch 8/100, Loss: 0.6112, Acc: 0.6647, Val Loss: 0.4386, Val Acc: 0.8568
Mejor modelo guardado con Val Loss: 0.4386
Epoch 9/100, Loss: 0.6031, Acc: 0.6741, Val Loss: 0.4501, Val Acc: 0.8126
Epoch 10/100, Loss: 0.6018, Acc: 0.6724, Val Loss: 0.4878, Val Acc: 0.7942
Epoch 11/100, Loss: 0.5959, Acc: 0.6785, Val Loss: 0.4392, Val Acc: 0.8420
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5889, Acc: 0.6886, Val Loss: 0.4757, Val Acc: 0.8034
Epoch 13/100, Loss: 0.5867, Acc: 0.6873, Val Loss: 0.4244, Val Acc: 0.8479
Mejor modelo guardado con Val Loss: 0.4244
Epoch 14/100, Loss: 0.5885, Acc: 0.6866, Val Loss: 0.5022, Val Acc: 0.7765
Epoch 15/100, Loss: 0.5881, Acc: 0.6840, Val Loss: 0.4492, Val Acc: 0.8266
Epoch 16/100, Loss: 0.5842, Acc: 0.6939, Val Loss: 0.4268, Val Acc: 0.8605
Epoch 17/100, Loss: 0.5841, Acc: 0.6921, Val Loss: 0.4502, Val Acc: 0.8306
Epoch 18/100, Loss: 0.5845, Acc: 0.6913, Val Loss: 0.4061, Val Acc: 0.8888
Mejor modelo guardado con Val Loss: 0.4061
Epoch 19/100, Loss: 0.5860, Acc: 0.6889, Val Loss: 0.4139, Val Acc: 0.8675
Epoch 20/100, Loss: 0.5875, Acc: 0.6880, Val Loss: 0.4179, Val Acc: 0.8549
Epoch 21/100, Loss: 0.5821, Acc: 0.6934, Val Loss: 0.3936, Val Acc: 0.9017
Mejor modelo guardado con Val Loss: 0.3936
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5808, Acc: 0.6925, Val Loss: 0.4387, Val Acc: 0.8420
Epoch 23/100, Loss: 0.5788, Acc: 0.6960, Val Loss: 0.4058, Val Acc: 0.8763
Epoch 24/100, Loss: 0.5800, Acc: 0.6944, Val Loss: 0.4337, Val Acc: 0.8446
Epoch 25/100, Loss: 0.5799, Acc: 0.6907, Val Loss: 0.4631, Val Acc: 0.7890
Epoch 26/100, Loss: 0.5802, Acc: 0.6927, Val Loss: 0.4355, Val Acc: 0.8439
Epoch 27/100, Loss: 0.5795, Acc: 0.6937, Val Loss: 0.4188, Val Acc: 0.8594
Epoch 28/100, Loss: 0.5801, Acc: 0.6943, Val Loss: 0.4114, Val Acc: 0.8693
Epoch 29/100, Loss: 0.5797, Acc: 0.6930, Val Loss: 0.4034, Val Acc: 0.8792
Epoch 30/100, Loss: 0.5793, Acc: 0.6924, Val Loss: 0.4126, Val Acc: 0.8704
Epoch 31/100, Loss: 0.5778, Acc: 0.6956, Val Loss: 0.3933, Val Acc: 0.8899
Mejor modelo guardado con Val Loss: 0.3933
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5767, Acc: 0.6969, Val Loss: 0.4203, Val Acc: 0.8612
Epoch 33/100, Loss: 0.5760, Acc: 0.6961, Val Loss: 0.4130, Val Acc: 0.8686
Epoch 34/100, Loss: 0.5770, Acc: 0.6965, Val Loss: 0.4384, Val Acc: 0.8428
Epoch 35/100, Loss: 0.5760, Acc: 0.6984, Val Loss: 0.4200, Val Acc: 0.8605
Epoch 36/100, Loss: 0.5763, Acc: 0.6986, Val Loss: 0.4199, Val Acc: 0.8601
Epoch 37/100, Loss: 0.5758, Acc: 0.6950, Val Loss: 0.4177, Val Acc: 0.8627
Epoch 38/100, Loss: 0.5761, Acc: 0.6978, Val Loss: 0.4118, Val Acc: 0.8667
Epoch 39/100, Loss: 0.5758, Acc: 0.6959, Val Loss: 0.4390, Val Acc: 0.8406
Epoch 40/100, Loss: 0.5755, Acc: 0.6977, Val Loss: 0.4096, Val Acc: 0.8715
Epoch 41/100, Loss: 0.5760, Acc: 0.6962, Val Loss: 0.4274, Val Acc: 0.8531
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5748, Acc: 0.6983, Val Loss: 0.4266, Val Acc: 0.8549
Epoch 43/100, Loss: 0.5748, Acc: 0.6964, Val Loss: 0.4140, Val Acc: 0.8678
Epoch 44/100, Loss: 0.5744, Acc: 0.6975, Val Loss: 0.4267, Val Acc: 0.8538
Epoch 45/100, Loss: 0.5748, Acc: 0.6970, Val Loss: 0.4230, Val Acc: 0.8590
Epoch 46/100, Loss: 0.5748, Acc: 0.6970, Val Loss: 0.4265, Val Acc: 0.8560
Epoch 47/100, Loss: 0.5744, Acc: 0.6971, Val Loss: 0.4298, Val Acc: 0.8516
Epoch 48/100, Loss: 0.5747, Acc: 0.6978, Val Loss: 0.4183, Val Acc: 0.8627
Epoch 49/100, Loss: 0.5743, Acc: 0.6974, Val Loss: 0.4286, Val Acc: 0.8549
Epoch 50/100, Loss: 0.5744, Acc: 0.6981, Val Loss: 0.4248, Val Acc: 0.8542
Epoch 51/100, Loss: 0.5738, Acc: 0.6973, Val Loss: 0.4300, Val Acc: 0.8527
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5728, Acc: 0.6996, Val Loss: 0.4009, Val Acc: 0.8829
Epoch 53/100, Loss: 0.5735, Acc: 0.6970, Val Loss: 0.4124, Val Acc: 0.8671
Epoch 54/100, Loss: 0.5724, Acc: 0.6990, Val Loss: 0.4181, Val Acc: 0.8638
Epoch 55/100, Loss: 0.5720, Acc: 0.6990, Val Loss: 0.4181, Val Acc: 0.8630
Epoch 56/100, Loss: 0.5717, Acc: 0.6988, Val Loss: 0.4229, Val Acc: 0.8579
Epoch 57/100, Loss: 0.5714, Acc: 0.6990, Val Loss: 0.4244, Val Acc: 0.8557
Epoch 58/100, Loss: 0.5711, Acc: 0.6995, Val Loss: 0.4155, Val Acc: 0.8649
Epoch 59/100, Loss: 0.5713, Acc: 0.6974, Val Loss: 0.4221, Val Acc: 0.8575
Epoch 60/100, Loss: 0.5707, Acc: 0.7001, Val Loss: 0.4097, Val Acc: 0.8700
Epoch 61/100, Loss: 0.5709, Acc: 0.6976, Val Loss: 0.4127, Val Acc: 0.8663
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5705, Acc: 0.6990, Val Loss: 0.4157, Val Acc: 0.8627
Epoch 63/100, Loss: 0.5704, Acc: 0.6993, Val Loss: 0.4130, Val Acc: 0.8656
Epoch 64/100, Loss: 0.5702, Acc: 0.6991, Val Loss: 0.4207, Val Acc: 0.8586
Epoch 65/100, Loss: 0.5701, Acc: 0.6986, Val Loss: 0.4131, Val Acc: 0.8660
Epoch 66/100, Loss: 0.5703, Acc: 0.6998, Val Loss: 0.4190, Val Acc: 0.8594
Epoch 67/100, Loss: 0.5701, Acc: 0.6985, Val Loss: 0.4171, Val Acc: 0.8616
Epoch 68/100, Loss: 0.5700, Acc: 0.6984, Val Loss: 0.4169, Val Acc: 0.8619
Epoch 69/100, Loss: 0.5698, Acc: 0.6984, Val Loss: 0.4113, Val Acc: 0.8678
Epoch 70/100, Loss: 0.5698, Acc: 0.6997, Val Loss: 0.4154, Val Acc: 0.8627
Epoch 71/100, Loss: 0.5697, Acc: 0.7002, Val Loss: 0.4134, Val Acc: 0.8652
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5696, Acc: 0.6995, Val Loss: 0.4142, Val Acc: 0.8645
Epoch 73/100, Loss: 0.5695, Acc: 0.6997, Val Loss: 0.4166, Val Acc: 0.8612
Epoch 74/100, Loss: 0.5696, Acc: 0.6999, Val Loss: 0.4153, Val Acc: 0.8627
Epoch 75/100, Loss: 0.5694, Acc: 0.6999, Val Loss: 0.4212, Val Acc: 0.8582
Epoch 76/100, Loss: 0.5694, Acc: 0.6989, Val Loss: 0.4167, Val Acc: 0.8605
Epoch 77/100, Loss: 0.5693, Acc: 0.6992, Val Loss: 0.4164, Val Acc: 0.8616
Epoch 78/100, Loss: 0.5693, Acc: 0.6997, Val Loss: 0.4204, Val Acc: 0.8575
Epoch 79/100, Loss: 0.5691, Acc: 0.6993, Val Loss: 0.4173, Val Acc: 0.8594
Epoch 80/100, Loss: 0.5691, Acc: 0.6998, Val Loss: 0.4158, Val Acc: 0.8605
Epoch 81/100, Loss: 0.5690, Acc: 0.6994, Val Loss: 0.4144, Val Acc: 0.8619
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5686, Acc: 0.6996, Val Loss: 0.4183, Val Acc: 0.8594
Epoch 83/100, Loss: 0.5684, Acc: 0.6992, Val Loss: 0.4199, Val Acc: 0.8571
Epoch 84/100, Loss: 0.5680, Acc: 0.6994, Val Loss: 0.4161, Val Acc: 0.8605
Epoch 85/100, Loss: 0.5678, Acc: 0.7003, Val Loss: 0.4123, Val Acc: 0.8649
Epoch 86/100, Loss: 0.5676, Acc: 0.6996, Val Loss: 0.4176, Val Acc: 0.8586
Epoch 87/100, Loss: 0.5675, Acc: 0.6996, Val Loss: 0.4151, Val Acc: 0.8616
Epoch 88/100, Loss: 0.5675, Acc: 0.7003, Val Loss: 0.4166, Val Acc: 0.8594
Epoch 89/100, Loss: 0.5673, Acc: 0.7003, Val Loss: 0.4116, Val Acc: 0.8652
Epoch 90/100, Loss: 0.5673, Acc: 0.7013, Val Loss: 0.4169, Val Acc: 0.8594
Epoch 91/100, Loss: 0.5672, Acc: 0.7008, Val Loss: 0.4154, Val Acc: 0.8608
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5670, Acc: 0.7013, Val Loss: 0.4175, Val Acc: 0.8590
Epoch 93/100, Loss: 0.5670, Acc: 0.7016, Val Loss: 0.4128, Val Acc: 0.8641
Epoch 94/100, Loss: 0.5670, Acc: 0.7009, Val Loss: 0.4113, Val Acc: 0.8641
Epoch 95/100, Loss: 0.5668, Acc: 0.7015, Val Loss: 0.4168, Val Acc: 0.8590
Epoch 96/100, Loss: 0.5668, Acc: 0.7015, Val Loss: 0.4108, Val Acc: 0.8645
Epoch 97/100, Loss: 0.5667, Acc: 0.7007, Val Loss: 0.4126, Val Acc: 0.8638
Epoch 98/100, Loss: 0.5667, Acc: 0.7014, Val Loss: 0.4143, Val Acc: 0.8605
Epoch 99/100, Loss: 0.5665, Acc: 0.7007, Val Loss: 0.4128, Val Acc: 0.8638
Epoch 100/100, Loss: 0.5665, Acc: 0.7011, Val Loss: 0.4137, Val Acc: 0.8634

##############################
Resultados para principal:  118  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5 
 {'training': [0.5664829976990978, 0.7010849577050386, 0.6494732521548775, 0.873252391464312, 0.7449195763044331], 'validate': [0.41367024495158083, 0.8634020618556701, 0.9823702252693438, 0.7396755162241888, 0.843920908708456], 'test': [0.5680393802898901, 0.714075382803298, 0.6522469550608988, 0.9156839622641509, 0.7618346823644837]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  032  --- window & package numer:  5

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  032  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  5
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  032  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6651, Acc: 0.6219, Val Loss: 0.7313, Val Acc: 0.4462
Mejor modelo guardado con Val Loss: 0.7313
Epoch 2/100, Loss: 0.6464, Acc: 0.6421, Val Loss: 0.7830, Val Acc: 0.3848
Epoch 3/100, Loss: 0.6318, Acc: 0.6558, Val Loss: 0.7947, Val Acc: 0.3428
Epoch 4/100, Loss: 0.6236, Acc: 0.6588, Val Loss: 0.7396, Val Acc: 0.4219
Epoch 5/100, Loss: 0.6229, Acc: 0.6574, Val Loss: 0.7563, Val Acc: 0.3542
Epoch 6/100, Loss: 0.6183, Acc: 0.6550, Val Loss: 0.7180, Val Acc: 0.3560
Mejor modelo guardado con Val Loss: 0.7180
Epoch 7/100, Loss: 0.6117, Acc: 0.6684, Val Loss: 0.7416, Val Acc: 0.2990
Epoch 8/100, Loss: 0.6101, Acc: 0.6726, Val Loss: 0.6756, Val Acc: 0.6112
Mejor modelo guardado con Val Loss: 0.6756
Epoch 9/100, Loss: 0.6112, Acc: 0.6933, Val Loss: 0.6644, Val Acc: 0.7323
Mejor modelo guardado con Val Loss: 0.6644
Epoch 10/100, Loss: 0.6030, Acc: 0.6958, Val Loss: 0.6003, Val Acc: 0.8601
Mejor modelo guardado con Val Loss: 0.6003
Epoch 11/100, Loss: 0.6029, Acc: 0.6951, Val Loss: 0.5848, Val Acc: 0.8509
Mejor modelo guardado con Val Loss: 0.5848
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5990, Acc: 0.7001, Val Loss: 0.5267, Val Acc: 0.9253
Mejor modelo guardado con Val Loss: 0.5267
Epoch 13/100, Loss: 0.5933, Acc: 0.7004, Val Loss: 0.5984, Val Acc: 0.8487
Epoch 14/100, Loss: 0.5932, Acc: 0.7017, Val Loss: 0.6239, Val Acc: 0.8015
Epoch 15/100, Loss: 0.5908, Acc: 0.7007, Val Loss: 0.5846, Val Acc: 0.8476
Epoch 16/100, Loss: 0.5895, Acc: 0.7020, Val Loss: 0.5685, Val Acc: 0.8594
Epoch 17/100, Loss: 0.5894, Acc: 0.7005, Val Loss: 0.5365, Val Acc: 0.8792
Epoch 18/100, Loss: 0.5878, Acc: 0.7020, Val Loss: 0.5057, Val Acc: 0.9124
Mejor modelo guardado con Val Loss: 0.5057
Epoch 19/100, Loss: 0.5876, Acc: 0.7014, Val Loss: 0.6049, Val Acc: 0.8023
Epoch 20/100, Loss: 0.5872, Acc: 0.7031, Val Loss: 0.5308, Val Acc: 0.8568
Epoch 21/100, Loss: 0.5872, Acc: 0.7026, Val Loss: 0.5678, Val Acc: 0.8177
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5824, Acc: 0.7068, Val Loss: 0.5563, Val Acc: 0.8457
Epoch 23/100, Loss: 0.5798, Acc: 0.7075, Val Loss: 0.5261, Val Acc: 0.8796
Epoch 24/100, Loss: 0.5785, Acc: 0.7079, Val Loss: 0.5586, Val Acc: 0.8395
Epoch 25/100, Loss: 0.5786, Acc: 0.7095, Val Loss: 0.5593, Val Acc: 0.8369
Epoch 26/100, Loss: 0.5785, Acc: 0.7086, Val Loss: 0.5641, Val Acc: 0.8328
Epoch 27/100, Loss: 0.5778, Acc: 0.7087, Val Loss: 0.5087, Val Acc: 0.8818
Epoch 28/100, Loss: 0.5776, Acc: 0.7083, Val Loss: 0.5511, Val Acc: 0.8351
Epoch 29/100, Loss: 0.5786, Acc: 0.7097, Val Loss: 0.4948, Val Acc: 0.8884
Mejor modelo guardado con Val Loss: 0.4948
Epoch 30/100, Loss: 0.5775, Acc: 0.7104, Val Loss: 0.5317, Val Acc: 0.8479
Epoch 31/100, Loss: 0.5761, Acc: 0.7076, Val Loss: 0.5198, Val Acc: 0.8564
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5733, Acc: 0.7132, Val Loss: 0.5116, Val Acc: 0.8708
Epoch 33/100, Loss: 0.5732, Acc: 0.7147, Val Loss: 0.5252, Val Acc: 0.8549
Epoch 34/100, Loss: 0.5737, Acc: 0.7126, Val Loss: 0.5229, Val Acc: 0.8597
Epoch 35/100, Loss: 0.5734, Acc: 0.7151, Val Loss: 0.4883, Val Acc: 0.8848
Mejor modelo guardado con Val Loss: 0.4883
Epoch 36/100, Loss: 0.5733, Acc: 0.7105, Val Loss: 0.5296, Val Acc: 0.8520
Epoch 37/100, Loss: 0.5725, Acc: 0.7104, Val Loss: 0.5160, Val Acc: 0.8645
Epoch 38/100, Loss: 0.5722, Acc: 0.7116, Val Loss: 0.5062, Val Acc: 0.8704
Epoch 39/100, Loss: 0.5716, Acc: 0.7151, Val Loss: 0.5353, Val Acc: 0.8446
Epoch 40/100, Loss: 0.5716, Acc: 0.7129, Val Loss: 0.5057, Val Acc: 0.8667
Epoch 41/100, Loss: 0.5716, Acc: 0.7150, Val Loss: 0.5358, Val Acc: 0.8380
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5709, Acc: 0.7136, Val Loss: 0.5181, Val Acc: 0.8560
Epoch 43/100, Loss: 0.5703, Acc: 0.7154, Val Loss: 0.4989, Val Acc: 0.8733
Epoch 44/100, Loss: 0.5699, Acc: 0.7154, Val Loss: 0.5283, Val Acc: 0.8487
Epoch 45/100, Loss: 0.5706, Acc: 0.7140, Val Loss: 0.5141, Val Acc: 0.8579
Epoch 46/100, Loss: 0.5697, Acc: 0.7149, Val Loss: 0.5246, Val Acc: 0.8487
Epoch 47/100, Loss: 0.5698, Acc: 0.7132, Val Loss: 0.4860, Val Acc: 0.8796
Mejor modelo guardado con Val Loss: 0.4860
Epoch 48/100, Loss: 0.5700, Acc: 0.7142, Val Loss: 0.4967, Val Acc: 0.8726
Epoch 49/100, Loss: 0.5696, Acc: 0.7167, Val Loss: 0.5144, Val Acc: 0.8560
Epoch 50/100, Loss: 0.5695, Acc: 0.7155, Val Loss: 0.5076, Val Acc: 0.8634
Epoch 51/100, Loss: 0.5689, Acc: 0.7152, Val Loss: 0.4968, Val Acc: 0.8719
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5686, Acc: 0.7157, Val Loss: 0.5228, Val Acc: 0.8505
Epoch 53/100, Loss: 0.5689, Acc: 0.7166, Val Loss: 0.5032, Val Acc: 0.8660
Epoch 54/100, Loss: 0.5685, Acc: 0.7167, Val Loss: 0.5072, Val Acc: 0.8608
Epoch 55/100, Loss: 0.5686, Acc: 0.7163, Val Loss: 0.5065, Val Acc: 0.8605
Epoch 56/100, Loss: 0.5683, Acc: 0.7178, Val Loss: 0.5029, Val Acc: 0.8645
Epoch 57/100, Loss: 0.5682, Acc: 0.7161, Val Loss: 0.5024, Val Acc: 0.8638
Epoch 58/100, Loss: 0.5683, Acc: 0.7150, Val Loss: 0.5097, Val Acc: 0.8582
Epoch 59/100, Loss: 0.5681, Acc: 0.7163, Val Loss: 0.5133, Val Acc: 0.8553
Epoch 60/100, Loss: 0.5680, Acc: 0.7155, Val Loss: 0.5006, Val Acc: 0.8616
Epoch 61/100, Loss: 0.5683, Acc: 0.7157, Val Loss: 0.4955, Val Acc: 0.8682
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5678, Acc: 0.7160, Val Loss: 0.4987, Val Acc: 0.8649
Epoch 63/100, Loss: 0.5676, Acc: 0.7184, Val Loss: 0.4941, Val Acc: 0.8693
Epoch 64/100, Loss: 0.5675, Acc: 0.7172, Val Loss: 0.5046, Val Acc: 0.8590
Epoch 65/100, Loss: 0.5676, Acc: 0.7163, Val Loss: 0.4998, Val Acc: 0.8641
Epoch 66/100, Loss: 0.5674, Acc: 0.7170, Val Loss: 0.4975, Val Acc: 0.8663
Epoch 67/100, Loss: 0.5675, Acc: 0.7171, Val Loss: 0.4984, Val Acc: 0.8638
Epoch 68/100, Loss: 0.5674, Acc: 0.7181, Val Loss: 0.5038, Val Acc: 0.8605
Epoch 69/100, Loss: 0.5675, Acc: 0.7169, Val Loss: 0.5027, Val Acc: 0.8612
Epoch 70/100, Loss: 0.5674, Acc: 0.7157, Val Loss: 0.4894, Val Acc: 0.8711
Epoch 71/100, Loss: 0.5674, Acc: 0.7183, Val Loss: 0.4916, Val Acc: 0.8697
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5672, Acc: 0.7175, Val Loss: 0.4959, Val Acc: 0.8671
Epoch 73/100, Loss: 0.5672, Acc: 0.7173, Val Loss: 0.4968, Val Acc: 0.8667
Epoch 74/100, Loss: 0.5667, Acc: 0.7177, Val Loss: 0.4952, Val Acc: 0.8675
Epoch 75/100, Loss: 0.5658, Acc: 0.7172, Val Loss: 0.4995, Val Acc: 0.8630
Epoch 76/100, Loss: 0.5654, Acc: 0.7187, Val Loss: 0.5008, Val Acc: 0.8601
Epoch 77/100, Loss: 0.5651, Acc: 0.7177, Val Loss: 0.4998, Val Acc: 0.8608
Epoch 78/100, Loss: 0.5648, Acc: 0.7191, Val Loss: 0.5006, Val Acc: 0.8605
Epoch 79/100, Loss: 0.5647, Acc: 0.7180, Val Loss: 0.5000, Val Acc: 0.8616
Epoch 80/100, Loss: 0.5643, Acc: 0.7190, Val Loss: 0.5024, Val Acc: 0.8594
Epoch 81/100, Loss: 0.5640, Acc: 0.7178, Val Loss: 0.5006, Val Acc: 0.8634
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5635, Acc: 0.7197, Val Loss: 0.5059, Val Acc: 0.8594
Epoch 83/100, Loss: 0.5630, Acc: 0.7189, Val Loss: 0.5060, Val Acc: 0.8619
Epoch 84/100, Loss: 0.5623, Acc: 0.7196, Val Loss: 0.5061, Val Acc: 0.8616
Epoch 85/100, Loss: 0.5620, Acc: 0.7188, Val Loss: 0.5057, Val Acc: 0.8627
Epoch 86/100, Loss: 0.5618, Acc: 0.7207, Val Loss: 0.5031, Val Acc: 0.8645
Epoch 87/100, Loss: 0.5617, Acc: 0.7195, Val Loss: 0.4976, Val Acc: 0.8671
Epoch 88/100, Loss: 0.5616, Acc: 0.7191, Val Loss: 0.5004, Val Acc: 0.8649
Epoch 89/100, Loss: 0.5616, Acc: 0.7196, Val Loss: 0.4996, Val Acc: 0.8649
Epoch 90/100, Loss: 0.5615, Acc: 0.7200, Val Loss: 0.5048, Val Acc: 0.8616
Epoch 91/100, Loss: 0.5614, Acc: 0.7177, Val Loss: 0.5011, Val Acc: 0.8641
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5613, Acc: 0.7195, Val Loss: 0.5021, Val Acc: 0.8641
Epoch 93/100, Loss: 0.5613, Acc: 0.7198, Val Loss: 0.5054, Val Acc: 0.8616
Epoch 94/100, Loss: 0.5612, Acc: 0.7199, Val Loss: 0.4995, Val Acc: 0.8649
Epoch 95/100, Loss: 0.5612, Acc: 0.7196, Val Loss: 0.5023, Val Acc: 0.8630
Epoch 96/100, Loss: 0.5611, Acc: 0.7197, Val Loss: 0.5044, Val Acc: 0.8608
Epoch 97/100, Loss: 0.5610, Acc: 0.7194, Val Loss: 0.5008, Val Acc: 0.8638
Epoch 98/100, Loss: 0.5609, Acc: 0.7193, Val Loss: 0.4980, Val Acc: 0.8660
Epoch 99/100, Loss: 0.5611, Acc: 0.7195, Val Loss: 0.5007, Val Acc: 0.8638
Epoch 100/100, Loss: 0.5609, Acc: 0.7197, Val Loss: 0.5022, Val Acc: 0.8627

##############################
Resultados para principal:  032  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  5 
 {'training': [0.560948135288115, 0.7197499080544317, 0.6846011131725418, 0.8145695364238411, 0.7439516129032258], 'validate': [0.5022073443545851, 0.8626656848306333, 0.9330396475770925, 0.7809734513274337, 0.8502609393817744], 'test': [0.6502080979170622, 0.6307420494699647, 0.585, 0.8968160377358491, 0.7081005586592178]}

##############################
Resultados para window:  5 
 {'067:124:010:009:118:032': {'training': [0.40409018946027175, 0.8165685913938948, 0.8473652331920049, 0.772075055187638, 0.8079699682356338], 'validate': [0.405043731248656, 0.8350515463917526, 0.7959582790091264, 0.9004424778761062, 0.8449826989619377], 'test': [0.805612392378626, 0.6604829210836278, 0.6850715746421268, 0.5925707547169812, 0.6354726525450521]}, '124:067:010:009:118:032': {'training': [0.4853527890535434, 0.7711474806914307, 0.7511505028123402, 0.8107064017660044, 0.7797929753162877], 'validate': [0.7387869468955106, 0.5821060382916053, 0.5598915989159892, 0.7617994100294986, 0.6454233052171197], 'test': [0.7776274250613319, 0.5082449941107184, 0.504590395480226, 0.8425707547169812, 0.6311837455830389]}, '010:067:124:009:118:032': {'training': [0.5046593377961969, 0.7369437293122472, 0.6908821349147517, 0.8572479764532744, 0.7651260159264428], 'validate': [0.8878178582635037, 0.49705449189985274, 0.4966931216931217, 0.553834808259587, 0.5237099023709902], 'test': [0.6562125064708568, 0.6154299175500589, 0.5771971496437055, 0.8596698113207547, 0.6906679298910469]}, '009:067:124:010:118:032': {'training': [0.12496375474214291, 0.947682971680765, 0.9382315865298038, 0.9584253127299485, 0.9482209482209483], 'validate': [0.20243084430153113, 0.9193667157584683, 0.875743555849306, 0.9771386430678466, 0.9236667828511677], 'test': [0.20692744092256934, 0.9169611307420494, 0.9158823529411765, 0.9180424528301887, 0.9169611307420494]}, '118:067:124:010:009:032': {'training': [0.5664829976990978, 0.7010849577050386, 0.6494732521548775, 0.873252391464312, 0.7449195763044331], 'validate': [0.41367024495158083, 0.8634020618556701, 0.9823702252693438, 0.7396755162241888, 0.843920908708456], 'test': [0.5680393802898901, 0.714075382803298, 0.6522469550608988, 0.9156839622641509, 0.7618346823644837]}, '032:067:124:010:009:118': {'training': [0.560948135288115, 0.7197499080544317, 0.6846011131725418, 0.8145695364238411, 0.7439516129032258], 'validate': [0.5022073443545851, 0.8626656848306333, 0.9330396475770925, 0.7809734513274337, 0.8502609393817744], 'test': [0.6502080979170622, 0.6307420494699647, 0.585, 0.8968160377358491, 0.7081005586592178]}}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  095  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  095  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6850, Acc: 0.5579, Val Loss: 0.6845, Val Acc: 0.5967
Mejor modelo guardado con Val Loss: 0.6845
Epoch 2/100, Loss: 0.6817, Acc: 0.5767, Val Loss: 0.6742, Val Acc: 0.6402
Mejor modelo guardado con Val Loss: 0.6742
Epoch 3/100, Loss: 0.6782, Acc: 0.5764, Val Loss: 0.6676, Val Acc: 0.5528
Mejor modelo guardado con Val Loss: 0.6676
Epoch 4/100, Loss: 0.6710, Acc: 0.6006, Val Loss: 0.6632, Val Acc: 0.5745
Mejor modelo guardado con Val Loss: 0.6632
Epoch 5/100, Loss: 0.6671, Acc: 0.6040, Val Loss: 0.6593, Val Acc: 0.5926
Mejor modelo guardado con Val Loss: 0.6593
Epoch 6/100, Loss: 0.6614, Acc: 0.6136, Val Loss: 0.6727, Val Acc: 0.5203
Epoch 7/100, Loss: 0.6593, Acc: 0.6110, Val Loss: 0.6668, Val Acc: 0.5343
Epoch 8/100, Loss: 0.6577, Acc: 0.6057, Val Loss: 0.6522, Val Acc: 0.5812
Mejor modelo guardado con Val Loss: 0.6522
Epoch 9/100, Loss: 0.6545, Acc: 0.6149, Val Loss: 0.6385, Val Acc: 0.6159
Mejor modelo guardado con Val Loss: 0.6385
Epoch 10/100, Loss: 0.6475, Acc: 0.6187, Val Loss: 0.6600, Val Acc: 0.5601
Epoch 11/100, Loss: 0.6494, Acc: 0.6197, Val Loss: 0.6576, Val Acc: 0.5613
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6435, Acc: 0.6275, Val Loss: 0.6498, Val Acc: 0.5841
Epoch 13/100, Loss: 0.6466, Acc: 0.6180, Val Loss: 0.6511, Val Acc: 0.5860
Epoch 14/100, Loss: 0.6415, Acc: 0.6297, Val Loss: 0.6419, Val Acc: 0.5893
Epoch 15/100, Loss: 0.6398, Acc: 0.6304, Val Loss: 0.6266, Val Acc: 0.6255
Mejor modelo guardado con Val Loss: 0.6266
Epoch 16/100, Loss: 0.6386, Acc: 0.6321, Val Loss: 0.6275, Val Acc: 0.6244
Epoch 17/100, Loss: 0.6369, Acc: 0.6321, Val Loss: 0.6332, Val Acc: 0.6041
Epoch 18/100, Loss: 0.6369, Acc: 0.6345, Val Loss: 0.6185, Val Acc: 0.6498
Mejor modelo guardado con Val Loss: 0.6185
Epoch 19/100, Loss: 0.6417, Acc: 0.6256, Val Loss: 0.6446, Val Acc: 0.5908
Epoch 20/100, Loss: 0.6380, Acc: 0.6296, Val Loss: 0.6256, Val Acc: 0.6081
Epoch 21/100, Loss: 0.6358, Acc: 0.6368, Val Loss: 0.6406, Val Acc: 0.5937
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6331, Acc: 0.6390, Val Loss: 0.6196, Val Acc: 0.6339
Epoch 23/100, Loss: 0.6319, Acc: 0.6447, Val Loss: 0.6332, Val Acc: 0.6085
Epoch 24/100, Loss: 0.6316, Acc: 0.6438, Val Loss: 0.6185, Val Acc: 0.6351
Epoch 25/100, Loss: 0.6310, Acc: 0.6428, Val Loss: 0.6311, Val Acc: 0.6137
Epoch 26/100, Loss: 0.6301, Acc: 0.6420, Val Loss: 0.6261, Val Acc: 0.6232
Epoch 27/100, Loss: 0.6302, Acc: 0.6460, Val Loss: 0.6521, Val Acc: 0.5875
Epoch 28/100, Loss: 0.6303, Acc: 0.6422, Val Loss: 0.6295, Val Acc: 0.6125
Epoch 29/100, Loss: 0.6304, Acc: 0.6448, Val Loss: 0.6359, Val Acc: 0.6048
Epoch 30/100, Loss: 0.6294, Acc: 0.6469, Val Loss: 0.6333, Val Acc: 0.6137
Epoch 31/100, Loss: 0.6283, Acc: 0.6477, Val Loss: 0.6424, Val Acc: 0.5993
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6282, Acc: 0.6483, Val Loss: 0.6414, Val Acc: 0.6018
Epoch 33/100, Loss: 0.6272, Acc: 0.6506, Val Loss: 0.6312, Val Acc: 0.6166
Epoch 34/100, Loss: 0.6271, Acc: 0.6521, Val Loss: 0.6255, Val Acc: 0.6229
Epoch 35/100, Loss: 0.6272, Acc: 0.6499, Val Loss: 0.6224, Val Acc: 0.6288
Epoch 36/100, Loss: 0.6266, Acc: 0.6499, Val Loss: 0.6204, Val Acc: 0.6336
Epoch 37/100, Loss: 0.6270, Acc: 0.6472, Val Loss: 0.6380, Val Acc: 0.6066
Epoch 38/100, Loss: 0.6262, Acc: 0.6504, Val Loss: 0.6473, Val Acc: 0.5930
Epoch 39/100, Loss: 0.6263, Acc: 0.6530, Val Loss: 0.6209, Val Acc: 0.6295
Epoch 40/100, Loss: 0.6262, Acc: 0.6521, Val Loss: 0.6373, Val Acc: 0.6052
Epoch 41/100, Loss: 0.6260, Acc: 0.6523, Val Loss: 0.6351, Val Acc: 0.6118
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6251, Acc: 0.6522, Val Loss: 0.6287, Val Acc: 0.6221
Epoch 43/100, Loss: 0.6252, Acc: 0.6533, Val Loss: 0.6251, Val Acc: 0.6258
Epoch 44/100, Loss: 0.6249, Acc: 0.6534, Val Loss: 0.6387, Val Acc: 0.6048
Epoch 45/100, Loss: 0.6250, Acc: 0.6527, Val Loss: 0.6246, Val Acc: 0.6258
Epoch 46/100, Loss: 0.6251, Acc: 0.6526, Val Loss: 0.6303, Val Acc: 0.6210
Epoch 47/100, Loss: 0.6248, Acc: 0.6516, Val Loss: 0.6347, Val Acc: 0.6133
Epoch 48/100, Loss: 0.6248, Acc: 0.6535, Val Loss: 0.6290, Val Acc: 0.6218
Epoch 49/100, Loss: 0.6245, Acc: 0.6538, Val Loss: 0.6342, Val Acc: 0.6144
Epoch 50/100, Loss: 0.6245, Acc: 0.6534, Val Loss: 0.6327, Val Acc: 0.6159
Epoch 51/100, Loss: 0.6243, Acc: 0.6544, Val Loss: 0.6470, Val Acc: 0.5926
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6241, Acc: 0.6560, Val Loss: 0.6285, Val Acc: 0.6240
Epoch 53/100, Loss: 0.6237, Acc: 0.6553, Val Loss: 0.6404, Val Acc: 0.6044
Epoch 54/100, Loss: 0.6241, Acc: 0.6551, Val Loss: 0.6281, Val Acc: 0.6236
Epoch 55/100, Loss: 0.6241, Acc: 0.6531, Val Loss: 0.6320, Val Acc: 0.6199
Epoch 56/100, Loss: 0.6237, Acc: 0.6565, Val Loss: 0.6297, Val Acc: 0.6203
Epoch 57/100, Loss: 0.6239, Acc: 0.6549, Val Loss: 0.6371, Val Acc: 0.6089
Epoch 58/100, Loss: 0.6237, Acc: 0.6553, Val Loss: 0.6324, Val Acc: 0.6185
Epoch 59/100, Loss: 0.6239, Acc: 0.6563, Val Loss: 0.6268, Val Acc: 0.6262
Epoch 60/100, Loss: 0.6237, Acc: 0.6552, Val Loss: 0.6263, Val Acc: 0.6255
Epoch 61/100, Loss: 0.6238, Acc: 0.6550, Val Loss: 0.6339, Val Acc: 0.6177
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6233, Acc: 0.6553, Val Loss: 0.6298, Val Acc: 0.6214
Epoch 63/100, Loss: 0.6236, Acc: 0.6562, Val Loss: 0.6343, Val Acc: 0.6148
Epoch 64/100, Loss: 0.6233, Acc: 0.6548, Val Loss: 0.6338, Val Acc: 0.6170
Epoch 65/100, Loss: 0.6232, Acc: 0.6569, Val Loss: 0.6315, Val Acc: 0.6192
Epoch 66/100, Loss: 0.6235, Acc: 0.6553, Val Loss: 0.6311, Val Acc: 0.6199
Epoch 67/100, Loss: 0.6233, Acc: 0.6552, Val Loss: 0.6312, Val Acc: 0.6196
Epoch 68/100, Loss: 0.6232, Acc: 0.6564, Val Loss: 0.6332, Val Acc: 0.6185
Epoch 69/100, Loss: 0.6232, Acc: 0.6564, Val Loss: 0.6300, Val Acc: 0.6207
Epoch 70/100, Loss: 0.6233, Acc: 0.6546, Val Loss: 0.6358, Val Acc: 0.6107
Epoch 71/100, Loss: 0.6232, Acc: 0.6559, Val Loss: 0.6367, Val Acc: 0.6107
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6229, Acc: 0.6565, Val Loss: 0.6292, Val Acc: 0.6214
Epoch 73/100, Loss: 0.6231, Acc: 0.6549, Val Loss: 0.6320, Val Acc: 0.6185
Epoch 74/100, Loss: 0.6231, Acc: 0.6547, Val Loss: 0.6309, Val Acc: 0.6210
Epoch 75/100, Loss: 0.6230, Acc: 0.6558, Val Loss: 0.6319, Val Acc: 0.6185
Epoch 76/100, Loss: 0.6230, Acc: 0.6559, Val Loss: 0.6315, Val Acc: 0.6188
Epoch 77/100, Loss: 0.6229, Acc: 0.6561, Val Loss: 0.6346, Val Acc: 0.6133
Epoch 78/100, Loss: 0.6229, Acc: 0.6560, Val Loss: 0.6353, Val Acc: 0.6125
Epoch 79/100, Loss: 0.6230, Acc: 0.6555, Val Loss: 0.6340, Val Acc: 0.6162
Epoch 80/100, Loss: 0.6229, Acc: 0.6555, Val Loss: 0.6321, Val Acc: 0.6173
Epoch 81/100, Loss: 0.6229, Acc: 0.6562, Val Loss: 0.6362, Val Acc: 0.6114
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6229, Acc: 0.6559, Val Loss: 0.6356, Val Acc: 0.6125
Epoch 83/100, Loss: 0.6228, Acc: 0.6554, Val Loss: 0.6362, Val Acc: 0.6122
Epoch 84/100, Loss: 0.6228, Acc: 0.6555, Val Loss: 0.6336, Val Acc: 0.6162
Epoch 85/100, Loss: 0.6229, Acc: 0.6557, Val Loss: 0.6302, Val Acc: 0.6196
Epoch 86/100, Loss: 0.6229, Acc: 0.6556, Val Loss: 0.6354, Val Acc: 0.6125
Epoch 87/100, Loss: 0.6228, Acc: 0.6555, Val Loss: 0.6330, Val Acc: 0.6177
Epoch 88/100, Loss: 0.6228, Acc: 0.6562, Val Loss: 0.6324, Val Acc: 0.6192
Epoch 89/100, Loss: 0.6227, Acc: 0.6570, Val Loss: 0.6308, Val Acc: 0.6192
Epoch 90/100, Loss: 0.6228, Acc: 0.6552, Val Loss: 0.6354, Val Acc: 0.6118
Epoch 91/100, Loss: 0.6228, Acc: 0.6564, Val Loss: 0.6335, Val Acc: 0.6162
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6227, Acc: 0.6550, Val Loss: 0.6328, Val Acc: 0.6185
Epoch 93/100, Loss: 0.6228, Acc: 0.6556, Val Loss: 0.6310, Val Acc: 0.6207
Epoch 94/100, Loss: 0.6228, Acc: 0.6562, Val Loss: 0.6335, Val Acc: 0.6159
Epoch 95/100, Loss: 0.6227, Acc: 0.6567, Val Loss: 0.6327, Val Acc: 0.6185
Epoch 96/100, Loss: 0.6227, Acc: 0.6548, Val Loss: 0.6350, Val Acc: 0.6125
Epoch 97/100, Loss: 0.6227, Acc: 0.6554, Val Loss: 0.6320, Val Acc: 0.6188
Epoch 98/100, Loss: 0.6226, Acc: 0.6559, Val Loss: 0.6315, Val Acc: 0.6177
Epoch 99/100, Loss: 0.6227, Acc: 0.6549, Val Loss: 0.6323, Val Acc: 0.6196
Epoch 100/100, Loss: 0.6226, Acc: 0.6565, Val Loss: 0.6322, Val Acc: 0.6192

##############################
Resultados para principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11 
 {'training': [0.6226424421206898, 0.6564857405703772, 0.6312287217579696, 0.7511970534069982, 0.6860073999327279], 'validate': [0.6321756462025088, 0.6191881918819189, 0.6111888111888112, 0.6474074074074074, 0.6287769784172662], 'test': [0.6351821529415419, 0.6448377581120944, 0.5993458708094849, 0.8674556213017751, 0.7088974854932302]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  065  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  065  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6924, Acc: 0.5166, Val Loss: 0.6956, Val Acc: 0.5000
Mejor modelo guardado con Val Loss: 0.6956
Epoch 2/100, Loss: 0.6918, Acc: 0.5204, Val Loss: 0.6931, Val Acc: 0.5015
Mejor modelo guardado con Val Loss: 0.6931
Epoch 3/100, Loss: 0.6930, Acc: 0.5050, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 4/100, Loss: 0.6934, Acc: 0.5031, Val Loss: 0.6942, Val Acc: 0.4982
Epoch 5/100, Loss: 0.6935, Acc: 0.4955, Val Loss: 0.6935, Val Acc: 0.4982
Epoch 6/100, Loss: 0.6935, Acc: 0.4914, Val Loss: 0.6930, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6930
Epoch 7/100, Loss: 0.6934, Acc: 0.4955, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 8/100, Loss: 0.6935, Acc: 0.4949, Val Loss: 0.6941, Val Acc: 0.4982
Epoch 9/100, Loss: 0.6935, Acc: 0.4949, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 10/100, Loss: 0.6934, Acc: 0.4963, Val Loss: 0.6937, Val Acc: 0.4982
Epoch 11/100, Loss: 0.6936, Acc: 0.4996, Val Loss: 0.6934, Val Acc: 0.4982
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4925, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 13/100, Loss: 0.6933, Acc: 0.5055, Val Loss: 0.6935, Val Acc: 0.4982
Epoch 14/100, Loss: 0.6932, Acc: 0.5040, Val Loss: 0.6934, Val Acc: 0.4982
Epoch 15/100, Loss: 0.6932, Acc: 0.5032, Val Loss: 0.6938, Val Acc: 0.4982
Epoch 16/100, Loss: 0.6936, Acc: 0.4877, Val Loss: 0.6933, Val Acc: 0.4982
Epoch 17/100, Loss: 0.6932, Acc: 0.5030, Val Loss: 0.6934, Val Acc: 0.4989
Epoch 18/100, Loss: 0.6933, Acc: 0.5027, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 19/100, Loss: 0.6932, Acc: 0.5064, Val Loss: 0.6934, Val Acc: 0.4982
Epoch 20/100, Loss: 0.6933, Acc: 0.4994, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 21/100, Loss: 0.6933, Acc: 0.4960, Val Loss: 0.6932, Val Acc: 0.4982
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4971, Val Loss: 0.6933, Val Acc: 0.4982
Epoch 23/100, Loss: 0.6931, Acc: 0.4966, Val Loss: 0.6941, Val Acc: 0.5081
Epoch 24/100, Loss: 0.6925, Acc: 0.5201, Val Loss: 0.6936, Val Acc: 0.4982
Epoch 25/100, Loss: 0.6920, Acc: 0.5262, Val Loss: 0.6934, Val Acc: 0.5037
Epoch 26/100, Loss: 0.6927, Acc: 0.5198, Val Loss: 0.6941, Val Acc: 0.4786
Epoch 27/100, Loss: 0.6922, Acc: 0.5243, Val Loss: 0.6940, Val Acc: 0.4815
Epoch 28/100, Loss: 0.6918, Acc: 0.5281, Val Loss: 0.6935, Val Acc: 0.4989
Epoch 29/100, Loss: 0.6917, Acc: 0.5281, Val Loss: 0.6942, Val Acc: 0.4815
Epoch 30/100, Loss: 0.6916, Acc: 0.5292, Val Loss: 0.6938, Val Acc: 0.4985
Epoch 31/100, Loss: 0.6913, Acc: 0.5377, Val Loss: 0.6951, Val Acc: 0.4753
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6910, Acc: 0.5373, Val Loss: 0.6943, Val Acc: 0.4889
Epoch 33/100, Loss: 0.6909, Acc: 0.5352, Val Loss: 0.6943, Val Acc: 0.4926
Epoch 34/100, Loss: 0.6906, Acc: 0.5406, Val Loss: 0.6949, Val Acc: 0.4875
Epoch 35/100, Loss: 0.6905, Acc: 0.5397, Val Loss: 0.6943, Val Acc: 0.4911
Epoch 36/100, Loss: 0.6904, Acc: 0.5401, Val Loss: 0.6954, Val Acc: 0.4745
Epoch 37/100, Loss: 0.6903, Acc: 0.5408, Val Loss: 0.6960, Val Acc: 0.4668
Epoch 38/100, Loss: 0.6902, Acc: 0.5403, Val Loss: 0.6959, Val Acc: 0.4723
Epoch 39/100, Loss: 0.6902, Acc: 0.5330, Val Loss: 0.6939, Val Acc: 0.5018
Epoch 40/100, Loss: 0.6900, Acc: 0.5386, Val Loss: 0.6956, Val Acc: 0.4897
Epoch 41/100, Loss: 0.6892, Acc: 0.5413, Val Loss: 0.6974, Val Acc: 0.4720
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6885, Acc: 0.5482, Val Loss: 0.6966, Val Acc: 0.4841
Epoch 43/100, Loss: 0.6883, Acc: 0.5514, Val Loss: 0.6974, Val Acc: 0.4664
Epoch 44/100, Loss: 0.6883, Acc: 0.5481, Val Loss: 0.6967, Val Acc: 0.4797
Epoch 45/100, Loss: 0.6882, Acc: 0.5485, Val Loss: 0.6964, Val Acc: 0.4823
Epoch 46/100, Loss: 0.6880, Acc: 0.5483, Val Loss: 0.6969, Val Acc: 0.4753
Epoch 47/100, Loss: 0.6879, Acc: 0.5492, Val Loss: 0.6971, Val Acc: 0.4745
Epoch 48/100, Loss: 0.6877, Acc: 0.5523, Val Loss: 0.6971, Val Acc: 0.4764
Epoch 49/100, Loss: 0.6877, Acc: 0.5477, Val Loss: 0.6972, Val Acc: 0.4734
Epoch 50/100, Loss: 0.6875, Acc: 0.5522, Val Loss: 0.6978, Val Acc: 0.4683
Epoch 51/100, Loss: 0.6873, Acc: 0.5524, Val Loss: 0.6981, Val Acc: 0.4742
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6872, Acc: 0.5522, Val Loss: 0.6977, Val Acc: 0.4745
Epoch 53/100, Loss: 0.6872, Acc: 0.5501, Val Loss: 0.6978, Val Acc: 0.4720
Epoch 54/100, Loss: 0.6871, Acc: 0.5521, Val Loss: 0.6979, Val Acc: 0.4708
Epoch 55/100, Loss: 0.6871, Acc: 0.5524, Val Loss: 0.6979, Val Acc: 0.4742
Epoch 56/100, Loss: 0.6870, Acc: 0.5515, Val Loss: 0.6979, Val Acc: 0.4742
Epoch 57/100, Loss: 0.6869, Acc: 0.5542, Val Loss: 0.6980, Val Acc: 0.4753
Epoch 58/100, Loss: 0.6869, Acc: 0.5531, Val Loss: 0.6980, Val Acc: 0.4760
Epoch 59/100, Loss: 0.6869, Acc: 0.5547, Val Loss: 0.6978, Val Acc: 0.4797
Epoch 60/100, Loss: 0.6868, Acc: 0.5528, Val Loss: 0.6977, Val Acc: 0.4797
Epoch 61/100, Loss: 0.6868, Acc: 0.5535, Val Loss: 0.6985, Val Acc: 0.4638
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6866, Acc: 0.5535, Val Loss: 0.6984, Val Acc: 0.4712
Epoch 63/100, Loss: 0.6866, Acc: 0.5538, Val Loss: 0.6983, Val Acc: 0.4712
Epoch 64/100, Loss: 0.6865, Acc: 0.5542, Val Loss: 0.6981, Val Acc: 0.4749
Epoch 65/100, Loss: 0.6866, Acc: 0.5539, Val Loss: 0.6983, Val Acc: 0.4753
Epoch 66/100, Loss: 0.6865, Acc: 0.5552, Val Loss: 0.6984, Val Acc: 0.4745
Epoch 67/100, Loss: 0.6865, Acc: 0.5552, Val Loss: 0.6981, Val Acc: 0.4804
Epoch 68/100, Loss: 0.6864, Acc: 0.5557, Val Loss: 0.6985, Val Acc: 0.4697
Epoch 69/100, Loss: 0.6864, Acc: 0.5535, Val Loss: 0.6985, Val Acc: 0.4731
Epoch 70/100, Loss: 0.6864, Acc: 0.5537, Val Loss: 0.6985, Val Acc: 0.4731
Epoch 71/100, Loss: 0.6864, Acc: 0.5546, Val Loss: 0.6986, Val Acc: 0.4734
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6863, Acc: 0.5562, Val Loss: 0.6986, Val Acc: 0.4727
Epoch 73/100, Loss: 0.6863, Acc: 0.5547, Val Loss: 0.6987, Val Acc: 0.4683
Epoch 74/100, Loss: 0.6863, Acc: 0.5563, Val Loss: 0.6988, Val Acc: 0.4686
Epoch 75/100, Loss: 0.6863, Acc: 0.5546, Val Loss: 0.6987, Val Acc: 0.4716
Epoch 76/100, Loss: 0.6863, Acc: 0.5546, Val Loss: 0.6988, Val Acc: 0.4683
Epoch 77/100, Loss: 0.6863, Acc: 0.5541, Val Loss: 0.6987, Val Acc: 0.4731
Epoch 78/100, Loss: 0.6862, Acc: 0.5550, Val Loss: 0.6987, Val Acc: 0.4727
Epoch 79/100, Loss: 0.6863, Acc: 0.5565, Val Loss: 0.6987, Val Acc: 0.4731
Epoch 80/100, Loss: 0.6862, Acc: 0.5538, Val Loss: 0.6988, Val Acc: 0.4731
Epoch 81/100, Loss: 0.6862, Acc: 0.5548, Val Loss: 0.6987, Val Acc: 0.4720
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6862, Acc: 0.5544, Val Loss: 0.6988, Val Acc: 0.4738
Epoch 83/100, Loss: 0.6862, Acc: 0.5546, Val Loss: 0.6988, Val Acc: 0.4738
Epoch 84/100, Loss: 0.6861, Acc: 0.5546, Val Loss: 0.6989, Val Acc: 0.4731
Epoch 85/100, Loss: 0.6861, Acc: 0.5558, Val Loss: 0.6988, Val Acc: 0.4738
Epoch 86/100, Loss: 0.6861, Acc: 0.5560, Val Loss: 0.6989, Val Acc: 0.4720
Epoch 87/100, Loss: 0.6861, Acc: 0.5548, Val Loss: 0.6989, Val Acc: 0.4731
Epoch 88/100, Loss: 0.6861, Acc: 0.5544, Val Loss: 0.6988, Val Acc: 0.4738
Epoch 89/100, Loss: 0.6861, Acc: 0.5542, Val Loss: 0.6990, Val Acc: 0.4723
Epoch 90/100, Loss: 0.6861, Acc: 0.5547, Val Loss: 0.6990, Val Acc: 0.4742
Epoch 91/100, Loss: 0.6860, Acc: 0.5558, Val Loss: 0.6991, Val Acc: 0.4720
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6860, Acc: 0.5545, Val Loss: 0.6990, Val Acc: 0.4738
Epoch 93/100, Loss: 0.6860, Acc: 0.5543, Val Loss: 0.6992, Val Acc: 0.4712
Epoch 94/100, Loss: 0.6860, Acc: 0.5560, Val Loss: 0.6992, Val Acc: 0.4672
Epoch 95/100, Loss: 0.6860, Acc: 0.5553, Val Loss: 0.6991, Val Acc: 0.4731
Epoch 96/100, Loss: 0.6860, Acc: 0.5549, Val Loss: 0.6993, Val Acc: 0.4708
Epoch 97/100, Loss: 0.6859, Acc: 0.5552, Val Loss: 0.6991, Val Acc: 0.4731
Epoch 98/100, Loss: 0.6859, Acc: 0.5554, Val Loss: 0.6993, Val Acc: 0.4734
Epoch 99/100, Loss: 0.6859, Acc: 0.5559, Val Loss: 0.6993, Val Acc: 0.4734
Epoch 100/100, Loss: 0.6859, Acc: 0.5543, Val Loss: 0.6993, Val Acc: 0.4727

##############################
Resultados para principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11 
 {'training': [0.6858933026020748, 0.5542778288868445, 0.5457674855265217, 0.6423572744014733, 0.5901361982911767], 'validate': [0.6992814111155133, 0.47269372693726935, 0.4780189204229271, 0.6362962962962962, 0.5459167461074039], 'test': [0.6933400878366435, 0.5014749262536873, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  013  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  013  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6920, Acc: 0.5201, Val Loss: 0.6926, Val Acc: 0.5041
Mejor modelo guardado con Val Loss: 0.6926
Epoch 2/100, Loss: 0.6921, Acc: 0.5139, Val Loss: 0.6895, Val Acc: 0.5221
Mejor modelo guardado con Val Loss: 0.6895
Epoch 3/100, Loss: 0.6906, Acc: 0.5484, Val Loss: 0.6885, Val Acc: 0.5506
Mejor modelo guardado con Val Loss: 0.6885
Epoch 4/100, Loss: 0.6872, Acc: 0.5768, Val Loss: 0.6828, Val Acc: 0.6055
Mejor modelo guardado con Val Loss: 0.6828
Epoch 5/100, Loss: 0.6873, Acc: 0.5537, Val Loss: 0.6816, Val Acc: 0.5989
Mejor modelo guardado con Val Loss: 0.6816
Epoch 6/100, Loss: 0.6809, Acc: 0.5943, Val Loss: 0.6777, Val Acc: 0.6140
Mejor modelo guardado con Val Loss: 0.6777
Epoch 7/100, Loss: 0.6776, Acc: 0.6012, Val Loss: 0.6721, Val Acc: 0.6258
Mejor modelo guardado con Val Loss: 0.6721
Epoch 8/100, Loss: 0.6754, Acc: 0.5995, Val Loss: 0.6621, Val Acc: 0.6561
Mejor modelo guardado con Val Loss: 0.6621
Epoch 9/100, Loss: 0.6731, Acc: 0.6046, Val Loss: 0.6527, Val Acc: 0.6797
Mejor modelo guardado con Val Loss: 0.6527
Epoch 10/100, Loss: 0.6704, Acc: 0.6070, Val Loss: 0.6736, Val Acc: 0.6137
Epoch 11/100, Loss: 0.6713, Acc: 0.6005, Val Loss: 0.6488, Val Acc: 0.6775
Mejor modelo guardado con Val Loss: 0.6488
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6670, Acc: 0.6103, Val Loss: 0.6556, Val Acc: 0.6572
Epoch 13/100, Loss: 0.6652, Acc: 0.6155, Val Loss: 0.6672, Val Acc: 0.6218
Epoch 14/100, Loss: 0.6648, Acc: 0.6117, Val Loss: 0.6485, Val Acc: 0.6661
Mejor modelo guardado con Val Loss: 0.6485
Epoch 15/100, Loss: 0.6633, Acc: 0.6151, Val Loss: 0.6412, Val Acc: 0.6849
Mejor modelo guardado con Val Loss: 0.6412
Epoch 16/100, Loss: 0.6643, Acc: 0.6110, Val Loss: 0.6752, Val Acc: 0.6137
Epoch 17/100, Loss: 0.6627, Acc: 0.6168, Val Loss: 0.6416, Val Acc: 0.6779
Epoch 18/100, Loss: 0.6622, Acc: 0.6161, Val Loss: 0.6636, Val Acc: 0.6332
Epoch 19/100, Loss: 0.6624, Acc: 0.6143, Val Loss: 0.6570, Val Acc: 0.6446
Epoch 20/100, Loss: 0.6617, Acc: 0.6143, Val Loss: 0.6415, Val Acc: 0.6734
Epoch 21/100, Loss: 0.6603, Acc: 0.6169, Val Loss: 0.6612, Val Acc: 0.6347
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6598, Acc: 0.6173, Val Loss: 0.6603, Val Acc: 0.6417
Epoch 23/100, Loss: 0.6601, Acc: 0.6152, Val Loss: 0.6693, Val Acc: 0.6258
Epoch 24/100, Loss: 0.6587, Acc: 0.6206, Val Loss: 0.6435, Val Acc: 0.6668
Epoch 25/100, Loss: 0.6593, Acc: 0.6168, Val Loss: 0.6574, Val Acc: 0.6498
Epoch 26/100, Loss: 0.6583, Acc: 0.6179, Val Loss: 0.6554, Val Acc: 0.6517
Epoch 27/100, Loss: 0.6580, Acc: 0.6197, Val Loss: 0.6505, Val Acc: 0.6572
Epoch 28/100, Loss: 0.6581, Acc: 0.6167, Val Loss: 0.6418, Val Acc: 0.6701
Epoch 29/100, Loss: 0.6579, Acc: 0.6187, Val Loss: 0.6457, Val Acc: 0.6649
Epoch 30/100, Loss: 0.6575, Acc: 0.6190, Val Loss: 0.6445, Val Acc: 0.6686
Epoch 31/100, Loss: 0.6577, Acc: 0.6178, Val Loss: 0.6354, Val Acc: 0.6819
Mejor modelo guardado con Val Loss: 0.6354
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6569, Acc: 0.6190, Val Loss: 0.6556, Val Acc: 0.6539
Epoch 33/100, Loss: 0.6566, Acc: 0.6214, Val Loss: 0.6601, Val Acc: 0.6491
Epoch 34/100, Loss: 0.6565, Acc: 0.6203, Val Loss: 0.6438, Val Acc: 0.6690
Epoch 35/100, Loss: 0.6562, Acc: 0.6215, Val Loss: 0.6417, Val Acc: 0.6690
Epoch 36/100, Loss: 0.6561, Acc: 0.6215, Val Loss: 0.6541, Val Acc: 0.6554
Epoch 37/100, Loss: 0.6557, Acc: 0.6236, Val Loss: 0.6581, Val Acc: 0.6509
Epoch 38/100, Loss: 0.6556, Acc: 0.6223, Val Loss: 0.6490, Val Acc: 0.6616
Epoch 39/100, Loss: 0.6555, Acc: 0.6186, Val Loss: 0.6313, Val Acc: 0.6852
Mejor modelo guardado con Val Loss: 0.6313
Epoch 40/100, Loss: 0.6556, Acc: 0.6190, Val Loss: 0.6570, Val Acc: 0.6524
Epoch 41/100, Loss: 0.6552, Acc: 0.6220, Val Loss: 0.6561, Val Acc: 0.6528
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6547, Acc: 0.6215, Val Loss: 0.6535, Val Acc: 0.6568
Epoch 43/100, Loss: 0.6545, Acc: 0.6198, Val Loss: 0.6416, Val Acc: 0.6705
Epoch 44/100, Loss: 0.6548, Acc: 0.6199, Val Loss: 0.6461, Val Acc: 0.6664
Epoch 45/100, Loss: 0.6543, Acc: 0.6204, Val Loss: 0.6406, Val Acc: 0.6716
Epoch 46/100, Loss: 0.6542, Acc: 0.6218, Val Loss: 0.6421, Val Acc: 0.6683
Epoch 47/100, Loss: 0.6542, Acc: 0.6199, Val Loss: 0.6450, Val Acc: 0.6686
Epoch 48/100, Loss: 0.6538, Acc: 0.6220, Val Loss: 0.6463, Val Acc: 0.6657
Epoch 49/100, Loss: 0.6537, Acc: 0.6217, Val Loss: 0.6474, Val Acc: 0.6653
Epoch 50/100, Loss: 0.6539, Acc: 0.6214, Val Loss: 0.6466, Val Acc: 0.6657
Epoch 51/100, Loss: 0.6537, Acc: 0.6221, Val Loss: 0.6467, Val Acc: 0.6657
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6534, Acc: 0.6218, Val Loss: 0.6472, Val Acc: 0.6657
Epoch 53/100, Loss: 0.6534, Acc: 0.6224, Val Loss: 0.6432, Val Acc: 0.6708
Epoch 54/100, Loss: 0.6532, Acc: 0.6224, Val Loss: 0.6456, Val Acc: 0.6672
Epoch 55/100, Loss: 0.6532, Acc: 0.6217, Val Loss: 0.6477, Val Acc: 0.6649
Epoch 56/100, Loss: 0.6531, Acc: 0.6203, Val Loss: 0.6466, Val Acc: 0.6653
Epoch 57/100, Loss: 0.6530, Acc: 0.6214, Val Loss: 0.6475, Val Acc: 0.6653
Epoch 58/100, Loss: 0.6529, Acc: 0.6223, Val Loss: 0.6467, Val Acc: 0.6657
Epoch 59/100, Loss: 0.6529, Acc: 0.6212, Val Loss: 0.6499, Val Acc: 0.6642
Epoch 60/100, Loss: 0.6528, Acc: 0.6214, Val Loss: 0.6469, Val Acc: 0.6657
Epoch 61/100, Loss: 0.6528, Acc: 0.6214, Val Loss: 0.6514, Val Acc: 0.6620
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6526, Acc: 0.6228, Val Loss: 0.6479, Val Acc: 0.6653
Epoch 63/100, Loss: 0.6524, Acc: 0.6229, Val Loss: 0.6458, Val Acc: 0.6672
Epoch 64/100, Loss: 0.6512, Acc: 0.6221, Val Loss: 0.6499, Val Acc: 0.6646
Epoch 65/100, Loss: 0.6509, Acc: 0.6235, Val Loss: 0.6496, Val Acc: 0.6668
Epoch 66/100, Loss: 0.6509, Acc: 0.6220, Val Loss: 0.6517, Val Acc: 0.6653
Epoch 67/100, Loss: 0.6506, Acc: 0.6238, Val Loss: 0.6509, Val Acc: 0.6657
Epoch 68/100, Loss: 0.6504, Acc: 0.6229, Val Loss: 0.6495, Val Acc: 0.6672
Epoch 69/100, Loss: 0.6503, Acc: 0.6225, Val Loss: 0.6534, Val Acc: 0.6635
Epoch 70/100, Loss: 0.6502, Acc: 0.6222, Val Loss: 0.6497, Val Acc: 0.6664
Epoch 71/100, Loss: 0.6502, Acc: 0.6227, Val Loss: 0.6482, Val Acc: 0.6686
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6501, Acc: 0.6235, Val Loss: 0.6502, Val Acc: 0.6664
Epoch 73/100, Loss: 0.6500, Acc: 0.6231, Val Loss: 0.6498, Val Acc: 0.6668
Epoch 74/100, Loss: 0.6500, Acc: 0.6226, Val Loss: 0.6513, Val Acc: 0.6664
Epoch 75/100, Loss: 0.6499, Acc: 0.6227, Val Loss: 0.6508, Val Acc: 0.6672
Epoch 76/100, Loss: 0.6499, Acc: 0.6229, Val Loss: 0.6496, Val Acc: 0.6668
Epoch 77/100, Loss: 0.6499, Acc: 0.6224, Val Loss: 0.6510, Val Acc: 0.6661
Epoch 78/100, Loss: 0.6498, Acc: 0.6230, Val Loss: 0.6508, Val Acc: 0.6672
Epoch 79/100, Loss: 0.6498, Acc: 0.6224, Val Loss: 0.6507, Val Acc: 0.6661
Epoch 80/100, Loss: 0.6497, Acc: 0.6231, Val Loss: 0.6519, Val Acc: 0.6657
Epoch 81/100, Loss: 0.6497, Acc: 0.6240, Val Loss: 0.6500, Val Acc: 0.6668
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6497, Acc: 0.6225, Val Loss: 0.6511, Val Acc: 0.6675
Epoch 83/100, Loss: 0.6497, Acc: 0.6232, Val Loss: 0.6520, Val Acc: 0.6661
Epoch 84/100, Loss: 0.6496, Acc: 0.6232, Val Loss: 0.6505, Val Acc: 0.6675
Epoch 85/100, Loss: 0.6496, Acc: 0.6236, Val Loss: 0.6510, Val Acc: 0.6675
Epoch 86/100, Loss: 0.6496, Acc: 0.6230, Val Loss: 0.6513, Val Acc: 0.6675
Epoch 87/100, Loss: 0.6495, Acc: 0.6232, Val Loss: 0.6510, Val Acc: 0.6672
Epoch 88/100, Loss: 0.6495, Acc: 0.6230, Val Loss: 0.6516, Val Acc: 0.6672
Epoch 89/100, Loss: 0.6494, Acc: 0.6217, Val Loss: 0.6516, Val Acc: 0.6668
Epoch 90/100, Loss: 0.6494, Acc: 0.6222, Val Loss: 0.6509, Val Acc: 0.6672
Epoch 91/100, Loss: 0.6494, Acc: 0.6233, Val Loss: 0.6510, Val Acc: 0.6672
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6493, Acc: 0.6233, Val Loss: 0.6503, Val Acc: 0.6672
Epoch 93/100, Loss: 0.6492, Acc: 0.6233, Val Loss: 0.6510, Val Acc: 0.6675
Epoch 94/100, Loss: 0.6492, Acc: 0.6227, Val Loss: 0.6518, Val Acc: 0.6672
Epoch 95/100, Loss: 0.6491, Acc: 0.6237, Val Loss: 0.6515, Val Acc: 0.6672
Epoch 96/100, Loss: 0.6491, Acc: 0.6236, Val Loss: 0.6512, Val Acc: 0.6668
Epoch 97/100, Loss: 0.6490, Acc: 0.6234, Val Loss: 0.6523, Val Acc: 0.6668
Epoch 98/100, Loss: 0.6489, Acc: 0.6236, Val Loss: 0.6532, Val Acc: 0.6653
Epoch 99/100, Loss: 0.6488, Acc: 0.6236, Val Loss: 0.6514, Val Acc: 0.6675
Epoch 100/100, Loss: 0.6487, Acc: 0.6230, Val Loss: 0.6514, Val Acc: 0.6672

##############################
Resultados para principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11 
 {'training': [0.648662588523963, 0.6229990800367985, 0.6788399570354458, 0.46556169429097605, 0.5523268516495521], 'validate': [0.6514455994894338, 0.6671586715867158, 0.635593220338983, 0.7777777777777778, 0.6995336442371752], 'test': [0.7238297664894248, 0.479646017699115, 0.4650943396226415, 0.2917159763313609, 0.35854545454545456]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  063  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  063  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6942, Acc: 0.4984, Val Loss: 0.6932, Val Acc: 0.4978
Mejor modelo guardado con Val Loss: 0.6932
Epoch 2/100, Loss: 0.6926, Acc: 0.5160, Val Loss: 0.6930, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6930
Epoch 3/100, Loss: 0.6936, Acc: 0.4941, Val Loss: 0.6930, Val Acc: 0.5015
Epoch 4/100, Loss: 0.6935, Acc: 0.4888, Val Loss: 0.6934, Val Acc: 0.4982
Epoch 5/100, Loss: 0.6935, Acc: 0.4992, Val Loss: 0.6938, Val Acc: 0.4982
Epoch 6/100, Loss: 0.6933, Acc: 0.5029, Val Loss: 0.6929, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6929
Epoch 7/100, Loss: 0.6935, Acc: 0.4948, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 8/100, Loss: 0.6936, Acc: 0.4962, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 9/100, Loss: 0.6937, Acc: 0.5010, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 10/100, Loss: 0.6936, Acc: 0.4983, Val Loss: 0.6950, Val Acc: 0.4982
Epoch 11/100, Loss: 0.6935, Acc: 0.4979, Val Loss: 0.6930, Val Acc: 0.5018
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4966, Val Loss: 0.6935, Val Acc: 0.4982
Epoch 13/100, Loss: 0.6935, Acc: 0.4959, Val Loss: 0.6933, Val Acc: 0.4982
Epoch 14/100, Loss: 0.6933, Acc: 0.4980, Val Loss: 0.6934, Val Acc: 0.4982
Epoch 15/100, Loss: 0.6933, Acc: 0.4988, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 16/100, Loss: 0.6934, Acc: 0.4975, Val Loss: 0.6936, Val Acc: 0.4982
Epoch 17/100, Loss: 0.6932, Acc: 0.5012, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 18/100, Loss: 0.6933, Acc: 0.4990, Val Loss: 0.6933, Val Acc: 0.4982
Epoch 19/100, Loss: 0.6934, Acc: 0.4978, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 20/100, Loss: 0.6932, Acc: 0.5006, Val Loss: 0.6935, Val Acc: 0.4982
Epoch 21/100, Loss: 0.6933, Acc: 0.5001, Val Loss: 0.6930, Val Acc: 0.5018
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4989, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 23/100, Loss: 0.6933, Acc: 0.4867, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 24/100, Loss: 0.6932, Acc: 0.4992, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 25/100, Loss: 0.6933, Acc: 0.5003, Val Loss: 0.6934, Val Acc: 0.4982
Epoch 26/100, Loss: 0.6933, Acc: 0.4983, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 27/100, Loss: 0.6933, Acc: 0.4970, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 28/100, Loss: 0.6933, Acc: 0.4968, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 29/100, Loss: 0.6932, Acc: 0.4981, Val Loss: 0.6931, Val Acc: 0.5015
Epoch 30/100, Loss: 0.6932, Acc: 0.4955, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 31/100, Loss: 0.6933, Acc: 0.4958, Val Loss: 0.6931, Val Acc: 0.5018
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4975, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 33/100, Loss: 0.6932, Acc: 0.4878, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 34/100, Loss: 0.6932, Acc: 0.4893, Val Loss: 0.6931, Val Acc: 0.5015
Epoch 35/100, Loss: 0.6932, Acc: 0.5006, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 36/100, Loss: 0.6932, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.4978
Epoch 37/100, Loss: 0.6932, Acc: 0.4950, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 38/100, Loss: 0.6932, Acc: 0.4984, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 39/100, Loss: 0.6932, Acc: 0.4938, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 40/100, Loss: 0.6932, Acc: 0.4970, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 41/100, Loss: 0.6932, Acc: 0.4977, Val Loss: 0.6931, Val Acc: 0.5018
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.4946, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 43/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 44/100, Loss: 0.6932, Acc: 0.4927, Val Loss: 0.6931, Val Acc: 0.5015
Epoch 45/100, Loss: 0.6932, Acc: 0.4940, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 46/100, Loss: 0.6932, Acc: 0.4979, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 47/100, Loss: 0.6932, Acc: 0.4910, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 48/100, Loss: 0.6932, Acc: 0.4889, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 49/100, Loss: 0.6932, Acc: 0.4989, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 50/100, Loss: 0.6932, Acc: 0.4997, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 51/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6931, Val Acc: 0.5015
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6932, Acc: 0.4916, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 53/100, Loss: 0.6932, Acc: 0.4935, Val Loss: 0.6931, Val Acc: 0.5015
Epoch 54/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 55/100, Loss: 0.6932, Acc: 0.4982, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 56/100, Loss: 0.6932, Acc: 0.4944, Val Loss: 0.6932, Val Acc: 0.4970
Epoch 57/100, Loss: 0.6932, Acc: 0.4928, Val Loss: 0.6932, Val Acc: 0.4974
Epoch 58/100, Loss: 0.6932, Acc: 0.4980, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 59/100, Loss: 0.6932, Acc: 0.4947, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 60/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 61/100, Loss: 0.6932, Acc: 0.4925, Val Loss: 0.6931, Val Acc: 0.5018
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 63/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 64/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 65/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 66/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 67/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 68/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5015
Epoch 69/100, Loss: 0.6932, Acc: 0.4971, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 70/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 71/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 73/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 74/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 75/100, Loss: 0.6932, Acc: 0.4959, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 76/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 77/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 78/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 79/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 80/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 81/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6931, Acc: 0.4908, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 83/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 84/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 85/100, Loss: 0.6931, Acc: 0.4956, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 86/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 87/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 88/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 89/100, Loss: 0.6931, Acc: 0.5005, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 90/100, Loss: 0.6930, Acc: 0.5007, Val Loss: 0.6923, Val Acc: 0.4993
Mejor modelo guardado con Val Loss: 0.6923
Epoch 91/100, Loss: 0.6927, Acc: 0.5029, Val Loss: 0.6920, Val Acc: 0.5070
Mejor modelo guardado con Val Loss: 0.6920
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6926, Acc: 0.5119, Val Loss: 0.6919, Val Acc: 0.5048
Mejor modelo guardado con Val Loss: 0.6919
Epoch 93/100, Loss: 0.6926, Acc: 0.5121, Val Loss: 0.6919, Val Acc: 0.5122
Mejor modelo guardado con Val Loss: 0.6919
Epoch 94/100, Loss: 0.6926, Acc: 0.5156, Val Loss: 0.6919, Val Acc: 0.5137
Mejor modelo guardado con Val Loss: 0.6919
Epoch 95/100, Loss: 0.6926, Acc: 0.5235, Val Loss: 0.6919, Val Acc: 0.5188
Epoch 96/100, Loss: 0.6925, Acc: 0.5215, Val Loss: 0.6919, Val Acc: 0.5144
Mejor modelo guardado con Val Loss: 0.6919
Epoch 97/100, Loss: 0.6925, Acc: 0.5206, Val Loss: 0.6919, Val Acc: 0.5225
Mejor modelo guardado con Val Loss: 0.6919
Epoch 98/100, Loss: 0.6925, Acc: 0.5206, Val Loss: 0.6918, Val Acc: 0.5192
Mejor modelo guardado con Val Loss: 0.6918
Epoch 99/100, Loss: 0.6925, Acc: 0.5225, Val Loss: 0.6918, Val Acc: 0.5210
Mejor modelo guardado con Val Loss: 0.6918
Epoch 100/100, Loss: 0.6925, Acc: 0.5247, Val Loss: 0.6918, Val Acc: 0.5232
Mejor modelo guardado con Val Loss: 0.6918

##############################
Resultados para principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11 
 {'training': [0.6925030501588507, 0.5247470101195952, 0.5229166666666667, 0.554696132596685, 0.5383378016085791], 'validate': [0.6918282231619192, 0.5232472324723247, 0.5295918367346939, 0.3844444444444444, 0.4454935622317597], 'test': [0.6922474469778672, 0.5333333333333333, 0.5346153846153846, 0.493491124260355, 0.5132307692307693]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  070  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  070  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6930, Acc: 0.5094, Val Loss: 0.6929, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6929
Epoch 2/100, Loss: 0.6931, Acc: 0.5062, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 3/100, Loss: 0.6935, Acc: 0.4973, Val Loss: 0.6933, Val Acc: 0.4982
Epoch 4/100, Loss: 0.6933, Acc: 0.5006, Val Loss: 0.6946, Val Acc: 0.4982
Epoch 5/100, Loss: 0.6934, Acc: 0.5019, Val Loss: 0.6929, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6929
Epoch 6/100, Loss: 0.6933, Acc: 0.5005, Val Loss: 0.6946, Val Acc: 0.4982
Epoch 7/100, Loss: 0.6932, Acc: 0.5063, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 8/100, Loss: 0.6934, Acc: 0.5002, Val Loss: 0.6938, Val Acc: 0.4982
Epoch 9/100, Loss: 0.6936, Acc: 0.4988, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 10/100, Loss: 0.6934, Acc: 0.4962, Val Loss: 0.6933, Val Acc: 0.4982
Epoch 11/100, Loss: 0.6933, Acc: 0.4984, Val Loss: 0.6935, Val Acc: 0.4982
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.5008, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 13/100, Loss: 0.6933, Acc: 0.4982, Val Loss: 0.6934, Val Acc: 0.4982
Epoch 14/100, Loss: 0.6933, Acc: 0.4992, Val Loss: 0.6938, Val Acc: 0.4982
Epoch 15/100, Loss: 0.6934, Acc: 0.4937, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 16/100, Loss: 0.6936, Acc: 0.4917, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 17/100, Loss: 0.6932, Acc: 0.5068, Val Loss: 0.6947, Val Acc: 0.4982
Epoch 18/100, Loss: 0.6933, Acc: 0.5023, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 19/100, Loss: 0.6933, Acc: 0.5005, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 20/100, Loss: 0.6933, Acc: 0.4977, Val Loss: 0.6934, Val Acc: 0.4982
Epoch 21/100, Loss: 0.6934, Acc: 0.5025, Val Loss: 0.6930, Val Acc: 0.5018
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4979, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 23/100, Loss: 0.6932, Acc: 0.4929, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 24/100, Loss: 0.6933, Acc: 0.4971, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 25/100, Loss: 0.6932, Acc: 0.5005, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 26/100, Loss: 0.6933, Acc: 0.4902, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 27/100, Loss: 0.6932, Acc: 0.4951, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 28/100, Loss: 0.6933, Acc: 0.4957, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 29/100, Loss: 0.6932, Acc: 0.4916, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 30/100, Loss: 0.6932, Acc: 0.4987, Val Loss: 0.6933, Val Acc: 0.4982
Epoch 31/100, Loss: 0.6933, Acc: 0.4964, Val Loss: 0.6932, Val Acc: 0.4982
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4969, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 33/100, Loss: 0.6932, Acc: 0.4932, Val Loss: 0.6931, Val Acc: 0.5022
Epoch 34/100, Loss: 0.6932, Acc: 0.4943, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 35/100, Loss: 0.6932, Acc: 0.4966, Val Loss: 0.6931, Val Acc: 0.5022
Epoch 36/100, Loss: 0.6932, Acc: 0.4971, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 37/100, Loss: 0.6932, Acc: 0.4948, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 38/100, Loss: 0.6932, Acc: 0.5004, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 39/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 40/100, Loss: 0.6931, Acc: 0.4981, Val Loss: 0.6932, Val Acc: 0.5018
Epoch 41/100, Loss: 0.6932, Acc: 0.5006, Val Loss: 0.6933, Val Acc: 0.4738
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6931, Acc: 0.5054, Val Loss: 0.6932, Val Acc: 0.4849
Epoch 43/100, Loss: 0.6931, Acc: 0.5111, Val Loss: 0.6932, Val Acc: 0.4882
Epoch 44/100, Loss: 0.6931, Acc: 0.5109, Val Loss: 0.6932, Val Acc: 0.4900
Epoch 45/100, Loss: 0.6931, Acc: 0.5064, Val Loss: 0.6932, Val Acc: 0.4793
Epoch 46/100, Loss: 0.6931, Acc: 0.5093, Val Loss: 0.6932, Val Acc: 0.4834
Epoch 47/100, Loss: 0.6931, Acc: 0.5042, Val Loss: 0.6933, Val Acc: 0.4756
Epoch 48/100, Loss: 0.6931, Acc: 0.5123, Val Loss: 0.6931, Val Acc: 0.4963
Epoch 49/100, Loss: 0.6931, Acc: 0.5124, Val Loss: 0.6932, Val Acc: 0.4934
Epoch 50/100, Loss: 0.6931, Acc: 0.5021, Val Loss: 0.6932, Val Acc: 0.4882
Epoch 51/100, Loss: 0.6931, Acc: 0.5136, Val Loss: 0.6932, Val Acc: 0.4801
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6931, Acc: 0.5172, Val Loss: 0.6932, Val Acc: 0.4812
Epoch 53/100, Loss: 0.6930, Acc: 0.5178, Val Loss: 0.6932, Val Acc: 0.4852
Epoch 54/100, Loss: 0.6930, Acc: 0.5168, Val Loss: 0.6930, Val Acc: 0.4886
Epoch 55/100, Loss: 0.6930, Acc: 0.5225, Val Loss: 0.6925, Val Acc: 0.4967
Mejor modelo guardado con Val Loss: 0.6925
Epoch 56/100, Loss: 0.6930, Acc: 0.5190, Val Loss: 0.6923, Val Acc: 0.5070
Mejor modelo guardado con Val Loss: 0.6923
Epoch 57/100, Loss: 0.6930, Acc: 0.5132, Val Loss: 0.6918, Val Acc: 0.5292
Mejor modelo guardado con Val Loss: 0.6918
Epoch 58/100, Loss: 0.6929, Acc: 0.5138, Val Loss: 0.6919, Val Acc: 0.5424
Epoch 59/100, Loss: 0.6928, Acc: 0.5137, Val Loss: 0.6912, Val Acc: 0.5539
Mejor modelo guardado con Val Loss: 0.6912
Epoch 60/100, Loss: 0.6927, Acc: 0.5185, Val Loss: 0.6909, Val Acc: 0.5509
Mejor modelo guardado con Val Loss: 0.6909
Epoch 61/100, Loss: 0.6926, Acc: 0.5155, Val Loss: 0.6908, Val Acc: 0.5554
Mejor modelo guardado con Val Loss: 0.6908
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6925, Acc: 0.5165, Val Loss: 0.6907, Val Acc: 0.5557
Mejor modelo guardado con Val Loss: 0.6907
Epoch 63/100, Loss: 0.6925, Acc: 0.5178, Val Loss: 0.6908, Val Acc: 0.5498
Epoch 64/100, Loss: 0.6925, Acc: 0.5167, Val Loss: 0.6907, Val Acc: 0.5554
Mejor modelo guardado con Val Loss: 0.6907
Epoch 65/100, Loss: 0.6925, Acc: 0.5162, Val Loss: 0.6906, Val Acc: 0.5494
Mejor modelo guardado con Val Loss: 0.6906
Epoch 66/100, Loss: 0.6925, Acc: 0.5159, Val Loss: 0.6906, Val Acc: 0.5513
Epoch 67/100, Loss: 0.6923, Acc: 0.5191, Val Loss: 0.6906, Val Acc: 0.5428
Mejor modelo guardado con Val Loss: 0.6906
Epoch 68/100, Loss: 0.6919, Acc: 0.5219, Val Loss: 0.6906, Val Acc: 0.5476
Epoch 69/100, Loss: 0.6918, Acc: 0.5218, Val Loss: 0.6907, Val Acc: 0.5483
Epoch 70/100, Loss: 0.6917, Acc: 0.5234, Val Loss: 0.6906, Val Acc: 0.5450
Epoch 71/100, Loss: 0.6917, Acc: 0.5255, Val Loss: 0.6906, Val Acc: 0.5483
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6916, Acc: 0.5262, Val Loss: 0.6906, Val Acc: 0.5458
Epoch 73/100, Loss: 0.6916, Acc: 0.5253, Val Loss: 0.6906, Val Acc: 0.5487
Epoch 74/100, Loss: 0.6915, Acc: 0.5266, Val Loss: 0.6906, Val Acc: 0.5491
Epoch 75/100, Loss: 0.6915, Acc: 0.5259, Val Loss: 0.6906, Val Acc: 0.5502
Epoch 76/100, Loss: 0.6915, Acc: 0.5268, Val Loss: 0.6906, Val Acc: 0.5461
Epoch 77/100, Loss: 0.6915, Acc: 0.5294, Val Loss: 0.6906, Val Acc: 0.5487
Epoch 78/100, Loss: 0.6914, Acc: 0.5277, Val Loss: 0.6906, Val Acc: 0.5461
Epoch 79/100, Loss: 0.6914, Acc: 0.5279, Val Loss: 0.6906, Val Acc: 0.5494
Epoch 80/100, Loss: 0.6914, Acc: 0.5273, Val Loss: 0.6906, Val Acc: 0.5480
Epoch 81/100, Loss: 0.6914, Acc: 0.5294, Val Loss: 0.6906, Val Acc: 0.5472
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6914, Acc: 0.5281, Val Loss: 0.6906, Val Acc: 0.5472
Epoch 83/100, Loss: 0.6914, Acc: 0.5284, Val Loss: 0.6906, Val Acc: 0.5494
Epoch 84/100, Loss: 0.6914, Acc: 0.5283, Val Loss: 0.6906, Val Acc: 0.5469
Epoch 85/100, Loss: 0.6913, Acc: 0.5279, Val Loss: 0.6906, Val Acc: 0.5491
Epoch 86/100, Loss: 0.6913, Acc: 0.5310, Val Loss: 0.6906, Val Acc: 0.5506
Epoch 87/100, Loss: 0.6913, Acc: 0.5309, Val Loss: 0.6906, Val Acc: 0.5480
Epoch 88/100, Loss: 0.6913, Acc: 0.5284, Val Loss: 0.6906, Val Acc: 0.5472
Epoch 89/100, Loss: 0.6913, Acc: 0.5290, Val Loss: 0.6906, Val Acc: 0.5487
Epoch 90/100, Loss: 0.6913, Acc: 0.5290, Val Loss: 0.6906, Val Acc: 0.5491
Epoch 91/100, Loss: 0.6913, Acc: 0.5323, Val Loss: 0.6906, Val Acc: 0.5476
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6912, Acc: 0.5290, Val Loss: 0.6906, Val Acc: 0.5483
Epoch 93/100, Loss: 0.6912, Acc: 0.5297, Val Loss: 0.6906, Val Acc: 0.5472
Epoch 94/100, Loss: 0.6912, Acc: 0.5306, Val Loss: 0.6906, Val Acc: 0.5483
Epoch 95/100, Loss: 0.6912, Acc: 0.5328, Val Loss: 0.6906, Val Acc: 0.5483
Epoch 96/100, Loss: 0.6912, Acc: 0.5305, Val Loss: 0.6906, Val Acc: 0.5472
Epoch 97/100, Loss: 0.6912, Acc: 0.5300, Val Loss: 0.6906, Val Acc: 0.5469
Epoch 98/100, Loss: 0.6911, Acc: 0.5323, Val Loss: 0.6906, Val Acc: 0.5483
Epoch 99/100, Loss: 0.6911, Acc: 0.5330, Val Loss: 0.6906, Val Acc: 0.5491
Epoch 100/100, Loss: 0.6911, Acc: 0.5306, Val Loss: 0.6906, Val Acc: 0.5487

##############################
Resultados para principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11 
 {'training': [0.6911022725736974, 0.5306347746090156, 0.5353448275862069, 0.4574585635359116, 0.4933465739821251], 'validate': [0.6906178718389466, 0.5487084870848709, 0.5605338417540515, 0.43555555555555553, 0.4902042517715715], 'test': [0.6931306933456997, 0.5103244837758112, 0.5123762376237624, 0.36745562130177517, 0.42798070296347346]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  040  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  040  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6790, Acc: 0.5960, Val Loss: 0.6877, Val Acc: 0.5487
Mejor modelo guardado con Val Loss: 0.6877
Epoch 2/100, Loss: 0.6623, Acc: 0.6443, Val Loss: 0.6809, Val Acc: 0.5635
Mejor modelo guardado con Val Loss: 0.6809
Epoch 3/100, Loss: 0.6477, Acc: 0.6515, Val Loss: 0.6741, Val Acc: 0.5970
Mejor modelo guardado con Val Loss: 0.6741
Epoch 4/100, Loss: 0.6320, Acc: 0.6707, Val Loss: 0.6750, Val Acc: 0.5745
Epoch 5/100, Loss: 0.6235, Acc: 0.6730, Val Loss: 0.6687, Val Acc: 0.5937
Mejor modelo guardado con Val Loss: 0.6687
Epoch 6/100, Loss: 0.6099, Acc: 0.6764, Val Loss: 0.6713, Val Acc: 0.6111
Epoch 7/100, Loss: 0.6080, Acc: 0.6801, Val Loss: 0.6759, Val Acc: 0.5878
Epoch 8/100, Loss: 0.6043, Acc: 0.6806, Val Loss: 0.7044, Val Acc: 0.5358
Epoch 9/100, Loss: 0.6127, Acc: 0.6676, Val Loss: 0.6855, Val Acc: 0.5701
Epoch 10/100, Loss: 0.5922, Acc: 0.6901, Val Loss: 0.6688, Val Acc: 0.6041
Epoch 11/100, Loss: 0.5968, Acc: 0.6842, Val Loss: 0.6654, Val Acc: 0.6107
Mejor modelo guardado con Val Loss: 0.6654
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5859, Acc: 0.6967, Val Loss: 0.6680, Val Acc: 0.6070
Epoch 13/100, Loss: 0.5857, Acc: 0.6927, Val Loss: 0.7092, Val Acc: 0.5668
Epoch 14/100, Loss: 0.5857, Acc: 0.6946, Val Loss: 0.6747, Val Acc: 0.6085
Epoch 15/100, Loss: 0.5864, Acc: 0.6958, Val Loss: 0.6625, Val Acc: 0.6214
Mejor modelo guardado con Val Loss: 0.6625
Epoch 16/100, Loss: 0.5828, Acc: 0.6973, Val Loss: 0.6766, Val Acc: 0.5952
Epoch 17/100, Loss: 0.5842, Acc: 0.6979, Val Loss: 0.6938, Val Acc: 0.5834
Epoch 18/100, Loss: 0.5821, Acc: 0.6933, Val Loss: 0.6782, Val Acc: 0.6096
Epoch 19/100, Loss: 0.5798, Acc: 0.6997, Val Loss: 0.7078, Val Acc: 0.5572
Epoch 20/100, Loss: 0.5767, Acc: 0.7008, Val Loss: 0.6619, Val Acc: 0.6199
Mejor modelo guardado con Val Loss: 0.6619
Epoch 21/100, Loss: 0.5775, Acc: 0.7017, Val Loss: 0.7033, Val Acc: 0.5627
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5786, Acc: 0.6995, Val Loss: 0.6586, Val Acc: 0.6196
Mejor modelo guardado con Val Loss: 0.6586
Epoch 23/100, Loss: 0.5736, Acc: 0.7049, Val Loss: 0.6902, Val Acc: 0.5926
Epoch 24/100, Loss: 0.5755, Acc: 0.7052, Val Loss: 0.6747, Val Acc: 0.6030
Epoch 25/100, Loss: 0.5760, Acc: 0.7041, Val Loss: 0.6608, Val Acc: 0.6199
Epoch 26/100, Loss: 0.5735, Acc: 0.7066, Val Loss: 0.6800, Val Acc: 0.5900
Epoch 27/100, Loss: 0.5733, Acc: 0.7055, Val Loss: 0.6854, Val Acc: 0.5889
Epoch 28/100, Loss: 0.5717, Acc: 0.7081, Val Loss: 0.6956, Val Acc: 0.5727
Epoch 29/100, Loss: 0.5710, Acc: 0.7099, Val Loss: 0.6853, Val Acc: 0.5886
Epoch 30/100, Loss: 0.5744, Acc: 0.7043, Val Loss: 0.6714, Val Acc: 0.6111
Epoch 31/100, Loss: 0.5715, Acc: 0.7075, Val Loss: 0.6662, Val Acc: 0.6170
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5697, Acc: 0.7102, Val Loss: 0.6872, Val Acc: 0.5812
Epoch 33/100, Loss: 0.5687, Acc: 0.7097, Val Loss: 0.6795, Val Acc: 0.6033
Epoch 34/100, Loss: 0.5699, Acc: 0.7066, Val Loss: 0.7017, Val Acc: 0.5712
Epoch 35/100, Loss: 0.5690, Acc: 0.7082, Val Loss: 0.6799, Val Acc: 0.6000
Epoch 36/100, Loss: 0.5690, Acc: 0.7082, Val Loss: 0.6681, Val Acc: 0.6185
Epoch 37/100, Loss: 0.5680, Acc: 0.7101, Val Loss: 0.6997, Val Acc: 0.5764
Epoch 38/100, Loss: 0.5686, Acc: 0.7087, Val Loss: 0.6850, Val Acc: 0.5863
Epoch 39/100, Loss: 0.5682, Acc: 0.7091, Val Loss: 0.6858, Val Acc: 0.5911
Epoch 40/100, Loss: 0.5673, Acc: 0.7123, Val Loss: 0.6765, Val Acc: 0.5996
Epoch 41/100, Loss: 0.5682, Acc: 0.7113, Val Loss: 0.6814, Val Acc: 0.5945
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5666, Acc: 0.7153, Val Loss: 0.6769, Val Acc: 0.6015
Epoch 43/100, Loss: 0.5667, Acc: 0.7129, Val Loss: 0.6903, Val Acc: 0.5812
Epoch 44/100, Loss: 0.5666, Acc: 0.7129, Val Loss: 0.6942, Val Acc: 0.5797
Epoch 45/100, Loss: 0.5670, Acc: 0.7120, Val Loss: 0.6866, Val Acc: 0.5908
Epoch 46/100, Loss: 0.5659, Acc: 0.7147, Val Loss: 0.6949, Val Acc: 0.5775
Epoch 47/100, Loss: 0.5666, Acc: 0.7134, Val Loss: 0.6878, Val Acc: 0.5897
Epoch 48/100, Loss: 0.5657, Acc: 0.7127, Val Loss: 0.6851, Val Acc: 0.5937
Epoch 49/100, Loss: 0.5658, Acc: 0.7134, Val Loss: 0.6838, Val Acc: 0.5959
Epoch 50/100, Loss: 0.5661, Acc: 0.7141, Val Loss: 0.6968, Val Acc: 0.5731
Epoch 51/100, Loss: 0.5658, Acc: 0.7125, Val Loss: 0.6914, Val Acc: 0.5801
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5656, Acc: 0.7155, Val Loss: 0.6866, Val Acc: 0.5878
Epoch 53/100, Loss: 0.5652, Acc: 0.7155, Val Loss: 0.6844, Val Acc: 0.5934
Epoch 54/100, Loss: 0.5649, Acc: 0.7156, Val Loss: 0.6781, Val Acc: 0.6037
Epoch 55/100, Loss: 0.5652, Acc: 0.7148, Val Loss: 0.6893, Val Acc: 0.5841
Epoch 56/100, Loss: 0.5650, Acc: 0.7146, Val Loss: 0.6851, Val Acc: 0.5941
Epoch 57/100, Loss: 0.5652, Acc: 0.7166, Val Loss: 0.6801, Val Acc: 0.6022
Epoch 58/100, Loss: 0.5649, Acc: 0.7160, Val Loss: 0.6769, Val Acc: 0.6022
Epoch 59/100, Loss: 0.5653, Acc: 0.7160, Val Loss: 0.6815, Val Acc: 0.6004
Epoch 60/100, Loss: 0.5653, Acc: 0.7149, Val Loss: 0.6833, Val Acc: 0.5985
Epoch 61/100, Loss: 0.5645, Acc: 0.7152, Val Loss: 0.6805, Val Acc: 0.5967
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5646, Acc: 0.7149, Val Loss: 0.6851, Val Acc: 0.5952
Epoch 63/100, Loss: 0.5644, Acc: 0.7173, Val Loss: 0.6800, Val Acc: 0.6004
Epoch 64/100, Loss: 0.5644, Acc: 0.7168, Val Loss: 0.6818, Val Acc: 0.6015
Epoch 65/100, Loss: 0.5644, Acc: 0.7155, Val Loss: 0.6845, Val Acc: 0.5956
Epoch 66/100, Loss: 0.5644, Acc: 0.7156, Val Loss: 0.6797, Val Acc: 0.6004
Epoch 67/100, Loss: 0.5644, Acc: 0.7148, Val Loss: 0.6796, Val Acc: 0.6000
Epoch 68/100, Loss: 0.5643, Acc: 0.7152, Val Loss: 0.6809, Val Acc: 0.6022
Epoch 69/100, Loss: 0.5643, Acc: 0.7162, Val Loss: 0.6840, Val Acc: 0.5959
Epoch 70/100, Loss: 0.5642, Acc: 0.7150, Val Loss: 0.6840, Val Acc: 0.5967
Epoch 71/100, Loss: 0.5643, Acc: 0.7183, Val Loss: 0.6807, Val Acc: 0.6026
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5641, Acc: 0.7160, Val Loss: 0.6818, Val Acc: 0.6022
Epoch 73/100, Loss: 0.5641, Acc: 0.7168, Val Loss: 0.6801, Val Acc: 0.5993
Epoch 74/100, Loss: 0.5640, Acc: 0.7166, Val Loss: 0.6819, Val Acc: 0.6011
Epoch 75/100, Loss: 0.5640, Acc: 0.7165, Val Loss: 0.6807, Val Acc: 0.6018
Epoch 76/100, Loss: 0.5641, Acc: 0.7155, Val Loss: 0.6804, Val Acc: 0.6000
Epoch 77/100, Loss: 0.5640, Acc: 0.7160, Val Loss: 0.6837, Val Acc: 0.5982
Epoch 78/100, Loss: 0.5640, Acc: 0.7168, Val Loss: 0.6816, Val Acc: 0.6011
Epoch 79/100, Loss: 0.5641, Acc: 0.7167, Val Loss: 0.6811, Val Acc: 0.5996
Epoch 80/100, Loss: 0.5641, Acc: 0.7147, Val Loss: 0.6822, Val Acc: 0.6007
Epoch 81/100, Loss: 0.5640, Acc: 0.7172, Val Loss: 0.6849, Val Acc: 0.5952
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5640, Acc: 0.7155, Val Loss: 0.6825, Val Acc: 0.5996
Epoch 83/100, Loss: 0.5639, Acc: 0.7177, Val Loss: 0.6825, Val Acc: 0.5993
Epoch 84/100, Loss: 0.5639, Acc: 0.7178, Val Loss: 0.6797, Val Acc: 0.6007
Epoch 85/100, Loss: 0.5640, Acc: 0.7156, Val Loss: 0.6843, Val Acc: 0.5952
Epoch 86/100, Loss: 0.5638, Acc: 0.7168, Val Loss: 0.6854, Val Acc: 0.5934
Epoch 87/100, Loss: 0.5639, Acc: 0.7162, Val Loss: 0.6842, Val Acc: 0.5959
Epoch 88/100, Loss: 0.5638, Acc: 0.7171, Val Loss: 0.6796, Val Acc: 0.6026
Epoch 89/100, Loss: 0.5636, Acc: 0.7180, Val Loss: 0.6813, Val Acc: 0.6007
Epoch 90/100, Loss: 0.5637, Acc: 0.7176, Val Loss: 0.6815, Val Acc: 0.6004
Epoch 91/100, Loss: 0.5636, Acc: 0.7169, Val Loss: 0.6784, Val Acc: 0.6011
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5636, Acc: 0.7174, Val Loss: 0.6814, Val Acc: 0.5982
Epoch 93/100, Loss: 0.5637, Acc: 0.7189, Val Loss: 0.6800, Val Acc: 0.6018
Epoch 94/100, Loss: 0.5636, Acc: 0.7176, Val Loss: 0.6821, Val Acc: 0.5985
Epoch 95/100, Loss: 0.5636, Acc: 0.7169, Val Loss: 0.6828, Val Acc: 0.5974
Epoch 96/100, Loss: 0.5634, Acc: 0.7186, Val Loss: 0.6803, Val Acc: 0.5996
Epoch 97/100, Loss: 0.5635, Acc: 0.7175, Val Loss: 0.6790, Val Acc: 0.6022
Epoch 98/100, Loss: 0.5635, Acc: 0.7190, Val Loss: 0.6801, Val Acc: 0.6022
Epoch 99/100, Loss: 0.5634, Acc: 0.7158, Val Loss: 0.6839, Val Acc: 0.5967
Epoch 100/100, Loss: 0.5635, Acc: 0.7194, Val Loss: 0.6809, Val Acc: 0.5996

##############################
Resultados para principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  11 
 {'training': [0.5634613865652321, 0.7194112235510579, 0.7059536171685704, 0.7511970534069982, 0.7278729478943612], 'validate': [0.68086360568224, 0.5996309963099631, 0.573734001112966, 0.7637037037037037, 0.6552272005084208], 'test': [0.5523398580416193, 0.7244837758112095, 0.7536912751677852, 0.6644970414201183, 0.7062893081761006]}

##############################
Resultados para window:  11 
 {'095:065:013:063:070:040': {'training': [0.6226424421206898, 0.6564857405703772, 0.6312287217579696, 0.7511970534069982, 0.6860073999327279], 'validate': [0.6321756462025088, 0.6191881918819189, 0.6111888111888112, 0.6474074074074074, 0.6287769784172662], 'test': [0.6351821529415419, 0.6448377581120944, 0.5993458708094849, 0.8674556213017751, 0.7088974854932302]}, '065:095:013:063:070:040': {'training': [0.6858933026020748, 0.5542778288868445, 0.5457674855265217, 0.6423572744014733, 0.5901361982911767], 'validate': [0.6992814111155133, 0.47269372693726935, 0.4780189204229271, 0.6362962962962962, 0.5459167461074039], 'test': [0.6933400878366435, 0.5014749262536873, 0.0, 0.0, 0.0]}, '013:095:065:063:070:040': {'training': [0.648662588523963, 0.6229990800367985, 0.6788399570354458, 0.46556169429097605, 0.5523268516495521], 'validate': [0.6514455994894338, 0.6671586715867158, 0.635593220338983, 0.7777777777777778, 0.6995336442371752], 'test': [0.7238297664894248, 0.479646017699115, 0.4650943396226415, 0.2917159763313609, 0.35854545454545456]}, '063:095:065:013:070:040': {'training': [0.6925030501588507, 0.5247470101195952, 0.5229166666666667, 0.554696132596685, 0.5383378016085791], 'validate': [0.6918282231619192, 0.5232472324723247, 0.5295918367346939, 0.3844444444444444, 0.4454935622317597], 'test': [0.6922474469778672, 0.5333333333333333, 0.5346153846153846, 0.493491124260355, 0.5132307692307693]}, '070:095:065:013:063:040': {'training': [0.6911022725736974, 0.5306347746090156, 0.5353448275862069, 0.4574585635359116, 0.4933465739821251], 'validate': [0.6906178718389466, 0.5487084870848709, 0.5605338417540515, 0.43555555555555553, 0.4902042517715715], 'test': [0.6931306933456997, 0.5103244837758112, 0.5123762376237624, 0.36745562130177517, 0.42798070296347346]}, '040:095:065:013:063:070': {'training': [0.5634613865652321, 0.7194112235510579, 0.7059536171685704, 0.7511970534069982, 0.7278729478943612], 'validate': [0.68086360568224, 0.5996309963099631, 0.573734001112966, 0.7637037037037037, 0.6552272005084208], 'test': [0.5523398580416193, 0.7244837758112095, 0.7536912751677852, 0.6644970414201183, 0.7062893081761006]}}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  102  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  102  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6413, Acc: 0.6759, Val Loss: 0.4660, Val Acc: 0.9244
Mejor modelo guardado con Val Loss: 0.4660
Epoch 2/100, Loss: 0.5749, Acc: 0.7315, Val Loss: 0.3277, Val Acc: 0.9649
Mejor modelo guardado con Val Loss: 0.3277
Epoch 3/100, Loss: 0.5352, Acc: 0.7468, Val Loss: 0.2672, Val Acc: 0.9624
Mejor modelo guardado con Val Loss: 0.2672
Epoch 4/100, Loss: 0.5189, Acc: 0.7526, Val Loss: 0.2802, Val Acc: 0.9347
Epoch 5/100, Loss: 0.5148, Acc: 0.7512, Val Loss: 0.2381, Val Acc: 0.9694
Mejor modelo guardado con Val Loss: 0.2381
Epoch 6/100, Loss: 0.5082, Acc: 0.7546, Val Loss: 0.2279, Val Acc: 0.9609
Mejor modelo guardado con Val Loss: 0.2279
Epoch 7/100, Loss: 0.4910, Acc: 0.7658, Val Loss: 0.2042, Val Acc: 0.9601
Mejor modelo guardado con Val Loss: 0.2042
Epoch 8/100, Loss: 0.4978, Acc: 0.7591, Val Loss: 0.2463, Val Acc: 0.9347
Epoch 9/100, Loss: 0.4845, Acc: 0.7670, Val Loss: 0.2341, Val Acc: 0.9435
Epoch 10/100, Loss: 0.4760, Acc: 0.7698, Val Loss: 0.1948, Val Acc: 0.9679
Mejor modelo guardado con Val Loss: 0.1948
Epoch 11/100, Loss: 0.4762, Acc: 0.7689, Val Loss: 0.2211, Val Acc: 0.9535
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4616, Acc: 0.7722, Val Loss: 0.2299, Val Acc: 0.9188
Epoch 13/100, Loss: 0.4552, Acc: 0.7795, Val Loss: 0.2226, Val Acc: 0.9251
Epoch 14/100, Loss: 0.4539, Acc: 0.7754, Val Loss: 0.2348, Val Acc: 0.9269
Epoch 15/100, Loss: 0.4503, Acc: 0.7787, Val Loss: 0.1822, Val Acc: 0.9557
Mejor modelo guardado con Val Loss: 0.1822
Epoch 16/100, Loss: 0.4541, Acc: 0.7783, Val Loss: 0.2200, Val Acc: 0.9295
Epoch 17/100, Loss: 0.4466, Acc: 0.7799, Val Loss: 0.1867, Val Acc: 0.9435
Epoch 18/100, Loss: 0.4441, Acc: 0.7831, Val Loss: 0.2199, Val Acc: 0.9207
Epoch 19/100, Loss: 0.4437, Acc: 0.7814, Val Loss: 0.2193, Val Acc: 0.9218
Epoch 20/100, Loss: 0.4429, Acc: 0.7814, Val Loss: 0.2056, Val Acc: 0.9310
Epoch 21/100, Loss: 0.4374, Acc: 0.7876, Val Loss: 0.1951, Val Acc: 0.9387
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4310, Acc: 0.7911, Val Loss: 0.1844, Val Acc: 0.9432
Epoch 23/100, Loss: 0.4275, Acc: 0.7911, Val Loss: 0.1975, Val Acc: 0.9358
Epoch 24/100, Loss: 0.4260, Acc: 0.7903, Val Loss: 0.1889, Val Acc: 0.9387
Epoch 25/100, Loss: 0.4279, Acc: 0.7926, Val Loss: 0.1773, Val Acc: 0.9554
Mejor modelo guardado con Val Loss: 0.1773
Epoch 26/100, Loss: 0.4247, Acc: 0.7916, Val Loss: 0.2029, Val Acc: 0.9336
Epoch 27/100, Loss: 0.4280, Acc: 0.7925, Val Loss: 0.1877, Val Acc: 0.9435
Epoch 28/100, Loss: 0.4206, Acc: 0.7968, Val Loss: 0.1990, Val Acc: 0.9365
Epoch 29/100, Loss: 0.4249, Acc: 0.7945, Val Loss: 0.2156, Val Acc: 0.9262
Epoch 30/100, Loss: 0.4226, Acc: 0.7943, Val Loss: 0.1986, Val Acc: 0.9391
Epoch 31/100, Loss: 0.4171, Acc: 0.7974, Val Loss: 0.1890, Val Acc: 0.9358
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4156, Acc: 0.7967, Val Loss: 0.1988, Val Acc: 0.9347
Epoch 33/100, Loss: 0.4140, Acc: 0.8000, Val Loss: 0.1769, Val Acc: 0.9454
Mejor modelo guardado con Val Loss: 0.1769
Epoch 34/100, Loss: 0.4144, Acc: 0.7996, Val Loss: 0.1855, Val Acc: 0.9399
Epoch 35/100, Loss: 0.4116, Acc: 0.8017, Val Loss: 0.1834, Val Acc: 0.9443
Epoch 36/100, Loss: 0.4119, Acc: 0.8017, Val Loss: 0.1896, Val Acc: 0.9358
Epoch 37/100, Loss: 0.4110, Acc: 0.8029, Val Loss: 0.1904, Val Acc: 0.9362
Epoch 38/100, Loss: 0.4108, Acc: 0.8047, Val Loss: 0.1922, Val Acc: 0.9347
Epoch 39/100, Loss: 0.4088, Acc: 0.8072, Val Loss: 0.1942, Val Acc: 0.9339
Epoch 40/100, Loss: 0.4097, Acc: 0.8054, Val Loss: 0.1923, Val Acc: 0.9358
Epoch 41/100, Loss: 0.4080, Acc: 0.8061, Val Loss: 0.2009, Val Acc: 0.9269
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4066, Acc: 0.8068, Val Loss: 0.1925, Val Acc: 0.9332
Epoch 43/100, Loss: 0.4067, Acc: 0.8069, Val Loss: 0.1917, Val Acc: 0.9343
Epoch 44/100, Loss: 0.4053, Acc: 0.8045, Val Loss: 0.1940, Val Acc: 0.9328
Epoch 45/100, Loss: 0.4054, Acc: 0.8059, Val Loss: 0.1857, Val Acc: 0.9369
Epoch 46/100, Loss: 0.4046, Acc: 0.8078, Val Loss: 0.1910, Val Acc: 0.9336
Epoch 47/100, Loss: 0.4046, Acc: 0.8083, Val Loss: 0.1922, Val Acc: 0.9328
Epoch 48/100, Loss: 0.4042, Acc: 0.8061, Val Loss: 0.1829, Val Acc: 0.9369
Epoch 49/100, Loss: 0.4040, Acc: 0.8086, Val Loss: 0.1909, Val Acc: 0.9336
Epoch 50/100, Loss: 0.4038, Acc: 0.8084, Val Loss: 0.1912, Val Acc: 0.9328
Epoch 51/100, Loss: 0.4039, Acc: 0.8060, Val Loss: 0.1806, Val Acc: 0.9384
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4025, Acc: 0.8087, Val Loss: 0.1843, Val Acc: 0.9380
Epoch 53/100, Loss: 0.4020, Acc: 0.8075, Val Loss: 0.1881, Val Acc: 0.9339
Epoch 54/100, Loss: 0.4016, Acc: 0.8094, Val Loss: 0.1820, Val Acc: 0.9369
Epoch 55/100, Loss: 0.4017, Acc: 0.8083, Val Loss: 0.1952, Val Acc: 0.9314
Epoch 56/100, Loss: 0.4012, Acc: 0.8109, Val Loss: 0.1805, Val Acc: 0.9380
Epoch 57/100, Loss: 0.4014, Acc: 0.8103, Val Loss: 0.1864, Val Acc: 0.9339
Epoch 58/100, Loss: 0.4012, Acc: 0.8082, Val Loss: 0.1816, Val Acc: 0.9380
Epoch 59/100, Loss: 0.4007, Acc: 0.8102, Val Loss: 0.1962, Val Acc: 0.9314
Epoch 60/100, Loss: 0.4006, Acc: 0.8097, Val Loss: 0.1804, Val Acc: 0.9373
Epoch 61/100, Loss: 0.4010, Acc: 0.8100, Val Loss: 0.1828, Val Acc: 0.9358
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4001, Acc: 0.8090, Val Loss: 0.1888, Val Acc: 0.9332
Epoch 63/100, Loss: 0.4000, Acc: 0.8104, Val Loss: 0.1852, Val Acc: 0.9347
Epoch 64/100, Loss: 0.3997, Acc: 0.8107, Val Loss: 0.1858, Val Acc: 0.9343
Epoch 65/100, Loss: 0.3995, Acc: 0.8098, Val Loss: 0.1902, Val Acc: 0.9325
Epoch 66/100, Loss: 0.3997, Acc: 0.8119, Val Loss: 0.1876, Val Acc: 0.9339
Epoch 67/100, Loss: 0.3996, Acc: 0.8109, Val Loss: 0.1832, Val Acc: 0.9354
Epoch 68/100, Loss: 0.3994, Acc: 0.8096, Val Loss: 0.1807, Val Acc: 0.9373
Epoch 69/100, Loss: 0.3990, Acc: 0.8109, Val Loss: 0.1824, Val Acc: 0.9365
Epoch 70/100, Loss: 0.3992, Acc: 0.8101, Val Loss: 0.1882, Val Acc: 0.9328
Epoch 71/100, Loss: 0.3990, Acc: 0.8109, Val Loss: 0.1825, Val Acc: 0.9358
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3989, Acc: 0.8121, Val Loss: 0.1867, Val Acc: 0.9339
Epoch 73/100, Loss: 0.3989, Acc: 0.8101, Val Loss: 0.1872, Val Acc: 0.9336
Epoch 74/100, Loss: 0.3988, Acc: 0.8114, Val Loss: 0.1851, Val Acc: 0.9343
Epoch 75/100, Loss: 0.3986, Acc: 0.8121, Val Loss: 0.1840, Val Acc: 0.9347
Epoch 76/100, Loss: 0.3986, Acc: 0.8103, Val Loss: 0.1862, Val Acc: 0.9339
Epoch 77/100, Loss: 0.3986, Acc: 0.8117, Val Loss: 0.1828, Val Acc: 0.9358
Epoch 78/100, Loss: 0.3983, Acc: 0.8130, Val Loss: 0.1831, Val Acc: 0.9351
Epoch 79/100, Loss: 0.3985, Acc: 0.8113, Val Loss: 0.1859, Val Acc: 0.9339
Epoch 80/100, Loss: 0.3984, Acc: 0.8126, Val Loss: 0.1867, Val Acc: 0.9336
Epoch 81/100, Loss: 0.3983, Acc: 0.8123, Val Loss: 0.1805, Val Acc: 0.9373
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3985, Acc: 0.8110, Val Loss: 0.1831, Val Acc: 0.9347
Epoch 83/100, Loss: 0.3981, Acc: 0.8104, Val Loss: 0.1847, Val Acc: 0.9339
Epoch 84/100, Loss: 0.3981, Acc: 0.8117, Val Loss: 0.1843, Val Acc: 0.9343
Epoch 85/100, Loss: 0.3981, Acc: 0.8119, Val Loss: 0.1827, Val Acc: 0.9343
Epoch 86/100, Loss: 0.3981, Acc: 0.8107, Val Loss: 0.1842, Val Acc: 0.9343
Epoch 87/100, Loss: 0.3979, Acc: 0.8125, Val Loss: 0.1869, Val Acc: 0.9332
Epoch 88/100, Loss: 0.3980, Acc: 0.8113, Val Loss: 0.1859, Val Acc: 0.9339
Epoch 89/100, Loss: 0.3980, Acc: 0.8123, Val Loss: 0.1839, Val Acc: 0.9343
Epoch 90/100, Loss: 0.3980, Acc: 0.8124, Val Loss: 0.1808, Val Acc: 0.9365
Epoch 91/100, Loss: 0.3979, Acc: 0.8113, Val Loss: 0.1853, Val Acc: 0.9343
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3977, Acc: 0.8122, Val Loss: 0.1808, Val Acc: 0.9362
Epoch 93/100, Loss: 0.3976, Acc: 0.8111, Val Loss: 0.1850, Val Acc: 0.9336
Epoch 94/100, Loss: 0.3976, Acc: 0.8120, Val Loss: 0.1832, Val Acc: 0.9358
Epoch 95/100, Loss: 0.3976, Acc: 0.8124, Val Loss: 0.1850, Val Acc: 0.9343
Epoch 96/100, Loss: 0.3972, Acc: 0.8120, Val Loss: 0.1867, Val Acc: 0.9339
Epoch 97/100, Loss: 0.3974, Acc: 0.8116, Val Loss: 0.1849, Val Acc: 0.9336
Epoch 98/100, Loss: 0.3973, Acc: 0.8114, Val Loss: 0.1844, Val Acc: 0.9336
Epoch 99/100, Loss: 0.3971, Acc: 0.8134, Val Loss: 0.1848, Val Acc: 0.9339
Epoch 100/100, Loss: 0.3971, Acc: 0.8129, Val Loss: 0.1846, Val Acc: 0.9343

##############################
Resultados para principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11 
 {'training': [0.3970837227115965, 0.8128794848206071, 0.8433077234128589, 0.7681399631675875, 0.8039707016191211], 'validate': [0.18455164442055447, 0.9343173431734317, 0.990787269681742, 0.8762962962962964, 0.9300314465408805], 'test': [0.7754848813110927, 0.5864306784660767, 0.5636042402826855, 0.7550295857988165, 0.6454223571067274]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  020  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  020  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6419, Acc: 0.6557, Val Loss: 0.7533, Val Acc: 0.4011
Mejor modelo guardado con Val Loss: 0.7533
Epoch 2/100, Loss: 0.5771, Acc: 0.7080, Val Loss: 0.8599, Val Acc: 0.4203
Epoch 3/100, Loss: 0.5790, Acc: 0.7033, Val Loss: 0.8652, Val Acc: 0.3731
Epoch 4/100, Loss: 0.5562, Acc: 0.7137, Val Loss: 0.8513, Val Acc: 0.4587
Epoch 5/100, Loss: 0.5605, Acc: 0.7161, Val Loss: 0.9066, Val Acc: 0.4373
Epoch 6/100, Loss: 0.5462, Acc: 0.7247, Val Loss: 0.9091, Val Acc: 0.4280
Epoch 7/100, Loss: 0.5442, Acc: 0.7232, Val Loss: 0.8012, Val Acc: 0.4756
Epoch 8/100, Loss: 0.5338, Acc: 0.7321, Val Loss: 0.9329, Val Acc: 0.3897
Epoch 9/100, Loss: 0.5372, Acc: 0.7302, Val Loss: 0.8594, Val Acc: 0.4373
Epoch 10/100, Loss: 0.5151, Acc: 0.7412, Val Loss: 0.8865, Val Acc: 0.4668
Epoch 11/100, Loss: 0.5227, Acc: 0.7363, Val Loss: 0.9587, Val Acc: 0.4487
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5087, Acc: 0.7450, Val Loss: 0.9397, Val Acc: 0.4605
Epoch 13/100, Loss: 0.5066, Acc: 0.7503, Val Loss: 0.9378, Val Acc: 0.4295
Epoch 14/100, Loss: 0.5066, Acc: 0.7469, Val Loss: 0.9258, Val Acc: 0.4542
Epoch 15/100, Loss: 0.5024, Acc: 0.7510, Val Loss: 0.9408, Val Acc: 0.4454
Epoch 16/100, Loss: 0.5008, Acc: 0.7498, Val Loss: 0.9236, Val Acc: 0.4594
Epoch 17/100, Loss: 0.4985, Acc: 0.7538, Val Loss: 0.8872, Val Acc: 0.4103
Epoch 18/100, Loss: 0.4987, Acc: 0.7530, Val Loss: 0.9762, Val Acc: 0.4380
Epoch 19/100, Loss: 0.4960, Acc: 0.7560, Val Loss: 0.9711, Val Acc: 0.4410
Epoch 20/100, Loss: 0.4953, Acc: 0.7532, Val Loss: 0.9647, Val Acc: 0.4579
Epoch 21/100, Loss: 0.4918, Acc: 0.7569, Val Loss: 0.9184, Val Acc: 0.4771
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4926, Acc: 0.7569, Val Loss: 0.9261, Val Acc: 0.4391
Epoch 23/100, Loss: 0.4812, Acc: 0.7667, Val Loss: 0.9718, Val Acc: 0.4280
Epoch 24/100, Loss: 0.4885, Acc: 0.7598, Val Loss: 0.9660, Val Acc: 0.4458
Epoch 25/100, Loss: 0.4809, Acc: 0.7650, Val Loss: 0.9592, Val Acc: 0.4410
Epoch 26/100, Loss: 0.4861, Acc: 0.7636, Val Loss: 0.9654, Val Acc: 0.4395
Epoch 27/100, Loss: 0.4806, Acc: 0.7657, Val Loss: 0.9482, Val Acc: 0.4542
Epoch 28/100, Loss: 0.4804, Acc: 0.7665, Val Loss: 0.9497, Val Acc: 0.4539
Epoch 29/100, Loss: 0.4789, Acc: 0.7653, Val Loss: 0.9603, Val Acc: 0.4454
Epoch 30/100, Loss: 0.4788, Acc: 0.7669, Val Loss: 0.9562, Val Acc: 0.4539
Epoch 31/100, Loss: 0.4770, Acc: 0.7673, Val Loss: 0.9590, Val Acc: 0.4542
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4743, Acc: 0.7684, Val Loss: 0.9655, Val Acc: 0.4590
Epoch 33/100, Loss: 0.4746, Acc: 0.7667, Val Loss: 0.9610, Val Acc: 0.4583
Epoch 34/100, Loss: 0.4744, Acc: 0.7676, Val Loss: 0.9817, Val Acc: 0.4435
Epoch 35/100, Loss: 0.4742, Acc: 0.7698, Val Loss: 0.9626, Val Acc: 0.4590
Epoch 36/100, Loss: 0.4749, Acc: 0.7684, Val Loss: 0.9532, Val Acc: 0.4554
Epoch 37/100, Loss: 0.4741, Acc: 0.7728, Val Loss: 0.9644, Val Acc: 0.4509
Epoch 38/100, Loss: 0.4727, Acc: 0.7707, Val Loss: 0.9675, Val Acc: 0.4472
Epoch 39/100, Loss: 0.4729, Acc: 0.7702, Val Loss: 0.9663, Val Acc: 0.4531
Epoch 40/100, Loss: 0.4721, Acc: 0.7707, Val Loss: 0.9509, Val Acc: 0.4679
Epoch 41/100, Loss: 0.4731, Acc: 0.7694, Val Loss: 0.9567, Val Acc: 0.4531
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4695, Acc: 0.7717, Val Loss: 0.9720, Val Acc: 0.4428
Epoch 43/100, Loss: 0.4700, Acc: 0.7718, Val Loss: 0.9623, Val Acc: 0.4561
Epoch 44/100, Loss: 0.4701, Acc: 0.7710, Val Loss: 0.9624, Val Acc: 0.4502
Epoch 45/100, Loss: 0.4703, Acc: 0.7707, Val Loss: 0.9626, Val Acc: 0.4476
Epoch 46/100, Loss: 0.4699, Acc: 0.7712, Val Loss: 0.9666, Val Acc: 0.4480
Epoch 47/100, Loss: 0.4695, Acc: 0.7723, Val Loss: 0.9644, Val Acc: 0.4502
Epoch 48/100, Loss: 0.4691, Acc: 0.7738, Val Loss: 0.9635, Val Acc: 0.4561
Epoch 49/100, Loss: 0.4689, Acc: 0.7729, Val Loss: 0.9722, Val Acc: 0.4513
Epoch 50/100, Loss: 0.4687, Acc: 0.7715, Val Loss: 0.9667, Val Acc: 0.4554
Epoch 51/100, Loss: 0.4682, Acc: 0.7715, Val Loss: 0.9653, Val Acc: 0.4498
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4678, Acc: 0.7734, Val Loss: 0.9684, Val Acc: 0.4531
Epoch 53/100, Loss: 0.4677, Acc: 0.7742, Val Loss: 0.9755, Val Acc: 0.4461
Epoch 54/100, Loss: 0.4679, Acc: 0.7708, Val Loss: 0.9722, Val Acc: 0.4483
Epoch 55/100, Loss: 0.4674, Acc: 0.7723, Val Loss: 0.9699, Val Acc: 0.4520
Epoch 56/100, Loss: 0.4670, Acc: 0.7740, Val Loss: 0.9765, Val Acc: 0.4458
Epoch 57/100, Loss: 0.4674, Acc: 0.7738, Val Loss: 0.9690, Val Acc: 0.4524
Epoch 58/100, Loss: 0.4671, Acc: 0.7718, Val Loss: 0.9757, Val Acc: 0.4472
Epoch 59/100, Loss: 0.4674, Acc: 0.7720, Val Loss: 0.9696, Val Acc: 0.4531
Epoch 60/100, Loss: 0.4668, Acc: 0.7731, Val Loss: 0.9635, Val Acc: 0.4565
Epoch 61/100, Loss: 0.4668, Acc: 0.7718, Val Loss: 0.9745, Val Acc: 0.4506
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4665, Acc: 0.7725, Val Loss: 0.9732, Val Acc: 0.4513
Epoch 63/100, Loss: 0.4665, Acc: 0.7723, Val Loss: 0.9726, Val Acc: 0.4498
Epoch 64/100, Loss: 0.4665, Acc: 0.7735, Val Loss: 0.9722, Val Acc: 0.4502
Epoch 65/100, Loss: 0.4662, Acc: 0.7732, Val Loss: 0.9740, Val Acc: 0.4498
Epoch 66/100, Loss: 0.4664, Acc: 0.7727, Val Loss: 0.9755, Val Acc: 0.4487
Epoch 67/100, Loss: 0.4661, Acc: 0.7730, Val Loss: 0.9725, Val Acc: 0.4491
Epoch 68/100, Loss: 0.4663, Acc: 0.7733, Val Loss: 0.9748, Val Acc: 0.4498
Epoch 69/100, Loss: 0.4662, Acc: 0.7727, Val Loss: 0.9746, Val Acc: 0.4506
Epoch 70/100, Loss: 0.4661, Acc: 0.7747, Val Loss: 0.9733, Val Acc: 0.4506
Epoch 71/100, Loss: 0.4659, Acc: 0.7730, Val Loss: 0.9737, Val Acc: 0.4502
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4659, Acc: 0.7731, Val Loss: 0.9738, Val Acc: 0.4517
Epoch 73/100, Loss: 0.4660, Acc: 0.7730, Val Loss: 0.9744, Val Acc: 0.4513
Epoch 74/100, Loss: 0.4660, Acc: 0.7737, Val Loss: 0.9753, Val Acc: 0.4502
Epoch 75/100, Loss: 0.4656, Acc: 0.7739, Val Loss: 0.9756, Val Acc: 0.4509
Epoch 76/100, Loss: 0.4657, Acc: 0.7749, Val Loss: 0.9754, Val Acc: 0.4506
Epoch 77/100, Loss: 0.4656, Acc: 0.7741, Val Loss: 0.9742, Val Acc: 0.4517
Epoch 78/100, Loss: 0.4657, Acc: 0.7741, Val Loss: 0.9760, Val Acc: 0.4506
Epoch 79/100, Loss: 0.4656, Acc: 0.7740, Val Loss: 0.9761, Val Acc: 0.4502
Epoch 80/100, Loss: 0.4655, Acc: 0.7744, Val Loss: 0.9775, Val Acc: 0.4506
Epoch 81/100, Loss: 0.4654, Acc: 0.7738, Val Loss: 0.9766, Val Acc: 0.4502
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4653, Acc: 0.7727, Val Loss: 0.9777, Val Acc: 0.4502
Epoch 83/100, Loss: 0.4653, Acc: 0.7746, Val Loss: 0.9789, Val Acc: 0.4506
Epoch 84/100, Loss: 0.4653, Acc: 0.7738, Val Loss: 0.9780, Val Acc: 0.4506
Epoch 85/100, Loss: 0.4655, Acc: 0.7736, Val Loss: 0.9786, Val Acc: 0.4506
Epoch 86/100, Loss: 0.4653, Acc: 0.7741, Val Loss: 0.9780, Val Acc: 0.4498
Epoch 87/100, Loss: 0.4652, Acc: 0.7738, Val Loss: 0.9777, Val Acc: 0.4506
Epoch 88/100, Loss: 0.4651, Acc: 0.7737, Val Loss: 0.9772, Val Acc: 0.4494
Epoch 89/100, Loss: 0.4651, Acc: 0.7757, Val Loss: 0.9773, Val Acc: 0.4506
Epoch 90/100, Loss: 0.4653, Acc: 0.7750, Val Loss: 0.9779, Val Acc: 0.4498
Epoch 91/100, Loss: 0.4651, Acc: 0.7736, Val Loss: 0.9781, Val Acc: 0.4509
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4651, Acc: 0.7744, Val Loss: 0.9739, Val Acc: 0.4539
Epoch 93/100, Loss: 0.4654, Acc: 0.7762, Val Loss: 0.9774, Val Acc: 0.4498
Epoch 94/100, Loss: 0.4651, Acc: 0.7741, Val Loss: 0.9803, Val Acc: 0.4498
Epoch 95/100, Loss: 0.4650, Acc: 0.7745, Val Loss: 0.9792, Val Acc: 0.4502
Epoch 96/100, Loss: 0.4649, Acc: 0.7725, Val Loss: 0.9780, Val Acc: 0.4498
Epoch 97/100, Loss: 0.4650, Acc: 0.7726, Val Loss: 0.9785, Val Acc: 0.4480
Epoch 98/100, Loss: 0.4649, Acc: 0.7753, Val Loss: 0.9779, Val Acc: 0.4517
Epoch 99/100, Loss: 0.4650, Acc: 0.7731, Val Loss: 0.9791, Val Acc: 0.4502
Epoch 100/100, Loss: 0.4649, Acc: 0.7747, Val Loss: 0.9779, Val Acc: 0.4498

##############################
Resultados para principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11 
 {'training': [0.46493174829061906, 0.7747010119595216, 0.7320566713373813, 0.8659300184162063, 0.7933856407660508], 'validate': [0.9779166877269745, 0.44981549815498156, 0.4718562874251497, 0.8755555555555555, 0.6132295719844358], 'test': [0.5935793774870207, 0.7162241887905605, 0.7153846153846154, 0.7153846153846154, 0.7153846153846154]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  125  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  125  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6704, Acc: 0.5980, Val Loss: 0.6795, Val Acc: 0.5860
Mejor modelo guardado con Val Loss: 0.6795
Epoch 2/100, Loss: 0.6433, Acc: 0.6406, Val Loss: 0.6773, Val Acc: 0.5804
Mejor modelo guardado con Val Loss: 0.6773
Epoch 3/100, Loss: 0.6187, Acc: 0.6701, Val Loss: 0.6701, Val Acc: 0.5974
Mejor modelo guardado con Val Loss: 0.6701
Epoch 4/100, Loss: 0.6129, Acc: 0.6706, Val Loss: 0.6681, Val Acc: 0.6085
Mejor modelo guardado con Val Loss: 0.6681
Epoch 5/100, Loss: 0.5993, Acc: 0.6823, Val Loss: 0.6574, Val Acc: 0.6089
Mejor modelo guardado con Val Loss: 0.6574
Epoch 6/100, Loss: 0.6004, Acc: 0.6810, Val Loss: 0.6512, Val Acc: 0.6173
Mejor modelo guardado con Val Loss: 0.6512
Epoch 7/100, Loss: 0.5735, Acc: 0.7066, Val Loss: 0.6405, Val Acc: 0.6299
Mejor modelo guardado con Val Loss: 0.6405
Epoch 8/100, Loss: 0.5804, Acc: 0.6943, Val Loss: 0.6445, Val Acc: 0.6196
Epoch 9/100, Loss: 0.5684, Acc: 0.7062, Val Loss: 0.6617, Val Acc: 0.6177
Epoch 10/100, Loss: 0.5666, Acc: 0.7056, Val Loss: 0.6583, Val Acc: 0.6022
Epoch 11/100, Loss: 0.5606, Acc: 0.7137, Val Loss: 0.6742, Val Acc: 0.6229
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5567, Acc: 0.7120, Val Loss: 0.6383, Val Acc: 0.6446
Mejor modelo guardado con Val Loss: 0.6383
Epoch 13/100, Loss: 0.5498, Acc: 0.7204, Val Loss: 0.6445, Val Acc: 0.6303
Epoch 14/100, Loss: 0.5477, Acc: 0.7261, Val Loss: 0.6433, Val Acc: 0.6277
Epoch 15/100, Loss: 0.5468, Acc: 0.7241, Val Loss: 0.6907, Val Acc: 0.6004
Epoch 16/100, Loss: 0.5431, Acc: 0.7303, Val Loss: 0.6362, Val Acc: 0.6406
Mejor modelo guardado con Val Loss: 0.6362
Epoch 17/100, Loss: 0.5422, Acc: 0.7292, Val Loss: 0.6407, Val Acc: 0.6413
Epoch 18/100, Loss: 0.5412, Acc: 0.7293, Val Loss: 0.6345, Val Acc: 0.6446
Mejor modelo guardado con Val Loss: 0.6345
Epoch 19/100, Loss: 0.5398, Acc: 0.7308, Val Loss: 0.6434, Val Acc: 0.6354
Epoch 20/100, Loss: 0.5368, Acc: 0.7345, Val Loss: 0.6781, Val Acc: 0.6159
Epoch 21/100, Loss: 0.5407, Acc: 0.7278, Val Loss: 0.6521, Val Acc: 0.6266
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5308, Acc: 0.7366, Val Loss: 0.6546, Val Acc: 0.6232
Epoch 23/100, Loss: 0.5298, Acc: 0.7392, Val Loss: 0.6399, Val Acc: 0.6421
Epoch 24/100, Loss: 0.5302, Acc: 0.7397, Val Loss: 0.6586, Val Acc: 0.6188
Epoch 25/100, Loss: 0.5312, Acc: 0.7363, Val Loss: 0.6451, Val Acc: 0.6391
Epoch 26/100, Loss: 0.5295, Acc: 0.7374, Val Loss: 0.6416, Val Acc: 0.6380
Epoch 27/100, Loss: 0.5269, Acc: 0.7411, Val Loss: 0.6642, Val Acc: 0.6166
Epoch 28/100, Loss: 0.5260, Acc: 0.7442, Val Loss: 0.6464, Val Acc: 0.6347
Epoch 29/100, Loss: 0.5263, Acc: 0.7402, Val Loss: 0.6586, Val Acc: 0.6288
Epoch 30/100, Loss: 0.5264, Acc: 0.7374, Val Loss: 0.6610, Val Acc: 0.6192
Epoch 31/100, Loss: 0.5249, Acc: 0.7420, Val Loss: 0.6786, Val Acc: 0.6137
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5226, Acc: 0.7436, Val Loss: 0.6482, Val Acc: 0.6336
Epoch 33/100, Loss: 0.5217, Acc: 0.7443, Val Loss: 0.6463, Val Acc: 0.6317
Epoch 34/100, Loss: 0.5216, Acc: 0.7432, Val Loss: 0.6526, Val Acc: 0.6277
Epoch 35/100, Loss: 0.5206, Acc: 0.7454, Val Loss: 0.6472, Val Acc: 0.6321
Epoch 36/100, Loss: 0.5203, Acc: 0.7451, Val Loss: 0.6491, Val Acc: 0.6351
Epoch 37/100, Loss: 0.5212, Acc: 0.7466, Val Loss: 0.6542, Val Acc: 0.6214
Epoch 38/100, Loss: 0.5208, Acc: 0.7449, Val Loss: 0.6448, Val Acc: 0.6351
Epoch 39/100, Loss: 0.5196, Acc: 0.7457, Val Loss: 0.6527, Val Acc: 0.6306
Epoch 40/100, Loss: 0.5196, Acc: 0.7458, Val Loss: 0.6612, Val Acc: 0.6218
Epoch 41/100, Loss: 0.5184, Acc: 0.7477, Val Loss: 0.6563, Val Acc: 0.6247
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5178, Acc: 0.7457, Val Loss: 0.6551, Val Acc: 0.6229
Epoch 43/100, Loss: 0.5176, Acc: 0.7485, Val Loss: 0.6477, Val Acc: 0.6332
Epoch 44/100, Loss: 0.5172, Acc: 0.7477, Val Loss: 0.6564, Val Acc: 0.6251
Epoch 45/100, Loss: 0.5169, Acc: 0.7473, Val Loss: 0.6520, Val Acc: 0.6284
Epoch 46/100, Loss: 0.5168, Acc: 0.7461, Val Loss: 0.6520, Val Acc: 0.6258
Epoch 47/100, Loss: 0.5170, Acc: 0.7484, Val Loss: 0.6481, Val Acc: 0.6365
Epoch 48/100, Loss: 0.5165, Acc: 0.7480, Val Loss: 0.6515, Val Acc: 0.6303
Epoch 49/100, Loss: 0.5163, Acc: 0.7482, Val Loss: 0.6519, Val Acc: 0.6277
Epoch 50/100, Loss: 0.5158, Acc: 0.7494, Val Loss: 0.6550, Val Acc: 0.6255
Epoch 51/100, Loss: 0.5161, Acc: 0.7484, Val Loss: 0.6539, Val Acc: 0.6288
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5153, Acc: 0.7493, Val Loss: 0.6506, Val Acc: 0.6280
Epoch 53/100, Loss: 0.5148, Acc: 0.7486, Val Loss: 0.6527, Val Acc: 0.6310
Epoch 54/100, Loss: 0.5151, Acc: 0.7499, Val Loss: 0.6488, Val Acc: 0.6347
Epoch 55/100, Loss: 0.5147, Acc: 0.7500, Val Loss: 0.6504, Val Acc: 0.6295
Epoch 56/100, Loss: 0.5146, Acc: 0.7501, Val Loss: 0.6506, Val Acc: 0.6284
Epoch 57/100, Loss: 0.5148, Acc: 0.7477, Val Loss: 0.6509, Val Acc: 0.6310
Epoch 58/100, Loss: 0.5144, Acc: 0.7501, Val Loss: 0.6508, Val Acc: 0.6303
Epoch 59/100, Loss: 0.5146, Acc: 0.7486, Val Loss: 0.6508, Val Acc: 0.6325
Epoch 60/100, Loss: 0.5146, Acc: 0.7489, Val Loss: 0.6560, Val Acc: 0.6240
Epoch 61/100, Loss: 0.5140, Acc: 0.7501, Val Loss: 0.6488, Val Acc: 0.6343
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5138, Acc: 0.7505, Val Loss: 0.6516, Val Acc: 0.6292
Epoch 63/100, Loss: 0.5137, Acc: 0.7500, Val Loss: 0.6531, Val Acc: 0.6299
Epoch 64/100, Loss: 0.5136, Acc: 0.7503, Val Loss: 0.6538, Val Acc: 0.6277
Epoch 65/100, Loss: 0.5138, Acc: 0.7495, Val Loss: 0.6514, Val Acc: 0.6295
Epoch 66/100, Loss: 0.5136, Acc: 0.7494, Val Loss: 0.6523, Val Acc: 0.6295
Epoch 67/100, Loss: 0.5136, Acc: 0.7493, Val Loss: 0.6514, Val Acc: 0.6299
Epoch 68/100, Loss: 0.5136, Acc: 0.7505, Val Loss: 0.6510, Val Acc: 0.6303
Epoch 69/100, Loss: 0.5134, Acc: 0.7503, Val Loss: 0.6536, Val Acc: 0.6299
Epoch 70/100, Loss: 0.5134, Acc: 0.7504, Val Loss: 0.6533, Val Acc: 0.6284
Epoch 71/100, Loss: 0.5132, Acc: 0.7496, Val Loss: 0.6504, Val Acc: 0.6295
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5132, Acc: 0.7507, Val Loss: 0.6530, Val Acc: 0.6299
Epoch 73/100, Loss: 0.5130, Acc: 0.7509, Val Loss: 0.6526, Val Acc: 0.6306
Epoch 74/100, Loss: 0.5131, Acc: 0.7495, Val Loss: 0.6524, Val Acc: 0.6295
Epoch 75/100, Loss: 0.5130, Acc: 0.7497, Val Loss: 0.6508, Val Acc: 0.6295
Epoch 76/100, Loss: 0.5130, Acc: 0.7511, Val Loss: 0.6530, Val Acc: 0.6314
Epoch 77/100, Loss: 0.5129, Acc: 0.7500, Val Loss: 0.6526, Val Acc: 0.6303
Epoch 78/100, Loss: 0.5131, Acc: 0.7497, Val Loss: 0.6527, Val Acc: 0.6295
Epoch 79/100, Loss: 0.5130, Acc: 0.7503, Val Loss: 0.6528, Val Acc: 0.6303
Epoch 80/100, Loss: 0.5129, Acc: 0.7488, Val Loss: 0.6530, Val Acc: 0.6306
Epoch 81/100, Loss: 0.5128, Acc: 0.7500, Val Loss: 0.6524, Val Acc: 0.6295
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5128, Acc: 0.7507, Val Loss: 0.6517, Val Acc: 0.6280
Epoch 83/100, Loss: 0.5129, Acc: 0.7504, Val Loss: 0.6509, Val Acc: 0.6284
Epoch 84/100, Loss: 0.5129, Acc: 0.7500, Val Loss: 0.6519, Val Acc: 0.6288
Epoch 85/100, Loss: 0.5127, Acc: 0.7508, Val Loss: 0.6542, Val Acc: 0.6273
Epoch 86/100, Loss: 0.5127, Acc: 0.7501, Val Loss: 0.6517, Val Acc: 0.6280
Epoch 87/100, Loss: 0.5127, Acc: 0.7506, Val Loss: 0.6542, Val Acc: 0.6277
Epoch 88/100, Loss: 0.5128, Acc: 0.7508, Val Loss: 0.6530, Val Acc: 0.6306
Epoch 89/100, Loss: 0.5127, Acc: 0.7499, Val Loss: 0.6525, Val Acc: 0.6292
Epoch 90/100, Loss: 0.5124, Acc: 0.7517, Val Loss: 0.6512, Val Acc: 0.6292
Epoch 91/100, Loss: 0.5125, Acc: 0.7511, Val Loss: 0.6523, Val Acc: 0.6292
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5126, Acc: 0.7496, Val Loss: 0.6510, Val Acc: 0.6299
Epoch 93/100, Loss: 0.5125, Acc: 0.7500, Val Loss: 0.6523, Val Acc: 0.6288
Epoch 94/100, Loss: 0.5125, Acc: 0.7505, Val Loss: 0.6517, Val Acc: 0.6280
Epoch 95/100, Loss: 0.5125, Acc: 0.7510, Val Loss: 0.6525, Val Acc: 0.6292
Epoch 96/100, Loss: 0.5125, Acc: 0.7506, Val Loss: 0.6527, Val Acc: 0.6292
Epoch 97/100, Loss: 0.5124, Acc: 0.7509, Val Loss: 0.6515, Val Acc: 0.6288
Epoch 98/100, Loss: 0.5123, Acc: 0.7511, Val Loss: 0.6508, Val Acc: 0.6295
Epoch 99/100, Loss: 0.5123, Acc: 0.7509, Val Loss: 0.6518, Val Acc: 0.6284
Epoch 100/100, Loss: 0.5124, Acc: 0.7500, Val Loss: 0.6538, Val Acc: 0.6292

##############################
Resultados para principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11 
 {'training': [0.5123960844726878, 0.7500459981600736, 0.7318407109895745, 0.7885819521178637, 0.7591525573973938], 'validate': [0.6537814524977706, 0.6291512915129152, 0.6126714565643371, 0.6948148148148148, 0.6511627906976745], 'test': [0.7243632100663095, 0.5504424778761062, 0.5404483430799221, 0.6562130177514793, 0.5927311598075895]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  011  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  011  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6916, Acc: 0.5168, Val Loss: 0.6938, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6938
Epoch 2/100, Loss: 0.6929, Acc: 0.5096, Val Loss: 0.6930, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6930
Epoch 3/100, Loss: 0.6934, Acc: 0.5027, Val Loss: 0.6929, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6929
Epoch 4/100, Loss: 0.6930, Acc: 0.5081, Val Loss: 0.6954, Val Acc: 0.4550
Epoch 5/100, Loss: 0.6927, Acc: 0.5137, Val Loss: 0.6972, Val Acc: 0.4133
Epoch 6/100, Loss: 0.6922, Acc: 0.5224, Val Loss: 0.7080, Val Acc: 0.1653
Epoch 7/100, Loss: 0.6914, Acc: 0.5221, Val Loss: 0.6958, Val Acc: 0.4539
Epoch 8/100, Loss: 0.6908, Acc: 0.5260, Val Loss: 0.7016, Val Acc: 0.5018
Epoch 9/100, Loss: 0.6898, Acc: 0.5194, Val Loss: 0.7083, Val Acc: 0.2952
Epoch 10/100, Loss: 0.6890, Acc: 0.5374, Val Loss: 0.7032, Val Acc: 0.4022
Epoch 11/100, Loss: 0.6876, Acc: 0.5411, Val Loss: 0.7291, Val Acc: 0.5018
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6877, Acc: 0.5347, Val Loss: 0.6979, Val Acc: 0.3996
Epoch 13/100, Loss: 0.6868, Acc: 0.5482, Val Loss: 0.7037, Val Acc: 0.3941
Epoch 14/100, Loss: 0.6862, Acc: 0.5500, Val Loss: 0.7177, Val Acc: 0.3151
Epoch 15/100, Loss: 0.6858, Acc: 0.5458, Val Loss: 0.7133, Val Acc: 0.3502
Epoch 16/100, Loss: 0.6853, Acc: 0.5538, Val Loss: 0.7072, Val Acc: 0.3956
Epoch 17/100, Loss: 0.6855, Acc: 0.5484, Val Loss: 0.7007, Val Acc: 0.4391
Epoch 18/100, Loss: 0.6847, Acc: 0.5492, Val Loss: 0.7220, Val Acc: 0.2756
Epoch 19/100, Loss: 0.6844, Acc: 0.5497, Val Loss: 0.7126, Val Acc: 0.3137
Epoch 20/100, Loss: 0.6843, Acc: 0.5449, Val Loss: 0.7244, Val Acc: 0.3210
Epoch 21/100, Loss: 0.6842, Acc: 0.5521, Val Loss: 0.7160, Val Acc: 0.3790
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6837, Acc: 0.5519, Val Loss: 0.7183, Val Acc: 0.3262
Epoch 23/100, Loss: 0.6834, Acc: 0.5546, Val Loss: 0.7225, Val Acc: 0.3273
Epoch 24/100, Loss: 0.6831, Acc: 0.5547, Val Loss: 0.7183, Val Acc: 0.3561
Epoch 25/100, Loss: 0.6828, Acc: 0.5553, Val Loss: 0.7197, Val Acc: 0.3498
Epoch 26/100, Loss: 0.6828, Acc: 0.5573, Val Loss: 0.7149, Val Acc: 0.3620
Epoch 27/100, Loss: 0.6824, Acc: 0.5527, Val Loss: 0.7229, Val Acc: 0.3576
Epoch 28/100, Loss: 0.6824, Acc: 0.5554, Val Loss: 0.7277, Val Acc: 0.3258
Epoch 29/100, Loss: 0.6822, Acc: 0.5536, Val Loss: 0.7284, Val Acc: 0.3325
Epoch 30/100, Loss: 0.6820, Acc: 0.5581, Val Loss: 0.7348, Val Acc: 0.2948
Epoch 31/100, Loss: 0.6825, Acc: 0.5534, Val Loss: 0.7188, Val Acc: 0.3753
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6817, Acc: 0.5573, Val Loss: 0.7210, Val Acc: 0.3653
Epoch 33/100, Loss: 0.6816, Acc: 0.5584, Val Loss: 0.7238, Val Acc: 0.3494
Epoch 34/100, Loss: 0.6816, Acc: 0.5577, Val Loss: 0.7238, Val Acc: 0.3568
Epoch 35/100, Loss: 0.6814, Acc: 0.5566, Val Loss: 0.7228, Val Acc: 0.3598
Epoch 36/100, Loss: 0.6814, Acc: 0.5592, Val Loss: 0.7311, Val Acc: 0.3229
Epoch 37/100, Loss: 0.6813, Acc: 0.5576, Val Loss: 0.7244, Val Acc: 0.3557
Epoch 38/100, Loss: 0.6812, Acc: 0.5582, Val Loss: 0.7259, Val Acc: 0.3469
Epoch 39/100, Loss: 0.6812, Acc: 0.5565, Val Loss: 0.7308, Val Acc: 0.3288
Epoch 40/100, Loss: 0.6810, Acc: 0.5591, Val Loss: 0.7358, Val Acc: 0.3122
Epoch 41/100, Loss: 0.6810, Acc: 0.5572, Val Loss: 0.7288, Val Acc: 0.3339
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6809, Acc: 0.5584, Val Loss: 0.7325, Val Acc: 0.3244
Epoch 43/100, Loss: 0.6808, Acc: 0.5579, Val Loss: 0.7249, Val Acc: 0.3557
Epoch 44/100, Loss: 0.6808, Acc: 0.5606, Val Loss: 0.7286, Val Acc: 0.3395
Epoch 45/100, Loss: 0.6808, Acc: 0.5589, Val Loss: 0.7299, Val Acc: 0.3369
Epoch 46/100, Loss: 0.6808, Acc: 0.5592, Val Loss: 0.7289, Val Acc: 0.3410
Epoch 47/100, Loss: 0.6807, Acc: 0.5576, Val Loss: 0.7274, Val Acc: 0.3487
Epoch 48/100, Loss: 0.6807, Acc: 0.5603, Val Loss: 0.7283, Val Acc: 0.3424
Epoch 49/100, Loss: 0.6806, Acc: 0.5596, Val Loss: 0.7280, Val Acc: 0.3428
Epoch 50/100, Loss: 0.6806, Acc: 0.5587, Val Loss: 0.7265, Val Acc: 0.3546
Epoch 51/100, Loss: 0.6802, Acc: 0.5583, Val Loss: 0.7252, Val Acc: 0.3376
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6794, Acc: 0.5569, Val Loss: 0.7209, Val Acc: 0.3465
Epoch 53/100, Loss: 0.6793, Acc: 0.5593, Val Loss: 0.7172, Val Acc: 0.3531
Epoch 54/100, Loss: 0.6778, Acc: 0.5622, Val Loss: 0.7166, Val Acc: 0.4956
Epoch 55/100, Loss: 0.6773, Acc: 0.6025, Val Loss: 0.7159, Val Acc: 0.5196
Epoch 56/100, Loss: 0.6771, Acc: 0.6042, Val Loss: 0.7143, Val Acc: 0.5354
Epoch 57/100, Loss: 0.6769, Acc: 0.6120, Val Loss: 0.7150, Val Acc: 0.5181
Epoch 58/100, Loss: 0.6766, Acc: 0.6115, Val Loss: 0.7113, Val Acc: 0.5720
Epoch 59/100, Loss: 0.6754, Acc: 0.6149, Val Loss: 0.7155, Val Acc: 0.5616
Epoch 60/100, Loss: 0.6731, Acc: 0.6196, Val Loss: 0.7187, Val Acc: 0.4756
Epoch 61/100, Loss: 0.6714, Acc: 0.6111, Val Loss: 0.7120, Val Acc: 0.4435
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6708, Acc: 0.6148, Val Loss: 0.7144, Val Acc: 0.4266
Epoch 63/100, Loss: 0.6707, Acc: 0.6153, Val Loss: 0.7150, Val Acc: 0.4351
Epoch 64/100, Loss: 0.6704, Acc: 0.6181, Val Loss: 0.7128, Val Acc: 0.4343
Epoch 65/100, Loss: 0.6700, Acc: 0.6167, Val Loss: 0.7132, Val Acc: 0.4435
Epoch 66/100, Loss: 0.6699, Acc: 0.6169, Val Loss: 0.7156, Val Acc: 0.4262
Epoch 67/100, Loss: 0.6696, Acc: 0.6160, Val Loss: 0.7160, Val Acc: 0.4369
Epoch 68/100, Loss: 0.6695, Acc: 0.6170, Val Loss: 0.7146, Val Acc: 0.4399
Epoch 69/100, Loss: 0.6693, Acc: 0.6178, Val Loss: 0.7144, Val Acc: 0.4395
Epoch 70/100, Loss: 0.6691, Acc: 0.6185, Val Loss: 0.7126, Val Acc: 0.4461
Epoch 71/100, Loss: 0.6689, Acc: 0.6151, Val Loss: 0.7132, Val Acc: 0.4399
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6687, Acc: 0.6173, Val Loss: 0.7143, Val Acc: 0.4406
Epoch 73/100, Loss: 0.6685, Acc: 0.6191, Val Loss: 0.7130, Val Acc: 0.4480
Epoch 74/100, Loss: 0.6683, Acc: 0.6182, Val Loss: 0.7126, Val Acc: 0.4472
Epoch 75/100, Loss: 0.6683, Acc: 0.6211, Val Loss: 0.7129, Val Acc: 0.4465
Epoch 76/100, Loss: 0.6681, Acc: 0.6173, Val Loss: 0.7134, Val Acc: 0.4406
Epoch 77/100, Loss: 0.6680, Acc: 0.6186, Val Loss: 0.7125, Val Acc: 0.4465
Epoch 78/100, Loss: 0.6679, Acc: 0.6197, Val Loss: 0.7132, Val Acc: 0.4443
Epoch 79/100, Loss: 0.6678, Acc: 0.6184, Val Loss: 0.7138, Val Acc: 0.4424
Epoch 80/100, Loss: 0.6676, Acc: 0.6190, Val Loss: 0.7139, Val Acc: 0.4421
Epoch 81/100, Loss: 0.6676, Acc: 0.6190, Val Loss: 0.7136, Val Acc: 0.4435
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6673, Acc: 0.6201, Val Loss: 0.7119, Val Acc: 0.4424
Epoch 83/100, Loss: 0.6673, Acc: 0.6197, Val Loss: 0.7129, Val Acc: 0.4376
Epoch 84/100, Loss: 0.6672, Acc: 0.6178, Val Loss: 0.7117, Val Acc: 0.4476
Epoch 85/100, Loss: 0.6670, Acc: 0.6196, Val Loss: 0.7128, Val Acc: 0.4417
Epoch 86/100, Loss: 0.6669, Acc: 0.6199, Val Loss: 0.7127, Val Acc: 0.4406
Epoch 87/100, Loss: 0.6669, Acc: 0.6211, Val Loss: 0.7131, Val Acc: 0.4454
Epoch 88/100, Loss: 0.6667, Acc: 0.6194, Val Loss: 0.7123, Val Acc: 0.4450
Epoch 89/100, Loss: 0.6666, Acc: 0.6222, Val Loss: 0.7119, Val Acc: 0.4469
Epoch 90/100, Loss: 0.6664, Acc: 0.6210, Val Loss: 0.7120, Val Acc: 0.4465
Epoch 91/100, Loss: 0.6662, Acc: 0.6220, Val Loss: 0.7113, Val Acc: 0.4469
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6662, Acc: 0.6201, Val Loss: 0.7110, Val Acc: 0.4491
Epoch 93/100, Loss: 0.6660, Acc: 0.6204, Val Loss: 0.7117, Val Acc: 0.4472
Epoch 94/100, Loss: 0.6659, Acc: 0.6210, Val Loss: 0.7110, Val Acc: 0.4476
Epoch 95/100, Loss: 0.6658, Acc: 0.6193, Val Loss: 0.7103, Val Acc: 0.4428
Epoch 96/100, Loss: 0.6657, Acc: 0.6194, Val Loss: 0.7094, Val Acc: 0.4502
Epoch 97/100, Loss: 0.6655, Acc: 0.6207, Val Loss: 0.7102, Val Acc: 0.4472
Epoch 98/100, Loss: 0.6654, Acc: 0.6203, Val Loss: 0.7119, Val Acc: 0.4421
Epoch 99/100, Loss: 0.6653, Acc: 0.6205, Val Loss: 0.7112, Val Acc: 0.4487
Epoch 100/100, Loss: 0.6652, Acc: 0.6197, Val Loss: 0.7107, Val Acc: 0.4491

##############################
Resultados para principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11 
 {'training': [0.6651892732455298, 0.6196872125114995, 0.6097189299017948, 0.6631675874769798, 0.6353211009174312], 'validate': [0.710657793422078, 0.4490774907749078, 0.457159976033553, 0.5651851851851852, 0.5054653858893673], 'test': [0.6934634728251763, 0.5014749262536873, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  021  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  021  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5986, Acc: 0.7188, Val Loss: 0.3732, Val Acc: 0.9314
Mejor modelo guardado con Val Loss: 0.3732
Epoch 2/100, Loss: 0.5334, Acc: 0.7437, Val Loss: 0.3551, Val Acc: 0.9428
Mejor modelo guardado con Val Loss: 0.3551
Epoch 3/100, Loss: 0.5204, Acc: 0.7462, Val Loss: 0.3363, Val Acc: 0.9166
Mejor modelo guardado con Val Loss: 0.3363
Epoch 4/100, Loss: 0.5091, Acc: 0.7583, Val Loss: 0.2936, Val Acc: 0.9439
Mejor modelo guardado con Val Loss: 0.2936
Epoch 5/100, Loss: 0.5038, Acc: 0.7592, Val Loss: 0.2544, Val Acc: 0.9539
Mejor modelo guardado con Val Loss: 0.2544
Epoch 6/100, Loss: 0.4976, Acc: 0.7633, Val Loss: 0.2616, Val Acc: 0.9502
Epoch 7/100, Loss: 0.4959, Acc: 0.7625, Val Loss: 0.2642, Val Acc: 0.9358
Epoch 8/100, Loss: 0.4894, Acc: 0.7632, Val Loss: 0.2457, Val Acc: 0.9531
Mejor modelo guardado con Val Loss: 0.2457
Epoch 9/100, Loss: 0.4989, Acc: 0.7584, Val Loss: 0.2959, Val Acc: 0.9432
Epoch 10/100, Loss: 0.4955, Acc: 0.7634, Val Loss: 0.2676, Val Acc: 0.9399
Epoch 11/100, Loss: 0.4913, Acc: 0.7631, Val Loss: 0.2618, Val Acc: 0.9336
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4847, Acc: 0.7684, Val Loss: 0.2264, Val Acc: 0.9491
Mejor modelo guardado con Val Loss: 0.2264
Epoch 13/100, Loss: 0.4836, Acc: 0.7707, Val Loss: 0.2349, Val Acc: 0.9435
Epoch 14/100, Loss: 0.4832, Acc: 0.7691, Val Loss: 0.2420, Val Acc: 0.9380
Epoch 15/100, Loss: 0.4819, Acc: 0.7725, Val Loss: 0.2431, Val Acc: 0.9513
Epoch 16/100, Loss: 0.4786, Acc: 0.7715, Val Loss: 0.2251, Val Acc: 0.9421
Mejor modelo guardado con Val Loss: 0.2251
Epoch 17/100, Loss: 0.4828, Acc: 0.7696, Val Loss: 0.2064, Val Acc: 0.9487
Mejor modelo guardado con Val Loss: 0.2064
Epoch 18/100, Loss: 0.4811, Acc: 0.7725, Val Loss: 0.2117, Val Acc: 0.9506
Epoch 19/100, Loss: 0.4769, Acc: 0.7730, Val Loss: 0.2228, Val Acc: 0.9391
Epoch 20/100, Loss: 0.4795, Acc: 0.7742, Val Loss: 0.2477, Val Acc: 0.9472
Epoch 21/100, Loss: 0.4750, Acc: 0.7750, Val Loss: 0.2366, Val Acc: 0.9428
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4721, Acc: 0.7778, Val Loss: 0.2372, Val Acc: 0.9435
Epoch 23/100, Loss: 0.4719, Acc: 0.7791, Val Loss: 0.2217, Val Acc: 0.9439
Epoch 24/100, Loss: 0.4685, Acc: 0.7802, Val Loss: 0.2320, Val Acc: 0.9487
Epoch 25/100, Loss: 0.4710, Acc: 0.7791, Val Loss: 0.2179, Val Acc: 0.9365
Epoch 26/100, Loss: 0.4708, Acc: 0.7773, Val Loss: 0.2181, Val Acc: 0.9498
Epoch 27/100, Loss: 0.4666, Acc: 0.7812, Val Loss: 0.2014, Val Acc: 0.9491
Mejor modelo guardado con Val Loss: 0.2014
Epoch 28/100, Loss: 0.4676, Acc: 0.7801, Val Loss: 0.2350, Val Acc: 0.9446
Epoch 29/100, Loss: 0.4663, Acc: 0.7802, Val Loss: 0.2087, Val Acc: 0.9550
Epoch 30/100, Loss: 0.4667, Acc: 0.7802, Val Loss: 0.2028, Val Acc: 0.9439
Epoch 31/100, Loss: 0.4660, Acc: 0.7833, Val Loss: 0.2233, Val Acc: 0.9325
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4646, Acc: 0.7836, Val Loss: 0.2137, Val Acc: 0.9424
Epoch 33/100, Loss: 0.4618, Acc: 0.7849, Val Loss: 0.2141, Val Acc: 0.9528
Epoch 34/100, Loss: 0.4630, Acc: 0.7822, Val Loss: 0.2156, Val Acc: 0.9531
Epoch 35/100, Loss: 0.4627, Acc: 0.7861, Val Loss: 0.2115, Val Acc: 0.9446
Epoch 36/100, Loss: 0.4625, Acc: 0.7847, Val Loss: 0.2260, Val Acc: 0.9476
Epoch 37/100, Loss: 0.4616, Acc: 0.7852, Val Loss: 0.2107, Val Acc: 0.9428
Epoch 38/100, Loss: 0.4610, Acc: 0.7846, Val Loss: 0.2089, Val Acc: 0.9435
Epoch 39/100, Loss: 0.4602, Acc: 0.7856, Val Loss: 0.2204, Val Acc: 0.9410
Epoch 40/100, Loss: 0.4601, Acc: 0.7868, Val Loss: 0.2120, Val Acc: 0.9535
Epoch 41/100, Loss: 0.4598, Acc: 0.7849, Val Loss: 0.2303, Val Acc: 0.9373
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4586, Acc: 0.7863, Val Loss: 0.2124, Val Acc: 0.9402
Epoch 43/100, Loss: 0.4580, Acc: 0.7883, Val Loss: 0.2170, Val Acc: 0.9435
Epoch 44/100, Loss: 0.4579, Acc: 0.7861, Val Loss: 0.2168, Val Acc: 0.9443
Epoch 45/100, Loss: 0.4579, Acc: 0.7868, Val Loss: 0.2123, Val Acc: 0.9421
Epoch 46/100, Loss: 0.4578, Acc: 0.7879, Val Loss: 0.2111, Val Acc: 0.9446
Epoch 47/100, Loss: 0.4574, Acc: 0.7869, Val Loss: 0.2116, Val Acc: 0.9395
Epoch 48/100, Loss: 0.4578, Acc: 0.7866, Val Loss: 0.2121, Val Acc: 0.9465
Epoch 49/100, Loss: 0.4570, Acc: 0.7863, Val Loss: 0.2190, Val Acc: 0.9395
Epoch 50/100, Loss: 0.4573, Acc: 0.7856, Val Loss: 0.2143, Val Acc: 0.9443
Epoch 51/100, Loss: 0.4569, Acc: 0.7889, Val Loss: 0.2050, Val Acc: 0.9502
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4563, Acc: 0.7874, Val Loss: 0.2096, Val Acc: 0.9461
Epoch 53/100, Loss: 0.4560, Acc: 0.7880, Val Loss: 0.2094, Val Acc: 0.9443
Epoch 54/100, Loss: 0.4561, Acc: 0.7895, Val Loss: 0.2105, Val Acc: 0.9443
Epoch 55/100, Loss: 0.4558, Acc: 0.7883, Val Loss: 0.2124, Val Acc: 0.9454
Epoch 56/100, Loss: 0.4558, Acc: 0.7875, Val Loss: 0.2105, Val Acc: 0.9461
Epoch 57/100, Loss: 0.4558, Acc: 0.7868, Val Loss: 0.2110, Val Acc: 0.9443
Epoch 58/100, Loss: 0.4555, Acc: 0.7873, Val Loss: 0.2117, Val Acc: 0.9424
Epoch 59/100, Loss: 0.4554, Acc: 0.7859, Val Loss: 0.2105, Val Acc: 0.9450
Epoch 60/100, Loss: 0.4555, Acc: 0.7880, Val Loss: 0.2087, Val Acc: 0.9476
Epoch 61/100, Loss: 0.4557, Acc: 0.7888, Val Loss: 0.2099, Val Acc: 0.9443
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4549, Acc: 0.7886, Val Loss: 0.2109, Val Acc: 0.9428
Epoch 63/100, Loss: 0.4548, Acc: 0.7874, Val Loss: 0.2102, Val Acc: 0.9476
Epoch 64/100, Loss: 0.4550, Acc: 0.7879, Val Loss: 0.2088, Val Acc: 0.9461
Epoch 65/100, Loss: 0.4547, Acc: 0.7885, Val Loss: 0.2115, Val Acc: 0.9424
Epoch 66/100, Loss: 0.4547, Acc: 0.7885, Val Loss: 0.2100, Val Acc: 0.9443
Epoch 67/100, Loss: 0.4545, Acc: 0.7885, Val Loss: 0.2117, Val Acc: 0.9450
Epoch 68/100, Loss: 0.4546, Acc: 0.7890, Val Loss: 0.2091, Val Acc: 0.9461
Epoch 69/100, Loss: 0.4546, Acc: 0.7887, Val Loss: 0.2104, Val Acc: 0.9432
Epoch 70/100, Loss: 0.4544, Acc: 0.7886, Val Loss: 0.2105, Val Acc: 0.9432
Epoch 71/100, Loss: 0.4546, Acc: 0.7870, Val Loss: 0.2101, Val Acc: 0.9435
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4542, Acc: 0.7884, Val Loss: 0.2108, Val Acc: 0.9435
Epoch 73/100, Loss: 0.4543, Acc: 0.7892, Val Loss: 0.2104, Val Acc: 0.9443
Epoch 74/100, Loss: 0.4542, Acc: 0.7890, Val Loss: 0.2099, Val Acc: 0.9439
Epoch 75/100, Loss: 0.4541, Acc: 0.7899, Val Loss: 0.2100, Val Acc: 0.9439
Epoch 76/100, Loss: 0.4541, Acc: 0.7891, Val Loss: 0.2100, Val Acc: 0.9446
Epoch 77/100, Loss: 0.4541, Acc: 0.7886, Val Loss: 0.2103, Val Acc: 0.9439
Epoch 78/100, Loss: 0.4541, Acc: 0.7883, Val Loss: 0.2098, Val Acc: 0.9435
Epoch 79/100, Loss: 0.4540, Acc: 0.7884, Val Loss: 0.2099, Val Acc: 0.9435
Epoch 80/100, Loss: 0.4540, Acc: 0.7887, Val Loss: 0.2102, Val Acc: 0.9439
Epoch 81/100, Loss: 0.4540, Acc: 0.7897, Val Loss: 0.2103, Val Acc: 0.9424
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4540, Acc: 0.7892, Val Loss: 0.2105, Val Acc: 0.9435
Epoch 83/100, Loss: 0.4539, Acc: 0.7891, Val Loss: 0.2094, Val Acc: 0.9435
Epoch 84/100, Loss: 0.4539, Acc: 0.7886, Val Loss: 0.2092, Val Acc: 0.9443
Epoch 85/100, Loss: 0.4538, Acc: 0.7893, Val Loss: 0.2100, Val Acc: 0.9435
Epoch 86/100, Loss: 0.4538, Acc: 0.7890, Val Loss: 0.2097, Val Acc: 0.9443
Epoch 87/100, Loss: 0.4539, Acc: 0.7884, Val Loss: 0.2099, Val Acc: 0.9432
Epoch 88/100, Loss: 0.4537, Acc: 0.7884, Val Loss: 0.2099, Val Acc: 0.9421
Epoch 89/100, Loss: 0.4538, Acc: 0.7885, Val Loss: 0.2089, Val Acc: 0.9439
Epoch 90/100, Loss: 0.4537, Acc: 0.7902, Val Loss: 0.2090, Val Acc: 0.9432
Epoch 91/100, Loss: 0.4536, Acc: 0.7890, Val Loss: 0.2091, Val Acc: 0.9421
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4538, Acc: 0.7879, Val Loss: 0.2085, Val Acc: 0.9450
Epoch 93/100, Loss: 0.4537, Acc: 0.7894, Val Loss: 0.2089, Val Acc: 0.9443
Epoch 94/100, Loss: 0.4536, Acc: 0.7897, Val Loss: 0.2092, Val Acc: 0.9428
Epoch 95/100, Loss: 0.4535, Acc: 0.7895, Val Loss: 0.2099, Val Acc: 0.9435
Epoch 96/100, Loss: 0.4536, Acc: 0.7890, Val Loss: 0.2081, Val Acc: 0.9439
Epoch 97/100, Loss: 0.4536, Acc: 0.7888, Val Loss: 0.2086, Val Acc: 0.9439
Epoch 98/100, Loss: 0.4535, Acc: 0.7897, Val Loss: 0.2098, Val Acc: 0.9432
Epoch 99/100, Loss: 0.4535, Acc: 0.7902, Val Loss: 0.2086, Val Acc: 0.9439
Epoch 100/100, Loss: 0.4534, Acc: 0.7894, Val Loss: 0.2080, Val Acc: 0.9458

##############################
Resultados para principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11 
 {'training': [0.4533602750838735, 0.7894204231830727, 0.7652423577098463, 0.8344383057090239, 0.7983437582591842], 'validate': [0.20800618333525436, 0.9457564575645756, 0.9324227174694465, 0.9607407407407408, 0.9463699379788398], 'test': [0.19508063828326622, 0.968141592920354, 0.9811435523114356, 0.9544378698224852, 0.9676064787042592]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  008  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  008  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6730, Acc: 0.6221, Val Loss: 0.6956, Val Acc: 0.4620
Mejor modelo guardado con Val Loss: 0.6956
Epoch 2/100, Loss: 0.6491, Acc: 0.6661, Val Loss: 0.7195, Val Acc: 0.4845
Epoch 3/100, Loss: 0.6230, Acc: 0.6865, Val Loss: 0.7390, Val Acc: 0.4731
Epoch 4/100, Loss: 0.6103, Acc: 0.6937, Val Loss: 0.7631, Val Acc: 0.4985
Epoch 5/100, Loss: 0.6007, Acc: 0.6966, Val Loss: 0.7992, Val Acc: 0.4875
Epoch 6/100, Loss: 0.5950, Acc: 0.6977, Val Loss: 0.7922, Val Acc: 0.5347
Epoch 7/100, Loss: 0.5936, Acc: 0.6973, Val Loss: 0.7680, Val Acc: 0.4321
Epoch 8/100, Loss: 0.5928, Acc: 0.6970, Val Loss: 0.8293, Val Acc: 0.4295
Epoch 9/100, Loss: 0.5848, Acc: 0.7039, Val Loss: 0.8634, Val Acc: 0.4472
Epoch 10/100, Loss: 0.5826, Acc: 0.7094, Val Loss: 0.8526, Val Acc: 0.4351
Epoch 11/100, Loss: 0.5827, Acc: 0.7091, Val Loss: 0.8851, Val Acc: 0.4520
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5777, Acc: 0.7115, Val Loss: 0.8700, Val Acc: 0.4565
Epoch 13/100, Loss: 0.5764, Acc: 0.7109, Val Loss: 0.8810, Val Acc: 0.4417
Epoch 14/100, Loss: 0.5739, Acc: 0.7119, Val Loss: 0.8783, Val Acc: 0.4653
Epoch 15/100, Loss: 0.5747, Acc: 0.7112, Val Loss: 0.8889, Val Acc: 0.4542
Epoch 16/100, Loss: 0.5726, Acc: 0.7148, Val Loss: 0.8754, Val Acc: 0.4406
Epoch 17/100, Loss: 0.5731, Acc: 0.7121, Val Loss: 0.8921, Val Acc: 0.4524
Epoch 18/100, Loss: 0.5745, Acc: 0.7106, Val Loss: 0.8456, Val Acc: 0.4465
Epoch 19/100, Loss: 0.5722, Acc: 0.7154, Val Loss: 0.8934, Val Acc: 0.4506
Epoch 20/100, Loss: 0.5720, Acc: 0.7157, Val Loss: 0.8794, Val Acc: 0.4649
Epoch 21/100, Loss: 0.5690, Acc: 0.7173, Val Loss: 0.8987, Val Acc: 0.4627
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5660, Acc: 0.7193, Val Loss: 0.9001, Val Acc: 0.4653
Epoch 23/100, Loss: 0.5674, Acc: 0.7201, Val Loss: 0.8949, Val Acc: 0.4653
Epoch 24/100, Loss: 0.5660, Acc: 0.7197, Val Loss: 0.9032, Val Acc: 0.4720
Epoch 25/100, Loss: 0.5657, Acc: 0.7199, Val Loss: 0.9004, Val Acc: 0.4491
Epoch 26/100, Loss: 0.5650, Acc: 0.7165, Val Loss: 0.9014, Val Acc: 0.4494
Epoch 27/100, Loss: 0.5644, Acc: 0.7202, Val Loss: 0.8933, Val Acc: 0.4690
Epoch 28/100, Loss: 0.5639, Acc: 0.7200, Val Loss: 0.9072, Val Acc: 0.4646
Epoch 29/100, Loss: 0.5636, Acc: 0.7197, Val Loss: 0.9022, Val Acc: 0.4742
Epoch 30/100, Loss: 0.5635, Acc: 0.7192, Val Loss: 0.9061, Val Acc: 0.4524
Epoch 31/100, Loss: 0.5642, Acc: 0.7197, Val Loss: 0.9003, Val Acc: 0.4716
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5616, Acc: 0.7227, Val Loss: 0.9050, Val Acc: 0.4520
Epoch 33/100, Loss: 0.5605, Acc: 0.7233, Val Loss: 0.9020, Val Acc: 0.4417
Epoch 34/100, Loss: 0.5606, Acc: 0.7237, Val Loss: 0.9069, Val Acc: 0.4384
Epoch 35/100, Loss: 0.5609, Acc: 0.7236, Val Loss: 0.8955, Val Acc: 0.4424
Epoch 36/100, Loss: 0.5608, Acc: 0.7224, Val Loss: 0.9047, Val Acc: 0.4539
Epoch 37/100, Loss: 0.5597, Acc: 0.7230, Val Loss: 0.9072, Val Acc: 0.4406
Epoch 38/100, Loss: 0.5599, Acc: 0.7249, Val Loss: 0.8979, Val Acc: 0.4469
Epoch 39/100, Loss: 0.5601, Acc: 0.7260, Val Loss: 0.9049, Val Acc: 0.4450
Epoch 40/100, Loss: 0.5594, Acc: 0.7242, Val Loss: 0.9028, Val Acc: 0.4561
Epoch 41/100, Loss: 0.5605, Acc: 0.7239, Val Loss: 0.9061, Val Acc: 0.4483
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5587, Acc: 0.7253, Val Loss: 0.9112, Val Acc: 0.4454
Epoch 43/100, Loss: 0.5588, Acc: 0.7255, Val Loss: 0.9012, Val Acc: 0.4439
Epoch 44/100, Loss: 0.5587, Acc: 0.7250, Val Loss: 0.9133, Val Acc: 0.4506
Epoch 45/100, Loss: 0.5583, Acc: 0.7250, Val Loss: 0.9102, Val Acc: 0.4594
Epoch 46/100, Loss: 0.5588, Acc: 0.7246, Val Loss: 0.9148, Val Acc: 0.4557
Epoch 47/100, Loss: 0.5582, Acc: 0.7262, Val Loss: 0.9105, Val Acc: 0.4461
Epoch 48/100, Loss: 0.5580, Acc: 0.7258, Val Loss: 0.9108, Val Acc: 0.4494
Epoch 49/100, Loss: 0.5578, Acc: 0.7252, Val Loss: 0.9131, Val Acc: 0.4517
Epoch 50/100, Loss: 0.5582, Acc: 0.7275, Val Loss: 0.9169, Val Acc: 0.4535
Epoch 51/100, Loss: 0.5584, Acc: 0.7268, Val Loss: 0.9161, Val Acc: 0.4494
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5577, Acc: 0.7270, Val Loss: 0.9150, Val Acc: 0.4613
Epoch 53/100, Loss: 0.5575, Acc: 0.7264, Val Loss: 0.9144, Val Acc: 0.4557
Epoch 54/100, Loss: 0.5572, Acc: 0.7276, Val Loss: 0.9122, Val Acc: 0.4465
Epoch 55/100, Loss: 0.5569, Acc: 0.7272, Val Loss: 0.9084, Val Acc: 0.4391
Epoch 56/100, Loss: 0.5572, Acc: 0.7271, Val Loss: 0.9083, Val Acc: 0.4483
Epoch 57/100, Loss: 0.5570, Acc: 0.7275, Val Loss: 0.9109, Val Acc: 0.4583
Epoch 58/100, Loss: 0.5567, Acc: 0.7271, Val Loss: 0.9116, Val Acc: 0.4509
Epoch 59/100, Loss: 0.5567, Acc: 0.7265, Val Loss: 0.9117, Val Acc: 0.4506
Epoch 60/100, Loss: 0.5567, Acc: 0.7270, Val Loss: 0.9086, Val Acc: 0.4472
Epoch 61/100, Loss: 0.5568, Acc: 0.7282, Val Loss: 0.9117, Val Acc: 0.4557
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5565, Acc: 0.7284, Val Loss: 0.9096, Val Acc: 0.4487
Epoch 63/100, Loss: 0.5564, Acc: 0.7280, Val Loss: 0.9109, Val Acc: 0.4531
Epoch 64/100, Loss: 0.5562, Acc: 0.7275, Val Loss: 0.9108, Val Acc: 0.4528
Epoch 65/100, Loss: 0.5563, Acc: 0.7272, Val Loss: 0.9116, Val Acc: 0.4554
Epoch 66/100, Loss: 0.5561, Acc: 0.7283, Val Loss: 0.9113, Val Acc: 0.4509
Epoch 67/100, Loss: 0.5563, Acc: 0.7275, Val Loss: 0.9112, Val Acc: 0.4524
Epoch 68/100, Loss: 0.5562, Acc: 0.7283, Val Loss: 0.9112, Val Acc: 0.4509
Epoch 69/100, Loss: 0.5560, Acc: 0.7283, Val Loss: 0.9106, Val Acc: 0.4513
Epoch 70/100, Loss: 0.5558, Acc: 0.7289, Val Loss: 0.9114, Val Acc: 0.4557
Epoch 71/100, Loss: 0.5558, Acc: 0.7282, Val Loss: 0.9108, Val Acc: 0.4542
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5555, Acc: 0.7279, Val Loss: 0.9100, Val Acc: 0.4506
Epoch 73/100, Loss: 0.5555, Acc: 0.7269, Val Loss: 0.9088, Val Acc: 0.4509
Epoch 74/100, Loss: 0.5555, Acc: 0.7276, Val Loss: 0.9092, Val Acc: 0.4513
Epoch 75/100, Loss: 0.5555, Acc: 0.7282, Val Loss: 0.9100, Val Acc: 0.4513
Epoch 76/100, Loss: 0.5554, Acc: 0.7270, Val Loss: 0.9112, Val Acc: 0.4561
Epoch 77/100, Loss: 0.5554, Acc: 0.7277, Val Loss: 0.9115, Val Acc: 0.4550
Epoch 78/100, Loss: 0.5554, Acc: 0.7282, Val Loss: 0.9106, Val Acc: 0.4528
Epoch 79/100, Loss: 0.5554, Acc: 0.7282, Val Loss: 0.9098, Val Acc: 0.4517
Epoch 80/100, Loss: 0.5553, Acc: 0.7283, Val Loss: 0.9098, Val Acc: 0.4524
Epoch 81/100, Loss: 0.5554, Acc: 0.7278, Val Loss: 0.9106, Val Acc: 0.4546
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5553, Acc: 0.7290, Val Loss: 0.9098, Val Acc: 0.4480
Epoch 83/100, Loss: 0.5553, Acc: 0.7281, Val Loss: 0.9099, Val Acc: 0.4506
Epoch 84/100, Loss: 0.5552, Acc: 0.7277, Val Loss: 0.9102, Val Acc: 0.4506
Epoch 85/100, Loss: 0.5553, Acc: 0.7286, Val Loss: 0.9094, Val Acc: 0.4491
Epoch 86/100, Loss: 0.5552, Acc: 0.7282, Val Loss: 0.9109, Val Acc: 0.4506
Epoch 87/100, Loss: 0.5553, Acc: 0.7283, Val Loss: 0.9111, Val Acc: 0.4524
Epoch 88/100, Loss: 0.5551, Acc: 0.7276, Val Loss: 0.9122, Val Acc: 0.4587
Epoch 89/100, Loss: 0.5552, Acc: 0.7284, Val Loss: 0.9094, Val Acc: 0.4491
Epoch 90/100, Loss: 0.5551, Acc: 0.7276, Val Loss: 0.9115, Val Acc: 0.4561
Epoch 91/100, Loss: 0.5551, Acc: 0.7280, Val Loss: 0.9105, Val Acc: 0.4509
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5551, Acc: 0.7279, Val Loss: 0.9110, Val Acc: 0.4531
Epoch 93/100, Loss: 0.5551, Acc: 0.7280, Val Loss: 0.9108, Val Acc: 0.4517
Epoch 94/100, Loss: 0.5551, Acc: 0.7290, Val Loss: 0.9115, Val Acc: 0.4546
Epoch 95/100, Loss: 0.5550, Acc: 0.7284, Val Loss: 0.9108, Val Acc: 0.4513
Epoch 96/100, Loss: 0.5550, Acc: 0.7282, Val Loss: 0.9111, Val Acc: 0.4517
Epoch 97/100, Loss: 0.5551, Acc: 0.7284, Val Loss: 0.9102, Val Acc: 0.4509
Epoch 98/100, Loss: 0.5547, Acc: 0.7289, Val Loss: 0.9091, Val Acc: 0.4506
Epoch 99/100, Loss: 0.5547, Acc: 0.7282, Val Loss: 0.9104, Val Acc: 0.4509
Epoch 100/100, Loss: 0.5544, Acc: 0.7289, Val Loss: 0.9114, Val Acc: 0.4491

##############################
Resultados para principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  11 
 {'training': [0.5543762764364838, 0.728886844526219, 0.6875660975978245, 0.838121546961326, 0.7554153871690596], 'validate': [0.9114427580389866, 0.4490774907749078, 0.4605190502484815, 0.6177777777777778, 0.5276811135716546], 'test': [0.6055494816798084, 0.8967551622418879, 0.8726362625139044, 0.9284023668639053, 0.8996559633027523]}

##############################
Resultados para window:  11 
 {'102:020:125:011:021:008': {'training': [0.3970837227115965, 0.8128794848206071, 0.8433077234128589, 0.7681399631675875, 0.8039707016191211], 'validate': [0.18455164442055447, 0.9343173431734317, 0.990787269681742, 0.8762962962962964, 0.9300314465408805], 'test': [0.7754848813110927, 0.5864306784660767, 0.5636042402826855, 0.7550295857988165, 0.6454223571067274]}, '020:102:125:011:021:008': {'training': [0.46493174829061906, 0.7747010119595216, 0.7320566713373813, 0.8659300184162063, 0.7933856407660508], 'validate': [0.9779166877269745, 0.44981549815498156, 0.4718562874251497, 0.8755555555555555, 0.6132295719844358], 'test': [0.5935793774870207, 0.7162241887905605, 0.7153846153846154, 0.7153846153846154, 0.7153846153846154]}, '125:102:020:011:021:008': {'training': [0.5123960844726878, 0.7500459981600736, 0.7318407109895745, 0.7885819521178637, 0.7591525573973938], 'validate': [0.6537814524977706, 0.6291512915129152, 0.6126714565643371, 0.6948148148148148, 0.6511627906976745], 'test': [0.7243632100663095, 0.5504424778761062, 0.5404483430799221, 0.6562130177514793, 0.5927311598075895]}, '011:102:020:125:021:008': {'training': [0.6651892732455298, 0.6196872125114995, 0.6097189299017948, 0.6631675874769798, 0.6353211009174312], 'validate': [0.710657793422078, 0.4490774907749078, 0.457159976033553, 0.5651851851851852, 0.5054653858893673], 'test': [0.6934634728251763, 0.5014749262536873, 0.0, 0.0, 0.0]}, '021:102:020:125:011:008': {'training': [0.4533602750838735, 0.7894204231830727, 0.7652423577098463, 0.8344383057090239, 0.7983437582591842], 'validate': [0.20800618333525436, 0.9457564575645756, 0.9324227174694465, 0.9607407407407408, 0.9463699379788398], 'test': [0.19508063828326622, 0.968141592920354, 0.9811435523114356, 0.9544378698224852, 0.9676064787042592]}, '008:102:020:125:011:021': {'training': [0.5543762764364838, 0.728886844526219, 0.6875660975978245, 0.838121546961326, 0.7554153871690596], 'validate': [0.9114427580389866, 0.4490774907749078, 0.4605190502484815, 0.6177777777777778, 0.5276811135716546], 'test': [0.6055494816798084, 0.8967551622418879, 0.8726362625139044, 0.9284023668639053, 0.8996559633027523]}}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  036  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  036  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  036  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6727, Acc: 0.6104, Val Loss: 0.6718, Val Acc: 0.5675
Mejor modelo guardado con Val Loss: 0.6718
Epoch 2/100, Loss: 0.6513, Acc: 0.6464, Val Loss: 0.6923, Val Acc: 0.5273
Epoch 3/100, Loss: 0.6390, Acc: 0.6557, Val Loss: 0.6562, Val Acc: 0.6137
Mejor modelo guardado con Val Loss: 0.6562
Epoch 4/100, Loss: 0.6298, Acc: 0.6540, Val Loss: 0.6529, Val Acc: 0.6107
Mejor modelo guardado con Val Loss: 0.6529
Epoch 5/100, Loss: 0.6228, Acc: 0.6584, Val Loss: 0.6654, Val Acc: 0.5904
Epoch 6/100, Loss: 0.6170, Acc: 0.6624, Val Loss: 0.6490, Val Acc: 0.6295
Mejor modelo guardado con Val Loss: 0.6490
Epoch 7/100, Loss: 0.6151, Acc: 0.6649, Val Loss: 0.6204, Val Acc: 0.6690
Mejor modelo guardado con Val Loss: 0.6204
Epoch 8/100, Loss: 0.6100, Acc: 0.6668, Val Loss: 0.6473, Val Acc: 0.6240
Epoch 9/100, Loss: 0.6066, Acc: 0.6679, Val Loss: 0.6321, Val Acc: 0.6354
Epoch 10/100, Loss: 0.6058, Acc: 0.6717, Val Loss: 0.6642, Val Acc: 0.6144
Epoch 11/100, Loss: 0.6060, Acc: 0.6716, Val Loss: 0.6379, Val Acc: 0.6498
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5992, Acc: 0.6785, Val Loss: 0.6257, Val Acc: 0.6491
Epoch 13/100, Loss: 0.5942, Acc: 0.6847, Val Loss: 0.6937, Val Acc: 0.5627
Epoch 14/100, Loss: 0.5945, Acc: 0.6839, Val Loss: 0.6854, Val Acc: 0.5649
Epoch 15/100, Loss: 0.5932, Acc: 0.6847, Val Loss: 0.6414, Val Acc: 0.6247
Epoch 16/100, Loss: 0.5934, Acc: 0.6860, Val Loss: 0.6597, Val Acc: 0.6026
Epoch 17/100, Loss: 0.5937, Acc: 0.6820, Val Loss: 0.6582, Val Acc: 0.5926
Epoch 18/100, Loss: 0.5892, Acc: 0.6870, Val Loss: 0.6695, Val Acc: 0.5886
Epoch 19/100, Loss: 0.5894, Acc: 0.6861, Val Loss: 0.6635, Val Acc: 0.5893
Epoch 20/100, Loss: 0.5879, Acc: 0.6903, Val Loss: 0.6507, Val Acc: 0.6125
Epoch 21/100, Loss: 0.5859, Acc: 0.6883, Val Loss: 0.6309, Val Acc: 0.6354
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5837, Acc: 0.6921, Val Loss: 0.6478, Val Acc: 0.6207
Epoch 23/100, Loss: 0.5853, Acc: 0.6892, Val Loss: 0.6473, Val Acc: 0.6273
Epoch 24/100, Loss: 0.5832, Acc: 0.6914, Val Loss: 0.6640, Val Acc: 0.5967
Epoch 25/100, Loss: 0.5830, Acc: 0.6922, Val Loss: 0.6726, Val Acc: 0.5801
Epoch 26/100, Loss: 0.5826, Acc: 0.6946, Val Loss: 0.6472, Val Acc: 0.6258
Epoch 27/100, Loss: 0.5821, Acc: 0.6918, Val Loss: 0.6821, Val Acc: 0.5771
Epoch 28/100, Loss: 0.5809, Acc: 0.6935, Val Loss: 0.6732, Val Acc: 0.5808
Epoch 29/100, Loss: 0.5796, Acc: 0.6953, Val Loss: 0.6761, Val Acc: 0.5779
Epoch 30/100, Loss: 0.5804, Acc: 0.6962, Val Loss: 0.6520, Val Acc: 0.6133
Epoch 31/100, Loss: 0.5796, Acc: 0.6949, Val Loss: 0.6810, Val Acc: 0.5716
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5778, Acc: 0.6970, Val Loss: 0.6687, Val Acc: 0.5856
Epoch 33/100, Loss: 0.5774, Acc: 0.6964, Val Loss: 0.6544, Val Acc: 0.6081
Epoch 34/100, Loss: 0.5770, Acc: 0.6977, Val Loss: 0.6714, Val Acc: 0.5819
Epoch 35/100, Loss: 0.5772, Acc: 0.6974, Val Loss: 0.6590, Val Acc: 0.6015
Epoch 36/100, Loss: 0.5758, Acc: 0.6973, Val Loss: 0.6504, Val Acc: 0.6125
Epoch 37/100, Loss: 0.5769, Acc: 0.6960, Val Loss: 0.6602, Val Acc: 0.6015
Epoch 38/100, Loss: 0.5762, Acc: 0.6994, Val Loss: 0.6422, Val Acc: 0.6207
Epoch 39/100, Loss: 0.5757, Acc: 0.6994, Val Loss: 0.6560, Val Acc: 0.6077
Epoch 40/100, Loss: 0.5757, Acc: 0.6981, Val Loss: 0.6457, Val Acc: 0.6148
Epoch 41/100, Loss: 0.5757, Acc: 0.6982, Val Loss: 0.6683, Val Acc: 0.5852
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5750, Acc: 0.7005, Val Loss: 0.6493, Val Acc: 0.6173
Epoch 43/100, Loss: 0.5746, Acc: 0.6977, Val Loss: 0.6607, Val Acc: 0.5948
Epoch 44/100, Loss: 0.5745, Acc: 0.6993, Val Loss: 0.6696, Val Acc: 0.5812
Epoch 45/100, Loss: 0.5744, Acc: 0.6987, Val Loss: 0.6614, Val Acc: 0.6044
Epoch 46/100, Loss: 0.5745, Acc: 0.6984, Val Loss: 0.6591, Val Acc: 0.6033
Epoch 47/100, Loss: 0.5738, Acc: 0.6988, Val Loss: 0.6563, Val Acc: 0.6118
Epoch 48/100, Loss: 0.5740, Acc: 0.6984, Val Loss: 0.6626, Val Acc: 0.5934
Epoch 49/100, Loss: 0.5738, Acc: 0.6994, Val Loss: 0.6591, Val Acc: 0.6063
Epoch 50/100, Loss: 0.5733, Acc: 0.7029, Val Loss: 0.6685, Val Acc: 0.5856
Epoch 51/100, Loss: 0.5740, Acc: 0.7004, Val Loss: 0.6635, Val Acc: 0.5967
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5730, Acc: 0.6971, Val Loss: 0.6609, Val Acc: 0.5989
Epoch 53/100, Loss: 0.5729, Acc: 0.6997, Val Loss: 0.6567, Val Acc: 0.6125
Epoch 54/100, Loss: 0.5728, Acc: 0.7007, Val Loss: 0.6626, Val Acc: 0.5948
Epoch 55/100, Loss: 0.5729, Acc: 0.6994, Val Loss: 0.6619, Val Acc: 0.5985
Epoch 56/100, Loss: 0.5730, Acc: 0.7004, Val Loss: 0.6579, Val Acc: 0.6092
Epoch 57/100, Loss: 0.5724, Acc: 0.6994, Val Loss: 0.6741, Val Acc: 0.5775
Epoch 58/100, Loss: 0.5728, Acc: 0.6999, Val Loss: 0.6687, Val Acc: 0.5863
Epoch 59/100, Loss: 0.5726, Acc: 0.7002, Val Loss: 0.6629, Val Acc: 0.5941
Epoch 60/100, Loss: 0.5728, Acc: 0.7008, Val Loss: 0.6643, Val Acc: 0.5941
Epoch 61/100, Loss: 0.5724, Acc: 0.7013, Val Loss: 0.6660, Val Acc: 0.5919
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5722, Acc: 0.6996, Val Loss: 0.6620, Val Acc: 0.5970
Epoch 63/100, Loss: 0.5721, Acc: 0.7001, Val Loss: 0.6652, Val Acc: 0.5952
Epoch 64/100, Loss: 0.5722, Acc: 0.7008, Val Loss: 0.6658, Val Acc: 0.5923
Epoch 65/100, Loss: 0.5722, Acc: 0.7001, Val Loss: 0.6631, Val Acc: 0.5963
Epoch 66/100, Loss: 0.5720, Acc: 0.6995, Val Loss: 0.6594, Val Acc: 0.6055
Epoch 67/100, Loss: 0.5719, Acc: 0.7010, Val Loss: 0.6604, Val Acc: 0.6018
Epoch 68/100, Loss: 0.5720, Acc: 0.7001, Val Loss: 0.6612, Val Acc: 0.5993
Epoch 69/100, Loss: 0.5717, Acc: 0.6987, Val Loss: 0.6670, Val Acc: 0.5900
Epoch 70/100, Loss: 0.5718, Acc: 0.7012, Val Loss: 0.6582, Val Acc: 0.6063
Epoch 71/100, Loss: 0.5718, Acc: 0.7006, Val Loss: 0.6635, Val Acc: 0.5941
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5716, Acc: 0.7001, Val Loss: 0.6577, Val Acc: 0.6107
Epoch 73/100, Loss: 0.5717, Acc: 0.7008, Val Loss: 0.6598, Val Acc: 0.6041
Epoch 74/100, Loss: 0.5716, Acc: 0.6997, Val Loss: 0.6590, Val Acc: 0.6059
Epoch 75/100, Loss: 0.5717, Acc: 0.7009, Val Loss: 0.6603, Val Acc: 0.6026
Epoch 76/100, Loss: 0.5717, Acc: 0.6995, Val Loss: 0.6608, Val Acc: 0.5996
Epoch 77/100, Loss: 0.5716, Acc: 0.7005, Val Loss: 0.6588, Val Acc: 0.6066
Epoch 78/100, Loss: 0.5715, Acc: 0.7006, Val Loss: 0.6574, Val Acc: 0.6122
Epoch 79/100, Loss: 0.5716, Acc: 0.7003, Val Loss: 0.6639, Val Acc: 0.5948
Epoch 80/100, Loss: 0.5716, Acc: 0.7000, Val Loss: 0.6645, Val Acc: 0.5934
Epoch 81/100, Loss: 0.5714, Acc: 0.7010, Val Loss: 0.6660, Val Acc: 0.5919
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5716, Acc: 0.6999, Val Loss: 0.6595, Val Acc: 0.6044
Epoch 83/100, Loss: 0.5714, Acc: 0.7001, Val Loss: 0.6582, Val Acc: 0.6085
Epoch 84/100, Loss: 0.5714, Acc: 0.6996, Val Loss: 0.6575, Val Acc: 0.6114
Epoch 85/100, Loss: 0.5714, Acc: 0.7005, Val Loss: 0.6613, Val Acc: 0.5989
Epoch 86/100, Loss: 0.5714, Acc: 0.7005, Val Loss: 0.6602, Val Acc: 0.6041
Epoch 87/100, Loss: 0.5713, Acc: 0.7014, Val Loss: 0.6633, Val Acc: 0.5956
Epoch 88/100, Loss: 0.5713, Acc: 0.7003, Val Loss: 0.6577, Val Acc: 0.6100
Epoch 89/100, Loss: 0.5714, Acc: 0.7005, Val Loss: 0.6616, Val Acc: 0.5982
Epoch 90/100, Loss: 0.5713, Acc: 0.7011, Val Loss: 0.6635, Val Acc: 0.5956
Epoch 91/100, Loss: 0.5713, Acc: 0.7008, Val Loss: 0.6671, Val Acc: 0.5915
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5713, Acc: 0.7012, Val Loss: 0.6654, Val Acc: 0.5926
Epoch 93/100, Loss: 0.5713, Acc: 0.7011, Val Loss: 0.6627, Val Acc: 0.5982
Epoch 94/100, Loss: 0.5712, Acc: 0.7001, Val Loss: 0.6597, Val Acc: 0.6041
Epoch 95/100, Loss: 0.5712, Acc: 0.7002, Val Loss: 0.6606, Val Acc: 0.6007
Epoch 96/100, Loss: 0.5711, Acc: 0.7010, Val Loss: 0.6635, Val Acc: 0.5945
Epoch 97/100, Loss: 0.5713, Acc: 0.6991, Val Loss: 0.6602, Val Acc: 0.6033
Epoch 98/100, Loss: 0.5711, Acc: 0.7012, Val Loss: 0.6567, Val Acc: 0.6122
Epoch 99/100, Loss: 0.5711, Acc: 0.7003, Val Loss: 0.6624, Val Acc: 0.5963
Epoch 100/100, Loss: 0.5711, Acc: 0.7006, Val Loss: 0.6629, Val Acc: 0.5952

##############################
Resultados para principal:  036  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11 
 {'training': [0.5710983482104655, 0.7006439742410303, 0.6746388443017657, 0.7740331491712708, 0.720926243567753], 'validate': [0.6629360720168712, 0.5952029520295203, 0.5624691358024692, 0.8437037037037037, 0.674962962962963], 'test': [0.7443391214001853, 0.5348082595870206, 0.5359186268277177, 0.49881656804733726, 0.5167024210848912]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  024  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  024  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  024  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6474, Acc: 0.6389, Val Loss: 0.7586, Val Acc: 0.5221
Mejor modelo guardado con Val Loss: 0.7586
Epoch 2/100, Loss: 0.6291, Acc: 0.6666, Val Loss: 0.7179, Val Acc: 0.4823
Mejor modelo guardado con Val Loss: 0.7179
Epoch 3/100, Loss: 0.6189, Acc: 0.6631, Val Loss: 0.7356, Val Acc: 0.4483
Epoch 4/100, Loss: 0.5989, Acc: 0.6833, Val Loss: 0.7529, Val Acc: 0.4664
Epoch 5/100, Loss: 0.5828, Acc: 0.6965, Val Loss: 0.7639, Val Acc: 0.5030
Epoch 6/100, Loss: 0.5817, Acc: 0.6976, Val Loss: 0.7632, Val Acc: 0.5011
Epoch 7/100, Loss: 0.5677, Acc: 0.7083, Val Loss: 0.7586, Val Acc: 0.5140
Epoch 8/100, Loss: 0.5620, Acc: 0.7141, Val Loss: 0.7322, Val Acc: 0.5539
Epoch 9/100, Loss: 0.5711, Acc: 0.7114, Val Loss: 0.6899, Val Acc: 0.5708
Mejor modelo guardado con Val Loss: 0.6899
Epoch 10/100, Loss: 0.5612, Acc: 0.7184, Val Loss: 0.7858, Val Acc: 0.5620
Epoch 11/100, Loss: 0.5608, Acc: 0.7207, Val Loss: 0.7320, Val Acc: 0.5446
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5457, Acc: 0.7327, Val Loss: 0.7279, Val Acc: 0.5325
Epoch 13/100, Loss: 0.5396, Acc: 0.7360, Val Loss: 0.7316, Val Acc: 0.5627
Epoch 14/100, Loss: 0.5396, Acc: 0.7341, Val Loss: 0.7600, Val Acc: 0.5362
Epoch 15/100, Loss: 0.5372, Acc: 0.7369, Val Loss: 0.7415, Val Acc: 0.5539
Epoch 16/100, Loss: 0.5364, Acc: 0.7399, Val Loss: 0.7260, Val Acc: 0.5568
Epoch 17/100, Loss: 0.5338, Acc: 0.7410, Val Loss: 0.7811, Val Acc: 0.5624
Epoch 18/100, Loss: 0.5291, Acc: 0.7437, Val Loss: 0.7604, Val Acc: 0.5406
Epoch 19/100, Loss: 0.5277, Acc: 0.7464, Val Loss: 0.8104, Val Acc: 0.5653
Epoch 20/100, Loss: 0.5316, Acc: 0.7400, Val Loss: 0.7103, Val Acc: 0.5830
Epoch 21/100, Loss: 0.5263, Acc: 0.7481, Val Loss: 0.7062, Val Acc: 0.6004
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5207, Acc: 0.7488, Val Loss: 0.7665, Val Acc: 0.5779
Epoch 23/100, Loss: 0.5185, Acc: 0.7519, Val Loss: 0.7678, Val Acc: 0.5982
Epoch 24/100, Loss: 0.5204, Acc: 0.7500, Val Loss: 0.7422, Val Acc: 0.5878
Epoch 25/100, Loss: 0.5166, Acc: 0.7552, Val Loss: 0.7213, Val Acc: 0.5731
Epoch 26/100, Loss: 0.5158, Acc: 0.7556, Val Loss: 0.7378, Val Acc: 0.5476
Epoch 27/100, Loss: 0.5158, Acc: 0.7551, Val Loss: 0.7391, Val Acc: 0.5834
Epoch 28/100, Loss: 0.5149, Acc: 0.7525, Val Loss: 0.7514, Val Acc: 0.6004
Epoch 29/100, Loss: 0.5129, Acc: 0.7537, Val Loss: 0.7453, Val Acc: 0.5970
Epoch 30/100, Loss: 0.5126, Acc: 0.7553, Val Loss: 0.7718, Val Acc: 0.6044
Epoch 31/100, Loss: 0.5124, Acc: 0.7539, Val Loss: 0.7293, Val Acc: 0.6004
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5075, Acc: 0.7607, Val Loss: 0.7681, Val Acc: 0.5908
Epoch 33/100, Loss: 0.5085, Acc: 0.7563, Val Loss: 0.7534, Val Acc: 0.5863
Epoch 34/100, Loss: 0.5068, Acc: 0.7593, Val Loss: 0.7429, Val Acc: 0.5830
Epoch 35/100, Loss: 0.5059, Acc: 0.7603, Val Loss: 0.7554, Val Acc: 0.5742
Epoch 36/100, Loss: 0.5049, Acc: 0.7595, Val Loss: 0.7449, Val Acc: 0.6059
Epoch 37/100, Loss: 0.5048, Acc: 0.7601, Val Loss: 0.7507, Val Acc: 0.5804
Epoch 38/100, Loss: 0.5044, Acc: 0.7595, Val Loss: 0.7567, Val Acc: 0.5882
Epoch 39/100, Loss: 0.5040, Acc: 0.7599, Val Loss: 0.7445, Val Acc: 0.6048
Epoch 40/100, Loss: 0.5027, Acc: 0.7621, Val Loss: 0.7348, Val Acc: 0.5690
Epoch 41/100, Loss: 0.5040, Acc: 0.7607, Val Loss: 0.7555, Val Acc: 0.5915
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5009, Acc: 0.7628, Val Loss: 0.7514, Val Acc: 0.6018
Epoch 43/100, Loss: 0.5009, Acc: 0.7616, Val Loss: 0.7510, Val Acc: 0.5875
Epoch 44/100, Loss: 0.5010, Acc: 0.7615, Val Loss: 0.7510, Val Acc: 0.5863
Epoch 45/100, Loss: 0.5007, Acc: 0.7616, Val Loss: 0.7526, Val Acc: 0.6007
Epoch 46/100, Loss: 0.5004, Acc: 0.7622, Val Loss: 0.7598, Val Acc: 0.5926
Epoch 47/100, Loss: 0.4998, Acc: 0.7626, Val Loss: 0.7607, Val Acc: 0.6007
Epoch 48/100, Loss: 0.4999, Acc: 0.7624, Val Loss: 0.7486, Val Acc: 0.6000
Epoch 49/100, Loss: 0.4991, Acc: 0.7643, Val Loss: 0.7575, Val Acc: 0.5863
Epoch 50/100, Loss: 0.4990, Acc: 0.7650, Val Loss: 0.7572, Val Acc: 0.5915
Epoch 51/100, Loss: 0.4984, Acc: 0.7636, Val Loss: 0.7566, Val Acc: 0.5882
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4974, Acc: 0.7638, Val Loss: 0.7504, Val Acc: 0.5923
Epoch 53/100, Loss: 0.4973, Acc: 0.7641, Val Loss: 0.7576, Val Acc: 0.5989
Epoch 54/100, Loss: 0.4971, Acc: 0.7648, Val Loss: 0.7678, Val Acc: 0.5911
Epoch 55/100, Loss: 0.4967, Acc: 0.7640, Val Loss: 0.7534, Val Acc: 0.5963
Epoch 56/100, Loss: 0.4969, Acc: 0.7642, Val Loss: 0.7543, Val Acc: 0.5893
Epoch 57/100, Loss: 0.4965, Acc: 0.7632, Val Loss: 0.7516, Val Acc: 0.5893
Epoch 58/100, Loss: 0.4968, Acc: 0.7648, Val Loss: 0.7549, Val Acc: 0.5948
Epoch 59/100, Loss: 0.4963, Acc: 0.7636, Val Loss: 0.7564, Val Acc: 0.5982
Epoch 60/100, Loss: 0.4963, Acc: 0.7646, Val Loss: 0.7555, Val Acc: 0.5900
Epoch 61/100, Loss: 0.4959, Acc: 0.7646, Val Loss: 0.7606, Val Acc: 0.5878
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4956, Acc: 0.7641, Val Loss: 0.7554, Val Acc: 0.5878
Epoch 63/100, Loss: 0.4955, Acc: 0.7661, Val Loss: 0.7535, Val Acc: 0.5923
Epoch 64/100, Loss: 0.4953, Acc: 0.7662, Val Loss: 0.7562, Val Acc: 0.5970
Epoch 65/100, Loss: 0.4955, Acc: 0.7672, Val Loss: 0.7527, Val Acc: 0.5970
Epoch 66/100, Loss: 0.4952, Acc: 0.7656, Val Loss: 0.7549, Val Acc: 0.5930
Epoch 67/100, Loss: 0.4951, Acc: 0.7640, Val Loss: 0.7571, Val Acc: 0.5974
Epoch 68/100, Loss: 0.4952, Acc: 0.7655, Val Loss: 0.7552, Val Acc: 0.5934
Epoch 69/100, Loss: 0.4952, Acc: 0.7632, Val Loss: 0.7548, Val Acc: 0.5889
Epoch 70/100, Loss: 0.4949, Acc: 0.7652, Val Loss: 0.7568, Val Acc: 0.5908
Epoch 71/100, Loss: 0.4949, Acc: 0.7655, Val Loss: 0.7542, Val Acc: 0.5893
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4946, Acc: 0.7666, Val Loss: 0.7595, Val Acc: 0.5963
Epoch 73/100, Loss: 0.4943, Acc: 0.7672, Val Loss: 0.7577, Val Acc: 0.5889
Epoch 74/100, Loss: 0.4943, Acc: 0.7669, Val Loss: 0.7562, Val Acc: 0.5893
Epoch 75/100, Loss: 0.4943, Acc: 0.7654, Val Loss: 0.7578, Val Acc: 0.5889
Epoch 76/100, Loss: 0.4942, Acc: 0.7667, Val Loss: 0.7575, Val Acc: 0.5882
Epoch 77/100, Loss: 0.4941, Acc: 0.7664, Val Loss: 0.7585, Val Acc: 0.5900
Epoch 78/100, Loss: 0.4942, Acc: 0.7655, Val Loss: 0.7574, Val Acc: 0.5886
Epoch 79/100, Loss: 0.4942, Acc: 0.7668, Val Loss: 0.7571, Val Acc: 0.5952
Epoch 80/100, Loss: 0.4939, Acc: 0.7661, Val Loss: 0.7596, Val Acc: 0.5963
Epoch 81/100, Loss: 0.4939, Acc: 0.7673, Val Loss: 0.7568, Val Acc: 0.5919
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4939, Acc: 0.7674, Val Loss: 0.7572, Val Acc: 0.5878
Epoch 83/100, Loss: 0.4939, Acc: 0.7667, Val Loss: 0.7572, Val Acc: 0.5908
Epoch 84/100, Loss: 0.4938, Acc: 0.7670, Val Loss: 0.7558, Val Acc: 0.5889
Epoch 85/100, Loss: 0.4937, Acc: 0.7670, Val Loss: 0.7587, Val Acc: 0.5871
Epoch 86/100, Loss: 0.4937, Acc: 0.7661, Val Loss: 0.7574, Val Acc: 0.5930
Epoch 87/100, Loss: 0.4936, Acc: 0.7678, Val Loss: 0.7592, Val Acc: 0.5893
Epoch 88/100, Loss: 0.4936, Acc: 0.7672, Val Loss: 0.7570, Val Acc: 0.5871
Epoch 89/100, Loss: 0.4935, Acc: 0.7672, Val Loss: 0.7582, Val Acc: 0.5897
Epoch 90/100, Loss: 0.4935, Acc: 0.7670, Val Loss: 0.7568, Val Acc: 0.5934
Epoch 91/100, Loss: 0.4934, Acc: 0.7659, Val Loss: 0.7579, Val Acc: 0.5893
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4934, Acc: 0.7672, Val Loss: 0.7549, Val Acc: 0.5889
Epoch 93/100, Loss: 0.4934, Acc: 0.7665, Val Loss: 0.7568, Val Acc: 0.5963
Epoch 94/100, Loss: 0.4933, Acc: 0.7673, Val Loss: 0.7570, Val Acc: 0.5948
Epoch 95/100, Loss: 0.4932, Acc: 0.7670, Val Loss: 0.7572, Val Acc: 0.5930
Epoch 96/100, Loss: 0.4932, Acc: 0.7662, Val Loss: 0.7558, Val Acc: 0.5882
Epoch 97/100, Loss: 0.4932, Acc: 0.7676, Val Loss: 0.7569, Val Acc: 0.5911
Epoch 98/100, Loss: 0.4932, Acc: 0.7677, Val Loss: 0.7576, Val Acc: 0.5937
Epoch 99/100, Loss: 0.4930, Acc: 0.7660, Val Loss: 0.7539, Val Acc: 0.5897
Epoch 100/100, Loss: 0.4928, Acc: 0.7671, Val Loss: 0.7615, Val Acc: 0.5904

##############################
Resultados para principal:  024  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11 
 {'training': [0.4927973107668711, 0.7670653173873045, 0.783672670321065, 0.7372007366482505, 0.7597267033592712], 'validate': [0.7614949106477028, 0.5904059040590406, 0.581081081081081, 0.6370370370370371, 0.607773851590106], 'test': [0.5874476241615584, 0.7064896755162242, 0.8571428571428571, 0.493491124260355, 0.6263612467142321]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  100  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  100  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  100  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6160, Acc: 0.7132, Val Loss: 0.8377, Val Acc: 0.3605
Mejor modelo guardado con Val Loss: 0.8377
Epoch 2/100, Loss: 0.5391, Acc: 0.7567, Val Loss: 0.9675, Val Acc: 0.3413
Epoch 3/100, Loss: 0.5041, Acc: 0.7751, Val Loss: 0.9741, Val Acc: 0.3745
Epoch 4/100, Loss: 0.4843, Acc: 0.7830, Val Loss: 1.0419, Val Acc: 0.3579
Epoch 5/100, Loss: 0.4817, Acc: 0.7838, Val Loss: 1.0618, Val Acc: 0.3701
Epoch 6/100, Loss: 0.4777, Acc: 0.7806, Val Loss: 1.0567, Val Acc: 0.3779
Epoch 7/100, Loss: 0.4684, Acc: 0.7847, Val Loss: 1.0363, Val Acc: 0.3590
Epoch 8/100, Loss: 0.4623, Acc: 0.7896, Val Loss: 1.0950, Val Acc: 0.3583
Epoch 9/100, Loss: 0.4613, Acc: 0.7888, Val Loss: 1.2317, Val Acc: 0.3572
Epoch 10/100, Loss: 0.4606, Acc: 0.7872, Val Loss: 1.0918, Val Acc: 0.3804
Epoch 11/100, Loss: 0.4703, Acc: 0.7815, Val Loss: 1.1205, Val Acc: 0.3631
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4485, Acc: 0.7957, Val Loss: 1.0982, Val Acc: 0.3720
Epoch 13/100, Loss: 0.4471, Acc: 0.7929, Val Loss: 1.2198, Val Acc: 0.3594
Epoch 14/100, Loss: 0.4527, Acc: 0.7915, Val Loss: 1.2219, Val Acc: 0.3631
Epoch 15/100, Loss: 0.4426, Acc: 0.7978, Val Loss: 1.1832, Val Acc: 0.3882
Epoch 16/100, Loss: 0.4450, Acc: 0.7937, Val Loss: 1.1741, Val Acc: 0.3576
Epoch 17/100, Loss: 0.4400, Acc: 0.7967, Val Loss: 1.1789, Val Acc: 0.3675
Epoch 18/100, Loss: 0.4418, Acc: 0.7954, Val Loss: 1.1941, Val Acc: 0.3646
Epoch 19/100, Loss: 0.4384, Acc: 0.7978, Val Loss: 1.1901, Val Acc: 0.3760
Epoch 20/100, Loss: 0.4362, Acc: 0.7989, Val Loss: 1.2015, Val Acc: 0.3734
Epoch 21/100, Loss: 0.4418, Acc: 0.7970, Val Loss: 1.2520, Val Acc: 0.3672
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4266, Acc: 0.8043, Val Loss: 1.2832, Val Acc: 0.3679
Epoch 23/100, Loss: 0.4288, Acc: 0.8023, Val Loss: 1.1913, Val Acc: 0.3679
Epoch 24/100, Loss: 0.4263, Acc: 0.8027, Val Loss: 1.2046, Val Acc: 0.3661
Epoch 25/100, Loss: 0.4270, Acc: 0.8042, Val Loss: 1.2743, Val Acc: 0.3705
Epoch 26/100, Loss: 0.4233, Acc: 0.8075, Val Loss: 1.1996, Val Acc: 0.3745
Epoch 27/100, Loss: 0.4237, Acc: 0.8057, Val Loss: 1.2350, Val Acc: 0.3723
Epoch 28/100, Loss: 0.4240, Acc: 0.8052, Val Loss: 1.2264, Val Acc: 0.3771
Epoch 29/100, Loss: 0.4204, Acc: 0.8086, Val Loss: 1.2420, Val Acc: 0.3679
Epoch 30/100, Loss: 0.4208, Acc: 0.8045, Val Loss: 1.2101, Val Acc: 0.3790
Epoch 31/100, Loss: 0.4206, Acc: 0.8063, Val Loss: 1.2177, Val Acc: 0.3782
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4163, Acc: 0.8087, Val Loss: 1.2324, Val Acc: 0.3812
Epoch 33/100, Loss: 0.4161, Acc: 0.8104, Val Loss: 1.2062, Val Acc: 0.3819
Epoch 34/100, Loss: 0.4151, Acc: 0.8100, Val Loss: 1.2854, Val Acc: 0.3779
Epoch 35/100, Loss: 0.4149, Acc: 0.8091, Val Loss: 1.2525, Val Acc: 0.3804
Epoch 36/100, Loss: 0.4136, Acc: 0.8101, Val Loss: 1.2486, Val Acc: 0.3756
Epoch 37/100, Loss: 0.4130, Acc: 0.8125, Val Loss: 1.2428, Val Acc: 0.3808
Epoch 38/100, Loss: 0.4122, Acc: 0.8112, Val Loss: 1.2823, Val Acc: 0.3786
Epoch 39/100, Loss: 0.4129, Acc: 0.8129, Val Loss: 1.2199, Val Acc: 0.3819
Epoch 40/100, Loss: 0.4109, Acc: 0.8123, Val Loss: 1.2361, Val Acc: 0.3819
Epoch 41/100, Loss: 0.4095, Acc: 0.8131, Val Loss: 1.2233, Val Acc: 0.3852
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4063, Acc: 0.8160, Val Loss: 1.2577, Val Acc: 0.3845
Epoch 43/100, Loss: 0.4061, Acc: 0.8137, Val Loss: 1.2525, Val Acc: 0.3830
Epoch 44/100, Loss: 0.4050, Acc: 0.8157, Val Loss: 1.2851, Val Acc: 0.3819
Epoch 45/100, Loss: 0.4042, Acc: 0.8178, Val Loss: 1.2970, Val Acc: 0.3823
Epoch 46/100, Loss: 0.4045, Acc: 0.8171, Val Loss: 1.2652, Val Acc: 0.3838
Epoch 47/100, Loss: 0.4037, Acc: 0.8162, Val Loss: 1.2618, Val Acc: 0.3856
Epoch 48/100, Loss: 0.4029, Acc: 0.8170, Val Loss: 1.2574, Val Acc: 0.3871
Epoch 49/100, Loss: 0.4026, Acc: 0.8192, Val Loss: 1.2657, Val Acc: 0.3834
Epoch 50/100, Loss: 0.4027, Acc: 0.8182, Val Loss: 1.2629, Val Acc: 0.3852
Epoch 51/100, Loss: 0.4020, Acc: 0.8159, Val Loss: 1.2626, Val Acc: 0.3863
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4000, Acc: 0.8193, Val Loss: 1.2682, Val Acc: 0.3871
Epoch 53/100, Loss: 0.4005, Acc: 0.8178, Val Loss: 1.2593, Val Acc: 0.3871
Epoch 54/100, Loss: 0.3997, Acc: 0.8196, Val Loss: 1.2742, Val Acc: 0.3882
Epoch 55/100, Loss: 0.3996, Acc: 0.8189, Val Loss: 1.2713, Val Acc: 0.3867
Epoch 56/100, Loss: 0.3994, Acc: 0.8195, Val Loss: 1.2798, Val Acc: 0.3871
Epoch 57/100, Loss: 0.3989, Acc: 0.8190, Val Loss: 1.2749, Val Acc: 0.3875
Epoch 58/100, Loss: 0.3987, Acc: 0.8198, Val Loss: 1.2591, Val Acc: 0.3878
Epoch 59/100, Loss: 0.3983, Acc: 0.8202, Val Loss: 1.2807, Val Acc: 0.3886
Epoch 60/100, Loss: 0.3984, Acc: 0.8214, Val Loss: 1.2776, Val Acc: 0.3878
Epoch 61/100, Loss: 0.3979, Acc: 0.8201, Val Loss: 1.2795, Val Acc: 0.3882
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3973, Acc: 0.8206, Val Loss: 1.2826, Val Acc: 0.3886
Epoch 63/100, Loss: 0.3970, Acc: 0.8201, Val Loss: 1.2643, Val Acc: 0.3886
Epoch 64/100, Loss: 0.3970, Acc: 0.8200, Val Loss: 1.2637, Val Acc: 0.3893
Epoch 65/100, Loss: 0.3969, Acc: 0.8207, Val Loss: 1.2671, Val Acc: 0.3882
Epoch 66/100, Loss: 0.3964, Acc: 0.8201, Val Loss: 1.2636, Val Acc: 0.3875
Epoch 67/100, Loss: 0.3962, Acc: 0.8204, Val Loss: 1.2715, Val Acc: 0.3893
Epoch 68/100, Loss: 0.3958, Acc: 0.8213, Val Loss: 1.2602, Val Acc: 0.3889
Epoch 69/100, Loss: 0.3959, Acc: 0.8205, Val Loss: 1.2677, Val Acc: 0.3897
Epoch 70/100, Loss: 0.3957, Acc: 0.8204, Val Loss: 1.2698, Val Acc: 0.3882
Epoch 71/100, Loss: 0.3956, Acc: 0.8209, Val Loss: 1.2679, Val Acc: 0.3911
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3950, Acc: 0.8213, Val Loss: 1.2771, Val Acc: 0.3882
Epoch 73/100, Loss: 0.3953, Acc: 0.8213, Val Loss: 1.2709, Val Acc: 0.3904
Epoch 74/100, Loss: 0.3950, Acc: 0.8213, Val Loss: 1.2723, Val Acc: 0.3886
Epoch 75/100, Loss: 0.3951, Acc: 0.8215, Val Loss: 1.2709, Val Acc: 0.3893
Epoch 76/100, Loss: 0.3948, Acc: 0.8213, Val Loss: 1.2662, Val Acc: 0.3908
Epoch 77/100, Loss: 0.3948, Acc: 0.8223, Val Loss: 1.2673, Val Acc: 0.3904
Epoch 78/100, Loss: 0.3946, Acc: 0.8204, Val Loss: 1.2672, Val Acc: 0.3889
Epoch 79/100, Loss: 0.3945, Acc: 0.8219, Val Loss: 1.2675, Val Acc: 0.3908
Epoch 80/100, Loss: 0.3945, Acc: 0.8215, Val Loss: 1.2661, Val Acc: 0.3904
Epoch 81/100, Loss: 0.3943, Acc: 0.8218, Val Loss: 1.2694, Val Acc: 0.3889
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3944, Acc: 0.8216, Val Loss: 1.2760, Val Acc: 0.3889
Epoch 83/100, Loss: 0.3943, Acc: 0.8227, Val Loss: 1.2683, Val Acc: 0.3908
Epoch 84/100, Loss: 0.3942, Acc: 0.8220, Val Loss: 1.2675, Val Acc: 0.3897
Epoch 85/100, Loss: 0.3942, Acc: 0.8225, Val Loss: 1.2776, Val Acc: 0.3889
Epoch 86/100, Loss: 0.3941, Acc: 0.8218, Val Loss: 1.2724, Val Acc: 0.3897
Epoch 87/100, Loss: 0.3940, Acc: 0.8213, Val Loss: 1.2726, Val Acc: 0.3900
Epoch 88/100, Loss: 0.3940, Acc: 0.8220, Val Loss: 1.2701, Val Acc: 0.3893
Epoch 89/100, Loss: 0.3938, Acc: 0.8209, Val Loss: 1.2747, Val Acc: 0.3904
Epoch 90/100, Loss: 0.3937, Acc: 0.8222, Val Loss: 1.2768, Val Acc: 0.3889
Epoch 91/100, Loss: 0.3935, Acc: 0.8215, Val Loss: 1.2726, Val Acc: 0.3915
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3935, Acc: 0.8227, Val Loss: 1.2757, Val Acc: 0.3893
Epoch 93/100, Loss: 0.3934, Acc: 0.8224, Val Loss: 1.2724, Val Acc: 0.3904
Epoch 94/100, Loss: 0.3933, Acc: 0.8218, Val Loss: 1.2692, Val Acc: 0.3908
Epoch 95/100, Loss: 0.3932, Acc: 0.8218, Val Loss: 1.2685, Val Acc: 0.3904
Epoch 96/100, Loss: 0.3931, Acc: 0.8225, Val Loss: 1.2721, Val Acc: 0.3893
Epoch 97/100, Loss: 0.3932, Acc: 0.8228, Val Loss: 1.2672, Val Acc: 0.3911
Epoch 98/100, Loss: 0.3929, Acc: 0.8231, Val Loss: 1.2726, Val Acc: 0.3900
Epoch 99/100, Loss: 0.3927, Acc: 0.8236, Val Loss: 1.2696, Val Acc: 0.3900
Epoch 100/100, Loss: 0.3929, Acc: 0.8222, Val Loss: 1.2720, Val Acc: 0.3893

##############################
Resultados para principal:  100  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11 
 {'training': [0.3928714917467182, 0.8221711131554738, 0.8570553400040841, 0.7729281767955801, 0.812820761111649], 'validate': [1.2720300958946693, 0.3892988929889299, 0.2849083215796897, 0.14962962962962964, 0.19621175327829043], 'test': [0.5349478440464668, 0.8333333333333334, 0.8688524590163934, 0.7840236686390533, 0.8242612752721618]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  090  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  090  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  090  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6870, Acc: 0.5562, Val Loss: 0.7050, Val Acc: 0.3930
Mejor modelo guardado con Val Loss: 0.7050
Epoch 2/100, Loss: 0.6780, Acc: 0.5905, Val Loss: 0.7165, Val Acc: 0.3956
Epoch 3/100, Loss: 0.6718, Acc: 0.6007, Val Loss: 0.7203, Val Acc: 0.3679
Epoch 4/100, Loss: 0.6633, Acc: 0.6100, Val Loss: 0.7212, Val Acc: 0.4125
Epoch 5/100, Loss: 0.6528, Acc: 0.6278, Val Loss: 0.7560, Val Acc: 0.3638
Epoch 6/100, Loss: 0.6480, Acc: 0.6319, Val Loss: 0.7434, Val Acc: 0.4007
Epoch 7/100, Loss: 0.6423, Acc: 0.6339, Val Loss: 0.7768, Val Acc: 0.3734
Epoch 8/100, Loss: 0.6373, Acc: 0.6351, Val Loss: 0.7772, Val Acc: 0.3716
Epoch 9/100, Loss: 0.6356, Acc: 0.6319, Val Loss: 0.7969, Val Acc: 0.3664
Epoch 10/100, Loss: 0.6304, Acc: 0.6409, Val Loss: 0.7931, Val Acc: 0.3823
Epoch 11/100, Loss: 0.6290, Acc: 0.6398, Val Loss: 0.7954, Val Acc: 0.3690
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6287, Acc: 0.6393, Val Loss: 0.8025, Val Acc: 0.3697
Epoch 13/100, Loss: 0.6248, Acc: 0.6467, Val Loss: 0.7973, Val Acc: 0.3668
Epoch 14/100, Loss: 0.6225, Acc: 0.6478, Val Loss: 0.8341, Val Acc: 0.3454
Epoch 15/100, Loss: 0.6211, Acc: 0.6501, Val Loss: 0.7983, Val Acc: 0.3886
Epoch 16/100, Loss: 0.6220, Acc: 0.6481, Val Loss: 0.7760, Val Acc: 0.4122
Epoch 17/100, Loss: 0.6225, Acc: 0.6485, Val Loss: 0.8111, Val Acc: 0.3808
Epoch 18/100, Loss: 0.6202, Acc: 0.6523, Val Loss: 0.8055, Val Acc: 0.3937
Epoch 19/100, Loss: 0.6191, Acc: 0.6489, Val Loss: 0.8012, Val Acc: 0.3996
Epoch 20/100, Loss: 0.6192, Acc: 0.6499, Val Loss: 0.8401, Val Acc: 0.3624
Epoch 21/100, Loss: 0.6204, Acc: 0.6511, Val Loss: 0.8209, Val Acc: 0.3849
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6167, Acc: 0.6517, Val Loss: 0.8242, Val Acc: 0.3775
Epoch 23/100, Loss: 0.6167, Acc: 0.6530, Val Loss: 0.8172, Val Acc: 0.3863
Epoch 24/100, Loss: 0.6166, Acc: 0.6538, Val Loss: 0.8254, Val Acc: 0.3804
Epoch 25/100, Loss: 0.6161, Acc: 0.6541, Val Loss: 0.8227, Val Acc: 0.3900
Epoch 26/100, Loss: 0.6159, Acc: 0.6529, Val Loss: 0.8345, Val Acc: 0.3705
Epoch 27/100, Loss: 0.6153, Acc: 0.6548, Val Loss: 0.8373, Val Acc: 0.3720
Epoch 28/100, Loss: 0.6147, Acc: 0.6542, Val Loss: 0.8133, Val Acc: 0.3956
Epoch 29/100, Loss: 0.6158, Acc: 0.6539, Val Loss: 0.8219, Val Acc: 0.3834
Epoch 30/100, Loss: 0.6151, Acc: 0.6551, Val Loss: 0.8492, Val Acc: 0.3653
Epoch 31/100, Loss: 0.6142, Acc: 0.6558, Val Loss: 0.8346, Val Acc: 0.3801
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6136, Acc: 0.6563, Val Loss: 0.8418, Val Acc: 0.3727
Epoch 33/100, Loss: 0.6135, Acc: 0.6574, Val Loss: 0.8481, Val Acc: 0.3705
Epoch 34/100, Loss: 0.6130, Acc: 0.6583, Val Loss: 0.8660, Val Acc: 0.3627
Epoch 35/100, Loss: 0.6142, Acc: 0.6576, Val Loss: 0.8346, Val Acc: 0.3852
Epoch 36/100, Loss: 0.6137, Acc: 0.6575, Val Loss: 0.8303, Val Acc: 0.3871
Epoch 37/100, Loss: 0.6129, Acc: 0.6592, Val Loss: 0.8200, Val Acc: 0.3945
Epoch 38/100, Loss: 0.6138, Acc: 0.6575, Val Loss: 0.8589, Val Acc: 0.3661
Epoch 39/100, Loss: 0.6131, Acc: 0.6547, Val Loss: 0.8385, Val Acc: 0.3827
Epoch 40/100, Loss: 0.6143, Acc: 0.6565, Val Loss: 0.8485, Val Acc: 0.3720
Epoch 41/100, Loss: 0.6134, Acc: 0.6552, Val Loss: 0.8374, Val Acc: 0.3808
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6125, Acc: 0.6557, Val Loss: 0.8520, Val Acc: 0.3720
Epoch 43/100, Loss: 0.6121, Acc: 0.6564, Val Loss: 0.8503, Val Acc: 0.3716
Epoch 44/100, Loss: 0.6124, Acc: 0.6558, Val Loss: 0.8474, Val Acc: 0.3720
Epoch 45/100, Loss: 0.6123, Acc: 0.6572, Val Loss: 0.8521, Val Acc: 0.3672
Epoch 46/100, Loss: 0.6129, Acc: 0.6594, Val Loss: 0.8458, Val Acc: 0.3775
Epoch 47/100, Loss: 0.6120, Acc: 0.6576, Val Loss: 0.8598, Val Acc: 0.3653
Epoch 48/100, Loss: 0.6121, Acc: 0.6575, Val Loss: 0.8444, Val Acc: 0.3764
Epoch 49/100, Loss: 0.6121, Acc: 0.6579, Val Loss: 0.8573, Val Acc: 0.3668
Epoch 50/100, Loss: 0.6120, Acc: 0.6565, Val Loss: 0.8452, Val Acc: 0.3745
Epoch 51/100, Loss: 0.6117, Acc: 0.6587, Val Loss: 0.8547, Val Acc: 0.3679
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6116, Acc: 0.6599, Val Loss: 0.8542, Val Acc: 0.3675
Epoch 53/100, Loss: 0.6112, Acc: 0.6570, Val Loss: 0.8391, Val Acc: 0.3827
Epoch 54/100, Loss: 0.6117, Acc: 0.6580, Val Loss: 0.8448, Val Acc: 0.3779
Epoch 55/100, Loss: 0.6116, Acc: 0.6575, Val Loss: 0.8465, Val Acc: 0.3734
Epoch 56/100, Loss: 0.6117, Acc: 0.6589, Val Loss: 0.8529, Val Acc: 0.3723
Epoch 57/100, Loss: 0.6116, Acc: 0.6573, Val Loss: 0.8491, Val Acc: 0.3716
Epoch 58/100, Loss: 0.6116, Acc: 0.6595, Val Loss: 0.8510, Val Acc: 0.3716
Epoch 59/100, Loss: 0.6115, Acc: 0.6570, Val Loss: 0.8477, Val Acc: 0.3738
Epoch 60/100, Loss: 0.6116, Acc: 0.6576, Val Loss: 0.8485, Val Acc: 0.3734
Epoch 61/100, Loss: 0.6116, Acc: 0.6588, Val Loss: 0.8488, Val Acc: 0.3720
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6114, Acc: 0.6577, Val Loss: 0.8455, Val Acc: 0.3779
Epoch 63/100, Loss: 0.6113, Acc: 0.6576, Val Loss: 0.8490, Val Acc: 0.3727
Epoch 64/100, Loss: 0.6113, Acc: 0.6580, Val Loss: 0.8478, Val Acc: 0.3720
Epoch 65/100, Loss: 0.6113, Acc: 0.6576, Val Loss: 0.8454, Val Acc: 0.3793
Epoch 66/100, Loss: 0.6115, Acc: 0.6573, Val Loss: 0.8486, Val Acc: 0.3731
Epoch 67/100, Loss: 0.6113, Acc: 0.6585, Val Loss: 0.8505, Val Acc: 0.3720
Epoch 68/100, Loss: 0.6113, Acc: 0.6578, Val Loss: 0.8493, Val Acc: 0.3723
Epoch 69/100, Loss: 0.6113, Acc: 0.6575, Val Loss: 0.8495, Val Acc: 0.3734
Epoch 70/100, Loss: 0.6112, Acc: 0.6585, Val Loss: 0.8516, Val Acc: 0.3720
Epoch 71/100, Loss: 0.6113, Acc: 0.6579, Val Loss: 0.8501, Val Acc: 0.3712
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6113, Acc: 0.6586, Val Loss: 0.8509, Val Acc: 0.3708
Epoch 73/100, Loss: 0.6112, Acc: 0.6588, Val Loss: 0.8517, Val Acc: 0.3712
Epoch 74/100, Loss: 0.6112, Acc: 0.6580, Val Loss: 0.8483, Val Acc: 0.3720
Epoch 75/100, Loss: 0.6112, Acc: 0.6578, Val Loss: 0.8510, Val Acc: 0.3708
Epoch 76/100, Loss: 0.6112, Acc: 0.6583, Val Loss: 0.8488, Val Acc: 0.3731
Epoch 77/100, Loss: 0.6112, Acc: 0.6583, Val Loss: 0.8502, Val Acc: 0.3720
Epoch 78/100, Loss: 0.6111, Acc: 0.6580, Val Loss: 0.8525, Val Acc: 0.3705
Epoch 79/100, Loss: 0.6111, Acc: 0.6578, Val Loss: 0.8477, Val Acc: 0.3734
Epoch 80/100, Loss: 0.6111, Acc: 0.6583, Val Loss: 0.8520, Val Acc: 0.3712
Epoch 81/100, Loss: 0.6111, Acc: 0.6578, Val Loss: 0.8509, Val Acc: 0.3720
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6111, Acc: 0.6574, Val Loss: 0.8479, Val Acc: 0.3742
Epoch 83/100, Loss: 0.6111, Acc: 0.6578, Val Loss: 0.8502, Val Acc: 0.3720
Epoch 84/100, Loss: 0.6111, Acc: 0.6583, Val Loss: 0.8526, Val Acc: 0.3708
Epoch 85/100, Loss: 0.6111, Acc: 0.6587, Val Loss: 0.8522, Val Acc: 0.3720
Epoch 86/100, Loss: 0.6111, Acc: 0.6579, Val Loss: 0.8511, Val Acc: 0.3720
Epoch 87/100, Loss: 0.6111, Acc: 0.6580, Val Loss: 0.8497, Val Acc: 0.3731
Epoch 88/100, Loss: 0.6111, Acc: 0.6584, Val Loss: 0.8484, Val Acc: 0.3727
Epoch 89/100, Loss: 0.6111, Acc: 0.6581, Val Loss: 0.8512, Val Acc: 0.3720
Epoch 90/100, Loss: 0.6111, Acc: 0.6585, Val Loss: 0.8495, Val Acc: 0.3727
Epoch 91/100, Loss: 0.6111, Acc: 0.6576, Val Loss: 0.8474, Val Acc: 0.3771
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6111, Acc: 0.6580, Val Loss: 0.8513, Val Acc: 0.3712
Epoch 93/100, Loss: 0.6110, Acc: 0.6584, Val Loss: 0.8516, Val Acc: 0.3723
Epoch 94/100, Loss: 0.6110, Acc: 0.6580, Val Loss: 0.8486, Val Acc: 0.3720
Epoch 95/100, Loss: 0.6110, Acc: 0.6577, Val Loss: 0.8503, Val Acc: 0.3727
Epoch 96/100, Loss: 0.6110, Acc: 0.6583, Val Loss: 0.8496, Val Acc: 0.3738
Epoch 97/100, Loss: 0.6110, Acc: 0.6574, Val Loss: 0.8500, Val Acc: 0.3734
Epoch 98/100, Loss: 0.6110, Acc: 0.6584, Val Loss: 0.8510, Val Acc: 0.3723
Epoch 99/100, Loss: 0.6110, Acc: 0.6584, Val Loss: 0.8521, Val Acc: 0.3720
Epoch 100/100, Loss: 0.6110, Acc: 0.6573, Val Loss: 0.8520, Val Acc: 0.3720

##############################
Resultados para principal:  090  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11 
 {'training': [0.610997293811384, 0.6573137074517019, 0.6132890365448505, 0.8499079189686924, 0.7124662292551138], 'validate': [0.8519604344700658, 0.3719557195571956, 0.41586998087954113, 0.6444444444444445, 0.505520046484602], 'test': [0.7049119933596197, 0.3831858407079646, 0.41293964394268345, 0.5627218934911242, 0.4763335837716003]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  091  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  091  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  091  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6689, Acc: 0.6147, Val Loss: 0.6871, Val Acc: 0.5498
Mejor modelo guardado con Val Loss: 0.6871
Epoch 2/100, Loss: 0.6448, Acc: 0.6551, Val Loss: 0.6691, Val Acc: 0.6030
Mejor modelo guardado con Val Loss: 0.6691
Epoch 3/100, Loss: 0.6285, Acc: 0.6642, Val Loss: 0.6632, Val Acc: 0.6177
Mejor modelo guardado con Val Loss: 0.6632
Epoch 4/100, Loss: 0.6196, Acc: 0.6738, Val Loss: 0.6668, Val Acc: 0.6033
Epoch 5/100, Loss: 0.6136, Acc: 0.6794, Val Loss: 0.6467, Val Acc: 0.6310
Mejor modelo guardado con Val Loss: 0.6467
Epoch 6/100, Loss: 0.6026, Acc: 0.6923, Val Loss: 0.6427, Val Acc: 0.6373
Mejor modelo guardado con Val Loss: 0.6427
Epoch 7/100, Loss: 0.5932, Acc: 0.7020, Val Loss: 0.6556, Val Acc: 0.6044
Epoch 8/100, Loss: 0.5881, Acc: 0.7046, Val Loss: 0.6461, Val Acc: 0.6314
Epoch 9/100, Loss: 0.5799, Acc: 0.7170, Val Loss: 0.6527, Val Acc: 0.6033
Epoch 10/100, Loss: 0.5869, Acc: 0.7034, Val Loss: 0.6420, Val Acc: 0.6185
Mejor modelo guardado con Val Loss: 0.6420
Epoch 11/100, Loss: 0.5789, Acc: 0.7202, Val Loss: 0.6427, Val Acc: 0.6354
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5712, Acc: 0.7234, Val Loss: 0.6374, Val Acc: 0.6299
Mejor modelo guardado con Val Loss: 0.6374
Epoch 13/100, Loss: 0.5670, Acc: 0.7244, Val Loss: 0.6745, Val Acc: 0.5897
Epoch 14/100, Loss: 0.5640, Acc: 0.7297, Val Loss: 0.6349, Val Acc: 0.6255
Mejor modelo guardado con Val Loss: 0.6349
Epoch 15/100, Loss: 0.5615, Acc: 0.7329, Val Loss: 0.6293, Val Acc: 0.6395
Mejor modelo guardado con Val Loss: 0.6293
Epoch 16/100, Loss: 0.5608, Acc: 0.7350, Val Loss: 0.6313, Val Acc: 0.6391
Epoch 17/100, Loss: 0.5649, Acc: 0.7292, Val Loss: 0.6435, Val Acc: 0.6125
Epoch 18/100, Loss: 0.5584, Acc: 0.7352, Val Loss: 0.6364, Val Acc: 0.6295
Epoch 19/100, Loss: 0.5592, Acc: 0.7312, Val Loss: 0.6273, Val Acc: 0.6520
Mejor modelo guardado con Val Loss: 0.6273
Epoch 20/100, Loss: 0.5569, Acc: 0.7390, Val Loss: 0.6238, Val Acc: 0.6664
Mejor modelo guardado con Val Loss: 0.6238
Epoch 21/100, Loss: 0.5546, Acc: 0.7405, Val Loss: 0.6221, Val Acc: 0.6620
Mejor modelo guardado con Val Loss: 0.6221
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5507, Acc: 0.7407, Val Loss: 0.6208, Val Acc: 0.6590
Mejor modelo guardado con Val Loss: 0.6208
Epoch 23/100, Loss: 0.5503, Acc: 0.7431, Val Loss: 0.6261, Val Acc: 0.6413
Epoch 24/100, Loss: 0.5493, Acc: 0.7430, Val Loss: 0.6237, Val Acc: 0.6461
Epoch 25/100, Loss: 0.5508, Acc: 0.7389, Val Loss: 0.6253, Val Acc: 0.6627
Epoch 26/100, Loss: 0.5481, Acc: 0.7436, Val Loss: 0.6230, Val Acc: 0.6476
Epoch 27/100, Loss: 0.5503, Acc: 0.7397, Val Loss: 0.6228, Val Acc: 0.6458
Epoch 28/100, Loss: 0.5483, Acc: 0.7431, Val Loss: 0.6237, Val Acc: 0.6624
Epoch 29/100, Loss: 0.5464, Acc: 0.7446, Val Loss: 0.6256, Val Acc: 0.6683
Epoch 30/100, Loss: 0.5473, Acc: 0.7414, Val Loss: 0.6231, Val Acc: 0.6502
Epoch 31/100, Loss: 0.5441, Acc: 0.7466, Val Loss: 0.6256, Val Acc: 0.6380
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5439, Acc: 0.7460, Val Loss: 0.6239, Val Acc: 0.6590
Epoch 33/100, Loss: 0.5437, Acc: 0.7465, Val Loss: 0.6248, Val Acc: 0.6443
Epoch 34/100, Loss: 0.5422, Acc: 0.7498, Val Loss: 0.6230, Val Acc: 0.6446
Epoch 35/100, Loss: 0.5421, Acc: 0.7483, Val Loss: 0.6225, Val Acc: 0.6502
Epoch 36/100, Loss: 0.5421, Acc: 0.7480, Val Loss: 0.6274, Val Acc: 0.6395
Epoch 37/100, Loss: 0.5425, Acc: 0.7468, Val Loss: 0.6244, Val Acc: 0.6424
Epoch 38/100, Loss: 0.5420, Acc: 0.7483, Val Loss: 0.6225, Val Acc: 0.6517
Epoch 39/100, Loss: 0.5413, Acc: 0.7465, Val Loss: 0.6220, Val Acc: 0.6524
Epoch 40/100, Loss: 0.5416, Acc: 0.7485, Val Loss: 0.6241, Val Acc: 0.6605
Epoch 41/100, Loss: 0.5406, Acc: 0.7494, Val Loss: 0.6233, Val Acc: 0.6476
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5399, Acc: 0.7515, Val Loss: 0.6237, Val Acc: 0.6476
Epoch 43/100, Loss: 0.5394, Acc: 0.7504, Val Loss: 0.6232, Val Acc: 0.6494
Epoch 44/100, Loss: 0.5402, Acc: 0.7499, Val Loss: 0.6246, Val Acc: 0.6483
Epoch 45/100, Loss: 0.5392, Acc: 0.7511, Val Loss: 0.6227, Val Acc: 0.6494
Epoch 46/100, Loss: 0.5398, Acc: 0.7491, Val Loss: 0.6254, Val Acc: 0.6465
Epoch 47/100, Loss: 0.5396, Acc: 0.7504, Val Loss: 0.6232, Val Acc: 0.6483
Epoch 48/100, Loss: 0.5391, Acc: 0.7504, Val Loss: 0.6257, Val Acc: 0.6465
Epoch 49/100, Loss: 0.5386, Acc: 0.7517, Val Loss: 0.6231, Val Acc: 0.6535
Epoch 50/100, Loss: 0.5387, Acc: 0.7517, Val Loss: 0.6232, Val Acc: 0.6498
Epoch 51/100, Loss: 0.5388, Acc: 0.7511, Val Loss: 0.6244, Val Acc: 0.6546
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5384, Acc: 0.7511, Val Loss: 0.6242, Val Acc: 0.6506
Epoch 53/100, Loss: 0.5378, Acc: 0.7511, Val Loss: 0.6241, Val Acc: 0.6494
Epoch 54/100, Loss: 0.5377, Acc: 0.7519, Val Loss: 0.6237, Val Acc: 0.6487
Epoch 55/100, Loss: 0.5376, Acc: 0.7517, Val Loss: 0.6239, Val Acc: 0.6476
Epoch 56/100, Loss: 0.5375, Acc: 0.7515, Val Loss: 0.6240, Val Acc: 0.6506
Epoch 57/100, Loss: 0.5373, Acc: 0.7511, Val Loss: 0.6233, Val Acc: 0.6524
Epoch 58/100, Loss: 0.5373, Acc: 0.7513, Val Loss: 0.6237, Val Acc: 0.6498
Epoch 59/100, Loss: 0.5374, Acc: 0.7531, Val Loss: 0.6243, Val Acc: 0.6557
Epoch 60/100, Loss: 0.5372, Acc: 0.7515, Val Loss: 0.6240, Val Acc: 0.6498
Epoch 61/100, Loss: 0.5371, Acc: 0.7523, Val Loss: 0.6241, Val Acc: 0.6498
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5367, Acc: 0.7526, Val Loss: 0.6240, Val Acc: 0.6494
Epoch 63/100, Loss: 0.5366, Acc: 0.7526, Val Loss: 0.6241, Val Acc: 0.6480
Epoch 64/100, Loss: 0.5364, Acc: 0.7534, Val Loss: 0.6241, Val Acc: 0.6502
Epoch 65/100, Loss: 0.5365, Acc: 0.7529, Val Loss: 0.6241, Val Acc: 0.6483
Epoch 66/100, Loss: 0.5365, Acc: 0.7528, Val Loss: 0.6244, Val Acc: 0.6487
Epoch 67/100, Loss: 0.5364, Acc: 0.7531, Val Loss: 0.6242, Val Acc: 0.6472
Epoch 68/100, Loss: 0.5362, Acc: 0.7531, Val Loss: 0.6242, Val Acc: 0.6498
Epoch 69/100, Loss: 0.5363, Acc: 0.7527, Val Loss: 0.6242, Val Acc: 0.6513
Epoch 70/100, Loss: 0.5362, Acc: 0.7524, Val Loss: 0.6244, Val Acc: 0.6469
Epoch 71/100, Loss: 0.5362, Acc: 0.7526, Val Loss: 0.6242, Val Acc: 0.6491
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5360, Acc: 0.7526, Val Loss: 0.6244, Val Acc: 0.6480
Epoch 73/100, Loss: 0.5360, Acc: 0.7527, Val Loss: 0.6249, Val Acc: 0.6469
Epoch 74/100, Loss: 0.5358, Acc: 0.7535, Val Loss: 0.6244, Val Acc: 0.6491
Epoch 75/100, Loss: 0.5361, Acc: 0.7514, Val Loss: 0.6244, Val Acc: 0.6472
Epoch 76/100, Loss: 0.5360, Acc: 0.7526, Val Loss: 0.6245, Val Acc: 0.6487
Epoch 77/100, Loss: 0.5359, Acc: 0.7536, Val Loss: 0.6244, Val Acc: 0.6476
Epoch 78/100, Loss: 0.5358, Acc: 0.7534, Val Loss: 0.6247, Val Acc: 0.6480
Epoch 79/100, Loss: 0.5359, Acc: 0.7526, Val Loss: 0.6245, Val Acc: 0.6498
Epoch 80/100, Loss: 0.5358, Acc: 0.7533, Val Loss: 0.6244, Val Acc: 0.6494
Epoch 81/100, Loss: 0.5358, Acc: 0.7531, Val Loss: 0.6243, Val Acc: 0.6465
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5357, Acc: 0.7531, Val Loss: 0.6245, Val Acc: 0.6483
Epoch 83/100, Loss: 0.5357, Acc: 0.7524, Val Loss: 0.6246, Val Acc: 0.6480
Epoch 84/100, Loss: 0.5357, Acc: 0.7521, Val Loss: 0.6245, Val Acc: 0.6487
Epoch 85/100, Loss: 0.5356, Acc: 0.7526, Val Loss: 0.6247, Val Acc: 0.6491
Epoch 86/100, Loss: 0.5356, Acc: 0.7532, Val Loss: 0.6246, Val Acc: 0.6476
Epoch 87/100, Loss: 0.5356, Acc: 0.7525, Val Loss: 0.6248, Val Acc: 0.6487
Epoch 88/100, Loss: 0.5356, Acc: 0.7528, Val Loss: 0.6248, Val Acc: 0.6483
Epoch 89/100, Loss: 0.5351, Acc: 0.7524, Val Loss: 0.6249, Val Acc: 0.6498
Epoch 90/100, Loss: 0.5344, Acc: 0.7541, Val Loss: 0.6251, Val Acc: 0.6491
Epoch 91/100, Loss: 0.5342, Acc: 0.7531, Val Loss: 0.6254, Val Acc: 0.6465
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5342, Acc: 0.7543, Val Loss: 0.6255, Val Acc: 0.6476
Epoch 93/100, Loss: 0.5341, Acc: 0.7535, Val Loss: 0.6255, Val Acc: 0.6480
Epoch 94/100, Loss: 0.5340, Acc: 0.7531, Val Loss: 0.6255, Val Acc: 0.6483
Epoch 95/100, Loss: 0.5340, Acc: 0.7539, Val Loss: 0.6256, Val Acc: 0.6472
Epoch 96/100, Loss: 0.5339, Acc: 0.7524, Val Loss: 0.6255, Val Acc: 0.6487
Epoch 97/100, Loss: 0.5339, Acc: 0.7540, Val Loss: 0.6254, Val Acc: 0.6480
Epoch 98/100, Loss: 0.5335, Acc: 0.7535, Val Loss: 0.6265, Val Acc: 0.6454
Epoch 99/100, Loss: 0.5335, Acc: 0.7532, Val Loss: 0.6265, Val Acc: 0.6443
Epoch 100/100, Loss: 0.5333, Acc: 0.7533, Val Loss: 0.6275, Val Acc: 0.6432

##############################
Resultados para principal:  091  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11 
 {'training': [0.533343970194363, 0.7532658693652254, 0.7461483339304908, 0.7670349907918969, 0.7564475118053033], 'validate': [0.6275119615155597, 0.6431734317343173, 0.6456273764258555, 0.6288888888888889, 0.6371482176360225], 'test': [0.9068517460013336, 0.40914454277286133, 0.44537521815008724, 0.7550295857988165, 0.5602634467618002]}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  019  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  019  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  019  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6439, Acc: 0.6791, Val Loss: 0.6338, Val Acc: 0.6450
Mejor modelo guardado con Val Loss: 0.6338
Epoch 2/100, Loss: 0.5807, Acc: 0.7241, Val Loss: 0.6194, Val Acc: 0.6661
Mejor modelo guardado con Val Loss: 0.6194
Epoch 3/100, Loss: 0.5432, Acc: 0.7393, Val Loss: 0.5510, Val Acc: 0.7317
Mejor modelo guardado con Val Loss: 0.5510
Epoch 4/100, Loss: 0.5302, Acc: 0.7462, Val Loss: 0.5444, Val Acc: 0.7295
Mejor modelo guardado con Val Loss: 0.5444
Epoch 5/100, Loss: 0.5274, Acc: 0.7457, Val Loss: 0.5547, Val Acc: 0.7232
Epoch 6/100, Loss: 0.5242, Acc: 0.7428, Val Loss: 0.5456, Val Acc: 0.7406
Epoch 7/100, Loss: 0.5173, Acc: 0.7505, Val Loss: 0.5415, Val Acc: 0.7310
Mejor modelo guardado con Val Loss: 0.5415
Epoch 8/100, Loss: 0.5141, Acc: 0.7536, Val Loss: 0.5705, Val Acc: 0.6963
Epoch 9/100, Loss: 0.5118, Acc: 0.7548, Val Loss: 0.6117, Val Acc: 0.6808
Epoch 10/100, Loss: 0.5169, Acc: 0.7492, Val Loss: 0.5591, Val Acc: 0.7203
Epoch 11/100, Loss: 0.5121, Acc: 0.7543, Val Loss: 0.5256, Val Acc: 0.7387
Mejor modelo guardado con Val Loss: 0.5256
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4981, Acc: 0.7600, Val Loss: 0.5966, Val Acc: 0.7137
Epoch 13/100, Loss: 0.4950, Acc: 0.7685, Val Loss: 0.5704, Val Acc: 0.7236
Epoch 14/100, Loss: 0.4989, Acc: 0.7658, Val Loss: 0.5460, Val Acc: 0.7362
Epoch 15/100, Loss: 0.4928, Acc: 0.7698, Val Loss: 0.5256, Val Acc: 0.7565
Mejor modelo guardado con Val Loss: 0.5256
Epoch 16/100, Loss: 0.4917, Acc: 0.7696, Val Loss: 0.5500, Val Acc: 0.7380
Epoch 17/100, Loss: 0.4929, Acc: 0.7672, Val Loss: 0.5557, Val Acc: 0.7292
Epoch 18/100, Loss: 0.4908, Acc: 0.7736, Val Loss: 0.5815, Val Acc: 0.7188
Epoch 19/100, Loss: 0.4908, Acc: 0.7721, Val Loss: 0.5431, Val Acc: 0.7417
Epoch 20/100, Loss: 0.4880, Acc: 0.7759, Val Loss: 0.5277, Val Acc: 0.7424
Epoch 21/100, Loss: 0.4928, Acc: 0.7741, Val Loss: 0.5335, Val Acc: 0.7432
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4745, Acc: 0.7862, Val Loss: 0.5547, Val Acc: 0.7469
Epoch 23/100, Loss: 0.4749, Acc: 0.7823, Val Loss: 0.5661, Val Acc: 0.7432
Epoch 24/100, Loss: 0.4730, Acc: 0.7853, Val Loss: 0.5397, Val Acc: 0.7542
Epoch 25/100, Loss: 0.4769, Acc: 0.7825, Val Loss: 0.5444, Val Acc: 0.7387
Epoch 26/100, Loss: 0.4714, Acc: 0.7876, Val Loss: 0.5161, Val Acc: 0.7539
Mejor modelo guardado con Val Loss: 0.5161
Epoch 27/100, Loss: 0.4720, Acc: 0.7882, Val Loss: 0.5260, Val Acc: 0.7568
Epoch 28/100, Loss: 0.4677, Acc: 0.7920, Val Loss: 0.5364, Val Acc: 0.7583
Epoch 29/100, Loss: 0.4686, Acc: 0.7897, Val Loss: 0.5317, Val Acc: 0.7513
Epoch 30/100, Loss: 0.4668, Acc: 0.7956, Val Loss: 0.5265, Val Acc: 0.7528
Epoch 31/100, Loss: 0.4620, Acc: 0.7959, Val Loss: 0.6025, Val Acc: 0.7218
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4581, Acc: 0.8019, Val Loss: 0.5610, Val Acc: 0.7458
Epoch 33/100, Loss: 0.4582, Acc: 0.7994, Val Loss: 0.5347, Val Acc: 0.7520
Epoch 34/100, Loss: 0.4567, Acc: 0.8012, Val Loss: 0.5405, Val Acc: 0.7498
Epoch 35/100, Loss: 0.4550, Acc: 0.8002, Val Loss: 0.5256, Val Acc: 0.7528
Epoch 36/100, Loss: 0.4541, Acc: 0.7995, Val Loss: 0.5444, Val Acc: 0.7476
Epoch 37/100, Loss: 0.4532, Acc: 0.8029, Val Loss: 0.5497, Val Acc: 0.7480
Epoch 38/100, Loss: 0.4540, Acc: 0.8019, Val Loss: 0.5168, Val Acc: 0.7616
Epoch 39/100, Loss: 0.4526, Acc: 0.8013, Val Loss: 0.5333, Val Acc: 0.7539
Epoch 40/100, Loss: 0.4526, Acc: 0.8013, Val Loss: 0.5295, Val Acc: 0.7554
Epoch 41/100, Loss: 0.4501, Acc: 0.8043, Val Loss: 0.5223, Val Acc: 0.7620
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4469, Acc: 0.8070, Val Loss: 0.5421, Val Acc: 0.7491
Epoch 43/100, Loss: 0.4462, Acc: 0.8098, Val Loss: 0.5299, Val Acc: 0.7583
Epoch 44/100, Loss: 0.4474, Acc: 0.8085, Val Loss: 0.5433, Val Acc: 0.7506
Epoch 45/100, Loss: 0.4457, Acc: 0.8089, Val Loss: 0.5605, Val Acc: 0.7454
Epoch 46/100, Loss: 0.4441, Acc: 0.8106, Val Loss: 0.5345, Val Acc: 0.7524
Epoch 47/100, Loss: 0.4448, Acc: 0.8090, Val Loss: 0.5368, Val Acc: 0.7506
Epoch 48/100, Loss: 0.4437, Acc: 0.8109, Val Loss: 0.5545, Val Acc: 0.7465
Epoch 49/100, Loss: 0.4437, Acc: 0.8099, Val Loss: 0.5388, Val Acc: 0.7513
Epoch 50/100, Loss: 0.4436, Acc: 0.8092, Val Loss: 0.5262, Val Acc: 0.7572
Epoch 51/100, Loss: 0.4419, Acc: 0.8116, Val Loss: 0.5473, Val Acc: 0.7494
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4412, Acc: 0.8127, Val Loss: 0.5343, Val Acc: 0.7542
Epoch 53/100, Loss: 0.4404, Acc: 0.8122, Val Loss: 0.5428, Val Acc: 0.7494
Epoch 54/100, Loss: 0.4394, Acc: 0.8111, Val Loss: 0.5389, Val Acc: 0.7506
Epoch 55/100, Loss: 0.4384, Acc: 0.8136, Val Loss: 0.5457, Val Acc: 0.7498
Epoch 56/100, Loss: 0.4377, Acc: 0.8122, Val Loss: 0.5536, Val Acc: 0.7465
Epoch 57/100, Loss: 0.4372, Acc: 0.8131, Val Loss: 0.5340, Val Acc: 0.7550
Epoch 58/100, Loss: 0.4359, Acc: 0.8144, Val Loss: 0.5391, Val Acc: 0.7513
Epoch 59/100, Loss: 0.4342, Acc: 0.8148, Val Loss: 0.5372, Val Acc: 0.7520
Epoch 60/100, Loss: 0.4332, Acc: 0.8164, Val Loss: 0.5488, Val Acc: 0.7458
Epoch 61/100, Loss: 0.4328, Acc: 0.8153, Val Loss: 0.5369, Val Acc: 0.7520
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4318, Acc: 0.8163, Val Loss: 0.5430, Val Acc: 0.7502
Epoch 63/100, Loss: 0.4315, Acc: 0.8161, Val Loss: 0.5337, Val Acc: 0.7539
Epoch 64/100, Loss: 0.4315, Acc: 0.8148, Val Loss: 0.5355, Val Acc: 0.7520
Epoch 65/100, Loss: 0.4311, Acc: 0.8159, Val Loss: 0.5346, Val Acc: 0.7539
Epoch 66/100, Loss: 0.4307, Acc: 0.8172, Val Loss: 0.5386, Val Acc: 0.7520
Epoch 67/100, Loss: 0.4304, Acc: 0.8167, Val Loss: 0.5408, Val Acc: 0.7517
Epoch 68/100, Loss: 0.4299, Acc: 0.8154, Val Loss: 0.5334, Val Acc: 0.7539
Epoch 69/100, Loss: 0.4304, Acc: 0.8152, Val Loss: 0.5403, Val Acc: 0.7513
Epoch 70/100, Loss: 0.4296, Acc: 0.8174, Val Loss: 0.5348, Val Acc: 0.7546
Epoch 71/100, Loss: 0.4292, Acc: 0.8159, Val Loss: 0.5353, Val Acc: 0.7542
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4288, Acc: 0.8173, Val Loss: 0.5343, Val Acc: 0.7542
Epoch 73/100, Loss: 0.4288, Acc: 0.8165, Val Loss: 0.5350, Val Acc: 0.7535
Epoch 74/100, Loss: 0.4285, Acc: 0.8164, Val Loss: 0.5313, Val Acc: 0.7550
Epoch 75/100, Loss: 0.4284, Acc: 0.8173, Val Loss: 0.5348, Val Acc: 0.7531
Epoch 76/100, Loss: 0.4280, Acc: 0.8170, Val Loss: 0.5415, Val Acc: 0.7517
Epoch 77/100, Loss: 0.4278, Acc: 0.8174, Val Loss: 0.5368, Val Acc: 0.7535
Epoch 78/100, Loss: 0.4277, Acc: 0.8176, Val Loss: 0.5346, Val Acc: 0.7542
Epoch 79/100, Loss: 0.4274, Acc: 0.8172, Val Loss: 0.5368, Val Acc: 0.7531
Epoch 80/100, Loss: 0.4278, Acc: 0.8175, Val Loss: 0.5303, Val Acc: 0.7546
Epoch 81/100, Loss: 0.4270, Acc: 0.8165, Val Loss: 0.5339, Val Acc: 0.7535
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4273, Acc: 0.8160, Val Loss: 0.5348, Val Acc: 0.7539
Epoch 83/100, Loss: 0.4269, Acc: 0.8181, Val Loss: 0.5400, Val Acc: 0.7528
Epoch 84/100, Loss: 0.4266, Acc: 0.8169, Val Loss: 0.5359, Val Acc: 0.7539
Epoch 85/100, Loss: 0.4264, Acc: 0.8176, Val Loss: 0.5308, Val Acc: 0.7550
Epoch 86/100, Loss: 0.4262, Acc: 0.8177, Val Loss: 0.5391, Val Acc: 0.7531
Epoch 87/100, Loss: 0.4260, Acc: 0.8185, Val Loss: 0.5362, Val Acc: 0.7531
Epoch 88/100, Loss: 0.4256, Acc: 0.8170, Val Loss: 0.5447, Val Acc: 0.7472
Epoch 89/100, Loss: 0.4257, Acc: 0.8184, Val Loss: 0.5314, Val Acc: 0.7539
Epoch 90/100, Loss: 0.4253, Acc: 0.8185, Val Loss: 0.5410, Val Acc: 0.7506
Epoch 91/100, Loss: 0.4254, Acc: 0.8181, Val Loss: 0.5386, Val Acc: 0.7528
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4250, Acc: 0.8177, Val Loss: 0.5276, Val Acc: 0.7561
Epoch 93/100, Loss: 0.4247, Acc: 0.8195, Val Loss: 0.5441, Val Acc: 0.7483
Epoch 94/100, Loss: 0.4247, Acc: 0.8189, Val Loss: 0.5428, Val Acc: 0.7483
Epoch 95/100, Loss: 0.4243, Acc: 0.8180, Val Loss: 0.5401, Val Acc: 0.7517
Epoch 96/100, Loss: 0.4240, Acc: 0.8186, Val Loss: 0.5384, Val Acc: 0.7528
Epoch 97/100, Loss: 0.4236, Acc: 0.8194, Val Loss: 0.5389, Val Acc: 0.7524
Epoch 98/100, Loss: 0.4238, Acc: 0.8177, Val Loss: 0.5328, Val Acc: 0.7561
Epoch 99/100, Loss: 0.4236, Acc: 0.8180, Val Loss: 0.5328, Val Acc: 0.7546
Epoch 100/100, Loss: 0.4235, Acc: 0.8188, Val Loss: 0.5328, Val Acc: 0.7557

##############################
Resultados para principal:  019  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  11 
 {'training': [0.4234535510373313, 0.8187672493100276, 0.8182487122884474, 0.8191528545119705, 0.8187005337750782], 'validate': [0.5327814074103222, 0.7557195571955719, 0.7120838471023427, 0.8555555555555555, 0.7772543741588156], 'test': [0.8985710704945168, 0.5147492625368731, 0.5107193901858028, 0.6343195266272189, 0.5658485088413829]}

##############################
Resultados para window:  11 
 {'036:024:100:090:091:019': {'training': [0.5710983482104655, 0.7006439742410303, 0.6746388443017657, 0.7740331491712708, 0.720926243567753], 'validate': [0.6629360720168712, 0.5952029520295203, 0.5624691358024692, 0.8437037037037037, 0.674962962962963], 'test': [0.7443391214001853, 0.5348082595870206, 0.5359186268277177, 0.49881656804733726, 0.5167024210848912]}, '024:036:100:090:091:019': {'training': [0.4927973107668711, 0.7670653173873045, 0.783672670321065, 0.7372007366482505, 0.7597267033592712], 'validate': [0.7614949106477028, 0.5904059040590406, 0.581081081081081, 0.6370370370370371, 0.607773851590106], 'test': [0.5874476241615584, 0.7064896755162242, 0.8571428571428571, 0.493491124260355, 0.6263612467142321]}, '100:036:024:090:091:019': {'training': [0.3928714917467182, 0.8221711131554738, 0.8570553400040841, 0.7729281767955801, 0.812820761111649], 'validate': [1.2720300958946693, 0.3892988929889299, 0.2849083215796897, 0.14962962962962964, 0.19621175327829043], 'test': [0.5349478440464668, 0.8333333333333334, 0.8688524590163934, 0.7840236686390533, 0.8242612752721618]}, '090:036:024:100:091:019': {'training': [0.610997293811384, 0.6573137074517019, 0.6132890365448505, 0.8499079189686924, 0.7124662292551138], 'validate': [0.8519604344700658, 0.3719557195571956, 0.41586998087954113, 0.6444444444444445, 0.505520046484602], 'test': [0.7049119933596197, 0.3831858407079646, 0.41293964394268345, 0.5627218934911242, 0.4763335837716003]}, '091:036:024:100:090:019': {'training': [0.533343970194363, 0.7532658693652254, 0.7461483339304908, 0.7670349907918969, 0.7564475118053033], 'validate': [0.6275119615155597, 0.6431734317343173, 0.6456273764258555, 0.6288888888888889, 0.6371482176360225], 'test': [0.9068517460013336, 0.40914454277286133, 0.44537521815008724, 0.7550295857988165, 0.5602634467618002]}, '019:036:024:100:090:091': {'training': [0.4234535510373313, 0.8187672493100276, 0.8182487122884474, 0.8191528545119705, 0.8187005337750782], 'validate': [0.5327814074103222, 0.7557195571955719, 0.7120838471023427, 0.8555555555555555, 0.7772543741588156], 'test': [0.8985710704945168, 0.5147492625368731, 0.5107193901858028, 0.6343195266272189, 0.5658485088413829]}}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  064  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  064  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  064  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6558, Acc: 0.6361, Val Loss: 0.7170, Val Acc: 0.4904
Mejor modelo guardado con Val Loss: 0.7170
Epoch 2/100, Loss: 0.6282, Acc: 0.6726, Val Loss: 0.7409, Val Acc: 0.4605
Epoch 3/100, Loss: 0.5986, Acc: 0.6972, Val Loss: 0.7502, Val Acc: 0.4686
Epoch 4/100, Loss: 0.5895, Acc: 0.6925, Val Loss: 0.7508, Val Acc: 0.4731
Epoch 5/100, Loss: 0.5720, Acc: 0.7067, Val Loss: 0.7582, Val Acc: 0.4923
Epoch 6/100, Loss: 0.5668, Acc: 0.7084, Val Loss: 0.7528, Val Acc: 0.4871
Epoch 7/100, Loss: 0.5613, Acc: 0.7111, Val Loss: 0.8008, Val Acc: 0.4609
Epoch 8/100, Loss: 0.5580, Acc: 0.7106, Val Loss: 0.7669, Val Acc: 0.4812
Epoch 9/100, Loss: 0.5510, Acc: 0.7155, Val Loss: 0.7579, Val Acc: 0.4974
Epoch 10/100, Loss: 0.5483, Acc: 0.7167, Val Loss: 0.7775, Val Acc: 0.4945
Epoch 11/100, Loss: 0.5438, Acc: 0.7213, Val Loss: 0.7615, Val Acc: 0.4967
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5363, Acc: 0.7308, Val Loss: 0.7924, Val Acc: 0.4686
Epoch 13/100, Loss: 0.5332, Acc: 0.7307, Val Loss: 0.8039, Val Acc: 0.4834
Epoch 14/100, Loss: 0.5344, Acc: 0.7283, Val Loss: 0.7754, Val Acc: 0.4889
Epoch 15/100, Loss: 0.5325, Acc: 0.7319, Val Loss: 0.7935, Val Acc: 0.4764
Epoch 16/100, Loss: 0.5312, Acc: 0.7305, Val Loss: 0.7766, Val Acc: 0.4923
Epoch 17/100, Loss: 0.5322, Acc: 0.7305, Val Loss: 0.7996, Val Acc: 0.4867
Epoch 18/100, Loss: 0.5305, Acc: 0.7303, Val Loss: 0.7724, Val Acc: 0.4967
Epoch 19/100, Loss: 0.5321, Acc: 0.7310, Val Loss: 0.7940, Val Acc: 0.4804
Epoch 20/100, Loss: 0.5266, Acc: 0.7369, Val Loss: 0.7824, Val Acc: 0.4937
Epoch 21/100, Loss: 0.5308, Acc: 0.7309, Val Loss: 0.7750, Val Acc: 0.4900
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5237, Acc: 0.7364, Val Loss: 0.7858, Val Acc: 0.4849
Epoch 23/100, Loss: 0.5233, Acc: 0.7371, Val Loss: 0.7869, Val Acc: 0.4867
Epoch 24/100, Loss: 0.5229, Acc: 0.7382, Val Loss: 0.7907, Val Acc: 0.4742
Epoch 25/100, Loss: 0.5215, Acc: 0.7382, Val Loss: 0.7848, Val Acc: 0.4956
Epoch 26/100, Loss: 0.5209, Acc: 0.7409, Val Loss: 0.7988, Val Acc: 0.4782
Epoch 27/100, Loss: 0.5210, Acc: 0.7373, Val Loss: 0.7913, Val Acc: 0.4919
Epoch 28/100, Loss: 0.5197, Acc: 0.7386, Val Loss: 0.8022, Val Acc: 0.4697
Epoch 29/100, Loss: 0.5209, Acc: 0.7386, Val Loss: 0.7810, Val Acc: 0.4919
Epoch 30/100, Loss: 0.5202, Acc: 0.7382, Val Loss: 0.7894, Val Acc: 0.4897
Epoch 31/100, Loss: 0.5190, Acc: 0.7402, Val Loss: 0.7912, Val Acc: 0.4908
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5172, Acc: 0.7396, Val Loss: 0.7987, Val Acc: 0.4841
Epoch 33/100, Loss: 0.5162, Acc: 0.7429, Val Loss: 0.7966, Val Acc: 0.4852
Epoch 34/100, Loss: 0.5159, Acc: 0.7421, Val Loss: 0.7792, Val Acc: 0.4945
Epoch 35/100, Loss: 0.5165, Acc: 0.7427, Val Loss: 0.7882, Val Acc: 0.4889
Epoch 36/100, Loss: 0.5157, Acc: 0.7443, Val Loss: 0.7927, Val Acc: 0.4893
Epoch 37/100, Loss: 0.5150, Acc: 0.7439, Val Loss: 0.8141, Val Acc: 0.4690
Epoch 38/100, Loss: 0.5161, Acc: 0.7431, Val Loss: 0.7925, Val Acc: 0.4875
Epoch 39/100, Loss: 0.5148, Acc: 0.7441, Val Loss: 0.7924, Val Acc: 0.4904
Epoch 40/100, Loss: 0.5136, Acc: 0.7453, Val Loss: 0.7983, Val Acc: 0.4856
Epoch 41/100, Loss: 0.5146, Acc: 0.7426, Val Loss: 0.8087, Val Acc: 0.4723
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5124, Acc: 0.7468, Val Loss: 0.7970, Val Acc: 0.4852
Epoch 43/100, Loss: 0.5123, Acc: 0.7455, Val Loss: 0.7891, Val Acc: 0.4926
Epoch 44/100, Loss: 0.5127, Acc: 0.7443, Val Loss: 0.7958, Val Acc: 0.4882
Epoch 45/100, Loss: 0.5119, Acc: 0.7440, Val Loss: 0.7906, Val Acc: 0.4878
Epoch 46/100, Loss: 0.5123, Acc: 0.7446, Val Loss: 0.7929, Val Acc: 0.4878
Epoch 47/100, Loss: 0.5116, Acc: 0.7448, Val Loss: 0.7886, Val Acc: 0.4908
Epoch 48/100, Loss: 0.5113, Acc: 0.7444, Val Loss: 0.7918, Val Acc: 0.4875
Epoch 49/100, Loss: 0.5116, Acc: 0.7448, Val Loss: 0.8025, Val Acc: 0.4815
Epoch 50/100, Loss: 0.5119, Acc: 0.7450, Val Loss: 0.7959, Val Acc: 0.4882
Epoch 51/100, Loss: 0.5113, Acc: 0.7466, Val Loss: 0.7938, Val Acc: 0.4889
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5108, Acc: 0.7454, Val Loss: 0.7923, Val Acc: 0.4889
Epoch 53/100, Loss: 0.5101, Acc: 0.7458, Val Loss: 0.7945, Val Acc: 0.4882
Epoch 54/100, Loss: 0.5106, Acc: 0.7454, Val Loss: 0.7936, Val Acc: 0.4878
Epoch 55/100, Loss: 0.5100, Acc: 0.7466, Val Loss: 0.7936, Val Acc: 0.4911
Epoch 56/100, Loss: 0.5098, Acc: 0.7456, Val Loss: 0.7953, Val Acc: 0.4875
Epoch 57/100, Loss: 0.5097, Acc: 0.7459, Val Loss: 0.7911, Val Acc: 0.4897
Epoch 58/100, Loss: 0.5091, Acc: 0.7482, Val Loss: 0.7996, Val Acc: 0.4875
Epoch 59/100, Loss: 0.5096, Acc: 0.7453, Val Loss: 0.7947, Val Acc: 0.4897
Epoch 60/100, Loss: 0.5092, Acc: 0.7463, Val Loss: 0.7902, Val Acc: 0.4897
Epoch 61/100, Loss: 0.5090, Acc: 0.7456, Val Loss: 0.7945, Val Acc: 0.4875
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5088, Acc: 0.7466, Val Loss: 0.7964, Val Acc: 0.4867
Epoch 63/100, Loss: 0.5086, Acc: 0.7480, Val Loss: 0.7952, Val Acc: 0.4893
Epoch 64/100, Loss: 0.5087, Acc: 0.7468, Val Loss: 0.7966, Val Acc: 0.4867
Epoch 65/100, Loss: 0.5085, Acc: 0.7458, Val Loss: 0.7932, Val Acc: 0.4878
Epoch 66/100, Loss: 0.5086, Acc: 0.7468, Val Loss: 0.7944, Val Acc: 0.4886
Epoch 67/100, Loss: 0.5083, Acc: 0.7461, Val Loss: 0.7935, Val Acc: 0.4893
Epoch 68/100, Loss: 0.5085, Acc: 0.7464, Val Loss: 0.7950, Val Acc: 0.4871
Epoch 69/100, Loss: 0.5083, Acc: 0.7471, Val Loss: 0.7956, Val Acc: 0.4878
Epoch 70/100, Loss: 0.5082, Acc: 0.7464, Val Loss: 0.7921, Val Acc: 0.4886
Epoch 71/100, Loss: 0.5077, Acc: 0.7477, Val Loss: 0.7929, Val Acc: 0.4875
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5074, Acc: 0.7467, Val Loss: 0.7920, Val Acc: 0.4878
Epoch 73/100, Loss: 0.5076, Acc: 0.7473, Val Loss: 0.7924, Val Acc: 0.4882
Epoch 74/100, Loss: 0.5074, Acc: 0.7464, Val Loss: 0.7927, Val Acc: 0.4867
Epoch 75/100, Loss: 0.5074, Acc: 0.7466, Val Loss: 0.7939, Val Acc: 0.4871
Epoch 76/100, Loss: 0.5072, Acc: 0.7481, Val Loss: 0.7952, Val Acc: 0.4856
Epoch 77/100, Loss: 0.5074, Acc: 0.7473, Val Loss: 0.7953, Val Acc: 0.4867
Epoch 78/100, Loss: 0.5074, Acc: 0.7465, Val Loss: 0.7935, Val Acc: 0.4871
Epoch 79/100, Loss: 0.5073, Acc: 0.7466, Val Loss: 0.7942, Val Acc: 0.4867
Epoch 80/100, Loss: 0.5070, Acc: 0.7473, Val Loss: 0.7956, Val Acc: 0.4834
Epoch 81/100, Loss: 0.5072, Acc: 0.7466, Val Loss: 0.7940, Val Acc: 0.4871
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5070, Acc: 0.7485, Val Loss: 0.7945, Val Acc: 0.4867
Epoch 83/100, Loss: 0.5069, Acc: 0.7476, Val Loss: 0.7945, Val Acc: 0.4871
Epoch 84/100, Loss: 0.5069, Acc: 0.7469, Val Loss: 0.7931, Val Acc: 0.4875
Epoch 85/100, Loss: 0.5069, Acc: 0.7477, Val Loss: 0.7936, Val Acc: 0.4863
Epoch 86/100, Loss: 0.5069, Acc: 0.7474, Val Loss: 0.7961, Val Acc: 0.4834
Epoch 87/100, Loss: 0.5068, Acc: 0.7476, Val Loss: 0.7928, Val Acc: 0.4867
Epoch 88/100, Loss: 0.5066, Acc: 0.7482, Val Loss: 0.7930, Val Acc: 0.4875
Epoch 89/100, Loss: 0.5065, Acc: 0.7485, Val Loss: 0.7975, Val Acc: 0.4841
Epoch 90/100, Loss: 0.5066, Acc: 0.7477, Val Loss: 0.7929, Val Acc: 0.4867
Epoch 91/100, Loss: 0.5066, Acc: 0.7479, Val Loss: 0.7952, Val Acc: 0.4863
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5065, Acc: 0.7479, Val Loss: 0.7955, Val Acc: 0.4841
Epoch 93/100, Loss: 0.5064, Acc: 0.7466, Val Loss: 0.7929, Val Acc: 0.4863
Epoch 94/100, Loss: 0.5064, Acc: 0.7478, Val Loss: 0.7915, Val Acc: 0.4878
Epoch 95/100, Loss: 0.5064, Acc: 0.7472, Val Loss: 0.7948, Val Acc: 0.4830
Epoch 96/100, Loss: 0.5062, Acc: 0.7481, Val Loss: 0.7940, Val Acc: 0.4834
Epoch 97/100, Loss: 0.5062, Acc: 0.7478, Val Loss: 0.7952, Val Acc: 0.4849
Epoch 98/100, Loss: 0.5060, Acc: 0.7472, Val Loss: 0.7925, Val Acc: 0.4863
Epoch 99/100, Loss: 0.5061, Acc: 0.7479, Val Loss: 0.7920, Val Acc: 0.4867
Epoch 100/100, Loss: 0.5059, Acc: 0.7473, Val Loss: 0.7923, Val Acc: 0.4863

##############################
Resultados para principal:  064  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11 
 {'training': [0.5059182659682596, 0.7472861085556578, 0.6828902522154056, 0.9224677716390424, 0.7848021934978456], 'validate': [0.7923373358194218, 0.4863468634686347, 0.4912718204488778, 0.8755555555555555, 0.6293929712460063], 'test': [0.7223270557961374, 0.487905604719764, 0.49303452453058755, 0.9633136094674556, 0.6522435897435898]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  060  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  060  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  060  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5868, Acc: 0.7075, Val Loss: 0.8034, Val Acc: 0.4764
Mejor modelo guardado con Val Loss: 0.8034
Epoch 2/100, Loss: 0.5349, Acc: 0.7333, Val Loss: 0.8210, Val Acc: 0.4753
Epoch 3/100, Loss: 0.5224, Acc: 0.7346, Val Loss: 0.8702, Val Acc: 0.4797
Epoch 4/100, Loss: 0.5109, Acc: 0.7466, Val Loss: 0.7997, Val Acc: 0.4838
Mejor modelo guardado con Val Loss: 0.7997
Epoch 5/100, Loss: 0.4997, Acc: 0.7487, Val Loss: 0.7665, Val Acc: 0.4387
Mejor modelo guardado con Val Loss: 0.7665
Epoch 6/100, Loss: 0.5000, Acc: 0.7447, Val Loss: 0.8747, Val Acc: 0.4889
Epoch 7/100, Loss: 0.4887, Acc: 0.7596, Val Loss: 0.8265, Val Acc: 0.4915
Epoch 8/100, Loss: 0.4907, Acc: 0.7534, Val Loss: 0.7633, Val Acc: 0.4996
Mejor modelo guardado con Val Loss: 0.7633
Epoch 9/100, Loss: 0.4811, Acc: 0.7569, Val Loss: 0.7737, Val Acc: 0.4985
Epoch 10/100, Loss: 0.4774, Acc: 0.7592, Val Loss: 0.7574, Val Acc: 0.5055
Mejor modelo guardado con Val Loss: 0.7574
Epoch 11/100, Loss: 0.4797, Acc: 0.7598, Val Loss: 0.7556, Val Acc: 0.4827
Mejor modelo guardado con Val Loss: 0.7556
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4800, Acc: 0.7639, Val Loss: 0.7801, Val Acc: 0.4904
Epoch 13/100, Loss: 0.4698, Acc: 0.7681, Val Loss: 0.8412, Val Acc: 0.5052
Epoch 14/100, Loss: 0.4631, Acc: 0.7715, Val Loss: 0.7978, Val Acc: 0.4790
Epoch 15/100, Loss: 0.4696, Acc: 0.7664, Val Loss: 0.8141, Val Acc: 0.4941
Epoch 16/100, Loss: 0.4644, Acc: 0.7707, Val Loss: 0.7838, Val Acc: 0.5059
Epoch 17/100, Loss: 0.4653, Acc: 0.7706, Val Loss: 0.7512, Val Acc: 0.4978
Mejor modelo guardado con Val Loss: 0.7512
Epoch 18/100, Loss: 0.4617, Acc: 0.7684, Val Loss: 0.8175, Val Acc: 0.4841
Epoch 19/100, Loss: 0.4645, Acc: 0.7707, Val Loss: 0.7659, Val Acc: 0.4959
Epoch 20/100, Loss: 0.4567, Acc: 0.7764, Val Loss: 0.7862, Val Acc: 0.5258
Epoch 21/100, Loss: 0.4629, Acc: 0.7731, Val Loss: 0.7740, Val Acc: 0.5122
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4592, Acc: 0.7724, Val Loss: 0.7753, Val Acc: 0.5059
Epoch 23/100, Loss: 0.4573, Acc: 0.7746, Val Loss: 0.7818, Val Acc: 0.5122
Epoch 24/100, Loss: 0.4557, Acc: 0.7738, Val Loss: 0.7861, Val Acc: 0.5030
Epoch 25/100, Loss: 0.4529, Acc: 0.7794, Val Loss: 0.8111, Val Acc: 0.5081
Epoch 26/100, Loss: 0.4528, Acc: 0.7772, Val Loss: 0.8298, Val Acc: 0.5081
Epoch 27/100, Loss: 0.4555, Acc: 0.7753, Val Loss: 0.7717, Val Acc: 0.5107
Epoch 28/100, Loss: 0.4497, Acc: 0.7774, Val Loss: 0.7632, Val Acc: 0.5111
Epoch 29/100, Loss: 0.4492, Acc: 0.7794, Val Loss: 0.7929, Val Acc: 0.5089
Epoch 30/100, Loss: 0.4481, Acc: 0.7810, Val Loss: 0.7816, Val Acc: 0.5096
Epoch 31/100, Loss: 0.4490, Acc: 0.7820, Val Loss: 0.7470, Val Acc: 0.5111
Mejor modelo guardado con Val Loss: 0.7470
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4443, Acc: 0.7821, Val Loss: 0.7664, Val Acc: 0.5133
Epoch 33/100, Loss: 0.4446, Acc: 0.7808, Val Loss: 0.7899, Val Acc: 0.5092
Epoch 34/100, Loss: 0.4429, Acc: 0.7800, Val Loss: 0.8037, Val Acc: 0.5092
Epoch 35/100, Loss: 0.4430, Acc: 0.7818, Val Loss: 0.7823, Val Acc: 0.5203
Epoch 36/100, Loss: 0.4430, Acc: 0.7839, Val Loss: 0.7619, Val Acc: 0.5133
Epoch 37/100, Loss: 0.4403, Acc: 0.7843, Val Loss: 0.7923, Val Acc: 0.5089
Epoch 38/100, Loss: 0.4406, Acc: 0.7815, Val Loss: 0.8052, Val Acc: 0.5103
Epoch 39/100, Loss: 0.4400, Acc: 0.7835, Val Loss: 0.7671, Val Acc: 0.5096
Epoch 40/100, Loss: 0.4405, Acc: 0.7832, Val Loss: 0.7480, Val Acc: 0.5162
Epoch 41/100, Loss: 0.4386, Acc: 0.7840, Val Loss: 0.7617, Val Acc: 0.5114
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4370, Acc: 0.7841, Val Loss: 0.7433, Val Acc: 0.5077
Mejor modelo guardado con Val Loss: 0.7433
Epoch 43/100, Loss: 0.4370, Acc: 0.7839, Val Loss: 0.7548, Val Acc: 0.5155
Epoch 44/100, Loss: 0.4363, Acc: 0.7841, Val Loss: 0.7541, Val Acc: 0.5092
Epoch 45/100, Loss: 0.4362, Acc: 0.7843, Val Loss: 0.7612, Val Acc: 0.5144
Epoch 46/100, Loss: 0.4357, Acc: 0.7833, Val Loss: 0.7733, Val Acc: 0.5133
Epoch 47/100, Loss: 0.4350, Acc: 0.7857, Val Loss: 0.7572, Val Acc: 0.5203
Epoch 48/100, Loss: 0.4358, Acc: 0.7853, Val Loss: 0.7587, Val Acc: 0.5133
Epoch 49/100, Loss: 0.4349, Acc: 0.7840, Val Loss: 0.7663, Val Acc: 0.5129
Epoch 50/100, Loss: 0.4348, Acc: 0.7839, Val Loss: 0.7742, Val Acc: 0.5125
Epoch 51/100, Loss: 0.4339, Acc: 0.7845, Val Loss: 0.7620, Val Acc: 0.5140
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4321, Acc: 0.7845, Val Loss: 0.7742, Val Acc: 0.5144
Epoch 53/100, Loss: 0.4320, Acc: 0.7838, Val Loss: 0.7614, Val Acc: 0.5151
Epoch 54/100, Loss: 0.4313, Acc: 0.7842, Val Loss: 0.7712, Val Acc: 0.5118
Epoch 55/100, Loss: 0.4311, Acc: 0.7844, Val Loss: 0.7687, Val Acc: 0.5137
Epoch 56/100, Loss: 0.4309, Acc: 0.7852, Val Loss: 0.7615, Val Acc: 0.5155
Epoch 57/100, Loss: 0.4305, Acc: 0.7858, Val Loss: 0.7639, Val Acc: 0.5125
Epoch 58/100, Loss: 0.4303, Acc: 0.7845, Val Loss: 0.7714, Val Acc: 0.5155
Epoch 59/100, Loss: 0.4300, Acc: 0.7857, Val Loss: 0.7658, Val Acc: 0.5155
Epoch 60/100, Loss: 0.4297, Acc: 0.7864, Val Loss: 0.7721, Val Acc: 0.5140
Epoch 61/100, Loss: 0.4295, Acc: 0.7856, Val Loss: 0.7712, Val Acc: 0.5129
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4290, Acc: 0.7867, Val Loss: 0.7728, Val Acc: 0.5133
Epoch 63/100, Loss: 0.4290, Acc: 0.7868, Val Loss: 0.7688, Val Acc: 0.5122
Epoch 64/100, Loss: 0.4290, Acc: 0.7871, Val Loss: 0.7680, Val Acc: 0.5118
Epoch 65/100, Loss: 0.4287, Acc: 0.7871, Val Loss: 0.7606, Val Acc: 0.5114
Epoch 66/100, Loss: 0.4287, Acc: 0.7871, Val Loss: 0.7687, Val Acc: 0.5129
Epoch 67/100, Loss: 0.4284, Acc: 0.7871, Val Loss: 0.7723, Val Acc: 0.5133
Epoch 68/100, Loss: 0.4284, Acc: 0.7879, Val Loss: 0.7691, Val Acc: 0.5111
Epoch 69/100, Loss: 0.4284, Acc: 0.7865, Val Loss: 0.7621, Val Acc: 0.5107
Epoch 70/100, Loss: 0.4282, Acc: 0.7883, Val Loss: 0.7638, Val Acc: 0.5122
Epoch 71/100, Loss: 0.4280, Acc: 0.7867, Val Loss: 0.7609, Val Acc: 0.5140
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4278, Acc: 0.7877, Val Loss: 0.7665, Val Acc: 0.5122
Epoch 73/100, Loss: 0.4277, Acc: 0.7883, Val Loss: 0.7606, Val Acc: 0.5137
Epoch 74/100, Loss: 0.4276, Acc: 0.7872, Val Loss: 0.7707, Val Acc: 0.5122
Epoch 75/100, Loss: 0.4276, Acc: 0.7878, Val Loss: 0.7646, Val Acc: 0.5137
Epoch 76/100, Loss: 0.4276, Acc: 0.7875, Val Loss: 0.7675, Val Acc: 0.5122
Epoch 77/100, Loss: 0.4275, Acc: 0.7873, Val Loss: 0.7639, Val Acc: 0.5133
Epoch 78/100, Loss: 0.4273, Acc: 0.7874, Val Loss: 0.7699, Val Acc: 0.5144
Epoch 79/100, Loss: 0.4273, Acc: 0.7880, Val Loss: 0.7672, Val Acc: 0.5133
Epoch 80/100, Loss: 0.4272, Acc: 0.7886, Val Loss: 0.7688, Val Acc: 0.5129
Epoch 81/100, Loss: 0.4271, Acc: 0.7883, Val Loss: 0.7649, Val Acc: 0.5144
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4271, Acc: 0.7878, Val Loss: 0.7660, Val Acc: 0.5129
Epoch 83/100, Loss: 0.4271, Acc: 0.7875, Val Loss: 0.7628, Val Acc: 0.5133
Epoch 84/100, Loss: 0.4270, Acc: 0.7875, Val Loss: 0.7649, Val Acc: 0.5140
Epoch 85/100, Loss: 0.4268, Acc: 0.7878, Val Loss: 0.7634, Val Acc: 0.5173
Epoch 86/100, Loss: 0.4268, Acc: 0.7879, Val Loss: 0.7683, Val Acc: 0.5166
Epoch 87/100, Loss: 0.4267, Acc: 0.7882, Val Loss: 0.7682, Val Acc: 0.5162
Epoch 88/100, Loss: 0.4266, Acc: 0.7886, Val Loss: 0.7648, Val Acc: 0.5151
Epoch 89/100, Loss: 0.4264, Acc: 0.7891, Val Loss: 0.7657, Val Acc: 0.5166
Epoch 90/100, Loss: 0.4264, Acc: 0.7892, Val Loss: 0.7623, Val Acc: 0.5185
Epoch 91/100, Loss: 0.4263, Acc: 0.7889, Val Loss: 0.7611, Val Acc: 0.5181
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4263, Acc: 0.7898, Val Loss: 0.7656, Val Acc: 0.5185
Epoch 93/100, Loss: 0.4262, Acc: 0.7888, Val Loss: 0.7618, Val Acc: 0.5181
Epoch 94/100, Loss: 0.4261, Acc: 0.7892, Val Loss: 0.7631, Val Acc: 0.5185
Epoch 95/100, Loss: 0.4261, Acc: 0.7891, Val Loss: 0.7634, Val Acc: 0.5181
Epoch 96/100, Loss: 0.4259, Acc: 0.7892, Val Loss: 0.7626, Val Acc: 0.5196
Epoch 97/100, Loss: 0.4259, Acc: 0.7892, Val Loss: 0.7654, Val Acc: 0.5173
Epoch 98/100, Loss: 0.4259, Acc: 0.7898, Val Loss: 0.7640, Val Acc: 0.5188
Epoch 99/100, Loss: 0.4257, Acc: 0.7892, Val Loss: 0.7653, Val Acc: 0.5185
Epoch 100/100, Loss: 0.4256, Acc: 0.7887, Val Loss: 0.7635, Val Acc: 0.5185

##############################
Resultados para principal:  060  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11 
 {'training': [0.4255506323967489, 0.7886844526218951, 0.8176840397485297, 0.7425414364640884, 0.7783032525817971], 'validate': [0.763476197109666, 0.518450184501845, 0.556390977443609, 0.16444444444444445, 0.2538593481989708], 'test': [0.9039880183507811, 0.5265486725663717, 0.5192394748755093, 0.678698224852071, 0.5883559887150551]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  028  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  028  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  028  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5708, Acc: 0.7793, Val Loss: 0.4601, Val Acc: 0.8413
Mejor modelo guardado con Val Loss: 0.4601
Epoch 2/100, Loss: 0.4596, Acc: 0.8086, Val Loss: 0.4039, Val Acc: 0.8520
Mejor modelo guardado con Val Loss: 0.4039
Epoch 3/100, Loss: 0.4302, Acc: 0.8155, Val Loss: 0.4085, Val Acc: 0.8413
Epoch 4/100, Loss: 0.4158, Acc: 0.8217, Val Loss: 0.4441, Val Acc: 0.8074
Epoch 5/100, Loss: 0.4070, Acc: 0.8246, Val Loss: 0.4303, Val Acc: 0.8232
Epoch 6/100, Loss: 0.4077, Acc: 0.8259, Val Loss: 0.3840, Val Acc: 0.8568
Mejor modelo guardado con Val Loss: 0.3840
Epoch 7/100, Loss: 0.3991, Acc: 0.8288, Val Loss: 0.4381, Val Acc: 0.8077
Epoch 8/100, Loss: 0.4000, Acc: 0.8274, Val Loss: 0.5124, Val Acc: 0.7808
Epoch 9/100, Loss: 0.3957, Acc: 0.8295, Val Loss: 0.4096, Val Acc: 0.8439
Epoch 10/100, Loss: 0.3900, Acc: 0.8337, Val Loss: 0.4032, Val Acc: 0.8391
Epoch 11/100, Loss: 0.3877, Acc: 0.8321, Val Loss: 0.3829, Val Acc: 0.8480
Mejor modelo guardado con Val Loss: 0.3829
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3828, Acc: 0.8362, Val Loss: 0.4300, Val Acc: 0.8362
Epoch 13/100, Loss: 0.3811, Acc: 0.8357, Val Loss: 0.3847, Val Acc: 0.8528
Epoch 14/100, Loss: 0.3738, Acc: 0.8416, Val Loss: 0.3932, Val Acc: 0.8542
Epoch 15/100, Loss: 0.3753, Acc: 0.8411, Val Loss: 0.4353, Val Acc: 0.8236
Epoch 16/100, Loss: 0.3757, Acc: 0.8386, Val Loss: 0.4060, Val Acc: 0.8410
Epoch 17/100, Loss: 0.3747, Acc: 0.8430, Val Loss: 0.3876, Val Acc: 0.8539
Epoch 18/100, Loss: 0.3733, Acc: 0.8394, Val Loss: 0.3689, Val Acc: 0.8649
Mejor modelo guardado con Val Loss: 0.3689
Epoch 19/100, Loss: 0.3681, Acc: 0.8420, Val Loss: 0.3899, Val Acc: 0.8509
Epoch 20/100, Loss: 0.3713, Acc: 0.8436, Val Loss: 0.4225, Val Acc: 0.8362
Epoch 21/100, Loss: 0.3723, Acc: 0.8394, Val Loss: 0.3874, Val Acc: 0.8517
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3628, Acc: 0.8443, Val Loss: 0.4193, Val Acc: 0.8472
Epoch 23/100, Loss: 0.3615, Acc: 0.8443, Val Loss: 0.3892, Val Acc: 0.8565
Epoch 24/100, Loss: 0.3629, Acc: 0.8431, Val Loss: 0.3963, Val Acc: 0.8590
Epoch 25/100, Loss: 0.3602, Acc: 0.8446, Val Loss: 0.4140, Val Acc: 0.8483
Epoch 26/100, Loss: 0.3595, Acc: 0.8467, Val Loss: 0.4139, Val Acc: 0.8502
Epoch 27/100, Loss: 0.3590, Acc: 0.8462, Val Loss: 0.4195, Val Acc: 0.8465
Epoch 28/100, Loss: 0.3584, Acc: 0.8442, Val Loss: 0.4120, Val Acc: 0.8565
Epoch 29/100, Loss: 0.3561, Acc: 0.8468, Val Loss: 0.4114, Val Acc: 0.8531
Epoch 30/100, Loss: 0.3569, Acc: 0.8483, Val Loss: 0.4039, Val Acc: 0.8550
Epoch 31/100, Loss: 0.3573, Acc: 0.8448, Val Loss: 0.3921, Val Acc: 0.8661
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3534, Acc: 0.8467, Val Loss: 0.4132, Val Acc: 0.8498
Epoch 33/100, Loss: 0.3521, Acc: 0.8477, Val Loss: 0.3988, Val Acc: 0.8620
Epoch 34/100, Loss: 0.3512, Acc: 0.8501, Val Loss: 0.4182, Val Acc: 0.8487
Epoch 35/100, Loss: 0.3523, Acc: 0.8486, Val Loss: 0.4086, Val Acc: 0.8579
Epoch 36/100, Loss: 0.3514, Acc: 0.8520, Val Loss: 0.4187, Val Acc: 0.8498
Epoch 37/100, Loss: 0.3512, Acc: 0.8465, Val Loss: 0.4005, Val Acc: 0.8613
Epoch 38/100, Loss: 0.3507, Acc: 0.8485, Val Loss: 0.3988, Val Acc: 0.8624
Epoch 39/100, Loss: 0.3511, Acc: 0.8496, Val Loss: 0.4220, Val Acc: 0.8517
Epoch 40/100, Loss: 0.3501, Acc: 0.8504, Val Loss: 0.4009, Val Acc: 0.8594
Epoch 41/100, Loss: 0.3512, Acc: 0.8473, Val Loss: 0.4104, Val Acc: 0.8587
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3485, Acc: 0.8491, Val Loss: 0.4055, Val Acc: 0.8594
Epoch 43/100, Loss: 0.3480, Acc: 0.8509, Val Loss: 0.4092, Val Acc: 0.8590
Epoch 44/100, Loss: 0.3475, Acc: 0.8498, Val Loss: 0.4071, Val Acc: 0.8587
Epoch 45/100, Loss: 0.3477, Acc: 0.8499, Val Loss: 0.4031, Val Acc: 0.8609
Epoch 46/100, Loss: 0.3470, Acc: 0.8500, Val Loss: 0.4121, Val Acc: 0.8565
Epoch 47/100, Loss: 0.3473, Acc: 0.8506, Val Loss: 0.4097, Val Acc: 0.8598
Epoch 48/100, Loss: 0.3473, Acc: 0.8509, Val Loss: 0.4024, Val Acc: 0.8590
Epoch 49/100, Loss: 0.3473, Acc: 0.8501, Val Loss: 0.4053, Val Acc: 0.8598
Epoch 50/100, Loss: 0.3467, Acc: 0.8504, Val Loss: 0.4197, Val Acc: 0.8509
Epoch 51/100, Loss: 0.3465, Acc: 0.8514, Val Loss: 0.4099, Val Acc: 0.8576
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3454, Acc: 0.8501, Val Loss: 0.4180, Val Acc: 0.8539
Epoch 53/100, Loss: 0.3454, Acc: 0.8507, Val Loss: 0.4160, Val Acc: 0.8557
Epoch 54/100, Loss: 0.3458, Acc: 0.8500, Val Loss: 0.4040, Val Acc: 0.8601
Epoch 55/100, Loss: 0.3453, Acc: 0.8515, Val Loss: 0.4135, Val Acc: 0.8572
Epoch 56/100, Loss: 0.3452, Acc: 0.8515, Val Loss: 0.4113, Val Acc: 0.8576
Epoch 57/100, Loss: 0.3452, Acc: 0.8513, Val Loss: 0.4055, Val Acc: 0.8594
Epoch 58/100, Loss: 0.3447, Acc: 0.8511, Val Loss: 0.4178, Val Acc: 0.8524
Epoch 59/100, Loss: 0.3452, Acc: 0.8508, Val Loss: 0.4086, Val Acc: 0.8594
Epoch 60/100, Loss: 0.3448, Acc: 0.8512, Val Loss: 0.4122, Val Acc: 0.8583
Epoch 61/100, Loss: 0.3447, Acc: 0.8500, Val Loss: 0.4108, Val Acc: 0.8579
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3442, Acc: 0.8501, Val Loss: 0.4104, Val Acc: 0.8576
Epoch 63/100, Loss: 0.3443, Acc: 0.8508, Val Loss: 0.4095, Val Acc: 0.8587
Epoch 64/100, Loss: 0.3443, Acc: 0.8507, Val Loss: 0.4050, Val Acc: 0.8601
Epoch 65/100, Loss: 0.3442, Acc: 0.8494, Val Loss: 0.4100, Val Acc: 0.8583
Epoch 66/100, Loss: 0.3441, Acc: 0.8514, Val Loss: 0.4096, Val Acc: 0.8594
Epoch 67/100, Loss: 0.3441, Acc: 0.8511, Val Loss: 0.4101, Val Acc: 0.8587
Epoch 68/100, Loss: 0.3440, Acc: 0.8507, Val Loss: 0.4098, Val Acc: 0.8583
Epoch 69/100, Loss: 0.3440, Acc: 0.8502, Val Loss: 0.4122, Val Acc: 0.8576
Epoch 70/100, Loss: 0.3441, Acc: 0.8504, Val Loss: 0.4097, Val Acc: 0.8587
Epoch 71/100, Loss: 0.3439, Acc: 0.8500, Val Loss: 0.4062, Val Acc: 0.8598
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3438, Acc: 0.8500, Val Loss: 0.4114, Val Acc: 0.8583
Epoch 73/100, Loss: 0.3437, Acc: 0.8500, Val Loss: 0.4144, Val Acc: 0.8565
Epoch 74/100, Loss: 0.3437, Acc: 0.8510, Val Loss: 0.4094, Val Acc: 0.8587
Epoch 75/100, Loss: 0.3437, Acc: 0.8501, Val Loss: 0.4106, Val Acc: 0.8579
Epoch 76/100, Loss: 0.3435, Acc: 0.8512, Val Loss: 0.4133, Val Acc: 0.8576
Epoch 77/100, Loss: 0.3436, Acc: 0.8500, Val Loss: 0.4104, Val Acc: 0.8583
Epoch 78/100, Loss: 0.3436, Acc: 0.8503, Val Loss: 0.4135, Val Acc: 0.8572
Epoch 79/100, Loss: 0.3436, Acc: 0.8514, Val Loss: 0.4086, Val Acc: 0.8594
Epoch 80/100, Loss: 0.3435, Acc: 0.8509, Val Loss: 0.4078, Val Acc: 0.8594
Epoch 81/100, Loss: 0.3435, Acc: 0.8504, Val Loss: 0.4087, Val Acc: 0.8590
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3435, Acc: 0.8506, Val Loss: 0.4111, Val Acc: 0.8594
Epoch 83/100, Loss: 0.3435, Acc: 0.8498, Val Loss: 0.4074, Val Acc: 0.8598
Epoch 84/100, Loss: 0.3434, Acc: 0.8507, Val Loss: 0.4135, Val Acc: 0.8576
Epoch 85/100, Loss: 0.3434, Acc: 0.8510, Val Loss: 0.4079, Val Acc: 0.8594
Epoch 86/100, Loss: 0.3434, Acc: 0.8509, Val Loss: 0.4113, Val Acc: 0.8590
Epoch 87/100, Loss: 0.3434, Acc: 0.8505, Val Loss: 0.4081, Val Acc: 0.8594
Epoch 88/100, Loss: 0.3433, Acc: 0.8502, Val Loss: 0.4109, Val Acc: 0.8590
Epoch 89/100, Loss: 0.3432, Acc: 0.8508, Val Loss: 0.4101, Val Acc: 0.8590
Epoch 90/100, Loss: 0.3432, Acc: 0.8511, Val Loss: 0.4085, Val Acc: 0.8598
Epoch 91/100, Loss: 0.3434, Acc: 0.8508, Val Loss: 0.4087, Val Acc: 0.8594
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3431, Acc: 0.8511, Val Loss: 0.4141, Val Acc: 0.8565
Epoch 93/100, Loss: 0.3432, Acc: 0.8509, Val Loss: 0.4139, Val Acc: 0.8565
Epoch 94/100, Loss: 0.3431, Acc: 0.8512, Val Loss: 0.4060, Val Acc: 0.8601
Epoch 95/100, Loss: 0.3431, Acc: 0.8511, Val Loss: 0.4153, Val Acc: 0.8561
Epoch 96/100, Loss: 0.3431, Acc: 0.8513, Val Loss: 0.4088, Val Acc: 0.8594
Epoch 97/100, Loss: 0.3430, Acc: 0.8509, Val Loss: 0.4112, Val Acc: 0.8587
Epoch 98/100, Loss: 0.3430, Acc: 0.8509, Val Loss: 0.4113, Val Acc: 0.8587
Epoch 99/100, Loss: 0.3431, Acc: 0.8503, Val Loss: 0.4115, Val Acc: 0.8590
Epoch 100/100, Loss: 0.3429, Acc: 0.8511, Val Loss: 0.4093, Val Acc: 0.8598

##############################
Resultados para principal:  028  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11 
 {'training': [0.34291025821287474, 0.8510579576816927, 0.8649683968588393, 0.8316758747697974, 0.8479954933809032], 'validate': [0.4093092894398196, 0.8597785977859779, 0.985, 0.7296296296296296, 0.8382978723404255], 'test': [0.7965579504533759, 0.6200589970501474, 1.0, 0.2378698224852071, 0.384321223709369]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  033  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  033  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  033  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6866, Acc: 0.5531, Val Loss: 0.6881, Val Acc: 0.5572
Mejor modelo guardado con Val Loss: 0.6881
Epoch 2/100, Loss: 0.6869, Acc: 0.5557, Val Loss: 0.6900, Val Acc: 0.5328
Epoch 3/100, Loss: 0.6842, Acc: 0.5709, Val Loss: 0.6949, Val Acc: 0.4886
Epoch 4/100, Loss: 0.6853, Acc: 0.5784, Val Loss: 0.6986, Val Acc: 0.4708
Epoch 5/100, Loss: 0.6834, Acc: 0.5799, Val Loss: 0.7028, Val Acc: 0.4579
Epoch 6/100, Loss: 0.6795, Acc: 0.5908, Val Loss: 0.7069, Val Acc: 0.4535
Epoch 7/100, Loss: 0.6766, Acc: 0.5929, Val Loss: 0.7050, Val Acc: 0.4705
Epoch 8/100, Loss: 0.6758, Acc: 0.5909, Val Loss: 0.7119, Val Acc: 0.4605
Epoch 9/100, Loss: 0.6772, Acc: 0.5870, Val Loss: 0.7167, Val Acc: 0.4494
Epoch 10/100, Loss: 0.6729, Acc: 0.5946, Val Loss: 0.7144, Val Acc: 0.4579
Epoch 11/100, Loss: 0.6698, Acc: 0.5966, Val Loss: 0.7198, Val Acc: 0.4576
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6670, Acc: 0.6043, Val Loss: 0.7175, Val Acc: 0.4613
Epoch 13/100, Loss: 0.6668, Acc: 0.6029, Val Loss: 0.7122, Val Acc: 0.4664
Epoch 14/100, Loss: 0.6664, Acc: 0.6035, Val Loss: 0.7240, Val Acc: 0.4583
Epoch 15/100, Loss: 0.6653, Acc: 0.6075, Val Loss: 0.7214, Val Acc: 0.4587
Epoch 16/100, Loss: 0.6658, Acc: 0.6030, Val Loss: 0.7294, Val Acc: 0.4554
Epoch 17/100, Loss: 0.6641, Acc: 0.6085, Val Loss: 0.7225, Val Acc: 0.4598
Epoch 18/100, Loss: 0.6634, Acc: 0.6099, Val Loss: 0.7283, Val Acc: 0.4605
Epoch 19/100, Loss: 0.6642, Acc: 0.6013, Val Loss: 0.7305, Val Acc: 0.4601
Epoch 20/100, Loss: 0.6618, Acc: 0.6090, Val Loss: 0.7254, Val Acc: 0.4590
Epoch 21/100, Loss: 0.6610, Acc: 0.6088, Val Loss: 0.7174, Val Acc: 0.4775
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6594, Acc: 0.6086, Val Loss: 0.7214, Val Acc: 0.4786
Epoch 23/100, Loss: 0.6593, Acc: 0.6102, Val Loss: 0.7266, Val Acc: 0.4627
Epoch 24/100, Loss: 0.6589, Acc: 0.6073, Val Loss: 0.7261, Val Acc: 0.4579
Epoch 25/100, Loss: 0.6591, Acc: 0.6114, Val Loss: 0.7318, Val Acc: 0.4734
Epoch 26/100, Loss: 0.6584, Acc: 0.6093, Val Loss: 0.7235, Val Acc: 0.4697
Epoch 27/100, Loss: 0.6581, Acc: 0.6117, Val Loss: 0.7376, Val Acc: 0.4642
Epoch 28/100, Loss: 0.6570, Acc: 0.6109, Val Loss: 0.7363, Val Acc: 0.4686
Epoch 29/100, Loss: 0.6574, Acc: 0.6144, Val Loss: 0.7328, Val Acc: 0.4609
Epoch 30/100, Loss: 0.6569, Acc: 0.6123, Val Loss: 0.7329, Val Acc: 0.4720
Epoch 31/100, Loss: 0.6567, Acc: 0.6134, Val Loss: 0.7311, Val Acc: 0.4590
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6562, Acc: 0.6125, Val Loss: 0.7331, Val Acc: 0.4723
Epoch 33/100, Loss: 0.6567, Acc: 0.6135, Val Loss: 0.7369, Val Acc: 0.4764
Epoch 34/100, Loss: 0.6559, Acc: 0.6118, Val Loss: 0.7393, Val Acc: 0.4624
Epoch 35/100, Loss: 0.6559, Acc: 0.6133, Val Loss: 0.7328, Val Acc: 0.4609
Epoch 36/100, Loss: 0.6554, Acc: 0.6143, Val Loss: 0.7325, Val Acc: 0.4657
Epoch 37/100, Loss: 0.6552, Acc: 0.6153, Val Loss: 0.7402, Val Acc: 0.4631
Epoch 38/100, Loss: 0.6551, Acc: 0.6137, Val Loss: 0.7358, Val Acc: 0.4594
Epoch 39/100, Loss: 0.6550, Acc: 0.6128, Val Loss: 0.7375, Val Acc: 0.4867
Epoch 40/100, Loss: 0.6547, Acc: 0.6139, Val Loss: 0.7238, Val Acc: 0.4812
Epoch 41/100, Loss: 0.6545, Acc: 0.6139, Val Loss: 0.7395, Val Acc: 0.4815
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6542, Acc: 0.6149, Val Loss: 0.7371, Val Acc: 0.4668
Epoch 43/100, Loss: 0.6536, Acc: 0.6157, Val Loss: 0.7354, Val Acc: 0.4701
Epoch 44/100, Loss: 0.6537, Acc: 0.6158, Val Loss: 0.7316, Val Acc: 0.4679
Epoch 45/100, Loss: 0.6537, Acc: 0.6160, Val Loss: 0.7346, Val Acc: 0.4642
Epoch 46/100, Loss: 0.6536, Acc: 0.6155, Val Loss: 0.7362, Val Acc: 0.4712
Epoch 47/100, Loss: 0.6532, Acc: 0.6170, Val Loss: 0.7412, Val Acc: 0.4771
Epoch 48/100, Loss: 0.6532, Acc: 0.6165, Val Loss: 0.7349, Val Acc: 0.4653
Epoch 49/100, Loss: 0.6533, Acc: 0.6161, Val Loss: 0.7364, Val Acc: 0.4613
Epoch 50/100, Loss: 0.6532, Acc: 0.6172, Val Loss: 0.7371, Val Acc: 0.4657
Epoch 51/100, Loss: 0.6530, Acc: 0.6159, Val Loss: 0.7336, Val Acc: 0.4686
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6528, Acc: 0.6155, Val Loss: 0.7342, Val Acc: 0.4690
Epoch 53/100, Loss: 0.6528, Acc: 0.6151, Val Loss: 0.7346, Val Acc: 0.4679
Epoch 54/100, Loss: 0.6532, Acc: 0.6152, Val Loss: 0.7361, Val Acc: 0.4664
Epoch 55/100, Loss: 0.6525, Acc: 0.6165, Val Loss: 0.7374, Val Acc: 0.4686
Epoch 56/100, Loss: 0.6526, Acc: 0.6161, Val Loss: 0.7374, Val Acc: 0.4649
Epoch 57/100, Loss: 0.6524, Acc: 0.6172, Val Loss: 0.7322, Val Acc: 0.4708
Epoch 58/100, Loss: 0.6525, Acc: 0.6155, Val Loss: 0.7368, Val Acc: 0.4646
Epoch 59/100, Loss: 0.6522, Acc: 0.6167, Val Loss: 0.7331, Val Acc: 0.4649
Epoch 60/100, Loss: 0.6524, Acc: 0.6163, Val Loss: 0.7404, Val Acc: 0.4764
Epoch 61/100, Loss: 0.6523, Acc: 0.6182, Val Loss: 0.7396, Val Acc: 0.4635
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6522, Acc: 0.6163, Val Loss: 0.7369, Val Acc: 0.4661
Epoch 63/100, Loss: 0.6522, Acc: 0.6162, Val Loss: 0.7362, Val Acc: 0.4668
Epoch 64/100, Loss: 0.6523, Acc: 0.6168, Val Loss: 0.7370, Val Acc: 0.4661
Epoch 65/100, Loss: 0.6521, Acc: 0.6164, Val Loss: 0.7371, Val Acc: 0.4683
Epoch 66/100, Loss: 0.6521, Acc: 0.6174, Val Loss: 0.7375, Val Acc: 0.4679
Epoch 67/100, Loss: 0.6521, Acc: 0.6177, Val Loss: 0.7377, Val Acc: 0.4649
Epoch 68/100, Loss: 0.6521, Acc: 0.6171, Val Loss: 0.7368, Val Acc: 0.4668
Epoch 69/100, Loss: 0.6520, Acc: 0.6159, Val Loss: 0.7381, Val Acc: 0.4638
Epoch 70/100, Loss: 0.6520, Acc: 0.6164, Val Loss: 0.7384, Val Acc: 0.4642
Epoch 71/100, Loss: 0.6520, Acc: 0.6169, Val Loss: 0.7386, Val Acc: 0.4642
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6520, Acc: 0.6172, Val Loss: 0.7378, Val Acc: 0.4672
Epoch 73/100, Loss: 0.6519, Acc: 0.6163, Val Loss: 0.7383, Val Acc: 0.4627
Epoch 74/100, Loss: 0.6519, Acc: 0.6165, Val Loss: 0.7377, Val Acc: 0.4675
Epoch 75/100, Loss: 0.6519, Acc: 0.6170, Val Loss: 0.7383, Val Acc: 0.4627
Epoch 76/100, Loss: 0.6518, Acc: 0.6167, Val Loss: 0.7383, Val Acc: 0.4646
Epoch 77/100, Loss: 0.6517, Acc: 0.6166, Val Loss: 0.7371, Val Acc: 0.4646
Epoch 78/100, Loss: 0.6518, Acc: 0.6169, Val Loss: 0.7372, Val Acc: 0.4683
Epoch 79/100, Loss: 0.6517, Acc: 0.6172, Val Loss: 0.7377, Val Acc: 0.4672
Epoch 80/100, Loss: 0.6517, Acc: 0.6166, Val Loss: 0.7375, Val Acc: 0.4672
Epoch 81/100, Loss: 0.6517, Acc: 0.6170, Val Loss: 0.7382, Val Acc: 0.4638
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6517, Acc: 0.6167, Val Loss: 0.7381, Val Acc: 0.4646
Epoch 83/100, Loss: 0.6517, Acc: 0.6166, Val Loss: 0.7379, Val Acc: 0.4657
Epoch 84/100, Loss: 0.6516, Acc: 0.6178, Val Loss: 0.7376, Val Acc: 0.4664
Epoch 85/100, Loss: 0.6516, Acc: 0.6175, Val Loss: 0.7379, Val Acc: 0.4661
Epoch 86/100, Loss: 0.6516, Acc: 0.6170, Val Loss: 0.7380, Val Acc: 0.4649
Epoch 87/100, Loss: 0.6516, Acc: 0.6171, Val Loss: 0.7385, Val Acc: 0.4631
Epoch 88/100, Loss: 0.6515, Acc: 0.6178, Val Loss: 0.7374, Val Acc: 0.4664
Epoch 89/100, Loss: 0.6515, Acc: 0.6167, Val Loss: 0.7380, Val Acc: 0.4664
Epoch 90/100, Loss: 0.6515, Acc: 0.6165, Val Loss: 0.7369, Val Acc: 0.4668
Epoch 91/100, Loss: 0.6515, Acc: 0.6167, Val Loss: 0.7379, Val Acc: 0.4672
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6515, Acc: 0.6171, Val Loss: 0.7379, Val Acc: 0.4668
Epoch 93/100, Loss: 0.6515, Acc: 0.6167, Val Loss: 0.7378, Val Acc: 0.4668
Epoch 94/100, Loss: 0.6514, Acc: 0.6168, Val Loss: 0.7375, Val Acc: 0.4683
Epoch 95/100, Loss: 0.6514, Acc: 0.6177, Val Loss: 0.7378, Val Acc: 0.4668
Epoch 96/100, Loss: 0.6514, Acc: 0.6172, Val Loss: 0.7376, Val Acc: 0.4672
Epoch 97/100, Loss: 0.6514, Acc: 0.6174, Val Loss: 0.7379, Val Acc: 0.4668
Epoch 98/100, Loss: 0.6514, Acc: 0.6169, Val Loss: 0.7382, Val Acc: 0.4661
Epoch 99/100, Loss: 0.6514, Acc: 0.6178, Val Loss: 0.7374, Val Acc: 0.4661
Epoch 100/100, Loss: 0.6513, Acc: 0.6170, Val Loss: 0.7376, Val Acc: 0.4661

##############################
Resultados para principal:  033  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11 
 {'training': [0.6513394364328042, 0.6170193192272309, 0.6889352818371608, 0.425414364640884, 0.5260161675964933], 'validate': [0.7375531570855961, 0.4660516605166052, 0.43975155279503103, 0.26222222222222225, 0.328538283062645], 'test': [0.6894072384204505, 0.5536873156342182, 0.6338880484114977, 0.24792899408284025, 0.3564440663547427]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  026  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  026  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  026  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6642, Acc: 0.6247, Val Loss: 0.7610, Val Acc: 0.3391
Mejor modelo guardado con Val Loss: 0.7610
Epoch 2/100, Loss: 0.6391, Acc: 0.6606, Val Loss: 0.7724, Val Acc: 0.4077
Epoch 3/100, Loss: 0.6213, Acc: 0.6801, Val Loss: 0.7904, Val Acc: 0.4554
Epoch 4/100, Loss: 0.6046, Acc: 0.6879, Val Loss: 0.8334, Val Acc: 0.3871
Epoch 5/100, Loss: 0.6188, Acc: 0.6751, Val Loss: 0.7490, Val Acc: 0.4823
Mejor modelo guardado con Val Loss: 0.7490
Epoch 6/100, Loss: 0.6198, Acc: 0.6817, Val Loss: 0.7976, Val Acc: 0.3745
Epoch 7/100, Loss: 0.5999, Acc: 0.6968, Val Loss: 0.7995, Val Acc: 0.4369
Epoch 8/100, Loss: 0.5876, Acc: 0.7092, Val Loss: 0.8116, Val Acc: 0.3624
Epoch 9/100, Loss: 0.5814, Acc: 0.7059, Val Loss: 0.8438, Val Acc: 0.4107
Epoch 10/100, Loss: 0.5783, Acc: 0.7158, Val Loss: 0.8502, Val Acc: 0.4114
Epoch 11/100, Loss: 0.5789, Acc: 0.7098, Val Loss: 0.8011, Val Acc: 0.4856
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5681, Acc: 0.7192, Val Loss: 0.8558, Val Acc: 0.4070
Epoch 13/100, Loss: 0.5604, Acc: 0.7279, Val Loss: 0.8505, Val Acc: 0.4280
Epoch 14/100, Loss: 0.5550, Acc: 0.7326, Val Loss: 0.8536, Val Acc: 0.4288
Epoch 15/100, Loss: 0.5563, Acc: 0.7301, Val Loss: 0.8556, Val Acc: 0.4207
Epoch 16/100, Loss: 0.5490, Acc: 0.7378, Val Loss: 0.8872, Val Acc: 0.4044
Epoch 17/100, Loss: 0.5495, Acc: 0.7356, Val Loss: 0.8743, Val Acc: 0.4328
Epoch 18/100, Loss: 0.5458, Acc: 0.7369, Val Loss: 0.9232, Val Acc: 0.3771
Epoch 19/100, Loss: 0.5436, Acc: 0.7394, Val Loss: 0.9045, Val Acc: 0.3948
Epoch 20/100, Loss: 0.5465, Acc: 0.7367, Val Loss: 0.9176, Val Acc: 0.4203
Epoch 21/100, Loss: 0.5418, Acc: 0.7401, Val Loss: 0.9235, Val Acc: 0.4066
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5368, Acc: 0.7412, Val Loss: 0.9505, Val Acc: 0.3819
Epoch 23/100, Loss: 0.5371, Acc: 0.7443, Val Loss: 0.9183, Val Acc: 0.4269
Epoch 24/100, Loss: 0.5343, Acc: 0.7438, Val Loss: 0.9259, Val Acc: 0.4103
Epoch 25/100, Loss: 0.5341, Acc: 0.7456, Val Loss: 0.9411, Val Acc: 0.3889
Epoch 26/100, Loss: 0.5321, Acc: 0.7496, Val Loss: 0.9477, Val Acc: 0.3856
Epoch 27/100, Loss: 0.5317, Acc: 0.7454, Val Loss: 0.9282, Val Acc: 0.4092
Epoch 28/100, Loss: 0.5328, Acc: 0.7434, Val Loss: 0.9334, Val Acc: 0.4030
Epoch 29/100, Loss: 0.5302, Acc: 0.7467, Val Loss: 0.9338, Val Acc: 0.4188
Epoch 30/100, Loss: 0.5278, Acc: 0.7509, Val Loss: 0.9473, Val Acc: 0.4004
Epoch 31/100, Loss: 0.5287, Acc: 0.7466, Val Loss: 0.9502, Val Acc: 0.3657
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5261, Acc: 0.7509, Val Loss: 0.9495, Val Acc: 0.3893
Epoch 33/100, Loss: 0.5240, Acc: 0.7526, Val Loss: 0.9593, Val Acc: 0.3863
Epoch 34/100, Loss: 0.5245, Acc: 0.7522, Val Loss: 0.9400, Val Acc: 0.4030
Epoch 35/100, Loss: 0.5258, Acc: 0.7457, Val Loss: 0.9379, Val Acc: 0.4114
Epoch 36/100, Loss: 0.5238, Acc: 0.7503, Val Loss: 0.9148, Val Acc: 0.4443
Epoch 37/100, Loss: 0.5235, Acc: 0.7516, Val Loss: 0.9546, Val Acc: 0.3941
Epoch 38/100, Loss: 0.5227, Acc: 0.7521, Val Loss: 0.9348, Val Acc: 0.4203
Epoch 39/100, Loss: 0.5239, Acc: 0.7507, Val Loss: 0.9646, Val Acc: 0.3941
Epoch 40/100, Loss: 0.5226, Acc: 0.7515, Val Loss: 0.9439, Val Acc: 0.4059
Epoch 41/100, Loss: 0.5219, Acc: 0.7532, Val Loss: 0.9655, Val Acc: 0.3967
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5213, Acc: 0.7527, Val Loss: 0.9444, Val Acc: 0.4181
Epoch 43/100, Loss: 0.5205, Acc: 0.7530, Val Loss: 0.9458, Val Acc: 0.4129
Epoch 44/100, Loss: 0.5206, Acc: 0.7536, Val Loss: 0.9412, Val Acc: 0.4214
Epoch 45/100, Loss: 0.5200, Acc: 0.7554, Val Loss: 0.9600, Val Acc: 0.3989
Epoch 46/100, Loss: 0.5201, Acc: 0.7537, Val Loss: 0.9761, Val Acc: 0.3863
Epoch 47/100, Loss: 0.5208, Acc: 0.7531, Val Loss: 0.9667, Val Acc: 0.3959
Epoch 48/100, Loss: 0.5206, Acc: 0.7534, Val Loss: 0.9748, Val Acc: 0.3904
Epoch 49/100, Loss: 0.5200, Acc: 0.7520, Val Loss: 0.9764, Val Acc: 0.3875
Epoch 50/100, Loss: 0.5195, Acc: 0.7542, Val Loss: 0.9490, Val Acc: 0.4166
Epoch 51/100, Loss: 0.5192, Acc: 0.7531, Val Loss: 0.9538, Val Acc: 0.4085
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5184, Acc: 0.7537, Val Loss: 0.9529, Val Acc: 0.4133
Epoch 53/100, Loss: 0.5184, Acc: 0.7546, Val Loss: 0.9649, Val Acc: 0.3978
Epoch 54/100, Loss: 0.5184, Acc: 0.7538, Val Loss: 0.9633, Val Acc: 0.4026
Epoch 55/100, Loss: 0.5181, Acc: 0.7548, Val Loss: 0.9535, Val Acc: 0.4111
Epoch 56/100, Loss: 0.5181, Acc: 0.7533, Val Loss: 0.9619, Val Acc: 0.4015
Epoch 57/100, Loss: 0.5183, Acc: 0.7548, Val Loss: 0.9668, Val Acc: 0.3996
Epoch 58/100, Loss: 0.5179, Acc: 0.7557, Val Loss: 0.9523, Val Acc: 0.4166
Epoch 59/100, Loss: 0.5180, Acc: 0.7558, Val Loss: 0.9582, Val Acc: 0.4052
Epoch 60/100, Loss: 0.5175, Acc: 0.7543, Val Loss: 0.9632, Val Acc: 0.4004
Epoch 61/100, Loss: 0.5177, Acc: 0.7544, Val Loss: 0.9617, Val Acc: 0.4022
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5174, Acc: 0.7544, Val Loss: 0.9674, Val Acc: 0.3985
Epoch 63/100, Loss: 0.5172, Acc: 0.7550, Val Loss: 0.9654, Val Acc: 0.4018
Epoch 64/100, Loss: 0.5173, Acc: 0.7553, Val Loss: 0.9646, Val Acc: 0.4015
Epoch 65/100, Loss: 0.5172, Acc: 0.7544, Val Loss: 0.9652, Val Acc: 0.4022
Epoch 66/100, Loss: 0.5170, Acc: 0.7551, Val Loss: 0.9667, Val Acc: 0.4026
Epoch 67/100, Loss: 0.5170, Acc: 0.7539, Val Loss: 0.9678, Val Acc: 0.3989
Epoch 68/100, Loss: 0.5171, Acc: 0.7545, Val Loss: 0.9624, Val Acc: 0.4026
Epoch 69/100, Loss: 0.5170, Acc: 0.7546, Val Loss: 0.9679, Val Acc: 0.3993
Epoch 70/100, Loss: 0.5169, Acc: 0.7556, Val Loss: 0.9637, Val Acc: 0.4022
Epoch 71/100, Loss: 0.5168, Acc: 0.7544, Val Loss: 0.9668, Val Acc: 0.3996
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5166, Acc: 0.7557, Val Loss: 0.9662, Val Acc: 0.4015
Epoch 73/100, Loss: 0.5166, Acc: 0.7539, Val Loss: 0.9605, Val Acc: 0.4048
Epoch 74/100, Loss: 0.5166, Acc: 0.7546, Val Loss: 0.9662, Val Acc: 0.4018
Epoch 75/100, Loss: 0.5166, Acc: 0.7541, Val Loss: 0.9652, Val Acc: 0.4018
Epoch 76/100, Loss: 0.5166, Acc: 0.7547, Val Loss: 0.9638, Val Acc: 0.4022
Epoch 77/100, Loss: 0.5165, Acc: 0.7548, Val Loss: 0.9615, Val Acc: 0.4044
Epoch 78/100, Loss: 0.5166, Acc: 0.7539, Val Loss: 0.9652, Val Acc: 0.4015
Epoch 79/100, Loss: 0.5164, Acc: 0.7541, Val Loss: 0.9650, Val Acc: 0.4022
Epoch 80/100, Loss: 0.5163, Acc: 0.7559, Val Loss: 0.9726, Val Acc: 0.3970
Epoch 81/100, Loss: 0.5162, Acc: 0.7558, Val Loss: 0.9613, Val Acc: 0.4041
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5166, Acc: 0.7557, Val Loss: 0.9666, Val Acc: 0.4022
Epoch 83/100, Loss: 0.5164, Acc: 0.7545, Val Loss: 0.9652, Val Acc: 0.4015
Epoch 84/100, Loss: 0.5163, Acc: 0.7546, Val Loss: 0.9656, Val Acc: 0.4018
Epoch 85/100, Loss: 0.5161, Acc: 0.7542, Val Loss: 0.9738, Val Acc: 0.3970
Epoch 86/100, Loss: 0.5161, Acc: 0.7548, Val Loss: 0.9741, Val Acc: 0.3970
Epoch 87/100, Loss: 0.5161, Acc: 0.7559, Val Loss: 0.9689, Val Acc: 0.4018
Epoch 88/100, Loss: 0.5161, Acc: 0.7551, Val Loss: 0.9681, Val Acc: 0.4011
Epoch 89/100, Loss: 0.5160, Acc: 0.7546, Val Loss: 0.9692, Val Acc: 0.4018
Epoch 90/100, Loss: 0.5160, Acc: 0.7547, Val Loss: 0.9700, Val Acc: 0.4015
Epoch 91/100, Loss: 0.5160, Acc: 0.7545, Val Loss: 0.9689, Val Acc: 0.4015
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5157, Acc: 0.7564, Val Loss: 0.9645, Val Acc: 0.4037
Epoch 93/100, Loss: 0.5160, Acc: 0.7549, Val Loss: 0.9711, Val Acc: 0.4015
Epoch 94/100, Loss: 0.5157, Acc: 0.7549, Val Loss: 0.9662, Val Acc: 0.4033
Epoch 95/100, Loss: 0.5159, Acc: 0.7554, Val Loss: 0.9662, Val Acc: 0.4033
Epoch 96/100, Loss: 0.5159, Acc: 0.7556, Val Loss: 0.9716, Val Acc: 0.4004
Epoch 97/100, Loss: 0.5157, Acc: 0.7566, Val Loss: 0.9674, Val Acc: 0.4037
Epoch 98/100, Loss: 0.5158, Acc: 0.7549, Val Loss: 0.9680, Val Acc: 0.4041
Epoch 99/100, Loss: 0.5156, Acc: 0.7549, Val Loss: 0.9759, Val Acc: 0.4000
Epoch 100/100, Loss: 0.5155, Acc: 0.7555, Val Loss: 0.9754, Val Acc: 0.4022

##############################
Resultados para principal:  026  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11 
 {'training': [0.5155030051830611, 0.7554737810487581, 0.7503612716763006, 0.7650092081031308, 0.757614444647091], 'validate': [0.9753617387871409, 0.4022140221402214, 0.40559440559440557, 0.42962962962962964, 0.4172661870503597], 'test': [0.6760669665516548, 0.5899705014749262, 0.5589159465828751, 0.8420118343195266, 0.6718602455146364]}

######################################## 
########################################
Grupo en indetificación:  ['064', '060', '028', '033', '026', '110']  --- principal:  110  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  110  --- group:  ['064', '060', '028', '033', '026', '110']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  110  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6026, Acc: 0.7148, Val Loss: 0.5357, Val Acc: 0.7948
Mejor modelo guardado con Val Loss: 0.5357
Epoch 2/100, Loss: 0.5085, Acc: 0.7759, Val Loss: 0.4854, Val Acc: 0.7679
Mejor modelo guardado con Val Loss: 0.4854
Epoch 3/100, Loss: 0.4669, Acc: 0.7848, Val Loss: 0.5422, Val Acc: 0.6959
Epoch 4/100, Loss: 0.4300, Acc: 0.8007, Val Loss: 0.5003, Val Acc: 0.7358
Epoch 5/100, Loss: 0.4262, Acc: 0.8040, Val Loss: 0.4624, Val Acc: 0.7661
Mejor modelo guardado con Val Loss: 0.4624
Epoch 6/100, Loss: 0.4184, Acc: 0.8098, Val Loss: 0.4036, Val Acc: 0.8395
Mejor modelo guardado con Val Loss: 0.4036
Epoch 7/100, Loss: 0.4152, Acc: 0.8083, Val Loss: 0.4763, Val Acc: 0.7568
Epoch 8/100, Loss: 0.4028, Acc: 0.8141, Val Loss: 0.5650, Val Acc: 0.7074
Epoch 9/100, Loss: 0.4078, Acc: 0.8130, Val Loss: 0.4245, Val Acc: 0.7915
Epoch 10/100, Loss: 0.4036, Acc: 0.8151, Val Loss: 0.4354, Val Acc: 0.8114
Epoch 11/100, Loss: 0.3939, Acc: 0.8226, Val Loss: 0.4092, Val Acc: 0.8033
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3825, Acc: 0.8271, Val Loss: 0.4095, Val Acc: 0.7982
Epoch 13/100, Loss: 0.3830, Acc: 0.8302, Val Loss: 0.3906, Val Acc: 0.8188
Mejor modelo guardado con Val Loss: 0.3906
Epoch 14/100, Loss: 0.3754, Acc: 0.8325, Val Loss: 0.5804, Val Acc: 0.7177
Epoch 15/100, Loss: 0.3785, Acc: 0.8308, Val Loss: 0.4838, Val Acc: 0.7601
Epoch 16/100, Loss: 0.3800, Acc: 0.8301, Val Loss: 0.4539, Val Acc: 0.7705
Epoch 17/100, Loss: 0.3748, Acc: 0.8315, Val Loss: 0.5391, Val Acc: 0.7273
Epoch 18/100, Loss: 0.3835, Acc: 0.8286, Val Loss: 0.3882, Val Acc: 0.8417
Mejor modelo guardado con Val Loss: 0.3882
Epoch 19/100, Loss: 0.3863, Acc: 0.8250, Val Loss: 0.4642, Val Acc: 0.7646
Epoch 20/100, Loss: 0.3660, Acc: 0.8392, Val Loss: 0.5480, Val Acc: 0.7151
Epoch 21/100, Loss: 0.3701, Acc: 0.8348, Val Loss: 0.4312, Val Acc: 0.7963
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3633, Acc: 0.8410, Val Loss: 0.4783, Val Acc: 0.7631
Epoch 23/100, Loss: 0.3602, Acc: 0.8419, Val Loss: 0.4634, Val Acc: 0.7779
Epoch 24/100, Loss: 0.3614, Acc: 0.8421, Val Loss: 0.4565, Val Acc: 0.7716
Epoch 25/100, Loss: 0.3619, Acc: 0.8424, Val Loss: 0.4107, Val Acc: 0.7989
Epoch 26/100, Loss: 0.3626, Acc: 0.8419, Val Loss: 0.5020, Val Acc: 0.7498
Epoch 27/100, Loss: 0.3587, Acc: 0.8457, Val Loss: 0.4556, Val Acc: 0.7801
Epoch 28/100, Loss: 0.3582, Acc: 0.8450, Val Loss: 0.5929, Val Acc: 0.6956
Epoch 29/100, Loss: 0.3620, Acc: 0.8389, Val Loss: 0.5078, Val Acc: 0.7369
Epoch 30/100, Loss: 0.3572, Acc: 0.8454, Val Loss: 0.5157, Val Acc: 0.7432
Epoch 31/100, Loss: 0.3557, Acc: 0.8435, Val Loss: 0.4805, Val Acc: 0.7642
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3529, Acc: 0.8463, Val Loss: 0.4823, Val Acc: 0.7565
Epoch 33/100, Loss: 0.3530, Acc: 0.8445, Val Loss: 0.5195, Val Acc: 0.7332
Epoch 34/100, Loss: 0.3533, Acc: 0.8443, Val Loss: 0.5142, Val Acc: 0.7380
Epoch 35/100, Loss: 0.3516, Acc: 0.8482, Val Loss: 0.4850, Val Acc: 0.7601
Epoch 36/100, Loss: 0.3524, Acc: 0.8452, Val Loss: 0.4778, Val Acc: 0.7609
Epoch 37/100, Loss: 0.3502, Acc: 0.8466, Val Loss: 0.4715, Val Acc: 0.7697
Epoch 38/100, Loss: 0.3494, Acc: 0.8480, Val Loss: 0.4410, Val Acc: 0.7834
Epoch 39/100, Loss: 0.3515, Acc: 0.8478, Val Loss: 0.4956, Val Acc: 0.7472
Epoch 40/100, Loss: 0.3499, Acc: 0.8483, Val Loss: 0.5210, Val Acc: 0.7365
Epoch 41/100, Loss: 0.3501, Acc: 0.8477, Val Loss: 0.4612, Val Acc: 0.7749
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3472, Acc: 0.8482, Val Loss: 0.4717, Val Acc: 0.7701
Epoch 43/100, Loss: 0.3470, Acc: 0.8501, Val Loss: 0.4940, Val Acc: 0.7565
Epoch 44/100, Loss: 0.3469, Acc: 0.8491, Val Loss: 0.4805, Val Acc: 0.7620
Epoch 45/100, Loss: 0.3477, Acc: 0.8468, Val Loss: 0.4820, Val Acc: 0.7631
Epoch 46/100, Loss: 0.3463, Acc: 0.8493, Val Loss: 0.5016, Val Acc: 0.7506
Epoch 47/100, Loss: 0.3465, Acc: 0.8495, Val Loss: 0.4873, Val Acc: 0.7576
Epoch 48/100, Loss: 0.3459, Acc: 0.8508, Val Loss: 0.4652, Val Acc: 0.7694
Epoch 49/100, Loss: 0.3457, Acc: 0.8504, Val Loss: 0.4871, Val Acc: 0.7620
Epoch 50/100, Loss: 0.3458, Acc: 0.8500, Val Loss: 0.4824, Val Acc: 0.7594
Epoch 51/100, Loss: 0.3457, Acc: 0.8508, Val Loss: 0.4341, Val Acc: 0.7867
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3451, Acc: 0.8489, Val Loss: 0.5101, Val Acc: 0.7480
Epoch 53/100, Loss: 0.3445, Acc: 0.8495, Val Loss: 0.4938, Val Acc: 0.7550
Epoch 54/100, Loss: 0.3441, Acc: 0.8501, Val Loss: 0.4758, Val Acc: 0.7653
Epoch 55/100, Loss: 0.3437, Acc: 0.8500, Val Loss: 0.4944, Val Acc: 0.7531
Epoch 56/100, Loss: 0.3441, Acc: 0.8508, Val Loss: 0.5004, Val Acc: 0.7494
Epoch 57/100, Loss: 0.3439, Acc: 0.8512, Val Loss: 0.4663, Val Acc: 0.7705
Epoch 58/100, Loss: 0.3437, Acc: 0.8511, Val Loss: 0.4908, Val Acc: 0.7572
Epoch 59/100, Loss: 0.3433, Acc: 0.8502, Val Loss: 0.4551, Val Acc: 0.7764
Epoch 60/100, Loss: 0.3435, Acc: 0.8504, Val Loss: 0.4858, Val Acc: 0.7601
Epoch 61/100, Loss: 0.3434, Acc: 0.8507, Val Loss: 0.4730, Val Acc: 0.7653
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3426, Acc: 0.8513, Val Loss: 0.4831, Val Acc: 0.7624
Epoch 63/100, Loss: 0.3428, Acc: 0.8511, Val Loss: 0.4825, Val Acc: 0.7627
Epoch 64/100, Loss: 0.3424, Acc: 0.8506, Val Loss: 0.4793, Val Acc: 0.7638
Epoch 65/100, Loss: 0.3423, Acc: 0.8509, Val Loss: 0.4968, Val Acc: 0.7531
Epoch 66/100, Loss: 0.3426, Acc: 0.8505, Val Loss: 0.4899, Val Acc: 0.7572
Epoch 67/100, Loss: 0.3425, Acc: 0.8498, Val Loss: 0.4771, Val Acc: 0.7657
Epoch 68/100, Loss: 0.3422, Acc: 0.8507, Val Loss: 0.4782, Val Acc: 0.7649
Epoch 69/100, Loss: 0.3424, Acc: 0.8511, Val Loss: 0.4793, Val Acc: 0.7657
Epoch 70/100, Loss: 0.3423, Acc: 0.8518, Val Loss: 0.4993, Val Acc: 0.7513
Epoch 71/100, Loss: 0.3424, Acc: 0.8505, Val Loss: 0.4873, Val Acc: 0.7613
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3420, Acc: 0.8514, Val Loss: 0.4842, Val Acc: 0.7616
Epoch 73/100, Loss: 0.3420, Acc: 0.8504, Val Loss: 0.4817, Val Acc: 0.7609
Epoch 74/100, Loss: 0.3418, Acc: 0.8505, Val Loss: 0.4847, Val Acc: 0.7598
Epoch 75/100, Loss: 0.3419, Acc: 0.8512, Val Loss: 0.4749, Val Acc: 0.7675
Epoch 76/100, Loss: 0.3418, Acc: 0.8516, Val Loss: 0.4781, Val Acc: 0.7653
Epoch 77/100, Loss: 0.3414, Acc: 0.8525, Val Loss: 0.5037, Val Acc: 0.7502
Epoch 78/100, Loss: 0.3418, Acc: 0.8508, Val Loss: 0.4779, Val Acc: 0.7642
Epoch 79/100, Loss: 0.3418, Acc: 0.8511, Val Loss: 0.4896, Val Acc: 0.7568
Epoch 80/100, Loss: 0.3417, Acc: 0.8511, Val Loss: 0.4895, Val Acc: 0.7572
Epoch 81/100, Loss: 0.3416, Acc: 0.8511, Val Loss: 0.4951, Val Acc: 0.7542
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3417, Acc: 0.8509, Val Loss: 0.4968, Val Acc: 0.7517
Epoch 83/100, Loss: 0.3415, Acc: 0.8511, Val Loss: 0.4789, Val Acc: 0.7638
Epoch 84/100, Loss: 0.3416, Acc: 0.8515, Val Loss: 0.4857, Val Acc: 0.7601
Epoch 85/100, Loss: 0.3415, Acc: 0.8516, Val Loss: 0.4839, Val Acc: 0.7605
Epoch 86/100, Loss: 0.3414, Acc: 0.8516, Val Loss: 0.4828, Val Acc: 0.7616
Epoch 87/100, Loss: 0.3413, Acc: 0.8503, Val Loss: 0.4767, Val Acc: 0.7653
Epoch 88/100, Loss: 0.3413, Acc: 0.8518, Val Loss: 0.4792, Val Acc: 0.7638
Epoch 89/100, Loss: 0.3415, Acc: 0.8525, Val Loss: 0.4826, Val Acc: 0.7624
Epoch 90/100, Loss: 0.3412, Acc: 0.8516, Val Loss: 0.4879, Val Acc: 0.7583
Epoch 91/100, Loss: 0.3412, Acc: 0.8515, Val Loss: 0.4906, Val Acc: 0.7565
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3412, Acc: 0.8523, Val Loss: 0.4912, Val Acc: 0.7568
Epoch 93/100, Loss: 0.3413, Acc: 0.8510, Val Loss: 0.4924, Val Acc: 0.7561
Epoch 94/100, Loss: 0.3412, Acc: 0.8519, Val Loss: 0.4733, Val Acc: 0.7690
Epoch 95/100, Loss: 0.3412, Acc: 0.8514, Val Loss: 0.4979, Val Acc: 0.7520
Epoch 96/100, Loss: 0.3410, Acc: 0.8520, Val Loss: 0.4843, Val Acc: 0.7620
Epoch 97/100, Loss: 0.3408, Acc: 0.8514, Val Loss: 0.5032, Val Acc: 0.7502
Epoch 98/100, Loss: 0.3410, Acc: 0.8511, Val Loss: 0.4779, Val Acc: 0.7661
Epoch 99/100, Loss: 0.3410, Acc: 0.8514, Val Loss: 0.4878, Val Acc: 0.7579
Epoch 100/100, Loss: 0.3411, Acc: 0.8505, Val Loss: 0.4838, Val Acc: 0.7616

##############################
Resultados para principal:  110  --- grupo:  ['064', '060', '028', '033', '026', '110']  --- window & package numer:  11 
 {'training': [0.3410565940195415, 0.8505059797608095, 0.8510795349695516, 0.8493554327808471, 0.8502166098257904], 'validate': [0.48377900509986765, 0.7616236162361624, 0.9160756501182034, 0.5740740740740741, 0.7058287795992714], 'test': [0.8511531845016299, 0.5743362831858407, 0.5439971499821874, 0.9035502958579882, 0.6791194129419613]}

##############################
Resultados para window:  11 
 {'064:060:028:033:026:110': {'training': [0.5059182659682596, 0.7472861085556578, 0.6828902522154056, 0.9224677716390424, 0.7848021934978456], 'validate': [0.7923373358194218, 0.4863468634686347, 0.4912718204488778, 0.8755555555555555, 0.6293929712460063], 'test': [0.7223270557961374, 0.487905604719764, 0.49303452453058755, 0.9633136094674556, 0.6522435897435898]}, '060:064:028:033:026:110': {'training': [0.4255506323967489, 0.7886844526218951, 0.8176840397485297, 0.7425414364640884, 0.7783032525817971], 'validate': [0.763476197109666, 0.518450184501845, 0.556390977443609, 0.16444444444444445, 0.2538593481989708], 'test': [0.9039880183507811, 0.5265486725663717, 0.5192394748755093, 0.678698224852071, 0.5883559887150551]}, '028:064:060:033:026:110': {'training': [0.34291025821287474, 0.8510579576816927, 0.8649683968588393, 0.8316758747697974, 0.8479954933809032], 'validate': [0.4093092894398196, 0.8597785977859779, 0.985, 0.7296296296296296, 0.8382978723404255], 'test': [0.7965579504533759, 0.6200589970501474, 1.0, 0.2378698224852071, 0.384321223709369]}, '033:064:060:028:026:110': {'training': [0.6513394364328042, 0.6170193192272309, 0.6889352818371608, 0.425414364640884, 0.5260161675964933], 'validate': [0.7375531570855961, 0.4660516605166052, 0.43975155279503103, 0.26222222222222225, 0.328538283062645], 'test': [0.6894072384204505, 0.5536873156342182, 0.6338880484114977, 0.24792899408284025, 0.3564440663547427]}, '026:064:060:028:033:110': {'training': [0.5155030051830611, 0.7554737810487581, 0.7503612716763006, 0.7650092081031308, 0.757614444647091], 'validate': [0.9753617387871409, 0.4022140221402214, 0.40559440559440557, 0.42962962962962964, 0.4172661870503597], 'test': [0.6760669665516548, 0.5899705014749262, 0.5589159465828751, 0.8420118343195266, 0.6718602455146364]}, '110:064:060:028:033:026': {'training': [0.3410565940195415, 0.8505059797608095, 0.8510795349695516, 0.8493554327808471, 0.8502166098257904], 'validate': [0.48377900509986765, 0.7616236162361624, 0.9160756501182034, 0.5740740740740741, 0.7058287795992714], 'test': [0.8511531845016299, 0.5743362831858407, 0.5439971499821874, 0.9035502958579882, 0.6791194129419613]}}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  104  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  104  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  104  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6845, Acc: 0.5696, Val Loss: 0.6475, Val Acc: 0.8188
Mejor modelo guardado con Val Loss: 0.6475
Epoch 2/100, Loss: 0.6818, Acc: 0.5634, Val Loss: 0.6748, Val Acc: 0.5018
Epoch 3/100, Loss: 0.6884, Acc: 0.5364, Val Loss: 0.6891, Val Acc: 0.5018
Epoch 4/100, Loss: 0.6927, Acc: 0.5153, Val Loss: 0.6932, Val Acc: 0.5015
Epoch 5/100, Loss: 0.6919, Acc: 0.5279, Val Loss: 0.6875, Val Acc: 0.7181
Epoch 6/100, Loss: 0.6915, Acc: 0.5340, Val Loss: 0.6867, Val Acc: 0.4982
Epoch 7/100, Loss: 0.6913, Acc: 0.5420, Val Loss: 0.6846, Val Acc: 0.8454
Epoch 8/100, Loss: 0.6893, Acc: 0.5583, Val Loss: 0.6899, Val Acc: 0.4982
Epoch 9/100, Loss: 0.6907, Acc: 0.5517, Val Loss: 0.6828, Val Acc: 0.5018
Epoch 10/100, Loss: 0.6904, Acc: 0.5498, Val Loss: 0.6861, Val Acc: 0.4982
Epoch 11/100, Loss: 0.6897, Acc: 0.5681, Val Loss: 0.6804, Val Acc: 0.8458
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6894, Acc: 0.5632, Val Loss: 0.6825, Val Acc: 0.7428
Epoch 13/100, Loss: 0.6891, Acc: 0.5881, Val Loss: 0.6790, Val Acc: 0.5018
Epoch 14/100, Loss: 0.6888, Acc: 0.5710, Val Loss: 0.6790, Val Acc: 0.8391
Epoch 15/100, Loss: 0.6885, Acc: 0.5919, Val Loss: 0.6773, Val Acc: 0.8565
Epoch 16/100, Loss: 0.6884, Acc: 0.5851, Val Loss: 0.6769, Val Acc: 0.5018
Epoch 17/100, Loss: 0.6882, Acc: 0.5718, Val Loss: 0.6760, Val Acc: 0.8539
Epoch 18/100, Loss: 0.6879, Acc: 0.5669, Val Loss: 0.6757, Val Acc: 0.8472
Epoch 19/100, Loss: 0.6877, Acc: 0.5916, Val Loss: 0.6789, Val Acc: 0.7948
Epoch 20/100, Loss: 0.6878, Acc: 0.5914, Val Loss: 0.6769, Val Acc: 0.7945
Epoch 21/100, Loss: 0.6872, Acc: 0.6130, Val Loss: 0.6734, Val Acc: 0.8339
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6869, Acc: 0.5797, Val Loss: 0.6767, Val Acc: 0.7716
Epoch 23/100, Loss: 0.6867, Acc: 0.6198, Val Loss: 0.6740, Val Acc: 0.8085
Epoch 24/100, Loss: 0.6867, Acc: 0.6157, Val Loss: 0.6767, Val Acc: 0.7410
Epoch 25/100, Loss: 0.6866, Acc: 0.6167, Val Loss: 0.6739, Val Acc: 0.7760
Epoch 26/100, Loss: 0.6864, Acc: 0.6021, Val Loss: 0.6726, Val Acc: 0.7908
Epoch 27/100, Loss: 0.6863, Acc: 0.6177, Val Loss: 0.6734, Val Acc: 0.8063
Epoch 28/100, Loss: 0.6861, Acc: 0.6186, Val Loss: 0.6752, Val Acc: 0.6882
Epoch 29/100, Loss: 0.6860, Acc: 0.6077, Val Loss: 0.6748, Val Acc: 0.7351
Epoch 30/100, Loss: 0.6859, Acc: 0.6184, Val Loss: 0.6709, Val Acc: 0.8166
Epoch 31/100, Loss: 0.6853, Acc: 0.6119, Val Loss: 0.6716, Val Acc: 0.7469
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6850, Acc: 0.6141, Val Loss: 0.6695, Val Acc: 0.7959
Epoch 33/100, Loss: 0.6841, Acc: 0.6146, Val Loss: 0.6651, Val Acc: 0.8247
Epoch 34/100, Loss: 0.6836, Acc: 0.6190, Val Loss: 0.6654, Val Acc: 0.7642
Epoch 35/100, Loss: 0.6832, Acc: 0.6098, Val Loss: 0.6610, Val Acc: 0.8092
Epoch 36/100, Loss: 0.6823, Acc: 0.6152, Val Loss: 0.6588, Val Acc: 0.8299
Epoch 37/100, Loss: 0.6818, Acc: 0.6161, Val Loss: 0.6574, Val Acc: 0.7830
Epoch 38/100, Loss: 0.6811, Acc: 0.6124, Val Loss: 0.6535, Val Acc: 0.8066
Epoch 39/100, Loss: 0.6804, Acc: 0.6145, Val Loss: 0.6521, Val Acc: 0.7712
Epoch 40/100, Loss: 0.6797, Acc: 0.6095, Val Loss: 0.6480, Val Acc: 0.8070
Epoch 41/100, Loss: 0.6790, Acc: 0.6135, Val Loss: 0.6456, Val Acc: 0.7790
Mejor modelo guardado con Val Loss: 0.6456
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6783, Acc: 0.6121, Val Loss: 0.6446, Val Acc: 0.7852
Mejor modelo guardado con Val Loss: 0.6446
Epoch 43/100, Loss: 0.6780, Acc: 0.6056, Val Loss: 0.6439, Val Acc: 0.7727
Mejor modelo guardado con Val Loss: 0.6439
Epoch 44/100, Loss: 0.6776, Acc: 0.6098, Val Loss: 0.6412, Val Acc: 0.8022
Mejor modelo guardado con Val Loss: 0.6412
Epoch 45/100, Loss: 0.6772, Acc: 0.6069, Val Loss: 0.6397, Val Acc: 0.7985
Mejor modelo guardado con Val Loss: 0.6397
Epoch 46/100, Loss: 0.6768, Acc: 0.6052, Val Loss: 0.6379, Val Acc: 0.8129
Mejor modelo guardado con Val Loss: 0.6379
Epoch 47/100, Loss: 0.6765, Acc: 0.6098, Val Loss: 0.6371, Val Acc: 0.8041
Mejor modelo guardado con Val Loss: 0.6371
Epoch 48/100, Loss: 0.6762, Acc: 0.6084, Val Loss: 0.6358, Val Acc: 0.7915
Mejor modelo guardado con Val Loss: 0.6358
Epoch 49/100, Loss: 0.6759, Acc: 0.6078, Val Loss: 0.6388, Val Acc: 0.7376
Epoch 50/100, Loss: 0.6755, Acc: 0.6080, Val Loss: 0.6361, Val Acc: 0.7494
Epoch 51/100, Loss: 0.6750, Acc: 0.6075, Val Loss: 0.6335, Val Acc: 0.7815
Mejor modelo guardado con Val Loss: 0.6335
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6747, Acc: 0.6091, Val Loss: 0.6323, Val Acc: 0.7801
Mejor modelo guardado con Val Loss: 0.6323
Epoch 53/100, Loss: 0.6745, Acc: 0.6081, Val Loss: 0.6319, Val Acc: 0.7727
Mejor modelo guardado con Val Loss: 0.6319
Epoch 54/100, Loss: 0.6743, Acc: 0.6084, Val Loss: 0.6311, Val Acc: 0.7771
Mejor modelo guardado con Val Loss: 0.6311
Epoch 55/100, Loss: 0.6742, Acc: 0.6069, Val Loss: 0.6302, Val Acc: 0.7790
Mejor modelo guardado con Val Loss: 0.6302
Epoch 56/100, Loss: 0.6740, Acc: 0.6088, Val Loss: 0.6304, Val Acc: 0.7697
Epoch 57/100, Loss: 0.6739, Acc: 0.6070, Val Loss: 0.6291, Val Acc: 0.7771
Mejor modelo guardado con Val Loss: 0.6291
Epoch 58/100, Loss: 0.6736, Acc: 0.6084, Val Loss: 0.6285, Val Acc: 0.7801
Mejor modelo guardado con Val Loss: 0.6285
Epoch 59/100, Loss: 0.6734, Acc: 0.6066, Val Loss: 0.6277, Val Acc: 0.7786
Mejor modelo guardado con Val Loss: 0.6277
Epoch 60/100, Loss: 0.6732, Acc: 0.6061, Val Loss: 0.6266, Val Acc: 0.7904
Mejor modelo guardado con Val Loss: 0.6266
Epoch 61/100, Loss: 0.6730, Acc: 0.6097, Val Loss: 0.6280, Val Acc: 0.7620
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6730, Acc: 0.6067, Val Loss: 0.6260, Val Acc: 0.7804
Mejor modelo guardado con Val Loss: 0.6260
Epoch 63/100, Loss: 0.6728, Acc: 0.6064, Val Loss: 0.6253, Val Acc: 0.7919
Mejor modelo guardado con Val Loss: 0.6253
Epoch 64/100, Loss: 0.6727, Acc: 0.6080, Val Loss: 0.6256, Val Acc: 0.7827
Epoch 65/100, Loss: 0.6726, Acc: 0.6086, Val Loss: 0.6250, Val Acc: 0.7875
Mejor modelo guardado con Val Loss: 0.6250
Epoch 66/100, Loss: 0.6725, Acc: 0.6105, Val Loss: 0.6248, Val Acc: 0.7845
Mejor modelo guardado con Val Loss: 0.6248
Epoch 67/100, Loss: 0.6724, Acc: 0.6086, Val Loss: 0.6247, Val Acc: 0.7808
Mejor modelo guardado con Val Loss: 0.6247
Epoch 68/100, Loss: 0.6724, Acc: 0.6064, Val Loss: 0.6237, Val Acc: 0.7915
Mejor modelo guardado con Val Loss: 0.6237
Epoch 69/100, Loss: 0.6723, Acc: 0.6085, Val Loss: 0.6246, Val Acc: 0.7738
Epoch 70/100, Loss: 0.6721, Acc: 0.6077, Val Loss: 0.6232, Val Acc: 0.7908
Mejor modelo guardado con Val Loss: 0.6232
Epoch 71/100, Loss: 0.6721, Acc: 0.6084, Val Loss: 0.6226, Val Acc: 0.7941
Mejor modelo guardado con Val Loss: 0.6226
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6720, Acc: 0.6089, Val Loss: 0.6226, Val Acc: 0.7908
Epoch 73/100, Loss: 0.6719, Acc: 0.6083, Val Loss: 0.6226, Val Acc: 0.7889
Epoch 74/100, Loss: 0.6719, Acc: 0.6074, Val Loss: 0.6224, Val Acc: 0.7871
Mejor modelo guardado con Val Loss: 0.6224
Epoch 75/100, Loss: 0.6718, Acc: 0.6081, Val Loss: 0.6221, Val Acc: 0.7900
Mejor modelo guardado con Val Loss: 0.6221
Epoch 76/100, Loss: 0.6718, Acc: 0.6088, Val Loss: 0.6216, Val Acc: 0.7923
Mejor modelo guardado con Val Loss: 0.6216
Epoch 77/100, Loss: 0.6717, Acc: 0.6086, Val Loss: 0.6216, Val Acc: 0.7915
Mejor modelo guardado con Val Loss: 0.6216
Epoch 78/100, Loss: 0.6716, Acc: 0.6083, Val Loss: 0.6212, Val Acc: 0.7919
Mejor modelo guardado con Val Loss: 0.6212
Epoch 79/100, Loss: 0.6716, Acc: 0.6073, Val Loss: 0.6210, Val Acc: 0.7926
Mejor modelo guardado con Val Loss: 0.6210
Epoch 80/100, Loss: 0.6715, Acc: 0.6075, Val Loss: 0.6207, Val Acc: 0.7948
Mejor modelo guardado con Val Loss: 0.6207
Epoch 81/100, Loss: 0.6715, Acc: 0.6082, Val Loss: 0.6208, Val Acc: 0.7915
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6714, Acc: 0.6085, Val Loss: 0.6207, Val Acc: 0.7900
Mejor modelo guardado con Val Loss: 0.6207
Epoch 83/100, Loss: 0.6714, Acc: 0.6069, Val Loss: 0.6206, Val Acc: 0.7882
Mejor modelo guardado con Val Loss: 0.6206
Epoch 84/100, Loss: 0.6713, Acc: 0.6074, Val Loss: 0.6202, Val Acc: 0.7915
Mejor modelo guardado con Val Loss: 0.6202
Epoch 85/100, Loss: 0.6713, Acc: 0.6086, Val Loss: 0.6205, Val Acc: 0.7845
Epoch 86/100, Loss: 0.6712, Acc: 0.6086, Val Loss: 0.6199, Val Acc: 0.7893
Mejor modelo guardado con Val Loss: 0.6199
Epoch 87/100, Loss: 0.6712, Acc: 0.6075, Val Loss: 0.6195, Val Acc: 0.7911
Mejor modelo guardado con Val Loss: 0.6195
Epoch 88/100, Loss: 0.6711, Acc: 0.6084, Val Loss: 0.6195, Val Acc: 0.7900
Mejor modelo guardado con Val Loss: 0.6195
Epoch 89/100, Loss: 0.6710, Acc: 0.6078, Val Loss: 0.6192, Val Acc: 0.7915
Mejor modelo guardado con Val Loss: 0.6192
Epoch 90/100, Loss: 0.6709, Acc: 0.6070, Val Loss: 0.6190, Val Acc: 0.7911
Mejor modelo guardado con Val Loss: 0.6190
Epoch 91/100, Loss: 0.6709, Acc: 0.6085, Val Loss: 0.6193, Val Acc: 0.7845
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6708, Acc: 0.6083, Val Loss: 0.6194, Val Acc: 0.7815
Epoch 93/100, Loss: 0.6708, Acc: 0.6084, Val Loss: 0.6187, Val Acc: 0.7867
Mejor modelo guardado con Val Loss: 0.6187
Epoch 94/100, Loss: 0.6707, Acc: 0.6071, Val Loss: 0.6185, Val Acc: 0.7871
Mejor modelo guardado con Val Loss: 0.6185
Epoch 95/100, Loss: 0.6707, Acc: 0.6076, Val Loss: 0.6182, Val Acc: 0.7897
Mejor modelo guardado con Val Loss: 0.6182
Epoch 96/100, Loss: 0.6706, Acc: 0.6085, Val Loss: 0.6182, Val Acc: 0.7878
Epoch 97/100, Loss: 0.6705, Acc: 0.6074, Val Loss: 0.6179, Val Acc: 0.7889
Mejor modelo guardado con Val Loss: 0.6179
Epoch 98/100, Loss: 0.6705, Acc: 0.6076, Val Loss: 0.6177, Val Acc: 0.7893
Mejor modelo guardado con Val Loss: 0.6177
Epoch 99/100, Loss: 0.6704, Acc: 0.6087, Val Loss: 0.6181, Val Acc: 0.7827
Epoch 100/100, Loss: 0.6704, Acc: 0.6076, Val Loss: 0.6171, Val Acc: 0.7904
Mejor modelo guardado con Val Loss: 0.6171

##############################
Resultados para principal:  104  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11 
 {'training': [0.6704058806284261, 0.6076356945722171, 0.5859271278949698, 0.7314917127071823, 0.6506675403390941], 'validate': [0.6171137219251588, 0.7904059040590405, 0.9081419624217119, 0.6444444444444445, 0.7538994800693241], 'test': [0.6385112596008012, 0.723598820058997, 0.736941472624292, 0.6928994082840236, 0.7142421469960354]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  093  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  093  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  093  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6787, Acc: 0.5875, Val Loss: 0.7238, Val Acc: 0.3118
Mejor modelo guardado con Val Loss: 0.7238
Epoch 2/100, Loss: 0.6688, Acc: 0.6187, Val Loss: 0.7461, Val Acc: 0.4022
Epoch 3/100, Loss: 0.6689, Acc: 0.5964, Val Loss: 0.6931, Val Acc: 0.5011
Mejor modelo guardado con Val Loss: 0.6931
Epoch 4/100, Loss: 0.6753, Acc: 0.5738, Val Loss: 0.7068, Val Acc: 0.4804
Epoch 5/100, Loss: 0.6712, Acc: 0.6293, Val Loss: 0.7227, Val Acc: 0.3945
Epoch 6/100, Loss: 0.6607, Acc: 0.6361, Val Loss: 0.7171, Val Acc: 0.4605
Epoch 7/100, Loss: 0.6490, Acc: 0.6441, Val Loss: 0.7449, Val Acc: 0.4620
Epoch 8/100, Loss: 0.6431, Acc: 0.6427, Val Loss: 0.7110, Val Acc: 0.5325
Epoch 9/100, Loss: 0.6359, Acc: 0.6489, Val Loss: 0.7267, Val Acc: 0.5125
Epoch 10/100, Loss: 0.6359, Acc: 0.6478, Val Loss: 0.7750, Val Acc: 0.4908
Epoch 11/100, Loss: 0.6417, Acc: 0.6439, Val Loss: 0.7235, Val Acc: 0.5362
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6291, Acc: 0.6620, Val Loss: 0.7311, Val Acc: 0.5280
Epoch 13/100, Loss: 0.6284, Acc: 0.6524, Val Loss: 0.7707, Val Acc: 0.4749
Epoch 14/100, Loss: 0.6276, Acc: 0.6587, Val Loss: 0.7511, Val Acc: 0.5077
Epoch 15/100, Loss: 0.6272, Acc: 0.6534, Val Loss: 0.7551, Val Acc: 0.5107
Epoch 16/100, Loss: 0.6233, Acc: 0.6576, Val Loss: 0.7511, Val Acc: 0.5044
Epoch 17/100, Loss: 0.6223, Acc: 0.6600, Val Loss: 0.7943, Val Acc: 0.4554
Epoch 18/100, Loss: 0.6306, Acc: 0.6594, Val Loss: 0.7800, Val Acc: 0.4705
Epoch 19/100, Loss: 0.6260, Acc: 0.6562, Val Loss: 0.7710, Val Acc: 0.4827
Epoch 20/100, Loss: 0.6245, Acc: 0.6595, Val Loss: 0.7761, Val Acc: 0.4889
Epoch 21/100, Loss: 0.6232, Acc: 0.6592, Val Loss: 0.7644, Val Acc: 0.5066
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6231, Acc: 0.6602, Val Loss: 0.7493, Val Acc: 0.5284
Epoch 23/100, Loss: 0.6204, Acc: 0.6609, Val Loss: 0.7699, Val Acc: 0.4878
Epoch 24/100, Loss: 0.6187, Acc: 0.6621, Val Loss: 0.7621, Val Acc: 0.4930
Epoch 25/100, Loss: 0.6206, Acc: 0.6574, Val Loss: 0.7806, Val Acc: 0.4893
Epoch 26/100, Loss: 0.6188, Acc: 0.6632, Val Loss: 0.7528, Val Acc: 0.5299
Epoch 27/100, Loss: 0.6190, Acc: 0.6632, Val Loss: 0.7686, Val Acc: 0.5033
Epoch 28/100, Loss: 0.6187, Acc: 0.6607, Val Loss: 0.7894, Val Acc: 0.4764
Epoch 29/100, Loss: 0.6180, Acc: 0.6641, Val Loss: 0.7902, Val Acc: 0.4343
Epoch 30/100, Loss: 0.6255, Acc: 0.6615, Val Loss: 0.7957, Val Acc: 0.4852
Epoch 31/100, Loss: 0.6216, Acc: 0.6623, Val Loss: 0.7982, Val Acc: 0.4886
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6186, Acc: 0.6633, Val Loss: 0.7788, Val Acc: 0.4882
Epoch 33/100, Loss: 0.6175, Acc: 0.6621, Val Loss: 0.7729, Val Acc: 0.4989
Epoch 34/100, Loss: 0.6170, Acc: 0.6627, Val Loss: 0.7846, Val Acc: 0.4797
Epoch 35/100, Loss: 0.6179, Acc: 0.6653, Val Loss: 0.8014, Val Acc: 0.4631
Epoch 36/100, Loss: 0.6172, Acc: 0.6628, Val Loss: 0.7857, Val Acc: 0.4827
Epoch 37/100, Loss: 0.6162, Acc: 0.6627, Val Loss: 0.7659, Val Acc: 0.5111
Epoch 38/100, Loss: 0.6160, Acc: 0.6622, Val Loss: 0.7860, Val Acc: 0.4801
Epoch 39/100, Loss: 0.6183, Acc: 0.6652, Val Loss: 0.7890, Val Acc: 0.4683
Epoch 40/100, Loss: 0.6178, Acc: 0.6614, Val Loss: 0.7726, Val Acc: 0.5026
Epoch 41/100, Loss: 0.6164, Acc: 0.6637, Val Loss: 0.7756, Val Acc: 0.4915
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6151, Acc: 0.6651, Val Loss: 0.7800, Val Acc: 0.4923
Epoch 43/100, Loss: 0.6172, Acc: 0.6652, Val Loss: 0.7845, Val Acc: 0.4841
Epoch 44/100, Loss: 0.6154, Acc: 0.6650, Val Loss: 0.7849, Val Acc: 0.4797
Epoch 45/100, Loss: 0.6150, Acc: 0.6645, Val Loss: 0.7865, Val Acc: 0.4904
Epoch 46/100, Loss: 0.6152, Acc: 0.6654, Val Loss: 0.7734, Val Acc: 0.5004
Epoch 47/100, Loss: 0.6154, Acc: 0.6649, Val Loss: 0.7767, Val Acc: 0.4926
Epoch 48/100, Loss: 0.6150, Acc: 0.6629, Val Loss: 0.7784, Val Acc: 0.4904
Epoch 49/100, Loss: 0.6151, Acc: 0.6649, Val Loss: 0.7860, Val Acc: 0.4834
Epoch 50/100, Loss: 0.6150, Acc: 0.6663, Val Loss: 0.7862, Val Acc: 0.4819
Epoch 51/100, Loss: 0.6155, Acc: 0.6640, Val Loss: 0.7720, Val Acc: 0.5004
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6146, Acc: 0.6643, Val Loss: 0.7783, Val Acc: 0.4911
Epoch 53/100, Loss: 0.6146, Acc: 0.6648, Val Loss: 0.7840, Val Acc: 0.4815
Epoch 54/100, Loss: 0.6142, Acc: 0.6645, Val Loss: 0.7855, Val Acc: 0.4827
Epoch 55/100, Loss: 0.6140, Acc: 0.6641, Val Loss: 0.7802, Val Acc: 0.4897
Epoch 56/100, Loss: 0.6142, Acc: 0.6662, Val Loss: 0.7825, Val Acc: 0.4889
Epoch 57/100, Loss: 0.6140, Acc: 0.6644, Val Loss: 0.7850, Val Acc: 0.4849
Epoch 58/100, Loss: 0.6139, Acc: 0.6646, Val Loss: 0.7843, Val Acc: 0.4871
Epoch 59/100, Loss: 0.6141, Acc: 0.6654, Val Loss: 0.7792, Val Acc: 0.4900
Epoch 60/100, Loss: 0.6139, Acc: 0.6657, Val Loss: 0.7886, Val Acc: 0.4804
Epoch 61/100, Loss: 0.6140, Acc: 0.6655, Val Loss: 0.7824, Val Acc: 0.4900
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6137, Acc: 0.6655, Val Loss: 0.7837, Val Acc: 0.4875
Epoch 63/100, Loss: 0.6137, Acc: 0.6653, Val Loss: 0.7835, Val Acc: 0.4904
Epoch 64/100, Loss: 0.6138, Acc: 0.6659, Val Loss: 0.7867, Val Acc: 0.4830
Epoch 65/100, Loss: 0.6136, Acc: 0.6658, Val Loss: 0.7884, Val Acc: 0.4797
Epoch 66/100, Loss: 0.6136, Acc: 0.6654, Val Loss: 0.7852, Val Acc: 0.4856
Epoch 67/100, Loss: 0.6134, Acc: 0.6665, Val Loss: 0.7892, Val Acc: 0.4797
Epoch 68/100, Loss: 0.6136, Acc: 0.6639, Val Loss: 0.7873, Val Acc: 0.4808
Epoch 69/100, Loss: 0.6134, Acc: 0.6660, Val Loss: 0.7849, Val Acc: 0.4882
Epoch 70/100, Loss: 0.6134, Acc: 0.6654, Val Loss: 0.7859, Val Acc: 0.4860
Epoch 71/100, Loss: 0.6133, Acc: 0.6651, Val Loss: 0.7853, Val Acc: 0.4867
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6132, Acc: 0.6661, Val Loss: 0.7846, Val Acc: 0.4886
Epoch 73/100, Loss: 0.6131, Acc: 0.6654, Val Loss: 0.7863, Val Acc: 0.4841
Epoch 74/100, Loss: 0.6132, Acc: 0.6668, Val Loss: 0.7863, Val Acc: 0.4860
Epoch 75/100, Loss: 0.6130, Acc: 0.6655, Val Loss: 0.7840, Val Acc: 0.4915
Epoch 76/100, Loss: 0.6130, Acc: 0.6652, Val Loss: 0.7870, Val Acc: 0.4834
Epoch 77/100, Loss: 0.6131, Acc: 0.6653, Val Loss: 0.7870, Val Acc: 0.4852
Epoch 78/100, Loss: 0.6132, Acc: 0.6657, Val Loss: 0.7862, Val Acc: 0.4867
Epoch 79/100, Loss: 0.6130, Acc: 0.6661, Val Loss: 0.7850, Val Acc: 0.4893
Epoch 80/100, Loss: 0.6130, Acc: 0.6650, Val Loss: 0.7856, Val Acc: 0.4886
Epoch 81/100, Loss: 0.6130, Acc: 0.6649, Val Loss: 0.7862, Val Acc: 0.4875
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6130, Acc: 0.6661, Val Loss: 0.7859, Val Acc: 0.4878
Epoch 83/100, Loss: 0.6130, Acc: 0.6662, Val Loss: 0.7859, Val Acc: 0.4893
Epoch 84/100, Loss: 0.6130, Acc: 0.6658, Val Loss: 0.7855, Val Acc: 0.4889
Epoch 85/100, Loss: 0.6129, Acc: 0.6661, Val Loss: 0.7865, Val Acc: 0.4871
Epoch 86/100, Loss: 0.6129, Acc: 0.6655, Val Loss: 0.7869, Val Acc: 0.4860
Epoch 87/100, Loss: 0.6126, Acc: 0.6652, Val Loss: 0.7851, Val Acc: 0.4904
Epoch 88/100, Loss: 0.6125, Acc: 0.6655, Val Loss: 0.7870, Val Acc: 0.4867
Epoch 89/100, Loss: 0.6125, Acc: 0.6673, Val Loss: 0.7869, Val Acc: 0.4867
Epoch 90/100, Loss: 0.6123, Acc: 0.6661, Val Loss: 0.7889, Val Acc: 0.4841
Epoch 91/100, Loss: 0.6124, Acc: 0.6666, Val Loss: 0.7877, Val Acc: 0.4852
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6124, Acc: 0.6669, Val Loss: 0.7881, Val Acc: 0.4860
Epoch 93/100, Loss: 0.6122, Acc: 0.6666, Val Loss: 0.7889, Val Acc: 0.4852
Epoch 94/100, Loss: 0.6122, Acc: 0.6658, Val Loss: 0.7876, Val Acc: 0.4867
Epoch 95/100, Loss: 0.6122, Acc: 0.6658, Val Loss: 0.7878, Val Acc: 0.4867
Epoch 96/100, Loss: 0.6121, Acc: 0.6661, Val Loss: 0.7875, Val Acc: 0.4867
Epoch 97/100, Loss: 0.6121, Acc: 0.6668, Val Loss: 0.7873, Val Acc: 0.4878
Epoch 98/100, Loss: 0.6122, Acc: 0.6657, Val Loss: 0.7869, Val Acc: 0.4882
Epoch 99/100, Loss: 0.6120, Acc: 0.6660, Val Loss: 0.7865, Val Acc: 0.4889
Epoch 100/100, Loss: 0.6119, Acc: 0.6670, Val Loss: 0.7854, Val Acc: 0.4893

##############################
Resultados para principal:  093  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11 
 {'training': [0.6118878834600721, 0.6669733210671573, 0.6553381393752146, 0.7031307550644568, 0.6783937455579246], 'validate': [0.7854306982007138, 0.48929889298892987, 0.4897466827503016, 0.6014814814814815, 0.5398936170212766], 'test': [0.6931965823443431, 0.5011799410029498, 0.3333333333333333, 0.000591715976331361, 0.0011813349084465446]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  088  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  088  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  088  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6818, Acc: 0.5351, Val Loss: 0.6238, Val Acc: 0.7749
Mejor modelo guardado con Val Loss: 0.6238
Epoch 2/100, Loss: 0.6725, Acc: 0.5553, Val Loss: 0.6226, Val Acc: 0.5373
Mejor modelo guardado con Val Loss: 0.6226
Epoch 3/100, Loss: 0.6687, Acc: 0.5594, Val Loss: 0.5899, Val Acc: 0.7923
Mejor modelo guardado con Val Loss: 0.5899
Epoch 4/100, Loss: 0.6631, Acc: 0.5639, Val Loss: 0.5496, Val Acc: 0.7598
Mejor modelo guardado con Val Loss: 0.5496
Epoch 5/100, Loss: 0.6610, Acc: 0.5630, Val Loss: 0.5430, Val Acc: 0.7258
Mejor modelo guardado con Val Loss: 0.5430
Epoch 6/100, Loss: 0.6605, Acc: 0.5645, Val Loss: 0.5581, Val Acc: 0.6284
Epoch 7/100, Loss: 0.6582, Acc: 0.5643, Val Loss: 0.5635, Val Acc: 0.7830
Epoch 8/100, Loss: 0.6548, Acc: 0.5718, Val Loss: 0.5170, Val Acc: 0.7421
Mejor modelo guardado con Val Loss: 0.5170
Epoch 9/100, Loss: 0.6529, Acc: 0.5764, Val Loss: 0.5161, Val Acc: 0.8406
Mejor modelo guardado con Val Loss: 0.5161
Epoch 10/100, Loss: 0.6526, Acc: 0.5714, Val Loss: 0.5392, Val Acc: 0.8173
Epoch 11/100, Loss: 0.6520, Acc: 0.5747, Val Loss: 0.4942, Val Acc: 0.8406
Mejor modelo guardado con Val Loss: 0.4942
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6477, Acc: 0.5798, Val Loss: 0.4965, Val Acc: 0.8520
Epoch 13/100, Loss: 0.6475, Acc: 0.5794, Val Loss: 0.4762, Val Acc: 0.8631
Mejor modelo guardado con Val Loss: 0.4762
Epoch 14/100, Loss: 0.6469, Acc: 0.5791, Val Loss: 0.5058, Val Acc: 0.8321
Epoch 15/100, Loss: 0.6468, Acc: 0.5829, Val Loss: 0.4899, Val Acc: 0.8509
Epoch 16/100, Loss: 0.6455, Acc: 0.5810, Val Loss: 0.4687, Val Acc: 0.8738
Mejor modelo guardado con Val Loss: 0.4687
Epoch 17/100, Loss: 0.6443, Acc: 0.5856, Val Loss: 0.4925, Val Acc: 0.8764
Epoch 18/100, Loss: 0.6458, Acc: 0.5794, Val Loss: 0.4825, Val Acc: 0.8410
Epoch 19/100, Loss: 0.6459, Acc: 0.5784, Val Loss: 0.4633, Val Acc: 0.8727
Mejor modelo guardado con Val Loss: 0.4633
Epoch 20/100, Loss: 0.6453, Acc: 0.5801, Val Loss: 0.4716, Val Acc: 0.8779
Epoch 21/100, Loss: 0.6415, Acc: 0.5868, Val Loss: 0.4639, Val Acc: 0.8675
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6409, Acc: 0.5896, Val Loss: 0.4663, Val Acc: 0.8672
Epoch 23/100, Loss: 0.6407, Acc: 0.5884, Val Loss: 0.4646, Val Acc: 0.8657
Epoch 24/100, Loss: 0.6405, Acc: 0.5884, Val Loss: 0.4796, Val Acc: 0.8638
Epoch 25/100, Loss: 0.6398, Acc: 0.5886, Val Loss: 0.4569, Val Acc: 0.8487
Mejor modelo guardado con Val Loss: 0.4569
Epoch 26/100, Loss: 0.6394, Acc: 0.5889, Val Loss: 0.4596, Val Acc: 0.8723
Epoch 27/100, Loss: 0.6402, Acc: 0.5888, Val Loss: 0.4660, Val Acc: 0.8756
Epoch 28/100, Loss: 0.6389, Acc: 0.5900, Val Loss: 0.4499, Val Acc: 0.8790
Mejor modelo guardado con Val Loss: 0.4499
Epoch 29/100, Loss: 0.6391, Acc: 0.5904, Val Loss: 0.4561, Val Acc: 0.8524
Epoch 30/100, Loss: 0.6388, Acc: 0.5891, Val Loss: 0.4671, Val Acc: 0.8624
Epoch 31/100, Loss: 0.6386, Acc: 0.5900, Val Loss: 0.4644, Val Acc: 0.8642
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6380, Acc: 0.5912, Val Loss: 0.4593, Val Acc: 0.8520
Epoch 33/100, Loss: 0.6373, Acc: 0.5908, Val Loss: 0.4540, Val Acc: 0.8443
Epoch 34/100, Loss: 0.6372, Acc: 0.5908, Val Loss: 0.4545, Val Acc: 0.8756
Epoch 35/100, Loss: 0.6371, Acc: 0.5881, Val Loss: 0.4626, Val Acc: 0.8539
Epoch 36/100, Loss: 0.6373, Acc: 0.5909, Val Loss: 0.4558, Val Acc: 0.8683
Epoch 37/100, Loss: 0.6369, Acc: 0.5930, Val Loss: 0.4587, Val Acc: 0.8672
Epoch 38/100, Loss: 0.6370, Acc: 0.5912, Val Loss: 0.4592, Val Acc: 0.8554
Epoch 39/100, Loss: 0.6364, Acc: 0.5902, Val Loss: 0.4528, Val Acc: 0.8679
Epoch 40/100, Loss: 0.6365, Acc: 0.5914, Val Loss: 0.4561, Val Acc: 0.8668
Epoch 41/100, Loss: 0.6363, Acc: 0.5934, Val Loss: 0.4459, Val Acc: 0.8749
Mejor modelo guardado con Val Loss: 0.4459
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6359, Acc: 0.5931, Val Loss: 0.4505, Val Acc: 0.8446
Epoch 43/100, Loss: 0.6361, Acc: 0.5909, Val Loss: 0.4516, Val Acc: 0.8624
Epoch 44/100, Loss: 0.6357, Acc: 0.5925, Val Loss: 0.4467, Val Acc: 0.8694
Epoch 45/100, Loss: 0.6359, Acc: 0.5934, Val Loss: 0.4456, Val Acc: 0.8756
Mejor modelo guardado con Val Loss: 0.4456
Epoch 46/100, Loss: 0.6358, Acc: 0.5919, Val Loss: 0.4492, Val Acc: 0.8672
Epoch 47/100, Loss: 0.6356, Acc: 0.5924, Val Loss: 0.4518, Val Acc: 0.8561
Epoch 48/100, Loss: 0.6359, Acc: 0.5926, Val Loss: 0.4502, Val Acc: 0.8565
Epoch 49/100, Loss: 0.6355, Acc: 0.5912, Val Loss: 0.4491, Val Acc: 0.8668
Epoch 50/100, Loss: 0.6353, Acc: 0.5911, Val Loss: 0.4495, Val Acc: 0.8616
Epoch 51/100, Loss: 0.6353, Acc: 0.5923, Val Loss: 0.4506, Val Acc: 0.8513
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6351, Acc: 0.5913, Val Loss: 0.4481, Val Acc: 0.8594
Epoch 53/100, Loss: 0.6350, Acc: 0.5913, Val Loss: 0.4502, Val Acc: 0.8624
Epoch 54/100, Loss: 0.6349, Acc: 0.5915, Val Loss: 0.4468, Val Acc: 0.8587
Epoch 55/100, Loss: 0.6349, Acc: 0.5915, Val Loss: 0.4477, Val Acc: 0.8579
Epoch 56/100, Loss: 0.6348, Acc: 0.5911, Val Loss: 0.4485, Val Acc: 0.8635
Epoch 57/100, Loss: 0.6348, Acc: 0.5928, Val Loss: 0.4464, Val Acc: 0.8594
Epoch 58/100, Loss: 0.6348, Acc: 0.5914, Val Loss: 0.4476, Val Acc: 0.8594
Epoch 59/100, Loss: 0.6348, Acc: 0.5918, Val Loss: 0.4484, Val Acc: 0.8579
Epoch 60/100, Loss: 0.6347, Acc: 0.5923, Val Loss: 0.4468, Val Acc: 0.8642
Epoch 61/100, Loss: 0.6346, Acc: 0.5905, Val Loss: 0.4472, Val Acc: 0.8738
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6346, Acc: 0.5926, Val Loss: 0.4469, Val Acc: 0.8642
Epoch 63/100, Loss: 0.6344, Acc: 0.5934, Val Loss: 0.4481, Val Acc: 0.8590
Epoch 64/100, Loss: 0.6345, Acc: 0.5920, Val Loss: 0.4472, Val Acc: 0.8594
Epoch 65/100, Loss: 0.6344, Acc: 0.5917, Val Loss: 0.4473, Val Acc: 0.8613
Epoch 66/100, Loss: 0.6344, Acc: 0.5913, Val Loss: 0.4473, Val Acc: 0.8631
Epoch 67/100, Loss: 0.6343, Acc: 0.5925, Val Loss: 0.4483, Val Acc: 0.8590
Epoch 68/100, Loss: 0.6343, Acc: 0.5917, Val Loss: 0.4471, Val Acc: 0.8638
Epoch 69/100, Loss: 0.6343, Acc: 0.5923, Val Loss: 0.4465, Val Acc: 0.8590
Epoch 70/100, Loss: 0.6343, Acc: 0.5921, Val Loss: 0.4474, Val Acc: 0.8598
Epoch 71/100, Loss: 0.6344, Acc: 0.5933, Val Loss: 0.4472, Val Acc: 0.8590
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6342, Acc: 0.5910, Val Loss: 0.4469, Val Acc: 0.8613
Epoch 73/100, Loss: 0.6342, Acc: 0.5926, Val Loss: 0.4469, Val Acc: 0.8594
Epoch 74/100, Loss: 0.6342, Acc: 0.5925, Val Loss: 0.4465, Val Acc: 0.8590
Epoch 75/100, Loss: 0.6342, Acc: 0.5914, Val Loss: 0.4467, Val Acc: 0.8590
Epoch 76/100, Loss: 0.6342, Acc: 0.5924, Val Loss: 0.4467, Val Acc: 0.8590
Epoch 77/100, Loss: 0.6341, Acc: 0.5907, Val Loss: 0.4468, Val Acc: 0.8583
Epoch 78/100, Loss: 0.6341, Acc: 0.5910, Val Loss: 0.4466, Val Acc: 0.8587
Epoch 79/100, Loss: 0.6341, Acc: 0.5920, Val Loss: 0.4469, Val Acc: 0.8587
Epoch 80/100, Loss: 0.6341, Acc: 0.5920, Val Loss: 0.4471, Val Acc: 0.8579
Epoch 81/100, Loss: 0.6341, Acc: 0.5912, Val Loss: 0.4467, Val Acc: 0.8583
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6340, Acc: 0.5915, Val Loss: 0.4469, Val Acc: 0.8583
Epoch 83/100, Loss: 0.6341, Acc: 0.5911, Val Loss: 0.4465, Val Acc: 0.8587
Epoch 84/100, Loss: 0.6340, Acc: 0.5924, Val Loss: 0.4467, Val Acc: 0.8583
Epoch 85/100, Loss: 0.6340, Acc: 0.5927, Val Loss: 0.4460, Val Acc: 0.8616
Epoch 86/100, Loss: 0.6340, Acc: 0.5914, Val Loss: 0.4470, Val Acc: 0.8579
Epoch 87/100, Loss: 0.6339, Acc: 0.5919, Val Loss: 0.4465, Val Acc: 0.8594
Epoch 88/100, Loss: 0.6340, Acc: 0.5913, Val Loss: 0.4463, Val Acc: 0.8587
Epoch 89/100, Loss: 0.6339, Acc: 0.5920, Val Loss: 0.4460, Val Acc: 0.8613
Epoch 90/100, Loss: 0.6340, Acc: 0.5923, Val Loss: 0.4460, Val Acc: 0.8587
Epoch 91/100, Loss: 0.6339, Acc: 0.5916, Val Loss: 0.4467, Val Acc: 0.8583
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6340, Acc: 0.5923, Val Loss: 0.4469, Val Acc: 0.8583
Epoch 93/100, Loss: 0.6339, Acc: 0.5914, Val Loss: 0.4464, Val Acc: 0.8590
Epoch 94/100, Loss: 0.6339, Acc: 0.5922, Val Loss: 0.4467, Val Acc: 0.8583
Epoch 95/100, Loss: 0.6339, Acc: 0.5922, Val Loss: 0.4465, Val Acc: 0.8583
Epoch 96/100, Loss: 0.6339, Acc: 0.5919, Val Loss: 0.4468, Val Acc: 0.8620
Epoch 97/100, Loss: 0.6339, Acc: 0.5929, Val Loss: 0.4470, Val Acc: 0.8583
Epoch 98/100, Loss: 0.6338, Acc: 0.5925, Val Loss: 0.4462, Val Acc: 0.8587
Epoch 99/100, Loss: 0.6338, Acc: 0.5918, Val Loss: 0.4461, Val Acc: 0.8624
Epoch 100/100, Loss: 0.6338, Acc: 0.5922, Val Loss: 0.4463, Val Acc: 0.8620

##############################
Resultados para principal:  088  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11 
 {'training': [0.6337963493131341, 0.5921803127874885, 0.5549190261099483, 0.9276243093922651, 0.6944233818156752], 'validate': [0.4463452017151339, 0.8619926199261992, 0.870257966616085, 0.8496296296296296, 0.8598200899550225], 'test': [0.4494189889222946, 0.863716814159292, 0.813585291113381, 0.942603550295858, 0.8733552631578947]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  055  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  055  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  055  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6584, Acc: 0.6341, Val Loss: 0.5493, Val Acc: 0.7764
Mejor modelo guardado con Val Loss: 0.5493
Epoch 2/100, Loss: 0.6255, Acc: 0.6698, Val Loss: 0.5125, Val Acc: 0.7804
Mejor modelo guardado con Val Loss: 0.5125
Epoch 3/100, Loss: 0.6110, Acc: 0.6712, Val Loss: 0.5062, Val Acc: 0.7627
Mejor modelo guardado con Val Loss: 0.5062
Epoch 4/100, Loss: 0.6038, Acc: 0.6730, Val Loss: 0.4070, Val Acc: 0.8830
Mejor modelo guardado con Val Loss: 0.4070
Epoch 5/100, Loss: 0.5953, Acc: 0.6867, Val Loss: 0.3796, Val Acc: 0.9133
Mejor modelo guardado con Val Loss: 0.3796
Epoch 6/100, Loss: 0.5873, Acc: 0.6937, Val Loss: 0.4007, Val Acc: 0.8694
Epoch 7/100, Loss: 0.5834, Acc: 0.6945, Val Loss: 0.3481, Val Acc: 0.8941
Mejor modelo guardado con Val Loss: 0.3481
Epoch 8/100, Loss: 0.5830, Acc: 0.6917, Val Loss: 0.3237, Val Acc: 0.9170
Mejor modelo guardado con Val Loss: 0.3237
Epoch 9/100, Loss: 0.5795, Acc: 0.6932, Val Loss: 0.3832, Val Acc: 0.8738
Epoch 10/100, Loss: 0.5795, Acc: 0.6978, Val Loss: 0.4125, Val Acc: 0.8797
Epoch 11/100, Loss: 0.5788, Acc: 0.6956, Val Loss: 0.4052, Val Acc: 0.8354
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5707, Acc: 0.6985, Val Loss: 0.3925, Val Acc: 0.8410
Epoch 13/100, Loss: 0.5707, Acc: 0.7044, Val Loss: 0.3350, Val Acc: 0.8974
Epoch 14/100, Loss: 0.5687, Acc: 0.7024, Val Loss: 0.4572, Val Acc: 0.7720
Epoch 15/100, Loss: 0.5628, Acc: 0.7108, Val Loss: 0.4068, Val Acc: 0.8173
Epoch 16/100, Loss: 0.5655, Acc: 0.7049, Val Loss: 0.3531, Val Acc: 0.8672
Epoch 17/100, Loss: 0.5644, Acc: 0.7101, Val Loss: 0.3610, Val Acc: 0.8542
Epoch 18/100, Loss: 0.5653, Acc: 0.7050, Val Loss: 0.3608, Val Acc: 0.8683
Epoch 19/100, Loss: 0.5590, Acc: 0.7070, Val Loss: 0.3696, Val Acc: 0.8461
Epoch 20/100, Loss: 0.5597, Acc: 0.7113, Val Loss: 0.3588, Val Acc: 0.8561
Epoch 21/100, Loss: 0.5593, Acc: 0.7120, Val Loss: 0.3626, Val Acc: 0.8491
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5548, Acc: 0.7118, Val Loss: 0.3551, Val Acc: 0.8631
Epoch 23/100, Loss: 0.5533, Acc: 0.7129, Val Loss: 0.3436, Val Acc: 0.8749
Epoch 24/100, Loss: 0.5520, Acc: 0.7131, Val Loss: 0.3659, Val Acc: 0.8579
Epoch 25/100, Loss: 0.5528, Acc: 0.7121, Val Loss: 0.3700, Val Acc: 0.8458
Epoch 26/100, Loss: 0.5511, Acc: 0.7114, Val Loss: 0.3512, Val Acc: 0.8624
Epoch 27/100, Loss: 0.5512, Acc: 0.7121, Val Loss: 0.3519, Val Acc: 0.8528
Epoch 28/100, Loss: 0.5500, Acc: 0.7127, Val Loss: 0.3729, Val Acc: 0.8373
Epoch 29/100, Loss: 0.5505, Acc: 0.7134, Val Loss: 0.3756, Val Acc: 0.8354
Epoch 30/100, Loss: 0.5490, Acc: 0.7178, Val Loss: 0.3855, Val Acc: 0.8247
Epoch 31/100, Loss: 0.5495, Acc: 0.7147, Val Loss: 0.3897, Val Acc: 0.8251
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5474, Acc: 0.7136, Val Loss: 0.3642, Val Acc: 0.8435
Epoch 33/100, Loss: 0.5465, Acc: 0.7166, Val Loss: 0.3934, Val Acc: 0.8177
Epoch 34/100, Loss: 0.5459, Acc: 0.7178, Val Loss: 0.3457, Val Acc: 0.8631
Epoch 35/100, Loss: 0.5461, Acc: 0.7175, Val Loss: 0.3639, Val Acc: 0.8465
Epoch 36/100, Loss: 0.5458, Acc: 0.7178, Val Loss: 0.3704, Val Acc: 0.8461
Epoch 37/100, Loss: 0.5457, Acc: 0.7164, Val Loss: 0.3537, Val Acc: 0.8502
Epoch 38/100, Loss: 0.5453, Acc: 0.7159, Val Loss: 0.3619, Val Acc: 0.8443
Epoch 39/100, Loss: 0.5448, Acc: 0.7180, Val Loss: 0.3688, Val Acc: 0.8413
Epoch 40/100, Loss: 0.5451, Acc: 0.7193, Val Loss: 0.3617, Val Acc: 0.8461
Epoch 41/100, Loss: 0.5447, Acc: 0.7161, Val Loss: 0.3637, Val Acc: 0.8406
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5432, Acc: 0.7186, Val Loss: 0.3532, Val Acc: 0.8535
Epoch 43/100, Loss: 0.5431, Acc: 0.7183, Val Loss: 0.3714, Val Acc: 0.8402
Epoch 44/100, Loss: 0.5434, Acc: 0.7198, Val Loss: 0.3514, Val Acc: 0.8513
Epoch 45/100, Loss: 0.5425, Acc: 0.7170, Val Loss: 0.3869, Val Acc: 0.8221
Epoch 46/100, Loss: 0.5430, Acc: 0.7188, Val Loss: 0.3707, Val Acc: 0.8402
Epoch 47/100, Loss: 0.5422, Acc: 0.7191, Val Loss: 0.3655, Val Acc: 0.8424
Epoch 48/100, Loss: 0.5424, Acc: 0.7194, Val Loss: 0.3669, Val Acc: 0.8424
Epoch 49/100, Loss: 0.5418, Acc: 0.7212, Val Loss: 0.3380, Val Acc: 0.8683
Epoch 50/100, Loss: 0.5419, Acc: 0.7171, Val Loss: 0.3442, Val Acc: 0.8661
Epoch 51/100, Loss: 0.5422, Acc: 0.7189, Val Loss: 0.3544, Val Acc: 0.8498
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5414, Acc: 0.7223, Val Loss: 0.3452, Val Acc: 0.8605
Epoch 53/100, Loss: 0.5415, Acc: 0.7196, Val Loss: 0.3550, Val Acc: 0.8498
Epoch 54/100, Loss: 0.5411, Acc: 0.7210, Val Loss: 0.3546, Val Acc: 0.8513
Epoch 55/100, Loss: 0.5412, Acc: 0.7201, Val Loss: 0.3509, Val Acc: 0.8539
Epoch 56/100, Loss: 0.5409, Acc: 0.7210, Val Loss: 0.3568, Val Acc: 0.8509
Epoch 57/100, Loss: 0.5409, Acc: 0.7201, Val Loss: 0.3662, Val Acc: 0.8417
Epoch 58/100, Loss: 0.5409, Acc: 0.7214, Val Loss: 0.3411, Val Acc: 0.8605
Epoch 59/100, Loss: 0.5408, Acc: 0.7222, Val Loss: 0.3603, Val Acc: 0.8446
Epoch 60/100, Loss: 0.5407, Acc: 0.7209, Val Loss: 0.3370, Val Acc: 0.8624
Epoch 61/100, Loss: 0.5407, Acc: 0.7219, Val Loss: 0.3650, Val Acc: 0.8465
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5404, Acc: 0.7213, Val Loss: 0.3583, Val Acc: 0.8483
Epoch 63/100, Loss: 0.5402, Acc: 0.7216, Val Loss: 0.3579, Val Acc: 0.8483
Epoch 64/100, Loss: 0.5402, Acc: 0.7228, Val Loss: 0.3540, Val Acc: 0.8509
Epoch 65/100, Loss: 0.5403, Acc: 0.7227, Val Loss: 0.3574, Val Acc: 0.8487
Epoch 66/100, Loss: 0.5402, Acc: 0.7213, Val Loss: 0.3563, Val Acc: 0.8498
Epoch 67/100, Loss: 0.5400, Acc: 0.7218, Val Loss: 0.3591, Val Acc: 0.8472
Epoch 68/100, Loss: 0.5400, Acc: 0.7195, Val Loss: 0.3570, Val Acc: 0.8491
Epoch 69/100, Loss: 0.5399, Acc: 0.7209, Val Loss: 0.3564, Val Acc: 0.8498
Epoch 70/100, Loss: 0.5400, Acc: 0.7210, Val Loss: 0.3625, Val Acc: 0.8446
Epoch 71/100, Loss: 0.5399, Acc: 0.7213, Val Loss: 0.3639, Val Acc: 0.8424
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5398, Acc: 0.7222, Val Loss: 0.3555, Val Acc: 0.8491
Epoch 73/100, Loss: 0.5397, Acc: 0.7217, Val Loss: 0.3616, Val Acc: 0.8454
Epoch 74/100, Loss: 0.5397, Acc: 0.7213, Val Loss: 0.3524, Val Acc: 0.8520
Epoch 75/100, Loss: 0.5397, Acc: 0.7221, Val Loss: 0.3570, Val Acc: 0.8480
Epoch 76/100, Loss: 0.5397, Acc: 0.7213, Val Loss: 0.3518, Val Acc: 0.8531
Epoch 77/100, Loss: 0.5396, Acc: 0.7214, Val Loss: 0.3504, Val Acc: 0.8539
Epoch 78/100, Loss: 0.5396, Acc: 0.7210, Val Loss: 0.3529, Val Acc: 0.8509
Epoch 79/100, Loss: 0.5397, Acc: 0.7211, Val Loss: 0.3530, Val Acc: 0.8517
Epoch 80/100, Loss: 0.5395, Acc: 0.7214, Val Loss: 0.3522, Val Acc: 0.8524
Epoch 81/100, Loss: 0.5396, Acc: 0.7216, Val Loss: 0.3564, Val Acc: 0.8476
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5394, Acc: 0.7225, Val Loss: 0.3498, Val Acc: 0.8535
Epoch 83/100, Loss: 0.5393, Acc: 0.7227, Val Loss: 0.3631, Val Acc: 0.8439
Epoch 84/100, Loss: 0.5394, Acc: 0.7221, Val Loss: 0.3533, Val Acc: 0.8502
Epoch 85/100, Loss: 0.5394, Acc: 0.7226, Val Loss: 0.3500, Val Acc: 0.8535
Epoch 86/100, Loss: 0.5395, Acc: 0.7217, Val Loss: 0.3506, Val Acc: 0.8531
Epoch 87/100, Loss: 0.5394, Acc: 0.7225, Val Loss: 0.3589, Val Acc: 0.8472
Epoch 88/100, Loss: 0.5395, Acc: 0.7231, Val Loss: 0.3527, Val Acc: 0.8513
Epoch 89/100, Loss: 0.5395, Acc: 0.7218, Val Loss: 0.3559, Val Acc: 0.8487
Epoch 90/100, Loss: 0.5393, Acc: 0.7220, Val Loss: 0.3609, Val Acc: 0.8450
Epoch 91/100, Loss: 0.5391, Acc: 0.7227, Val Loss: 0.3488, Val Acc: 0.8535
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5388, Acc: 0.7231, Val Loss: 0.3529, Val Acc: 0.8506
Epoch 93/100, Loss: 0.5387, Acc: 0.7230, Val Loss: 0.3509, Val Acc: 0.8535
Epoch 94/100, Loss: 0.5388, Acc: 0.7230, Val Loss: 0.3542, Val Acc: 0.8494
Epoch 95/100, Loss: 0.5386, Acc: 0.7224, Val Loss: 0.3597, Val Acc: 0.8465
Epoch 96/100, Loss: 0.5387, Acc: 0.7222, Val Loss: 0.3585, Val Acc: 0.8469
Epoch 97/100, Loss: 0.5386, Acc: 0.7212, Val Loss: 0.3578, Val Acc: 0.8469
Epoch 98/100, Loss: 0.5387, Acc: 0.7229, Val Loss: 0.3517, Val Acc: 0.8509
Epoch 99/100, Loss: 0.5386, Acc: 0.7224, Val Loss: 0.3556, Val Acc: 0.8480
Epoch 100/100, Loss: 0.5386, Acc: 0.7226, Val Loss: 0.3569, Val Acc: 0.8480

##############################
Resultados para principal:  055  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11 
 {'training': [0.5385660960571198, 0.7226310947562098, 0.7297811607992388, 0.7062615101289135, 0.7178287318671034], 'validate': [0.35689708140007287, 0.847970479704797, 1.0, 0.6948148148148148, 0.8199300699300699], 'test': [0.4019097131940554, 0.8799410029498526, 0.8843618933493109, 0.8733727810650888, 0.8788329860077404]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  045  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  045  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  045  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5065, Acc: 0.8025, Val Loss: 0.2382, Val Acc: 0.9705
Mejor modelo guardado con Val Loss: 0.2382
Epoch 2/100, Loss: 0.4031, Acc: 0.8339, Val Loss: 0.2257, Val Acc: 0.9465
Mejor modelo guardado con Val Loss: 0.2257
Epoch 3/100, Loss: 0.3482, Acc: 0.8545, Val Loss: 0.1485, Val Acc: 0.9672
Mejor modelo guardado con Val Loss: 0.1485
Epoch 4/100, Loss: 0.3650, Acc: 0.8425, Val Loss: 0.1890, Val Acc: 0.9454
Epoch 5/100, Loss: 0.3363, Acc: 0.8584, Val Loss: 0.1574, Val Acc: 0.9576
Epoch 6/100, Loss: 0.3265, Acc: 0.8598, Val Loss: 0.1492, Val Acc: 0.9509
Epoch 7/100, Loss: 0.3196, Acc: 0.8661, Val Loss: 0.1391, Val Acc: 0.9635
Mejor modelo guardado con Val Loss: 0.1391
Epoch 8/100, Loss: 0.3074, Acc: 0.8716, Val Loss: 0.1585, Val Acc: 0.9520
Epoch 9/100, Loss: 0.3110, Acc: 0.8693, Val Loss: 0.1750, Val Acc: 0.9380
Epoch 10/100, Loss: 0.3010, Acc: 0.8733, Val Loss: 0.1323, Val Acc: 0.9583
Mejor modelo guardado con Val Loss: 0.1323
Epoch 11/100, Loss: 0.3095, Acc: 0.8706, Val Loss: 0.1485, Val Acc: 0.9539
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2846, Acc: 0.8807, Val Loss: 0.1255, Val Acc: 0.9679
Mejor modelo guardado con Val Loss: 0.1255
Epoch 13/100, Loss: 0.2809, Acc: 0.8831, Val Loss: 0.1380, Val Acc: 0.9587
Epoch 14/100, Loss: 0.2849, Acc: 0.8785, Val Loss: 0.1291, Val Acc: 0.9568
Epoch 15/100, Loss: 0.2747, Acc: 0.8845, Val Loss: 0.1288, Val Acc: 0.9594
Epoch 16/100, Loss: 0.2718, Acc: 0.8869, Val Loss: 0.1260, Val Acc: 0.9568
Epoch 17/100, Loss: 0.2755, Acc: 0.8825, Val Loss: 0.1231, Val Acc: 0.9601
Mejor modelo guardado con Val Loss: 0.1231
Epoch 18/100, Loss: 0.2762, Acc: 0.8843, Val Loss: 0.1231, Val Acc: 0.9638
Mejor modelo guardado con Val Loss: 0.1231
Epoch 19/100, Loss: 0.2689, Acc: 0.8869, Val Loss: 0.1455, Val Acc: 0.9472
Epoch 20/100, Loss: 0.2732, Acc: 0.8867, Val Loss: 0.1470, Val Acc: 0.9506
Epoch 21/100, Loss: 0.2664, Acc: 0.8868, Val Loss: 0.1270, Val Acc: 0.9579
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2551, Acc: 0.8926, Val Loss: 0.1149, Val Acc: 0.9675
Mejor modelo guardado con Val Loss: 0.1149
Epoch 23/100, Loss: 0.2535, Acc: 0.8936, Val Loss: 0.1135, Val Acc: 0.9601
Mejor modelo guardado con Val Loss: 0.1135
Epoch 24/100, Loss: 0.2530, Acc: 0.8933, Val Loss: 0.1136, Val Acc: 0.9620
Epoch 25/100, Loss: 0.2586, Acc: 0.8919, Val Loss: 0.1172, Val Acc: 0.9616
Epoch 26/100, Loss: 0.2543, Acc: 0.8932, Val Loss: 0.1223, Val Acc: 0.9598
Epoch 27/100, Loss: 0.2509, Acc: 0.8937, Val Loss: 0.1154, Val Acc: 0.9646
Epoch 28/100, Loss: 0.2510, Acc: 0.8946, Val Loss: 0.1195, Val Acc: 0.9638
Epoch 29/100, Loss: 0.2504, Acc: 0.8943, Val Loss: 0.1285, Val Acc: 0.9557
Epoch 30/100, Loss: 0.2490, Acc: 0.8946, Val Loss: 0.1230, Val Acc: 0.9598
Epoch 31/100, Loss: 0.2490, Acc: 0.8954, Val Loss: 0.1166, Val Acc: 0.9646
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2423, Acc: 0.8989, Val Loss: 0.1272, Val Acc: 0.9594
Epoch 33/100, Loss: 0.2420, Acc: 0.8981, Val Loss: 0.1172, Val Acc: 0.9594
Epoch 34/100, Loss: 0.2407, Acc: 0.8996, Val Loss: 0.1208, Val Acc: 0.9616
Epoch 35/100, Loss: 0.2407, Acc: 0.8979, Val Loss: 0.1166, Val Acc: 0.9598
Epoch 36/100, Loss: 0.2406, Acc: 0.8986, Val Loss: 0.1265, Val Acc: 0.9587
Epoch 37/100, Loss: 0.2394, Acc: 0.8996, Val Loss: 0.1165, Val Acc: 0.9638
Epoch 38/100, Loss: 0.2398, Acc: 0.8997, Val Loss: 0.1311, Val Acc: 0.9594
Epoch 39/100, Loss: 0.2386, Acc: 0.9000, Val Loss: 0.1210, Val Acc: 0.9605
Epoch 40/100, Loss: 0.2372, Acc: 0.9007, Val Loss: 0.1231, Val Acc: 0.9587
Epoch 41/100, Loss: 0.2386, Acc: 0.9015, Val Loss: 0.1250, Val Acc: 0.9583
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2352, Acc: 0.9010, Val Loss: 0.1215, Val Acc: 0.9613
Epoch 43/100, Loss: 0.2341, Acc: 0.9006, Val Loss: 0.1186, Val Acc: 0.9601
Epoch 44/100, Loss: 0.2341, Acc: 0.9013, Val Loss: 0.1204, Val Acc: 0.9576
Epoch 45/100, Loss: 0.2336, Acc: 0.9012, Val Loss: 0.1172, Val Acc: 0.9605
Epoch 46/100, Loss: 0.2334, Acc: 0.9029, Val Loss: 0.1172, Val Acc: 0.9601
Epoch 47/100, Loss: 0.2328, Acc: 0.9031, Val Loss: 0.1216, Val Acc: 0.9583
Epoch 48/100, Loss: 0.2322, Acc: 0.9035, Val Loss: 0.1217, Val Acc: 0.9572
Epoch 49/100, Loss: 0.2313, Acc: 0.9026, Val Loss: 0.1223, Val Acc: 0.9587
Epoch 50/100, Loss: 0.2321, Acc: 0.9029, Val Loss: 0.1178, Val Acc: 0.9609
Epoch 51/100, Loss: 0.2322, Acc: 0.9024, Val Loss: 0.1233, Val Acc: 0.9594
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2303, Acc: 0.9043, Val Loss: 0.1177, Val Acc: 0.9590
Epoch 53/100, Loss: 0.2294, Acc: 0.9044, Val Loss: 0.1179, Val Acc: 0.9609
Epoch 54/100, Loss: 0.2297, Acc: 0.9034, Val Loss: 0.1186, Val Acc: 0.9605
Epoch 55/100, Loss: 0.2290, Acc: 0.9040, Val Loss: 0.1209, Val Acc: 0.9609
Epoch 56/100, Loss: 0.2295, Acc: 0.9031, Val Loss: 0.1214, Val Acc: 0.9598
Epoch 57/100, Loss: 0.2291, Acc: 0.9048, Val Loss: 0.1203, Val Acc: 0.9594
Epoch 58/100, Loss: 0.2291, Acc: 0.9044, Val Loss: 0.1202, Val Acc: 0.9594
Epoch 59/100, Loss: 0.2288, Acc: 0.9052, Val Loss: 0.1199, Val Acc: 0.9598
Epoch 60/100, Loss: 0.2283, Acc: 0.9035, Val Loss: 0.1206, Val Acc: 0.9583
Epoch 61/100, Loss: 0.2282, Acc: 0.9041, Val Loss: 0.1202, Val Acc: 0.9609
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2273, Acc: 0.9049, Val Loss: 0.1195, Val Acc: 0.9590
Epoch 63/100, Loss: 0.2274, Acc: 0.9040, Val Loss: 0.1201, Val Acc: 0.9579
Epoch 64/100, Loss: 0.2270, Acc: 0.9050, Val Loss: 0.1185, Val Acc: 0.9601
Epoch 65/100, Loss: 0.2274, Acc: 0.9059, Val Loss: 0.1192, Val Acc: 0.9601
Epoch 66/100, Loss: 0.2273, Acc: 0.9046, Val Loss: 0.1194, Val Acc: 0.9576
Epoch 67/100, Loss: 0.2270, Acc: 0.9055, Val Loss: 0.1184, Val Acc: 0.9594
Epoch 68/100, Loss: 0.2269, Acc: 0.9060, Val Loss: 0.1196, Val Acc: 0.9576
Epoch 69/100, Loss: 0.2270, Acc: 0.9054, Val Loss: 0.1204, Val Acc: 0.9583
Epoch 70/100, Loss: 0.2268, Acc: 0.9052, Val Loss: 0.1184, Val Acc: 0.9605
Epoch 71/100, Loss: 0.2269, Acc: 0.9054, Val Loss: 0.1212, Val Acc: 0.9576
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2263, Acc: 0.9042, Val Loss: 0.1186, Val Acc: 0.9605
Epoch 73/100, Loss: 0.2263, Acc: 0.9055, Val Loss: 0.1188, Val Acc: 0.9587
Epoch 74/100, Loss: 0.2261, Acc: 0.9056, Val Loss: 0.1182, Val Acc: 0.9605
Epoch 75/100, Loss: 0.2261, Acc: 0.9048, Val Loss: 0.1187, Val Acc: 0.9583
Epoch 76/100, Loss: 0.2261, Acc: 0.9066, Val Loss: 0.1187, Val Acc: 0.9587
Epoch 77/100, Loss: 0.2260, Acc: 0.9056, Val Loss: 0.1187, Val Acc: 0.9605
Epoch 78/100, Loss: 0.2260, Acc: 0.9062, Val Loss: 0.1189, Val Acc: 0.9583
Epoch 79/100, Loss: 0.2258, Acc: 0.9063, Val Loss: 0.1187, Val Acc: 0.9605
Epoch 80/100, Loss: 0.2257, Acc: 0.9058, Val Loss: 0.1188, Val Acc: 0.9583
Epoch 81/100, Loss: 0.2257, Acc: 0.9059, Val Loss: 0.1196, Val Acc: 0.9579
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2258, Acc: 0.9060, Val Loss: 0.1187, Val Acc: 0.9598
Epoch 83/100, Loss: 0.2260, Acc: 0.9060, Val Loss: 0.1191, Val Acc: 0.9609
Epoch 84/100, Loss: 0.2257, Acc: 0.9068, Val Loss: 0.1182, Val Acc: 0.9609
Epoch 85/100, Loss: 0.2256, Acc: 0.9055, Val Loss: 0.1194, Val Acc: 0.9583
Epoch 86/100, Loss: 0.2252, Acc: 0.9060, Val Loss: 0.1194, Val Acc: 0.9601
Epoch 87/100, Loss: 0.2255, Acc: 0.9052, Val Loss: 0.1192, Val Acc: 0.9583
Epoch 88/100, Loss: 0.2253, Acc: 0.9062, Val Loss: 0.1183, Val Acc: 0.9587
Epoch 89/100, Loss: 0.2253, Acc: 0.9057, Val Loss: 0.1187, Val Acc: 0.9583
Epoch 90/100, Loss: 0.2253, Acc: 0.9060, Val Loss: 0.1182, Val Acc: 0.9583
Epoch 91/100, Loss: 0.2250, Acc: 0.9050, Val Loss: 0.1186, Val Acc: 0.9601
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2252, Acc: 0.9046, Val Loss: 0.1188, Val Acc: 0.9590
Epoch 93/100, Loss: 0.2251, Acc: 0.9064, Val Loss: 0.1192, Val Acc: 0.9587
Epoch 94/100, Loss: 0.2248, Acc: 0.9069, Val Loss: 0.1183, Val Acc: 0.9587
Epoch 95/100, Loss: 0.2249, Acc: 0.9062, Val Loss: 0.1189, Val Acc: 0.9587
Epoch 96/100, Loss: 0.2250, Acc: 0.9056, Val Loss: 0.1192, Val Acc: 0.9594
Epoch 97/100, Loss: 0.2247, Acc: 0.9061, Val Loss: 0.1196, Val Acc: 0.9583
Epoch 98/100, Loss: 0.2247, Acc: 0.9067, Val Loss: 0.1184, Val Acc: 0.9587
Epoch 99/100, Loss: 0.2246, Acc: 0.9065, Val Loss: 0.1190, Val Acc: 0.9583
Epoch 100/100, Loss: 0.2245, Acc: 0.9054, Val Loss: 0.1188, Val Acc: 0.9583

##############################
Resultados para principal:  045  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11 
 {'training': [0.22449911156156904, 0.9054277828886844, 0.9159108087679516, 0.892633517495396, 0.9041223652303675], 'validate': [0.11877231448239019, 0.9583025830258303, 0.9544452608376194, 0.9622222222222222, 0.9583179638509775], 'test': [1.1735287669272918, 0.5864306784660767, 0.5546282245827011, 0.8650887573964497, 0.675913083680074]}

######################################## 
########################################
Grupo en indetificación:  ['104', '093', '088', '055', '045', '022']  --- principal:  022  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  022  --- group:  ['104', '093', '088', '055', '045', '022']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  022  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6284, Acc: 0.7056, Val Loss: 0.4622, Val Acc: 0.9502
Mejor modelo guardado con Val Loss: 0.4622
Epoch 2/100, Loss: 0.5391, Acc: 0.7717, Val Loss: 0.3612, Val Acc: 0.9502
Mejor modelo guardado con Val Loss: 0.3612
Epoch 3/100, Loss: 0.4900, Acc: 0.7925, Val Loss: 0.2834, Val Acc: 0.9590
Mejor modelo guardado con Val Loss: 0.2834
Epoch 4/100, Loss: 0.4555, Acc: 0.8018, Val Loss: 0.2414, Val Acc: 0.9683
Mejor modelo guardado con Val Loss: 0.2414
Epoch 5/100, Loss: 0.4393, Acc: 0.8079, Val Loss: 0.2080, Val Acc: 0.9635
Mejor modelo guardado con Val Loss: 0.2080
Epoch 6/100, Loss: 0.4215, Acc: 0.8130, Val Loss: 0.1934, Val Acc: 0.9579
Mejor modelo guardado con Val Loss: 0.1934
Epoch 7/100, Loss: 0.4207, Acc: 0.8152, Val Loss: 0.1924, Val Acc: 0.9598
Mejor modelo guardado con Val Loss: 0.1924
Epoch 8/100, Loss: 0.4146, Acc: 0.8191, Val Loss: 0.1722, Val Acc: 0.9753
Mejor modelo guardado con Val Loss: 0.1722
Epoch 9/100, Loss: 0.3983, Acc: 0.8321, Val Loss: 0.1950, Val Acc: 0.9506
Epoch 10/100, Loss: 0.4022, Acc: 0.8276, Val Loss: 0.1687, Val Acc: 0.9731
Mejor modelo guardado con Val Loss: 0.1687
Epoch 11/100, Loss: 0.4092, Acc: 0.8183, Val Loss: 0.1889, Val Acc: 0.9649
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3844, Acc: 0.8403, Val Loss: 0.1522, Val Acc: 0.9749
Mejor modelo guardado con Val Loss: 0.1522
Epoch 13/100, Loss: 0.3818, Acc: 0.8368, Val Loss: 0.1519, Val Acc: 0.9712
Mejor modelo guardado con Val Loss: 0.1519
Epoch 14/100, Loss: 0.3747, Acc: 0.8409, Val Loss: 0.1565, Val Acc: 0.9697
Epoch 15/100, Loss: 0.3726, Acc: 0.8449, Val Loss: 0.1538, Val Acc: 0.9635
Epoch 16/100, Loss: 0.3739, Acc: 0.8419, Val Loss: 0.1350, Val Acc: 0.9742
Mejor modelo guardado con Val Loss: 0.1350
Epoch 17/100, Loss: 0.3739, Acc: 0.8416, Val Loss: 0.1481, Val Acc: 0.9738
Epoch 18/100, Loss: 0.3719, Acc: 0.8429, Val Loss: 0.1368, Val Acc: 0.9775
Epoch 19/100, Loss: 0.3736, Acc: 0.8428, Val Loss: 0.1431, Val Acc: 0.9742
Epoch 20/100, Loss: 0.3678, Acc: 0.8435, Val Loss: 0.1325, Val Acc: 0.9771
Mejor modelo guardado con Val Loss: 0.1325
Epoch 21/100, Loss: 0.3649, Acc: 0.8467, Val Loss: 0.1287, Val Acc: 0.9760
Mejor modelo guardado con Val Loss: 0.1287
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3648, Acc: 0.8486, Val Loss: 0.1362, Val Acc: 0.9712
Epoch 23/100, Loss: 0.3586, Acc: 0.8495, Val Loss: 0.1302, Val Acc: 0.9756
Epoch 24/100, Loss: 0.3599, Acc: 0.8496, Val Loss: 0.1285, Val Acc: 0.9790
Mejor modelo guardado con Val Loss: 0.1285
Epoch 25/100, Loss: 0.3578, Acc: 0.8506, Val Loss: 0.1265, Val Acc: 0.9771
Mejor modelo guardado con Val Loss: 0.1265
Epoch 26/100, Loss: 0.3590, Acc: 0.8477, Val Loss: 0.1427, Val Acc: 0.9694
Epoch 27/100, Loss: 0.3568, Acc: 0.8531, Val Loss: 0.1279, Val Acc: 0.9756
Epoch 28/100, Loss: 0.3546, Acc: 0.8526, Val Loss: 0.1399, Val Acc: 0.9675
Epoch 29/100, Loss: 0.3549, Acc: 0.8555, Val Loss: 0.1229, Val Acc: 0.9775
Mejor modelo guardado con Val Loss: 0.1229
Epoch 30/100, Loss: 0.3548, Acc: 0.8513, Val Loss: 0.1337, Val Acc: 0.9694
Epoch 31/100, Loss: 0.3514, Acc: 0.8555, Val Loss: 0.1260, Val Acc: 0.9731
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3506, Acc: 0.8558, Val Loss: 0.1268, Val Acc: 0.9745
Epoch 33/100, Loss: 0.3521, Acc: 0.8546, Val Loss: 0.1285, Val Acc: 0.9723
Epoch 34/100, Loss: 0.3497, Acc: 0.8539, Val Loss: 0.1464, Val Acc: 0.9605
Epoch 35/100, Loss: 0.3501, Acc: 0.8550, Val Loss: 0.1252, Val Acc: 0.9749
Epoch 36/100, Loss: 0.3496, Acc: 0.8545, Val Loss: 0.1347, Val Acc: 0.9694
Epoch 37/100, Loss: 0.3483, Acc: 0.8580, Val Loss: 0.1173, Val Acc: 0.9779
Mejor modelo guardado con Val Loss: 0.1173
Epoch 38/100, Loss: 0.3484, Acc: 0.8558, Val Loss: 0.1187, Val Acc: 0.9768
Epoch 39/100, Loss: 0.3476, Acc: 0.8560, Val Loss: 0.1375, Val Acc: 0.9683
Epoch 40/100, Loss: 0.3480, Acc: 0.8556, Val Loss: 0.1336, Val Acc: 0.9690
Epoch 41/100, Loss: 0.3461, Acc: 0.8561, Val Loss: 0.1152, Val Acc: 0.9775
Mejor modelo guardado con Val Loss: 0.1152
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3454, Acc: 0.8576, Val Loss: 0.1140, Val Acc: 0.9790
Mejor modelo guardado con Val Loss: 0.1140
Epoch 43/100, Loss: 0.3460, Acc: 0.8560, Val Loss: 0.1178, Val Acc: 0.9760
Epoch 44/100, Loss: 0.3452, Acc: 0.8572, Val Loss: 0.1252, Val Acc: 0.9734
Epoch 45/100, Loss: 0.3454, Acc: 0.8566, Val Loss: 0.1174, Val Acc: 0.9764
Epoch 46/100, Loss: 0.3459, Acc: 0.8574, Val Loss: 0.1132, Val Acc: 0.9786
Mejor modelo guardado con Val Loss: 0.1132
Epoch 47/100, Loss: 0.3443, Acc: 0.8571, Val Loss: 0.1157, Val Acc: 0.9790
Epoch 48/100, Loss: 0.3445, Acc: 0.8580, Val Loss: 0.1316, Val Acc: 0.9686
Epoch 49/100, Loss: 0.3451, Acc: 0.8561, Val Loss: 0.1192, Val Acc: 0.9756
Epoch 50/100, Loss: 0.3449, Acc: 0.8576, Val Loss: 0.1173, Val Acc: 0.9756
Epoch 51/100, Loss: 0.3442, Acc: 0.8563, Val Loss: 0.1160, Val Acc: 0.9771
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3435, Acc: 0.8572, Val Loss: 0.1154, Val Acc: 0.9771
Epoch 53/100, Loss: 0.3433, Acc: 0.8581, Val Loss: 0.1205, Val Acc: 0.9753
Epoch 54/100, Loss: 0.3428, Acc: 0.8591, Val Loss: 0.1214, Val Acc: 0.9749
Epoch 55/100, Loss: 0.3431, Acc: 0.8571, Val Loss: 0.1178, Val Acc: 0.9760
Epoch 56/100, Loss: 0.3431, Acc: 0.8587, Val Loss: 0.1290, Val Acc: 0.9701
Epoch 57/100, Loss: 0.3438, Acc: 0.8572, Val Loss: 0.1193, Val Acc: 0.9753
Epoch 58/100, Loss: 0.3425, Acc: 0.8598, Val Loss: 0.1265, Val Acc: 0.9720
Epoch 59/100, Loss: 0.3423, Acc: 0.8579, Val Loss: 0.1174, Val Acc: 0.9753
Epoch 60/100, Loss: 0.3418, Acc: 0.8588, Val Loss: 0.1157, Val Acc: 0.9768
Epoch 61/100, Loss: 0.3424, Acc: 0.8580, Val Loss: 0.1191, Val Acc: 0.9749
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3414, Acc: 0.8589, Val Loss: 0.1194, Val Acc: 0.9749
Epoch 63/100, Loss: 0.3414, Acc: 0.8588, Val Loss: 0.1172, Val Acc: 0.9760
Epoch 64/100, Loss: 0.3410, Acc: 0.8588, Val Loss: 0.1221, Val Acc: 0.9738
Epoch 65/100, Loss: 0.3413, Acc: 0.8587, Val Loss: 0.1168, Val Acc: 0.9760
Epoch 66/100, Loss: 0.3413, Acc: 0.8592, Val Loss: 0.1176, Val Acc: 0.9760
Epoch 67/100, Loss: 0.3411, Acc: 0.8589, Val Loss: 0.1161, Val Acc: 0.9768
Epoch 68/100, Loss: 0.3413, Acc: 0.8597, Val Loss: 0.1174, Val Acc: 0.9756
Epoch 69/100, Loss: 0.3408, Acc: 0.8600, Val Loss: 0.1206, Val Acc: 0.9745
Epoch 70/100, Loss: 0.3409, Acc: 0.8597, Val Loss: 0.1167, Val Acc: 0.9760
Epoch 71/100, Loss: 0.3407, Acc: 0.8594, Val Loss: 0.1223, Val Acc: 0.9738
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3408, Acc: 0.8602, Val Loss: 0.1168, Val Acc: 0.9764
Epoch 73/100, Loss: 0.3406, Acc: 0.8601, Val Loss: 0.1185, Val Acc: 0.9749
Epoch 74/100, Loss: 0.3406, Acc: 0.8597, Val Loss: 0.1173, Val Acc: 0.9753
Epoch 75/100, Loss: 0.3407, Acc: 0.8598, Val Loss: 0.1166, Val Acc: 0.9760
Epoch 76/100, Loss: 0.3406, Acc: 0.8599, Val Loss: 0.1168, Val Acc: 0.9760
Epoch 77/100, Loss: 0.3404, Acc: 0.8597, Val Loss: 0.1184, Val Acc: 0.9753
Epoch 78/100, Loss: 0.3405, Acc: 0.8597, Val Loss: 0.1165, Val Acc: 0.9764
Epoch 79/100, Loss: 0.3404, Acc: 0.8597, Val Loss: 0.1177, Val Acc: 0.9756
Epoch 80/100, Loss: 0.3404, Acc: 0.8607, Val Loss: 0.1176, Val Acc: 0.9749
Epoch 81/100, Loss: 0.3404, Acc: 0.8605, Val Loss: 0.1181, Val Acc: 0.9753
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3404, Acc: 0.8592, Val Loss: 0.1176, Val Acc: 0.9756
Epoch 83/100, Loss: 0.3403, Acc: 0.8598, Val Loss: 0.1155, Val Acc: 0.9764
Epoch 84/100, Loss: 0.3403, Acc: 0.8593, Val Loss: 0.1174, Val Acc: 0.9756
Epoch 85/100, Loss: 0.3403, Acc: 0.8597, Val Loss: 0.1160, Val Acc: 0.9760
Epoch 86/100, Loss: 0.3404, Acc: 0.8598, Val Loss: 0.1173, Val Acc: 0.9756
Epoch 87/100, Loss: 0.3402, Acc: 0.8586, Val Loss: 0.1180, Val Acc: 0.9745
Epoch 88/100, Loss: 0.3402, Acc: 0.8603, Val Loss: 0.1182, Val Acc: 0.9745
Epoch 89/100, Loss: 0.3401, Acc: 0.8601, Val Loss: 0.1167, Val Acc: 0.9756
Epoch 90/100, Loss: 0.3402, Acc: 0.8603, Val Loss: 0.1183, Val Acc: 0.9745
Epoch 91/100, Loss: 0.3401, Acc: 0.8598, Val Loss: 0.1165, Val Acc: 0.9760
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3401, Acc: 0.8592, Val Loss: 0.1190, Val Acc: 0.9745
Epoch 93/100, Loss: 0.3400, Acc: 0.8603, Val Loss: 0.1162, Val Acc: 0.9764
Epoch 94/100, Loss: 0.3403, Acc: 0.8588, Val Loss: 0.1163, Val Acc: 0.9760
Epoch 95/100, Loss: 0.3400, Acc: 0.8603, Val Loss: 0.1183, Val Acc: 0.9745
Epoch 96/100, Loss: 0.3400, Acc: 0.8603, Val Loss: 0.1168, Val Acc: 0.9760
Epoch 97/100, Loss: 0.3399, Acc: 0.8596, Val Loss: 0.1182, Val Acc: 0.9742
Epoch 98/100, Loss: 0.3398, Acc: 0.8592, Val Loss: 0.1162, Val Acc: 0.9760
Epoch 99/100, Loss: 0.3398, Acc: 0.8592, Val Loss: 0.1162, Val Acc: 0.9764
Epoch 100/100, Loss: 0.3399, Acc: 0.8608, Val Loss: 0.1162, Val Acc: 0.9760

##############################
Resultados para principal:  022  --- grupo:  ['104', '093', '088', '055', '045', '022']  --- window & package numer:  11 
 {'training': [0.33987501308034074, 0.8608095676172953, 0.8812536499902667, 0.8337016574585635, 0.8568183968959969], 'validate': [0.11623934786333594, 0.9760147601476015, 0.9612347451543432, 0.9918518518518519, 0.976303317535545], 'test': [2.049142396428956, 0.3053097345132743, 0.36093684650773733, 0.5106508875739645, 0.4229355550110267]}

##############################
Resultados para window:  11 
 {'104:093:088:055:045:022': {'training': [0.6704058806284261, 0.6076356945722171, 0.5859271278949698, 0.7314917127071823, 0.6506675403390941], 'validate': [0.6171137219251588, 0.7904059040590405, 0.9081419624217119, 0.6444444444444445, 0.7538994800693241], 'test': [0.6385112596008012, 0.723598820058997, 0.736941472624292, 0.6928994082840236, 0.7142421469960354]}, '093:104:088:055:045:022': {'training': [0.6118878834600721, 0.6669733210671573, 0.6553381393752146, 0.7031307550644568, 0.6783937455579246], 'validate': [0.7854306982007138, 0.48929889298892987, 0.4897466827503016, 0.6014814814814815, 0.5398936170212766], 'test': [0.6931965823443431, 0.5011799410029498, 0.3333333333333333, 0.000591715976331361, 0.0011813349084465446]}, '088:104:093:055:045:022': {'training': [0.6337963493131341, 0.5921803127874885, 0.5549190261099483, 0.9276243093922651, 0.6944233818156752], 'validate': [0.4463452017151339, 0.8619926199261992, 0.870257966616085, 0.8496296296296296, 0.8598200899550225], 'test': [0.4494189889222946, 0.863716814159292, 0.813585291113381, 0.942603550295858, 0.8733552631578947]}, '055:104:093:088:045:022': {'training': [0.5385660960571198, 0.7226310947562098, 0.7297811607992388, 0.7062615101289135, 0.7178287318671034], 'validate': [0.35689708140007287, 0.847970479704797, 1.0, 0.6948148148148148, 0.8199300699300699], 'test': [0.4019097131940554, 0.8799410029498526, 0.8843618933493109, 0.8733727810650888, 0.8788329860077404]}, '045:104:093:088:055:022': {'training': [0.22449911156156904, 0.9054277828886844, 0.9159108087679516, 0.892633517495396, 0.9041223652303675], 'validate': [0.11877231448239019, 0.9583025830258303, 0.9544452608376194, 0.9622222222222222, 0.9583179638509775], 'test': [1.1735287669272918, 0.5864306784660767, 0.5546282245827011, 0.8650887573964497, 0.675913083680074]}, '022:104:093:088:055:045': {'training': [0.33987501308034074, 0.8608095676172953, 0.8812536499902667, 0.8337016574585635, 0.8568183968959969], 'validate': [0.11623934786333594, 0.9760147601476015, 0.9612347451543432, 0.9918518518518519, 0.976303317535545], 'test': [2.049142396428956, 0.3053097345132743, 0.36093684650773733, 0.5106508875739645, 0.4229355550110267]}}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  062  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  062  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  062  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4069, Acc: 0.8672, Val Loss: 0.6873, Val Acc: 0.6373
Mejor modelo guardado con Val Loss: 0.6873
Epoch 2/100, Loss: 0.2852, Acc: 0.8879, Val Loss: 0.6940, Val Acc: 0.6432
Epoch 3/100, Loss: 0.2685, Acc: 0.8921, Val Loss: 0.6281, Val Acc: 0.6756
Mejor modelo guardado con Val Loss: 0.6281
Epoch 4/100, Loss: 0.2587, Acc: 0.8949, Val Loss: 0.7415, Val Acc: 0.6435
Epoch 5/100, Loss: 0.2476, Acc: 0.8978, Val Loss: 0.7459, Val Acc: 0.6642
Epoch 6/100, Loss: 0.2498, Acc: 0.8981, Val Loss: 0.6757, Val Acc: 0.6808
Epoch 7/100, Loss: 0.2400, Acc: 0.9006, Val Loss: 0.6354, Val Acc: 0.6771
Epoch 8/100, Loss: 0.2456, Acc: 0.9004, Val Loss: 0.8189, Val Acc: 0.6502
Epoch 9/100, Loss: 0.2339, Acc: 0.9048, Val Loss: 0.7739, Val Acc: 0.6554
Epoch 10/100, Loss: 0.2373, Acc: 0.9029, Val Loss: 0.6554, Val Acc: 0.6838
Epoch 11/100, Loss: 0.2281, Acc: 0.9061, Val Loss: 0.6694, Val Acc: 0.6934
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2173, Acc: 0.9114, Val Loss: 0.6849, Val Acc: 0.6886
Epoch 13/100, Loss: 0.2160, Acc: 0.9105, Val Loss: 0.7485, Val Acc: 0.6616
Epoch 14/100, Loss: 0.2109, Acc: 0.9130, Val Loss: 0.6339, Val Acc: 0.6996
Epoch 15/100, Loss: 0.2123, Acc: 0.9099, Val Loss: 0.7905, Val Acc: 0.6834
Epoch 16/100, Loss: 0.2129, Acc: 0.9110, Val Loss: 0.7022, Val Acc: 0.6904
Epoch 17/100, Loss: 0.2099, Acc: 0.9110, Val Loss: 0.7568, Val Acc: 0.6948
Epoch 18/100, Loss: 0.2139, Acc: 0.9109, Val Loss: 0.6930, Val Acc: 0.6708
Epoch 19/100, Loss: 0.2120, Acc: 0.9114, Val Loss: 0.8087, Val Acc: 0.6771
Epoch 20/100, Loss: 0.2098, Acc: 0.9132, Val Loss: 0.9275, Val Acc: 0.6421
Epoch 21/100, Loss: 0.2098, Acc: 0.9120, Val Loss: 0.7453, Val Acc: 0.6856
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2026, Acc: 0.9154, Val Loss: 0.7599, Val Acc: 0.6893
Epoch 23/100, Loss: 0.1981, Acc: 0.9164, Val Loss: 0.8594, Val Acc: 0.6716
Epoch 24/100, Loss: 0.1963, Acc: 0.9173, Val Loss: 0.7807, Val Acc: 0.6779
Epoch 25/100, Loss: 0.1982, Acc: 0.9173, Val Loss: 0.8235, Val Acc: 0.6690
Epoch 26/100, Loss: 0.1965, Acc: 0.9176, Val Loss: 0.8014, Val Acc: 0.6649
Epoch 27/100, Loss: 0.1968, Acc: 0.9155, Val Loss: 0.8045, Val Acc: 0.6653
Epoch 28/100, Loss: 0.1953, Acc: 0.9178, Val Loss: 0.7495, Val Acc: 0.6911
Epoch 29/100, Loss: 0.1948, Acc: 0.9168, Val Loss: 0.7651, Val Acc: 0.6841
Epoch 30/100, Loss: 0.1924, Acc: 0.9190, Val Loss: 0.8669, Val Acc: 0.6694
Epoch 31/100, Loss: 0.1943, Acc: 0.9186, Val Loss: 0.8438, Val Acc: 0.6657
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.1918, Acc: 0.9184, Val Loss: 0.8241, Val Acc: 0.6672
Epoch 33/100, Loss: 0.1922, Acc: 0.9194, Val Loss: 0.8064, Val Acc: 0.6771
Epoch 34/100, Loss: 0.1904, Acc: 0.9201, Val Loss: 0.8102, Val Acc: 0.6790
Epoch 35/100, Loss: 0.1913, Acc: 0.9198, Val Loss: 0.8579, Val Acc: 0.6712
Epoch 36/100, Loss: 0.1896, Acc: 0.9200, Val Loss: 0.7918, Val Acc: 0.6779
Epoch 37/100, Loss: 0.1889, Acc: 0.9219, Val Loss: 0.8002, Val Acc: 0.6657
Epoch 38/100, Loss: 0.1885, Acc: 0.9203, Val Loss: 0.8263, Val Acc: 0.6742
Epoch 39/100, Loss: 0.1879, Acc: 0.9233, Val Loss: 0.8087, Val Acc: 0.6801
Epoch 40/100, Loss: 0.1881, Acc: 0.9212, Val Loss: 0.8771, Val Acc: 0.6683
Epoch 41/100, Loss: 0.1875, Acc: 0.9226, Val Loss: 0.7592, Val Acc: 0.6779
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.1852, Acc: 0.9224, Val Loss: 0.8824, Val Acc: 0.6672
Epoch 43/100, Loss: 0.1848, Acc: 0.9236, Val Loss: 0.8384, Val Acc: 0.6764
Epoch 44/100, Loss: 0.1850, Acc: 0.9233, Val Loss: 0.8073, Val Acc: 0.6779
Epoch 45/100, Loss: 0.1838, Acc: 0.9226, Val Loss: 0.8324, Val Acc: 0.6756
Epoch 46/100, Loss: 0.1839, Acc: 0.9228, Val Loss: 0.8077, Val Acc: 0.6768
Epoch 47/100, Loss: 0.1839, Acc: 0.9229, Val Loss: 0.8479, Val Acc: 0.6716
Epoch 48/100, Loss: 0.1836, Acc: 0.9232, Val Loss: 0.8104, Val Acc: 0.6760
Epoch 49/100, Loss: 0.1835, Acc: 0.9242, Val Loss: 0.8407, Val Acc: 0.6771
Epoch 50/100, Loss: 0.1832, Acc: 0.9236, Val Loss: 0.8120, Val Acc: 0.6775
Epoch 51/100, Loss: 0.1835, Acc: 0.9241, Val Loss: 0.8102, Val Acc: 0.6779
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.1822, Acc: 0.9247, Val Loss: 0.8167, Val Acc: 0.6801
Epoch 53/100, Loss: 0.1818, Acc: 0.9236, Val Loss: 0.8534, Val Acc: 0.6742
Epoch 54/100, Loss: 0.1816, Acc: 0.9233, Val Loss: 0.8308, Val Acc: 0.6771
Epoch 55/100, Loss: 0.1816, Acc: 0.9245, Val Loss: 0.8396, Val Acc: 0.6775
Epoch 56/100, Loss: 0.1816, Acc: 0.9248, Val Loss: 0.8360, Val Acc: 0.6775
Epoch 57/100, Loss: 0.1812, Acc: 0.9245, Val Loss: 0.8443, Val Acc: 0.6760
Epoch 58/100, Loss: 0.1811, Acc: 0.9255, Val Loss: 0.8526, Val Acc: 0.6745
Epoch 59/100, Loss: 0.1811, Acc: 0.9247, Val Loss: 0.8396, Val Acc: 0.6756
Epoch 60/100, Loss: 0.1809, Acc: 0.9242, Val Loss: 0.8445, Val Acc: 0.6760
Epoch 61/100, Loss: 0.1809, Acc: 0.9243, Val Loss: 0.8399, Val Acc: 0.6768
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.1804, Acc: 0.9257, Val Loss: 0.8403, Val Acc: 0.6779
Epoch 63/100, Loss: 0.1803, Acc: 0.9246, Val Loss: 0.8401, Val Acc: 0.6771
Epoch 64/100, Loss: 0.1802, Acc: 0.9243, Val Loss: 0.8370, Val Acc: 0.6771
Epoch 65/100, Loss: 0.1800, Acc: 0.9246, Val Loss: 0.8572, Val Acc: 0.6760
Epoch 66/100, Loss: 0.1803, Acc: 0.9253, Val Loss: 0.8451, Val Acc: 0.6790
Epoch 67/100, Loss: 0.1801, Acc: 0.9247, Val Loss: 0.8441, Val Acc: 0.6779
Epoch 68/100, Loss: 0.1801, Acc: 0.9253, Val Loss: 0.8435, Val Acc: 0.6790
Epoch 69/100, Loss: 0.1798, Acc: 0.9258, Val Loss: 0.8429, Val Acc: 0.6779
Epoch 70/100, Loss: 0.1799, Acc: 0.9253, Val Loss: 0.8548, Val Acc: 0.6786
Epoch 71/100, Loss: 0.1798, Acc: 0.9248, Val Loss: 0.8550, Val Acc: 0.6771
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.1796, Acc: 0.9249, Val Loss: 0.8420, Val Acc: 0.6782
Epoch 73/100, Loss: 0.1795, Acc: 0.9252, Val Loss: 0.8373, Val Acc: 0.6775
Epoch 74/100, Loss: 0.1795, Acc: 0.9254, Val Loss: 0.8423, Val Acc: 0.6786
Epoch 75/100, Loss: 0.1794, Acc: 0.9246, Val Loss: 0.8527, Val Acc: 0.6760
Epoch 76/100, Loss: 0.1793, Acc: 0.9251, Val Loss: 0.8440, Val Acc: 0.6786
Epoch 77/100, Loss: 0.1796, Acc: 0.9257, Val Loss: 0.8696, Val Acc: 0.6764
Epoch 78/100, Loss: 0.1794, Acc: 0.9246, Val Loss: 0.8533, Val Acc: 0.6775
Epoch 79/100, Loss: 0.1792, Acc: 0.9258, Val Loss: 0.8563, Val Acc: 0.6782
Epoch 80/100, Loss: 0.1793, Acc: 0.9253, Val Loss: 0.8378, Val Acc: 0.6793
Epoch 81/100, Loss: 0.1792, Acc: 0.9259, Val Loss: 0.8544, Val Acc: 0.6775
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.1791, Acc: 0.9249, Val Loss: 0.8480, Val Acc: 0.6793
Epoch 83/100, Loss: 0.1791, Acc: 0.9256, Val Loss: 0.8550, Val Acc: 0.6786
Epoch 84/100, Loss: 0.1791, Acc: 0.9252, Val Loss: 0.8487, Val Acc: 0.6790
Epoch 85/100, Loss: 0.1790, Acc: 0.9248, Val Loss: 0.8554, Val Acc: 0.6775
Epoch 86/100, Loss: 0.1790, Acc: 0.9254, Val Loss: 0.8661, Val Acc: 0.6764
Epoch 87/100, Loss: 0.1790, Acc: 0.9251, Val Loss: 0.8545, Val Acc: 0.6768
Epoch 88/100, Loss: 0.1790, Acc: 0.9257, Val Loss: 0.8454, Val Acc: 0.6779
Epoch 89/100, Loss: 0.1789, Acc: 0.9254, Val Loss: 0.8541, Val Acc: 0.6790
Epoch 90/100, Loss: 0.1788, Acc: 0.9247, Val Loss: 0.8473, Val Acc: 0.6786
Epoch 91/100, Loss: 0.1787, Acc: 0.9256, Val Loss: 0.8482, Val Acc: 0.6779
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.1787, Acc: 0.9256, Val Loss: 0.8524, Val Acc: 0.6782
Epoch 93/100, Loss: 0.1787, Acc: 0.9256, Val Loss: 0.8484, Val Acc: 0.6779
Epoch 94/100, Loss: 0.1786, Acc: 0.9257, Val Loss: 0.8708, Val Acc: 0.6742
Epoch 95/100, Loss: 0.1785, Acc: 0.9251, Val Loss: 0.8623, Val Acc: 0.6768
Epoch 96/100, Loss: 0.1786, Acc: 0.9251, Val Loss: 0.8557, Val Acc: 0.6786
Epoch 97/100, Loss: 0.1786, Acc: 0.9255, Val Loss: 0.8583, Val Acc: 0.6771
Epoch 98/100, Loss: 0.1785, Acc: 0.9259, Val Loss: 0.8475, Val Acc: 0.6782
Epoch 99/100, Loss: 0.1784, Acc: 0.9252, Val Loss: 0.8451, Val Acc: 0.6782
Epoch 100/100, Loss: 0.1783, Acc: 0.9253, Val Loss: 0.8475, Val Acc: 0.6782

##############################
Resultados para principal:  062  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11 
 {'training': [0.17825482451488034, 0.9252989880404784, 0.9145421903052064, 0.938121546961326, 0.9261818181818182], 'validate': [0.8474564817409183, 0.6782287822878229, 0.7792056074766355, 0.49407407407407405, 0.6047144152311876], 'test': [0.21172386731179255, 0.935693215339233, 0.9730077120822622, 0.8958579881656805, 0.9328404189772027]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  035  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  035  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  035  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6662, Acc: 0.6592, Val Loss: 0.6405, Val Acc: 0.7173
Mejor modelo guardado con Val Loss: 0.6405
Epoch 2/100, Loss: 0.6181, Acc: 0.7282, Val Loss: 0.5998, Val Acc: 0.7295
Mejor modelo guardado con Val Loss: 0.5998
Epoch 3/100, Loss: 0.5720, Acc: 0.7483, Val Loss: 0.5303, Val Acc: 0.7934
Mejor modelo guardado con Val Loss: 0.5303
Epoch 4/100, Loss: 0.5433, Acc: 0.7580, Val Loss: 0.5427, Val Acc: 0.7506
Epoch 5/100, Loss: 0.5246, Acc: 0.7605, Val Loss: 0.4629, Val Acc: 0.8052
Mejor modelo guardado con Val Loss: 0.4629
Epoch 6/100, Loss: 0.5004, Acc: 0.7716, Val Loss: 0.5033, Val Acc: 0.7705
Epoch 7/100, Loss: 0.4967, Acc: 0.7694, Val Loss: 0.4842, Val Acc: 0.7849
Epoch 8/100, Loss: 0.4845, Acc: 0.7768, Val Loss: 0.4294, Val Acc: 0.8196
Mejor modelo guardado con Val Loss: 0.4294
Epoch 9/100, Loss: 0.4850, Acc: 0.7731, Val Loss: 0.4445, Val Acc: 0.8148
Epoch 10/100, Loss: 0.4815, Acc: 0.7790, Val Loss: 0.4623, Val Acc: 0.7978
Epoch 11/100, Loss: 0.4730, Acc: 0.7830, Val Loss: 0.4380, Val Acc: 0.8137
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4589, Acc: 0.7919, Val Loss: 0.4422, Val Acc: 0.8155
Epoch 13/100, Loss: 0.4565, Acc: 0.7953, Val Loss: 0.4315, Val Acc: 0.8221
Epoch 14/100, Loss: 0.4515, Acc: 0.7967, Val Loss: 0.4192, Val Acc: 0.8255
Mejor modelo guardado con Val Loss: 0.4192
Epoch 15/100, Loss: 0.4541, Acc: 0.7957, Val Loss: 0.4497, Val Acc: 0.8103
Epoch 16/100, Loss: 0.4476, Acc: 0.7999, Val Loss: 0.4121, Val Acc: 0.8288
Mejor modelo guardado con Val Loss: 0.4121
Epoch 17/100, Loss: 0.4503, Acc: 0.8011, Val Loss: 0.4173, Val Acc: 0.8229
Epoch 18/100, Loss: 0.4433, Acc: 0.8024, Val Loss: 0.4262, Val Acc: 0.8188
Epoch 19/100, Loss: 0.4429, Acc: 0.8027, Val Loss: 0.4043, Val Acc: 0.8306
Mejor modelo guardado con Val Loss: 0.4043
Epoch 20/100, Loss: 0.4421, Acc: 0.7989, Val Loss: 0.4152, Val Acc: 0.8273
Epoch 21/100, Loss: 0.4391, Acc: 0.8018, Val Loss: 0.4261, Val Acc: 0.8225
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4358, Acc: 0.8052, Val Loss: 0.4006, Val Acc: 0.8339
Mejor modelo guardado con Val Loss: 0.4006
Epoch 23/100, Loss: 0.4331, Acc: 0.8084, Val Loss: 0.4110, Val Acc: 0.8325
Epoch 24/100, Loss: 0.4283, Acc: 0.8101, Val Loss: 0.4275, Val Acc: 0.8170
Epoch 25/100, Loss: 0.4279, Acc: 0.8101, Val Loss: 0.4525, Val Acc: 0.8092
Epoch 26/100, Loss: 0.4318, Acc: 0.8082, Val Loss: 0.4235, Val Acc: 0.8262
Epoch 27/100, Loss: 0.4258, Acc: 0.8118, Val Loss: 0.4144, Val Acc: 0.8273
Epoch 28/100, Loss: 0.4263, Acc: 0.8106, Val Loss: 0.4513, Val Acc: 0.8114
Epoch 29/100, Loss: 0.4246, Acc: 0.8118, Val Loss: 0.4668, Val Acc: 0.8018
Epoch 30/100, Loss: 0.4282, Acc: 0.8098, Val Loss: 0.4217, Val Acc: 0.8240
Epoch 31/100, Loss: 0.4275, Acc: 0.8117, Val Loss: 0.4136, Val Acc: 0.8269
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4191, Acc: 0.8159, Val Loss: 0.4251, Val Acc: 0.8240
Epoch 33/100, Loss: 0.4193, Acc: 0.8165, Val Loss: 0.4134, Val Acc: 0.8251
Epoch 34/100, Loss: 0.4174, Acc: 0.8177, Val Loss: 0.4074, Val Acc: 0.8288
Epoch 35/100, Loss: 0.4161, Acc: 0.8161, Val Loss: 0.4259, Val Acc: 0.8225
Epoch 36/100, Loss: 0.4166, Acc: 0.8183, Val Loss: 0.4038, Val Acc: 0.8303
Epoch 37/100, Loss: 0.4151, Acc: 0.8158, Val Loss: 0.4235, Val Acc: 0.8244
Epoch 38/100, Loss: 0.4141, Acc: 0.8178, Val Loss: 0.4062, Val Acc: 0.8288
Epoch 39/100, Loss: 0.4138, Acc: 0.8194, Val Loss: 0.4235, Val Acc: 0.8218
Epoch 40/100, Loss: 0.4149, Acc: 0.8166, Val Loss: 0.4153, Val Acc: 0.8280
Epoch 41/100, Loss: 0.4128, Acc: 0.8202, Val Loss: 0.4234, Val Acc: 0.8225
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4117, Acc: 0.8196, Val Loss: 0.4077, Val Acc: 0.8306
Epoch 43/100, Loss: 0.4118, Acc: 0.8208, Val Loss: 0.4126, Val Acc: 0.8295
Epoch 44/100, Loss: 0.4100, Acc: 0.8214, Val Loss: 0.4166, Val Acc: 0.8269
Epoch 45/100, Loss: 0.4105, Acc: 0.8197, Val Loss: 0.4157, Val Acc: 0.8258
Epoch 46/100, Loss: 0.4089, Acc: 0.8231, Val Loss: 0.4126, Val Acc: 0.8295
Epoch 47/100, Loss: 0.4087, Acc: 0.8204, Val Loss: 0.4124, Val Acc: 0.8280
Epoch 48/100, Loss: 0.4085, Acc: 0.8190, Val Loss: 0.4179, Val Acc: 0.8251
Epoch 49/100, Loss: 0.4092, Acc: 0.8213, Val Loss: 0.4097, Val Acc: 0.8288
Epoch 50/100, Loss: 0.4074, Acc: 0.8211, Val Loss: 0.4081, Val Acc: 0.8292
Epoch 51/100, Loss: 0.4065, Acc: 0.8221, Val Loss: 0.4267, Val Acc: 0.8218
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4063, Acc: 0.8215, Val Loss: 0.4192, Val Acc: 0.8258
Epoch 53/100, Loss: 0.4063, Acc: 0.8225, Val Loss: 0.4098, Val Acc: 0.8314
Epoch 54/100, Loss: 0.4065, Acc: 0.8226, Val Loss: 0.4071, Val Acc: 0.8306
Epoch 55/100, Loss: 0.4055, Acc: 0.8218, Val Loss: 0.4191, Val Acc: 0.8244
Epoch 56/100, Loss: 0.4054, Acc: 0.8234, Val Loss: 0.4141, Val Acc: 0.8295
Epoch 57/100, Loss: 0.4051, Acc: 0.8229, Val Loss: 0.4215, Val Acc: 0.8244
Epoch 58/100, Loss: 0.4052, Acc: 0.8219, Val Loss: 0.4202, Val Acc: 0.8244
Epoch 59/100, Loss: 0.4042, Acc: 0.8232, Val Loss: 0.4331, Val Acc: 0.8192
Epoch 60/100, Loss: 0.4042, Acc: 0.8225, Val Loss: 0.4148, Val Acc: 0.8295
Epoch 61/100, Loss: 0.4043, Acc: 0.8224, Val Loss: 0.4142, Val Acc: 0.8295
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4038, Acc: 0.8241, Val Loss: 0.4113, Val Acc: 0.8295
Epoch 63/100, Loss: 0.4036, Acc: 0.8242, Val Loss: 0.4088, Val Acc: 0.8310
Epoch 64/100, Loss: 0.4037, Acc: 0.8241, Val Loss: 0.4114, Val Acc: 0.8292
Epoch 65/100, Loss: 0.4036, Acc: 0.8238, Val Loss: 0.4139, Val Acc: 0.8284
Epoch 66/100, Loss: 0.4038, Acc: 0.8234, Val Loss: 0.4158, Val Acc: 0.8280
Epoch 67/100, Loss: 0.4032, Acc: 0.8228, Val Loss: 0.4084, Val Acc: 0.8310
Epoch 68/100, Loss: 0.4032, Acc: 0.8229, Val Loss: 0.4137, Val Acc: 0.8284
Epoch 69/100, Loss: 0.4028, Acc: 0.8236, Val Loss: 0.4146, Val Acc: 0.8277
Epoch 70/100, Loss: 0.4035, Acc: 0.8238, Val Loss: 0.4103, Val Acc: 0.8299
Epoch 71/100, Loss: 0.4031, Acc: 0.8251, Val Loss: 0.4148, Val Acc: 0.8292
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4027, Acc: 0.8247, Val Loss: 0.4129, Val Acc: 0.8292
Epoch 73/100, Loss: 0.4028, Acc: 0.8236, Val Loss: 0.4186, Val Acc: 0.8258
Epoch 74/100, Loss: 0.4026, Acc: 0.8248, Val Loss: 0.4182, Val Acc: 0.8262
Epoch 75/100, Loss: 0.4025, Acc: 0.8246, Val Loss: 0.4133, Val Acc: 0.8288
Epoch 76/100, Loss: 0.4025, Acc: 0.8243, Val Loss: 0.4154, Val Acc: 0.8288
Epoch 77/100, Loss: 0.4024, Acc: 0.8255, Val Loss: 0.4102, Val Acc: 0.8295
Epoch 78/100, Loss: 0.4023, Acc: 0.8246, Val Loss: 0.4148, Val Acc: 0.8284
Epoch 79/100, Loss: 0.4022, Acc: 0.8247, Val Loss: 0.4125, Val Acc: 0.8299
Epoch 80/100, Loss: 0.4022, Acc: 0.8254, Val Loss: 0.4122, Val Acc: 0.8292
Epoch 81/100, Loss: 0.4023, Acc: 0.8242, Val Loss: 0.4162, Val Acc: 0.8280
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4020, Acc: 0.8238, Val Loss: 0.4094, Val Acc: 0.8303
Epoch 83/100, Loss: 0.4020, Acc: 0.8237, Val Loss: 0.4123, Val Acc: 0.8295
Epoch 84/100, Loss: 0.4019, Acc: 0.8246, Val Loss: 0.4130, Val Acc: 0.8292
Epoch 85/100, Loss: 0.4018, Acc: 0.8240, Val Loss: 0.4116, Val Acc: 0.8295
Epoch 86/100, Loss: 0.4018, Acc: 0.8238, Val Loss: 0.4197, Val Acc: 0.8262
Epoch 87/100, Loss: 0.4019, Acc: 0.8252, Val Loss: 0.4110, Val Acc: 0.8299
Epoch 88/100, Loss: 0.4017, Acc: 0.8237, Val Loss: 0.4144, Val Acc: 0.8280
Epoch 89/100, Loss: 0.4016, Acc: 0.8251, Val Loss: 0.4149, Val Acc: 0.8280
Epoch 90/100, Loss: 0.4016, Acc: 0.8247, Val Loss: 0.4187, Val Acc: 0.8273
Epoch 91/100, Loss: 0.4013, Acc: 0.8257, Val Loss: 0.4148, Val Acc: 0.8284
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4016, Acc: 0.8240, Val Loss: 0.4116, Val Acc: 0.8303
Epoch 93/100, Loss: 0.4013, Acc: 0.8257, Val Loss: 0.4222, Val Acc: 0.8240
Epoch 94/100, Loss: 0.4012, Acc: 0.8250, Val Loss: 0.4151, Val Acc: 0.8280
Epoch 95/100, Loss: 0.4012, Acc: 0.8247, Val Loss: 0.4161, Val Acc: 0.8277
Epoch 96/100, Loss: 0.4013, Acc: 0.8252, Val Loss: 0.4154, Val Acc: 0.8277
Epoch 97/100, Loss: 0.4010, Acc: 0.8251, Val Loss: 0.4117, Val Acc: 0.8292
Epoch 98/100, Loss: 0.4009, Acc: 0.8253, Val Loss: 0.4142, Val Acc: 0.8277
Epoch 99/100, Loss: 0.4008, Acc: 0.8251, Val Loss: 0.4136, Val Acc: 0.8277
Epoch 100/100, Loss: 0.4009, Acc: 0.8251, Val Loss: 0.4143, Val Acc: 0.8280

##############################
Resultados para principal:  035  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11 
 {'training': [0.4009109954715543, 0.825114995400184, 0.816843239360747, 0.8377532228360958, 0.8271661060096372], 'validate': [0.41425987281078513, 0.8280442804428044, 0.779746835443038, 0.9125925925925926, 0.8409556313993174], 'test': [0.46543725228534555, 0.7805309734513274, 0.7280617164898746, 0.893491124260355, 0.8023379383634431]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  002  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  002  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  002  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6850, Acc: 0.5558, Val Loss: 0.6894, Val Acc: 0.5273
Mejor modelo guardado con Val Loss: 0.6894
Epoch 2/100, Loss: 0.6793, Acc: 0.5715, Val Loss: 0.6890, Val Acc: 0.5413
Mejor modelo guardado con Val Loss: 0.6890
Epoch 3/100, Loss: 0.6663, Acc: 0.5890, Val Loss: 0.6828, Val Acc: 0.5756
Mejor modelo guardado con Val Loss: 0.6828
Epoch 4/100, Loss: 0.6553, Acc: 0.6060, Val Loss: 0.6841, Val Acc: 0.5720
Epoch 5/100, Loss: 0.6487, Acc: 0.6121, Val Loss: 0.6900, Val Acc: 0.5365
Epoch 6/100, Loss: 0.6398, Acc: 0.6300, Val Loss: 0.6933, Val Acc: 0.5284
Epoch 7/100, Loss: 0.6347, Acc: 0.6360, Val Loss: 0.6964, Val Acc: 0.5125
Epoch 8/100, Loss: 0.6312, Acc: 0.6354, Val Loss: 0.7010, Val Acc: 0.5288
Epoch 9/100, Loss: 0.6259, Acc: 0.6436, Val Loss: 0.6936, Val Acc: 0.5443
Epoch 10/100, Loss: 0.6182, Acc: 0.6517, Val Loss: 0.7008, Val Acc: 0.5469
Epoch 11/100, Loss: 0.6156, Acc: 0.6580, Val Loss: 0.6962, Val Acc: 0.5539
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6070, Acc: 0.6653, Val Loss: 0.7070, Val Acc: 0.5310
Epoch 13/100, Loss: 0.6013, Acc: 0.6716, Val Loss: 0.7138, Val Acc: 0.5240
Epoch 14/100, Loss: 0.6012, Acc: 0.6672, Val Loss: 0.7054, Val Acc: 0.5251
Epoch 15/100, Loss: 0.5981, Acc: 0.6769, Val Loss: 0.7173, Val Acc: 0.5225
Epoch 16/100, Loss: 0.5953, Acc: 0.6760, Val Loss: 0.7125, Val Acc: 0.5343
Epoch 17/100, Loss: 0.5963, Acc: 0.6746, Val Loss: 0.7006, Val Acc: 0.5572
Epoch 18/100, Loss: 0.5929, Acc: 0.6757, Val Loss: 0.7077, Val Acc: 0.5347
Epoch 19/100, Loss: 0.5923, Acc: 0.6742, Val Loss: 0.7154, Val Acc: 0.5170
Epoch 20/100, Loss: 0.5883, Acc: 0.6792, Val Loss: 0.7104, Val Acc: 0.5365
Epoch 21/100, Loss: 0.5874, Acc: 0.6739, Val Loss: 0.7136, Val Acc: 0.5210
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5821, Acc: 0.6883, Val Loss: 0.7191, Val Acc: 0.5207
Epoch 23/100, Loss: 0.5813, Acc: 0.6871, Val Loss: 0.7245, Val Acc: 0.5089
Epoch 24/100, Loss: 0.5826, Acc: 0.6856, Val Loss: 0.7141, Val Acc: 0.5277
Epoch 25/100, Loss: 0.5802, Acc: 0.6856, Val Loss: 0.7253, Val Acc: 0.5269
Epoch 26/100, Loss: 0.5800, Acc: 0.6851, Val Loss: 0.7101, Val Acc: 0.5428
Epoch 27/100, Loss: 0.5800, Acc: 0.6879, Val Loss: 0.7131, Val Acc: 0.5303
Epoch 28/100, Loss: 0.5791, Acc: 0.6864, Val Loss: 0.7210, Val Acc: 0.5406
Epoch 29/100, Loss: 0.5774, Acc: 0.6908, Val Loss: 0.7384, Val Acc: 0.5170
Epoch 30/100, Loss: 0.5767, Acc: 0.6848, Val Loss: 0.7230, Val Acc: 0.5192
Epoch 31/100, Loss: 0.5763, Acc: 0.6901, Val Loss: 0.7234, Val Acc: 0.5343
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5744, Acc: 0.6895, Val Loss: 0.7247, Val Acc: 0.5196
Epoch 33/100, Loss: 0.5731, Acc: 0.6932, Val Loss: 0.7250, Val Acc: 0.5255
Epoch 34/100, Loss: 0.5735, Acc: 0.6877, Val Loss: 0.7170, Val Acc: 0.5358
Epoch 35/100, Loss: 0.5722, Acc: 0.6906, Val Loss: 0.7147, Val Acc: 0.5395
Epoch 36/100, Loss: 0.5723, Acc: 0.6943, Val Loss: 0.7200, Val Acc: 0.5277
Epoch 37/100, Loss: 0.5717, Acc: 0.6941, Val Loss: 0.7136, Val Acc: 0.5384
Epoch 38/100, Loss: 0.5730, Acc: 0.6906, Val Loss: 0.7214, Val Acc: 0.5236
Epoch 39/100, Loss: 0.5705, Acc: 0.6932, Val Loss: 0.7255, Val Acc: 0.5181
Epoch 40/100, Loss: 0.5717, Acc: 0.6925, Val Loss: 0.7150, Val Acc: 0.5376
Epoch 41/100, Loss: 0.5704, Acc: 0.6939, Val Loss: 0.7333, Val Acc: 0.5247
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5695, Acc: 0.6950, Val Loss: 0.7176, Val Acc: 0.5417
Epoch 43/100, Loss: 0.5685, Acc: 0.6935, Val Loss: 0.7225, Val Acc: 0.5317
Epoch 44/100, Loss: 0.5685, Acc: 0.6946, Val Loss: 0.7217, Val Acc: 0.5336
Epoch 45/100, Loss: 0.5679, Acc: 0.6955, Val Loss: 0.7228, Val Acc: 0.5288
Epoch 46/100, Loss: 0.5684, Acc: 0.6973, Val Loss: 0.7263, Val Acc: 0.5218
Epoch 47/100, Loss: 0.5677, Acc: 0.6945, Val Loss: 0.7311, Val Acc: 0.5255
Epoch 48/100, Loss: 0.5679, Acc: 0.6962, Val Loss: 0.7219, Val Acc: 0.5336
Epoch 49/100, Loss: 0.5672, Acc: 0.6969, Val Loss: 0.7257, Val Acc: 0.5203
Epoch 50/100, Loss: 0.5673, Acc: 0.6948, Val Loss: 0.7260, Val Acc: 0.5207
Epoch 51/100, Loss: 0.5668, Acc: 0.6955, Val Loss: 0.7284, Val Acc: 0.5221
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5665, Acc: 0.6970, Val Loss: 0.7262, Val Acc: 0.5236
Epoch 53/100, Loss: 0.5661, Acc: 0.6970, Val Loss: 0.7267, Val Acc: 0.5240
Epoch 54/100, Loss: 0.5656, Acc: 0.6953, Val Loss: 0.7240, Val Acc: 0.5362
Epoch 55/100, Loss: 0.5657, Acc: 0.6978, Val Loss: 0.7277, Val Acc: 0.5236
Epoch 56/100, Loss: 0.5656, Acc: 0.6965, Val Loss: 0.7285, Val Acc: 0.5214
Epoch 57/100, Loss: 0.5656, Acc: 0.6976, Val Loss: 0.7237, Val Acc: 0.5277
Epoch 58/100, Loss: 0.5653, Acc: 0.6974, Val Loss: 0.7298, Val Acc: 0.5236
Epoch 59/100, Loss: 0.5653, Acc: 0.6980, Val Loss: 0.7293, Val Acc: 0.5232
Epoch 60/100, Loss: 0.5650, Acc: 0.6987, Val Loss: 0.7270, Val Acc: 0.5262
Epoch 61/100, Loss: 0.5650, Acc: 0.6979, Val Loss: 0.7247, Val Acc: 0.5347
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5645, Acc: 0.6986, Val Loss: 0.7244, Val Acc: 0.5358
Epoch 63/100, Loss: 0.5643, Acc: 0.6976, Val Loss: 0.7272, Val Acc: 0.5251
Epoch 64/100, Loss: 0.5640, Acc: 0.6979, Val Loss: 0.7260, Val Acc: 0.5292
Epoch 65/100, Loss: 0.5640, Acc: 0.6989, Val Loss: 0.7289, Val Acc: 0.5214
Epoch 66/100, Loss: 0.5636, Acc: 0.6974, Val Loss: 0.7242, Val Acc: 0.5328
Epoch 67/100, Loss: 0.5635, Acc: 0.6998, Val Loss: 0.7266, Val Acc: 0.5269
Epoch 68/100, Loss: 0.5635, Acc: 0.6998, Val Loss: 0.7282, Val Acc: 0.5247
Epoch 69/100, Loss: 0.5633, Acc: 0.6980, Val Loss: 0.7278, Val Acc: 0.5251
Epoch 70/100, Loss: 0.5633, Acc: 0.6994, Val Loss: 0.7304, Val Acc: 0.5203
Epoch 71/100, Loss: 0.5633, Acc: 0.6996, Val Loss: 0.7284, Val Acc: 0.5221
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5629, Acc: 0.6997, Val Loss: 0.7229, Val Acc: 0.5351
Epoch 73/100, Loss: 0.5633, Acc: 0.6998, Val Loss: 0.7265, Val Acc: 0.5284
Epoch 74/100, Loss: 0.5629, Acc: 0.7002, Val Loss: 0.7284, Val Acc: 0.5236
Epoch 75/100, Loss: 0.5627, Acc: 0.7000, Val Loss: 0.7290, Val Acc: 0.5214
Epoch 76/100, Loss: 0.5622, Acc: 0.7003, Val Loss: 0.7287, Val Acc: 0.5218
Epoch 77/100, Loss: 0.5620, Acc: 0.6996, Val Loss: 0.7274, Val Acc: 0.5244
Epoch 78/100, Loss: 0.5619, Acc: 0.7006, Val Loss: 0.7250, Val Acc: 0.5336
Epoch 79/100, Loss: 0.5621, Acc: 0.7010, Val Loss: 0.7273, Val Acc: 0.5262
Epoch 80/100, Loss: 0.5620, Acc: 0.6993, Val Loss: 0.7272, Val Acc: 0.5284
Epoch 81/100, Loss: 0.5617, Acc: 0.7006, Val Loss: 0.7286, Val Acc: 0.5221
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5615, Acc: 0.6994, Val Loss: 0.7272, Val Acc: 0.5269
Epoch 83/100, Loss: 0.5615, Acc: 0.7007, Val Loss: 0.7277, Val Acc: 0.5244
Epoch 84/100, Loss: 0.5614, Acc: 0.7011, Val Loss: 0.7271, Val Acc: 0.5258
Epoch 85/100, Loss: 0.5611, Acc: 0.7011, Val Loss: 0.7267, Val Acc: 0.5262
Epoch 86/100, Loss: 0.5610, Acc: 0.6999, Val Loss: 0.7281, Val Acc: 0.5221
Epoch 87/100, Loss: 0.5609, Acc: 0.6999, Val Loss: 0.7280, Val Acc: 0.5240
Epoch 88/100, Loss: 0.5608, Acc: 0.7009, Val Loss: 0.7316, Val Acc: 0.5199
Epoch 89/100, Loss: 0.5608, Acc: 0.7000, Val Loss: 0.7284, Val Acc: 0.5229
Epoch 90/100, Loss: 0.5607, Acc: 0.7003, Val Loss: 0.7275, Val Acc: 0.5262
Epoch 91/100, Loss: 0.5605, Acc: 0.7007, Val Loss: 0.7270, Val Acc: 0.5262
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5605, Acc: 0.7021, Val Loss: 0.7275, Val Acc: 0.5266
Epoch 93/100, Loss: 0.5604, Acc: 0.7009, Val Loss: 0.7296, Val Acc: 0.5214
Epoch 94/100, Loss: 0.5604, Acc: 0.7023, Val Loss: 0.7254, Val Acc: 0.5325
Epoch 95/100, Loss: 0.5603, Acc: 0.7004, Val Loss: 0.7287, Val Acc: 0.5229
Epoch 96/100, Loss: 0.5602, Acc: 0.7014, Val Loss: 0.7275, Val Acc: 0.5273
Epoch 97/100, Loss: 0.5601, Acc: 0.7007, Val Loss: 0.7285, Val Acc: 0.5244
Epoch 98/100, Loss: 0.5600, Acc: 0.7029, Val Loss: 0.7302, Val Acc: 0.5199
Epoch 99/100, Loss: 0.5598, Acc: 0.7003, Val Loss: 0.7291, Val Acc: 0.5240
Epoch 100/100, Loss: 0.5597, Acc: 0.7021, Val Loss: 0.7263, Val Acc: 0.5306

##############################
Resultados para principal:  002  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11 
 {'training': [0.5597150688886423, 0.7021159153633855, 0.6998541210795041, 0.7068139963167588, 0.7033168407549936], 'validate': [0.7263419780620309, 0.5306273062730628, 0.5223112128146453, 0.6762962962962963, 0.5894125242091672], 'test': [0.6877493082352404, 0.5743362831858407, 0.580983606557377, 0.5242603550295858, 0.5511664074650078]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  043  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  043  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  043  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5363, Acc: 0.8072, Val Loss: 0.6095, Val Acc: 0.6764
Mejor modelo guardado con Val Loss: 0.6095
Epoch 2/100, Loss: 0.3869, Acc: 0.8498, Val Loss: 0.5904, Val Acc: 0.7162
Mejor modelo guardado con Val Loss: 0.5904
Epoch 3/100, Loss: 0.3264, Acc: 0.8649, Val Loss: 0.6008, Val Acc: 0.7177
Epoch 4/100, Loss: 0.3139, Acc: 0.8690, Val Loss: 0.5513, Val Acc: 0.7328
Mejor modelo guardado con Val Loss: 0.5513
Epoch 5/100, Loss: 0.3003, Acc: 0.8708, Val Loss: 0.5057, Val Acc: 0.7679
Mejor modelo guardado con Val Loss: 0.5057
Epoch 6/100, Loss: 0.2964, Acc: 0.8711, Val Loss: 0.7431, Val Acc: 0.6251
Epoch 7/100, Loss: 0.2781, Acc: 0.8806, Val Loss: 0.5212, Val Acc: 0.7675
Epoch 8/100, Loss: 0.2835, Acc: 0.8824, Val Loss: 0.5558, Val Acc: 0.7620
Epoch 9/100, Loss: 0.2832, Acc: 0.8828, Val Loss: 0.6675, Val Acc: 0.7070
Epoch 10/100, Loss: 0.2947, Acc: 0.8776, Val Loss: 0.5167, Val Acc: 0.7749
Epoch 11/100, Loss: 0.2878, Acc: 0.8805, Val Loss: 0.5353, Val Acc: 0.7779
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2639, Acc: 0.8940, Val Loss: 0.5209, Val Acc: 0.7827
Epoch 13/100, Loss: 0.2627, Acc: 0.8936, Val Loss: 0.6045, Val Acc: 0.7332
Epoch 14/100, Loss: 0.2662, Acc: 0.8908, Val Loss: 0.5157, Val Acc: 0.7801
Epoch 15/100, Loss: 0.2594, Acc: 0.8951, Val Loss: 0.5227, Val Acc: 0.7756
Epoch 16/100, Loss: 0.2575, Acc: 0.8937, Val Loss: 0.5115, Val Acc: 0.7882
Epoch 17/100, Loss: 0.2532, Acc: 0.8978, Val Loss: 0.5451, Val Acc: 0.7712
Epoch 18/100, Loss: 0.2518, Acc: 0.8983, Val Loss: 0.6228, Val Acc: 0.7262
Epoch 19/100, Loss: 0.2478, Acc: 0.8987, Val Loss: 0.5379, Val Acc: 0.7830
Epoch 20/100, Loss: 0.2458, Acc: 0.9000, Val Loss: 0.5289, Val Acc: 0.7797
Epoch 21/100, Loss: 0.2425, Acc: 0.9012, Val Loss: 0.5255, Val Acc: 0.7915
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2355, Acc: 0.9054, Val Loss: 0.5463, Val Acc: 0.7849
Epoch 23/100, Loss: 0.2351, Acc: 0.9059, Val Loss: 0.5610, Val Acc: 0.7723
Epoch 24/100, Loss: 0.2401, Acc: 0.9025, Val Loss: 0.5784, Val Acc: 0.7528
Epoch 25/100, Loss: 0.2343, Acc: 0.9050, Val Loss: 0.5056, Val Acc: 0.7974
Mejor modelo guardado con Val Loss: 0.5056
Epoch 26/100, Loss: 0.2319, Acc: 0.9073, Val Loss: 0.5200, Val Acc: 0.7982
Epoch 27/100, Loss: 0.2324, Acc: 0.9068, Val Loss: 0.5194, Val Acc: 0.8018
Epoch 28/100, Loss: 0.2317, Acc: 0.9062, Val Loss: 0.5833, Val Acc: 0.7679
Epoch 29/100, Loss: 0.2279, Acc: 0.9098, Val Loss: 0.5309, Val Acc: 0.7937
Epoch 30/100, Loss: 0.2273, Acc: 0.9097, Val Loss: 0.5320, Val Acc: 0.7959
Epoch 31/100, Loss: 0.2277, Acc: 0.9095, Val Loss: 0.5569, Val Acc: 0.7867
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2232, Acc: 0.9118, Val Loss: 0.5333, Val Acc: 0.8015
Epoch 33/100, Loss: 0.2227, Acc: 0.9121, Val Loss: 0.5916, Val Acc: 0.7812
Epoch 34/100, Loss: 0.2235, Acc: 0.9112, Val Loss: 0.5654, Val Acc: 0.7852
Epoch 35/100, Loss: 0.2212, Acc: 0.9131, Val Loss: 0.5492, Val Acc: 0.7963
Epoch 36/100, Loss: 0.2214, Acc: 0.9108, Val Loss: 0.5523, Val Acc: 0.7996
Epoch 37/100, Loss: 0.2208, Acc: 0.9114, Val Loss: 0.5176, Val Acc: 0.8000
Epoch 38/100, Loss: 0.2206, Acc: 0.9118, Val Loss: 0.5350, Val Acc: 0.8000
Epoch 39/100, Loss: 0.2212, Acc: 0.9118, Val Loss: 0.5377, Val Acc: 0.8026
Epoch 40/100, Loss: 0.2196, Acc: 0.9127, Val Loss: 0.5780, Val Acc: 0.7838
Epoch 41/100, Loss: 0.2197, Acc: 0.9132, Val Loss: 0.5447, Val Acc: 0.8011
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2160, Acc: 0.9138, Val Loss: 0.5608, Val Acc: 0.7934
Epoch 43/100, Loss: 0.2168, Acc: 0.9148, Val Loss: 0.5942, Val Acc: 0.7764
Epoch 44/100, Loss: 0.2165, Acc: 0.9133, Val Loss: 0.5506, Val Acc: 0.7985
Epoch 45/100, Loss: 0.2152, Acc: 0.9147, Val Loss: 0.5526, Val Acc: 0.8004
Epoch 46/100, Loss: 0.2160, Acc: 0.9142, Val Loss: 0.5632, Val Acc: 0.7904
Epoch 47/100, Loss: 0.2152, Acc: 0.9162, Val Loss: 0.5934, Val Acc: 0.7727
Epoch 48/100, Loss: 0.2171, Acc: 0.9128, Val Loss: 0.5340, Val Acc: 0.8077
Epoch 49/100, Loss: 0.2147, Acc: 0.9154, Val Loss: 0.5464, Val Acc: 0.8004
Epoch 50/100, Loss: 0.2150, Acc: 0.9159, Val Loss: 0.5395, Val Acc: 0.8007
Epoch 51/100, Loss: 0.2140, Acc: 0.9155, Val Loss: 0.5582, Val Acc: 0.7989
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2132, Acc: 0.9154, Val Loss: 0.5451, Val Acc: 0.8011
Epoch 53/100, Loss: 0.2130, Acc: 0.9162, Val Loss: 0.5408, Val Acc: 0.8044
Epoch 54/100, Loss: 0.2130, Acc: 0.9166, Val Loss: 0.5439, Val Acc: 0.8018
Epoch 55/100, Loss: 0.2123, Acc: 0.9167, Val Loss: 0.5397, Val Acc: 0.8022
Epoch 56/100, Loss: 0.2125, Acc: 0.9167, Val Loss: 0.5669, Val Acc: 0.7978
Epoch 57/100, Loss: 0.2125, Acc: 0.9161, Val Loss: 0.5629, Val Acc: 0.7926
Epoch 58/100, Loss: 0.2124, Acc: 0.9160, Val Loss: 0.5491, Val Acc: 0.7989
Epoch 59/100, Loss: 0.2122, Acc: 0.9153, Val Loss: 0.5716, Val Acc: 0.7989
Epoch 60/100, Loss: 0.2121, Acc: 0.9154, Val Loss: 0.5722, Val Acc: 0.7941
Epoch 61/100, Loss: 0.2122, Acc: 0.9167, Val Loss: 0.5580, Val Acc: 0.7963
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2114, Acc: 0.9163, Val Loss: 0.5647, Val Acc: 0.7993
Epoch 63/100, Loss: 0.2112, Acc: 0.9172, Val Loss: 0.5614, Val Acc: 0.8000
Epoch 64/100, Loss: 0.2109, Acc: 0.9175, Val Loss: 0.5633, Val Acc: 0.7985
Epoch 65/100, Loss: 0.2110, Acc: 0.9160, Val Loss: 0.5738, Val Acc: 0.7937
Epoch 66/100, Loss: 0.2110, Acc: 0.9172, Val Loss: 0.5703, Val Acc: 0.7963
Epoch 67/100, Loss: 0.2113, Acc: 0.9172, Val Loss: 0.5669, Val Acc: 0.7978
Epoch 68/100, Loss: 0.2107, Acc: 0.9159, Val Loss: 0.5575, Val Acc: 0.7989
Epoch 69/100, Loss: 0.2107, Acc: 0.9171, Val Loss: 0.5719, Val Acc: 0.7974
Epoch 70/100, Loss: 0.2107, Acc: 0.9174, Val Loss: 0.5719, Val Acc: 0.7967
Epoch 71/100, Loss: 0.2107, Acc: 0.9167, Val Loss: 0.5692, Val Acc: 0.7978
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2104, Acc: 0.9171, Val Loss: 0.5563, Val Acc: 0.8011
Epoch 73/100, Loss: 0.2105, Acc: 0.9168, Val Loss: 0.5646, Val Acc: 0.7996
Epoch 74/100, Loss: 0.2102, Acc: 0.9175, Val Loss: 0.5655, Val Acc: 0.7989
Epoch 75/100, Loss: 0.2102, Acc: 0.9165, Val Loss: 0.5659, Val Acc: 0.7993
Epoch 76/100, Loss: 0.2103, Acc: 0.9171, Val Loss: 0.5613, Val Acc: 0.8000
Epoch 77/100, Loss: 0.2101, Acc: 0.9164, Val Loss: 0.5595, Val Acc: 0.8004
Epoch 78/100, Loss: 0.2100, Acc: 0.9173, Val Loss: 0.5549, Val Acc: 0.8015
Epoch 79/100, Loss: 0.2104, Acc: 0.9164, Val Loss: 0.5605, Val Acc: 0.8004
Epoch 80/100, Loss: 0.2100, Acc: 0.9169, Val Loss: 0.5546, Val Acc: 0.8007
Epoch 81/100, Loss: 0.2101, Acc: 0.9167, Val Loss: 0.5667, Val Acc: 0.7996
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2099, Acc: 0.9174, Val Loss: 0.5637, Val Acc: 0.7996
Epoch 83/100, Loss: 0.2099, Acc: 0.9178, Val Loss: 0.5651, Val Acc: 0.8000
Epoch 84/100, Loss: 0.2100, Acc: 0.9176, Val Loss: 0.5643, Val Acc: 0.8000
Epoch 85/100, Loss: 0.2100, Acc: 0.9171, Val Loss: 0.5716, Val Acc: 0.7948
Epoch 86/100, Loss: 0.2097, Acc: 0.9172, Val Loss: 0.5579, Val Acc: 0.7996
Epoch 87/100, Loss: 0.2097, Acc: 0.9171, Val Loss: 0.5643, Val Acc: 0.7993
Epoch 88/100, Loss: 0.2096, Acc: 0.9167, Val Loss: 0.5636, Val Acc: 0.8000
Epoch 89/100, Loss: 0.2096, Acc: 0.9178, Val Loss: 0.5661, Val Acc: 0.7996
Epoch 90/100, Loss: 0.2097, Acc: 0.9172, Val Loss: 0.5573, Val Acc: 0.8004
Epoch 91/100, Loss: 0.2097, Acc: 0.9167, Val Loss: 0.5602, Val Acc: 0.7996
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2097, Acc: 0.9169, Val Loss: 0.5568, Val Acc: 0.8004
Epoch 93/100, Loss: 0.2097, Acc: 0.9168, Val Loss: 0.5599, Val Acc: 0.7993
Epoch 94/100, Loss: 0.2097, Acc: 0.9171, Val Loss: 0.5540, Val Acc: 0.8007
Epoch 95/100, Loss: 0.2096, Acc: 0.9172, Val Loss: 0.5699, Val Acc: 0.8004
Epoch 96/100, Loss: 0.2095, Acc: 0.9170, Val Loss: 0.5655, Val Acc: 0.8000
Epoch 97/100, Loss: 0.2093, Acc: 0.9177, Val Loss: 0.5646, Val Acc: 0.8007
Epoch 98/100, Loss: 0.2093, Acc: 0.9179, Val Loss: 0.5518, Val Acc: 0.8022
Epoch 99/100, Loss: 0.2092, Acc: 0.9175, Val Loss: 0.5732, Val Acc: 0.7959
Epoch 100/100, Loss: 0.2090, Acc: 0.9166, Val Loss: 0.5574, Val Acc: 0.8011

##############################
Resultados para principal:  043  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11 
 {'training': [0.20904957924617357, 0.9165593376264949, 0.9311725452812202, 0.8994475138121547, 0.9150351288056207], 'validate': [0.5574011993269588, 0.8011070110701107, 0.8696444849589791, 0.7066666666666667, 0.7797302819779321], 'test': [0.4129106363738483, 0.8165191740412979, 0.75, 0.9479289940828403, 0.8374281233664401]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  073  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  073  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  073  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6935, Acc: 0.4999, Val Loss: 0.6975, Val Acc: 0.3875
Mejor modelo guardado con Val Loss: 0.6975
Epoch 2/100, Loss: 0.6922, Acc: 0.5310, Val Loss: 0.6933, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6933
Epoch 3/100, Loss: 0.6933, Acc: 0.5013, Val Loss: 0.6930, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6930
Epoch 4/100, Loss: 0.6935, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.4989
Epoch 5/100, Loss: 0.6935, Acc: 0.4964, Val Loss: 0.6942, Val Acc: 0.4982
Epoch 6/100, Loss: 0.6933, Acc: 0.5056, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 7/100, Loss: 0.6938, Acc: 0.4948, Val Loss: 0.6938, Val Acc: 0.4982
Epoch 8/100, Loss: 0.6936, Acc: 0.4933, Val Loss: 0.6942, Val Acc: 0.4982
Epoch 9/100, Loss: 0.6935, Acc: 0.4922, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 10/100, Loss: 0.6933, Acc: 0.4997, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 11/100, Loss: 0.6933, Acc: 0.4953, Val Loss: 0.6933, Val Acc: 0.4982
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6934, Acc: 0.4960, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 13/100, Loss: 0.6933, Acc: 0.4951, Val Loss: 0.6930, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6930
Epoch 14/100, Loss: 0.6934, Acc: 0.4953, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 15/100, Loss: 0.6933, Acc: 0.5005, Val Loss: 0.6935, Val Acc: 0.4982
Epoch 16/100, Loss: 0.6932, Acc: 0.4971, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 17/100, Loss: 0.6934, Acc: 0.4977, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 18/100, Loss: 0.6932, Acc: 0.5060, Val Loss: 0.6938, Val Acc: 0.4982
Epoch 19/100, Loss: 0.6934, Acc: 0.4988, Val Loss: 0.6930, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6930
Epoch 20/100, Loss: 0.6933, Acc: 0.5008, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 21/100, Loss: 0.6935, Acc: 0.4946, Val Loss: 0.6937, Val Acc: 0.4982
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4970, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 23/100, Loss: 0.6932, Acc: 0.5020, Val Loss: 0.6934, Val Acc: 0.4982
Epoch 24/100, Loss: 0.6932, Acc: 0.4931, Val Loss: 0.6932, Val Acc: 0.4982
Epoch 25/100, Loss: 0.6933, Acc: 0.5017, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 26/100, Loss: 0.6933, Acc: 0.5016, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 27/100, Loss: 0.6932, Acc: 0.4981, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 28/100, Loss: 0.6932, Acc: 0.4989, Val Loss: 0.6941, Val Acc: 0.5018
Epoch 29/100, Loss: 0.6927, Acc: 0.5097, Val Loss: 0.6947, Val Acc: 0.4476
Epoch 30/100, Loss: 0.6924, Acc: 0.5220, Val Loss: 0.6958, Val Acc: 0.3989
Epoch 31/100, Loss: 0.6919, Acc: 0.5524, Val Loss: 0.6960, Val Acc: 0.4310
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6915, Acc: 0.5520, Val Loss: 0.6960, Val Acc: 0.4295
Epoch 33/100, Loss: 0.6912, Acc: 0.5566, Val Loss: 0.6973, Val Acc: 0.3985
Epoch 34/100, Loss: 0.6908, Acc: 0.5621, Val Loss: 0.6967, Val Acc: 0.4244
Epoch 35/100, Loss: 0.6906, Acc: 0.5608, Val Loss: 0.6987, Val Acc: 0.3808
Epoch 36/100, Loss: 0.6902, Acc: 0.5608, Val Loss: 0.6978, Val Acc: 0.4247
Epoch 37/100, Loss: 0.6900, Acc: 0.5640, Val Loss: 0.6974, Val Acc: 0.4292
Epoch 38/100, Loss: 0.6897, Acc: 0.5652, Val Loss: 0.6982, Val Acc: 0.4354
Epoch 39/100, Loss: 0.6892, Acc: 0.5702, Val Loss: 0.7001, Val Acc: 0.4000
Epoch 40/100, Loss: 0.6888, Acc: 0.5715, Val Loss: 0.7018, Val Acc: 0.3815
Epoch 41/100, Loss: 0.6884, Acc: 0.5722, Val Loss: 0.7029, Val Acc: 0.3908
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6881, Acc: 0.5737, Val Loss: 0.7016, Val Acc: 0.3978
Epoch 43/100, Loss: 0.6879, Acc: 0.5726, Val Loss: 0.7028, Val Acc: 0.3923
Epoch 44/100, Loss: 0.6878, Acc: 0.5732, Val Loss: 0.7036, Val Acc: 0.3793
Epoch 45/100, Loss: 0.6875, Acc: 0.5715, Val Loss: 0.7042, Val Acc: 0.3734
Epoch 46/100, Loss: 0.6873, Acc: 0.5752, Val Loss: 0.7043, Val Acc: 0.3812
Epoch 47/100, Loss: 0.6871, Acc: 0.5746, Val Loss: 0.7030, Val Acc: 0.4030
Epoch 48/100, Loss: 0.6869, Acc: 0.5741, Val Loss: 0.7045, Val Acc: 0.3923
Epoch 49/100, Loss: 0.6867, Acc: 0.5761, Val Loss: 0.7042, Val Acc: 0.3982
Epoch 50/100, Loss: 0.6864, Acc: 0.5747, Val Loss: 0.7054, Val Acc: 0.3734
Epoch 51/100, Loss: 0.6859, Acc: 0.5780, Val Loss: 0.7060, Val Acc: 0.3764
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6855, Acc: 0.5772, Val Loss: 0.7053, Val Acc: 0.3923
Epoch 53/100, Loss: 0.6853, Acc: 0.5789, Val Loss: 0.7069, Val Acc: 0.3697
Epoch 54/100, Loss: 0.6852, Acc: 0.5791, Val Loss: 0.7062, Val Acc: 0.3919
Epoch 55/100, Loss: 0.6850, Acc: 0.5802, Val Loss: 0.7071, Val Acc: 0.3860
Epoch 56/100, Loss: 0.6849, Acc: 0.5799, Val Loss: 0.7064, Val Acc: 0.3985
Epoch 57/100, Loss: 0.6848, Acc: 0.5822, Val Loss: 0.7074, Val Acc: 0.3845
Epoch 58/100, Loss: 0.6847, Acc: 0.5802, Val Loss: 0.7067, Val Acc: 0.3985
Epoch 59/100, Loss: 0.6845, Acc: 0.5833, Val Loss: 0.7070, Val Acc: 0.3993
Epoch 60/100, Loss: 0.6844, Acc: 0.5833, Val Loss: 0.7076, Val Acc: 0.3919
Epoch 61/100, Loss: 0.6843, Acc: 0.5812, Val Loss: 0.7086, Val Acc: 0.3849
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6842, Acc: 0.5815, Val Loss: 0.7082, Val Acc: 0.3930
Epoch 63/100, Loss: 0.6841, Acc: 0.5833, Val Loss: 0.7084, Val Acc: 0.3923
Epoch 64/100, Loss: 0.6840, Acc: 0.5825, Val Loss: 0.7087, Val Acc: 0.3959
Epoch 65/100, Loss: 0.6840, Acc: 0.5832, Val Loss: 0.7095, Val Acc: 0.3915
Epoch 66/100, Loss: 0.6839, Acc: 0.5821, Val Loss: 0.7094, Val Acc: 0.3948
Epoch 67/100, Loss: 0.6838, Acc: 0.5820, Val Loss: 0.7106, Val Acc: 0.3863
Epoch 68/100, Loss: 0.6837, Acc: 0.5828, Val Loss: 0.7106, Val Acc: 0.3900
Epoch 69/100, Loss: 0.6836, Acc: 0.5826, Val Loss: 0.7104, Val Acc: 0.3915
Epoch 70/100, Loss: 0.6836, Acc: 0.5812, Val Loss: 0.7109, Val Acc: 0.3886
Epoch 71/100, Loss: 0.6834, Acc: 0.5841, Val Loss: 0.7117, Val Acc: 0.3856
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6833, Acc: 0.5852, Val Loss: 0.7114, Val Acc: 0.3897
Epoch 73/100, Loss: 0.6833, Acc: 0.5835, Val Loss: 0.7112, Val Acc: 0.3897
Epoch 74/100, Loss: 0.6832, Acc: 0.5830, Val Loss: 0.7110, Val Acc: 0.3930
Epoch 75/100, Loss: 0.6832, Acc: 0.5837, Val Loss: 0.7113, Val Acc: 0.3878
Epoch 76/100, Loss: 0.6831, Acc: 0.5841, Val Loss: 0.7112, Val Acc: 0.3923
Epoch 77/100, Loss: 0.6831, Acc: 0.5844, Val Loss: 0.7115, Val Acc: 0.3875
Epoch 78/100, Loss: 0.6830, Acc: 0.5834, Val Loss: 0.7116, Val Acc: 0.3875
Epoch 79/100, Loss: 0.6830, Acc: 0.5855, Val Loss: 0.7115, Val Acc: 0.3926
Epoch 80/100, Loss: 0.6829, Acc: 0.5843, Val Loss: 0.7118, Val Acc: 0.3878
Epoch 81/100, Loss: 0.6829, Acc: 0.5848, Val Loss: 0.7122, Val Acc: 0.3882
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6829, Acc: 0.5847, Val Loss: 0.7121, Val Acc: 0.3889
Epoch 83/100, Loss: 0.6828, Acc: 0.5836, Val Loss: 0.7123, Val Acc: 0.3878
Epoch 84/100, Loss: 0.6828, Acc: 0.5843, Val Loss: 0.7123, Val Acc: 0.3886
Epoch 85/100, Loss: 0.6827, Acc: 0.5846, Val Loss: 0.7123, Val Acc: 0.3893
Epoch 86/100, Loss: 0.6827, Acc: 0.5857, Val Loss: 0.7122, Val Acc: 0.3919
Epoch 87/100, Loss: 0.6826, Acc: 0.5842, Val Loss: 0.7126, Val Acc: 0.3882
Epoch 88/100, Loss: 0.6826, Acc: 0.5841, Val Loss: 0.7130, Val Acc: 0.3860
Epoch 89/100, Loss: 0.6825, Acc: 0.5843, Val Loss: 0.7131, Val Acc: 0.3867
Epoch 90/100, Loss: 0.6825, Acc: 0.5847, Val Loss: 0.7131, Val Acc: 0.3863
Epoch 91/100, Loss: 0.6824, Acc: 0.5852, Val Loss: 0.7129, Val Acc: 0.3882
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6824, Acc: 0.5845, Val Loss: 0.7132, Val Acc: 0.3875
Epoch 93/100, Loss: 0.6823, Acc: 0.5837, Val Loss: 0.7131, Val Acc: 0.3882
Epoch 94/100, Loss: 0.6823, Acc: 0.5844, Val Loss: 0.7135, Val Acc: 0.3871
Epoch 95/100, Loss: 0.6822, Acc: 0.5847, Val Loss: 0.7137, Val Acc: 0.3863
Epoch 96/100, Loss: 0.6820, Acc: 0.5832, Val Loss: 0.7143, Val Acc: 0.3889
Epoch 97/100, Loss: 0.6818, Acc: 0.5852, Val Loss: 0.7154, Val Acc: 0.3856
Epoch 98/100, Loss: 0.6817, Acc: 0.5833, Val Loss: 0.7163, Val Acc: 0.3812
Epoch 99/100, Loss: 0.6816, Acc: 0.5837, Val Loss: 0.7163, Val Acc: 0.3819
Epoch 100/100, Loss: 0.6816, Acc: 0.5850, Val Loss: 0.7162, Val Acc: 0.3830

##############################
Resultados para principal:  073  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11 
 {'training': [0.6815674856593001, 0.5850045998160074, 0.5823624305431081, 0.598342541436464, 0.590244345535471], 'validate': [0.7162060349486595, 0.38302583025830256, 0.4147245762711864, 0.58, 0.4836318715256331], 'test': [0.6932577603268173, 0.5014749262536873, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['062', '035', '002', '043', '073', '109']  --- principal:  109  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  109  --- group:  ['062', '035', '002', '043', '073', '109']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  109  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6698, Acc: 0.6074, Val Loss: 0.7242, Val Acc: 0.3550
Mejor modelo guardado con Val Loss: 0.7242
Epoch 2/100, Loss: 0.6444, Acc: 0.6451, Val Loss: 0.7252, Val Acc: 0.4299
Epoch 3/100, Loss: 0.6303, Acc: 0.6469, Val Loss: 0.7681, Val Acc: 0.3568
Epoch 4/100, Loss: 0.6211, Acc: 0.6466, Val Loss: 0.7565, Val Acc: 0.3878
Epoch 5/100, Loss: 0.6098, Acc: 0.6561, Val Loss: 0.7598, Val Acc: 0.4170
Epoch 6/100, Loss: 0.6027, Acc: 0.6604, Val Loss: 0.7597, Val Acc: 0.4720
Epoch 7/100, Loss: 0.5954, Acc: 0.6614, Val Loss: 0.7626, Val Acc: 0.4458
Epoch 8/100, Loss: 0.5949, Acc: 0.6622, Val Loss: 0.7478, Val Acc: 0.4624
Epoch 9/100, Loss: 0.5910, Acc: 0.6641, Val Loss: 0.7913, Val Acc: 0.4343
Epoch 10/100, Loss: 0.5911, Acc: 0.6636, Val Loss: 0.7588, Val Acc: 0.4384
Epoch 11/100, Loss: 0.5844, Acc: 0.6661, Val Loss: 0.7714, Val Acc: 0.4192
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5807, Acc: 0.6683, Val Loss: 0.7705, Val Acc: 0.4675
Epoch 13/100, Loss: 0.5786, Acc: 0.6741, Val Loss: 0.7672, Val Acc: 0.4605
Epoch 14/100, Loss: 0.5764, Acc: 0.6760, Val Loss: 0.7688, Val Acc: 0.4428
Epoch 15/100, Loss: 0.5791, Acc: 0.6703, Val Loss: 0.8015, Val Acc: 0.4258
Epoch 16/100, Loss: 0.5763, Acc: 0.6727, Val Loss: 0.7811, Val Acc: 0.4565
Epoch 17/100, Loss: 0.5760, Acc: 0.6746, Val Loss: 0.7580, Val Acc: 0.4661
Epoch 18/100, Loss: 0.5733, Acc: 0.6751, Val Loss: 0.7540, Val Acc: 0.4579
Epoch 19/100, Loss: 0.5729, Acc: 0.6764, Val Loss: 0.7569, Val Acc: 0.4686
Epoch 20/100, Loss: 0.5738, Acc: 0.6731, Val Loss: 0.7796, Val Acc: 0.4631
Epoch 21/100, Loss: 0.5714, Acc: 0.6769, Val Loss: 0.7537, Val Acc: 0.4731
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5710, Acc: 0.6783, Val Loss: 0.7650, Val Acc: 0.4590
Epoch 23/100, Loss: 0.5687, Acc: 0.6799, Val Loss: 0.7543, Val Acc: 0.4723
Epoch 24/100, Loss: 0.5681, Acc: 0.6804, Val Loss: 0.7611, Val Acc: 0.4649
Epoch 25/100, Loss: 0.5684, Acc: 0.6799, Val Loss: 0.7622, Val Acc: 0.4627
Epoch 26/100, Loss: 0.5680, Acc: 0.6821, Val Loss: 0.7673, Val Acc: 0.4601
Epoch 27/100, Loss: 0.5667, Acc: 0.6808, Val Loss: 0.7633, Val Acc: 0.4635
Epoch 28/100, Loss: 0.5669, Acc: 0.6836, Val Loss: 0.7759, Val Acc: 0.4520
Epoch 29/100, Loss: 0.5668, Acc: 0.6825, Val Loss: 0.7679, Val Acc: 0.4594
Epoch 30/100, Loss: 0.5669, Acc: 0.6833, Val Loss: 0.7670, Val Acc: 0.4609
Epoch 31/100, Loss: 0.5659, Acc: 0.6832, Val Loss: 0.7627, Val Acc: 0.4675
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5648, Acc: 0.6823, Val Loss: 0.7644, Val Acc: 0.4642
Epoch 33/100, Loss: 0.5649, Acc: 0.6818, Val Loss: 0.7742, Val Acc: 0.4546
Epoch 34/100, Loss: 0.5643, Acc: 0.6815, Val Loss: 0.7694, Val Acc: 0.4598
Epoch 35/100, Loss: 0.5640, Acc: 0.6841, Val Loss: 0.7613, Val Acc: 0.4661
Epoch 36/100, Loss: 0.5642, Acc: 0.6836, Val Loss: 0.7643, Val Acc: 0.4616
Epoch 37/100, Loss: 0.5640, Acc: 0.6827, Val Loss: 0.7615, Val Acc: 0.4664
Epoch 38/100, Loss: 0.5634, Acc: 0.6848, Val Loss: 0.7702, Val Acc: 0.4590
Epoch 39/100, Loss: 0.5635, Acc: 0.6849, Val Loss: 0.7677, Val Acc: 0.4631
Epoch 40/100, Loss: 0.5636, Acc: 0.6840, Val Loss: 0.7680, Val Acc: 0.4609
Epoch 41/100, Loss: 0.5632, Acc: 0.6844, Val Loss: 0.7689, Val Acc: 0.4620
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5628, Acc: 0.6847, Val Loss: 0.7590, Val Acc: 0.4694
Epoch 43/100, Loss: 0.5626, Acc: 0.6847, Val Loss: 0.7722, Val Acc: 0.4613
Epoch 44/100, Loss: 0.5623, Acc: 0.6849, Val Loss: 0.7680, Val Acc: 0.4616
Epoch 45/100, Loss: 0.5619, Acc: 0.6852, Val Loss: 0.7684, Val Acc: 0.4605
Epoch 46/100, Loss: 0.5615, Acc: 0.6854, Val Loss: 0.7644, Val Acc: 0.4646
Epoch 47/100, Loss: 0.5619, Acc: 0.6864, Val Loss: 0.7755, Val Acc: 0.4554
Epoch 48/100, Loss: 0.5616, Acc: 0.6866, Val Loss: 0.7649, Val Acc: 0.4649
Epoch 49/100, Loss: 0.5616, Acc: 0.6859, Val Loss: 0.7641, Val Acc: 0.4646
Epoch 50/100, Loss: 0.5617, Acc: 0.6865, Val Loss: 0.7658, Val Acc: 0.4642
Epoch 51/100, Loss: 0.5613, Acc: 0.6854, Val Loss: 0.7640, Val Acc: 0.4646
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5610, Acc: 0.6853, Val Loss: 0.7706, Val Acc: 0.4601
Epoch 53/100, Loss: 0.5608, Acc: 0.6856, Val Loss: 0.7679, Val Acc: 0.4620
Epoch 54/100, Loss: 0.5609, Acc: 0.6856, Val Loss: 0.7663, Val Acc: 0.4620
Epoch 55/100, Loss: 0.5609, Acc: 0.6859, Val Loss: 0.7667, Val Acc: 0.4627
Epoch 56/100, Loss: 0.5608, Acc: 0.6868, Val Loss: 0.7674, Val Acc: 0.4616
Epoch 57/100, Loss: 0.5607, Acc: 0.6865, Val Loss: 0.7665, Val Acc: 0.4620
Epoch 58/100, Loss: 0.5607, Acc: 0.6865, Val Loss: 0.7735, Val Acc: 0.4587
Epoch 59/100, Loss: 0.5607, Acc: 0.6861, Val Loss: 0.7677, Val Acc: 0.4638
Epoch 60/100, Loss: 0.5605, Acc: 0.6861, Val Loss: 0.7652, Val Acc: 0.4631
Epoch 61/100, Loss: 0.5605, Acc: 0.6865, Val Loss: 0.7676, Val Acc: 0.4616
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5603, Acc: 0.6861, Val Loss: 0.7680, Val Acc: 0.4620
Epoch 63/100, Loss: 0.5603, Acc: 0.6869, Val Loss: 0.7692, Val Acc: 0.4609
Epoch 64/100, Loss: 0.5602, Acc: 0.6867, Val Loss: 0.7685, Val Acc: 0.4613
Epoch 65/100, Loss: 0.5602, Acc: 0.6869, Val Loss: 0.7693, Val Acc: 0.4609
Epoch 66/100, Loss: 0.5601, Acc: 0.6876, Val Loss: 0.7693, Val Acc: 0.4613
Epoch 67/100, Loss: 0.5601, Acc: 0.6865, Val Loss: 0.7706, Val Acc: 0.4609
Epoch 68/100, Loss: 0.5600, Acc: 0.6870, Val Loss: 0.7708, Val Acc: 0.4609
Epoch 69/100, Loss: 0.5600, Acc: 0.6863, Val Loss: 0.7695, Val Acc: 0.4613
Epoch 70/100, Loss: 0.5600, Acc: 0.6871, Val Loss: 0.7682, Val Acc: 0.4627
Epoch 71/100, Loss: 0.5599, Acc: 0.6873, Val Loss: 0.7688, Val Acc: 0.4616
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5597, Acc: 0.6875, Val Loss: 0.7709, Val Acc: 0.4609
Epoch 73/100, Loss: 0.5598, Acc: 0.6874, Val Loss: 0.7706, Val Acc: 0.4609
Epoch 74/100, Loss: 0.5597, Acc: 0.6874, Val Loss: 0.7712, Val Acc: 0.4609
Epoch 75/100, Loss: 0.5597, Acc: 0.6860, Val Loss: 0.7691, Val Acc: 0.4613
Epoch 76/100, Loss: 0.5597, Acc: 0.6874, Val Loss: 0.7683, Val Acc: 0.4624
Epoch 77/100, Loss: 0.5597, Acc: 0.6873, Val Loss: 0.7696, Val Acc: 0.4613
Epoch 78/100, Loss: 0.5597, Acc: 0.6878, Val Loss: 0.7694, Val Acc: 0.4609
Epoch 79/100, Loss: 0.5596, Acc: 0.6869, Val Loss: 0.7692, Val Acc: 0.4609
Epoch 80/100, Loss: 0.5596, Acc: 0.6871, Val Loss: 0.7694, Val Acc: 0.4613
Epoch 81/100, Loss: 0.5596, Acc: 0.6872, Val Loss: 0.7678, Val Acc: 0.4624
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5597, Acc: 0.6875, Val Loss: 0.7690, Val Acc: 0.4609
Epoch 83/100, Loss: 0.5596, Acc: 0.6879, Val Loss: 0.7693, Val Acc: 0.4613
Epoch 84/100, Loss: 0.5596, Acc: 0.6873, Val Loss: 0.7690, Val Acc: 0.4613
Epoch 85/100, Loss: 0.5595, Acc: 0.6876, Val Loss: 0.7702, Val Acc: 0.4609
Epoch 86/100, Loss: 0.5595, Acc: 0.6863, Val Loss: 0.7685, Val Acc: 0.4616
Epoch 87/100, Loss: 0.5595, Acc: 0.6868, Val Loss: 0.7685, Val Acc: 0.4613
Epoch 88/100, Loss: 0.5594, Acc: 0.6864, Val Loss: 0.7681, Val Acc: 0.4613
Epoch 89/100, Loss: 0.5594, Acc: 0.6872, Val Loss: 0.7680, Val Acc: 0.4616
Epoch 90/100, Loss: 0.5593, Acc: 0.6870, Val Loss: 0.7686, Val Acc: 0.4609
Epoch 91/100, Loss: 0.5592, Acc: 0.6879, Val Loss: 0.7693, Val Acc: 0.4609
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5592, Acc: 0.6872, Val Loss: 0.7682, Val Acc: 0.4609
Epoch 93/100, Loss: 0.5592, Acc: 0.6871, Val Loss: 0.7695, Val Acc: 0.4609
Epoch 94/100, Loss: 0.5592, Acc: 0.6868, Val Loss: 0.7679, Val Acc: 0.4616
Epoch 95/100, Loss: 0.5591, Acc: 0.6884, Val Loss: 0.7695, Val Acc: 0.4613
Epoch 96/100, Loss: 0.5590, Acc: 0.6864, Val Loss: 0.7693, Val Acc: 0.4609
Epoch 97/100, Loss: 0.5591, Acc: 0.6862, Val Loss: 0.7694, Val Acc: 0.4609
Epoch 98/100, Loss: 0.5590, Acc: 0.6876, Val Loss: 0.7699, Val Acc: 0.4605
Epoch 99/100, Loss: 0.5590, Acc: 0.6869, Val Loss: 0.7694, Val Acc: 0.4609
Epoch 100/100, Loss: 0.5590, Acc: 0.6870, Val Loss: 0.7688, Val Acc: 0.4609

##############################
Resultados para principal:  109  --- grupo:  ['062', '035', '002', '043', '073', '109']  --- window & package numer:  11 
 {'training': [0.5589518022076625, 0.6870285188592457, 0.6280626420813337, 0.9158379373848987, 0.7451303566077315], 'validate': [0.7687537968158722, 0.46088560885608854, 0.4786620530565167, 0.9222222222222223, 0.6302201974183751], 'test': [0.6902477572549064, 0.5097345132743363, 0.5078740157480315, 0.5343195266272189, 0.5207612456747405]}

##############################
Resultados para window:  11 
 {'062:035:002:043:073:109': {'training': [0.17825482451488034, 0.9252989880404784, 0.9145421903052064, 0.938121546961326, 0.9261818181818182], 'validate': [0.8474564817409183, 0.6782287822878229, 0.7792056074766355, 0.49407407407407405, 0.6047144152311876], 'test': [0.21172386731179255, 0.935693215339233, 0.9730077120822622, 0.8958579881656805, 0.9328404189772027]}, '035:062:002:043:073:109': {'training': [0.4009109954715543, 0.825114995400184, 0.816843239360747, 0.8377532228360958, 0.8271661060096372], 'validate': [0.41425987281078513, 0.8280442804428044, 0.779746835443038, 0.9125925925925926, 0.8409556313993174], 'test': [0.46543725228534555, 0.7805309734513274, 0.7280617164898746, 0.893491124260355, 0.8023379383634431]}, '002:062:035:043:073:109': {'training': [0.5597150688886423, 0.7021159153633855, 0.6998541210795041, 0.7068139963167588, 0.7033168407549936], 'validate': [0.7263419780620309, 0.5306273062730628, 0.5223112128146453, 0.6762962962962963, 0.5894125242091672], 'test': [0.6877493082352404, 0.5743362831858407, 0.580983606557377, 0.5242603550295858, 0.5511664074650078]}, '043:062:035:002:073:109': {'training': [0.20904957924617357, 0.9165593376264949, 0.9311725452812202, 0.8994475138121547, 0.9150351288056207], 'validate': [0.5574011993269588, 0.8011070110701107, 0.8696444849589791, 0.7066666666666667, 0.7797302819779321], 'test': [0.4129106363738483, 0.8165191740412979, 0.75, 0.9479289940828403, 0.8374281233664401]}, '073:062:035:002:043:109': {'training': [0.6815674856593001, 0.5850045998160074, 0.5823624305431081, 0.598342541436464, 0.590244345535471], 'validate': [0.7162060349486595, 0.38302583025830256, 0.4147245762711864, 0.58, 0.4836318715256331], 'test': [0.6932577603268173, 0.5014749262536873, 0.0, 0.0, 0.0]}, '109:062:035:002:043:073': {'training': [0.5589518022076625, 0.6870285188592457, 0.6280626420813337, 0.9158379373848987, 0.7451303566077315], 'validate': [0.7687537968158722, 0.46088560885608854, 0.4786620530565167, 0.9222222222222223, 0.6302201974183751], 'test': [0.6902477572549064, 0.5097345132743363, 0.5078740157480315, 0.5343195266272189, 0.5207612456747405]}}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  098  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  098  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  098  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6670, Acc: 0.6334, Val Loss: 0.6065, Val Acc: 0.8007
Mejor modelo guardado con Val Loss: 0.6065
Epoch 2/100, Loss: 0.6257, Acc: 0.6822, Val Loss: 0.5222, Val Acc: 0.9092
Mejor modelo guardado con Val Loss: 0.5222
Epoch 3/100, Loss: 0.5921, Acc: 0.6918, Val Loss: 0.4613, Val Acc: 0.8524
Mejor modelo guardado con Val Loss: 0.4613
Epoch 4/100, Loss: 0.5698, Acc: 0.6996, Val Loss: 0.4238, Val Acc: 0.9089
Mejor modelo guardado con Val Loss: 0.4238
Epoch 5/100, Loss: 0.5577, Acc: 0.7008, Val Loss: 0.4035, Val Acc: 0.8948
Mejor modelo guardado con Val Loss: 0.4035
Epoch 6/100, Loss: 0.5448, Acc: 0.7022, Val Loss: 0.4530, Val Acc: 0.8668
Epoch 7/100, Loss: 0.5387, Acc: 0.7061, Val Loss: 0.3559, Val Acc: 0.9310
Mejor modelo guardado con Val Loss: 0.3559
Epoch 8/100, Loss: 0.5303, Acc: 0.7067, Val Loss: 0.3471, Val Acc: 0.9085
Mejor modelo guardado con Val Loss: 0.3471
Epoch 9/100, Loss: 0.5262, Acc: 0.7053, Val Loss: 0.3440, Val Acc: 0.9137
Mejor modelo guardado con Val Loss: 0.3440
Epoch 10/100, Loss: 0.5217, Acc: 0.7158, Val Loss: 0.3334, Val Acc: 0.9052
Mejor modelo guardado con Val Loss: 0.3334
Epoch 11/100, Loss: 0.5202, Acc: 0.7261, Val Loss: 0.3243, Val Acc: 0.9188
Mejor modelo guardado con Val Loss: 0.3243
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5053, Acc: 0.7592, Val Loss: 0.3382, Val Acc: 0.9266
Epoch 13/100, Loss: 0.5070, Acc: 0.7550, Val Loss: 0.3139, Val Acc: 0.9151
Mejor modelo guardado con Val Loss: 0.3139
Epoch 14/100, Loss: 0.5027, Acc: 0.7645, Val Loss: 0.3078, Val Acc: 0.9244
Mejor modelo guardado con Val Loss: 0.3078
Epoch 15/100, Loss: 0.4984, Acc: 0.7717, Val Loss: 0.3265, Val Acc: 0.8930
Epoch 16/100, Loss: 0.4980, Acc: 0.7723, Val Loss: 0.3146, Val Acc: 0.9244
Epoch 17/100, Loss: 0.4972, Acc: 0.7695, Val Loss: 0.3106, Val Acc: 0.9159
Epoch 18/100, Loss: 0.4922, Acc: 0.7741, Val Loss: 0.3099, Val Acc: 0.9232
Epoch 19/100, Loss: 0.4903, Acc: 0.7749, Val Loss: 0.3171, Val Acc: 0.9026
Epoch 20/100, Loss: 0.4890, Acc: 0.7764, Val Loss: 0.3235, Val Acc: 0.8952
Epoch 21/100, Loss: 0.4874, Acc: 0.7736, Val Loss: 0.3090, Val Acc: 0.9059
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4822, Acc: 0.7781, Val Loss: 0.3022, Val Acc: 0.9118
Mejor modelo guardado con Val Loss: 0.3022
Epoch 23/100, Loss: 0.4818, Acc: 0.7787, Val Loss: 0.3120, Val Acc: 0.8985
Epoch 24/100, Loss: 0.4805, Acc: 0.7794, Val Loss: 0.2942, Val Acc: 0.9236
Mejor modelo guardado con Val Loss: 0.2942
Epoch 25/100, Loss: 0.4806, Acc: 0.7809, Val Loss: 0.3243, Val Acc: 0.8771
Epoch 26/100, Loss: 0.4792, Acc: 0.7803, Val Loss: 0.3035, Val Acc: 0.9063
Epoch 27/100, Loss: 0.4767, Acc: 0.7816, Val Loss: 0.3057, Val Acc: 0.9041
Epoch 28/100, Loss: 0.4765, Acc: 0.7822, Val Loss: 0.2990, Val Acc: 0.9133
Epoch 29/100, Loss: 0.4765, Acc: 0.7819, Val Loss: 0.2992, Val Acc: 0.9144
Epoch 30/100, Loss: 0.4761, Acc: 0.7826, Val Loss: 0.3029, Val Acc: 0.9100
Epoch 31/100, Loss: 0.4747, Acc: 0.7844, Val Loss: 0.3011, Val Acc: 0.9092
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4720, Acc: 0.7851, Val Loss: 0.3100, Val Acc: 0.8985
Epoch 33/100, Loss: 0.4726, Acc: 0.7828, Val Loss: 0.2985, Val Acc: 0.9114
Epoch 34/100, Loss: 0.4713, Acc: 0.7861, Val Loss: 0.3000, Val Acc: 0.9100
Epoch 35/100, Loss: 0.4711, Acc: 0.7861, Val Loss: 0.2950, Val Acc: 0.9140
Epoch 36/100, Loss: 0.4703, Acc: 0.7852, Val Loss: 0.3028, Val Acc: 0.9055
Epoch 37/100, Loss: 0.4694, Acc: 0.7891, Val Loss: 0.3144, Val Acc: 0.8989
Epoch 38/100, Loss: 0.4695, Acc: 0.7869, Val Loss: 0.3081, Val Acc: 0.8967
Epoch 39/100, Loss: 0.4692, Acc: 0.7874, Val Loss: 0.2994, Val Acc: 0.9111
Epoch 40/100, Loss: 0.4695, Acc: 0.7875, Val Loss: 0.3143, Val Acc: 0.8963
Epoch 41/100, Loss: 0.4686, Acc: 0.7888, Val Loss: 0.2896, Val Acc: 0.9133
Mejor modelo guardado con Val Loss: 0.2896
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4672, Acc: 0.7879, Val Loss: 0.3104, Val Acc: 0.8970
Epoch 43/100, Loss: 0.4668, Acc: 0.7897, Val Loss: 0.3088, Val Acc: 0.8989
Epoch 44/100, Loss: 0.4664, Acc: 0.7894, Val Loss: 0.2996, Val Acc: 0.9092
Epoch 45/100, Loss: 0.4665, Acc: 0.7880, Val Loss: 0.3070, Val Acc: 0.9011
Epoch 46/100, Loss: 0.4660, Acc: 0.7898, Val Loss: 0.3066, Val Acc: 0.9022
Epoch 47/100, Loss: 0.4663, Acc: 0.7893, Val Loss: 0.2979, Val Acc: 0.9118
Epoch 48/100, Loss: 0.4654, Acc: 0.7904, Val Loss: 0.3116, Val Acc: 0.8926
Epoch 49/100, Loss: 0.4654, Acc: 0.7904, Val Loss: 0.3062, Val Acc: 0.8993
Epoch 50/100, Loss: 0.4653, Acc: 0.7896, Val Loss: 0.3027, Val Acc: 0.9063
Epoch 51/100, Loss: 0.4652, Acc: 0.7877, Val Loss: 0.3052, Val Acc: 0.9048
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4647, Acc: 0.7906, Val Loss: 0.3004, Val Acc: 0.9059
Epoch 53/100, Loss: 0.4644, Acc: 0.7911, Val Loss: 0.3006, Val Acc: 0.9107
Epoch 54/100, Loss: 0.4645, Acc: 0.7904, Val Loss: 0.3029, Val Acc: 0.9055
Epoch 55/100, Loss: 0.4644, Acc: 0.7909, Val Loss: 0.2977, Val Acc: 0.9118
Epoch 56/100, Loss: 0.4643, Acc: 0.7901, Val Loss: 0.2968, Val Acc: 0.9103
Epoch 57/100, Loss: 0.4640, Acc: 0.7920, Val Loss: 0.3002, Val Acc: 0.9066
Epoch 58/100, Loss: 0.4641, Acc: 0.7900, Val Loss: 0.3007, Val Acc: 0.9074
Epoch 59/100, Loss: 0.4642, Acc: 0.7910, Val Loss: 0.2979, Val Acc: 0.9100
Epoch 60/100, Loss: 0.4636, Acc: 0.7908, Val Loss: 0.2972, Val Acc: 0.9103
Epoch 61/100, Loss: 0.4636, Acc: 0.7906, Val Loss: 0.3030, Val Acc: 0.9055
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4634, Acc: 0.7915, Val Loss: 0.2982, Val Acc: 0.9103
Epoch 63/100, Loss: 0.4634, Acc: 0.7915, Val Loss: 0.2994, Val Acc: 0.9089
Epoch 64/100, Loss: 0.4632, Acc: 0.7908, Val Loss: 0.2964, Val Acc: 0.9092
Epoch 65/100, Loss: 0.4631, Acc: 0.7914, Val Loss: 0.2966, Val Acc: 0.9118
Epoch 66/100, Loss: 0.4631, Acc: 0.7918, Val Loss: 0.2994, Val Acc: 0.9096
Epoch 67/100, Loss: 0.4631, Acc: 0.7914, Val Loss: 0.2985, Val Acc: 0.9100
Epoch 68/100, Loss: 0.4630, Acc: 0.7925, Val Loss: 0.2970, Val Acc: 0.9092
Epoch 69/100, Loss: 0.4631, Acc: 0.7914, Val Loss: 0.2966, Val Acc: 0.9092
Epoch 70/100, Loss: 0.4629, Acc: 0.7914, Val Loss: 0.3029, Val Acc: 0.9048
Epoch 71/100, Loss: 0.4629, Acc: 0.7915, Val Loss: 0.2959, Val Acc: 0.9100
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4627, Acc: 0.7912, Val Loss: 0.2974, Val Acc: 0.9089
Epoch 73/100, Loss: 0.4627, Acc: 0.7914, Val Loss: 0.3016, Val Acc: 0.9070
Epoch 74/100, Loss: 0.4627, Acc: 0.7918, Val Loss: 0.2999, Val Acc: 0.9092
Epoch 75/100, Loss: 0.4628, Acc: 0.7917, Val Loss: 0.2992, Val Acc: 0.9096
Epoch 76/100, Loss: 0.4626, Acc: 0.7924, Val Loss: 0.2984, Val Acc: 0.9096
Epoch 77/100, Loss: 0.4626, Acc: 0.7914, Val Loss: 0.2972, Val Acc: 0.9085
Epoch 78/100, Loss: 0.4625, Acc: 0.7914, Val Loss: 0.2987, Val Acc: 0.9103
Epoch 79/100, Loss: 0.4625, Acc: 0.7914, Val Loss: 0.3009, Val Acc: 0.9066
Epoch 80/100, Loss: 0.4625, Acc: 0.7925, Val Loss: 0.2974, Val Acc: 0.9107
Epoch 81/100, Loss: 0.4624, Acc: 0.7918, Val Loss: 0.2989, Val Acc: 0.9092
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4624, Acc: 0.7925, Val Loss: 0.2980, Val Acc: 0.9092
Epoch 83/100, Loss: 0.4624, Acc: 0.7927, Val Loss: 0.2991, Val Acc: 0.9092
Epoch 84/100, Loss: 0.4623, Acc: 0.7919, Val Loss: 0.2992, Val Acc: 0.9092
Epoch 85/100, Loss: 0.4623, Acc: 0.7923, Val Loss: 0.2962, Val Acc: 0.9096
Epoch 86/100, Loss: 0.4623, Acc: 0.7910, Val Loss: 0.3003, Val Acc: 0.9089
Epoch 87/100, Loss: 0.4622, Acc: 0.7925, Val Loss: 0.2990, Val Acc: 0.9096
Epoch 88/100, Loss: 0.4621, Acc: 0.7928, Val Loss: 0.2961, Val Acc: 0.9111
Epoch 89/100, Loss: 0.4621, Acc: 0.7911, Val Loss: 0.2998, Val Acc: 0.9100
Epoch 90/100, Loss: 0.4619, Acc: 0.7929, Val Loss: 0.3004, Val Acc: 0.9092
Epoch 91/100, Loss: 0.4619, Acc: 0.7925, Val Loss: 0.2977, Val Acc: 0.9111
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4617, Acc: 0.7930, Val Loss: 0.2998, Val Acc: 0.9092
Epoch 93/100, Loss: 0.4617, Acc: 0.7920, Val Loss: 0.2967, Val Acc: 0.9118
Epoch 94/100, Loss: 0.4616, Acc: 0.7929, Val Loss: 0.2991, Val Acc: 0.9089
Epoch 95/100, Loss: 0.4616, Acc: 0.7919, Val Loss: 0.2973, Val Acc: 0.9103
Epoch 96/100, Loss: 0.4615, Acc: 0.7929, Val Loss: 0.3009, Val Acc: 0.9081
Epoch 97/100, Loss: 0.4615, Acc: 0.7924, Val Loss: 0.2986, Val Acc: 0.9103
Epoch 98/100, Loss: 0.4615, Acc: 0.7928, Val Loss: 0.2988, Val Acc: 0.9103
Epoch 99/100, Loss: 0.4613, Acc: 0.7930, Val Loss: 0.2951, Val Acc: 0.9133
Epoch 100/100, Loss: 0.4614, Acc: 0.7927, Val Loss: 0.2975, Val Acc: 0.9114

##############################
Resultados para principal:  098  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11 
 {'training': [0.46139170411758285, 0.7927322907083717, 0.7415234909533222, 0.898158379373849, 0.8123594569834264], 'validate': [0.29747184305343516, 0.9114391143911439, 0.961730449251248, 0.8562962962962963, 0.9059561128526645], 'test': [0.6602721815963961, 0.6117994100294986, 0.5698282300224048, 0.9029585798816568, 0.6987179487179487]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  025  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  025  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  025  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6762, Acc: 0.5990, Val Loss: 0.6520, Val Acc: 0.6830
Mejor modelo guardado con Val Loss: 0.6520
Epoch 2/100, Loss: 0.6526, Acc: 0.6350, Val Loss: 0.5992, Val Acc: 0.7893
Mejor modelo guardado con Val Loss: 0.5992
Epoch 3/100, Loss: 0.6277, Acc: 0.6539, Val Loss: 0.5820, Val Acc: 0.6867
Mejor modelo guardado con Val Loss: 0.5820
Epoch 4/100, Loss: 0.6110, Acc: 0.6611, Val Loss: 0.5387, Val Acc: 0.8399
Mejor modelo guardado con Val Loss: 0.5387
Epoch 5/100, Loss: 0.6040, Acc: 0.6609, Val Loss: 0.5140, Val Acc: 0.7801
Mejor modelo guardado con Val Loss: 0.5140
Epoch 6/100, Loss: 0.5941, Acc: 0.6712, Val Loss: 0.5096, Val Acc: 0.7978
Mejor modelo guardado con Val Loss: 0.5096
Epoch 7/100, Loss: 0.5954, Acc: 0.6623, Val Loss: 0.5164, Val Acc: 0.7812
Epoch 8/100, Loss: 0.5835, Acc: 0.6742, Val Loss: 0.5097, Val Acc: 0.7963
Epoch 9/100, Loss: 0.5843, Acc: 0.6698, Val Loss: 0.4931, Val Acc: 0.7941
Mejor modelo guardado con Val Loss: 0.4931
Epoch 10/100, Loss: 0.5861, Acc: 0.6706, Val Loss: 0.4913, Val Acc: 0.8280
Mejor modelo guardado con Val Loss: 0.4913
Epoch 11/100, Loss: 0.5787, Acc: 0.6747, Val Loss: 0.5154, Val Acc: 0.8004
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5736, Acc: 0.6823, Val Loss: 0.5141, Val Acc: 0.7664
Epoch 13/100, Loss: 0.5711, Acc: 0.6834, Val Loss: 0.4978, Val Acc: 0.7819
Epoch 14/100, Loss: 0.5716, Acc: 0.6817, Val Loss: 0.4933, Val Acc: 0.7819
Epoch 15/100, Loss: 0.5682, Acc: 0.6879, Val Loss: 0.4776, Val Acc: 0.7989
Mejor modelo guardado con Val Loss: 0.4776
Epoch 16/100, Loss: 0.5693, Acc: 0.6850, Val Loss: 0.4754, Val Acc: 0.7959
Mejor modelo guardado con Val Loss: 0.4754
Epoch 17/100, Loss: 0.5683, Acc: 0.6867, Val Loss: 0.5064, Val Acc: 0.7727
Epoch 18/100, Loss: 0.5658, Acc: 0.6868, Val Loss: 0.4941, Val Acc: 0.7753
Epoch 19/100, Loss: 0.5638, Acc: 0.6902, Val Loss: 0.5055, Val Acc: 0.7517
Epoch 20/100, Loss: 0.5629, Acc: 0.6919, Val Loss: 0.4988, Val Acc: 0.7749
Epoch 21/100, Loss: 0.5624, Acc: 0.6943, Val Loss: 0.5021, Val Acc: 0.7915
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5594, Acc: 0.6964, Val Loss: 0.4979, Val Acc: 0.7675
Epoch 23/100, Loss: 0.5591, Acc: 0.6968, Val Loss: 0.5067, Val Acc: 0.7587
Epoch 24/100, Loss: 0.5573, Acc: 0.6985, Val Loss: 0.5007, Val Acc: 0.7657
Epoch 25/100, Loss: 0.5581, Acc: 0.6990, Val Loss: 0.4921, Val Acc: 0.7897
Epoch 26/100, Loss: 0.5573, Acc: 0.6994, Val Loss: 0.4908, Val Acc: 0.7756
Epoch 27/100, Loss: 0.5572, Acc: 0.6987, Val Loss: 0.5193, Val Acc: 0.7424
Epoch 28/100, Loss: 0.5575, Acc: 0.6978, Val Loss: 0.4901, Val Acc: 0.7738
Epoch 29/100, Loss: 0.5556, Acc: 0.6984, Val Loss: 0.5153, Val Acc: 0.7465
Epoch 30/100, Loss: 0.5560, Acc: 0.7006, Val Loss: 0.5169, Val Acc: 0.7531
Epoch 31/100, Loss: 0.5539, Acc: 0.6994, Val Loss: 0.5011, Val Acc: 0.7609
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5528, Acc: 0.7038, Val Loss: 0.5105, Val Acc: 0.7469
Epoch 33/100, Loss: 0.5527, Acc: 0.7034, Val Loss: 0.5089, Val Acc: 0.7472
Epoch 34/100, Loss: 0.5531, Acc: 0.7020, Val Loss: 0.5155, Val Acc: 0.7410
Epoch 35/100, Loss: 0.5517, Acc: 0.7029, Val Loss: 0.5083, Val Acc: 0.7565
Epoch 36/100, Loss: 0.5519, Acc: 0.7033, Val Loss: 0.5050, Val Acc: 0.7705
Epoch 37/100, Loss: 0.5523, Acc: 0.7032, Val Loss: 0.5109, Val Acc: 0.7568
Epoch 38/100, Loss: 0.5512, Acc: 0.7042, Val Loss: 0.5031, Val Acc: 0.7524
Epoch 39/100, Loss: 0.5513, Acc: 0.7058, Val Loss: 0.5148, Val Acc: 0.7369
Epoch 40/100, Loss: 0.5513, Acc: 0.7043, Val Loss: 0.5357, Val Acc: 0.7122
Epoch 41/100, Loss: 0.5512, Acc: 0.7047, Val Loss: 0.5199, Val Acc: 0.7424
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5501, Acc: 0.7051, Val Loss: 0.5136, Val Acc: 0.7509
Epoch 43/100, Loss: 0.5497, Acc: 0.7052, Val Loss: 0.5229, Val Acc: 0.7417
Epoch 44/100, Loss: 0.5501, Acc: 0.7070, Val Loss: 0.5188, Val Acc: 0.7332
Epoch 45/100, Loss: 0.5497, Acc: 0.7054, Val Loss: 0.5171, Val Acc: 0.7446
Epoch 46/100, Loss: 0.5494, Acc: 0.7052, Val Loss: 0.5195, Val Acc: 0.7402
Epoch 47/100, Loss: 0.5491, Acc: 0.7066, Val Loss: 0.5103, Val Acc: 0.7483
Epoch 48/100, Loss: 0.5489, Acc: 0.7058, Val Loss: 0.5200, Val Acc: 0.7328
Epoch 49/100, Loss: 0.5481, Acc: 0.7075, Val Loss: 0.5252, Val Acc: 0.7280
Epoch 50/100, Loss: 0.5482, Acc: 0.7086, Val Loss: 0.5153, Val Acc: 0.7428
Epoch 51/100, Loss: 0.5478, Acc: 0.7068, Val Loss: 0.5247, Val Acc: 0.7273
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5473, Acc: 0.7085, Val Loss: 0.5225, Val Acc: 0.7369
Epoch 53/100, Loss: 0.5472, Acc: 0.7091, Val Loss: 0.5200, Val Acc: 0.7461
Epoch 54/100, Loss: 0.5472, Acc: 0.7081, Val Loss: 0.5225, Val Acc: 0.7306
Epoch 55/100, Loss: 0.5471, Acc: 0.7086, Val Loss: 0.5198, Val Acc: 0.7380
Epoch 56/100, Loss: 0.5470, Acc: 0.7083, Val Loss: 0.5145, Val Acc: 0.7498
Epoch 57/100, Loss: 0.5468, Acc: 0.7102, Val Loss: 0.5216, Val Acc: 0.7310
Epoch 58/100, Loss: 0.5467, Acc: 0.7092, Val Loss: 0.5161, Val Acc: 0.7480
Epoch 59/100, Loss: 0.5466, Acc: 0.7099, Val Loss: 0.5181, Val Acc: 0.7461
Epoch 60/100, Loss: 0.5465, Acc: 0.7092, Val Loss: 0.5207, Val Acc: 0.7365
Epoch 61/100, Loss: 0.5466, Acc: 0.7099, Val Loss: 0.5164, Val Acc: 0.7435
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5462, Acc: 0.7094, Val Loss: 0.5198, Val Acc: 0.7328
Epoch 63/100, Loss: 0.5462, Acc: 0.7099, Val Loss: 0.5151, Val Acc: 0.7472
Epoch 64/100, Loss: 0.5461, Acc: 0.7100, Val Loss: 0.5206, Val Acc: 0.7380
Epoch 65/100, Loss: 0.5460, Acc: 0.7099, Val Loss: 0.5189, Val Acc: 0.7424
Epoch 66/100, Loss: 0.5460, Acc: 0.7095, Val Loss: 0.5171, Val Acc: 0.7450
Epoch 67/100, Loss: 0.5459, Acc: 0.7102, Val Loss: 0.5165, Val Acc: 0.7421
Epoch 68/100, Loss: 0.5458, Acc: 0.7092, Val Loss: 0.5186, Val Acc: 0.7395
Epoch 69/100, Loss: 0.5459, Acc: 0.7103, Val Loss: 0.5196, Val Acc: 0.7387
Epoch 70/100, Loss: 0.5458, Acc: 0.7098, Val Loss: 0.5168, Val Acc: 0.7432
Epoch 71/100, Loss: 0.5455, Acc: 0.7105, Val Loss: 0.5210, Val Acc: 0.7387
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5452, Acc: 0.7107, Val Loss: 0.5208, Val Acc: 0.7410
Epoch 73/100, Loss: 0.5451, Acc: 0.7105, Val Loss: 0.5197, Val Acc: 0.7387
Epoch 74/100, Loss: 0.5451, Acc: 0.7110, Val Loss: 0.5192, Val Acc: 0.7376
Epoch 75/100, Loss: 0.5451, Acc: 0.7104, Val Loss: 0.5191, Val Acc: 0.7391
Epoch 76/100, Loss: 0.5449, Acc: 0.7099, Val Loss: 0.5173, Val Acc: 0.7395
Epoch 77/100, Loss: 0.5450, Acc: 0.7104, Val Loss: 0.5182, Val Acc: 0.7387
Epoch 78/100, Loss: 0.5449, Acc: 0.7098, Val Loss: 0.5201, Val Acc: 0.7362
Epoch 79/100, Loss: 0.5448, Acc: 0.7099, Val Loss: 0.5190, Val Acc: 0.7387
Epoch 80/100, Loss: 0.5448, Acc: 0.7092, Val Loss: 0.5208, Val Acc: 0.7391
Epoch 81/100, Loss: 0.5447, Acc: 0.7109, Val Loss: 0.5189, Val Acc: 0.7391
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5447, Acc: 0.7099, Val Loss: 0.5200, Val Acc: 0.7373
Epoch 83/100, Loss: 0.5446, Acc: 0.7097, Val Loss: 0.5204, Val Acc: 0.7413
Epoch 84/100, Loss: 0.5445, Acc: 0.7110, Val Loss: 0.5196, Val Acc: 0.7421
Epoch 85/100, Loss: 0.5445, Acc: 0.7107, Val Loss: 0.5191, Val Acc: 0.7399
Epoch 86/100, Loss: 0.5445, Acc: 0.7102, Val Loss: 0.5200, Val Acc: 0.7376
Epoch 87/100, Loss: 0.5444, Acc: 0.7101, Val Loss: 0.5199, Val Acc: 0.7376
Epoch 88/100, Loss: 0.5444, Acc: 0.7099, Val Loss: 0.5200, Val Acc: 0.7354
Epoch 89/100, Loss: 0.5443, Acc: 0.7098, Val Loss: 0.5190, Val Acc: 0.7402
Epoch 90/100, Loss: 0.5443, Acc: 0.7105, Val Loss: 0.5214, Val Acc: 0.7358
Epoch 91/100, Loss: 0.5442, Acc: 0.7099, Val Loss: 0.5206, Val Acc: 0.7376
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5442, Acc: 0.7098, Val Loss: 0.5208, Val Acc: 0.7395
Epoch 93/100, Loss: 0.5441, Acc: 0.7104, Val Loss: 0.5204, Val Acc: 0.7376
Epoch 94/100, Loss: 0.5441, Acc: 0.7108, Val Loss: 0.5206, Val Acc: 0.7365
Epoch 95/100, Loss: 0.5441, Acc: 0.7102, Val Loss: 0.5192, Val Acc: 0.7399
Epoch 96/100, Loss: 0.5440, Acc: 0.7108, Val Loss: 0.5205, Val Acc: 0.7369
Epoch 97/100, Loss: 0.5440, Acc: 0.7099, Val Loss: 0.5205, Val Acc: 0.7369
Epoch 98/100, Loss: 0.5440, Acc: 0.7099, Val Loss: 0.5216, Val Acc: 0.7362
Epoch 99/100, Loss: 0.5439, Acc: 0.7096, Val Loss: 0.5199, Val Acc: 0.7373
Epoch 100/100, Loss: 0.5438, Acc: 0.7110, Val Loss: 0.5198, Val Acc: 0.7362

##############################
Resultados para principal:  025  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11 
 {'training': [0.5437774800552396, 0.7110395584176633, 0.6559901867248195, 0.8863720073664825, 0.7539750920341506], 'validate': [0.5198050283415373, 0.7361623616236163, 0.7562550443906376, 0.6940740740740741, 0.723831595210506], 'test': [0.549684354437972, 0.7519174041297935, 0.7399660825325043, 0.7745562130177515, 0.7568661462850534]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  059  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  059  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  059  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6453, Acc: 0.6518, Val Loss: 0.4834, Val Acc: 0.9155
Mejor modelo guardado con Val Loss: 0.4834
Epoch 2/100, Loss: 0.5989, Acc: 0.6811, Val Loss: 0.3756, Val Acc: 0.9140
Mejor modelo guardado con Val Loss: 0.3756
Epoch 3/100, Loss: 0.5886, Acc: 0.6804, Val Loss: 0.3701, Val Acc: 0.9218
Mejor modelo guardado con Val Loss: 0.3701
Epoch 4/100, Loss: 0.5920, Acc: 0.6769, Val Loss: 0.4123, Val Acc: 0.9192
Epoch 5/100, Loss: 0.5843, Acc: 0.6845, Val Loss: 0.3754, Val Acc: 0.9111
Epoch 6/100, Loss: 0.5899, Acc: 0.6750, Val Loss: 0.3910, Val Acc: 0.9173
Epoch 7/100, Loss: 0.5787, Acc: 0.6816, Val Loss: 0.3376, Val Acc: 0.9177
Mejor modelo guardado con Val Loss: 0.3376
Epoch 8/100, Loss: 0.5810, Acc: 0.6761, Val Loss: 0.3470, Val Acc: 0.9026
Epoch 9/100, Loss: 0.5755, Acc: 0.6797, Val Loss: 0.3516, Val Acc: 0.9151
Epoch 10/100, Loss: 0.5740, Acc: 0.6868, Val Loss: 0.3238, Val Acc: 0.9188
Mejor modelo guardado con Val Loss: 0.3238
Epoch 11/100, Loss: 0.5749, Acc: 0.6780, Val Loss: 0.3717, Val Acc: 0.8786
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5651, Acc: 0.6858, Val Loss: 0.3319, Val Acc: 0.9041
Epoch 13/100, Loss: 0.5628, Acc: 0.6856, Val Loss: 0.3244, Val Acc: 0.9048
Epoch 14/100, Loss: 0.5617, Acc: 0.6842, Val Loss: 0.3256, Val Acc: 0.9162
Epoch 15/100, Loss: 0.5666, Acc: 0.6854, Val Loss: 0.3090, Val Acc: 0.9199
Mejor modelo guardado con Val Loss: 0.3090
Epoch 16/100, Loss: 0.5626, Acc: 0.6876, Val Loss: 0.3097, Val Acc: 0.9166
Epoch 17/100, Loss: 0.5639, Acc: 0.6845, Val Loss: 0.2942, Val Acc: 0.9170
Mejor modelo guardado con Val Loss: 0.2942
Epoch 18/100, Loss: 0.5603, Acc: 0.6902, Val Loss: 0.2785, Val Acc: 0.9173
Mejor modelo guardado con Val Loss: 0.2785
Epoch 19/100, Loss: 0.5601, Acc: 0.6892, Val Loss: 0.3272, Val Acc: 0.8893
Epoch 20/100, Loss: 0.5595, Acc: 0.6902, Val Loss: 0.3053, Val Acc: 0.9155
Epoch 21/100, Loss: 0.5610, Acc: 0.6850, Val Loss: 0.3208, Val Acc: 0.9125
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5569, Acc: 0.6877, Val Loss: 0.3156, Val Acc: 0.9092
Epoch 23/100, Loss: 0.5545, Acc: 0.6925, Val Loss: 0.3063, Val Acc: 0.9070
Epoch 24/100, Loss: 0.5557, Acc: 0.6925, Val Loss: 0.3251, Val Acc: 0.9218
Epoch 25/100, Loss: 0.5570, Acc: 0.6838, Val Loss: 0.2875, Val Acc: 0.9225
Epoch 26/100, Loss: 0.5560, Acc: 0.6900, Val Loss: 0.3352, Val Acc: 0.9000
Epoch 27/100, Loss: 0.5527, Acc: 0.6893, Val Loss: 0.3157, Val Acc: 0.9203
Epoch 28/100, Loss: 0.5540, Acc: 0.6931, Val Loss: 0.3053, Val Acc: 0.9066
Epoch 29/100, Loss: 0.5525, Acc: 0.6927, Val Loss: 0.2882, Val Acc: 0.9162
Epoch 30/100, Loss: 0.5525, Acc: 0.6927, Val Loss: 0.3014, Val Acc: 0.9173
Epoch 31/100, Loss: 0.5515, Acc: 0.6961, Val Loss: 0.2836, Val Acc: 0.9188
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5499, Acc: 0.6968, Val Loss: 0.2925, Val Acc: 0.9114
Epoch 33/100, Loss: 0.5504, Acc: 0.6946, Val Loss: 0.2969, Val Acc: 0.9111
Epoch 34/100, Loss: 0.5497, Acc: 0.6949, Val Loss: 0.3043, Val Acc: 0.9089
Epoch 35/100, Loss: 0.5491, Acc: 0.6949, Val Loss: 0.3070, Val Acc: 0.9100
Epoch 36/100, Loss: 0.5492, Acc: 0.6966, Val Loss: 0.2947, Val Acc: 0.9063
Epoch 37/100, Loss: 0.5489, Acc: 0.6910, Val Loss: 0.2919, Val Acc: 0.9096
Epoch 38/100, Loss: 0.5486, Acc: 0.6964, Val Loss: 0.2939, Val Acc: 0.9044
Epoch 39/100, Loss: 0.5484, Acc: 0.6974, Val Loss: 0.2958, Val Acc: 0.9063
Epoch 40/100, Loss: 0.5485, Acc: 0.6964, Val Loss: 0.3011, Val Acc: 0.8989
Epoch 41/100, Loss: 0.5475, Acc: 0.6940, Val Loss: 0.2946, Val Acc: 0.9085
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5473, Acc: 0.6959, Val Loss: 0.2954, Val Acc: 0.9037
Epoch 43/100, Loss: 0.5469, Acc: 0.6954, Val Loss: 0.2983, Val Acc: 0.8967
Epoch 44/100, Loss: 0.5465, Acc: 0.6947, Val Loss: 0.3019, Val Acc: 0.9004
Epoch 45/100, Loss: 0.5462, Acc: 0.6957, Val Loss: 0.2995, Val Acc: 0.9004
Epoch 46/100, Loss: 0.5460, Acc: 0.6942, Val Loss: 0.2958, Val Acc: 0.9081
Epoch 47/100, Loss: 0.5461, Acc: 0.6962, Val Loss: 0.2932, Val Acc: 0.9041
Epoch 48/100, Loss: 0.5460, Acc: 0.6957, Val Loss: 0.2975, Val Acc: 0.9070
Epoch 49/100, Loss: 0.5462, Acc: 0.6950, Val Loss: 0.2905, Val Acc: 0.9140
Epoch 50/100, Loss: 0.5457, Acc: 0.6975, Val Loss: 0.2942, Val Acc: 0.9063
Epoch 51/100, Loss: 0.5457, Acc: 0.6944, Val Loss: 0.2927, Val Acc: 0.9133
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5455, Acc: 0.6989, Val Loss: 0.2944, Val Acc: 0.9081
Epoch 53/100, Loss: 0.5451, Acc: 0.6960, Val Loss: 0.2866, Val Acc: 0.9125
Epoch 54/100, Loss: 0.5450, Acc: 0.6969, Val Loss: 0.2951, Val Acc: 0.9077
Epoch 55/100, Loss: 0.5451, Acc: 0.6990, Val Loss: 0.2982, Val Acc: 0.9063
Epoch 56/100, Loss: 0.5449, Acc: 0.6967, Val Loss: 0.2889, Val Acc: 0.9103
Epoch 57/100, Loss: 0.5448, Acc: 0.6979, Val Loss: 0.2950, Val Acc: 0.9103
Epoch 58/100, Loss: 0.5446, Acc: 0.6979, Val Loss: 0.2888, Val Acc: 0.9114
Epoch 59/100, Loss: 0.5445, Acc: 0.6992, Val Loss: 0.2908, Val Acc: 0.9107
Epoch 60/100, Loss: 0.5446, Acc: 0.6992, Val Loss: 0.2935, Val Acc: 0.9096
Epoch 61/100, Loss: 0.5445, Acc: 0.6969, Val Loss: 0.2909, Val Acc: 0.9103
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5443, Acc: 0.6985, Val Loss: 0.2923, Val Acc: 0.9100
Epoch 63/100, Loss: 0.5442, Acc: 0.6968, Val Loss: 0.2918, Val Acc: 0.9103
Epoch 64/100, Loss: 0.5442, Acc: 0.6977, Val Loss: 0.2920, Val Acc: 0.9107
Epoch 65/100, Loss: 0.5442, Acc: 0.6990, Val Loss: 0.2917, Val Acc: 0.9107
Epoch 66/100, Loss: 0.5441, Acc: 0.6987, Val Loss: 0.2931, Val Acc: 0.9096
Epoch 67/100, Loss: 0.5441, Acc: 0.6978, Val Loss: 0.2914, Val Acc: 0.9100
Epoch 68/100, Loss: 0.5440, Acc: 0.6986, Val Loss: 0.2914, Val Acc: 0.9107
Epoch 69/100, Loss: 0.5440, Acc: 0.6995, Val Loss: 0.2925, Val Acc: 0.9092
Epoch 70/100, Loss: 0.5440, Acc: 0.6976, Val Loss: 0.2905, Val Acc: 0.9111
Epoch 71/100, Loss: 0.5440, Acc: 0.6998, Val Loss: 0.2918, Val Acc: 0.9096
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5438, Acc: 0.6972, Val Loss: 0.2923, Val Acc: 0.9089
Epoch 73/100, Loss: 0.5438, Acc: 0.6972, Val Loss: 0.2915, Val Acc: 0.9100
Epoch 74/100, Loss: 0.5437, Acc: 0.6986, Val Loss: 0.2903, Val Acc: 0.9111
Epoch 75/100, Loss: 0.5437, Acc: 0.6976, Val Loss: 0.2910, Val Acc: 0.9107
Epoch 76/100, Loss: 0.5437, Acc: 0.6977, Val Loss: 0.2897, Val Acc: 0.9111
Epoch 77/100, Loss: 0.5437, Acc: 0.6982, Val Loss: 0.2907, Val Acc: 0.9111
Epoch 78/100, Loss: 0.5437, Acc: 0.6976, Val Loss: 0.2899, Val Acc: 0.9111
Epoch 79/100, Loss: 0.5437, Acc: 0.6997, Val Loss: 0.2904, Val Acc: 0.9111
Epoch 80/100, Loss: 0.5436, Acc: 0.6981, Val Loss: 0.2895, Val Acc: 0.9111
Epoch 81/100, Loss: 0.5436, Acc: 0.6984, Val Loss: 0.2905, Val Acc: 0.9111
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5436, Acc: 0.6981, Val Loss: 0.2901, Val Acc: 0.9111
Epoch 83/100, Loss: 0.5436, Acc: 0.6998, Val Loss: 0.2898, Val Acc: 0.9111
Epoch 84/100, Loss: 0.5436, Acc: 0.6975, Val Loss: 0.2912, Val Acc: 0.9103
Epoch 85/100, Loss: 0.5436, Acc: 0.6986, Val Loss: 0.2917, Val Acc: 0.9103
Epoch 86/100, Loss: 0.5435, Acc: 0.6996, Val Loss: 0.2915, Val Acc: 0.9107
Epoch 87/100, Loss: 0.5435, Acc: 0.6980, Val Loss: 0.2913, Val Acc: 0.9107
Epoch 88/100, Loss: 0.5435, Acc: 0.6977, Val Loss: 0.2907, Val Acc: 0.9111
Epoch 89/100, Loss: 0.5436, Acc: 0.6981, Val Loss: 0.2899, Val Acc: 0.9111
Epoch 90/100, Loss: 0.5435, Acc: 0.6997, Val Loss: 0.2914, Val Acc: 0.9092
Epoch 91/100, Loss: 0.5435, Acc: 0.6974, Val Loss: 0.2908, Val Acc: 0.9111
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5434, Acc: 0.6980, Val Loss: 0.2890, Val Acc: 0.9111
Epoch 93/100, Loss: 0.5435, Acc: 0.6980, Val Loss: 0.2886, Val Acc: 0.9114
Epoch 94/100, Loss: 0.5434, Acc: 0.6993, Val Loss: 0.2898, Val Acc: 0.9111
Epoch 95/100, Loss: 0.5434, Acc: 0.6993, Val Loss: 0.2909, Val Acc: 0.9107
Epoch 96/100, Loss: 0.5434, Acc: 0.6986, Val Loss: 0.2899, Val Acc: 0.9111
Epoch 97/100, Loss: 0.5433, Acc: 0.6982, Val Loss: 0.2902, Val Acc: 0.9107
Epoch 98/100, Loss: 0.5433, Acc: 0.6978, Val Loss: 0.2896, Val Acc: 0.9111
Epoch 99/100, Loss: 0.5433, Acc: 0.6990, Val Loss: 0.2922, Val Acc: 0.9100
Epoch 100/100, Loss: 0.5434, Acc: 0.6991, Val Loss: 0.2901, Val Acc: 0.9111

##############################
Resultados para principal:  059  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11 
 {'training': [0.5433564936226404, 0.699080036798528, 0.7018889096689732, 0.6911602209944752, 0.6964832513686555], 'validate': [0.2900814344716627, 0.911070110701107, 0.9800865800865801, 0.8385185185185186, 0.9037924151696607], 'test': [0.5397337804425437, 0.7168141592920354, 0.6688251618871416, 0.855621301775148, 0.7507788161993769]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  121  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  121  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  121  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.3705, Acc: 0.9132, Val Loss: 0.9852, Val Acc: 0.4923
Mejor modelo guardado con Val Loss: 0.9852
Epoch 2/100, Loss: 0.2063, Acc: 0.9421, Val Loss: 1.1878, Val Acc: 0.4956
Epoch 3/100, Loss: 0.1821, Acc: 0.9413, Val Loss: 0.9757, Val Acc: 0.5421
Mejor modelo guardado con Val Loss: 0.9757
Epoch 4/100, Loss: 0.1689, Acc: 0.9414, Val Loss: 1.5590, Val Acc: 0.4934
Epoch 5/100, Loss: 0.1544, Acc: 0.9473, Val Loss: 1.1542, Val Acc: 0.5428
Epoch 6/100, Loss: 0.1586, Acc: 0.9442, Val Loss: 1.3163, Val Acc: 0.5066
Epoch 7/100, Loss: 0.1491, Acc: 0.9457, Val Loss: 1.3075, Val Acc: 0.5351
Epoch 8/100, Loss: 0.1510, Acc: 0.9445, Val Loss: 1.0109, Val Acc: 0.5723
Epoch 9/100, Loss: 0.1559, Acc: 0.9450, Val Loss: 1.1113, Val Acc: 0.5583
Epoch 10/100, Loss: 0.1455, Acc: 0.9489, Val Loss: 1.2930, Val Acc: 0.5288
Epoch 11/100, Loss: 0.1439, Acc: 0.9463, Val Loss: 1.3638, Val Acc: 0.5461
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.1346, Acc: 0.9494, Val Loss: 1.2983, Val Acc: 0.5244
Epoch 13/100, Loss: 0.1318, Acc: 0.9503, Val Loss: 1.6366, Val Acc: 0.5159
Epoch 14/100, Loss: 0.1360, Acc: 0.9490, Val Loss: 1.2102, Val Acc: 0.5572
Epoch 15/100, Loss: 0.1311, Acc: 0.9534, Val Loss: 1.1646, Val Acc: 0.5517
Epoch 16/100, Loss: 0.1284, Acc: 0.9524, Val Loss: 1.2362, Val Acc: 0.5476
Epoch 17/100, Loss: 0.1240, Acc: 0.9538, Val Loss: 1.4766, Val Acc: 0.5144
Epoch 18/100, Loss: 0.1295, Acc: 0.9519, Val Loss: 1.5664, Val Acc: 0.5144
Epoch 19/100, Loss: 0.1290, Acc: 0.9510, Val Loss: 1.1892, Val Acc: 0.5469
Epoch 20/100, Loss: 0.1268, Acc: 0.9527, Val Loss: 1.1266, Val Acc: 0.5347
Epoch 21/100, Loss: 0.1259, Acc: 0.9534, Val Loss: 1.2704, Val Acc: 0.5114
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.1230, Acc: 0.9534, Val Loss: 1.3025, Val Acc: 0.5410
Epoch 23/100, Loss: 0.1182, Acc: 0.9552, Val Loss: 1.3967, Val Acc: 0.5443
Epoch 24/100, Loss: 0.1198, Acc: 0.9544, Val Loss: 1.7591, Val Acc: 0.5347
Epoch 25/100, Loss: 0.1170, Acc: 0.9539, Val Loss: 1.4532, Val Acc: 0.5351
Epoch 26/100, Loss: 0.1188, Acc: 0.9546, Val Loss: 1.4439, Val Acc: 0.5406
Epoch 27/100, Loss: 0.1155, Acc: 0.9555, Val Loss: 1.6329, Val Acc: 0.5395
Epoch 28/100, Loss: 0.1180, Acc: 0.9545, Val Loss: 1.2621, Val Acc: 0.5458
Epoch 29/100, Loss: 0.1143, Acc: 0.9557, Val Loss: 1.4332, Val Acc: 0.5328
Epoch 30/100, Loss: 0.1134, Acc: 0.9560, Val Loss: 1.2767, Val Acc: 0.5395
Epoch 31/100, Loss: 0.1154, Acc: 0.9547, Val Loss: 1.1906, Val Acc: 0.5454
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.1102, Acc: 0.9573, Val Loss: 1.2325, Val Acc: 0.5498
Epoch 33/100, Loss: 0.1098, Acc: 0.9584, Val Loss: 1.4413, Val Acc: 0.5328
Epoch 34/100, Loss: 0.1087, Acc: 0.9582, Val Loss: 1.5370, Val Acc: 0.5384
Epoch 35/100, Loss: 0.1094, Acc: 0.9581, Val Loss: 1.4544, Val Acc: 0.5351
Epoch 36/100, Loss: 0.1086, Acc: 0.9586, Val Loss: 1.1148, Val Acc: 0.5590
Epoch 37/100, Loss: 0.1095, Acc: 0.9576, Val Loss: 1.1848, Val Acc: 0.5469
Epoch 38/100, Loss: 0.1084, Acc: 0.9572, Val Loss: 1.3472, Val Acc: 0.5339
Epoch 39/100, Loss: 0.1068, Acc: 0.9586, Val Loss: 1.3011, Val Acc: 0.5424
Epoch 40/100, Loss: 0.1072, Acc: 0.9582, Val Loss: 1.5053, Val Acc: 0.5417
Epoch 41/100, Loss: 0.1076, Acc: 0.9583, Val Loss: 1.3242, Val Acc: 0.5461
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.1060, Acc: 0.9580, Val Loss: 1.3756, Val Acc: 0.5432
Epoch 43/100, Loss: 0.1054, Acc: 0.9590, Val Loss: 1.4771, Val Acc: 0.5362
Epoch 44/100, Loss: 0.1048, Acc: 0.9594, Val Loss: 1.4459, Val Acc: 0.5387
Epoch 45/100, Loss: 0.1047, Acc: 0.9596, Val Loss: 1.4485, Val Acc: 0.5387
Epoch 46/100, Loss: 0.1044, Acc: 0.9593, Val Loss: 1.3574, Val Acc: 0.5439
Epoch 47/100, Loss: 0.1046, Acc: 0.9592, Val Loss: 1.4119, Val Acc: 0.5358
Epoch 48/100, Loss: 0.1054, Acc: 0.9598, Val Loss: 1.3905, Val Acc: 0.5406
Epoch 49/100, Loss: 0.1042, Acc: 0.9594, Val Loss: 1.3527, Val Acc: 0.5410
Epoch 50/100, Loss: 0.1050, Acc: 0.9590, Val Loss: 1.4665, Val Acc: 0.5373
Epoch 51/100, Loss: 0.1032, Acc: 0.9599, Val Loss: 1.3868, Val Acc: 0.5395
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.1029, Acc: 0.9598, Val Loss: 1.3632, Val Acc: 0.5450
Epoch 53/100, Loss: 0.1028, Acc: 0.9598, Val Loss: 1.4399, Val Acc: 0.5384
Epoch 54/100, Loss: 0.1029, Acc: 0.9603, Val Loss: 1.3507, Val Acc: 0.5424
Epoch 55/100, Loss: 0.1027, Acc: 0.9591, Val Loss: 1.4456, Val Acc: 0.5328
Epoch 56/100, Loss: 0.1025, Acc: 0.9593, Val Loss: 1.4360, Val Acc: 0.5387
Epoch 57/100, Loss: 0.1025, Acc: 0.9600, Val Loss: 1.3923, Val Acc: 0.5399
Epoch 58/100, Loss: 0.1024, Acc: 0.9600, Val Loss: 1.4044, Val Acc: 0.5406
Epoch 59/100, Loss: 0.1022, Acc: 0.9592, Val Loss: 1.4212, Val Acc: 0.5387
Epoch 60/100, Loss: 0.1025, Acc: 0.9592, Val Loss: 1.3252, Val Acc: 0.5450
Epoch 61/100, Loss: 0.1023, Acc: 0.9602, Val Loss: 1.4730, Val Acc: 0.5384
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.1015, Acc: 0.9605, Val Loss: 1.4423, Val Acc: 0.5376
Epoch 63/100, Loss: 0.1016, Acc: 0.9597, Val Loss: 1.3949, Val Acc: 0.5402
Epoch 64/100, Loss: 0.1016, Acc: 0.9594, Val Loss: 1.4340, Val Acc: 0.5376
Epoch 65/100, Loss: 0.1016, Acc: 0.9596, Val Loss: 1.3955, Val Acc: 0.5402
Epoch 66/100, Loss: 0.1014, Acc: 0.9598, Val Loss: 1.4646, Val Acc: 0.5376
Epoch 67/100, Loss: 0.1015, Acc: 0.9601, Val Loss: 1.4354, Val Acc: 0.5399
Epoch 68/100, Loss: 0.1014, Acc: 0.9597, Val Loss: 1.4497, Val Acc: 0.5376
Epoch 69/100, Loss: 0.1013, Acc: 0.9602, Val Loss: 1.4312, Val Acc: 0.5384
Epoch 70/100, Loss: 0.1011, Acc: 0.9595, Val Loss: 1.4156, Val Acc: 0.5410
Epoch 71/100, Loss: 0.1011, Acc: 0.9594, Val Loss: 1.4912, Val Acc: 0.5343
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.1011, Acc: 0.9602, Val Loss: 1.4477, Val Acc: 0.5369
Epoch 73/100, Loss: 0.1010, Acc: 0.9595, Val Loss: 1.4338, Val Acc: 0.5369
Epoch 74/100, Loss: 0.1009, Acc: 0.9596, Val Loss: 1.4365, Val Acc: 0.5376
Epoch 75/100, Loss: 0.1009, Acc: 0.9602, Val Loss: 1.4433, Val Acc: 0.5373
Epoch 76/100, Loss: 0.1009, Acc: 0.9595, Val Loss: 1.4354, Val Acc: 0.5395
Epoch 77/100, Loss: 0.1007, Acc: 0.9599, Val Loss: 1.4245, Val Acc: 0.5399
Epoch 78/100, Loss: 0.1008, Acc: 0.9595, Val Loss: 1.4509, Val Acc: 0.5376
Epoch 79/100, Loss: 0.1006, Acc: 0.9594, Val Loss: 1.4599, Val Acc: 0.5354
Epoch 80/100, Loss: 0.1008, Acc: 0.9602, Val Loss: 1.4476, Val Acc: 0.5373
Epoch 81/100, Loss: 0.1007, Acc: 0.9597, Val Loss: 1.4544, Val Acc: 0.5373
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.1007, Acc: 0.9602, Val Loss: 1.4405, Val Acc: 0.5402
Epoch 83/100, Loss: 0.1007, Acc: 0.9598, Val Loss: 1.4021, Val Acc: 0.5410
Epoch 84/100, Loss: 0.1005, Acc: 0.9599, Val Loss: 1.4748, Val Acc: 0.5347
Epoch 85/100, Loss: 0.1005, Acc: 0.9600, Val Loss: 1.4155, Val Acc: 0.5387
Epoch 86/100, Loss: 0.1005, Acc: 0.9604, Val Loss: 1.4195, Val Acc: 0.5391
Epoch 87/100, Loss: 0.1005, Acc: 0.9600, Val Loss: 1.4273, Val Acc: 0.5376
Epoch 88/100, Loss: 0.1006, Acc: 0.9599, Val Loss: 1.4380, Val Acc: 0.5365
Epoch 89/100, Loss: 0.1005, Acc: 0.9598, Val Loss: 1.4337, Val Acc: 0.5380
Epoch 90/100, Loss: 0.1005, Acc: 0.9598, Val Loss: 1.4398, Val Acc: 0.5399
Epoch 91/100, Loss: 0.1004, Acc: 0.9599, Val Loss: 1.4341, Val Acc: 0.5391
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.1003, Acc: 0.9595, Val Loss: 1.4671, Val Acc: 0.5380
Epoch 93/100, Loss: 0.1005, Acc: 0.9598, Val Loss: 1.4279, Val Acc: 0.5406
Epoch 94/100, Loss: 0.1003, Acc: 0.9599, Val Loss: 1.4417, Val Acc: 0.5373
Epoch 95/100, Loss: 0.1004, Acc: 0.9602, Val Loss: 1.4206, Val Acc: 0.5399
Epoch 96/100, Loss: 0.1002, Acc: 0.9598, Val Loss: 1.4633, Val Acc: 0.5376
Epoch 97/100, Loss: 0.1002, Acc: 0.9604, Val Loss: 1.4693, Val Acc: 0.5354
Epoch 98/100, Loss: 0.1003, Acc: 0.9603, Val Loss: 1.4282, Val Acc: 0.5406
Epoch 99/100, Loss: 0.1001, Acc: 0.9599, Val Loss: 1.4590, Val Acc: 0.5376
Epoch 100/100, Loss: 0.1002, Acc: 0.9596, Val Loss: 1.4376, Val Acc: 0.5402

##############################
Resultados para principal:  121  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11 
 {'training': [0.10019261168166926, 0.9596136154553818, 0.9482665708640201, 0.9721915285451197, 0.9600800218241339], 'validate': [1.4375625629476163, 0.5402214022140222, 0.5215410107705054, 0.9325925925925926, 0.6689691817215728], 'test': [0.3897809752456422, 0.8283185840707965, 0.8001083423618635, 0.8739644970414201, 0.8354072398190046]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  107  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  107  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  107  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5234, Acc: 0.8578, Val Loss: 0.8944, Val Acc: 0.4502
Mejor modelo guardado con Val Loss: 0.8944
Epoch 2/100, Loss: 0.3225, Acc: 0.9091, Val Loss: 1.1083, Val Acc: 0.5077
Epoch 3/100, Loss: 0.2725, Acc: 0.9142, Val Loss: 1.1106, Val Acc: 0.5129
Epoch 4/100, Loss: 0.2705, Acc: 0.9107, Val Loss: 1.1529, Val Acc: 0.5089
Epoch 5/100, Loss: 0.2417, Acc: 0.9197, Val Loss: 1.2598, Val Acc: 0.4037
Epoch 6/100, Loss: 0.2357, Acc: 0.9213, Val Loss: 1.2588, Val Acc: 0.5085
Epoch 7/100, Loss: 0.2201, Acc: 0.9263, Val Loss: 1.2760, Val Acc: 0.5022
Epoch 8/100, Loss: 0.2316, Acc: 0.9191, Val Loss: 1.2920, Val Acc: 0.5192
Epoch 9/100, Loss: 0.2228, Acc: 0.9246, Val Loss: 1.3133, Val Acc: 0.5092
Epoch 10/100, Loss: 0.2242, Acc: 0.9196, Val Loss: 1.3353, Val Acc: 0.5103
Epoch 11/100, Loss: 0.2110, Acc: 0.9289, Val Loss: 1.2952, Val Acc: 0.5037
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2038, Acc: 0.9330, Val Loss: 1.3143, Val Acc: 0.5100
Epoch 13/100, Loss: 0.1996, Acc: 0.9336, Val Loss: 1.3310, Val Acc: 0.4996
Epoch 14/100, Loss: 0.2041, Acc: 0.9311, Val Loss: 1.2991, Val Acc: 0.5247
Epoch 15/100, Loss: 0.1970, Acc: 0.9351, Val Loss: 1.2983, Val Acc: 0.5229
Epoch 16/100, Loss: 0.1958, Acc: 0.9348, Val Loss: 1.2983, Val Acc: 0.5280
Epoch 17/100, Loss: 0.1971, Acc: 0.9340, Val Loss: 1.3073, Val Acc: 0.5074
Epoch 18/100, Loss: 0.1947, Acc: 0.9346, Val Loss: 1.2881, Val Acc: 0.5232
Epoch 19/100, Loss: 0.1971, Acc: 0.9324, Val Loss: 1.3216, Val Acc: 0.5140
Epoch 20/100, Loss: 0.1983, Acc: 0.9342, Val Loss: 1.3773, Val Acc: 0.4974
Epoch 21/100, Loss: 0.1963, Acc: 0.9340, Val Loss: 1.3215, Val Acc: 0.5196
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.1909, Acc: 0.9363, Val Loss: 1.3400, Val Acc: 0.5148
Epoch 23/100, Loss: 0.1930, Acc: 0.9356, Val Loss: 1.3474, Val Acc: 0.5081
Epoch 24/100, Loss: 0.1926, Acc: 0.9350, Val Loss: 1.3744, Val Acc: 0.4967
Epoch 25/100, Loss: 0.1910, Acc: 0.9371, Val Loss: 1.3472, Val Acc: 0.5151
Epoch 26/100, Loss: 0.1906, Acc: 0.9363, Val Loss: 1.4386, Val Acc: 0.4852
Epoch 27/100, Loss: 0.1916, Acc: 0.9368, Val Loss: 1.3292, Val Acc: 0.5232
Epoch 28/100, Loss: 0.1883, Acc: 0.9380, Val Loss: 1.3872, Val Acc: 0.5041
Epoch 29/100, Loss: 0.1879, Acc: 0.9380, Val Loss: 1.3600, Val Acc: 0.5077
Epoch 30/100, Loss: 0.1878, Acc: 0.9370, Val Loss: 1.3283, Val Acc: 0.5236
Epoch 31/100, Loss: 0.1878, Acc: 0.9380, Val Loss: 1.3586, Val Acc: 0.5114
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.1848, Acc: 0.9393, Val Loss: 1.3465, Val Acc: 0.5181
Epoch 33/100, Loss: 0.1840, Acc: 0.9388, Val Loss: 1.3694, Val Acc: 0.5103
Epoch 34/100, Loss: 0.1845, Acc: 0.9392, Val Loss: 1.3623, Val Acc: 0.5140
Epoch 35/100, Loss: 0.1844, Acc: 0.9384, Val Loss: 1.3635, Val Acc: 0.5107
Epoch 36/100, Loss: 0.1842, Acc: 0.9400, Val Loss: 1.3481, Val Acc: 0.5199
Epoch 37/100, Loss: 0.1845, Acc: 0.9393, Val Loss: 1.3819, Val Acc: 0.5052
Epoch 38/100, Loss: 0.1836, Acc: 0.9394, Val Loss: 1.3471, Val Acc: 0.5218
Epoch 39/100, Loss: 0.1857, Acc: 0.9387, Val Loss: 1.3707, Val Acc: 0.5114
Epoch 40/100, Loss: 0.1831, Acc: 0.9397, Val Loss: 1.3671, Val Acc: 0.5118
Epoch 41/100, Loss: 0.1832, Acc: 0.9406, Val Loss: 1.3540, Val Acc: 0.5148
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.1822, Acc: 0.9402, Val Loss: 1.3467, Val Acc: 0.5221
Epoch 43/100, Loss: 0.1814, Acc: 0.9408, Val Loss: 1.3643, Val Acc: 0.5148
Epoch 44/100, Loss: 0.1813, Acc: 0.9410, Val Loss: 1.3649, Val Acc: 0.5148
Epoch 45/100, Loss: 0.1817, Acc: 0.9399, Val Loss: 1.3586, Val Acc: 0.5162
Epoch 46/100, Loss: 0.1813, Acc: 0.9411, Val Loss: 1.3739, Val Acc: 0.5137
Epoch 47/100, Loss: 0.1812, Acc: 0.9407, Val Loss: 1.3579, Val Acc: 0.5162
Epoch 48/100, Loss: 0.1808, Acc: 0.9410, Val Loss: 1.3712, Val Acc: 0.5148
Epoch 49/100, Loss: 0.1805, Acc: 0.9414, Val Loss: 1.3646, Val Acc: 0.5162
Epoch 50/100, Loss: 0.1814, Acc: 0.9403, Val Loss: 1.3612, Val Acc: 0.5162
Epoch 51/100, Loss: 0.1811, Acc: 0.9408, Val Loss: 1.3499, Val Acc: 0.5247
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.1800, Acc: 0.9411, Val Loss: 1.3556, Val Acc: 0.5199
Epoch 53/100, Loss: 0.1797, Acc: 0.9423, Val Loss: 1.3675, Val Acc: 0.5137
Epoch 54/100, Loss: 0.1798, Acc: 0.9416, Val Loss: 1.3633, Val Acc: 0.5159
Epoch 55/100, Loss: 0.1798, Acc: 0.9417, Val Loss: 1.3711, Val Acc: 0.5133
Epoch 56/100, Loss: 0.1800, Acc: 0.9419, Val Loss: 1.3679, Val Acc: 0.5144
Epoch 57/100, Loss: 0.1793, Acc: 0.9420, Val Loss: 1.3743, Val Acc: 0.5125
Epoch 58/100, Loss: 0.1796, Acc: 0.9418, Val Loss: 1.3535, Val Acc: 0.5221
Epoch 59/100, Loss: 0.1799, Acc: 0.9421, Val Loss: 1.3508, Val Acc: 0.5244
Epoch 60/100, Loss: 0.1797, Acc: 0.9427, Val Loss: 1.3732, Val Acc: 0.5137
Epoch 61/100, Loss: 0.1798, Acc: 0.9419, Val Loss: 1.3736, Val Acc: 0.5137
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.1792, Acc: 0.9423, Val Loss: 1.3747, Val Acc: 0.5137
Epoch 63/100, Loss: 0.1787, Acc: 0.9424, Val Loss: 1.3815, Val Acc: 0.5118
Epoch 64/100, Loss: 0.1790, Acc: 0.9425, Val Loss: 1.3646, Val Acc: 0.5166
Epoch 65/100, Loss: 0.1789, Acc: 0.9420, Val Loss: 1.3658, Val Acc: 0.5159
Epoch 66/100, Loss: 0.1790, Acc: 0.9426, Val Loss: 1.3654, Val Acc: 0.5162
Epoch 67/100, Loss: 0.1788, Acc: 0.9425, Val Loss: 1.3650, Val Acc: 0.5170
Epoch 68/100, Loss: 0.1788, Acc: 0.9422, Val Loss: 1.3675, Val Acc: 0.5155
Epoch 69/100, Loss: 0.1788, Acc: 0.9426, Val Loss: 1.3695, Val Acc: 0.5140
Epoch 70/100, Loss: 0.1790, Acc: 0.9418, Val Loss: 1.3699, Val Acc: 0.5137
Epoch 71/100, Loss: 0.1786, Acc: 0.9420, Val Loss: 1.3642, Val Acc: 0.5166
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.1786, Acc: 0.9424, Val Loss: 1.3732, Val Acc: 0.5144
Epoch 73/100, Loss: 0.1787, Acc: 0.9418, Val Loss: 1.3652, Val Acc: 0.5159
Epoch 74/100, Loss: 0.1784, Acc: 0.9429, Val Loss: 1.3713, Val Acc: 0.5140
Epoch 75/100, Loss: 0.1783, Acc: 0.9424, Val Loss: 1.3611, Val Acc: 0.5181
Epoch 76/100, Loss: 0.1785, Acc: 0.9428, Val Loss: 1.3659, Val Acc: 0.5162
Epoch 77/100, Loss: 0.1785, Acc: 0.9429, Val Loss: 1.3674, Val Acc: 0.5159
Epoch 78/100, Loss: 0.1786, Acc: 0.9424, Val Loss: 1.3748, Val Acc: 0.5144
Epoch 79/100, Loss: 0.1783, Acc: 0.9430, Val Loss: 1.3633, Val Acc: 0.5170
Epoch 80/100, Loss: 0.1784, Acc: 0.9430, Val Loss: 1.3614, Val Acc: 0.5181
Epoch 81/100, Loss: 0.1785, Acc: 0.9423, Val Loss: 1.3670, Val Acc: 0.5159
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.1782, Acc: 0.9423, Val Loss: 1.3663, Val Acc: 0.5162
Epoch 83/100, Loss: 0.1784, Acc: 0.9426, Val Loss: 1.3652, Val Acc: 0.5166
Epoch 84/100, Loss: 0.1782, Acc: 0.9431, Val Loss: 1.3631, Val Acc: 0.5177
Epoch 85/100, Loss: 0.1784, Acc: 0.9428, Val Loss: 1.3596, Val Acc: 0.5199
Epoch 86/100, Loss: 0.1783, Acc: 0.9429, Val Loss: 1.3591, Val Acc: 0.5203
Epoch 87/100, Loss: 0.1783, Acc: 0.9427, Val Loss: 1.3729, Val Acc: 0.5148
Epoch 88/100, Loss: 0.1784, Acc: 0.9429, Val Loss: 1.3678, Val Acc: 0.5159
Epoch 89/100, Loss: 0.1783, Acc: 0.9428, Val Loss: 1.3698, Val Acc: 0.5140
Epoch 90/100, Loss: 0.1782, Acc: 0.9417, Val Loss: 1.3710, Val Acc: 0.5140
Epoch 91/100, Loss: 0.1782, Acc: 0.9431, Val Loss: 1.3687, Val Acc: 0.5159
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.1783, Acc: 0.9424, Val Loss: 1.3671, Val Acc: 0.5166
Epoch 93/100, Loss: 0.1781, Acc: 0.9431, Val Loss: 1.3595, Val Acc: 0.5207
Epoch 94/100, Loss: 0.1783, Acc: 0.9428, Val Loss: 1.3627, Val Acc: 0.5181
Epoch 95/100, Loss: 0.1781, Acc: 0.9431, Val Loss: 1.3592, Val Acc: 0.5203
Epoch 96/100, Loss: 0.1782, Acc: 0.9426, Val Loss: 1.3635, Val Acc: 0.5185
Epoch 97/100, Loss: 0.1782, Acc: 0.9429, Val Loss: 1.3658, Val Acc: 0.5162
Epoch 98/100, Loss: 0.1781, Acc: 0.9432, Val Loss: 1.3709, Val Acc: 0.5159
Epoch 99/100, Loss: 0.1780, Acc: 0.9429, Val Loss: 1.3659, Val Acc: 0.5181
Epoch 100/100, Loss: 0.1782, Acc: 0.9429, Val Loss: 1.3692, Val Acc: 0.5162

##############################
Resultados para principal:  107  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11 
 {'training': [0.17819748710851221, 0.9428702851885925, 0.9159314997405293, 0.9751381215469613, 0.9446079743109446], 'validate': [1.3691589017940122, 0.5162361623616236, 0.5081555834378921, 0.9, 0.6495589414595028], 'test': [0.44268763852569293, 0.8790560471976401, 0.862400906002265, 0.9011834319526627, 0.8813657407407407]}

######################################## 
########################################
Grupo en indetificación:  ['098', '025', '059', '121', '107', '086']  --- principal:  086  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  086  --- group:  ['098', '025', '059', '121', '107', '086']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  086  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6564, Acc: 0.6650, Val Loss: 0.7875, Val Acc: 0.3790
Mejor modelo guardado con Val Loss: 0.7875
Epoch 2/100, Loss: 0.6022, Acc: 0.7183, Val Loss: 0.8364, Val Acc: 0.3317
Epoch 3/100, Loss: 0.5651, Acc: 0.7353, Val Loss: 0.9033, Val Acc: 0.3945
Epoch 4/100, Loss: 0.5342, Acc: 0.7549, Val Loss: 1.0009, Val Acc: 0.3472
Epoch 5/100, Loss: 0.5121, Acc: 0.7690, Val Loss: 0.9926, Val Acc: 0.3967
Epoch 6/100, Loss: 0.5060, Acc: 0.7711, Val Loss: 0.9756, Val Acc: 0.4048
Epoch 7/100, Loss: 0.4935, Acc: 0.7786, Val Loss: 0.9811, Val Acc: 0.4162
Epoch 8/100, Loss: 0.4968, Acc: 0.7738, Val Loss: 1.0881, Val Acc: 0.2897
Epoch 9/100, Loss: 0.4946, Acc: 0.7770, Val Loss: 1.0608, Val Acc: 0.4011
Epoch 10/100, Loss: 0.4836, Acc: 0.7809, Val Loss: 1.0558, Val Acc: 0.3908
Epoch 11/100, Loss: 0.4788, Acc: 0.7880, Val Loss: 1.0655, Val Acc: 0.3601
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4651, Acc: 0.7913, Val Loss: 1.1387, Val Acc: 0.3790
Epoch 13/100, Loss: 0.4671, Acc: 0.7926, Val Loss: 1.0833, Val Acc: 0.3705
Epoch 14/100, Loss: 0.4746, Acc: 0.7826, Val Loss: 1.1156, Val Acc: 0.3649
Epoch 15/100, Loss: 0.4619, Acc: 0.7914, Val Loss: 1.0480, Val Acc: 0.3982
Epoch 16/100, Loss: 0.4627, Acc: 0.7919, Val Loss: 1.1387, Val Acc: 0.3465
Epoch 17/100, Loss: 0.4625, Acc: 0.7929, Val Loss: 1.0978, Val Acc: 0.3627
Epoch 18/100, Loss: 0.4639, Acc: 0.7920, Val Loss: 1.0659, Val Acc: 0.3542
Epoch 19/100, Loss: 0.4618, Acc: 0.7887, Val Loss: 1.0822, Val Acc: 0.3889
Epoch 20/100, Loss: 0.4609, Acc: 0.7913, Val Loss: 1.1003, Val Acc: 0.3897
Epoch 21/100, Loss: 0.4551, Acc: 0.7977, Val Loss: 1.0731, Val Acc: 0.4015
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4523, Acc: 0.7955, Val Loss: 1.1020, Val Acc: 0.3815
Epoch 23/100, Loss: 0.4486, Acc: 0.7994, Val Loss: 1.1767, Val Acc: 0.3391
Epoch 24/100, Loss: 0.4487, Acc: 0.7974, Val Loss: 1.0715, Val Acc: 0.3845
Epoch 25/100, Loss: 0.4485, Acc: 0.7973, Val Loss: 1.1225, Val Acc: 0.3804
Epoch 26/100, Loss: 0.4459, Acc: 0.7988, Val Loss: 1.0736, Val Acc: 0.3989
Epoch 27/100, Loss: 0.4471, Acc: 0.7982, Val Loss: 1.1001, Val Acc: 0.3793
Epoch 28/100, Loss: 0.4468, Acc: 0.7971, Val Loss: 1.1045, Val Acc: 0.3749
Epoch 29/100, Loss: 0.4463, Acc: 0.7975, Val Loss: 1.0903, Val Acc: 0.3779
Epoch 30/100, Loss: 0.4441, Acc: 0.7984, Val Loss: 1.1080, Val Acc: 0.3638
Epoch 31/100, Loss: 0.4461, Acc: 0.7986, Val Loss: 1.1148, Val Acc: 0.3690
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4417, Acc: 0.8027, Val Loss: 1.1186, Val Acc: 0.3790
Epoch 33/100, Loss: 0.4407, Acc: 0.8030, Val Loss: 1.1562, Val Acc: 0.3550
Epoch 34/100, Loss: 0.4410, Acc: 0.8018, Val Loss: 1.1206, Val Acc: 0.3790
Epoch 35/100, Loss: 0.4394, Acc: 0.8029, Val Loss: 1.1390, Val Acc: 0.3587
Epoch 36/100, Loss: 0.4411, Acc: 0.8008, Val Loss: 1.1105, Val Acc: 0.3812
Epoch 37/100, Loss: 0.4399, Acc: 0.8030, Val Loss: 1.1329, Val Acc: 0.3686
Epoch 38/100, Loss: 0.4393, Acc: 0.8013, Val Loss: 1.1094, Val Acc: 0.3867
Epoch 39/100, Loss: 0.4405, Acc: 0.8021, Val Loss: 1.1045, Val Acc: 0.3723
Epoch 40/100, Loss: 0.4400, Acc: 0.8006, Val Loss: 1.1311, Val Acc: 0.3635
Epoch 41/100, Loss: 0.4400, Acc: 0.8014, Val Loss: 1.0842, Val Acc: 0.3760
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4336, Acc: 0.8022, Val Loss: 1.0894, Val Acc: 0.3749
Epoch 43/100, Loss: 0.4340, Acc: 0.8014, Val Loss: 1.0463, Val Acc: 0.3838
Epoch 44/100, Loss: 0.4329, Acc: 0.8030, Val Loss: 1.0504, Val Acc: 0.3790
Epoch 45/100, Loss: 0.4331, Acc: 0.8021, Val Loss: 1.0607, Val Acc: 0.3812
Epoch 46/100, Loss: 0.4319, Acc: 0.8039, Val Loss: 1.0637, Val Acc: 0.3812
Epoch 47/100, Loss: 0.4306, Acc: 0.8035, Val Loss: 1.0323, Val Acc: 0.3834
Epoch 48/100, Loss: 0.4301, Acc: 0.8036, Val Loss: 1.0421, Val Acc: 0.3904
Epoch 49/100, Loss: 0.4291, Acc: 0.8043, Val Loss: 1.0453, Val Acc: 0.3849
Epoch 50/100, Loss: 0.4295, Acc: 0.8029, Val Loss: 1.0185, Val Acc: 0.3926
Epoch 51/100, Loss: 0.4289, Acc: 0.8047, Val Loss: 1.0165, Val Acc: 0.3993
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4277, Acc: 0.8042, Val Loss: 1.0236, Val Acc: 0.3945
Epoch 53/100, Loss: 0.4269, Acc: 0.8056, Val Loss: 1.0330, Val Acc: 0.3900
Epoch 54/100, Loss: 0.4268, Acc: 0.8036, Val Loss: 1.0276, Val Acc: 0.3934
Epoch 55/100, Loss: 0.4272, Acc: 0.8050, Val Loss: 1.0323, Val Acc: 0.3904
Epoch 56/100, Loss: 0.4260, Acc: 0.8038, Val Loss: 1.0275, Val Acc: 0.3923
Epoch 57/100, Loss: 0.4261, Acc: 0.8059, Val Loss: 1.0301, Val Acc: 0.3893
Epoch 58/100, Loss: 0.4258, Acc: 0.8049, Val Loss: 1.0131, Val Acc: 0.3926
Epoch 59/100, Loss: 0.4252, Acc: 0.8049, Val Loss: 1.0295, Val Acc: 0.3959
Epoch 60/100, Loss: 0.4248, Acc: 0.8049, Val Loss: 1.0246, Val Acc: 0.3923
Epoch 61/100, Loss: 0.4250, Acc: 0.8042, Val Loss: 0.9981, Val Acc: 0.3985
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4245, Acc: 0.8049, Val Loss: 1.0174, Val Acc: 0.3959
Epoch 63/100, Loss: 0.4240, Acc: 0.8056, Val Loss: 1.0151, Val Acc: 0.3941
Epoch 64/100, Loss: 0.4241, Acc: 0.8059, Val Loss: 1.0233, Val Acc: 0.3952
Epoch 65/100, Loss: 0.4240, Acc: 0.8052, Val Loss: 1.0244, Val Acc: 0.3948
Epoch 66/100, Loss: 0.4238, Acc: 0.8054, Val Loss: 1.0183, Val Acc: 0.3945
Epoch 67/100, Loss: 0.4235, Acc: 0.8061, Val Loss: 1.0140, Val Acc: 0.3978
Epoch 68/100, Loss: 0.4236, Acc: 0.8035, Val Loss: 1.0212, Val Acc: 0.3937
Epoch 69/100, Loss: 0.4236, Acc: 0.8048, Val Loss: 1.0177, Val Acc: 0.3945
Epoch 70/100, Loss: 0.4235, Acc: 0.8052, Val Loss: 1.0135, Val Acc: 0.3952
Epoch 71/100, Loss: 0.4233, Acc: 0.8051, Val Loss: 1.0125, Val Acc: 0.3993
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4228, Acc: 0.8055, Val Loss: 1.0122, Val Acc: 0.3978
Epoch 73/100, Loss: 0.4227, Acc: 0.8057, Val Loss: 1.0183, Val Acc: 0.3952
Epoch 74/100, Loss: 0.4229, Acc: 0.8059, Val Loss: 1.0139, Val Acc: 0.3967
Epoch 75/100, Loss: 0.4226, Acc: 0.8053, Val Loss: 1.0135, Val Acc: 0.3970
Epoch 76/100, Loss: 0.4226, Acc: 0.8048, Val Loss: 1.0183, Val Acc: 0.3948
Epoch 77/100, Loss: 0.4223, Acc: 0.8063, Val Loss: 1.0119, Val Acc: 0.3967
Epoch 78/100, Loss: 0.4224, Acc: 0.8058, Val Loss: 1.0144, Val Acc: 0.3948
Epoch 79/100, Loss: 0.4224, Acc: 0.8053, Val Loss: 1.0092, Val Acc: 0.3978
Epoch 80/100, Loss: 0.4222, Acc: 0.8053, Val Loss: 1.0168, Val Acc: 0.3952
Epoch 81/100, Loss: 0.4220, Acc: 0.8060, Val Loss: 1.0122, Val Acc: 0.3967
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4220, Acc: 0.8067, Val Loss: 1.0056, Val Acc: 0.3974
Epoch 83/100, Loss: 0.4220, Acc: 0.8055, Val Loss: 1.0102, Val Acc: 0.3970
Epoch 84/100, Loss: 0.4219, Acc: 0.8050, Val Loss: 1.0110, Val Acc: 0.3978
Epoch 85/100, Loss: 0.4220, Acc: 0.8060, Val Loss: 1.0060, Val Acc: 0.3989
Epoch 86/100, Loss: 0.4216, Acc: 0.8055, Val Loss: 1.0153, Val Acc: 0.3963
Epoch 87/100, Loss: 0.4219, Acc: 0.8067, Val Loss: 1.0122, Val Acc: 0.3963
Epoch 88/100, Loss: 0.4216, Acc: 0.8073, Val Loss: 0.9999, Val Acc: 0.4015
Epoch 89/100, Loss: 0.4216, Acc: 0.8064, Val Loss: 1.0066, Val Acc: 0.4018
Epoch 90/100, Loss: 0.4214, Acc: 0.8058, Val Loss: 1.0061, Val Acc: 0.3970
Epoch 91/100, Loss: 0.4214, Acc: 0.8051, Val Loss: 1.0125, Val Acc: 0.3923
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4213, Acc: 0.8069, Val Loss: 1.0048, Val Acc: 0.3974
Epoch 93/100, Loss: 0.4212, Acc: 0.8063, Val Loss: 1.0043, Val Acc: 0.4011
Epoch 94/100, Loss: 0.4192, Acc: 0.8077, Val Loss: 0.9523, Val Acc: 0.4277
Epoch 95/100, Loss: 0.4179, Acc: 0.8093, Val Loss: 0.9575, Val Acc: 0.4303
Epoch 96/100, Loss: 0.4183, Acc: 0.8093, Val Loss: 0.9600, Val Acc: 0.4255
Epoch 97/100, Loss: 0.4178, Acc: 0.8092, Val Loss: 0.9490, Val Acc: 0.4303
Epoch 98/100, Loss: 0.4178, Acc: 0.8087, Val Loss: 0.9567, Val Acc: 0.4266
Epoch 99/100, Loss: 0.4172, Acc: 0.8088, Val Loss: 0.9629, Val Acc: 0.4232
Epoch 100/100, Loss: 0.4178, Acc: 0.8090, Val Loss: 0.9555, Val Acc: 0.4306

##############################
Resultados para principal:  086  --- grupo:  ['098', '025', '059', '121', '107', '086']  --- window & package numer:  11 
 {'training': [0.41782572706467314, 0.809015639374425, 0.7840447154471545, 0.8524861878453038, 0.8168343038644785], 'validate': [0.9555203089880389, 0.4306273062730627, 0.4509903504316912, 0.6577777777777778, 0.53510093401627], 'test': [0.7495901719579157, 0.40412979351032446, 0.4400871459694989, 0.7171597633136094, 0.5454545454545454]}

##############################
Resultados para window:  11 
 {'098:025:059:121:107:086': {'training': [0.46139170411758285, 0.7927322907083717, 0.7415234909533222, 0.898158379373849, 0.8123594569834264], 'validate': [0.29747184305343516, 0.9114391143911439, 0.961730449251248, 0.8562962962962963, 0.9059561128526645], 'test': [0.6602721815963961, 0.6117994100294986, 0.5698282300224048, 0.9029585798816568, 0.6987179487179487]}, '025:098:059:121:107:086': {'training': [0.5437774800552396, 0.7110395584176633, 0.6559901867248195, 0.8863720073664825, 0.7539750920341506], 'validate': [0.5198050283415373, 0.7361623616236163, 0.7562550443906376, 0.6940740740740741, 0.723831595210506], 'test': [0.549684354437972, 0.7519174041297935, 0.7399660825325043, 0.7745562130177515, 0.7568661462850534]}, '059:098:025:121:107:086': {'training': [0.5433564936226404, 0.699080036798528, 0.7018889096689732, 0.6911602209944752, 0.6964832513686555], 'validate': [0.2900814344716627, 0.911070110701107, 0.9800865800865801, 0.8385185185185186, 0.9037924151696607], 'test': [0.5397337804425437, 0.7168141592920354, 0.6688251618871416, 0.855621301775148, 0.7507788161993769]}, '121:098:025:059:107:086': {'training': [0.10019261168166926, 0.9596136154553818, 0.9482665708640201, 0.9721915285451197, 0.9600800218241339], 'validate': [1.4375625629476163, 0.5402214022140222, 0.5215410107705054, 0.9325925925925926, 0.6689691817215728], 'test': [0.3897809752456422, 0.8283185840707965, 0.8001083423618635, 0.8739644970414201, 0.8354072398190046]}, '107:098:025:059:121:086': {'training': [0.17819748710851221, 0.9428702851885925, 0.9159314997405293, 0.9751381215469613, 0.9446079743109446], 'validate': [1.3691589017940122, 0.5162361623616236, 0.5081555834378921, 0.9, 0.6495589414595028], 'test': [0.44268763852569293, 0.8790560471976401, 0.862400906002265, 0.9011834319526627, 0.8813657407407407]}, '086:098:025:059:121:107': {'training': [0.41782572706467314, 0.809015639374425, 0.7840447154471545, 0.8524861878453038, 0.8168343038644785], 'validate': [0.9555203089880389, 0.4306273062730627, 0.4509903504316912, 0.6577777777777778, 0.53510093401627], 'test': [0.7495901719579157, 0.40412979351032446, 0.4400871459694989, 0.7171597633136094, 0.5454545454545454]}}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  031  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  031  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  031  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6764, Acc: 0.6073, Val Loss: 0.7009, Val Acc: 0.4716
Mejor modelo guardado con Val Loss: 0.7009
Epoch 2/100, Loss: 0.6650, Acc: 0.6298, Val Loss: 0.7127, Val Acc: 0.4919
Epoch 3/100, Loss: 0.6452, Acc: 0.6508, Val Loss: 0.7383, Val Acc: 0.4889
Epoch 4/100, Loss: 0.6325, Acc: 0.6580, Val Loss: 0.7534, Val Acc: 0.4915
Epoch 5/100, Loss: 0.6216, Acc: 0.6726, Val Loss: 0.7735, Val Acc: 0.4697
Epoch 6/100, Loss: 0.6165, Acc: 0.6714, Val Loss: 0.8010, Val Acc: 0.4827
Epoch 7/100, Loss: 0.6161, Acc: 0.6705, Val Loss: 0.8084, Val Acc: 0.4627
Epoch 8/100, Loss: 0.6122, Acc: 0.6734, Val Loss: 0.8289, Val Acc: 0.4686
Epoch 9/100, Loss: 0.6054, Acc: 0.6821, Val Loss: 0.7894, Val Acc: 0.5015
Epoch 10/100, Loss: 0.6077, Acc: 0.6772, Val Loss: 0.8214, Val Acc: 0.4469
Epoch 11/100, Loss: 0.6048, Acc: 0.6807, Val Loss: 0.8060, Val Acc: 0.5066
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5941, Acc: 0.6909, Val Loss: 0.8061, Val Acc: 0.5299
Epoch 13/100, Loss: 0.5940, Acc: 0.6932, Val Loss: 0.8488, Val Acc: 0.4797
Epoch 14/100, Loss: 0.5904, Acc: 0.6975, Val Loss: 0.8315, Val Acc: 0.4815
Epoch 15/100, Loss: 0.5920, Acc: 0.6917, Val Loss: 0.8251, Val Acc: 0.5332
Epoch 16/100, Loss: 0.5895, Acc: 0.6974, Val Loss: 0.8494, Val Acc: 0.4849
Epoch 17/100, Loss: 0.5893, Acc: 0.6942, Val Loss: 0.8446, Val Acc: 0.4993
Epoch 18/100, Loss: 0.5873, Acc: 0.6959, Val Loss: 0.8577, Val Acc: 0.5063
Epoch 19/100, Loss: 0.5918, Acc: 0.6906, Val Loss: 0.8325, Val Acc: 0.4369
Epoch 20/100, Loss: 0.5905, Acc: 0.6947, Val Loss: 0.8410, Val Acc: 0.4406
Epoch 21/100, Loss: 0.5880, Acc: 0.6955, Val Loss: 0.8757, Val Acc: 0.4945
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5834, Acc: 0.7040, Val Loss: 0.8631, Val Acc: 0.4823
Epoch 23/100, Loss: 0.5830, Acc: 0.6996, Val Loss: 0.8671, Val Acc: 0.4779
Epoch 24/100, Loss: 0.5817, Acc: 0.7029, Val Loss: 0.8565, Val Acc: 0.4875
Epoch 25/100, Loss: 0.5820, Acc: 0.7021, Val Loss: 0.8560, Val Acc: 0.4823
Epoch 26/100, Loss: 0.5810, Acc: 0.7064, Val Loss: 0.8616, Val Acc: 0.4989
Epoch 27/100, Loss: 0.5812, Acc: 0.7040, Val Loss: 0.8706, Val Acc: 0.4661
Epoch 28/100, Loss: 0.5800, Acc: 0.7063, Val Loss: 0.8846, Val Acc: 0.4461
Epoch 29/100, Loss: 0.5814, Acc: 0.7017, Val Loss: 0.8866, Val Acc: 0.4790
Epoch 30/100, Loss: 0.5802, Acc: 0.7046, Val Loss: 0.8640, Val Acc: 0.4808
Epoch 31/100, Loss: 0.5795, Acc: 0.7071, Val Loss: 0.8583, Val Acc: 0.4793
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5769, Acc: 0.7096, Val Loss: 0.8928, Val Acc: 0.4494
Epoch 33/100, Loss: 0.5773, Acc: 0.7085, Val Loss: 0.8694, Val Acc: 0.4993
Epoch 34/100, Loss: 0.5766, Acc: 0.7115, Val Loss: 0.8751, Val Acc: 0.4830
Epoch 35/100, Loss: 0.5762, Acc: 0.7104, Val Loss: 0.8887, Val Acc: 0.4579
Epoch 36/100, Loss: 0.5769, Acc: 0.7093, Val Loss: 0.8769, Val Acc: 0.4712
Epoch 37/100, Loss: 0.5758, Acc: 0.7075, Val Loss: 0.8789, Val Acc: 0.4734
Epoch 38/100, Loss: 0.5759, Acc: 0.7097, Val Loss: 0.8835, Val Acc: 0.4897
Epoch 39/100, Loss: 0.5753, Acc: 0.7099, Val Loss: 0.8791, Val Acc: 0.4694
Epoch 40/100, Loss: 0.5747, Acc: 0.7094, Val Loss: 0.8697, Val Acc: 0.4893
Epoch 41/100, Loss: 0.5756, Acc: 0.7104, Val Loss: 0.8924, Val Acc: 0.4579
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5749, Acc: 0.7116, Val Loss: 0.8730, Val Acc: 0.4849
Epoch 43/100, Loss: 0.5743, Acc: 0.7117, Val Loss: 0.8843, Val Acc: 0.4731
Epoch 44/100, Loss: 0.5739, Acc: 0.7134, Val Loss: 0.8780, Val Acc: 0.4801
Epoch 45/100, Loss: 0.5743, Acc: 0.7120, Val Loss: 0.8701, Val Acc: 0.5066
Epoch 46/100, Loss: 0.5738, Acc: 0.7113, Val Loss: 0.8845, Val Acc: 0.4583
Epoch 47/100, Loss: 0.5738, Acc: 0.7121, Val Loss: 0.8721, Val Acc: 0.4889
Epoch 48/100, Loss: 0.5734, Acc: 0.7118, Val Loss: 0.8778, Val Acc: 0.4801
Epoch 49/100, Loss: 0.5741, Acc: 0.7101, Val Loss: 0.8794, Val Acc: 0.4779
Epoch 50/100, Loss: 0.5731, Acc: 0.7104, Val Loss: 0.8910, Val Acc: 0.4661
Epoch 51/100, Loss: 0.5734, Acc: 0.7135, Val Loss: 0.8714, Val Acc: 0.4875
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5727, Acc: 0.7124, Val Loss: 0.8789, Val Acc: 0.4775
Epoch 53/100, Loss: 0.5721, Acc: 0.7130, Val Loss: 0.8735, Val Acc: 0.4989
Epoch 54/100, Loss: 0.5729, Acc: 0.7119, Val Loss: 0.8768, Val Acc: 0.4926
Epoch 55/100, Loss: 0.5725, Acc: 0.7152, Val Loss: 0.8740, Val Acc: 0.4764
Epoch 56/100, Loss: 0.5717, Acc: 0.7136, Val Loss: 0.8738, Val Acc: 0.5037
Epoch 57/100, Loss: 0.5724, Acc: 0.7114, Val Loss: 0.8740, Val Acc: 0.4867
Epoch 58/100, Loss: 0.5722, Acc: 0.7108, Val Loss: 0.8849, Val Acc: 0.4727
Epoch 59/100, Loss: 0.5718, Acc: 0.7124, Val Loss: 0.8849, Val Acc: 0.4631
Epoch 60/100, Loss: 0.5717, Acc: 0.7126, Val Loss: 0.8756, Val Acc: 0.4867
Epoch 61/100, Loss: 0.5718, Acc: 0.7137, Val Loss: 0.8787, Val Acc: 0.4878
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5716, Acc: 0.7132, Val Loss: 0.8786, Val Acc: 0.4875
Epoch 63/100, Loss: 0.5714, Acc: 0.7135, Val Loss: 0.8783, Val Acc: 0.4827
Epoch 64/100, Loss: 0.5712, Acc: 0.7124, Val Loss: 0.8856, Val Acc: 0.4649
Epoch 65/100, Loss: 0.5715, Acc: 0.7134, Val Loss: 0.8784, Val Acc: 0.4863
Epoch 66/100, Loss: 0.5716, Acc: 0.7132, Val Loss: 0.8794, Val Acc: 0.4801
Epoch 67/100, Loss: 0.5714, Acc: 0.7137, Val Loss: 0.8800, Val Acc: 0.4860
Epoch 68/100, Loss: 0.5714, Acc: 0.7134, Val Loss: 0.8832, Val Acc: 0.4790
Epoch 69/100, Loss: 0.5714, Acc: 0.7132, Val Loss: 0.8814, Val Acc: 0.4815
Epoch 70/100, Loss: 0.5712, Acc: 0.7130, Val Loss: 0.8840, Val Acc: 0.4753
Epoch 71/100, Loss: 0.5712, Acc: 0.7134, Val Loss: 0.8802, Val Acc: 0.4875
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5711, Acc: 0.7130, Val Loss: 0.8832, Val Acc: 0.4756
Epoch 73/100, Loss: 0.5709, Acc: 0.7124, Val Loss: 0.8804, Val Acc: 0.4886
Epoch 74/100, Loss: 0.5711, Acc: 0.7134, Val Loss: 0.8828, Val Acc: 0.4790
Epoch 75/100, Loss: 0.5710, Acc: 0.7136, Val Loss: 0.8826, Val Acc: 0.4782
Epoch 76/100, Loss: 0.5709, Acc: 0.7135, Val Loss: 0.8817, Val Acc: 0.4804
Epoch 77/100, Loss: 0.5710, Acc: 0.7126, Val Loss: 0.8821, Val Acc: 0.4793
Epoch 78/100, Loss: 0.5711, Acc: 0.7113, Val Loss: 0.8823, Val Acc: 0.4793
Epoch 79/100, Loss: 0.5709, Acc: 0.7134, Val Loss: 0.8816, Val Acc: 0.4827
Epoch 80/100, Loss: 0.5708, Acc: 0.7132, Val Loss: 0.8822, Val Acc: 0.4823
Epoch 81/100, Loss: 0.5709, Acc: 0.7132, Val Loss: 0.8832, Val Acc: 0.4801
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5709, Acc: 0.7127, Val Loss: 0.8816, Val Acc: 0.4827
Epoch 83/100, Loss: 0.5708, Acc: 0.7153, Val Loss: 0.8846, Val Acc: 0.4749
Epoch 84/100, Loss: 0.5707, Acc: 0.7126, Val Loss: 0.8845, Val Acc: 0.4756
Epoch 85/100, Loss: 0.5705, Acc: 0.7134, Val Loss: 0.8833, Val Acc: 0.4764
Epoch 86/100, Loss: 0.5707, Acc: 0.7127, Val Loss: 0.8808, Val Acc: 0.4838
Epoch 87/100, Loss: 0.5706, Acc: 0.7131, Val Loss: 0.8821, Val Acc: 0.4819
Epoch 88/100, Loss: 0.5704, Acc: 0.7131, Val Loss: 0.8845, Val Acc: 0.4753
Epoch 89/100, Loss: 0.5704, Acc: 0.7133, Val Loss: 0.8848, Val Acc: 0.4760
Epoch 90/100, Loss: 0.5703, Acc: 0.7145, Val Loss: 0.8807, Val Acc: 0.4849
Epoch 91/100, Loss: 0.5704, Acc: 0.7138, Val Loss: 0.8835, Val Acc: 0.4804
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5704, Acc: 0.7131, Val Loss: 0.8847, Val Acc: 0.4760
Epoch 93/100, Loss: 0.5704, Acc: 0.7122, Val Loss: 0.8849, Val Acc: 0.4756
Epoch 94/100, Loss: 0.5705, Acc: 0.7130, Val Loss: 0.8830, Val Acc: 0.4823
Epoch 95/100, Loss: 0.5703, Acc: 0.7135, Val Loss: 0.8845, Val Acc: 0.4786
Epoch 96/100, Loss: 0.5702, Acc: 0.7134, Val Loss: 0.8824, Val Acc: 0.4827
Epoch 97/100, Loss: 0.5703, Acc: 0.7134, Val Loss: 0.8829, Val Acc: 0.4812
Epoch 98/100, Loss: 0.5704, Acc: 0.7141, Val Loss: 0.8828, Val Acc: 0.4823
Epoch 99/100, Loss: 0.5703, Acc: 0.7134, Val Loss: 0.8849, Val Acc: 0.4786
Epoch 100/100, Loss: 0.5701, Acc: 0.7136, Val Loss: 0.8861, Val Acc: 0.4756

##############################
Resultados para principal:  031  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11 
 {'training': [0.5700760268901836, 0.7136154553817847, 0.6996381182147166, 0.7476979742173112, 0.722870114840203], 'validate': [0.8860723778258922, 0.4756457564575646, 0.4826744753538311, 0.7325925925925926, 0.5819358634892615], 'test': [0.6959069045084827, 0.5067846607669616, 0.5060893098782138, 0.44260355029585796, 0.4722222222222222]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  051  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  051  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  051  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6434, Acc: 0.6679, Val Loss: 0.6796, Val Acc: 0.5594
Mejor modelo guardado con Val Loss: 0.6796
Epoch 2/100, Loss: 0.5699, Acc: 0.7354, Val Loss: 0.6936, Val Acc: 0.5679
Epoch 3/100, Loss: 0.5270, Acc: 0.7516, Val Loss: 0.6976, Val Acc: 0.5993
Epoch 4/100, Loss: 0.5137, Acc: 0.7523, Val Loss: 0.7089, Val Acc: 0.6000
Epoch 5/100, Loss: 0.4911, Acc: 0.7689, Val Loss: 0.7361, Val Acc: 0.5782
Epoch 6/100, Loss: 0.4848, Acc: 0.7741, Val Loss: 0.7489, Val Acc: 0.6100
Epoch 7/100, Loss: 0.4747, Acc: 0.7798, Val Loss: 0.7020, Val Acc: 0.5926
Epoch 8/100, Loss: 0.4631, Acc: 0.7865, Val Loss: 0.7285, Val Acc: 0.6258
Epoch 9/100, Loss: 0.4502, Acc: 0.7917, Val Loss: 0.7709, Val Acc: 0.6277
Epoch 10/100, Loss: 0.4421, Acc: 0.7976, Val Loss: 0.7465, Val Acc: 0.6170
Epoch 11/100, Loss: 0.4430, Acc: 0.7976, Val Loss: 0.7649, Val Acc: 0.6107
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4301, Acc: 0.8024, Val Loss: 0.7605, Val Acc: 0.6273
Epoch 13/100, Loss: 0.4271, Acc: 0.8038, Val Loss: 0.7728, Val Acc: 0.6314
Epoch 14/100, Loss: 0.4266, Acc: 0.8059, Val Loss: 0.7254, Val Acc: 0.6273
Epoch 15/100, Loss: 0.4233, Acc: 0.8064, Val Loss: 0.7329, Val Acc: 0.6321
Epoch 16/100, Loss: 0.4210, Acc: 0.8066, Val Loss: 0.7941, Val Acc: 0.6317
Epoch 17/100, Loss: 0.4193, Acc: 0.8078, Val Loss: 0.7145, Val Acc: 0.6292
Epoch 18/100, Loss: 0.4189, Acc: 0.8080, Val Loss: 0.7361, Val Acc: 0.6292
Epoch 19/100, Loss: 0.4193, Acc: 0.8083, Val Loss: 0.7846, Val Acc: 0.6292
Epoch 20/100, Loss: 0.4145, Acc: 0.8112, Val Loss: 0.7381, Val Acc: 0.6369
Epoch 21/100, Loss: 0.4155, Acc: 0.8093, Val Loss: 0.7673, Val Acc: 0.5993
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4070, Acc: 0.8133, Val Loss: 0.7843, Val Acc: 0.6347
Epoch 23/100, Loss: 0.4068, Acc: 0.8133, Val Loss: 0.8237, Val Acc: 0.6325
Epoch 24/100, Loss: 0.4023, Acc: 0.8178, Val Loss: 0.7640, Val Acc: 0.6384
Epoch 25/100, Loss: 0.4057, Acc: 0.8171, Val Loss: 0.7639, Val Acc: 0.6458
Epoch 26/100, Loss: 0.4051, Acc: 0.8162, Val Loss: 0.7745, Val Acc: 0.6325
Epoch 27/100, Loss: 0.4030, Acc: 0.8143, Val Loss: 0.8396, Val Acc: 0.6332
Epoch 28/100, Loss: 0.4025, Acc: 0.8182, Val Loss: 0.7515, Val Acc: 0.6424
Epoch 29/100, Loss: 0.4012, Acc: 0.8153, Val Loss: 0.7652, Val Acc: 0.6395
Epoch 30/100, Loss: 0.4004, Acc: 0.8186, Val Loss: 0.8014, Val Acc: 0.6339
Epoch 31/100, Loss: 0.4020, Acc: 0.8174, Val Loss: 0.7853, Val Acc: 0.6332
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3966, Acc: 0.8185, Val Loss: 0.8159, Val Acc: 0.6469
Epoch 33/100, Loss: 0.3958, Acc: 0.8211, Val Loss: 0.8193, Val Acc: 0.6410
Epoch 34/100, Loss: 0.3952, Acc: 0.8209, Val Loss: 0.8165, Val Acc: 0.6369
Epoch 35/100, Loss: 0.3943, Acc: 0.8206, Val Loss: 0.7835, Val Acc: 0.6402
Epoch 36/100, Loss: 0.3938, Acc: 0.8208, Val Loss: 0.8410, Val Acc: 0.6410
Epoch 37/100, Loss: 0.3954, Acc: 0.8194, Val Loss: 0.7930, Val Acc: 0.6454
Epoch 38/100, Loss: 0.3955, Acc: 0.8200, Val Loss: 0.7990, Val Acc: 0.6351
Epoch 39/100, Loss: 0.3933, Acc: 0.8209, Val Loss: 0.8086, Val Acc: 0.6395
Epoch 40/100, Loss: 0.3934, Acc: 0.8220, Val Loss: 0.8164, Val Acc: 0.6391
Epoch 41/100, Loss: 0.3926, Acc: 0.8227, Val Loss: 0.7914, Val Acc: 0.6395
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3900, Acc: 0.8236, Val Loss: 0.7886, Val Acc: 0.6387
Epoch 43/100, Loss: 0.3908, Acc: 0.8228, Val Loss: 0.7922, Val Acc: 0.6443
Epoch 44/100, Loss: 0.3902, Acc: 0.8204, Val Loss: 0.8094, Val Acc: 0.6399
Epoch 45/100, Loss: 0.3897, Acc: 0.8233, Val Loss: 0.8002, Val Acc: 0.6421
Epoch 46/100, Loss: 0.3900, Acc: 0.8224, Val Loss: 0.8088, Val Acc: 0.6432
Epoch 47/100, Loss: 0.3903, Acc: 0.8236, Val Loss: 0.7944, Val Acc: 0.6435
Epoch 48/100, Loss: 0.3895, Acc: 0.8224, Val Loss: 0.7904, Val Acc: 0.6413
Epoch 49/100, Loss: 0.3892, Acc: 0.8223, Val Loss: 0.8050, Val Acc: 0.6435
Epoch 50/100, Loss: 0.3889, Acc: 0.8245, Val Loss: 0.7978, Val Acc: 0.6428
Epoch 51/100, Loss: 0.3885, Acc: 0.8226, Val Loss: 0.7846, Val Acc: 0.6443
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3878, Acc: 0.8246, Val Loss: 0.7926, Val Acc: 0.6439
Epoch 53/100, Loss: 0.3879, Acc: 0.8246, Val Loss: 0.8091, Val Acc: 0.6421
Epoch 54/100, Loss: 0.3885, Acc: 0.8213, Val Loss: 0.7970, Val Acc: 0.6417
Epoch 55/100, Loss: 0.3871, Acc: 0.8254, Val Loss: 0.7957, Val Acc: 0.6439
Epoch 56/100, Loss: 0.3870, Acc: 0.8236, Val Loss: 0.7929, Val Acc: 0.6421
Epoch 57/100, Loss: 0.3869, Acc: 0.8238, Val Loss: 0.8043, Val Acc: 0.6443
Epoch 58/100, Loss: 0.3871, Acc: 0.8248, Val Loss: 0.8003, Val Acc: 0.6399
Epoch 59/100, Loss: 0.3871, Acc: 0.8236, Val Loss: 0.8233, Val Acc: 0.6428
Epoch 60/100, Loss: 0.3870, Acc: 0.8239, Val Loss: 0.8036, Val Acc: 0.6421
Epoch 61/100, Loss: 0.3873, Acc: 0.8239, Val Loss: 0.8145, Val Acc: 0.6421
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3862, Acc: 0.8242, Val Loss: 0.8090, Val Acc: 0.6443
Epoch 63/100, Loss: 0.3862, Acc: 0.8254, Val Loss: 0.8046, Val Acc: 0.6435
Epoch 64/100, Loss: 0.3862, Acc: 0.8253, Val Loss: 0.8098, Val Acc: 0.6446
Epoch 65/100, Loss: 0.3858, Acc: 0.8241, Val Loss: 0.8055, Val Acc: 0.6454
Epoch 66/100, Loss: 0.3861, Acc: 0.8237, Val Loss: 0.8001, Val Acc: 0.6439
Epoch 67/100, Loss: 0.3857, Acc: 0.8248, Val Loss: 0.8113, Val Acc: 0.6421
Epoch 68/100, Loss: 0.3855, Acc: 0.8256, Val Loss: 0.8113, Val Acc: 0.6439
Epoch 69/100, Loss: 0.3853, Acc: 0.8261, Val Loss: 0.8095, Val Acc: 0.6465
Epoch 70/100, Loss: 0.3854, Acc: 0.8263, Val Loss: 0.8067, Val Acc: 0.6454
Epoch 71/100, Loss: 0.3853, Acc: 0.8262, Val Loss: 0.8036, Val Acc: 0.6458
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3850, Acc: 0.8262, Val Loss: 0.8039, Val Acc: 0.6458
Epoch 73/100, Loss: 0.3849, Acc: 0.8254, Val Loss: 0.8025, Val Acc: 0.6446
Epoch 74/100, Loss: 0.3849, Acc: 0.8257, Val Loss: 0.8087, Val Acc: 0.6465
Epoch 75/100, Loss: 0.3849, Acc: 0.8263, Val Loss: 0.8064, Val Acc: 0.6458
Epoch 76/100, Loss: 0.3848, Acc: 0.8264, Val Loss: 0.8062, Val Acc: 0.6454
Epoch 77/100, Loss: 0.3848, Acc: 0.8259, Val Loss: 0.8140, Val Acc: 0.6458
Epoch 78/100, Loss: 0.3847, Acc: 0.8258, Val Loss: 0.8027, Val Acc: 0.6458
Epoch 79/100, Loss: 0.3846, Acc: 0.8258, Val Loss: 0.8088, Val Acc: 0.6454
Epoch 80/100, Loss: 0.3846, Acc: 0.8264, Val Loss: 0.8168, Val Acc: 0.6439
Epoch 81/100, Loss: 0.3848, Acc: 0.8254, Val Loss: 0.8100, Val Acc: 0.6446
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3846, Acc: 0.8259, Val Loss: 0.8020, Val Acc: 0.6446
Epoch 83/100, Loss: 0.3848, Acc: 0.8249, Val Loss: 0.8065, Val Acc: 0.6465
Epoch 84/100, Loss: 0.3845, Acc: 0.8246, Val Loss: 0.8036, Val Acc: 0.6458
Epoch 85/100, Loss: 0.3846, Acc: 0.8259, Val Loss: 0.8082, Val Acc: 0.6472
Epoch 86/100, Loss: 0.3846, Acc: 0.8247, Val Loss: 0.8091, Val Acc: 0.6461
Epoch 87/100, Loss: 0.3843, Acc: 0.8264, Val Loss: 0.8056, Val Acc: 0.6469
Epoch 88/100, Loss: 0.3844, Acc: 0.8265, Val Loss: 0.8060, Val Acc: 0.6465
Epoch 89/100, Loss: 0.3844, Acc: 0.8261, Val Loss: 0.8131, Val Acc: 0.6465
Epoch 90/100, Loss: 0.3844, Acc: 0.8262, Val Loss: 0.8064, Val Acc: 0.6454
Epoch 91/100, Loss: 0.3845, Acc: 0.8263, Val Loss: 0.8033, Val Acc: 0.6446
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3844, Acc: 0.8270, Val Loss: 0.8099, Val Acc: 0.6458
Epoch 93/100, Loss: 0.3842, Acc: 0.8259, Val Loss: 0.8149, Val Acc: 0.6450
Epoch 94/100, Loss: 0.3841, Acc: 0.8253, Val Loss: 0.8034, Val Acc: 0.6472
Epoch 95/100, Loss: 0.3843, Acc: 0.8259, Val Loss: 0.8087, Val Acc: 0.6461
Epoch 96/100, Loss: 0.3841, Acc: 0.8262, Val Loss: 0.8093, Val Acc: 0.6461
Epoch 97/100, Loss: 0.3843, Acc: 0.8260, Val Loss: 0.8051, Val Acc: 0.6465
Epoch 98/100, Loss: 0.3841, Acc: 0.8264, Val Loss: 0.8039, Val Acc: 0.6439
Epoch 99/100, Loss: 0.3838, Acc: 0.8262, Val Loss: 0.8105, Val Acc: 0.6458
Epoch 100/100, Loss: 0.3841, Acc: 0.8258, Val Loss: 0.8173, Val Acc: 0.6476

##############################
Resultados para principal:  051  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11 
 {'training': [0.3840782343573601, 0.8257589696412143, 0.8351023502653525, 0.8114180478821362, 0.8230898561554268], 'validate': [0.8173064126871353, 0.6476014760147601, 0.6179104477611941, 0.7666666666666667, 0.684297520661157], 'test': [0.5831562831716718, 0.752802359882006, 0.8597972972972973, 0.6023668639053255, 0.708420320111343]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  096  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  096  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  096  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6911, Acc: 0.5337, Val Loss: 0.6876, Val Acc: 0.5646
Mejor modelo guardado con Val Loss: 0.6876
Epoch 2/100, Loss: 0.6925, Acc: 0.5158, Val Loss: 0.6849, Val Acc: 0.6284
Mejor modelo guardado con Val Loss: 0.6849
Epoch 3/100, Loss: 0.6927, Acc: 0.5164, Val Loss: 0.6929, Val Acc: 0.4982
Epoch 4/100, Loss: 0.6920, Acc: 0.5197, Val Loss: 0.6868, Val Acc: 0.5989
Epoch 5/100, Loss: 0.6896, Acc: 0.5506, Val Loss: 0.6808, Val Acc: 0.6310
Mejor modelo guardado con Val Loss: 0.6808
Epoch 6/100, Loss: 0.6901, Acc: 0.5382, Val Loss: 0.6890, Val Acc: 0.5531
Epoch 7/100, Loss: 0.6883, Acc: 0.5508, Val Loss: 0.6811, Val Acc: 0.6089
Epoch 8/100, Loss: 0.6877, Acc: 0.5523, Val Loss: 0.6803, Val Acc: 0.5967
Mejor modelo guardado con Val Loss: 0.6803
Epoch 9/100, Loss: 0.6869, Acc: 0.5497, Val Loss: 0.6810, Val Acc: 0.5875
Epoch 10/100, Loss: 0.6841, Acc: 0.5699, Val Loss: 0.6893, Val Acc: 0.5317
Epoch 11/100, Loss: 0.6826, Acc: 0.5738, Val Loss: 0.6839, Val Acc: 0.5620
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6811, Acc: 0.5787, Val Loss: 0.6824, Val Acc: 0.5768
Epoch 13/100, Loss: 0.6793, Acc: 0.5848, Val Loss: 0.6829, Val Acc: 0.5768
Epoch 14/100, Loss: 0.6792, Acc: 0.5810, Val Loss: 0.6861, Val Acc: 0.5568
Epoch 15/100, Loss: 0.6783, Acc: 0.5865, Val Loss: 0.6839, Val Acc: 0.5576
Epoch 16/100, Loss: 0.6774, Acc: 0.5882, Val Loss: 0.6870, Val Acc: 0.5528
Epoch 17/100, Loss: 0.6773, Acc: 0.5859, Val Loss: 0.6873, Val Acc: 0.5517
Epoch 18/100, Loss: 0.6796, Acc: 0.5777, Val Loss: 0.6878, Val Acc: 0.5498
Epoch 19/100, Loss: 0.6766, Acc: 0.5876, Val Loss: 0.6870, Val Acc: 0.5480
Epoch 20/100, Loss: 0.6755, Acc: 0.5898, Val Loss: 0.6864, Val Acc: 0.5590
Epoch 21/100, Loss: 0.6758, Acc: 0.5855, Val Loss: 0.6887, Val Acc: 0.5428
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6744, Acc: 0.5917, Val Loss: 0.6885, Val Acc: 0.5450
Epoch 23/100, Loss: 0.6741, Acc: 0.5912, Val Loss: 0.6882, Val Acc: 0.5472
Epoch 24/100, Loss: 0.6737, Acc: 0.5923, Val Loss: 0.6891, Val Acc: 0.5450
Epoch 25/100, Loss: 0.6736, Acc: 0.5934, Val Loss: 0.6896, Val Acc: 0.5432
Epoch 26/100, Loss: 0.6733, Acc: 0.5933, Val Loss: 0.6901, Val Acc: 0.5399
Epoch 27/100, Loss: 0.6729, Acc: 0.5932, Val Loss: 0.6897, Val Acc: 0.5424
Epoch 28/100, Loss: 0.6730, Acc: 0.5955, Val Loss: 0.6918, Val Acc: 0.5413
Epoch 29/100, Loss: 0.6724, Acc: 0.5944, Val Loss: 0.6916, Val Acc: 0.5373
Epoch 30/100, Loss: 0.6724, Acc: 0.5936, Val Loss: 0.6932, Val Acc: 0.5365
Epoch 31/100, Loss: 0.6721, Acc: 0.5953, Val Loss: 0.6916, Val Acc: 0.5365
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6718, Acc: 0.5953, Val Loss: 0.6931, Val Acc: 0.5358
Epoch 33/100, Loss: 0.6717, Acc: 0.5948, Val Loss: 0.6921, Val Acc: 0.5358
Epoch 34/100, Loss: 0.6713, Acc: 0.5977, Val Loss: 0.6919, Val Acc: 0.5406
Epoch 35/100, Loss: 0.6714, Acc: 0.5960, Val Loss: 0.6927, Val Acc: 0.5351
Epoch 36/100, Loss: 0.6714, Acc: 0.5972, Val Loss: 0.6945, Val Acc: 0.5310
Epoch 37/100, Loss: 0.6709, Acc: 0.5984, Val Loss: 0.6937, Val Acc: 0.5365
Epoch 38/100, Loss: 0.6713, Acc: 0.5957, Val Loss: 0.6960, Val Acc: 0.5317
Epoch 39/100, Loss: 0.6704, Acc: 0.6003, Val Loss: 0.6932, Val Acc: 0.5347
Epoch 40/100, Loss: 0.6710, Acc: 0.5972, Val Loss: 0.6946, Val Acc: 0.5328
Epoch 41/100, Loss: 0.6709, Acc: 0.5971, Val Loss: 0.6935, Val Acc: 0.5354
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6703, Acc: 0.5984, Val Loss: 0.6932, Val Acc: 0.5373
Epoch 43/100, Loss: 0.6703, Acc: 0.5997, Val Loss: 0.6947, Val Acc: 0.5365
Epoch 44/100, Loss: 0.6703, Acc: 0.5994, Val Loss: 0.6965, Val Acc: 0.5292
Epoch 45/100, Loss: 0.6704, Acc: 0.5978, Val Loss: 0.6955, Val Acc: 0.5314
Epoch 46/100, Loss: 0.6702, Acc: 0.5992, Val Loss: 0.6958, Val Acc: 0.5299
Epoch 47/100, Loss: 0.6704, Acc: 0.5995, Val Loss: 0.6965, Val Acc: 0.5325
Epoch 48/100, Loss: 0.6703, Acc: 0.5973, Val Loss: 0.6948, Val Acc: 0.5321
Epoch 49/100, Loss: 0.6700, Acc: 0.6005, Val Loss: 0.6949, Val Acc: 0.5321
Epoch 50/100, Loss: 0.6702, Acc: 0.5979, Val Loss: 0.6958, Val Acc: 0.5332
Epoch 51/100, Loss: 0.6700, Acc: 0.5987, Val Loss: 0.6963, Val Acc: 0.5292
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6699, Acc: 0.6000, Val Loss: 0.6945, Val Acc: 0.5347
Epoch 53/100, Loss: 0.6698, Acc: 0.5981, Val Loss: 0.6952, Val Acc: 0.5321
Epoch 54/100, Loss: 0.6699, Acc: 0.5975, Val Loss: 0.6957, Val Acc: 0.5321
Epoch 55/100, Loss: 0.6699, Acc: 0.5991, Val Loss: 0.6956, Val Acc: 0.5328
Epoch 56/100, Loss: 0.6697, Acc: 0.5988, Val Loss: 0.6959, Val Acc: 0.5328
Epoch 57/100, Loss: 0.6697, Acc: 0.5994, Val Loss: 0.6964, Val Acc: 0.5328
Epoch 58/100, Loss: 0.6696, Acc: 0.6002, Val Loss: 0.6959, Val Acc: 0.5314
Epoch 59/100, Loss: 0.6698, Acc: 0.5997, Val Loss: 0.6958, Val Acc: 0.5306
Epoch 60/100, Loss: 0.6696, Acc: 0.5991, Val Loss: 0.6960, Val Acc: 0.5314
Epoch 61/100, Loss: 0.6697, Acc: 0.6011, Val Loss: 0.6971, Val Acc: 0.5262
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6696, Acc: 0.6002, Val Loss: 0.6961, Val Acc: 0.5317
Epoch 63/100, Loss: 0.6696, Acc: 0.5993, Val Loss: 0.6959, Val Acc: 0.5310
Epoch 64/100, Loss: 0.6695, Acc: 0.5989, Val Loss: 0.6958, Val Acc: 0.5314
Epoch 65/100, Loss: 0.6695, Acc: 0.6000, Val Loss: 0.6961, Val Acc: 0.5303
Epoch 66/100, Loss: 0.6695, Acc: 0.5994, Val Loss: 0.6964, Val Acc: 0.5303
Epoch 67/100, Loss: 0.6695, Acc: 0.5989, Val Loss: 0.6962, Val Acc: 0.5299
Epoch 68/100, Loss: 0.6694, Acc: 0.5986, Val Loss: 0.6965, Val Acc: 0.5295
Epoch 69/100, Loss: 0.6694, Acc: 0.5995, Val Loss: 0.6967, Val Acc: 0.5295
Epoch 70/100, Loss: 0.6693, Acc: 0.5994, Val Loss: 0.6968, Val Acc: 0.5303
Epoch 71/100, Loss: 0.6694, Acc: 0.5998, Val Loss: 0.6968, Val Acc: 0.5292
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6693, Acc: 0.5992, Val Loss: 0.6968, Val Acc: 0.5288
Epoch 73/100, Loss: 0.6693, Acc: 0.5994, Val Loss: 0.6970, Val Acc: 0.5310
Epoch 74/100, Loss: 0.6693, Acc: 0.5992, Val Loss: 0.6969, Val Acc: 0.5295
Epoch 75/100, Loss: 0.6693, Acc: 0.6001, Val Loss: 0.6972, Val Acc: 0.5303
Epoch 76/100, Loss: 0.6693, Acc: 0.5994, Val Loss: 0.6968, Val Acc: 0.5295
Epoch 77/100, Loss: 0.6692, Acc: 0.5994, Val Loss: 0.6969, Val Acc: 0.5295
Epoch 78/100, Loss: 0.6693, Acc: 0.5986, Val Loss: 0.6969, Val Acc: 0.5288
Epoch 79/100, Loss: 0.6693, Acc: 0.5994, Val Loss: 0.6969, Val Acc: 0.5292
Epoch 80/100, Loss: 0.6692, Acc: 0.5990, Val Loss: 0.6971, Val Acc: 0.5295
Epoch 81/100, Loss: 0.6692, Acc: 0.5994, Val Loss: 0.6971, Val Acc: 0.5273
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6692, Acc: 0.6003, Val Loss: 0.6969, Val Acc: 0.5292
Epoch 83/100, Loss: 0.6692, Acc: 0.5996, Val Loss: 0.6971, Val Acc: 0.5284
Epoch 84/100, Loss: 0.6692, Acc: 0.5989, Val Loss: 0.6972, Val Acc: 0.5288
Epoch 85/100, Loss: 0.6692, Acc: 0.5998, Val Loss: 0.6971, Val Acc: 0.5273
Epoch 86/100, Loss: 0.6691, Acc: 0.5994, Val Loss: 0.6974, Val Acc: 0.5299
Epoch 87/100, Loss: 0.6691, Acc: 0.5999, Val Loss: 0.6971, Val Acc: 0.5277
Epoch 88/100, Loss: 0.6691, Acc: 0.5989, Val Loss: 0.6970, Val Acc: 0.5288
Epoch 89/100, Loss: 0.6691, Acc: 0.5998, Val Loss: 0.6971, Val Acc: 0.5284
Epoch 90/100, Loss: 0.6691, Acc: 0.5997, Val Loss: 0.6972, Val Acc: 0.5269
Epoch 91/100, Loss: 0.6691, Acc: 0.5997, Val Loss: 0.6973, Val Acc: 0.5299
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6691, Acc: 0.5992, Val Loss: 0.6973, Val Acc: 0.5280
Epoch 93/100, Loss: 0.6691, Acc: 0.5992, Val Loss: 0.6972, Val Acc: 0.5277
Epoch 94/100, Loss: 0.6691, Acc: 0.5999, Val Loss: 0.6969, Val Acc: 0.5284
Epoch 95/100, Loss: 0.6690, Acc: 0.5995, Val Loss: 0.6969, Val Acc: 0.5280
Epoch 96/100, Loss: 0.6690, Acc: 0.5997, Val Loss: 0.6969, Val Acc: 0.5288
Epoch 97/100, Loss: 0.6690, Acc: 0.5996, Val Loss: 0.6970, Val Acc: 0.5284
Epoch 98/100, Loss: 0.6690, Acc: 0.5994, Val Loss: 0.6969, Val Acc: 0.5288
Epoch 99/100, Loss: 0.6690, Acc: 0.5998, Val Loss: 0.6971, Val Acc: 0.5277
Epoch 100/100, Loss: 0.6690, Acc: 0.6002, Val Loss: 0.6971, Val Acc: 0.5277

##############################
Resultados para principal:  096  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11 
 {'training': [0.6689505702876781, 0.6001839926402944, 0.583154341822645, 0.7, 0.6362571141613659], 'validate': [0.6970909404200177, 0.5276752767527675, 0.5248933143669986, 0.5466666666666666, 0.5355587808417998], 'test': [0.6798744415337185, 0.5985250737463127, 0.6031347962382445, 0.5692307692307692, 0.5856925418569254]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  034  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  034  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  034  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6870, Acc: 0.5609, Val Loss: 0.7079, Val Acc: 0.3985
Mejor modelo guardado con Val Loss: 0.7079
Epoch 2/100, Loss: 0.6836, Acc: 0.5683, Val Loss: 0.7172, Val Acc: 0.3731
Epoch 3/100, Loss: 0.6815, Acc: 0.5795, Val Loss: 0.7136, Val Acc: 0.3937
Epoch 4/100, Loss: 0.6891, Acc: 0.5407, Val Loss: 0.6931, Val Acc: 0.5018
Mejor modelo guardado con Val Loss: 0.6931
Epoch 5/100, Loss: 0.6933, Acc: 0.5024, Val Loss: 0.6948, Val Acc: 0.4982
Epoch 6/100, Loss: 0.6932, Acc: 0.5067, Val Loss: 0.6932, Val Acc: 0.4985
Epoch 7/100, Loss: 0.6928, Acc: 0.5085, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 8/100, Loss: 0.6899, Acc: 0.5267, Val Loss: 0.7116, Val Acc: 0.4417
Epoch 9/100, Loss: 0.6843, Acc: 0.5654, Val Loss: 0.7263, Val Acc: 0.3572
Epoch 10/100, Loss: 0.6816, Acc: 0.5714, Val Loss: 0.7324, Val Acc: 0.3782
Epoch 11/100, Loss: 0.6796, Acc: 0.5796, Val Loss: 0.7415, Val Acc: 0.3454
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6769, Acc: 0.5871, Val Loss: 0.7428, Val Acc: 0.3524
Epoch 13/100, Loss: 0.6700, Acc: 0.5926, Val Loss: 0.7381, Val Acc: 0.4450
Epoch 14/100, Loss: 0.6709, Acc: 0.5852, Val Loss: 0.7722, Val Acc: 0.3476
Epoch 15/100, Loss: 0.6660, Acc: 0.5978, Val Loss: 0.7849, Val Acc: 0.3247
Epoch 16/100, Loss: 0.6636, Acc: 0.5999, Val Loss: 0.7951, Val Acc: 0.3354
Epoch 17/100, Loss: 0.6637, Acc: 0.5976, Val Loss: 0.7979, Val Acc: 0.3262
Epoch 18/100, Loss: 0.6617, Acc: 0.6037, Val Loss: 0.8077, Val Acc: 0.3310
Epoch 19/100, Loss: 0.6578, Acc: 0.6121, Val Loss: 0.7881, Val Acc: 0.3649
Epoch 20/100, Loss: 0.6567, Acc: 0.6115, Val Loss: 0.8056, Val Acc: 0.3465
Epoch 21/100, Loss: 0.6576, Acc: 0.6141, Val Loss: 0.8277, Val Acc: 0.3173
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6540, Acc: 0.6190, Val Loss: 0.8144, Val Acc: 0.3406
Epoch 23/100, Loss: 0.6541, Acc: 0.6171, Val Loss: 0.8263, Val Acc: 0.3022
Epoch 24/100, Loss: 0.6511, Acc: 0.6251, Val Loss: 0.8068, Val Acc: 0.3476
Epoch 25/100, Loss: 0.6522, Acc: 0.6238, Val Loss: 0.8209, Val Acc: 0.3166
Epoch 26/100, Loss: 0.6510, Acc: 0.6193, Val Loss: 0.8229, Val Acc: 0.3177
Epoch 27/100, Loss: 0.6497, Acc: 0.6282, Val Loss: 0.8166, Val Acc: 0.3022
Epoch 28/100, Loss: 0.6497, Acc: 0.6251, Val Loss: 0.8425, Val Acc: 0.2970
Epoch 29/100, Loss: 0.6485, Acc: 0.6312, Val Loss: 0.8473, Val Acc: 0.3063
Epoch 30/100, Loss: 0.6471, Acc: 0.6305, Val Loss: 0.8248, Val Acc: 0.3137
Epoch 31/100, Loss: 0.6475, Acc: 0.6318, Val Loss: 0.8256, Val Acc: 0.3181
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6454, Acc: 0.6350, Val Loss: 0.8440, Val Acc: 0.2948
Epoch 33/100, Loss: 0.6454, Acc: 0.6326, Val Loss: 0.8306, Val Acc: 0.2956
Epoch 34/100, Loss: 0.6453, Acc: 0.6344, Val Loss: 0.8507, Val Acc: 0.2956
Epoch 35/100, Loss: 0.6450, Acc: 0.6309, Val Loss: 0.8386, Val Acc: 0.2959
Epoch 36/100, Loss: 0.6450, Acc: 0.6351, Val Loss: 0.8447, Val Acc: 0.3059
Epoch 37/100, Loss: 0.6446, Acc: 0.6340, Val Loss: 0.8415, Val Acc: 0.2952
Epoch 38/100, Loss: 0.6441, Acc: 0.6374, Val Loss: 0.8523, Val Acc: 0.3070
Epoch 39/100, Loss: 0.6441, Acc: 0.6335, Val Loss: 0.8513, Val Acc: 0.2934
Epoch 40/100, Loss: 0.6435, Acc: 0.6362, Val Loss: 0.8439, Val Acc: 0.2926
Epoch 41/100, Loss: 0.6432, Acc: 0.6378, Val Loss: 0.8576, Val Acc: 0.3000
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6421, Acc: 0.6378, Val Loss: 0.8480, Val Acc: 0.2970
Epoch 43/100, Loss: 0.6420, Acc: 0.6386, Val Loss: 0.8504, Val Acc: 0.2989
Epoch 44/100, Loss: 0.6424, Acc: 0.6373, Val Loss: 0.8542, Val Acc: 0.2978
Epoch 45/100, Loss: 0.6417, Acc: 0.6389, Val Loss: 0.8614, Val Acc: 0.3007
Epoch 46/100, Loss: 0.6417, Acc: 0.6376, Val Loss: 0.8586, Val Acc: 0.2945
Epoch 47/100, Loss: 0.6418, Acc: 0.6377, Val Loss: 0.8618, Val Acc: 0.3018
Epoch 48/100, Loss: 0.6414, Acc: 0.6399, Val Loss: 0.8558, Val Acc: 0.2996
Epoch 49/100, Loss: 0.6412, Acc: 0.6387, Val Loss: 0.8661, Val Acc: 0.2989
Epoch 50/100, Loss: 0.6411, Acc: 0.6397, Val Loss: 0.8578, Val Acc: 0.2963
Epoch 51/100, Loss: 0.6412, Acc: 0.6397, Val Loss: 0.8611, Val Acc: 0.2963
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6404, Acc: 0.6391, Val Loss: 0.8535, Val Acc: 0.2952
Epoch 53/100, Loss: 0.6407, Acc: 0.6404, Val Loss: 0.8582, Val Acc: 0.2956
Epoch 54/100, Loss: 0.6405, Acc: 0.6397, Val Loss: 0.8537, Val Acc: 0.2952
Epoch 55/100, Loss: 0.6404, Acc: 0.6402, Val Loss: 0.8584, Val Acc: 0.2945
Epoch 56/100, Loss: 0.6403, Acc: 0.6417, Val Loss: 0.8628, Val Acc: 0.2978
Epoch 57/100, Loss: 0.6405, Acc: 0.6418, Val Loss: 0.8596, Val Acc: 0.2956
Epoch 58/100, Loss: 0.6403, Acc: 0.6406, Val Loss: 0.8596, Val Acc: 0.2956
Epoch 59/100, Loss: 0.6398, Acc: 0.6398, Val Loss: 0.8576, Val Acc: 0.2963
Epoch 60/100, Loss: 0.6400, Acc: 0.6432, Val Loss: 0.8613, Val Acc: 0.2967
Epoch 61/100, Loss: 0.6399, Acc: 0.6395, Val Loss: 0.8585, Val Acc: 0.2978
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6398, Acc: 0.6444, Val Loss: 0.8608, Val Acc: 0.2982
Epoch 63/100, Loss: 0.6397, Acc: 0.6397, Val Loss: 0.8590, Val Acc: 0.2963
Epoch 64/100, Loss: 0.6397, Acc: 0.6437, Val Loss: 0.8618, Val Acc: 0.2963
Epoch 65/100, Loss: 0.6396, Acc: 0.6418, Val Loss: 0.8603, Val Acc: 0.2963
Epoch 66/100, Loss: 0.6396, Acc: 0.6439, Val Loss: 0.8618, Val Acc: 0.2989
Epoch 67/100, Loss: 0.6396, Acc: 0.6443, Val Loss: 0.8609, Val Acc: 0.2959
Epoch 68/100, Loss: 0.6396, Acc: 0.6428, Val Loss: 0.8620, Val Acc: 0.2963
Epoch 69/100, Loss: 0.6395, Acc: 0.6423, Val Loss: 0.8605, Val Acc: 0.2963
Epoch 70/100, Loss: 0.6395, Acc: 0.6447, Val Loss: 0.8631, Val Acc: 0.2982
Epoch 71/100, Loss: 0.6395, Acc: 0.6443, Val Loss: 0.8622, Val Acc: 0.2974
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6393, Acc: 0.6432, Val Loss: 0.8631, Val Acc: 0.2978
Epoch 73/100, Loss: 0.6394, Acc: 0.6434, Val Loss: 0.8629, Val Acc: 0.2996
Epoch 74/100, Loss: 0.6394, Acc: 0.6432, Val Loss: 0.8625, Val Acc: 0.2985
Epoch 75/100, Loss: 0.6393, Acc: 0.6432, Val Loss: 0.8627, Val Acc: 0.2985
Epoch 76/100, Loss: 0.6393, Acc: 0.6441, Val Loss: 0.8612, Val Acc: 0.2959
Epoch 77/100, Loss: 0.6393, Acc: 0.6437, Val Loss: 0.8621, Val Acc: 0.2959
Epoch 78/100, Loss: 0.6393, Acc: 0.6433, Val Loss: 0.8618, Val Acc: 0.2967
Epoch 79/100, Loss: 0.6392, Acc: 0.6440, Val Loss: 0.8624, Val Acc: 0.2959
Epoch 80/100, Loss: 0.6391, Acc: 0.6446, Val Loss: 0.8641, Val Acc: 0.2985
Epoch 81/100, Loss: 0.6392, Acc: 0.6445, Val Loss: 0.8629, Val Acc: 0.2963
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6391, Acc: 0.6433, Val Loss: 0.8635, Val Acc: 0.2967
Epoch 83/100, Loss: 0.6391, Acc: 0.6441, Val Loss: 0.8631, Val Acc: 0.2967
Epoch 84/100, Loss: 0.6391, Acc: 0.6437, Val Loss: 0.8636, Val Acc: 0.2982
Epoch 85/100, Loss: 0.6391, Acc: 0.6446, Val Loss: 0.8645, Val Acc: 0.2996
Epoch 86/100, Loss: 0.6391, Acc: 0.6447, Val Loss: 0.8633, Val Acc: 0.2970
Epoch 87/100, Loss: 0.6390, Acc: 0.6440, Val Loss: 0.8646, Val Acc: 0.2996
Epoch 88/100, Loss: 0.6391, Acc: 0.6436, Val Loss: 0.8641, Val Acc: 0.2978
Epoch 89/100, Loss: 0.6389, Acc: 0.6449, Val Loss: 0.8632, Val Acc: 0.2963
Epoch 90/100, Loss: 0.6388, Acc: 0.6433, Val Loss: 0.8651, Val Acc: 0.2989
Epoch 91/100, Loss: 0.6388, Acc: 0.6448, Val Loss: 0.8647, Val Acc: 0.2967
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6388, Acc: 0.6440, Val Loss: 0.8652, Val Acc: 0.2963
Epoch 93/100, Loss: 0.6387, Acc: 0.6436, Val Loss: 0.8646, Val Acc: 0.2963
Epoch 94/100, Loss: 0.6387, Acc: 0.6442, Val Loss: 0.8661, Val Acc: 0.2963
Epoch 95/100, Loss: 0.6387, Acc: 0.6461, Val Loss: 0.8653, Val Acc: 0.2959
Epoch 96/100, Loss: 0.6386, Acc: 0.6448, Val Loss: 0.8652, Val Acc: 0.2959
Epoch 97/100, Loss: 0.6386, Acc: 0.6449, Val Loss: 0.8657, Val Acc: 0.2963
Epoch 98/100, Loss: 0.6386, Acc: 0.6450, Val Loss: 0.8645, Val Acc: 0.2967
Epoch 99/100, Loss: 0.6385, Acc: 0.6448, Val Loss: 0.8656, Val Acc: 0.2974
Epoch 100/100, Loss: 0.6385, Acc: 0.6447, Val Loss: 0.8635, Val Acc: 0.2967

##############################
Resultados para principal:  034  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11 
 {'training': [0.6385364850947038, 0.6447102115915363, 0.6420289855072464, 0.652670349907919, 0.6473059360730593], 'validate': [0.8634626061417335, 0.2966789667896679, 0.32965686274509803, 0.3985185185185185, 0.3608316566063045], 'test': [0.6931110867914164, 0.5014749262536873, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  014  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  014  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  014  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6758, Acc: 0.6080, Val Loss: 0.6798, Val Acc: 0.5601
Mejor modelo guardado con Val Loss: 0.6798
Epoch 2/100, Loss: 0.6658, Acc: 0.6169, Val Loss: 0.6908, Val Acc: 0.5118
Epoch 3/100, Loss: 0.6651, Acc: 0.6276, Val Loss: 0.6811, Val Acc: 0.5613
Epoch 4/100, Loss: 0.6487, Acc: 0.6610, Val Loss: 0.6879, Val Acc: 0.5225
Epoch 5/100, Loss: 0.6399, Acc: 0.6617, Val Loss: 0.6798, Val Acc: 0.5568
Mejor modelo guardado con Val Loss: 0.6798
Epoch 6/100, Loss: 0.6291, Acc: 0.6724, Val Loss: 0.6812, Val Acc: 0.5649
Epoch 7/100, Loss: 0.6201, Acc: 0.6743, Val Loss: 0.6765, Val Acc: 0.5701
Mejor modelo guardado con Val Loss: 0.6765
Epoch 8/100, Loss: 0.6147, Acc: 0.6746, Val Loss: 0.6870, Val Acc: 0.5613
Epoch 9/100, Loss: 0.6089, Acc: 0.6774, Val Loss: 0.7037, Val Acc: 0.5439
Epoch 10/100, Loss: 0.6050, Acc: 0.6821, Val Loss: 0.6972, Val Acc: 0.5579
Epoch 11/100, Loss: 0.6035, Acc: 0.6845, Val Loss: 0.6988, Val Acc: 0.5561
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5938, Acc: 0.6913, Val Loss: 0.7019, Val Acc: 0.5572
Epoch 13/100, Loss: 0.5950, Acc: 0.6907, Val Loss: 0.6974, Val Acc: 0.5535
Epoch 14/100, Loss: 0.5932, Acc: 0.6889, Val Loss: 0.6965, Val Acc: 0.5590
Epoch 15/100, Loss: 0.5893, Acc: 0.6925, Val Loss: 0.7039, Val Acc: 0.5513
Epoch 16/100, Loss: 0.5906, Acc: 0.6927, Val Loss: 0.7116, Val Acc: 0.5568
Epoch 17/100, Loss: 0.5901, Acc: 0.6950, Val Loss: 0.7002, Val Acc: 0.5624
Epoch 18/100, Loss: 0.5884, Acc: 0.6931, Val Loss: 0.7070, Val Acc: 0.5542
Epoch 19/100, Loss: 0.5922, Acc: 0.6863, Val Loss: 0.7015, Val Acc: 0.5502
Epoch 20/100, Loss: 0.5881, Acc: 0.6915, Val Loss: 0.7113, Val Acc: 0.5502
Epoch 21/100, Loss: 0.5913, Acc: 0.6876, Val Loss: 0.6959, Val Acc: 0.5421
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5840, Acc: 0.7004, Val Loss: 0.7083, Val Acc: 0.5561
Epoch 23/100, Loss: 0.5831, Acc: 0.6972, Val Loss: 0.7106, Val Acc: 0.5568
Epoch 24/100, Loss: 0.5813, Acc: 0.7017, Val Loss: 0.7087, Val Acc: 0.5579
Epoch 25/100, Loss: 0.5821, Acc: 0.7002, Val Loss: 0.7174, Val Acc: 0.5465
Epoch 26/100, Loss: 0.5825, Acc: 0.6988, Val Loss: 0.7014, Val Acc: 0.5554
Epoch 27/100, Loss: 0.5821, Acc: 0.6973, Val Loss: 0.7125, Val Acc: 0.5609
Epoch 28/100, Loss: 0.5808, Acc: 0.6987, Val Loss: 0.7182, Val Acc: 0.5590
Epoch 29/100, Loss: 0.5809, Acc: 0.7020, Val Loss: 0.7143, Val Acc: 0.5587
Epoch 30/100, Loss: 0.5813, Acc: 0.6997, Val Loss: 0.7066, Val Acc: 0.5524
Epoch 31/100, Loss: 0.5806, Acc: 0.6984, Val Loss: 0.7148, Val Acc: 0.5561
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5790, Acc: 0.6992, Val Loss: 0.7156, Val Acc: 0.5524
Epoch 33/100, Loss: 0.5775, Acc: 0.7021, Val Loss: 0.7124, Val Acc: 0.5557
Epoch 34/100, Loss: 0.5771, Acc: 0.7028, Val Loss: 0.7132, Val Acc: 0.5616
Epoch 35/100, Loss: 0.5771, Acc: 0.7022, Val Loss: 0.7137, Val Acc: 0.5502
Epoch 36/100, Loss: 0.5781, Acc: 0.7028, Val Loss: 0.7138, Val Acc: 0.5557
Epoch 37/100, Loss: 0.5765, Acc: 0.7040, Val Loss: 0.7135, Val Acc: 0.5583
Epoch 38/100, Loss: 0.5774, Acc: 0.7022, Val Loss: 0.7209, Val Acc: 0.5458
Epoch 39/100, Loss: 0.5771, Acc: 0.6997, Val Loss: 0.7149, Val Acc: 0.5565
Epoch 40/100, Loss: 0.5775, Acc: 0.7030, Val Loss: 0.7147, Val Acc: 0.5565
Epoch 41/100, Loss: 0.5769, Acc: 0.7027, Val Loss: 0.7153, Val Acc: 0.5539
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5757, Acc: 0.7029, Val Loss: 0.7163, Val Acc: 0.5554
Epoch 43/100, Loss: 0.5751, Acc: 0.7051, Val Loss: 0.7138, Val Acc: 0.5594
Epoch 44/100, Loss: 0.5753, Acc: 0.7033, Val Loss: 0.7140, Val Acc: 0.5557
Epoch 45/100, Loss: 0.5753, Acc: 0.7025, Val Loss: 0.7111, Val Acc: 0.5568
Epoch 46/100, Loss: 0.5756, Acc: 0.7037, Val Loss: 0.7123, Val Acc: 0.5572
Epoch 47/100, Loss: 0.5754, Acc: 0.7050, Val Loss: 0.7129, Val Acc: 0.5590
Epoch 48/100, Loss: 0.5745, Acc: 0.7052, Val Loss: 0.7135, Val Acc: 0.5601
Epoch 49/100, Loss: 0.5745, Acc: 0.7049, Val Loss: 0.7149, Val Acc: 0.5528
Epoch 50/100, Loss: 0.5744, Acc: 0.7030, Val Loss: 0.7202, Val Acc: 0.5483
Epoch 51/100, Loss: 0.5743, Acc: 0.7046, Val Loss: 0.7170, Val Acc: 0.5557
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5747, Acc: 0.7012, Val Loss: 0.7180, Val Acc: 0.5531
Epoch 53/100, Loss: 0.5741, Acc: 0.7063, Val Loss: 0.7166, Val Acc: 0.5590
Epoch 54/100, Loss: 0.5729, Acc: 0.7037, Val Loss: 0.7222, Val Acc: 0.5557
Epoch 55/100, Loss: 0.5712, Acc: 0.7059, Val Loss: 0.7185, Val Acc: 0.5572
Epoch 56/100, Loss: 0.5709, Acc: 0.7074, Val Loss: 0.7207, Val Acc: 0.5550
Epoch 57/100, Loss: 0.5714, Acc: 0.7057, Val Loss: 0.7210, Val Acc: 0.5554
Epoch 58/100, Loss: 0.5711, Acc: 0.7063, Val Loss: 0.7185, Val Acc: 0.5557
Epoch 59/100, Loss: 0.5706, Acc: 0.7052, Val Loss: 0.7176, Val Acc: 0.5520
Epoch 60/100, Loss: 0.5707, Acc: 0.7059, Val Loss: 0.7174, Val Acc: 0.5554
Epoch 61/100, Loss: 0.5706, Acc: 0.7049, Val Loss: 0.7192, Val Acc: 0.5557
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5703, Acc: 0.7068, Val Loss: 0.7175, Val Acc: 0.5565
Epoch 63/100, Loss: 0.5703, Acc: 0.7058, Val Loss: 0.7186, Val Acc: 0.5546
Epoch 64/100, Loss: 0.5702, Acc: 0.7063, Val Loss: 0.7178, Val Acc: 0.5554
Epoch 65/100, Loss: 0.5702, Acc: 0.7065, Val Loss: 0.7169, Val Acc: 0.5561
Epoch 66/100, Loss: 0.5701, Acc: 0.7062, Val Loss: 0.7164, Val Acc: 0.5565
Epoch 67/100, Loss: 0.5699, Acc: 0.7061, Val Loss: 0.7206, Val Acc: 0.5542
Epoch 68/100, Loss: 0.5700, Acc: 0.7066, Val Loss: 0.7183, Val Acc: 0.5561
Epoch 69/100, Loss: 0.5700, Acc: 0.7064, Val Loss: 0.7171, Val Acc: 0.5565
Epoch 70/100, Loss: 0.5701, Acc: 0.7061, Val Loss: 0.7169, Val Acc: 0.5561
Epoch 71/100, Loss: 0.5697, Acc: 0.7056, Val Loss: 0.7166, Val Acc: 0.5557
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5699, Acc: 0.7065, Val Loss: 0.7167, Val Acc: 0.5568
Epoch 73/100, Loss: 0.5697, Acc: 0.7072, Val Loss: 0.7177, Val Acc: 0.5565
Epoch 74/100, Loss: 0.5697, Acc: 0.7066, Val Loss: 0.7177, Val Acc: 0.5550
Epoch 75/100, Loss: 0.5696, Acc: 0.7074, Val Loss: 0.7185, Val Acc: 0.5550
Epoch 76/100, Loss: 0.5697, Acc: 0.7072, Val Loss: 0.7170, Val Acc: 0.5561
Epoch 77/100, Loss: 0.5697, Acc: 0.7063, Val Loss: 0.7175, Val Acc: 0.5550
Epoch 78/100, Loss: 0.5696, Acc: 0.7065, Val Loss: 0.7181, Val Acc: 0.5565
Epoch 79/100, Loss: 0.5696, Acc: 0.7072, Val Loss: 0.7163, Val Acc: 0.5557
Epoch 80/100, Loss: 0.5696, Acc: 0.7075, Val Loss: 0.7163, Val Acc: 0.5561
Epoch 81/100, Loss: 0.5696, Acc: 0.7072, Val Loss: 0.7173, Val Acc: 0.5554
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5696, Acc: 0.7071, Val Loss: 0.7170, Val Acc: 0.5561
Epoch 83/100, Loss: 0.5695, Acc: 0.7071, Val Loss: 0.7166, Val Acc: 0.5583
Epoch 84/100, Loss: 0.5696, Acc: 0.7052, Val Loss: 0.7173, Val Acc: 0.5554
Epoch 85/100, Loss: 0.5695, Acc: 0.7058, Val Loss: 0.7176, Val Acc: 0.5561
Epoch 86/100, Loss: 0.5694, Acc: 0.7063, Val Loss: 0.7186, Val Acc: 0.5561
Epoch 87/100, Loss: 0.5695, Acc: 0.7070, Val Loss: 0.7188, Val Acc: 0.5561
Epoch 88/100, Loss: 0.5694, Acc: 0.7066, Val Loss: 0.7183, Val Acc: 0.5565
Epoch 89/100, Loss: 0.5694, Acc: 0.7066, Val Loss: 0.7170, Val Acc: 0.5554
Epoch 90/100, Loss: 0.5694, Acc: 0.7058, Val Loss: 0.7175, Val Acc: 0.5561
Epoch 91/100, Loss: 0.5693, Acc: 0.7067, Val Loss: 0.7177, Val Acc: 0.5542
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5693, Acc: 0.7074, Val Loss: 0.7172, Val Acc: 0.5554
Epoch 93/100, Loss: 0.5692, Acc: 0.7068, Val Loss: 0.7182, Val Acc: 0.5561
Epoch 94/100, Loss: 0.5693, Acc: 0.7064, Val Loss: 0.7166, Val Acc: 0.5579
Epoch 95/100, Loss: 0.5693, Acc: 0.7066, Val Loss: 0.7180, Val Acc: 0.5557
Epoch 96/100, Loss: 0.5691, Acc: 0.7063, Val Loss: 0.7187, Val Acc: 0.5557
Epoch 97/100, Loss: 0.5692, Acc: 0.7063, Val Loss: 0.7166, Val Acc: 0.5565
Epoch 98/100, Loss: 0.5691, Acc: 0.7063, Val Loss: 0.7182, Val Acc: 0.5568
Epoch 99/100, Loss: 0.5692, Acc: 0.7068, Val Loss: 0.7165, Val Acc: 0.5565
Epoch 100/100, Loss: 0.5691, Acc: 0.7070, Val Loss: 0.7183, Val Acc: 0.5550

##############################
Resultados para principal:  014  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11 
 {'training': [0.5691354141941615, 0.7069917203311867, 0.7491675915649278, 0.6215469613259669, 0.6794162053346754], 'validate': [0.7183377243751703, 0.5549815498154982, 0.6046511627906976, 0.30814814814814817, 0.408243375858685], 'test': [0.7012668994237792, 0.5386430678466076, 0.5252808988764045, 0.7745562130177515, 0.6260162601626016]}

######################################## 
########################################
Grupo en indetificación:  ['031', '051', '096', '034', '014', '092']  --- principal:  092  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  092  --- group:  ['031', '051', '096', '034', '014', '092']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  092  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6908, Acc: 0.5237, Val Loss: 0.6922, Val Acc: 0.5070
Mejor modelo guardado con Val Loss: 0.6922
Epoch 2/100, Loss: 0.6915, Acc: 0.5286, Val Loss: 0.6947, Val Acc: 0.4963
Epoch 3/100, Loss: 0.6931, Acc: 0.5045, Val Loss: 0.6867, Val Acc: 0.6004
Mejor modelo guardado con Val Loss: 0.6867
Epoch 4/100, Loss: 0.6918, Acc: 0.5271, Val Loss: 0.6931, Val Acc: 0.5018
Epoch 5/100, Loss: 0.6932, Acc: 0.5048, Val Loss: 0.6935, Val Acc: 0.5018
Epoch 6/100, Loss: 0.6940, Acc: 0.4981, Val Loss: 0.6933, Val Acc: 0.4982
Epoch 7/100, Loss: 0.6935, Acc: 0.4966, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 8/100, Loss: 0.6934, Acc: 0.4990, Val Loss: 0.6935, Val Acc: 0.4982
Epoch 9/100, Loss: 0.6933, Acc: 0.5071, Val Loss: 0.6932, Val Acc: 0.5018
Epoch 10/100, Loss: 0.6933, Acc: 0.5004, Val Loss: 0.6930, Val Acc: 0.5018
Epoch 11/100, Loss: 0.6935, Acc: 0.5001, Val Loss: 0.6931, Val Acc: 0.5018
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4994, Val Loss: 0.6935, Val Acc: 0.4937
Epoch 13/100, Loss: 0.6934, Acc: 0.4995, Val Loss: 0.6937, Val Acc: 0.4893
Epoch 14/100, Loss: 0.6905, Acc: 0.5336, Val Loss: 0.6795, Val Acc: 0.6413
Mejor modelo guardado con Val Loss: 0.6795
Epoch 15/100, Loss: 0.6826, Acc: 0.6010, Val Loss: 0.6750, Val Acc: 0.6395
Mejor modelo guardado con Val Loss: 0.6750
Epoch 16/100, Loss: 0.6779, Acc: 0.6075, Val Loss: 0.6654, Val Acc: 0.6631
Mejor modelo guardado con Val Loss: 0.6654
Epoch 17/100, Loss: 0.6734, Acc: 0.6145, Val Loss: 0.6651, Val Acc: 0.6480
Mejor modelo guardado con Val Loss: 0.6651
Epoch 18/100, Loss: 0.6694, Acc: 0.6240, Val Loss: 0.6597, Val Acc: 0.6557
Mejor modelo guardado con Val Loss: 0.6597
Epoch 19/100, Loss: 0.6650, Acc: 0.6368, Val Loss: 0.6559, Val Acc: 0.6520
Mejor modelo guardado con Val Loss: 0.6559
Epoch 20/100, Loss: 0.6619, Acc: 0.6340, Val Loss: 0.6630, Val Acc: 0.6199
Epoch 21/100, Loss: 0.6572, Acc: 0.6413, Val Loss: 0.6855, Val Acc: 0.5469
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6559, Acc: 0.6428, Val Loss: 0.6579, Val Acc: 0.6255
Epoch 23/100, Loss: 0.6520, Acc: 0.6514, Val Loss: 0.6540, Val Acc: 0.6339
Mejor modelo guardado con Val Loss: 0.6540
Epoch 24/100, Loss: 0.6487, Acc: 0.6536, Val Loss: 0.6542, Val Acc: 0.6266
Epoch 25/100, Loss: 0.6471, Acc: 0.6573, Val Loss: 0.6450, Val Acc: 0.6550
Mejor modelo guardado con Val Loss: 0.6450
Epoch 26/100, Loss: 0.6450, Acc: 0.6536, Val Loss: 0.6396, Val Acc: 0.6528
Mejor modelo guardado con Val Loss: 0.6396
Epoch 27/100, Loss: 0.6409, Acc: 0.6563, Val Loss: 0.6453, Val Acc: 0.6395
Epoch 28/100, Loss: 0.6387, Acc: 0.6587, Val Loss: 0.6561, Val Acc: 0.6199
Epoch 29/100, Loss: 0.6355, Acc: 0.6632, Val Loss: 0.6320, Val Acc: 0.6712
Mejor modelo guardado con Val Loss: 0.6320
Epoch 30/100, Loss: 0.6333, Acc: 0.6604, Val Loss: 0.6683, Val Acc: 0.5923
Epoch 31/100, Loss: 0.6317, Acc: 0.6630, Val Loss: 0.6444, Val Acc: 0.6328
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6278, Acc: 0.6663, Val Loss: 0.6505, Val Acc: 0.6207
Epoch 33/100, Loss: 0.6269, Acc: 0.6650, Val Loss: 0.6562, Val Acc: 0.6085
Epoch 34/100, Loss: 0.6255, Acc: 0.6658, Val Loss: 0.6311, Val Acc: 0.6624
Mejor modelo guardado con Val Loss: 0.6311
Epoch 35/100, Loss: 0.6246, Acc: 0.6688, Val Loss: 0.6394, Val Acc: 0.6354
Epoch 36/100, Loss: 0.6240, Acc: 0.6697, Val Loss: 0.6401, Val Acc: 0.6406
Epoch 37/100, Loss: 0.6226, Acc: 0.6715, Val Loss: 0.6403, Val Acc: 0.6336
Epoch 38/100, Loss: 0.6220, Acc: 0.6702, Val Loss: 0.6445, Val Acc: 0.6251
Epoch 39/100, Loss: 0.6206, Acc: 0.6696, Val Loss: 0.6457, Val Acc: 0.6221
Epoch 40/100, Loss: 0.6195, Acc: 0.6708, Val Loss: 0.6426, Val Acc: 0.6280
Epoch 41/100, Loss: 0.6185, Acc: 0.6699, Val Loss: 0.6417, Val Acc: 0.6321
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6178, Acc: 0.6707, Val Loss: 0.6516, Val Acc: 0.6159
Epoch 43/100, Loss: 0.6168, Acc: 0.6735, Val Loss: 0.6400, Val Acc: 0.6303
Epoch 44/100, Loss: 0.6164, Acc: 0.6721, Val Loss: 0.6355, Val Acc: 0.6465
Epoch 45/100, Loss: 0.6161, Acc: 0.6750, Val Loss: 0.6466, Val Acc: 0.6240
Epoch 46/100, Loss: 0.6152, Acc: 0.6736, Val Loss: 0.6323, Val Acc: 0.6509
Epoch 47/100, Loss: 0.6150, Acc: 0.6717, Val Loss: 0.6518, Val Acc: 0.6155
Epoch 48/100, Loss: 0.6129, Acc: 0.6774, Val Loss: 0.6488, Val Acc: 0.6199
Epoch 49/100, Loss: 0.6123, Acc: 0.6764, Val Loss: 0.6354, Val Acc: 0.6458
Epoch 50/100, Loss: 0.6115, Acc: 0.6761, Val Loss: 0.6528, Val Acc: 0.6155
Epoch 51/100, Loss: 0.6108, Acc: 0.6777, Val Loss: 0.6357, Val Acc: 0.6439
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6098, Acc: 0.6774, Val Loss: 0.6428, Val Acc: 0.6251
Epoch 53/100, Loss: 0.6098, Acc: 0.6794, Val Loss: 0.6498, Val Acc: 0.6188
Epoch 54/100, Loss: 0.6094, Acc: 0.6792, Val Loss: 0.6448, Val Acc: 0.6229
Epoch 55/100, Loss: 0.6089, Acc: 0.6759, Val Loss: 0.6447, Val Acc: 0.6232
Epoch 56/100, Loss: 0.6089, Acc: 0.6774, Val Loss: 0.6487, Val Acc: 0.6203
Epoch 57/100, Loss: 0.6084, Acc: 0.6784, Val Loss: 0.6453, Val Acc: 0.6236
Epoch 58/100, Loss: 0.6083, Acc: 0.6786, Val Loss: 0.6443, Val Acc: 0.6244
Epoch 59/100, Loss: 0.6082, Acc: 0.6781, Val Loss: 0.6469, Val Acc: 0.6225
Epoch 60/100, Loss: 0.6077, Acc: 0.6787, Val Loss: 0.6419, Val Acc: 0.6299
Epoch 61/100, Loss: 0.6072, Acc: 0.6776, Val Loss: 0.6456, Val Acc: 0.6251
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6069, Acc: 0.6800, Val Loss: 0.6452, Val Acc: 0.6236
Epoch 63/100, Loss: 0.6065, Acc: 0.6811, Val Loss: 0.6393, Val Acc: 0.6354
Epoch 64/100, Loss: 0.6068, Acc: 0.6799, Val Loss: 0.6428, Val Acc: 0.6284
Epoch 65/100, Loss: 0.6065, Acc: 0.6803, Val Loss: 0.6428, Val Acc: 0.6288
Epoch 66/100, Loss: 0.6063, Acc: 0.6795, Val Loss: 0.6435, Val Acc: 0.6273
Epoch 67/100, Loss: 0.6063, Acc: 0.6786, Val Loss: 0.6456, Val Acc: 0.6229
Epoch 68/100, Loss: 0.6061, Acc: 0.6803, Val Loss: 0.6392, Val Acc: 0.6343
Epoch 69/100, Loss: 0.6057, Acc: 0.6810, Val Loss: 0.6500, Val Acc: 0.6188
Epoch 70/100, Loss: 0.6057, Acc: 0.6794, Val Loss: 0.6434, Val Acc: 0.6284
Epoch 71/100, Loss: 0.6056, Acc: 0.6817, Val Loss: 0.6438, Val Acc: 0.6262
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6055, Acc: 0.6805, Val Loss: 0.6442, Val Acc: 0.6251
Epoch 73/100, Loss: 0.6054, Acc: 0.6810, Val Loss: 0.6447, Val Acc: 0.6240
Epoch 74/100, Loss: 0.6052, Acc: 0.6814, Val Loss: 0.6410, Val Acc: 0.6321
Epoch 75/100, Loss: 0.6051, Acc: 0.6819, Val Loss: 0.6489, Val Acc: 0.6218
Epoch 76/100, Loss: 0.6052, Acc: 0.6810, Val Loss: 0.6482, Val Acc: 0.6229
Epoch 77/100, Loss: 0.6051, Acc: 0.6810, Val Loss: 0.6454, Val Acc: 0.6229
Epoch 78/100, Loss: 0.6049, Acc: 0.6807, Val Loss: 0.6428, Val Acc: 0.6284
Epoch 79/100, Loss: 0.6049, Acc: 0.6831, Val Loss: 0.6421, Val Acc: 0.6292
Epoch 80/100, Loss: 0.6048, Acc: 0.6819, Val Loss: 0.6475, Val Acc: 0.6229
Epoch 81/100, Loss: 0.6047, Acc: 0.6806, Val Loss: 0.6460, Val Acc: 0.6232
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6040, Acc: 0.6813, Val Loss: 0.6476, Val Acc: 0.6240
Epoch 83/100, Loss: 0.6032, Acc: 0.6804, Val Loss: 0.6420, Val Acc: 0.6269
Epoch 84/100, Loss: 0.6031, Acc: 0.6826, Val Loss: 0.6447, Val Acc: 0.6247
Epoch 85/100, Loss: 0.6029, Acc: 0.6821, Val Loss: 0.6459, Val Acc: 0.6225
Epoch 86/100, Loss: 0.6028, Acc: 0.6816, Val Loss: 0.6426, Val Acc: 0.6269
Epoch 87/100, Loss: 0.6027, Acc: 0.6830, Val Loss: 0.6481, Val Acc: 0.6196
Epoch 88/100, Loss: 0.6028, Acc: 0.6823, Val Loss: 0.6454, Val Acc: 0.6240
Epoch 89/100, Loss: 0.6021, Acc: 0.6828, Val Loss: 0.6418, Val Acc: 0.6277
Epoch 90/100, Loss: 0.6019, Acc: 0.6806, Val Loss: 0.6427, Val Acc: 0.6288
Epoch 91/100, Loss: 0.6017, Acc: 0.6807, Val Loss: 0.6422, Val Acc: 0.6277
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6016, Acc: 0.6810, Val Loss: 0.6403, Val Acc: 0.6306
Epoch 93/100, Loss: 0.6016, Acc: 0.6800, Val Loss: 0.6418, Val Acc: 0.6280
Epoch 94/100, Loss: 0.6014, Acc: 0.6798, Val Loss: 0.6432, Val Acc: 0.6284
Epoch 95/100, Loss: 0.6013, Acc: 0.6821, Val Loss: 0.6397, Val Acc: 0.6310
Epoch 96/100, Loss: 0.6011, Acc: 0.6820, Val Loss: 0.6445, Val Acc: 0.6269
Epoch 97/100, Loss: 0.6011, Acc: 0.6802, Val Loss: 0.6400, Val Acc: 0.6306
Epoch 98/100, Loss: 0.6010, Acc: 0.6809, Val Loss: 0.6403, Val Acc: 0.6303
Epoch 99/100, Loss: 0.6009, Acc: 0.6803, Val Loss: 0.6426, Val Acc: 0.6269
Epoch 100/100, Loss: 0.6008, Acc: 0.6823, Val Loss: 0.6438, Val Acc: 0.6273

##############################
Resultados para principal:  092  --- grupo:  ['031', '051', '096', '034', '014', '092']  --- window & package numer:  11 
 {'training': [0.6008001895157042, 0.6823367065317387, 0.7056376118161015, 0.6246777163904236, 0.66269414867637], 'validate': [0.643795980963596, 0.6273062730627307, 0.7796052631578947, 0.3511111111111111, 0.48416751787538304], 'test': [0.8036756060033474, 0.42035398230088494, 0.4468906913866358, 0.6846153846153846, 0.5407805562047208]}

##############################
Resultados para window:  11 
 {'031:051:096:034:014:092': {'training': [0.5700760268901836, 0.7136154553817847, 0.6996381182147166, 0.7476979742173112, 0.722870114840203], 'validate': [0.8860723778258922, 0.4756457564575646, 0.4826744753538311, 0.7325925925925926, 0.5819358634892615], 'test': [0.6959069045084827, 0.5067846607669616, 0.5060893098782138, 0.44260355029585796, 0.4722222222222222]}, '051:031:096:034:014:092': {'training': [0.3840782343573601, 0.8257589696412143, 0.8351023502653525, 0.8114180478821362, 0.8230898561554268], 'validate': [0.8173064126871353, 0.6476014760147601, 0.6179104477611941, 0.7666666666666667, 0.684297520661157], 'test': [0.5831562831716718, 0.752802359882006, 0.8597972972972973, 0.6023668639053255, 0.708420320111343]}, '096:031:051:034:014:092': {'training': [0.6689505702876781, 0.6001839926402944, 0.583154341822645, 0.7, 0.6362571141613659], 'validate': [0.6970909404200177, 0.5276752767527675, 0.5248933143669986, 0.5466666666666666, 0.5355587808417998], 'test': [0.6798744415337185, 0.5985250737463127, 0.6031347962382445, 0.5692307692307692, 0.5856925418569254]}, '034:031:051:096:014:092': {'training': [0.6385364850947038, 0.6447102115915363, 0.6420289855072464, 0.652670349907919, 0.6473059360730593], 'validate': [0.8634626061417335, 0.2966789667896679, 0.32965686274509803, 0.3985185185185185, 0.3608316566063045], 'test': [0.6931110867914164, 0.5014749262536873, 0.0, 0.0, 0.0]}, '014:031:051:096:034:092': {'training': [0.5691354141941615, 0.7069917203311867, 0.7491675915649278, 0.6215469613259669, 0.6794162053346754], 'validate': [0.7183377243751703, 0.5549815498154982, 0.6046511627906976, 0.30814814814814817, 0.408243375858685], 'test': [0.7012668994237792, 0.5386430678466076, 0.5252808988764045, 0.7745562130177515, 0.6260162601626016]}, '092:031:051:096:034:014': {'training': [0.6008001895157042, 0.6823367065317387, 0.7056376118161015, 0.6246777163904236, 0.66269414867637], 'validate': [0.643795980963596, 0.6273062730627307, 0.7796052631578947, 0.3511111111111111, 0.48416751787538304], 'test': [0.8036756060033474, 0.42035398230088494, 0.4468906913866358, 0.6846153846153846, 0.5407805562047208]}}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  007  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  007  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  007  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.4805, Acc: 0.8463, Val Loss: 0.2647, Val Acc: 0.9513
Mejor modelo guardado con Val Loss: 0.2647
Epoch 2/100, Loss: 0.3333, Acc: 0.8769, Val Loss: 0.2990, Val Acc: 0.8720
Epoch 3/100, Loss: 0.3046, Acc: 0.8791, Val Loss: 0.2212, Val Acc: 0.9236
Mejor modelo guardado con Val Loss: 0.2212
Epoch 4/100, Loss: 0.2843, Acc: 0.8887, Val Loss: 0.1114, Val Acc: 0.9738
Mejor modelo guardado con Val Loss: 0.1114
Epoch 5/100, Loss: 0.2833, Acc: 0.8868, Val Loss: 0.1262, Val Acc: 0.9760
Epoch 6/100, Loss: 0.2746, Acc: 0.8900, Val Loss: 0.1957, Val Acc: 0.9247
Epoch 7/100, Loss: 0.2685, Acc: 0.8930, Val Loss: 0.1418, Val Acc: 0.9480
Epoch 8/100, Loss: 0.2738, Acc: 0.8884, Val Loss: 0.1316, Val Acc: 0.9472
Epoch 9/100, Loss: 0.2567, Acc: 0.8967, Val Loss: 0.0843, Val Acc: 0.9849
Mejor modelo guardado con Val Loss: 0.0843
Epoch 10/100, Loss: 0.2529, Acc: 0.8990, Val Loss: 0.0833, Val Acc: 0.9863
Mejor modelo guardado con Val Loss: 0.0833
Epoch 11/100, Loss: 0.2515, Acc: 0.9022, Val Loss: 0.2427, Val Acc: 0.8978
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.2383, Acc: 0.9092, Val Loss: 0.1288, Val Acc: 0.9524
Epoch 13/100, Loss: 0.2364, Acc: 0.9069, Val Loss: 0.0799, Val Acc: 0.9871
Mejor modelo guardado con Val Loss: 0.0799
Epoch 14/100, Loss: 0.2379, Acc: 0.9076, Val Loss: 0.1809, Val Acc: 0.9185
Epoch 15/100, Loss: 0.2332, Acc: 0.9091, Val Loss: 0.1052, Val Acc: 0.9638
Epoch 16/100, Loss: 0.2308, Acc: 0.9106, Val Loss: 0.1106, Val Acc: 0.9631
Epoch 17/100, Loss: 0.2344, Acc: 0.9068, Val Loss: 0.0998, Val Acc: 0.9701
Epoch 18/100, Loss: 0.2360, Acc: 0.9094, Val Loss: 0.1141, Val Acc: 0.9565
Epoch 19/100, Loss: 0.2432, Acc: 0.9026, Val Loss: 0.1402, Val Acc: 0.9384
Epoch 20/100, Loss: 0.2286, Acc: 0.9093, Val Loss: 0.1116, Val Acc: 0.9590
Epoch 21/100, Loss: 0.2304, Acc: 0.9109, Val Loss: 0.0923, Val Acc: 0.9753
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2229, Acc: 0.9133, Val Loss: 0.1727, Val Acc: 0.9266
Epoch 23/100, Loss: 0.2211, Acc: 0.9145, Val Loss: 0.1059, Val Acc: 0.9598
Epoch 24/100, Loss: 0.2249, Acc: 0.9099, Val Loss: 0.0933, Val Acc: 0.9668
Epoch 25/100, Loss: 0.2197, Acc: 0.9156, Val Loss: 0.1367, Val Acc: 0.9461
Epoch 26/100, Loss: 0.2186, Acc: 0.9151, Val Loss: 0.1184, Val Acc: 0.9557
Epoch 27/100, Loss: 0.2194, Acc: 0.9157, Val Loss: 0.0916, Val Acc: 0.9694
Epoch 28/100, Loss: 0.2167, Acc: 0.9145, Val Loss: 0.0770, Val Acc: 0.9801
Mejor modelo guardado con Val Loss: 0.0770
Epoch 29/100, Loss: 0.2172, Acc: 0.9171, Val Loss: 0.1443, Val Acc: 0.9443
Epoch 30/100, Loss: 0.2155, Acc: 0.9165, Val Loss: 0.1045, Val Acc: 0.9579
Epoch 31/100, Loss: 0.2167, Acc: 0.9159, Val Loss: 0.0972, Val Acc: 0.9635
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2108, Acc: 0.9178, Val Loss: 0.0942, Val Acc: 0.9675
Epoch 33/100, Loss: 0.2129, Acc: 0.9178, Val Loss: 0.1207, Val Acc: 0.9502
Epoch 34/100, Loss: 0.2113, Acc: 0.9190, Val Loss: 0.0939, Val Acc: 0.9697
Epoch 35/100, Loss: 0.2112, Acc: 0.9180, Val Loss: 0.1243, Val Acc: 0.9461
Epoch 36/100, Loss: 0.2127, Acc: 0.9164, Val Loss: 0.0919, Val Acc: 0.9668
Epoch 37/100, Loss: 0.2115, Acc: 0.9185, Val Loss: 0.0824, Val Acc: 0.9745
Epoch 38/100, Loss: 0.2106, Acc: 0.9183, Val Loss: 0.1104, Val Acc: 0.9583
Epoch 39/100, Loss: 0.2109, Acc: 0.9196, Val Loss: 0.1096, Val Acc: 0.9583
Epoch 40/100, Loss: 0.2094, Acc: 0.9184, Val Loss: 0.1077, Val Acc: 0.9605
Epoch 41/100, Loss: 0.2127, Acc: 0.9172, Val Loss: 0.1193, Val Acc: 0.9520
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2076, Acc: 0.9213, Val Loss: 0.1053, Val Acc: 0.9598
Epoch 43/100, Loss: 0.2072, Acc: 0.9211, Val Loss: 0.0877, Val Acc: 0.9697
Epoch 44/100, Loss: 0.2083, Acc: 0.9208, Val Loss: 0.1015, Val Acc: 0.9601
Epoch 45/100, Loss: 0.2074, Acc: 0.9192, Val Loss: 0.1163, Val Acc: 0.9528
Epoch 46/100, Loss: 0.2072, Acc: 0.9196, Val Loss: 0.1377, Val Acc: 0.9424
Epoch 47/100, Loss: 0.2071, Acc: 0.9197, Val Loss: 0.1007, Val Acc: 0.9605
Epoch 48/100, Loss: 0.2065, Acc: 0.9203, Val Loss: 0.0866, Val Acc: 0.9708
Epoch 49/100, Loss: 0.2076, Acc: 0.9184, Val Loss: 0.0998, Val Acc: 0.9627
Epoch 50/100, Loss: 0.2065, Acc: 0.9186, Val Loss: 0.0886, Val Acc: 0.9708
Epoch 51/100, Loss: 0.2056, Acc: 0.9200, Val Loss: 0.0873, Val Acc: 0.9683
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2049, Acc: 0.9206, Val Loss: 0.1114, Val Acc: 0.9546
Epoch 53/100, Loss: 0.2053, Acc: 0.9208, Val Loss: 0.0938, Val Acc: 0.9649
Epoch 54/100, Loss: 0.2052, Acc: 0.9211, Val Loss: 0.0997, Val Acc: 0.9620
Epoch 55/100, Loss: 0.2046, Acc: 0.9210, Val Loss: 0.1085, Val Acc: 0.9557
Epoch 56/100, Loss: 0.2046, Acc: 0.9215, Val Loss: 0.1031, Val Acc: 0.9590
Epoch 57/100, Loss: 0.2047, Acc: 0.9204, Val Loss: 0.1094, Val Acc: 0.9568
Epoch 58/100, Loss: 0.2047, Acc: 0.9209, Val Loss: 0.1008, Val Acc: 0.9616
Epoch 59/100, Loss: 0.2043, Acc: 0.9229, Val Loss: 0.0938, Val Acc: 0.9642
Epoch 60/100, Loss: 0.2050, Acc: 0.9206, Val Loss: 0.0951, Val Acc: 0.9638
Epoch 61/100, Loss: 0.2046, Acc: 0.9209, Val Loss: 0.1198, Val Acc: 0.9498
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2039, Acc: 0.9213, Val Loss: 0.1020, Val Acc: 0.9598
Epoch 63/100, Loss: 0.2036, Acc: 0.9213, Val Loss: 0.1021, Val Acc: 0.9616
Epoch 64/100, Loss: 0.2036, Acc: 0.9208, Val Loss: 0.0965, Val Acc: 0.9635
Epoch 65/100, Loss: 0.2035, Acc: 0.9206, Val Loss: 0.0909, Val Acc: 0.9653
Epoch 66/100, Loss: 0.2037, Acc: 0.9215, Val Loss: 0.1035, Val Acc: 0.9576
Epoch 67/100, Loss: 0.2041, Acc: 0.9203, Val Loss: 0.1068, Val Acc: 0.9565
Epoch 68/100, Loss: 0.2033, Acc: 0.9213, Val Loss: 0.1042, Val Acc: 0.9598
Epoch 69/100, Loss: 0.2037, Acc: 0.9207, Val Loss: 0.0989, Val Acc: 0.9624
Epoch 70/100, Loss: 0.2035, Acc: 0.9214, Val Loss: 0.0992, Val Acc: 0.9609
Epoch 71/100, Loss: 0.2035, Acc: 0.9208, Val Loss: 0.1054, Val Acc: 0.9568
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2033, Acc: 0.9213, Val Loss: 0.1064, Val Acc: 0.9572
Epoch 73/100, Loss: 0.2031, Acc: 0.9216, Val Loss: 0.1067, Val Acc: 0.9568
Epoch 74/100, Loss: 0.2033, Acc: 0.9213, Val Loss: 0.1063, Val Acc: 0.9576
Epoch 75/100, Loss: 0.2032, Acc: 0.9214, Val Loss: 0.1037, Val Acc: 0.9598
Epoch 76/100, Loss: 0.2032, Acc: 0.9213, Val Loss: 0.1038, Val Acc: 0.9583
Epoch 77/100, Loss: 0.2034, Acc: 0.9211, Val Loss: 0.1003, Val Acc: 0.9620
Epoch 78/100, Loss: 0.2031, Acc: 0.9216, Val Loss: 0.1011, Val Acc: 0.9609
Epoch 79/100, Loss: 0.2030, Acc: 0.9213, Val Loss: 0.1137, Val Acc: 0.9528
Epoch 80/100, Loss: 0.2031, Acc: 0.9213, Val Loss: 0.0996, Val Acc: 0.9624
Epoch 81/100, Loss: 0.2029, Acc: 0.9213, Val Loss: 0.1147, Val Acc: 0.9513
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2035, Acc: 0.9221, Val Loss: 0.1082, Val Acc: 0.9554
Epoch 83/100, Loss: 0.2030, Acc: 0.9212, Val Loss: 0.1000, Val Acc: 0.9620
Epoch 84/100, Loss: 0.2031, Acc: 0.9213, Val Loss: 0.1060, Val Acc: 0.9568
Epoch 85/100, Loss: 0.2029, Acc: 0.9217, Val Loss: 0.0988, Val Acc: 0.9624
Epoch 86/100, Loss: 0.2029, Acc: 0.9219, Val Loss: 0.1042, Val Acc: 0.9590
Epoch 87/100, Loss: 0.2027, Acc: 0.9216, Val Loss: 0.1106, Val Acc: 0.9546
Epoch 88/100, Loss: 0.2026, Acc: 0.9211, Val Loss: 0.1095, Val Acc: 0.9554
Epoch 89/100, Loss: 0.2026, Acc: 0.9216, Val Loss: 0.0996, Val Acc: 0.9624
Epoch 90/100, Loss: 0.2028, Acc: 0.9217, Val Loss: 0.1059, Val Acc: 0.9572
Epoch 91/100, Loss: 0.2025, Acc: 0.9215, Val Loss: 0.1009, Val Acc: 0.9613
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2025, Acc: 0.9213, Val Loss: 0.1140, Val Acc: 0.9528
Epoch 93/100, Loss: 0.2027, Acc: 0.9211, Val Loss: 0.1064, Val Acc: 0.9572
Epoch 94/100, Loss: 0.2024, Acc: 0.9214, Val Loss: 0.0989, Val Acc: 0.9624
Epoch 95/100, Loss: 0.2025, Acc: 0.9220, Val Loss: 0.0985, Val Acc: 0.9624
Epoch 96/100, Loss: 0.2024, Acc: 0.9217, Val Loss: 0.1064, Val Acc: 0.9565
Epoch 97/100, Loss: 0.2024, Acc: 0.9213, Val Loss: 0.1027, Val Acc: 0.9609
Epoch 98/100, Loss: 0.2023, Acc: 0.9210, Val Loss: 0.1027, Val Acc: 0.9605
Epoch 99/100, Loss: 0.2023, Acc: 0.9205, Val Loss: 0.1105, Val Acc: 0.9546
Epoch 100/100, Loss: 0.2023, Acc: 0.9217, Val Loss: 0.0967, Val Acc: 0.9627

##############################
Resultados para principal:  007  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11 
 {'training': [0.2023128821801569, 0.9217111315547378, 0.9181735159817351, 0.9257826887661141, 0.9219624025676295], 'validate': [0.09673029539543529, 0.962730627306273, 0.9303928325292902, 1.0, 0.9639414494823277], 'test': [0.06411171216025667, 0.9817109144542773, 0.9993865030674847, 0.9639053254437869, 0.9813253012048193]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  111  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  111  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  111  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5404, Acc: 0.7960, Val Loss: 0.3277, Val Acc: 0.9542
Mejor modelo guardado con Val Loss: 0.3277
Epoch 2/100, Loss: 0.3945, Acc: 0.8401, Val Loss: 0.2675, Val Acc: 0.9395
Mejor modelo guardado con Val Loss: 0.2675
Epoch 3/100, Loss: 0.3756, Acc: 0.8365, Val Loss: 0.2140, Val Acc: 0.9587
Mejor modelo guardado con Val Loss: 0.2140
Epoch 4/100, Loss: 0.3674, Acc: 0.8475, Val Loss: 0.1924, Val Acc: 0.9646
Mejor modelo guardado con Val Loss: 0.1924
Epoch 5/100, Loss: 0.3496, Acc: 0.8495, Val Loss: 0.1832, Val Acc: 0.9517
Mejor modelo guardado con Val Loss: 0.1832
Epoch 6/100, Loss: 0.3587, Acc: 0.8465, Val Loss: 0.1785, Val Acc: 0.9646
Mejor modelo guardado con Val Loss: 0.1785
Epoch 7/100, Loss: 0.3357, Acc: 0.8560, Val Loss: 0.2024, Val Acc: 0.9376
Epoch 8/100, Loss: 0.3241, Acc: 0.8630, Val Loss: 0.1824, Val Acc: 0.9583
Epoch 9/100, Loss: 0.3308, Acc: 0.8598, Val Loss: 0.1659, Val Acc: 0.9771
Mejor modelo guardado con Val Loss: 0.1659
Epoch 10/100, Loss: 0.3265, Acc: 0.8580, Val Loss: 0.1478, Val Acc: 0.9701
Mejor modelo guardado con Val Loss: 0.1478
Epoch 11/100, Loss: 0.3158, Acc: 0.8690, Val Loss: 0.1864, Val Acc: 0.9694
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3095, Acc: 0.8661, Val Loss: 0.1455, Val Acc: 0.9638
Mejor modelo guardado con Val Loss: 0.1455
Epoch 13/100, Loss: 0.3028, Acc: 0.8739, Val Loss: 0.1435, Val Acc: 0.9579
Mejor modelo guardado con Val Loss: 0.1435
Epoch 14/100, Loss: 0.2974, Acc: 0.8779, Val Loss: 0.1570, Val Acc: 0.9487
Epoch 15/100, Loss: 0.2982, Acc: 0.8753, Val Loss: 0.1168, Val Acc: 0.9683
Mejor modelo guardado con Val Loss: 0.1168
Epoch 16/100, Loss: 0.2950, Acc: 0.8757, Val Loss: 0.1262, Val Acc: 0.9642
Epoch 17/100, Loss: 0.2905, Acc: 0.8766, Val Loss: 0.1604, Val Acc: 0.9428
Epoch 18/100, Loss: 0.2891, Acc: 0.8787, Val Loss: 0.1228, Val Acc: 0.9672
Epoch 19/100, Loss: 0.2894, Acc: 0.8799, Val Loss: 0.1040, Val Acc: 0.9738
Mejor modelo guardado con Val Loss: 0.1040
Epoch 20/100, Loss: 0.2860, Acc: 0.8815, Val Loss: 0.1631, Val Acc: 0.9594
Epoch 21/100, Loss: 0.2883, Acc: 0.8805, Val Loss: 0.1160, Val Acc: 0.9731
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.2810, Acc: 0.8853, Val Loss: 0.1451, Val Acc: 0.9572
Epoch 23/100, Loss: 0.2808, Acc: 0.8841, Val Loss: 0.1561, Val Acc: 0.9491
Epoch 24/100, Loss: 0.2796, Acc: 0.8845, Val Loss: 0.1500, Val Acc: 0.9528
Epoch 25/100, Loss: 0.2790, Acc: 0.8840, Val Loss: 0.1257, Val Acc: 0.9638
Epoch 26/100, Loss: 0.2766, Acc: 0.8857, Val Loss: 0.1266, Val Acc: 0.9631
Epoch 27/100, Loss: 0.2826, Acc: 0.8834, Val Loss: 0.1273, Val Acc: 0.9624
Epoch 28/100, Loss: 0.2734, Acc: 0.8868, Val Loss: 0.1245, Val Acc: 0.9661
Epoch 29/100, Loss: 0.2747, Acc: 0.8856, Val Loss: 0.1229, Val Acc: 0.9649
Epoch 30/100, Loss: 0.2745, Acc: 0.8859, Val Loss: 0.1267, Val Acc: 0.9624
Epoch 31/100, Loss: 0.2739, Acc: 0.8868, Val Loss: 0.1160, Val Acc: 0.9672
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.2698, Acc: 0.8878, Val Loss: 0.1164, Val Acc: 0.9642
Epoch 33/100, Loss: 0.2709, Acc: 0.8886, Val Loss: 0.1178, Val Acc: 0.9627
Epoch 34/100, Loss: 0.2684, Acc: 0.8902, Val Loss: 0.1190, Val Acc: 0.9638
Epoch 35/100, Loss: 0.2687, Acc: 0.8893, Val Loss: 0.1038, Val Acc: 0.9694
Mejor modelo guardado con Val Loss: 0.1038
Epoch 36/100, Loss: 0.2685, Acc: 0.8882, Val Loss: 0.1175, Val Acc: 0.9635
Epoch 37/100, Loss: 0.2671, Acc: 0.8892, Val Loss: 0.1295, Val Acc: 0.9613
Epoch 38/100, Loss: 0.2679, Acc: 0.8891, Val Loss: 0.1183, Val Acc: 0.9631
Epoch 39/100, Loss: 0.2673, Acc: 0.8895, Val Loss: 0.1216, Val Acc: 0.9631
Epoch 40/100, Loss: 0.2662, Acc: 0.8891, Val Loss: 0.1100, Val Acc: 0.9672
Epoch 41/100, Loss: 0.2673, Acc: 0.8884, Val Loss: 0.1054, Val Acc: 0.9694
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2649, Acc: 0.8914, Val Loss: 0.1189, Val Acc: 0.9627
Epoch 43/100, Loss: 0.2641, Acc: 0.8897, Val Loss: 0.1224, Val Acc: 0.9635
Epoch 44/100, Loss: 0.2640, Acc: 0.8916, Val Loss: 0.1232, Val Acc: 0.9627
Epoch 45/100, Loss: 0.2637, Acc: 0.8911, Val Loss: 0.1188, Val Acc: 0.9642
Epoch 46/100, Loss: 0.2638, Acc: 0.8915, Val Loss: 0.1127, Val Acc: 0.9646
Epoch 47/100, Loss: 0.2640, Acc: 0.8910, Val Loss: 0.1151, Val Acc: 0.9635
Epoch 48/100, Loss: 0.2636, Acc: 0.8926, Val Loss: 0.1275, Val Acc: 0.9609
Epoch 49/100, Loss: 0.2630, Acc: 0.8911, Val Loss: 0.1142, Val Acc: 0.9649
Epoch 50/100, Loss: 0.2635, Acc: 0.8917, Val Loss: 0.1260, Val Acc: 0.9624
Epoch 51/100, Loss: 0.2631, Acc: 0.8894, Val Loss: 0.1239, Val Acc: 0.9620
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2618, Acc: 0.8919, Val Loss: 0.1183, Val Acc: 0.9642
Epoch 53/100, Loss: 0.2618, Acc: 0.8921, Val Loss: 0.1204, Val Acc: 0.9627
Epoch 54/100, Loss: 0.2617, Acc: 0.8914, Val Loss: 0.1293, Val Acc: 0.9576
Epoch 55/100, Loss: 0.2619, Acc: 0.8911, Val Loss: 0.1161, Val Acc: 0.9624
Epoch 56/100, Loss: 0.2613, Acc: 0.8920, Val Loss: 0.1274, Val Acc: 0.9609
Epoch 57/100, Loss: 0.2612, Acc: 0.8917, Val Loss: 0.1140, Val Acc: 0.9631
Epoch 58/100, Loss: 0.2614, Acc: 0.8914, Val Loss: 0.1216, Val Acc: 0.9638
Epoch 59/100, Loss: 0.2611, Acc: 0.8933, Val Loss: 0.1154, Val Acc: 0.9627
Epoch 60/100, Loss: 0.2609, Acc: 0.8928, Val Loss: 0.1123, Val Acc: 0.9631
Epoch 61/100, Loss: 0.2610, Acc: 0.8917, Val Loss: 0.1195, Val Acc: 0.9642
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2606, Acc: 0.8923, Val Loss: 0.1177, Val Acc: 0.9638
Epoch 63/100, Loss: 0.2603, Acc: 0.8930, Val Loss: 0.1141, Val Acc: 0.9631
Epoch 64/100, Loss: 0.2603, Acc: 0.8926, Val Loss: 0.1166, Val Acc: 0.9631
Epoch 65/100, Loss: 0.2602, Acc: 0.8928, Val Loss: 0.1232, Val Acc: 0.9624
Epoch 66/100, Loss: 0.2602, Acc: 0.8931, Val Loss: 0.1125, Val Acc: 0.9631
Epoch 67/100, Loss: 0.2600, Acc: 0.8928, Val Loss: 0.1156, Val Acc: 0.9631
Epoch 68/100, Loss: 0.2600, Acc: 0.8924, Val Loss: 0.1141, Val Acc: 0.9631
Epoch 69/100, Loss: 0.2598, Acc: 0.8926, Val Loss: 0.1187, Val Acc: 0.9631
Epoch 70/100, Loss: 0.2599, Acc: 0.8927, Val Loss: 0.1144, Val Acc: 0.9627
Epoch 71/100, Loss: 0.2595, Acc: 0.8921, Val Loss: 0.1126, Val Acc: 0.9631
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2594, Acc: 0.8925, Val Loss: 0.1141, Val Acc: 0.9627
Epoch 73/100, Loss: 0.2594, Acc: 0.8933, Val Loss: 0.1174, Val Acc: 0.9638
Epoch 74/100, Loss: 0.2595, Acc: 0.8921, Val Loss: 0.1179, Val Acc: 0.9635
Epoch 75/100, Loss: 0.2595, Acc: 0.8931, Val Loss: 0.1174, Val Acc: 0.9642
Epoch 76/100, Loss: 0.2592, Acc: 0.8931, Val Loss: 0.1220, Val Acc: 0.9627
Epoch 77/100, Loss: 0.2595, Acc: 0.8931, Val Loss: 0.1150, Val Acc: 0.9635
Epoch 78/100, Loss: 0.2593, Acc: 0.8925, Val Loss: 0.1170, Val Acc: 0.9642
Epoch 79/100, Loss: 0.2594, Acc: 0.8929, Val Loss: 0.1180, Val Acc: 0.9635
Epoch 80/100, Loss: 0.2592, Acc: 0.8933, Val Loss: 0.1134, Val Acc: 0.9627
Epoch 81/100, Loss: 0.2592, Acc: 0.8930, Val Loss: 0.1166, Val Acc: 0.9642
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2591, Acc: 0.8923, Val Loss: 0.1169, Val Acc: 0.9642
Epoch 83/100, Loss: 0.2592, Acc: 0.8926, Val Loss: 0.1200, Val Acc: 0.9624
Epoch 84/100, Loss: 0.2590, Acc: 0.8932, Val Loss: 0.1162, Val Acc: 0.9642
Epoch 85/100, Loss: 0.2590, Acc: 0.8925, Val Loss: 0.1163, Val Acc: 0.9642
Epoch 86/100, Loss: 0.2590, Acc: 0.8935, Val Loss: 0.1175, Val Acc: 0.9638
Epoch 87/100, Loss: 0.2591, Acc: 0.8938, Val Loss: 0.1169, Val Acc: 0.9642
Epoch 88/100, Loss: 0.2589, Acc: 0.8937, Val Loss: 0.1161, Val Acc: 0.9642
Epoch 89/100, Loss: 0.2589, Acc: 0.8928, Val Loss: 0.1153, Val Acc: 0.9646
Epoch 90/100, Loss: 0.2589, Acc: 0.8930, Val Loss: 0.1131, Val Acc: 0.9624
Epoch 91/100, Loss: 0.2587, Acc: 0.8936, Val Loss: 0.1209, Val Acc: 0.9627
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2586, Acc: 0.8927, Val Loss: 0.1179, Val Acc: 0.9635
Epoch 93/100, Loss: 0.2587, Acc: 0.8926, Val Loss: 0.1171, Val Acc: 0.9642
Epoch 94/100, Loss: 0.2587, Acc: 0.8928, Val Loss: 0.1153, Val Acc: 0.9638
Epoch 95/100, Loss: 0.2587, Acc: 0.8927, Val Loss: 0.1181, Val Acc: 0.9635
Epoch 96/100, Loss: 0.2585, Acc: 0.8929, Val Loss: 0.1230, Val Acc: 0.9620
Epoch 97/100, Loss: 0.2586, Acc: 0.8928, Val Loss: 0.1171, Val Acc: 0.9642
Epoch 98/100, Loss: 0.2584, Acc: 0.8934, Val Loss: 0.1173, Val Acc: 0.9642
Epoch 99/100, Loss: 0.2585, Acc: 0.8930, Val Loss: 0.1163, Val Acc: 0.9646
Epoch 100/100, Loss: 0.2584, Acc: 0.8931, Val Loss: 0.1151, Val Acc: 0.9635

##############################
Resultados para principal:  111  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11 
 {'training': [0.2584351615447349, 0.8931002759889605, 0.8753077734787197, 0.9165745856353591, 0.8954659949622166], 'validate': [0.1151473869158085, 0.9634686346863469, 0.9490308686288585, 0.9792592592592593, 0.963908129784907], 'test': [1.512867346405983, 0.39233038348082594, 0.4319852941176471, 0.6952662721893491, 0.5328798185941043]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  001  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  001  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  001  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5763, Acc: 0.7460, Val Loss: 0.6921, Val Acc: 0.5424
Mejor modelo guardado con Val Loss: 0.6921
Epoch 2/100, Loss: 0.4855, Acc: 0.7750, Val Loss: 0.7554, Val Acc: 0.5232
Epoch 3/100, Loss: 0.4690, Acc: 0.7823, Val Loss: 0.7770, Val Acc: 0.5384
Epoch 4/100, Loss: 0.4433, Acc: 0.7935, Val Loss: 0.8275, Val Acc: 0.5225
Epoch 5/100, Loss: 0.4369, Acc: 0.7914, Val Loss: 0.6878, Val Acc: 0.5834
Mejor modelo guardado con Val Loss: 0.6878
Epoch 6/100, Loss: 0.4212, Acc: 0.8023, Val Loss: 0.7482, Val Acc: 0.5520
Epoch 7/100, Loss: 0.4160, Acc: 0.8061, Val Loss: 0.7185, Val Acc: 0.5672
Epoch 8/100, Loss: 0.4094, Acc: 0.8066, Val Loss: 0.8007, Val Acc: 0.5395
Epoch 9/100, Loss: 0.3985, Acc: 0.8131, Val Loss: 0.8956, Val Acc: 0.5210
Epoch 10/100, Loss: 0.4053, Acc: 0.8069, Val Loss: 0.8240, Val Acc: 0.5007
Epoch 11/100, Loss: 0.3990, Acc: 0.8098, Val Loss: 0.7449, Val Acc: 0.5310
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3834, Acc: 0.8247, Val Loss: 0.7349, Val Acc: 0.5683
Epoch 13/100, Loss: 0.3774, Acc: 0.8242, Val Loss: 0.7708, Val Acc: 0.5705
Epoch 14/100, Loss: 0.3721, Acc: 0.8266, Val Loss: 0.8158, Val Acc: 0.5531
Epoch 15/100, Loss: 0.3780, Acc: 0.8236, Val Loss: 0.7975, Val Acc: 0.5458
Epoch 16/100, Loss: 0.3696, Acc: 0.8264, Val Loss: 0.7759, Val Acc: 0.5823
Epoch 17/100, Loss: 0.3662, Acc: 0.8303, Val Loss: 0.8966, Val Acc: 0.5524
Epoch 18/100, Loss: 0.3678, Acc: 0.8301, Val Loss: 0.8706, Val Acc: 0.5498
Epoch 19/100, Loss: 0.3645, Acc: 0.8328, Val Loss: 0.9194, Val Acc: 0.5498
Epoch 20/100, Loss: 0.3622, Acc: 0.8317, Val Loss: 0.8000, Val Acc: 0.5576
Epoch 21/100, Loss: 0.3618, Acc: 0.8328, Val Loss: 0.8442, Val Acc: 0.5613
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3530, Acc: 0.8398, Val Loss: 0.8546, Val Acc: 0.5642
Epoch 23/100, Loss: 0.3517, Acc: 0.8392, Val Loss: 0.8656, Val Acc: 0.5616
Epoch 24/100, Loss: 0.3510, Acc: 0.8368, Val Loss: 0.9372, Val Acc: 0.5557
Epoch 25/100, Loss: 0.3520, Acc: 0.8369, Val Loss: 0.9501, Val Acc: 0.5483
Epoch 26/100, Loss: 0.3487, Acc: 0.8415, Val Loss: 0.7365, Val Acc: 0.5815
Epoch 27/100, Loss: 0.3478, Acc: 0.8394, Val Loss: 0.8135, Val Acc: 0.5882
Epoch 28/100, Loss: 0.3457, Acc: 0.8414, Val Loss: 0.8142, Val Acc: 0.5712
Epoch 29/100, Loss: 0.3453, Acc: 0.8412, Val Loss: 0.9269, Val Acc: 0.5550
Epoch 30/100, Loss: 0.3438, Acc: 0.8408, Val Loss: 0.8574, Val Acc: 0.5638
Epoch 31/100, Loss: 0.3439, Acc: 0.8438, Val Loss: 0.8301, Val Acc: 0.5664
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3397, Acc: 0.8430, Val Loss: 0.9066, Val Acc: 0.5539
Epoch 33/100, Loss: 0.3402, Acc: 0.8446, Val Loss: 0.8839, Val Acc: 0.5565
Epoch 34/100, Loss: 0.3397, Acc: 0.8443, Val Loss: 0.8823, Val Acc: 0.5539
Epoch 35/100, Loss: 0.3382, Acc: 0.8463, Val Loss: 0.8774, Val Acc: 0.5609
Epoch 36/100, Loss: 0.3379, Acc: 0.8459, Val Loss: 0.7874, Val Acc: 0.5945
Epoch 37/100, Loss: 0.3381, Acc: 0.8456, Val Loss: 0.8752, Val Acc: 0.5642
Epoch 38/100, Loss: 0.3364, Acc: 0.8470, Val Loss: 0.8345, Val Acc: 0.5812
Epoch 39/100, Loss: 0.3349, Acc: 0.8466, Val Loss: 0.8355, Val Acc: 0.5782
Epoch 40/100, Loss: 0.3353, Acc: 0.8458, Val Loss: 0.8261, Val Acc: 0.5753
Epoch 41/100, Loss: 0.3343, Acc: 0.8464, Val Loss: 0.8506, Val Acc: 0.5731
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3310, Acc: 0.8489, Val Loss: 0.8741, Val Acc: 0.5683
Epoch 43/100, Loss: 0.3311, Acc: 0.8491, Val Loss: 0.8288, Val Acc: 0.5727
Epoch 44/100, Loss: 0.3307, Acc: 0.8498, Val Loss: 0.8437, Val Acc: 0.5720
Epoch 45/100, Loss: 0.3301, Acc: 0.8473, Val Loss: 0.8280, Val Acc: 0.5790
Epoch 46/100, Loss: 0.3300, Acc: 0.8502, Val Loss: 0.8223, Val Acc: 0.5753
Epoch 47/100, Loss: 0.3293, Acc: 0.8518, Val Loss: 0.8570, Val Acc: 0.5745
Epoch 48/100, Loss: 0.3299, Acc: 0.8506, Val Loss: 0.8360, Val Acc: 0.5753
Epoch 49/100, Loss: 0.3297, Acc: 0.8492, Val Loss: 0.8507, Val Acc: 0.5782
Epoch 50/100, Loss: 0.3291, Acc: 0.8497, Val Loss: 0.8354, Val Acc: 0.5801
Epoch 51/100, Loss: 0.3291, Acc: 0.8487, Val Loss: 0.8721, Val Acc: 0.5697
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3273, Acc: 0.8513, Val Loss: 0.8201, Val Acc: 0.5827
Epoch 53/100, Loss: 0.3277, Acc: 0.8517, Val Loss: 0.8305, Val Acc: 0.5808
Epoch 54/100, Loss: 0.3271, Acc: 0.8523, Val Loss: 0.8464, Val Acc: 0.5771
Epoch 55/100, Loss: 0.3273, Acc: 0.8504, Val Loss: 0.8352, Val Acc: 0.5768
Epoch 56/100, Loss: 0.3268, Acc: 0.8514, Val Loss: 0.8447, Val Acc: 0.5738
Epoch 57/100, Loss: 0.3266, Acc: 0.8507, Val Loss: 0.8330, Val Acc: 0.5771
Epoch 58/100, Loss: 0.3266, Acc: 0.8511, Val Loss: 0.8142, Val Acc: 0.5886
Epoch 59/100, Loss: 0.3265, Acc: 0.8530, Val Loss: 0.8864, Val Acc: 0.5661
Epoch 60/100, Loss: 0.3268, Acc: 0.8517, Val Loss: 0.8724, Val Acc: 0.5697
Epoch 61/100, Loss: 0.3259, Acc: 0.8526, Val Loss: 0.8700, Val Acc: 0.5668
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3256, Acc: 0.8508, Val Loss: 0.8671, Val Acc: 0.5690
Epoch 63/100, Loss: 0.3253, Acc: 0.8517, Val Loss: 0.8572, Val Acc: 0.5742
Epoch 64/100, Loss: 0.3251, Acc: 0.8527, Val Loss: 0.8666, Val Acc: 0.5705
Epoch 65/100, Loss: 0.3250, Acc: 0.8522, Val Loss: 0.8544, Val Acc: 0.5734
Epoch 66/100, Loss: 0.3250, Acc: 0.8520, Val Loss: 0.8378, Val Acc: 0.5786
Epoch 67/100, Loss: 0.3247, Acc: 0.8523, Val Loss: 0.8790, Val Acc: 0.5661
Epoch 68/100, Loss: 0.3248, Acc: 0.8524, Val Loss: 0.8697, Val Acc: 0.5686
Epoch 69/100, Loss: 0.3251, Acc: 0.8510, Val Loss: 0.8699, Val Acc: 0.5694
Epoch 70/100, Loss: 0.3248, Acc: 0.8521, Val Loss: 0.8546, Val Acc: 0.5731
Epoch 71/100, Loss: 0.3248, Acc: 0.8522, Val Loss: 0.8477, Val Acc: 0.5753
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3243, Acc: 0.8528, Val Loss: 0.8705, Val Acc: 0.5690
Epoch 73/100, Loss: 0.3244, Acc: 0.8519, Val Loss: 0.8619, Val Acc: 0.5742
Epoch 74/100, Loss: 0.3243, Acc: 0.8526, Val Loss: 0.8495, Val Acc: 0.5756
Epoch 75/100, Loss: 0.3244, Acc: 0.8526, Val Loss: 0.8472, Val Acc: 0.5760
Epoch 76/100, Loss: 0.3242, Acc: 0.8520, Val Loss: 0.8519, Val Acc: 0.5745
Epoch 77/100, Loss: 0.3242, Acc: 0.8523, Val Loss: 0.8547, Val Acc: 0.5756
Epoch 78/100, Loss: 0.3243, Acc: 0.8526, Val Loss: 0.8531, Val Acc: 0.5753
Epoch 79/100, Loss: 0.3240, Acc: 0.8523, Val Loss: 0.8548, Val Acc: 0.5742
Epoch 80/100, Loss: 0.3241, Acc: 0.8512, Val Loss: 0.8451, Val Acc: 0.5771
Epoch 81/100, Loss: 0.3241, Acc: 0.8520, Val Loss: 0.8602, Val Acc: 0.5738
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3239, Acc: 0.8525, Val Loss: 0.8606, Val Acc: 0.5738
Epoch 83/100, Loss: 0.3239, Acc: 0.8521, Val Loss: 0.8432, Val Acc: 0.5782
Epoch 84/100, Loss: 0.3238, Acc: 0.8523, Val Loss: 0.8608, Val Acc: 0.5734
Epoch 85/100, Loss: 0.3238, Acc: 0.8525, Val Loss: 0.8554, Val Acc: 0.5745
Epoch 86/100, Loss: 0.3238, Acc: 0.8522, Val Loss: 0.8739, Val Acc: 0.5690
Epoch 87/100, Loss: 0.3236, Acc: 0.8514, Val Loss: 0.8512, Val Acc: 0.5745
Epoch 88/100, Loss: 0.3236, Acc: 0.8528, Val Loss: 0.8512, Val Acc: 0.5756
Epoch 89/100, Loss: 0.3235, Acc: 0.8528, Val Loss: 0.8544, Val Acc: 0.5749
Epoch 90/100, Loss: 0.3238, Acc: 0.8527, Val Loss: 0.8434, Val Acc: 0.5775
Epoch 91/100, Loss: 0.3236, Acc: 0.8522, Val Loss: 0.8756, Val Acc: 0.5675
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3236, Acc: 0.8525, Val Loss: 0.8591, Val Acc: 0.5734
Epoch 93/100, Loss: 0.3234, Acc: 0.8530, Val Loss: 0.8514, Val Acc: 0.5760
Epoch 94/100, Loss: 0.3234, Acc: 0.8522, Val Loss: 0.8557, Val Acc: 0.5742
Epoch 95/100, Loss: 0.3233, Acc: 0.8525, Val Loss: 0.8615, Val Acc: 0.5745
Epoch 96/100, Loss: 0.3232, Acc: 0.8534, Val Loss: 0.8752, Val Acc: 0.5679
Epoch 97/100, Loss: 0.3232, Acc: 0.8529, Val Loss: 0.8448, Val Acc: 0.5779
Epoch 98/100, Loss: 0.3231, Acc: 0.8541, Val Loss: 0.8695, Val Acc: 0.5708
Epoch 99/100, Loss: 0.3225, Acc: 0.8535, Val Loss: 0.8714, Val Acc: 0.5675
Epoch 100/100, Loss: 0.3220, Acc: 0.8536, Val Loss: 0.8624, Val Acc: 0.5712

##############################
Resultados para principal:  001  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11 
 {'training': [0.32195205837625257, 0.8536338546458142, 0.8290759471969826, 0.8906077348066298, 0.8587410103879961], 'validate': [0.8623524497068206, 0.5712177121771218, 0.5417777777777778, 0.902962962962963, 0.6772222222222222], 'test': [0.8850938717149338, 0.415929203539823, 0.44076797385620914, 0.6384615384615384, 0.5215079748670856]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  082  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  082  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  082  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6565, Acc: 0.6247, Val Loss: 0.6867, Val Acc: 0.5683
Mejor modelo guardado con Val Loss: 0.6867
Epoch 2/100, Loss: 0.6221, Acc: 0.6952, Val Loss: 0.6926, Val Acc: 0.5303
Epoch 3/100, Loss: 0.5926, Acc: 0.7186, Val Loss: 0.7121, Val Acc: 0.5210
Epoch 4/100, Loss: 0.5694, Acc: 0.7266, Val Loss: 0.6610, Val Acc: 0.6122
Mejor modelo guardado con Val Loss: 0.6610
Epoch 5/100, Loss: 0.5537, Acc: 0.7312, Val Loss: 0.6528, Val Acc: 0.6229
Mejor modelo guardado con Val Loss: 0.6528
Epoch 6/100, Loss: 0.5502, Acc: 0.7247, Val Loss: 0.6568, Val Acc: 0.6299
Epoch 7/100, Loss: 0.5393, Acc: 0.7364, Val Loss: 0.7057, Val Acc: 0.5661
Epoch 8/100, Loss: 0.5340, Acc: 0.7331, Val Loss: 0.6572, Val Acc: 0.6166
Epoch 9/100, Loss: 0.5293, Acc: 0.7386, Val Loss: 0.6487, Val Acc: 0.6269
Mejor modelo guardado con Val Loss: 0.6487
Epoch 10/100, Loss: 0.5277, Acc: 0.7374, Val Loss: 0.7280, Val Acc: 0.5856
Epoch 11/100, Loss: 0.5254, Acc: 0.7375, Val Loss: 0.7109, Val Acc: 0.5967
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5136, Acc: 0.7477, Val Loss: 0.6978, Val Acc: 0.5900
Epoch 13/100, Loss: 0.5103, Acc: 0.7469, Val Loss: 0.7277, Val Acc: 0.5838
Epoch 14/100, Loss: 0.5147, Acc: 0.7435, Val Loss: 0.6853, Val Acc: 0.5793
Epoch 15/100, Loss: 0.5091, Acc: 0.7496, Val Loss: 0.7164, Val Acc: 0.5904
Epoch 16/100, Loss: 0.5124, Acc: 0.7495, Val Loss: 0.7151, Val Acc: 0.5694
Epoch 17/100, Loss: 0.5095, Acc: 0.7489, Val Loss: 0.6726, Val Acc: 0.6155
Epoch 18/100, Loss: 0.5068, Acc: 0.7493, Val Loss: 0.7228, Val Acc: 0.5838
Epoch 19/100, Loss: 0.5063, Acc: 0.7487, Val Loss: 0.6816, Val Acc: 0.6151
Epoch 20/100, Loss: 0.5122, Acc: 0.7439, Val Loss: 0.7180, Val Acc: 0.6000
Epoch 21/100, Loss: 0.5048, Acc: 0.7498, Val Loss: 0.6895, Val Acc: 0.6066
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4994, Acc: 0.7508, Val Loss: 0.7056, Val Acc: 0.6022
Epoch 23/100, Loss: 0.4968, Acc: 0.7538, Val Loss: 0.7000, Val Acc: 0.6085
Epoch 24/100, Loss: 0.4971, Acc: 0.7530, Val Loss: 0.7005, Val Acc: 0.6015
Epoch 25/100, Loss: 0.4951, Acc: 0.7539, Val Loss: 0.6980, Val Acc: 0.6048
Epoch 26/100, Loss: 0.4950, Acc: 0.7546, Val Loss: 0.7165, Val Acc: 0.5712
Epoch 27/100, Loss: 0.4937, Acc: 0.7560, Val Loss: 0.7380, Val Acc: 0.5742
Epoch 28/100, Loss: 0.4947, Acc: 0.7569, Val Loss: 0.7113, Val Acc: 0.5989
Epoch 29/100, Loss: 0.4944, Acc: 0.7552, Val Loss: 0.7216, Val Acc: 0.5970
Epoch 30/100, Loss: 0.4948, Acc: 0.7545, Val Loss: 0.6905, Val Acc: 0.6122
Epoch 31/100, Loss: 0.4926, Acc: 0.7576, Val Loss: 0.6829, Val Acc: 0.6151
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4900, Acc: 0.7586, Val Loss: 0.7175, Val Acc: 0.5993
Epoch 33/100, Loss: 0.4903, Acc: 0.7586, Val Loss: 0.7170, Val Acc: 0.6011
Epoch 34/100, Loss: 0.4895, Acc: 0.7567, Val Loss: 0.6816, Val Acc: 0.6192
Epoch 35/100, Loss: 0.4898, Acc: 0.7570, Val Loss: 0.6963, Val Acc: 0.6129
Epoch 36/100, Loss: 0.4891, Acc: 0.7596, Val Loss: 0.6884, Val Acc: 0.6218
Epoch 37/100, Loss: 0.4888, Acc: 0.7576, Val Loss: 0.6985, Val Acc: 0.6133
Epoch 38/100, Loss: 0.4896, Acc: 0.7583, Val Loss: 0.6921, Val Acc: 0.6148
Epoch 39/100, Loss: 0.4885, Acc: 0.7569, Val Loss: 0.7087, Val Acc: 0.6081
Epoch 40/100, Loss: 0.4883, Acc: 0.7585, Val Loss: 0.7006, Val Acc: 0.6129
Epoch 41/100, Loss: 0.4870, Acc: 0.7594, Val Loss: 0.7086, Val Acc: 0.6081
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4860, Acc: 0.7587, Val Loss: 0.6942, Val Acc: 0.6148
Epoch 43/100, Loss: 0.4865, Acc: 0.7573, Val Loss: 0.7232, Val Acc: 0.5996
Epoch 44/100, Loss: 0.4860, Acc: 0.7594, Val Loss: 0.7149, Val Acc: 0.6026
Epoch 45/100, Loss: 0.4859, Acc: 0.7598, Val Loss: 0.7029, Val Acc: 0.6100
Epoch 46/100, Loss: 0.4856, Acc: 0.7598, Val Loss: 0.7070, Val Acc: 0.6089
Epoch 47/100, Loss: 0.4855, Acc: 0.7593, Val Loss: 0.6997, Val Acc: 0.6122
Epoch 48/100, Loss: 0.4855, Acc: 0.7581, Val Loss: 0.7023, Val Acc: 0.6114
Epoch 49/100, Loss: 0.4853, Acc: 0.7587, Val Loss: 0.6923, Val Acc: 0.6140
Epoch 50/100, Loss: 0.4852, Acc: 0.7596, Val Loss: 0.6971, Val Acc: 0.6166
Epoch 51/100, Loss: 0.4801, Acc: 0.7626, Val Loss: 0.6907, Val Acc: 0.6236
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4763, Acc: 0.7674, Val Loss: 0.6987, Val Acc: 0.6203
Epoch 53/100, Loss: 0.4761, Acc: 0.7656, Val Loss: 0.7080, Val Acc: 0.6144
Epoch 54/100, Loss: 0.4758, Acc: 0.7646, Val Loss: 0.6889, Val Acc: 0.6251
Epoch 55/100, Loss: 0.4750, Acc: 0.7654, Val Loss: 0.7002, Val Acc: 0.6173
Epoch 56/100, Loss: 0.4752, Acc: 0.7695, Val Loss: 0.6919, Val Acc: 0.6225
Epoch 57/100, Loss: 0.4748, Acc: 0.7684, Val Loss: 0.6966, Val Acc: 0.6199
Epoch 58/100, Loss: 0.4750, Acc: 0.7685, Val Loss: 0.6952, Val Acc: 0.6214
Epoch 59/100, Loss: 0.4746, Acc: 0.7677, Val Loss: 0.6992, Val Acc: 0.6173
Epoch 60/100, Loss: 0.4744, Acc: 0.7698, Val Loss: 0.7009, Val Acc: 0.6140
Epoch 61/100, Loss: 0.4739, Acc: 0.7678, Val Loss: 0.7032, Val Acc: 0.6107
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4736, Acc: 0.7695, Val Loss: 0.6857, Val Acc: 0.6244
Epoch 63/100, Loss: 0.4732, Acc: 0.7699, Val Loss: 0.6922, Val Acc: 0.6229
Epoch 64/100, Loss: 0.4729, Acc: 0.7716, Val Loss: 0.6964, Val Acc: 0.6196
Epoch 65/100, Loss: 0.4727, Acc: 0.7699, Val Loss: 0.7031, Val Acc: 0.6122
Epoch 66/100, Loss: 0.4729, Acc: 0.7722, Val Loss: 0.6979, Val Acc: 0.6203
Epoch 67/100, Loss: 0.4727, Acc: 0.7699, Val Loss: 0.6939, Val Acc: 0.6210
Epoch 68/100, Loss: 0.4725, Acc: 0.7710, Val Loss: 0.6946, Val Acc: 0.6210
Epoch 69/100, Loss: 0.4726, Acc: 0.7714, Val Loss: 0.6917, Val Acc: 0.6229
Epoch 70/100, Loss: 0.4725, Acc: 0.7706, Val Loss: 0.6929, Val Acc: 0.6218
Epoch 71/100, Loss: 0.4723, Acc: 0.7709, Val Loss: 0.6953, Val Acc: 0.6192
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4719, Acc: 0.7718, Val Loss: 0.6923, Val Acc: 0.6210
Epoch 73/100, Loss: 0.4718, Acc: 0.7722, Val Loss: 0.6996, Val Acc: 0.6173
Epoch 74/100, Loss: 0.4720, Acc: 0.7719, Val Loss: 0.6962, Val Acc: 0.6203
Epoch 75/100, Loss: 0.4716, Acc: 0.7723, Val Loss: 0.6922, Val Acc: 0.6210
Epoch 76/100, Loss: 0.4717, Acc: 0.7718, Val Loss: 0.7001, Val Acc: 0.6151
Epoch 77/100, Loss: 0.4714, Acc: 0.7732, Val Loss: 0.6923, Val Acc: 0.6218
Epoch 78/100, Loss: 0.4714, Acc: 0.7720, Val Loss: 0.6965, Val Acc: 0.6196
Epoch 79/100, Loss: 0.4713, Acc: 0.7721, Val Loss: 0.6939, Val Acc: 0.6203
Epoch 80/100, Loss: 0.4711, Acc: 0.7725, Val Loss: 0.6900, Val Acc: 0.6229
Epoch 81/100, Loss: 0.4711, Acc: 0.7742, Val Loss: 0.7003, Val Acc: 0.6114
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4709, Acc: 0.7720, Val Loss: 0.6978, Val Acc: 0.6137
Epoch 83/100, Loss: 0.4708, Acc: 0.7744, Val Loss: 0.6896, Val Acc: 0.6218
Epoch 84/100, Loss: 0.4706, Acc: 0.7736, Val Loss: 0.6971, Val Acc: 0.6155
Epoch 85/100, Loss: 0.4707, Acc: 0.7728, Val Loss: 0.6938, Val Acc: 0.6173
Epoch 86/100, Loss: 0.4704, Acc: 0.7730, Val Loss: 0.6874, Val Acc: 0.6221
Epoch 87/100, Loss: 0.4704, Acc: 0.7737, Val Loss: 0.6951, Val Acc: 0.6170
Epoch 88/100, Loss: 0.4702, Acc: 0.7741, Val Loss: 0.6973, Val Acc: 0.6151
Epoch 89/100, Loss: 0.4703, Acc: 0.7733, Val Loss: 0.6941, Val Acc: 0.6177
Epoch 90/100, Loss: 0.4703, Acc: 0.7736, Val Loss: 0.6926, Val Acc: 0.6196
Epoch 91/100, Loss: 0.4701, Acc: 0.7729, Val Loss: 0.6934, Val Acc: 0.6181
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4700, Acc: 0.7742, Val Loss: 0.6926, Val Acc: 0.6188
Epoch 93/100, Loss: 0.4697, Acc: 0.7740, Val Loss: 0.6904, Val Acc: 0.6192
Epoch 94/100, Loss: 0.4696, Acc: 0.7751, Val Loss: 0.7022, Val Acc: 0.6100
Epoch 95/100, Loss: 0.4699, Acc: 0.7746, Val Loss: 0.6957, Val Acc: 0.6170
Epoch 96/100, Loss: 0.4696, Acc: 0.7741, Val Loss: 0.6970, Val Acc: 0.6125
Epoch 97/100, Loss: 0.4695, Acc: 0.7749, Val Loss: 0.6972, Val Acc: 0.6122
Epoch 98/100, Loss: 0.4694, Acc: 0.7753, Val Loss: 0.6940, Val Acc: 0.6173
Epoch 99/100, Loss: 0.4694, Acc: 0.7736, Val Loss: 0.6936, Val Acc: 0.6170
Epoch 100/100, Loss: 0.4694, Acc: 0.7746, Val Loss: 0.6953, Val Acc: 0.6166

##############################
Resultados para principal:  082  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11 
 {'training': [0.4693547781827588, 0.7746090156393745, 0.7503360215053764, 0.8224677716390424, 0.7847478474784748], 'validate': [0.6953100489322529, 0.6166051660516605, 0.5729020159399906, 0.9051851851851852, 0.7016939420040196], 'test': [0.489851268957246, 0.8035398230088495, 0.9398625429553265, 0.6473372781065089, 0.7666433076384023]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  103  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  103  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  103  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6846, Acc: 0.5558, Val Loss: 0.6967, Val Acc: 0.4812
Mejor modelo guardado con Val Loss: 0.6967
Epoch 2/100, Loss: 0.6806, Acc: 0.5815, Val Loss: 0.7013, Val Acc: 0.4705
Epoch 3/100, Loss: 0.6700, Acc: 0.6093, Val Loss: 0.7113, Val Acc: 0.4435
Epoch 4/100, Loss: 0.6640, Acc: 0.6146, Val Loss: 0.7117, Val Acc: 0.4332
Epoch 5/100, Loss: 0.6563, Acc: 0.6263, Val Loss: 0.7132, Val Acc: 0.4649
Epoch 6/100, Loss: 0.6499, Acc: 0.6280, Val Loss: 0.7239, Val Acc: 0.4653
Epoch 7/100, Loss: 0.6381, Acc: 0.6422, Val Loss: 0.7278, Val Acc: 0.4646
Epoch 8/100, Loss: 0.6351, Acc: 0.6444, Val Loss: 0.7339, Val Acc: 0.4472
Epoch 9/100, Loss: 0.6323, Acc: 0.6479, Val Loss: 0.7348, Val Acc: 0.4476
Epoch 10/100, Loss: 0.6246, Acc: 0.6534, Val Loss: 0.7320, Val Acc: 0.4616
Epoch 11/100, Loss: 0.6228, Acc: 0.6546, Val Loss: 0.7493, Val Acc: 0.4432
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6169, Acc: 0.6615, Val Loss: 0.7631, Val Acc: 0.4469
Epoch 13/100, Loss: 0.6131, Acc: 0.6652, Val Loss: 0.7619, Val Acc: 0.4402
Epoch 14/100, Loss: 0.6153, Acc: 0.6591, Val Loss: 0.7570, Val Acc: 0.4546
Epoch 15/100, Loss: 0.6107, Acc: 0.6635, Val Loss: 0.7441, Val Acc: 0.4594
Epoch 16/100, Loss: 0.6119, Acc: 0.6613, Val Loss: 0.7466, Val Acc: 0.4627
Epoch 17/100, Loss: 0.6104, Acc: 0.6647, Val Loss: 0.7532, Val Acc: 0.4546
Epoch 18/100, Loss: 0.6093, Acc: 0.6642, Val Loss: 0.7517, Val Acc: 0.4494
Epoch 19/100, Loss: 0.6071, Acc: 0.6678, Val Loss: 0.7604, Val Acc: 0.4502
Epoch 20/100, Loss: 0.6070, Acc: 0.6629, Val Loss: 0.7389, Val Acc: 0.4708
Epoch 21/100, Loss: 0.6047, Acc: 0.6702, Val Loss: 0.7696, Val Acc: 0.4465
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6024, Acc: 0.6747, Val Loss: 0.7549, Val Acc: 0.4679
Epoch 23/100, Loss: 0.6019, Acc: 0.6739, Val Loss: 0.7569, Val Acc: 0.4590
Epoch 24/100, Loss: 0.6015, Acc: 0.6730, Val Loss: 0.7615, Val Acc: 0.4576
Epoch 25/100, Loss: 0.6010, Acc: 0.6730, Val Loss: 0.7481, Val Acc: 0.4675
Epoch 26/100, Loss: 0.6000, Acc: 0.6755, Val Loss: 0.7494, Val Acc: 0.4686
Epoch 27/100, Loss: 0.6012, Acc: 0.6754, Val Loss: 0.7703, Val Acc: 0.4520
Epoch 28/100, Loss: 0.5989, Acc: 0.6745, Val Loss: 0.7532, Val Acc: 0.4642
Epoch 29/100, Loss: 0.5982, Acc: 0.6760, Val Loss: 0.7639, Val Acc: 0.4576
Epoch 30/100, Loss: 0.5978, Acc: 0.6753, Val Loss: 0.7569, Val Acc: 0.4635
Epoch 31/100, Loss: 0.5973, Acc: 0.6776, Val Loss: 0.7614, Val Acc: 0.4627
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5956, Acc: 0.6802, Val Loss: 0.7677, Val Acc: 0.4554
Epoch 33/100, Loss: 0.5957, Acc: 0.6798, Val Loss: 0.7695, Val Acc: 0.4554
Epoch 34/100, Loss: 0.5957, Acc: 0.6782, Val Loss: 0.7749, Val Acc: 0.4539
Epoch 35/100, Loss: 0.5953, Acc: 0.6799, Val Loss: 0.7721, Val Acc: 0.4557
Epoch 36/100, Loss: 0.5946, Acc: 0.6804, Val Loss: 0.7584, Val Acc: 0.4653
Epoch 37/100, Loss: 0.5950, Acc: 0.6780, Val Loss: 0.7575, Val Acc: 0.4649
Epoch 38/100, Loss: 0.5943, Acc: 0.6810, Val Loss: 0.7645, Val Acc: 0.4587
Epoch 39/100, Loss: 0.5945, Acc: 0.6799, Val Loss: 0.7597, Val Acc: 0.4642
Epoch 40/100, Loss: 0.5941, Acc: 0.6800, Val Loss: 0.7585, Val Acc: 0.4646
Epoch 41/100, Loss: 0.5937, Acc: 0.6811, Val Loss: 0.7573, Val Acc: 0.4672
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5930, Acc: 0.6811, Val Loss: 0.7633, Val Acc: 0.4653
Epoch 43/100, Loss: 0.5933, Acc: 0.6813, Val Loss: 0.7678, Val Acc: 0.4613
Epoch 44/100, Loss: 0.5931, Acc: 0.6827, Val Loss: 0.7628, Val Acc: 0.4683
Epoch 45/100, Loss: 0.5928, Acc: 0.6818, Val Loss: 0.7623, Val Acc: 0.4661
Epoch 46/100, Loss: 0.5924, Acc: 0.6813, Val Loss: 0.7614, Val Acc: 0.4635
Epoch 47/100, Loss: 0.5926, Acc: 0.6841, Val Loss: 0.7694, Val Acc: 0.4601
Epoch 48/100, Loss: 0.5928, Acc: 0.6827, Val Loss: 0.7602, Val Acc: 0.4661
Epoch 49/100, Loss: 0.5926, Acc: 0.6814, Val Loss: 0.7613, Val Acc: 0.4638
Epoch 50/100, Loss: 0.5923, Acc: 0.6810, Val Loss: 0.7597, Val Acc: 0.4668
Epoch 51/100, Loss: 0.5920, Acc: 0.6811, Val Loss: 0.7668, Val Acc: 0.4624
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5917, Acc: 0.6826, Val Loss: 0.7632, Val Acc: 0.4657
Epoch 53/100, Loss: 0.5915, Acc: 0.6835, Val Loss: 0.7624, Val Acc: 0.4638
Epoch 54/100, Loss: 0.5916, Acc: 0.6824, Val Loss: 0.7635, Val Acc: 0.4661
Epoch 55/100, Loss: 0.5912, Acc: 0.6832, Val Loss: 0.7697, Val Acc: 0.4620
Epoch 56/100, Loss: 0.5915, Acc: 0.6825, Val Loss: 0.7608, Val Acc: 0.4649
Epoch 57/100, Loss: 0.5913, Acc: 0.6830, Val Loss: 0.7660, Val Acc: 0.4631
Epoch 58/100, Loss: 0.5913, Acc: 0.6818, Val Loss: 0.7604, Val Acc: 0.4664
Epoch 59/100, Loss: 0.5912, Acc: 0.6831, Val Loss: 0.7646, Val Acc: 0.4653
Epoch 60/100, Loss: 0.5903, Acc: 0.6847, Val Loss: 0.7600, Val Acc: 0.4697
Epoch 61/100, Loss: 0.5895, Acc: 0.6851, Val Loss: 0.7611, Val Acc: 0.4716
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5890, Acc: 0.6843, Val Loss: 0.7646, Val Acc: 0.4664
Epoch 63/100, Loss: 0.5889, Acc: 0.6852, Val Loss: 0.7644, Val Acc: 0.4672
Epoch 64/100, Loss: 0.5890, Acc: 0.6845, Val Loss: 0.7614, Val Acc: 0.4708
Epoch 65/100, Loss: 0.5891, Acc: 0.6843, Val Loss: 0.7627, Val Acc: 0.4690
Epoch 66/100, Loss: 0.5888, Acc: 0.6850, Val Loss: 0.7629, Val Acc: 0.4672
Epoch 67/100, Loss: 0.5886, Acc: 0.6853, Val Loss: 0.7701, Val Acc: 0.4620
Epoch 68/100, Loss: 0.5891, Acc: 0.6842, Val Loss: 0.7655, Val Acc: 0.4679
Epoch 69/100, Loss: 0.5889, Acc: 0.6836, Val Loss: 0.7658, Val Acc: 0.4683
Epoch 70/100, Loss: 0.5889, Acc: 0.6856, Val Loss: 0.7625, Val Acc: 0.4716
Epoch 71/100, Loss: 0.5886, Acc: 0.6861, Val Loss: 0.7638, Val Acc: 0.4675
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5884, Acc: 0.6856, Val Loss: 0.7634, Val Acc: 0.4683
Epoch 73/100, Loss: 0.5885, Acc: 0.6846, Val Loss: 0.7641, Val Acc: 0.4697
Epoch 74/100, Loss: 0.5883, Acc: 0.6863, Val Loss: 0.7648, Val Acc: 0.4683
Epoch 75/100, Loss: 0.5884, Acc: 0.6854, Val Loss: 0.7649, Val Acc: 0.4672
Epoch 76/100, Loss: 0.5883, Acc: 0.6856, Val Loss: 0.7634, Val Acc: 0.4690
Epoch 77/100, Loss: 0.5883, Acc: 0.6845, Val Loss: 0.7648, Val Acc: 0.4683
Epoch 78/100, Loss: 0.5884, Acc: 0.6853, Val Loss: 0.7641, Val Acc: 0.4694
Epoch 79/100, Loss: 0.5882, Acc: 0.6855, Val Loss: 0.7643, Val Acc: 0.4690
Epoch 80/100, Loss: 0.5882, Acc: 0.6856, Val Loss: 0.7641, Val Acc: 0.4679
Epoch 81/100, Loss: 0.5881, Acc: 0.6856, Val Loss: 0.7641, Val Acc: 0.4686
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5881, Acc: 0.6851, Val Loss: 0.7644, Val Acc: 0.4694
Epoch 83/100, Loss: 0.5883, Acc: 0.6855, Val Loss: 0.7651, Val Acc: 0.4664
Epoch 84/100, Loss: 0.5881, Acc: 0.6855, Val Loss: 0.7651, Val Acc: 0.4679
Epoch 85/100, Loss: 0.5882, Acc: 0.6863, Val Loss: 0.7636, Val Acc: 0.4694
Epoch 86/100, Loss: 0.5880, Acc: 0.6858, Val Loss: 0.7641, Val Acc: 0.4697
Epoch 87/100, Loss: 0.5880, Acc: 0.6870, Val Loss: 0.7655, Val Acc: 0.4664
Epoch 88/100, Loss: 0.5881, Acc: 0.6850, Val Loss: 0.7656, Val Acc: 0.4668
Epoch 89/100, Loss: 0.5880, Acc: 0.6850, Val Loss: 0.7642, Val Acc: 0.4683
Epoch 90/100, Loss: 0.5880, Acc: 0.6856, Val Loss: 0.7639, Val Acc: 0.4683
Epoch 91/100, Loss: 0.5878, Acc: 0.6860, Val Loss: 0.7651, Val Acc: 0.4679
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5880, Acc: 0.6862, Val Loss: 0.7646, Val Acc: 0.4683
Epoch 93/100, Loss: 0.5879, Acc: 0.6853, Val Loss: 0.7649, Val Acc: 0.4697
Epoch 94/100, Loss: 0.5879, Acc: 0.6855, Val Loss: 0.7649, Val Acc: 0.4690
Epoch 95/100, Loss: 0.5877, Acc: 0.6855, Val Loss: 0.7646, Val Acc: 0.4679
Epoch 96/100, Loss: 0.5877, Acc: 0.6857, Val Loss: 0.7619, Val Acc: 0.4708
Epoch 97/100, Loss: 0.5879, Acc: 0.6859, Val Loss: 0.7657, Val Acc: 0.4672
Epoch 98/100, Loss: 0.5877, Acc: 0.6857, Val Loss: 0.7636, Val Acc: 0.4694
Epoch 99/100, Loss: 0.5877, Acc: 0.6865, Val Loss: 0.7650, Val Acc: 0.4679
Epoch 100/100, Loss: 0.5878, Acc: 0.6854, Val Loss: 0.7638, Val Acc: 0.4697

##############################
Resultados para principal:  103  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11 
 {'training': [0.587786949909161, 0.6853725850965962, 0.6310641627543035, 0.8911602209944751, 0.7388914338066881], 'validate': [0.7637609707754712, 0.4697416974169742, 0.48204704911267027, 0.8651851851851852, 0.6191359660747416], 'test': [0.6859419627009697, 0.5749262536873156, 0.5430051813471503, 0.9301775147928995, 0.6857142857142857]}

######################################## 
########################################
Grupo en indetificación:  ['007', '111', '001', '082', '103', '117']  --- principal:  117  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  117  --- group:  ['007', '111', '001', '082', '103', '117']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  117  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6277, Acc: 0.6997, Val Loss: 0.5085, Val Acc: 0.9159
Mejor modelo guardado con Val Loss: 0.5085
Epoch 2/100, Loss: 0.5598, Acc: 0.7242, Val Loss: 0.5528, Val Acc: 0.6708
Epoch 3/100, Loss: 0.5220, Acc: 0.7438, Val Loss: 0.4260, Val Acc: 0.9129
Mejor modelo guardado con Val Loss: 0.4260
Epoch 4/100, Loss: 0.5149, Acc: 0.7467, Val Loss: 0.4417, Val Acc: 0.8247
Epoch 5/100, Loss: 0.5097, Acc: 0.7462, Val Loss: 0.4041, Val Acc: 0.8720
Mejor modelo guardado con Val Loss: 0.4041
Epoch 6/100, Loss: 0.5011, Acc: 0.7510, Val Loss: 0.3909, Val Acc: 0.8432
Mejor modelo guardado con Val Loss: 0.3909
Epoch 7/100, Loss: 0.4944, Acc: 0.7542, Val Loss: 0.4417, Val Acc: 0.8506
Epoch 8/100, Loss: 0.4935, Acc: 0.7507, Val Loss: 0.4651, Val Acc: 0.7782
Epoch 9/100, Loss: 0.4866, Acc: 0.7547, Val Loss: 0.4324, Val Acc: 0.7815
Epoch 10/100, Loss: 0.4842, Acc: 0.7561, Val Loss: 0.4853, Val Acc: 0.7214
Epoch 11/100, Loss: 0.4857, Acc: 0.7559, Val Loss: 0.3601, Val Acc: 0.8535
Mejor modelo guardado con Val Loss: 0.3601
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4657, Acc: 0.7686, Val Loss: 0.4596, Val Acc: 0.7886
Epoch 13/100, Loss: 0.4645, Acc: 0.7684, Val Loss: 0.4252, Val Acc: 0.8118
Epoch 14/100, Loss: 0.4624, Acc: 0.7715, Val Loss: 0.4366, Val Acc: 0.7926
Epoch 15/100, Loss: 0.4595, Acc: 0.7768, Val Loss: 0.4438, Val Acc: 0.7952
Epoch 16/100, Loss: 0.4574, Acc: 0.7753, Val Loss: 0.4610, Val Acc: 0.7690
Epoch 17/100, Loss: 0.4596, Acc: 0.7716, Val Loss: 0.4015, Val Acc: 0.8133
Epoch 18/100, Loss: 0.4561, Acc: 0.7767, Val Loss: 0.4223, Val Acc: 0.8044
Epoch 19/100, Loss: 0.4549, Acc: 0.7796, Val Loss: 0.4216, Val Acc: 0.7904
Epoch 20/100, Loss: 0.4503, Acc: 0.7785, Val Loss: 0.4307, Val Acc: 0.8247
Epoch 21/100, Loss: 0.4483, Acc: 0.7803, Val Loss: 0.4436, Val Acc: 0.7649
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4427, Acc: 0.7841, Val Loss: 0.4609, Val Acc: 0.7638
Epoch 23/100, Loss: 0.4422, Acc: 0.7855, Val Loss: 0.4045, Val Acc: 0.8000
Epoch 24/100, Loss: 0.4426, Acc: 0.7833, Val Loss: 0.3987, Val Acc: 0.7996
Epoch 25/100, Loss: 0.4420, Acc: 0.7853, Val Loss: 0.3992, Val Acc: 0.7985
Epoch 26/100, Loss: 0.4394, Acc: 0.7863, Val Loss: 0.4677, Val Acc: 0.7384
Epoch 27/100, Loss: 0.4398, Acc: 0.7871, Val Loss: 0.4065, Val Acc: 0.7989
Epoch 28/100, Loss: 0.4376, Acc: 0.7877, Val Loss: 0.4095, Val Acc: 0.7963
Epoch 29/100, Loss: 0.4349, Acc: 0.7891, Val Loss: 0.4707, Val Acc: 0.7410
Epoch 30/100, Loss: 0.4349, Acc: 0.7880, Val Loss: 0.4141, Val Acc: 0.7812
Epoch 31/100, Loss: 0.4349, Acc: 0.7894, Val Loss: 0.4518, Val Acc: 0.7491
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4296, Acc: 0.7927, Val Loss: 0.4464, Val Acc: 0.7576
Epoch 33/100, Loss: 0.4295, Acc: 0.7928, Val Loss: 0.4244, Val Acc: 0.7701
Epoch 34/100, Loss: 0.4292, Acc: 0.7932, Val Loss: 0.4069, Val Acc: 0.7904
Epoch 35/100, Loss: 0.4287, Acc: 0.7914, Val Loss: 0.4152, Val Acc: 0.7838
Epoch 36/100, Loss: 0.4280, Acc: 0.7944, Val Loss: 0.4267, Val Acc: 0.7694
Epoch 37/100, Loss: 0.4272, Acc: 0.7949, Val Loss: 0.4347, Val Acc: 0.7624
Epoch 38/100, Loss: 0.4263, Acc: 0.7971, Val Loss: 0.4292, Val Acc: 0.7686
Epoch 39/100, Loss: 0.4264, Acc: 0.7948, Val Loss: 0.4381, Val Acc: 0.7720
Epoch 40/100, Loss: 0.4261, Acc: 0.7952, Val Loss: 0.4373, Val Acc: 0.7731
Epoch 41/100, Loss: 0.4252, Acc: 0.7972, Val Loss: 0.4456, Val Acc: 0.7572
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4237, Acc: 0.7983, Val Loss: 0.4361, Val Acc: 0.7646
Epoch 43/100, Loss: 0.4236, Acc: 0.7984, Val Loss: 0.4420, Val Acc: 0.7587
Epoch 44/100, Loss: 0.4223, Acc: 0.7983, Val Loss: 0.4420, Val Acc: 0.7594
Epoch 45/100, Loss: 0.4228, Acc: 0.8004, Val Loss: 0.4148, Val Acc: 0.7823
Epoch 46/100, Loss: 0.4225, Acc: 0.7981, Val Loss: 0.4320, Val Acc: 0.7679
Epoch 47/100, Loss: 0.4228, Acc: 0.7986, Val Loss: 0.4310, Val Acc: 0.7672
Epoch 48/100, Loss: 0.4220, Acc: 0.8005, Val Loss: 0.4405, Val Acc: 0.7502
Epoch 49/100, Loss: 0.4219, Acc: 0.8001, Val Loss: 0.4380, Val Acc: 0.7565
Epoch 50/100, Loss: 0.4210, Acc: 0.8008, Val Loss: 0.4334, Val Acc: 0.7638
Epoch 51/100, Loss: 0.4215, Acc: 0.7974, Val Loss: 0.4222, Val Acc: 0.7734
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4200, Acc: 0.8015, Val Loss: 0.4354, Val Acc: 0.7579
Epoch 53/100, Loss: 0.4196, Acc: 0.8010, Val Loss: 0.4312, Val Acc: 0.7668
Epoch 54/100, Loss: 0.4198, Acc: 0.8006, Val Loss: 0.4546, Val Acc: 0.7476
Epoch 55/100, Loss: 0.4197, Acc: 0.8014, Val Loss: 0.4413, Val Acc: 0.7528
Epoch 56/100, Loss: 0.4194, Acc: 0.7996, Val Loss: 0.4382, Val Acc: 0.7550
Epoch 57/100, Loss: 0.4193, Acc: 0.8004, Val Loss: 0.4366, Val Acc: 0.7609
Epoch 58/100, Loss: 0.4191, Acc: 0.8015, Val Loss: 0.4275, Val Acc: 0.7683
Epoch 59/100, Loss: 0.4191, Acc: 0.8013, Val Loss: 0.4331, Val Acc: 0.7594
Epoch 60/100, Loss: 0.4189, Acc: 0.8022, Val Loss: 0.4271, Val Acc: 0.7679
Epoch 61/100, Loss: 0.4187, Acc: 0.8011, Val Loss: 0.4430, Val Acc: 0.7535
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4183, Acc: 0.8035, Val Loss: 0.4347, Val Acc: 0.7627
Epoch 63/100, Loss: 0.4181, Acc: 0.8025, Val Loss: 0.4374, Val Acc: 0.7568
Epoch 64/100, Loss: 0.4181, Acc: 0.8030, Val Loss: 0.4443, Val Acc: 0.7542
Epoch 65/100, Loss: 0.4179, Acc: 0.8034, Val Loss: 0.4375, Val Acc: 0.7561
Epoch 66/100, Loss: 0.4178, Acc: 0.8025, Val Loss: 0.4376, Val Acc: 0.7565
Epoch 67/100, Loss: 0.4179, Acc: 0.8033, Val Loss: 0.4403, Val Acc: 0.7576
Epoch 68/100, Loss: 0.4176, Acc: 0.8030, Val Loss: 0.4349, Val Acc: 0.7565
Epoch 69/100, Loss: 0.4177, Acc: 0.8031, Val Loss: 0.4397, Val Acc: 0.7568
Epoch 70/100, Loss: 0.4177, Acc: 0.8026, Val Loss: 0.4360, Val Acc: 0.7572
Epoch 71/100, Loss: 0.4175, Acc: 0.8032, Val Loss: 0.4353, Val Acc: 0.7568
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4173, Acc: 0.8026, Val Loss: 0.4426, Val Acc: 0.7528
Epoch 73/100, Loss: 0.4174, Acc: 0.8030, Val Loss: 0.4327, Val Acc: 0.7594
Epoch 74/100, Loss: 0.4172, Acc: 0.8029, Val Loss: 0.4330, Val Acc: 0.7601
Epoch 75/100, Loss: 0.4172, Acc: 0.8038, Val Loss: 0.4397, Val Acc: 0.7568
Epoch 76/100, Loss: 0.4171, Acc: 0.8038, Val Loss: 0.4380, Val Acc: 0.7554
Epoch 77/100, Loss: 0.4171, Acc: 0.8040, Val Loss: 0.4387, Val Acc: 0.7561
Epoch 78/100, Loss: 0.4170, Acc: 0.8026, Val Loss: 0.4360, Val Acc: 0.7609
Epoch 79/100, Loss: 0.4171, Acc: 0.8033, Val Loss: 0.4400, Val Acc: 0.7542
Epoch 80/100, Loss: 0.4170, Acc: 0.8040, Val Loss: 0.4358, Val Acc: 0.7601
Epoch 81/100, Loss: 0.4169, Acc: 0.8022, Val Loss: 0.4389, Val Acc: 0.7554
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4170, Acc: 0.8031, Val Loss: 0.4322, Val Acc: 0.7605
Epoch 83/100, Loss: 0.4168, Acc: 0.8029, Val Loss: 0.4381, Val Acc: 0.7568
Epoch 84/100, Loss: 0.4167, Acc: 0.8029, Val Loss: 0.4379, Val Acc: 0.7565
Epoch 85/100, Loss: 0.4167, Acc: 0.8039, Val Loss: 0.4358, Val Acc: 0.7587
Epoch 86/100, Loss: 0.4166, Acc: 0.8029, Val Loss: 0.4365, Val Acc: 0.7568
Epoch 87/100, Loss: 0.4164, Acc: 0.8040, Val Loss: 0.4391, Val Acc: 0.7572
Epoch 88/100, Loss: 0.4165, Acc: 0.8040, Val Loss: 0.4445, Val Acc: 0.7502
Epoch 89/100, Loss: 0.4165, Acc: 0.8042, Val Loss: 0.4332, Val Acc: 0.7601
Epoch 90/100, Loss: 0.4161, Acc: 0.8034, Val Loss: 0.4324, Val Acc: 0.7601
Epoch 91/100, Loss: 0.4162, Acc: 0.8040, Val Loss: 0.4359, Val Acc: 0.7579
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4159, Acc: 0.8040, Val Loss: 0.4357, Val Acc: 0.7572
Epoch 93/100, Loss: 0.4160, Acc: 0.8034, Val Loss: 0.4370, Val Acc: 0.7576
Epoch 94/100, Loss: 0.4158, Acc: 0.8035, Val Loss: 0.4346, Val Acc: 0.7590
Epoch 95/100, Loss: 0.4157, Acc: 0.8039, Val Loss: 0.4366, Val Acc: 0.7568
Epoch 96/100, Loss: 0.4157, Acc: 0.8040, Val Loss: 0.4320, Val Acc: 0.7598
Epoch 97/100, Loss: 0.4156, Acc: 0.8040, Val Loss: 0.4360, Val Acc: 0.7576
Epoch 98/100, Loss: 0.4156, Acc: 0.8047, Val Loss: 0.4367, Val Acc: 0.7565
Epoch 99/100, Loss: 0.4156, Acc: 0.8042, Val Loss: 0.4365, Val Acc: 0.7546
Epoch 100/100, Loss: 0.4155, Acc: 0.8036, Val Loss: 0.4439, Val Acc: 0.7506

##############################
Resultados para principal:  117  --- grupo:  ['007', '111', '001', '082', '103', '117']  --- window & package numer:  11 
 {'training': [0.41548625490154384, 0.8035878564857406, 0.7540478026214341, 0.9005524861878453, 0.8208140998741082], 'validate': [0.44388315913289095, 0.7505535055350554, 0.709838107098381, 0.8444444444444444, 0.7713125845737483], 'test': [0.3547230342508487, 0.8775811209439528, 0.8880097382836275, 0.8633136094674556, 0.8754875487548754]}

##############################
Resultados para window:  11 
 {'007:111:001:082:103:117': {'training': [0.2023128821801569, 0.9217111315547378, 0.9181735159817351, 0.9257826887661141, 0.9219624025676295], 'validate': [0.09673029539543529, 0.962730627306273, 0.9303928325292902, 1.0, 0.9639414494823277], 'test': [0.06411171216025667, 0.9817109144542773, 0.9993865030674847, 0.9639053254437869, 0.9813253012048193]}, '111:007:001:082:103:117': {'training': [0.2584351615447349, 0.8931002759889605, 0.8753077734787197, 0.9165745856353591, 0.8954659949622166], 'validate': [0.1151473869158085, 0.9634686346863469, 0.9490308686288585, 0.9792592592592593, 0.963908129784907], 'test': [1.512867346405983, 0.39233038348082594, 0.4319852941176471, 0.6952662721893491, 0.5328798185941043]}, '001:007:111:082:103:117': {'training': [0.32195205837625257, 0.8536338546458142, 0.8290759471969826, 0.8906077348066298, 0.8587410103879961], 'validate': [0.8623524497068206, 0.5712177121771218, 0.5417777777777778, 0.902962962962963, 0.6772222222222222], 'test': [0.8850938717149338, 0.415929203539823, 0.44076797385620914, 0.6384615384615384, 0.5215079748670856]}, '082:007:111:001:103:117': {'training': [0.4693547781827588, 0.7746090156393745, 0.7503360215053764, 0.8224677716390424, 0.7847478474784748], 'validate': [0.6953100489322529, 0.6166051660516605, 0.5729020159399906, 0.9051851851851852, 0.7016939420040196], 'test': [0.489851268957246, 0.8035398230088495, 0.9398625429553265, 0.6473372781065089, 0.7666433076384023]}, '103:007:111:001:082:117': {'training': [0.587786949909161, 0.6853725850965962, 0.6310641627543035, 0.8911602209944751, 0.7388914338066881], 'validate': [0.7637609707754712, 0.4697416974169742, 0.48204704911267027, 0.8651851851851852, 0.6191359660747416], 'test': [0.6859419627009697, 0.5749262536873156, 0.5430051813471503, 0.9301775147928995, 0.6857142857142857]}, '117:007:111:001:082:103': {'training': [0.41548625490154384, 0.8035878564857406, 0.7540478026214341, 0.9005524861878453, 0.8208140998741082], 'validate': [0.44388315913289095, 0.7505535055350554, 0.709838107098381, 0.8444444444444444, 0.7713125845737483], 'test': [0.3547230342508487, 0.8775811209439528, 0.8880097382836275, 0.8633136094674556, 0.8754875487548754]}}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  067  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  067  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  067  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6060, Acc: 0.7066, Val Loss: 0.6346, Val Acc: 0.6339
Mejor modelo guardado con Val Loss: 0.6346
Epoch 2/100, Loss: 0.5689, Acc: 0.7213, Val Loss: 0.5990, Val Acc: 0.7218
Mejor modelo guardado con Val Loss: 0.5990
Epoch 3/100, Loss: 0.5630, Acc: 0.7190, Val Loss: 0.6426, Val Acc: 0.6155
Epoch 4/100, Loss: 0.5535, Acc: 0.7220, Val Loss: 0.5877, Val Acc: 0.7114
Mejor modelo guardado con Val Loss: 0.5877
Epoch 5/100, Loss: 0.5495, Acc: 0.7245, Val Loss: 0.5857, Val Acc: 0.6948
Mejor modelo guardado con Val Loss: 0.5857
Epoch 6/100, Loss: 0.5381, Acc: 0.7301, Val Loss: 0.6408, Val Acc: 0.6288
Epoch 7/100, Loss: 0.5355, Acc: 0.7362, Val Loss: 0.6026, Val Acc: 0.6649
Epoch 8/100, Loss: 0.5279, Acc: 0.7393, Val Loss: 0.6894, Val Acc: 0.5956
Epoch 9/100, Loss: 0.5333, Acc: 0.7369, Val Loss: 0.5514, Val Acc: 0.7502
Mejor modelo guardado con Val Loss: 0.5514
Epoch 10/100, Loss: 0.5320, Acc: 0.7350, Val Loss: 0.5642, Val Acc: 0.7336
Epoch 11/100, Loss: 0.5274, Acc: 0.7364, Val Loss: 0.6509, Val Acc: 0.6328
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5216, Acc: 0.7474, Val Loss: 0.5428, Val Acc: 0.7697
Mejor modelo guardado con Val Loss: 0.5428
Epoch 13/100, Loss: 0.5202, Acc: 0.7454, Val Loss: 0.5531, Val Acc: 0.7339
Epoch 14/100, Loss: 0.5170, Acc: 0.7503, Val Loss: 0.5627, Val Acc: 0.7122
Epoch 15/100, Loss: 0.5155, Acc: 0.7494, Val Loss: 0.5593, Val Acc: 0.7310
Epoch 16/100, Loss: 0.5124, Acc: 0.7506, Val Loss: 0.5810, Val Acc: 0.6930
Epoch 17/100, Loss: 0.5103, Acc: 0.7507, Val Loss: 0.5605, Val Acc: 0.7697
Epoch 18/100, Loss: 0.5092, Acc: 0.7541, Val Loss: 0.5712, Val Acc: 0.7007
Epoch 19/100, Loss: 0.5084, Acc: 0.7512, Val Loss: 0.5538, Val Acc: 0.7343
Epoch 20/100, Loss: 0.5090, Acc: 0.7477, Val Loss: 0.5325, Val Acc: 0.7565
Mejor modelo guardado con Val Loss: 0.5325
Epoch 21/100, Loss: 0.5072, Acc: 0.7501, Val Loss: 0.5555, Val Acc: 0.7775
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5019, Acc: 0.7564, Val Loss: 0.5250, Val Acc: 0.7697
Mejor modelo guardado con Val Loss: 0.5250
Epoch 23/100, Loss: 0.5032, Acc: 0.7550, Val Loss: 0.5542, Val Acc: 0.7384
Epoch 24/100, Loss: 0.5002, Acc: 0.7575, Val Loss: 0.5412, Val Acc: 0.7395
Epoch 25/100, Loss: 0.5006, Acc: 0.7562, Val Loss: 0.5448, Val Acc: 0.7428
Epoch 26/100, Loss: 0.5030, Acc: 0.7540, Val Loss: 0.5526, Val Acc: 0.7328
Epoch 27/100, Loss: 0.4992, Acc: 0.7576, Val Loss: 0.5562, Val Acc: 0.7325
Epoch 28/100, Loss: 0.4982, Acc: 0.7578, Val Loss: 0.5438, Val Acc: 0.7428
Epoch 29/100, Loss: 0.4974, Acc: 0.7598, Val Loss: 0.5718, Val Acc: 0.7041
Epoch 30/100, Loss: 0.4999, Acc: 0.7576, Val Loss: 0.5734, Val Acc: 0.7196
Epoch 31/100, Loss: 0.4965, Acc: 0.7598, Val Loss: 0.5579, Val Acc: 0.7240
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4944, Acc: 0.7600, Val Loss: 0.5324, Val Acc: 0.7601
Epoch 33/100, Loss: 0.4933, Acc: 0.7604, Val Loss: 0.5493, Val Acc: 0.7376
Epoch 34/100, Loss: 0.4935, Acc: 0.7604, Val Loss: 0.5567, Val Acc: 0.7236
Epoch 35/100, Loss: 0.4928, Acc: 0.7608, Val Loss: 0.5447, Val Acc: 0.7476
Epoch 36/100, Loss: 0.4934, Acc: 0.7603, Val Loss: 0.5379, Val Acc: 0.7487
Epoch 37/100, Loss: 0.4924, Acc: 0.7614, Val Loss: 0.5588, Val Acc: 0.7225
Epoch 38/100, Loss: 0.4922, Acc: 0.7603, Val Loss: 0.5499, Val Acc: 0.7358
Epoch 39/100, Loss: 0.4926, Acc: 0.7599, Val Loss: 0.5530, Val Acc: 0.7384
Epoch 40/100, Loss: 0.4908, Acc: 0.7633, Val Loss: 0.5428, Val Acc: 0.7417
Epoch 41/100, Loss: 0.4913, Acc: 0.7629, Val Loss: 0.5478, Val Acc: 0.7439
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4901, Acc: 0.7625, Val Loss: 0.5375, Val Acc: 0.7631
Epoch 43/100, Loss: 0.4902, Acc: 0.7600, Val Loss: 0.5461, Val Acc: 0.7435
Epoch 44/100, Loss: 0.4896, Acc: 0.7599, Val Loss: 0.5561, Val Acc: 0.7266
Epoch 45/100, Loss: 0.4895, Acc: 0.7613, Val Loss: 0.5575, Val Acc: 0.7247
Epoch 46/100, Loss: 0.4897, Acc: 0.7638, Val Loss: 0.5473, Val Acc: 0.7410
Epoch 47/100, Loss: 0.4896, Acc: 0.7615, Val Loss: 0.5485, Val Acc: 0.7432
Epoch 48/100, Loss: 0.4894, Acc: 0.7623, Val Loss: 0.5503, Val Acc: 0.7321
Epoch 49/100, Loss: 0.4890, Acc: 0.7639, Val Loss: 0.5434, Val Acc: 0.7465
Epoch 50/100, Loss: 0.4890, Acc: 0.7633, Val Loss: 0.5555, Val Acc: 0.7266
Epoch 51/100, Loss: 0.4890, Acc: 0.7626, Val Loss: 0.5410, Val Acc: 0.7446
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4882, Acc: 0.7626, Val Loss: 0.5374, Val Acc: 0.7620
Epoch 53/100, Loss: 0.4880, Acc: 0.7617, Val Loss: 0.5546, Val Acc: 0.7273
Epoch 54/100, Loss: 0.4879, Acc: 0.7638, Val Loss: 0.5376, Val Acc: 0.7601
Epoch 55/100, Loss: 0.4880, Acc: 0.7621, Val Loss: 0.5330, Val Acc: 0.7546
Epoch 56/100, Loss: 0.4861, Acc: 0.7635, Val Loss: 0.5361, Val Acc: 0.7476
Epoch 57/100, Loss: 0.4856, Acc: 0.7636, Val Loss: 0.5398, Val Acc: 0.7443
Epoch 58/100, Loss: 0.4851, Acc: 0.7637, Val Loss: 0.5323, Val Acc: 0.7498
Epoch 59/100, Loss: 0.4852, Acc: 0.7645, Val Loss: 0.5320, Val Acc: 0.7517
Epoch 60/100, Loss: 0.4852, Acc: 0.7636, Val Loss: 0.5304, Val Acc: 0.7550
Epoch 61/100, Loss: 0.4850, Acc: 0.7634, Val Loss: 0.5414, Val Acc: 0.7443
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4846, Acc: 0.7636, Val Loss: 0.5384, Val Acc: 0.7446
Epoch 63/100, Loss: 0.4844, Acc: 0.7638, Val Loss: 0.5327, Val Acc: 0.7524
Epoch 64/100, Loss: 0.4844, Acc: 0.7632, Val Loss: 0.5395, Val Acc: 0.7435
Epoch 65/100, Loss: 0.4844, Acc: 0.7634, Val Loss: 0.5344, Val Acc: 0.7498
Epoch 66/100, Loss: 0.4843, Acc: 0.7638, Val Loss: 0.5371, Val Acc: 0.7461
Epoch 67/100, Loss: 0.4843, Acc: 0.7636, Val Loss: 0.5354, Val Acc: 0.7480
Epoch 68/100, Loss: 0.4842, Acc: 0.7638, Val Loss: 0.5339, Val Acc: 0.7502
Epoch 69/100, Loss: 0.4840, Acc: 0.7636, Val Loss: 0.5345, Val Acc: 0.7498
Epoch 70/100, Loss: 0.4840, Acc: 0.7646, Val Loss: 0.5293, Val Acc: 0.7587
Epoch 71/100, Loss: 0.4840, Acc: 0.7631, Val Loss: 0.5335, Val Acc: 0.7509
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4838, Acc: 0.7644, Val Loss: 0.5348, Val Acc: 0.7494
Epoch 73/100, Loss: 0.4837, Acc: 0.7642, Val Loss: 0.5321, Val Acc: 0.7531
Epoch 74/100, Loss: 0.4838, Acc: 0.7644, Val Loss: 0.5363, Val Acc: 0.7487
Epoch 75/100, Loss: 0.4836, Acc: 0.7645, Val Loss: 0.5426, Val Acc: 0.7432
Epoch 76/100, Loss: 0.4838, Acc: 0.7642, Val Loss: 0.5367, Val Acc: 0.7450
Epoch 77/100, Loss: 0.4836, Acc: 0.7640, Val Loss: 0.5327, Val Acc: 0.7509
Epoch 78/100, Loss: 0.4832, Acc: 0.7638, Val Loss: 0.5272, Val Acc: 0.7531
Epoch 79/100, Loss: 0.4831, Acc: 0.7642, Val Loss: 0.5283, Val Acc: 0.7513
Epoch 80/100, Loss: 0.4829, Acc: 0.7640, Val Loss: 0.5308, Val Acc: 0.7461
Epoch 81/100, Loss: 0.4829, Acc: 0.7646, Val Loss: 0.5287, Val Acc: 0.7494
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4829, Acc: 0.7647, Val Loss: 0.5260, Val Acc: 0.7531
Epoch 83/100, Loss: 0.4829, Acc: 0.7651, Val Loss: 0.5284, Val Acc: 0.7502
Epoch 84/100, Loss: 0.4828, Acc: 0.7650, Val Loss: 0.5272, Val Acc: 0.7520
Epoch 85/100, Loss: 0.4827, Acc: 0.7644, Val Loss: 0.5267, Val Acc: 0.7513
Epoch 86/100, Loss: 0.4828, Acc: 0.7643, Val Loss: 0.5281, Val Acc: 0.7502
Epoch 87/100, Loss: 0.4826, Acc: 0.7651, Val Loss: 0.5268, Val Acc: 0.7520
Epoch 88/100, Loss: 0.4826, Acc: 0.7644, Val Loss: 0.5256, Val Acc: 0.7539
Epoch 89/100, Loss: 0.4825, Acc: 0.7647, Val Loss: 0.5312, Val Acc: 0.7450
Epoch 90/100, Loss: 0.4826, Acc: 0.7649, Val Loss: 0.5298, Val Acc: 0.7465
Epoch 91/100, Loss: 0.4826, Acc: 0.7646, Val Loss: 0.5281, Val Acc: 0.7491
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4825, Acc: 0.7649, Val Loss: 0.5290, Val Acc: 0.7494
Epoch 93/100, Loss: 0.4825, Acc: 0.7645, Val Loss: 0.5267, Val Acc: 0.7520
Epoch 94/100, Loss: 0.4825, Acc: 0.7642, Val Loss: 0.5286, Val Acc: 0.7491
Epoch 95/100, Loss: 0.4825, Acc: 0.7646, Val Loss: 0.5260, Val Acc: 0.7524
Epoch 96/100, Loss: 0.4824, Acc: 0.7653, Val Loss: 0.5284, Val Acc: 0.7480
Epoch 97/100, Loss: 0.4824, Acc: 0.7645, Val Loss: 0.5251, Val Acc: 0.7542
Epoch 98/100, Loss: 0.4823, Acc: 0.7637, Val Loss: 0.5234, Val Acc: 0.7572
Mejor modelo guardado con Val Loss: 0.5234
Epoch 99/100, Loss: 0.4822, Acc: 0.7641, Val Loss: 0.5275, Val Acc: 0.7513
Epoch 100/100, Loss: 0.4822, Acc: 0.7649, Val Loss: 0.5283, Val Acc: 0.7506

##############################
Resultados para principal:  067  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11 
 {'training': [0.4822398564523804, 0.7648574057037718, 0.8, 0.7057090239410682, 0.7499021526418786], 'validate': [0.5282553243775701, 0.7505535055350554, 0.7047387606318347, 0.8592592592592593, 0.774365821094793], 'test': [0.561646118057224, 0.7064896755162242, 0.8485456369107321, 0.5005917159763313, 0.6296985485671753]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  124  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  124  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  124  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6345, Acc: 0.7402, Val Loss: 0.6552, Val Acc: 0.5904
Mejor modelo guardado con Val Loss: 0.6552
Epoch 2/100, Loss: 0.5400, Acc: 0.8138, Val Loss: 0.6428, Val Acc: 0.6133
Mejor modelo guardado con Val Loss: 0.6428
Epoch 3/100, Loss: 0.4605, Acc: 0.8360, Val Loss: 0.5696, Val Acc: 0.7063
Mejor modelo guardado con Val Loss: 0.5696
Epoch 4/100, Loss: 0.4128, Acc: 0.8437, Val Loss: 0.5351, Val Acc: 0.7354
Mejor modelo guardado con Val Loss: 0.5351
Epoch 5/100, Loss: 0.3878, Acc: 0.8493, Val Loss: 0.6390, Val Acc: 0.6362
Epoch 6/100, Loss: 0.3718, Acc: 0.8496, Val Loss: 0.5347, Val Acc: 0.7151
Mejor modelo guardado con Val Loss: 0.5347
Epoch 7/100, Loss: 0.3673, Acc: 0.8527, Val Loss: 0.5142, Val Acc: 0.7487
Mejor modelo guardado con Val Loss: 0.5142
Epoch 8/100, Loss: 0.3454, Acc: 0.8638, Val Loss: 0.5905, Val Acc: 0.7044
Epoch 9/100, Loss: 0.3469, Acc: 0.8604, Val Loss: 0.5956, Val Acc: 0.6727
Epoch 10/100, Loss: 0.3392, Acc: 0.8617, Val Loss: 0.5160, Val Acc: 0.7576
Epoch 11/100, Loss: 0.3599, Acc: 0.8490, Val Loss: 0.5244, Val Acc: 0.7542
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.3438, Acc: 0.8617, Val Loss: 0.5724, Val Acc: 0.7339
Epoch 13/100, Loss: 0.3366, Acc: 0.8649, Val Loss: 0.6724, Val Acc: 0.6716
Epoch 14/100, Loss: 0.3346, Acc: 0.8638, Val Loss: 0.5597, Val Acc: 0.7376
Epoch 15/100, Loss: 0.3360, Acc: 0.8628, Val Loss: 0.5579, Val Acc: 0.7151
Epoch 16/100, Loss: 0.3340, Acc: 0.8614, Val Loss: 0.6417, Val Acc: 0.6882
Epoch 17/100, Loss: 0.3306, Acc: 0.8649, Val Loss: 0.6271, Val Acc: 0.7026
Epoch 18/100, Loss: 0.3321, Acc: 0.8642, Val Loss: 0.6915, Val Acc: 0.6446
Epoch 19/100, Loss: 0.3290, Acc: 0.8657, Val Loss: 0.6059, Val Acc: 0.7011
Epoch 20/100, Loss: 0.3206, Acc: 0.8721, Val Loss: 0.5502, Val Acc: 0.7432
Epoch 21/100, Loss: 0.3214, Acc: 0.8682, Val Loss: 0.6016, Val Acc: 0.7030
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3165, Acc: 0.8717, Val Loss: 0.6449, Val Acc: 0.6797
Epoch 23/100, Loss: 0.3140, Acc: 0.8750, Val Loss: 0.5834, Val Acc: 0.7251
Epoch 24/100, Loss: 0.3143, Acc: 0.8732, Val Loss: 0.5856, Val Acc: 0.7052
Epoch 25/100, Loss: 0.3163, Acc: 0.8729, Val Loss: 0.6603, Val Acc: 0.6664
Epoch 26/100, Loss: 0.3133, Acc: 0.8775, Val Loss: 0.7255, Val Acc: 0.6594
Epoch 27/100, Loss: 0.3140, Acc: 0.8735, Val Loss: 0.6371, Val Acc: 0.6738
Epoch 28/100, Loss: 0.3118, Acc: 0.8735, Val Loss: 0.7040, Val Acc: 0.6649
Epoch 29/100, Loss: 0.3114, Acc: 0.8745, Val Loss: 0.6503, Val Acc: 0.6808
Epoch 30/100, Loss: 0.3065, Acc: 0.8762, Val Loss: 0.5865, Val Acc: 0.7207
Epoch 31/100, Loss: 0.3071, Acc: 0.8751, Val Loss: 0.6002, Val Acc: 0.7107
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3029, Acc: 0.8782, Val Loss: 0.5896, Val Acc: 0.7218
Epoch 33/100, Loss: 0.3014, Acc: 0.8822, Val Loss: 0.6120, Val Acc: 0.7114
Epoch 34/100, Loss: 0.3018, Acc: 0.8792, Val Loss: 0.6856, Val Acc: 0.6609
Epoch 35/100, Loss: 0.3011, Acc: 0.8788, Val Loss: 0.5854, Val Acc: 0.7236
Epoch 36/100, Loss: 0.3007, Acc: 0.8798, Val Loss: 0.6520, Val Acc: 0.6756
Epoch 37/100, Loss: 0.3015, Acc: 0.8784, Val Loss: 0.5868, Val Acc: 0.7284
Epoch 38/100, Loss: 0.2991, Acc: 0.8813, Val Loss: 0.6174, Val Acc: 0.7052
Epoch 39/100, Loss: 0.2985, Acc: 0.8799, Val Loss: 0.5842, Val Acc: 0.7295
Epoch 40/100, Loss: 0.3004, Acc: 0.8805, Val Loss: 0.5790, Val Acc: 0.7387
Epoch 41/100, Loss: 0.3008, Acc: 0.8792, Val Loss: 0.5952, Val Acc: 0.7125
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.2962, Acc: 0.8824, Val Loss: 0.6284, Val Acc: 0.6952
Epoch 43/100, Loss: 0.2959, Acc: 0.8821, Val Loss: 0.6309, Val Acc: 0.7018
Epoch 44/100, Loss: 0.2954, Acc: 0.8825, Val Loss: 0.6337, Val Acc: 0.6919
Epoch 45/100, Loss: 0.2958, Acc: 0.8819, Val Loss: 0.6608, Val Acc: 0.6875
Epoch 46/100, Loss: 0.2949, Acc: 0.8833, Val Loss: 0.6301, Val Acc: 0.7033
Epoch 47/100, Loss: 0.2962, Acc: 0.8838, Val Loss: 0.6309, Val Acc: 0.6945
Epoch 48/100, Loss: 0.2941, Acc: 0.8831, Val Loss: 0.6024, Val Acc: 0.7196
Epoch 49/100, Loss: 0.2945, Acc: 0.8814, Val Loss: 0.6123, Val Acc: 0.6993
Epoch 50/100, Loss: 0.2942, Acc: 0.8828, Val Loss: 0.6062, Val Acc: 0.7159
Epoch 51/100, Loss: 0.2938, Acc: 0.8842, Val Loss: 0.6193, Val Acc: 0.7096
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.2929, Acc: 0.8832, Val Loss: 0.6188, Val Acc: 0.7077
Epoch 53/100, Loss: 0.2934, Acc: 0.8826, Val Loss: 0.6416, Val Acc: 0.6908
Epoch 54/100, Loss: 0.2924, Acc: 0.8842, Val Loss: 0.6049, Val Acc: 0.7125
Epoch 55/100, Loss: 0.2920, Acc: 0.8839, Val Loss: 0.6038, Val Acc: 0.7144
Epoch 56/100, Loss: 0.2922, Acc: 0.8843, Val Loss: 0.6328, Val Acc: 0.6978
Epoch 57/100, Loss: 0.2921, Acc: 0.8839, Val Loss: 0.5792, Val Acc: 0.7240
Epoch 58/100, Loss: 0.2920, Acc: 0.8839, Val Loss: 0.6189, Val Acc: 0.7059
Epoch 59/100, Loss: 0.2922, Acc: 0.8841, Val Loss: 0.6214, Val Acc: 0.7055
Epoch 60/100, Loss: 0.2915, Acc: 0.8850, Val Loss: 0.6098, Val Acc: 0.7089
Epoch 61/100, Loss: 0.2910, Acc: 0.8864, Val Loss: 0.6098, Val Acc: 0.7118
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.2911, Acc: 0.8852, Val Loss: 0.6161, Val Acc: 0.7085
Epoch 63/100, Loss: 0.2911, Acc: 0.8845, Val Loss: 0.6076, Val Acc: 0.7133
Epoch 64/100, Loss: 0.2908, Acc: 0.8854, Val Loss: 0.5864, Val Acc: 0.7262
Epoch 65/100, Loss: 0.2910, Acc: 0.8846, Val Loss: 0.5934, Val Acc: 0.7185
Epoch 66/100, Loss: 0.2905, Acc: 0.8867, Val Loss: 0.5997, Val Acc: 0.7166
Epoch 67/100, Loss: 0.2905, Acc: 0.8852, Val Loss: 0.6056, Val Acc: 0.7125
Epoch 68/100, Loss: 0.2905, Acc: 0.8845, Val Loss: 0.6120, Val Acc: 0.7096
Epoch 69/100, Loss: 0.2905, Acc: 0.8853, Val Loss: 0.6046, Val Acc: 0.7144
Epoch 70/100, Loss: 0.2901, Acc: 0.8847, Val Loss: 0.6139, Val Acc: 0.7107
Epoch 71/100, Loss: 0.2903, Acc: 0.8846, Val Loss: 0.5895, Val Acc: 0.7244
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.2896, Acc: 0.8864, Val Loss: 0.6209, Val Acc: 0.7044
Epoch 73/100, Loss: 0.2900, Acc: 0.8850, Val Loss: 0.6073, Val Acc: 0.7133
Epoch 74/100, Loss: 0.2899, Acc: 0.8841, Val Loss: 0.6151, Val Acc: 0.7100
Epoch 75/100, Loss: 0.2900, Acc: 0.8859, Val Loss: 0.6168, Val Acc: 0.7089
Epoch 76/100, Loss: 0.2898, Acc: 0.8856, Val Loss: 0.6235, Val Acc: 0.7074
Epoch 77/100, Loss: 0.2898, Acc: 0.8856, Val Loss: 0.6035, Val Acc: 0.7166
Epoch 78/100, Loss: 0.2899, Acc: 0.8853, Val Loss: 0.6158, Val Acc: 0.7096
Epoch 79/100, Loss: 0.2898, Acc: 0.8852, Val Loss: 0.6031, Val Acc: 0.7159
Epoch 80/100, Loss: 0.2897, Acc: 0.8857, Val Loss: 0.5964, Val Acc: 0.7203
Epoch 81/100, Loss: 0.2896, Acc: 0.8854, Val Loss: 0.6095, Val Acc: 0.7125
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.2896, Acc: 0.8855, Val Loss: 0.6246, Val Acc: 0.7059
Epoch 83/100, Loss: 0.2893, Acc: 0.8867, Val Loss: 0.6005, Val Acc: 0.7162
Epoch 84/100, Loss: 0.2896, Acc: 0.8862, Val Loss: 0.6148, Val Acc: 0.7103
Epoch 85/100, Loss: 0.2894, Acc: 0.8857, Val Loss: 0.6200, Val Acc: 0.7059
Epoch 86/100, Loss: 0.2894, Acc: 0.8848, Val Loss: 0.6176, Val Acc: 0.7085
Epoch 87/100, Loss: 0.2893, Acc: 0.8850, Val Loss: 0.6072, Val Acc: 0.7122
Epoch 88/100, Loss: 0.2892, Acc: 0.8847, Val Loss: 0.6319, Val Acc: 0.7018
Epoch 89/100, Loss: 0.2894, Acc: 0.8849, Val Loss: 0.6104, Val Acc: 0.7129
Epoch 90/100, Loss: 0.2893, Acc: 0.8850, Val Loss: 0.6150, Val Acc: 0.7100
Epoch 91/100, Loss: 0.2893, Acc: 0.8848, Val Loss: 0.6046, Val Acc: 0.7144
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.2892, Acc: 0.8855, Val Loss: 0.6138, Val Acc: 0.7111
Epoch 93/100, Loss: 0.2892, Acc: 0.8857, Val Loss: 0.6164, Val Acc: 0.7096
Epoch 94/100, Loss: 0.2890, Acc: 0.8856, Val Loss: 0.6199, Val Acc: 0.7074
Epoch 95/100, Loss: 0.2891, Acc: 0.8853, Val Loss: 0.6187, Val Acc: 0.7070
Epoch 96/100, Loss: 0.2892, Acc: 0.8848, Val Loss: 0.6189, Val Acc: 0.7074
Epoch 97/100, Loss: 0.2891, Acc: 0.8860, Val Loss: 0.6115, Val Acc: 0.7114
Epoch 98/100, Loss: 0.2888, Acc: 0.8862, Val Loss: 0.6018, Val Acc: 0.7159
Epoch 99/100, Loss: 0.2889, Acc: 0.8858, Val Loss: 0.6082, Val Acc: 0.7125
Epoch 100/100, Loss: 0.2890, Acc: 0.8864, Val Loss: 0.6067, Val Acc: 0.7122

##############################
Resultados para principal:  124  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11 
 {'training': [0.2890300487693341, 0.8863845446182153, 0.8605810555269039, 0.921915285451197, 0.8901929403396461], 'validate': [0.6066685814497083, 0.7121771217712177, 0.6595744680851063, 0.8725925925925926, 0.7512755102040817], 'test': [0.7280068122693952, 0.6286135693215339, 0.5823461979365686, 0.901775147928994, 0.7076851636870212]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  010  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  010  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  010  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.5894, Acc: 0.7134, Val Loss: 0.6640, Val Acc: 0.6137
Mejor modelo guardado con Val Loss: 0.6640
Epoch 2/100, Loss: 0.5437, Acc: 0.7325, Val Loss: 0.6449, Val Acc: 0.6661
Mejor modelo guardado con Val Loss: 0.6449
Epoch 3/100, Loss: 0.5277, Acc: 0.7379, Val Loss: 0.6978, Val Acc: 0.5483
Epoch 4/100, Loss: 0.5180, Acc: 0.7406, Val Loss: 0.6781, Val Acc: 0.6413
Epoch 5/100, Loss: 0.5166, Acc: 0.7420, Val Loss: 0.6968, Val Acc: 0.5967
Epoch 6/100, Loss: 0.5015, Acc: 0.7534, Val Loss: 0.7082, Val Acc: 0.6181
Epoch 7/100, Loss: 0.5042, Acc: 0.7537, Val Loss: 0.7157, Val Acc: 0.6491
Epoch 8/100, Loss: 0.4996, Acc: 0.7551, Val Loss: 0.7000, Val Acc: 0.6749
Epoch 9/100, Loss: 0.4973, Acc: 0.7544, Val Loss: 0.6943, Val Acc: 0.6074
Epoch 10/100, Loss: 0.4945, Acc: 0.7535, Val Loss: 0.7297, Val Acc: 0.6384
Epoch 11/100, Loss: 0.4919, Acc: 0.7586, Val Loss: 0.7244, Val Acc: 0.6181
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4827, Acc: 0.7648, Val Loss: 0.7708, Val Acc: 0.6376
Epoch 13/100, Loss: 0.4785, Acc: 0.7704, Val Loss: 0.7421, Val Acc: 0.6598
Epoch 14/100, Loss: 0.4787, Acc: 0.7697, Val Loss: 0.8125, Val Acc: 0.6269
Epoch 15/100, Loss: 0.4761, Acc: 0.7722, Val Loss: 0.7565, Val Acc: 0.6609
Epoch 16/100, Loss: 0.4765, Acc: 0.7717, Val Loss: 0.7300, Val Acc: 0.6712
Epoch 17/100, Loss: 0.4776, Acc: 0.7688, Val Loss: 0.7816, Val Acc: 0.6428
Epoch 18/100, Loss: 0.4743, Acc: 0.7741, Val Loss: 0.8320, Val Acc: 0.6708
Epoch 19/100, Loss: 0.4776, Acc: 0.7693, Val Loss: 0.8451, Val Acc: 0.6657
Epoch 20/100, Loss: 0.4731, Acc: 0.7730, Val Loss: 0.7819, Val Acc: 0.6679
Epoch 21/100, Loss: 0.4723, Acc: 0.7758, Val Loss: 0.8246, Val Acc: 0.6697
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4683, Acc: 0.7766, Val Loss: 0.8015, Val Acc: 0.6646
Epoch 23/100, Loss: 0.4674, Acc: 0.7767, Val Loss: 0.7655, Val Acc: 0.6635
Epoch 24/100, Loss: 0.4657, Acc: 0.7793, Val Loss: 0.8754, Val Acc: 0.6620
Epoch 25/100, Loss: 0.4679, Acc: 0.7765, Val Loss: 0.7700, Val Acc: 0.6661
Epoch 26/100, Loss: 0.4657, Acc: 0.7783, Val Loss: 0.8136, Val Acc: 0.6661
Epoch 27/100, Loss: 0.4648, Acc: 0.7779, Val Loss: 0.7911, Val Acc: 0.6661
Epoch 28/100, Loss: 0.4651, Acc: 0.7787, Val Loss: 0.8165, Val Acc: 0.6672
Epoch 29/100, Loss: 0.4671, Acc: 0.7758, Val Loss: 0.8948, Val Acc: 0.6594
Epoch 30/100, Loss: 0.4654, Acc: 0.7785, Val Loss: 0.8851, Val Acc: 0.6642
Epoch 31/100, Loss: 0.4650, Acc: 0.7773, Val Loss: 0.8691, Val Acc: 0.6627
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4630, Acc: 0.7781, Val Loss: 0.8105, Val Acc: 0.6686
Epoch 33/100, Loss: 0.4624, Acc: 0.7795, Val Loss: 0.7706, Val Acc: 0.6679
Epoch 34/100, Loss: 0.4618, Acc: 0.7802, Val Loss: 0.8437, Val Acc: 0.6613
Epoch 35/100, Loss: 0.4612, Acc: 0.7814, Val Loss: 0.8467, Val Acc: 0.6657
Epoch 36/100, Loss: 0.4606, Acc: 0.7810, Val Loss: 0.8482, Val Acc: 0.6649
Epoch 37/100, Loss: 0.4612, Acc: 0.7804, Val Loss: 0.8679, Val Acc: 0.6657
Epoch 38/100, Loss: 0.4614, Acc: 0.7815, Val Loss: 0.8194, Val Acc: 0.6705
Epoch 39/100, Loss: 0.4610, Acc: 0.7811, Val Loss: 0.8209, Val Acc: 0.6701
Epoch 40/100, Loss: 0.4601, Acc: 0.7813, Val Loss: 0.8061, Val Acc: 0.6664
Epoch 41/100, Loss: 0.4599, Acc: 0.7821, Val Loss: 0.8397, Val Acc: 0.6609
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4593, Acc: 0.7830, Val Loss: 0.8379, Val Acc: 0.6601
Epoch 43/100, Loss: 0.4589, Acc: 0.7822, Val Loss: 0.8543, Val Acc: 0.6646
Epoch 44/100, Loss: 0.4591, Acc: 0.7832, Val Loss: 0.8070, Val Acc: 0.6635
Epoch 45/100, Loss: 0.4586, Acc: 0.7810, Val Loss: 0.8310, Val Acc: 0.6642
Epoch 46/100, Loss: 0.4593, Acc: 0.7826, Val Loss: 0.8391, Val Acc: 0.6635
Epoch 47/100, Loss: 0.4579, Acc: 0.7819, Val Loss: 0.8501, Val Acc: 0.6620
Epoch 48/100, Loss: 0.4580, Acc: 0.7822, Val Loss: 0.8498, Val Acc: 0.6635
Epoch 49/100, Loss: 0.4578, Acc: 0.7819, Val Loss: 0.8658, Val Acc: 0.6620
Epoch 50/100, Loss: 0.4573, Acc: 0.7827, Val Loss: 0.8016, Val Acc: 0.6646
Epoch 51/100, Loss: 0.4566, Acc: 0.7830, Val Loss: 0.8338, Val Acc: 0.6635
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4558, Acc: 0.7833, Val Loss: 0.8187, Val Acc: 0.6609
Epoch 53/100, Loss: 0.4555, Acc: 0.7836, Val Loss: 0.8485, Val Acc: 0.6572
Epoch 54/100, Loss: 0.4554, Acc: 0.7830, Val Loss: 0.8455, Val Acc: 0.6594
Epoch 55/100, Loss: 0.4552, Acc: 0.7838, Val Loss: 0.8308, Val Acc: 0.6646
Epoch 56/100, Loss: 0.4552, Acc: 0.7843, Val Loss: 0.8314, Val Acc: 0.6635
Epoch 57/100, Loss: 0.4548, Acc: 0.7832, Val Loss: 0.8538, Val Acc: 0.6620
Epoch 58/100, Loss: 0.4547, Acc: 0.7832, Val Loss: 0.8446, Val Acc: 0.6609
Epoch 59/100, Loss: 0.4545, Acc: 0.7841, Val Loss: 0.8536, Val Acc: 0.6616
Epoch 60/100, Loss: 0.4545, Acc: 0.7834, Val Loss: 0.8480, Val Acc: 0.6601
Epoch 61/100, Loss: 0.4541, Acc: 0.7835, Val Loss: 0.8498, Val Acc: 0.6605
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4539, Acc: 0.7836, Val Loss: 0.8476, Val Acc: 0.6605
Epoch 63/100, Loss: 0.4538, Acc: 0.7850, Val Loss: 0.8453, Val Acc: 0.6613
Epoch 64/100, Loss: 0.4536, Acc: 0.7845, Val Loss: 0.8500, Val Acc: 0.6594
Epoch 65/100, Loss: 0.4537, Acc: 0.7843, Val Loss: 0.8507, Val Acc: 0.6594
Epoch 66/100, Loss: 0.4534, Acc: 0.7835, Val Loss: 0.8431, Val Acc: 0.6609
Epoch 67/100, Loss: 0.4535, Acc: 0.7839, Val Loss: 0.8563, Val Acc: 0.6598
Epoch 68/100, Loss: 0.4532, Acc: 0.7844, Val Loss: 0.8615, Val Acc: 0.6601
Epoch 69/100, Loss: 0.4532, Acc: 0.7845, Val Loss: 0.8562, Val Acc: 0.6583
Epoch 70/100, Loss: 0.4531, Acc: 0.7835, Val Loss: 0.8454, Val Acc: 0.6594
Epoch 71/100, Loss: 0.4530, Acc: 0.7848, Val Loss: 0.8599, Val Acc: 0.6605
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4530, Acc: 0.7842, Val Loss: 0.8540, Val Acc: 0.6605
Epoch 73/100, Loss: 0.4528, Acc: 0.7846, Val Loss: 0.8585, Val Acc: 0.6609
Epoch 74/100, Loss: 0.4528, Acc: 0.7842, Val Loss: 0.8529, Val Acc: 0.6613
Epoch 75/100, Loss: 0.4528, Acc: 0.7841, Val Loss: 0.8627, Val Acc: 0.6598
Epoch 76/100, Loss: 0.4526, Acc: 0.7836, Val Loss: 0.8510, Val Acc: 0.6598
Epoch 77/100, Loss: 0.4525, Acc: 0.7845, Val Loss: 0.8485, Val Acc: 0.6601
Epoch 78/100, Loss: 0.4524, Acc: 0.7846, Val Loss: 0.8555, Val Acc: 0.6601
Epoch 79/100, Loss: 0.4523, Acc: 0.7848, Val Loss: 0.8640, Val Acc: 0.6590
Epoch 80/100, Loss: 0.4522, Acc: 0.7847, Val Loss: 0.8626, Val Acc: 0.6598
Epoch 81/100, Loss: 0.4522, Acc: 0.7847, Val Loss: 0.8565, Val Acc: 0.6609
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4521, Acc: 0.7850, Val Loss: 0.8468, Val Acc: 0.6598
Epoch 83/100, Loss: 0.4521, Acc: 0.7845, Val Loss: 0.8535, Val Acc: 0.6594
Epoch 84/100, Loss: 0.4519, Acc: 0.7851, Val Loss: 0.8537, Val Acc: 0.6598
Epoch 85/100, Loss: 0.4520, Acc: 0.7842, Val Loss: 0.8596, Val Acc: 0.6576
Epoch 86/100, Loss: 0.4518, Acc: 0.7847, Val Loss: 0.8443, Val Acc: 0.6616
Epoch 87/100, Loss: 0.4518, Acc: 0.7846, Val Loss: 0.8582, Val Acc: 0.6601
Epoch 88/100, Loss: 0.4517, Acc: 0.7848, Val Loss: 0.8581, Val Acc: 0.6572
Epoch 89/100, Loss: 0.4517, Acc: 0.7854, Val Loss: 0.8529, Val Acc: 0.6598
Epoch 90/100, Loss: 0.4516, Acc: 0.7846, Val Loss: 0.8533, Val Acc: 0.6579
Epoch 91/100, Loss: 0.4515, Acc: 0.7850, Val Loss: 0.8589, Val Acc: 0.6568
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4514, Acc: 0.7855, Val Loss: 0.8673, Val Acc: 0.6590
Epoch 93/100, Loss: 0.4514, Acc: 0.7851, Val Loss: 0.8556, Val Acc: 0.6576
Epoch 94/100, Loss: 0.4513, Acc: 0.7847, Val Loss: 0.8542, Val Acc: 0.6590
Epoch 95/100, Loss: 0.4512, Acc: 0.7845, Val Loss: 0.8484, Val Acc: 0.6594
Epoch 96/100, Loss: 0.4512, Acc: 0.7851, Val Loss: 0.8521, Val Acc: 0.6601
Epoch 97/100, Loss: 0.4511, Acc: 0.7852, Val Loss: 0.8634, Val Acc: 0.6601
Epoch 98/100, Loss: 0.4511, Acc: 0.7856, Val Loss: 0.8584, Val Acc: 0.6583
Epoch 99/100, Loss: 0.4509, Acc: 0.7847, Val Loss: 0.8589, Val Acc: 0.6605
Epoch 100/100, Loss: 0.4503, Acc: 0.7845, Val Loss: 0.8408, Val Acc: 0.6627

##############################
Resultados para principal:  010  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11 
 {'training': [0.45033955724829366, 0.7845446182152714, 0.7127894156560088, 0.9524861878453039, 0.8153870408324136], 'validate': [0.8407598772021228, 0.6627306273062731, 0.6778140293637847, 0.6155555555555555, 0.6451863354037267], 'test': [0.6343440199798008, 0.6669616519174041, 0.6288470372071658, 0.8100591715976332, 0.7080424101370572]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  009  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  009  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  009  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.3726, Acc: 0.9078, Val Loss: 0.2411, Val Acc: 0.9708
Mejor modelo guardado con Val Loss: 0.2411
Epoch 2/100, Loss: 0.2192, Acc: 0.9274, Val Loss: 0.1819, Val Acc: 0.9768
Mejor modelo guardado con Val Loss: 0.1819
Epoch 3/100, Loss: 0.1962, Acc: 0.9256, Val Loss: 0.0913, Val Acc: 0.9812
Mejor modelo guardado con Val Loss: 0.0913
Epoch 4/100, Loss: 0.1761, Acc: 0.9274, Val Loss: 0.1176, Val Acc: 0.9804
Epoch 5/100, Loss: 0.1661, Acc: 0.9335, Val Loss: 0.1058, Val Acc: 0.9749
Epoch 6/100, Loss: 0.1665, Acc: 0.9304, Val Loss: 0.1130, Val Acc: 0.9712
Epoch 7/100, Loss: 0.1574, Acc: 0.9358, Val Loss: 0.1017, Val Acc: 0.9771
Epoch 8/100, Loss: 0.1570, Acc: 0.9328, Val Loss: 0.0718, Val Acc: 0.9801
Mejor modelo guardado con Val Loss: 0.0718
Epoch 9/100, Loss: 0.1441, Acc: 0.9383, Val Loss: 0.1066, Val Acc: 0.9734
Epoch 10/100, Loss: 0.1434, Acc: 0.9415, Val Loss: 0.1198, Val Acc: 0.9598
Epoch 11/100, Loss: 0.1365, Acc: 0.9439, Val Loss: 0.0742, Val Acc: 0.9793
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.1267, Acc: 0.9483, Val Loss: 0.0692, Val Acc: 0.9838
Mejor modelo guardado con Val Loss: 0.0692
Epoch 13/100, Loss: 0.1203, Acc: 0.9509, Val Loss: 0.0703, Val Acc: 0.9812
Epoch 14/100, Loss: 0.1210, Acc: 0.9484, Val Loss: 0.0758, Val Acc: 0.9819
Epoch 15/100, Loss: 0.1219, Acc: 0.9493, Val Loss: 0.0689, Val Acc: 0.9845
Mejor modelo guardado con Val Loss: 0.0689
Epoch 16/100, Loss: 0.1198, Acc: 0.9497, Val Loss: 0.0698, Val Acc: 0.9790
Epoch 17/100, Loss: 0.1234, Acc: 0.9488, Val Loss: 0.0690, Val Acc: 0.9808
Epoch 18/100, Loss: 0.1196, Acc: 0.9492, Val Loss: 0.0683, Val Acc: 0.9830
Mejor modelo guardado con Val Loss: 0.0683
Epoch 19/100, Loss: 0.1198, Acc: 0.9523, Val Loss: 0.0668, Val Acc: 0.9823
Mejor modelo guardado con Val Loss: 0.0668
Epoch 20/100, Loss: 0.1164, Acc: 0.9540, Val Loss: 0.0644, Val Acc: 0.9804
Mejor modelo guardado con Val Loss: 0.0644
Epoch 21/100, Loss: 0.1163, Acc: 0.9538, Val Loss: 0.0736, Val Acc: 0.9782
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.1110, Acc: 0.9547, Val Loss: 0.0695, Val Acc: 0.9801
Epoch 23/100, Loss: 0.1081, Acc: 0.9571, Val Loss: 0.0597, Val Acc: 0.9849
Mejor modelo guardado con Val Loss: 0.0597
Epoch 24/100, Loss: 0.1110, Acc: 0.9555, Val Loss: 0.0647, Val Acc: 0.9838
Epoch 25/100, Loss: 0.1102, Acc: 0.9557, Val Loss: 0.0676, Val Acc: 0.9797
Epoch 26/100, Loss: 0.1069, Acc: 0.9558, Val Loss: 0.0648, Val Acc: 0.9815
Epoch 27/100, Loss: 0.1070, Acc: 0.9582, Val Loss: 0.0683, Val Acc: 0.9790
Epoch 28/100, Loss: 0.1034, Acc: 0.9594, Val Loss: 0.0679, Val Acc: 0.9841
Epoch 29/100, Loss: 0.1029, Acc: 0.9574, Val Loss: 0.0752, Val Acc: 0.9815
Epoch 30/100, Loss: 0.1038, Acc: 0.9580, Val Loss: 0.0624, Val Acc: 0.9830
Epoch 31/100, Loss: 0.1040, Acc: 0.9598, Val Loss: 0.0658, Val Acc: 0.9823
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.0994, Acc: 0.9615, Val Loss: 0.0696, Val Acc: 0.9823
Epoch 33/100, Loss: 0.0983, Acc: 0.9604, Val Loss: 0.0650, Val Acc: 0.9834
Epoch 34/100, Loss: 0.0981, Acc: 0.9603, Val Loss: 0.0712, Val Acc: 0.9801
Epoch 35/100, Loss: 0.0973, Acc: 0.9616, Val Loss: 0.0714, Val Acc: 0.9786
Epoch 36/100, Loss: 0.0974, Acc: 0.9607, Val Loss: 0.0741, Val Acc: 0.9801
Epoch 37/100, Loss: 0.0958, Acc: 0.9614, Val Loss: 0.0709, Val Acc: 0.9790
Epoch 38/100, Loss: 0.0946, Acc: 0.9615, Val Loss: 0.0703, Val Acc: 0.9779
Epoch 39/100, Loss: 0.0942, Acc: 0.9606, Val Loss: 0.0692, Val Acc: 0.9775
Epoch 40/100, Loss: 0.0920, Acc: 0.9623, Val Loss: 0.0598, Val Acc: 0.9849
Epoch 41/100, Loss: 0.0926, Acc: 0.9617, Val Loss: 0.0698, Val Acc: 0.9793
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.0900, Acc: 0.9636, Val Loss: 0.0649, Val Acc: 0.9808
Epoch 43/100, Loss: 0.0911, Acc: 0.9634, Val Loss: 0.0687, Val Acc: 0.9786
Epoch 44/100, Loss: 0.0900, Acc: 0.9628, Val Loss: 0.0629, Val Acc: 0.9830
Epoch 45/100, Loss: 0.0889, Acc: 0.9632, Val Loss: 0.0678, Val Acc: 0.9827
Epoch 46/100, Loss: 0.0895, Acc: 0.9628, Val Loss: 0.0667, Val Acc: 0.9793
Epoch 47/100, Loss: 0.0899, Acc: 0.9635, Val Loss: 0.0651, Val Acc: 0.9812
Epoch 48/100, Loss: 0.0896, Acc: 0.9619, Val Loss: 0.0633, Val Acc: 0.9830
Epoch 49/100, Loss: 0.0893, Acc: 0.9630, Val Loss: 0.0645, Val Acc: 0.9819
Epoch 50/100, Loss: 0.0886, Acc: 0.9646, Val Loss: 0.0675, Val Acc: 0.9790
Epoch 51/100, Loss: 0.0884, Acc: 0.9622, Val Loss: 0.0627, Val Acc: 0.9838
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.0879, Acc: 0.9642, Val Loss: 0.0636, Val Acc: 0.9827
Epoch 53/100, Loss: 0.0873, Acc: 0.9637, Val Loss: 0.0688, Val Acc: 0.9771
Epoch 54/100, Loss: 0.0876, Acc: 0.9632, Val Loss: 0.0658, Val Acc: 0.9790
Epoch 55/100, Loss: 0.0874, Acc: 0.9634, Val Loss: 0.0645, Val Acc: 0.9823
Epoch 56/100, Loss: 0.0869, Acc: 0.9646, Val Loss: 0.0655, Val Acc: 0.9801
Epoch 57/100, Loss: 0.0869, Acc: 0.9651, Val Loss: 0.0662, Val Acc: 0.9790
Epoch 58/100, Loss: 0.0870, Acc: 0.9656, Val Loss: 0.0652, Val Acc: 0.9819
Epoch 59/100, Loss: 0.0867, Acc: 0.9642, Val Loss: 0.0624, Val Acc: 0.9841
Epoch 60/100, Loss: 0.0864, Acc: 0.9647, Val Loss: 0.0654, Val Acc: 0.9812
Epoch 61/100, Loss: 0.0868, Acc: 0.9649, Val Loss: 0.0654, Val Acc: 0.9808
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.0859, Acc: 0.9651, Val Loss: 0.0636, Val Acc: 0.9834
Epoch 63/100, Loss: 0.0859, Acc: 0.9644, Val Loss: 0.0656, Val Acc: 0.9801
Epoch 64/100, Loss: 0.0859, Acc: 0.9655, Val Loss: 0.0662, Val Acc: 0.9797
Epoch 65/100, Loss: 0.0858, Acc: 0.9649, Val Loss: 0.0626, Val Acc: 0.9838
Epoch 66/100, Loss: 0.0858, Acc: 0.9651, Val Loss: 0.0652, Val Acc: 0.9801
Epoch 67/100, Loss: 0.0858, Acc: 0.9649, Val Loss: 0.0672, Val Acc: 0.9786
Epoch 68/100, Loss: 0.0857, Acc: 0.9649, Val Loss: 0.0663, Val Acc: 0.9804
Epoch 69/100, Loss: 0.0856, Acc: 0.9658, Val Loss: 0.0641, Val Acc: 0.9834
Epoch 70/100, Loss: 0.0855, Acc: 0.9654, Val Loss: 0.0657, Val Acc: 0.9797
Epoch 71/100, Loss: 0.0855, Acc: 0.9653, Val Loss: 0.0651, Val Acc: 0.9808
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.0852, Acc: 0.9654, Val Loss: 0.0650, Val Acc: 0.9801
Epoch 73/100, Loss: 0.0852, Acc: 0.9654, Val Loss: 0.0638, Val Acc: 0.9827
Epoch 74/100, Loss: 0.0850, Acc: 0.9652, Val Loss: 0.0658, Val Acc: 0.9801
Epoch 75/100, Loss: 0.0850, Acc: 0.9659, Val Loss: 0.0656, Val Acc: 0.9801
Epoch 76/100, Loss: 0.0849, Acc: 0.9655, Val Loss: 0.0649, Val Acc: 0.9808
Epoch 77/100, Loss: 0.0850, Acc: 0.9655, Val Loss: 0.0651, Val Acc: 0.9804
Epoch 78/100, Loss: 0.0850, Acc: 0.9650, Val Loss: 0.0652, Val Acc: 0.9801
Epoch 79/100, Loss: 0.0850, Acc: 0.9655, Val Loss: 0.0653, Val Acc: 0.9801
Epoch 80/100, Loss: 0.0850, Acc: 0.9649, Val Loss: 0.0660, Val Acc: 0.9797
Epoch 81/100, Loss: 0.0847, Acc: 0.9649, Val Loss: 0.0666, Val Acc: 0.9793
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.0848, Acc: 0.9655, Val Loss: 0.0645, Val Acc: 0.9823
Epoch 83/100, Loss: 0.0850, Acc: 0.9657, Val Loss: 0.0650, Val Acc: 0.9804
Epoch 84/100, Loss: 0.0847, Acc: 0.9661, Val Loss: 0.0657, Val Acc: 0.9797
Epoch 85/100, Loss: 0.0848, Acc: 0.9653, Val Loss: 0.0655, Val Acc: 0.9804
Epoch 86/100, Loss: 0.0846, Acc: 0.9652, Val Loss: 0.0655, Val Acc: 0.9797
Epoch 87/100, Loss: 0.0848, Acc: 0.9653, Val Loss: 0.0659, Val Acc: 0.9801
Epoch 88/100, Loss: 0.0847, Acc: 0.9655, Val Loss: 0.0646, Val Acc: 0.9804
Epoch 89/100, Loss: 0.0846, Acc: 0.9659, Val Loss: 0.0654, Val Acc: 0.9801
Epoch 90/100, Loss: 0.0845, Acc: 0.9655, Val Loss: 0.0660, Val Acc: 0.9797
Epoch 91/100, Loss: 0.0845, Acc: 0.9658, Val Loss: 0.0647, Val Acc: 0.9812
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.0844, Acc: 0.9659, Val Loss: 0.0647, Val Acc: 0.9812
Epoch 93/100, Loss: 0.0844, Acc: 0.9651, Val Loss: 0.0664, Val Acc: 0.9797
Epoch 94/100, Loss: 0.0843, Acc: 0.9661, Val Loss: 0.0640, Val Acc: 0.9827
Epoch 95/100, Loss: 0.0843, Acc: 0.9656, Val Loss: 0.0647, Val Acc: 0.9812
Epoch 96/100, Loss: 0.0843, Acc: 0.9659, Val Loss: 0.0644, Val Acc: 0.9808
Epoch 97/100, Loss: 0.0844, Acc: 0.9653, Val Loss: 0.0645, Val Acc: 0.9812
Epoch 98/100, Loss: 0.0843, Acc: 0.9654, Val Loss: 0.0645, Val Acc: 0.9812
Epoch 99/100, Loss: 0.0843, Acc: 0.9654, Val Loss: 0.0636, Val Acc: 0.9834
Epoch 100/100, Loss: 0.0842, Acc: 0.9659, Val Loss: 0.0649, Val Acc: 0.9804

##############################
Resultados para principal:  009  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11 
 {'training': [0.0841597903893426, 0.965869365225391, 0.956506045840101, 0.9760589318600368, 0.966183574879227], 'validate': [0.06494159046506379, 0.9804428044280443, 0.9800148038490007, 0.9807407407407407, 0.9803776379118845], 'test': [0.1162783509946235, 0.95929203539823, 0.9813895781637717, 0.936094674556213, 0.9582071471835252]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  118  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  118  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  118  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6881, Acc: 0.5534, Val Loss: 0.6791, Val Acc: 0.6520
Mejor modelo guardado con Val Loss: 0.6791
Epoch 2/100, Loss: 0.6791, Acc: 0.5897, Val Loss: 0.6621, Val Acc: 0.6959
Mejor modelo guardado con Val Loss: 0.6621
Epoch 3/100, Loss: 0.6705, Acc: 0.6184, Val Loss: 0.6586, Val Acc: 0.6797
Mejor modelo guardado con Val Loss: 0.6586
Epoch 4/100, Loss: 0.6634, Acc: 0.6262, Val Loss: 0.6344, Val Acc: 0.7022
Mejor modelo guardado con Val Loss: 0.6344
Epoch 5/100, Loss: 0.6556, Acc: 0.6312, Val Loss: 0.6285, Val Acc: 0.6915
Mejor modelo guardado con Val Loss: 0.6285
Epoch 6/100, Loss: 0.6490, Acc: 0.6331, Val Loss: 0.5973, Val Acc: 0.6841
Mejor modelo guardado con Val Loss: 0.5973
Epoch 7/100, Loss: 0.6353, Acc: 0.6432, Val Loss: 0.5881, Val Acc: 0.7125
Mejor modelo guardado con Val Loss: 0.5881
Epoch 8/100, Loss: 0.6285, Acc: 0.6465, Val Loss: 0.5611, Val Acc: 0.7542
Mejor modelo guardado con Val Loss: 0.5611
Epoch 9/100, Loss: 0.6290, Acc: 0.6454, Val Loss: 0.5450, Val Acc: 0.7745
Mejor modelo guardado con Val Loss: 0.5450
Epoch 10/100, Loss: 0.6243, Acc: 0.6487, Val Loss: 0.6108, Val Acc: 0.6306
Epoch 11/100, Loss: 0.6315, Acc: 0.6413, Val Loss: 0.5466, Val Acc: 0.7554
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6158, Acc: 0.6561, Val Loss: 0.5439, Val Acc: 0.7598
Mejor modelo guardado con Val Loss: 0.5439
Epoch 13/100, Loss: 0.6175, Acc: 0.6536, Val Loss: 0.5832, Val Acc: 0.7162
Epoch 14/100, Loss: 0.6145, Acc: 0.6553, Val Loss: 0.5342, Val Acc: 0.7594
Mejor modelo guardado con Val Loss: 0.5342
Epoch 15/100, Loss: 0.6162, Acc: 0.6538, Val Loss: 0.5404, Val Acc: 0.7572
Epoch 16/100, Loss: 0.6125, Acc: 0.6599, Val Loss: 0.5720, Val Acc: 0.7450
Epoch 17/100, Loss: 0.6135, Acc: 0.6582, Val Loss: 0.5399, Val Acc: 0.7657
Epoch 18/100, Loss: 0.6130, Acc: 0.6595, Val Loss: 0.5511, Val Acc: 0.7524
Epoch 19/100, Loss: 0.6112, Acc: 0.6594, Val Loss: 0.5320, Val Acc: 0.7764
Mejor modelo guardado con Val Loss: 0.5320
Epoch 20/100, Loss: 0.6103, Acc: 0.6575, Val Loss: 0.5426, Val Acc: 0.7638
Epoch 21/100, Loss: 0.6082, Acc: 0.6636, Val Loss: 0.5536, Val Acc: 0.7472
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6070, Acc: 0.6662, Val Loss: 0.5439, Val Acc: 0.7638
Epoch 23/100, Loss: 0.6067, Acc: 0.6680, Val Loss: 0.5478, Val Acc: 0.7568
Epoch 24/100, Loss: 0.6059, Acc: 0.6660, Val Loss: 0.5279, Val Acc: 0.7683
Mejor modelo guardado con Val Loss: 0.5279
Epoch 25/100, Loss: 0.6068, Acc: 0.6660, Val Loss: 0.5287, Val Acc: 0.7768
Epoch 26/100, Loss: 0.6057, Acc: 0.6661, Val Loss: 0.5263, Val Acc: 0.7863
Mejor modelo guardado con Val Loss: 0.5263
Epoch 27/100, Loss: 0.6048, Acc: 0.6676, Val Loss: 0.5236, Val Acc: 0.7882
Mejor modelo guardado con Val Loss: 0.5236
Epoch 28/100, Loss: 0.6052, Acc: 0.6658, Val Loss: 0.5558, Val Acc: 0.7572
Epoch 29/100, Loss: 0.6059, Acc: 0.6665, Val Loss: 0.5382, Val Acc: 0.7672
Epoch 30/100, Loss: 0.6047, Acc: 0.6690, Val Loss: 0.5424, Val Acc: 0.7605
Epoch 31/100, Loss: 0.6044, Acc: 0.6681, Val Loss: 0.5336, Val Acc: 0.7697
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6024, Acc: 0.6688, Val Loss: 0.5432, Val Acc: 0.7690
Epoch 33/100, Loss: 0.6023, Acc: 0.6697, Val Loss: 0.5361, Val Acc: 0.7708
Epoch 34/100, Loss: 0.6019, Acc: 0.6680, Val Loss: 0.5334, Val Acc: 0.7712
Epoch 35/100, Loss: 0.6019, Acc: 0.6681, Val Loss: 0.5444, Val Acc: 0.7620
Epoch 36/100, Loss: 0.6011, Acc: 0.6693, Val Loss: 0.5413, Val Acc: 0.7701
Epoch 37/100, Loss: 0.6019, Acc: 0.6697, Val Loss: 0.5407, Val Acc: 0.7657
Epoch 38/100, Loss: 0.6007, Acc: 0.6700, Val Loss: 0.5285, Val Acc: 0.7646
Epoch 39/100, Loss: 0.6013, Acc: 0.6698, Val Loss: 0.5475, Val Acc: 0.7601
Epoch 40/100, Loss: 0.6002, Acc: 0.6714, Val Loss: 0.5485, Val Acc: 0.7576
Epoch 41/100, Loss: 0.5996, Acc: 0.6722, Val Loss: 0.5473, Val Acc: 0.7697
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5993, Acc: 0.6710, Val Loss: 0.5493, Val Acc: 0.7627
Epoch 43/100, Loss: 0.5991, Acc: 0.6723, Val Loss: 0.5382, Val Acc: 0.7712
Epoch 44/100, Loss: 0.5986, Acc: 0.6708, Val Loss: 0.5344, Val Acc: 0.7661
Epoch 45/100, Loss: 0.5986, Acc: 0.6726, Val Loss: 0.5369, Val Acc: 0.7683
Epoch 46/100, Loss: 0.5982, Acc: 0.6710, Val Loss: 0.5447, Val Acc: 0.7675
Epoch 47/100, Loss: 0.5979, Acc: 0.6715, Val Loss: 0.5388, Val Acc: 0.7638
Epoch 48/100, Loss: 0.5972, Acc: 0.6727, Val Loss: 0.5356, Val Acc: 0.7679
Epoch 49/100, Loss: 0.5974, Acc: 0.6726, Val Loss: 0.5430, Val Acc: 0.7701
Epoch 50/100, Loss: 0.5973, Acc: 0.6729, Val Loss: 0.5362, Val Acc: 0.7690
Epoch 51/100, Loss: 0.5969, Acc: 0.6733, Val Loss: 0.5422, Val Acc: 0.7690
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5966, Acc: 0.6725, Val Loss: 0.5415, Val Acc: 0.7705
Epoch 53/100, Loss: 0.5962, Acc: 0.6717, Val Loss: 0.5432, Val Acc: 0.7686
Epoch 54/100, Loss: 0.5957, Acc: 0.6741, Val Loss: 0.5434, Val Acc: 0.7690
Epoch 55/100, Loss: 0.5961, Acc: 0.6735, Val Loss: 0.5397, Val Acc: 0.7697
Epoch 56/100, Loss: 0.5958, Acc: 0.6747, Val Loss: 0.5374, Val Acc: 0.7694
Epoch 57/100, Loss: 0.5959, Acc: 0.6740, Val Loss: 0.5362, Val Acc: 0.7694
Epoch 58/100, Loss: 0.5954, Acc: 0.6736, Val Loss: 0.5332, Val Acc: 0.7712
Epoch 59/100, Loss: 0.5953, Acc: 0.6716, Val Loss: 0.5478, Val Acc: 0.7649
Epoch 60/100, Loss: 0.5957, Acc: 0.6732, Val Loss: 0.5342, Val Acc: 0.7727
Epoch 61/100, Loss: 0.5950, Acc: 0.6739, Val Loss: 0.5395, Val Acc: 0.7679
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5947, Acc: 0.6742, Val Loss: 0.5362, Val Acc: 0.7705
Epoch 63/100, Loss: 0.5947, Acc: 0.6750, Val Loss: 0.5344, Val Acc: 0.7720
Epoch 64/100, Loss: 0.5945, Acc: 0.6728, Val Loss: 0.5402, Val Acc: 0.7672
Epoch 65/100, Loss: 0.5945, Acc: 0.6745, Val Loss: 0.5349, Val Acc: 0.7720
Epoch 66/100, Loss: 0.5944, Acc: 0.6741, Val Loss: 0.5361, Val Acc: 0.7716
Epoch 67/100, Loss: 0.5943, Acc: 0.6733, Val Loss: 0.5429, Val Acc: 0.7701
Epoch 68/100, Loss: 0.5945, Acc: 0.6742, Val Loss: 0.5435, Val Acc: 0.7697
Epoch 69/100, Loss: 0.5941, Acc: 0.6738, Val Loss: 0.5441, Val Acc: 0.7690
Epoch 70/100, Loss: 0.5943, Acc: 0.6734, Val Loss: 0.5394, Val Acc: 0.7690
Epoch 71/100, Loss: 0.5941, Acc: 0.6752, Val Loss: 0.5390, Val Acc: 0.7679
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5941, Acc: 0.6741, Val Loss: 0.5371, Val Acc: 0.7686
Epoch 73/100, Loss: 0.5939, Acc: 0.6753, Val Loss: 0.5361, Val Acc: 0.7705
Epoch 74/100, Loss: 0.5938, Acc: 0.6741, Val Loss: 0.5400, Val Acc: 0.7686
Epoch 75/100, Loss: 0.5938, Acc: 0.6753, Val Loss: 0.5423, Val Acc: 0.7705
Epoch 76/100, Loss: 0.5938, Acc: 0.6754, Val Loss: 0.5384, Val Acc: 0.7672
Epoch 77/100, Loss: 0.5936, Acc: 0.6749, Val Loss: 0.5384, Val Acc: 0.7690
Epoch 78/100, Loss: 0.5936, Acc: 0.6747, Val Loss: 0.5381, Val Acc: 0.7672
Epoch 79/100, Loss: 0.5935, Acc: 0.6742, Val Loss: 0.5363, Val Acc: 0.7694
Epoch 80/100, Loss: 0.5934, Acc: 0.6744, Val Loss: 0.5389, Val Acc: 0.7679
Epoch 81/100, Loss: 0.5934, Acc: 0.6749, Val Loss: 0.5411, Val Acc: 0.7697
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5933, Acc: 0.6750, Val Loss: 0.5380, Val Acc: 0.7672
Epoch 83/100, Loss: 0.5932, Acc: 0.6758, Val Loss: 0.5413, Val Acc: 0.7701
Epoch 84/100, Loss: 0.5932, Acc: 0.6762, Val Loss: 0.5396, Val Acc: 0.7683
Epoch 85/100, Loss: 0.5932, Acc: 0.6750, Val Loss: 0.5370, Val Acc: 0.7701
Epoch 86/100, Loss: 0.5932, Acc: 0.6751, Val Loss: 0.5386, Val Acc: 0.7686
Epoch 87/100, Loss: 0.5931, Acc: 0.6747, Val Loss: 0.5391, Val Acc: 0.7694
Epoch 88/100, Loss: 0.5930, Acc: 0.6752, Val Loss: 0.5413, Val Acc: 0.7716
Epoch 89/100, Loss: 0.5930, Acc: 0.6760, Val Loss: 0.5394, Val Acc: 0.7701
Epoch 90/100, Loss: 0.5929, Acc: 0.6762, Val Loss: 0.5389, Val Acc: 0.7690
Epoch 91/100, Loss: 0.5929, Acc: 0.6752, Val Loss: 0.5383, Val Acc: 0.7683
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5928, Acc: 0.6762, Val Loss: 0.5415, Val Acc: 0.7720
Epoch 93/100, Loss: 0.5928, Acc: 0.6754, Val Loss: 0.5384, Val Acc: 0.7694
Epoch 94/100, Loss: 0.5927, Acc: 0.6756, Val Loss: 0.5374, Val Acc: 0.7686
Epoch 95/100, Loss: 0.5927, Acc: 0.6751, Val Loss: 0.5384, Val Acc: 0.7683
Epoch 96/100, Loss: 0.5926, Acc: 0.6750, Val Loss: 0.5393, Val Acc: 0.7690
Epoch 97/100, Loss: 0.5926, Acc: 0.6751, Val Loss: 0.5385, Val Acc: 0.7683
Epoch 98/100, Loss: 0.5925, Acc: 0.6755, Val Loss: 0.5357, Val Acc: 0.7720
Epoch 99/100, Loss: 0.5925, Acc: 0.6760, Val Loss: 0.5358, Val Acc: 0.7705
Epoch 100/100, Loss: 0.5925, Acc: 0.6751, Val Loss: 0.5379, Val Acc: 0.7686

##############################
Resultados para principal:  118  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11 
 {'training': [0.5924551367101696, 0.6750689972401104, 0.6246388232203836, 0.8758747697974217, 0.7292241643667586], 'validate': [0.5378969322110332, 0.7686346863468635, 0.7753236862147753, 0.7540740740740741, 0.7645512579797221], 'test': [0.6099510760802143, 0.6675516224188791, 0.6108704214257582, 0.9177514792899408, 0.7335067391818397]}

######################################## 
########################################
Grupo en indetificación:  ['067', '124', '010', '009', '118', '032']  --- principal:  032  --- window & package numer:  11

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  032  --- group:  ['067', '124', '010', '009', '118', '032']  --- window:  11
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  032  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6845, Acc: 0.5767, Val Loss: 0.7245, Val Acc: 0.1930
Mejor modelo guardado con Val Loss: 0.7245
Epoch 2/100, Loss: 0.6829, Acc: 0.5799, Val Loss: 0.7057, Val Acc: 0.4915
Mejor modelo guardado con Val Loss: 0.7057
Epoch 3/100, Loss: 0.6810, Acc: 0.5786, Val Loss: 0.7586, Val Acc: 0.1432
Epoch 4/100, Loss: 0.6758, Acc: 0.6022, Val Loss: 0.7263, Val Acc: 0.3351
Epoch 5/100, Loss: 0.6714, Acc: 0.6125, Val Loss: 0.7621, Val Acc: 0.2339
Epoch 6/100, Loss: 0.6680, Acc: 0.6178, Val Loss: 0.7518, Val Acc: 0.3406
Epoch 7/100, Loss: 0.6620, Acc: 0.6281, Val Loss: 0.7604, Val Acc: 0.3085
Epoch 8/100, Loss: 0.6590, Acc: 0.6311, Val Loss: 0.7896, Val Acc: 0.2686
Epoch 9/100, Loss: 0.6546, Acc: 0.6362, Val Loss: 0.7725, Val Acc: 0.3181
Epoch 10/100, Loss: 0.6518, Acc: 0.6345, Val Loss: 0.7638, Val Acc: 0.3583
Epoch 11/100, Loss: 0.6494, Acc: 0.6396, Val Loss: 0.8153, Val Acc: 0.2875
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6448, Acc: 0.6438, Val Loss: 0.8197, Val Acc: 0.2720
Epoch 13/100, Loss: 0.6437, Acc: 0.6472, Val Loss: 0.8454, Val Acc: 0.2513
Epoch 14/100, Loss: 0.6407, Acc: 0.6507, Val Loss: 0.8244, Val Acc: 0.2926
Epoch 15/100, Loss: 0.6388, Acc: 0.6552, Val Loss: 0.8223, Val Acc: 0.3037
Epoch 16/100, Loss: 0.6393, Acc: 0.6495, Val Loss: 0.7924, Val Acc: 0.3502
Epoch 17/100, Loss: 0.6366, Acc: 0.6567, Val Loss: 0.8225, Val Acc: 0.3063
Epoch 18/100, Loss: 0.6397, Acc: 0.6490, Val Loss: 0.8871, Val Acc: 0.2210
Epoch 19/100, Loss: 0.6372, Acc: 0.6492, Val Loss: 0.8839, Val Acc: 0.2221
Epoch 20/100, Loss: 0.6339, Acc: 0.6563, Val Loss: 0.8812, Val Acc: 0.2443
Epoch 21/100, Loss: 0.6344, Acc: 0.6512, Val Loss: 0.8014, Val Acc: 0.3635
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6305, Acc: 0.6614, Val Loss: 0.8284, Val Acc: 0.3100
Epoch 23/100, Loss: 0.6302, Acc: 0.6611, Val Loss: 0.8957, Val Acc: 0.2328
Epoch 24/100, Loss: 0.6293, Acc: 0.6611, Val Loss: 0.8522, Val Acc: 0.2867
Epoch 25/100, Loss: 0.6282, Acc: 0.6629, Val Loss: 0.8727, Val Acc: 0.2631
Epoch 26/100, Loss: 0.6290, Acc: 0.6580, Val Loss: 0.8844, Val Acc: 0.2572
Epoch 27/100, Loss: 0.6284, Acc: 0.6615, Val Loss: 0.8666, Val Acc: 0.2786
Epoch 28/100, Loss: 0.6280, Acc: 0.6610, Val Loss: 0.8917, Val Acc: 0.2465
Epoch 29/100, Loss: 0.6282, Acc: 0.6615, Val Loss: 0.8090, Val Acc: 0.3786
Epoch 30/100, Loss: 0.6265, Acc: 0.6642, Val Loss: 0.8691, Val Acc: 0.2808
Epoch 31/100, Loss: 0.6263, Acc: 0.6628, Val Loss: 0.8617, Val Acc: 0.2967
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6255, Acc: 0.6649, Val Loss: 0.8686, Val Acc: 0.2841
Epoch 33/100, Loss: 0.6252, Acc: 0.6649, Val Loss: 0.8721, Val Acc: 0.2804
Epoch 34/100, Loss: 0.6253, Acc: 0.6638, Val Loss: 0.8608, Val Acc: 0.3041
Epoch 35/100, Loss: 0.6244, Acc: 0.6643, Val Loss: 0.8482, Val Acc: 0.3199
Epoch 36/100, Loss: 0.6246, Acc: 0.6652, Val Loss: 0.8719, Val Acc: 0.2845
Epoch 37/100, Loss: 0.6246, Acc: 0.6645, Val Loss: 0.8881, Val Acc: 0.2631
Epoch 38/100, Loss: 0.6246, Acc: 0.6644, Val Loss: 0.8654, Val Acc: 0.3007
Epoch 39/100, Loss: 0.6238, Acc: 0.6681, Val Loss: 0.8812, Val Acc: 0.2749
Epoch 40/100, Loss: 0.6243, Acc: 0.6638, Val Loss: 0.8805, Val Acc: 0.2760
Epoch 41/100, Loss: 0.6230, Acc: 0.6697, Val Loss: 0.8651, Val Acc: 0.3022
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6226, Acc: 0.6694, Val Loss: 0.8802, Val Acc: 0.2779
Epoch 43/100, Loss: 0.6229, Acc: 0.6679, Val Loss: 0.8688, Val Acc: 0.2996
Epoch 44/100, Loss: 0.6227, Acc: 0.6661, Val Loss: 0.8893, Val Acc: 0.2672
Epoch 45/100, Loss: 0.6226, Acc: 0.6672, Val Loss: 0.8669, Val Acc: 0.3018
Epoch 46/100, Loss: 0.6223, Acc: 0.6692, Val Loss: 0.8645, Val Acc: 0.3066
Epoch 47/100, Loss: 0.6217, Acc: 0.6663, Val Loss: 0.8659, Val Acc: 0.3037
Epoch 48/100, Loss: 0.6207, Acc: 0.6696, Val Loss: 0.8408, Val Acc: 0.3395
Epoch 49/100, Loss: 0.6205, Acc: 0.6662, Val Loss: 0.8589, Val Acc: 0.3140
Epoch 50/100, Loss: 0.6205, Acc: 0.6695, Val Loss: 0.8849, Val Acc: 0.2716
Epoch 51/100, Loss: 0.6202, Acc: 0.6691, Val Loss: 0.8873, Val Acc: 0.2664
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6199, Acc: 0.6685, Val Loss: 0.8748, Val Acc: 0.2845
Epoch 53/100, Loss: 0.6195, Acc: 0.6688, Val Loss: 0.8759, Val Acc: 0.2948
Epoch 54/100, Loss: 0.6192, Acc: 0.6711, Val Loss: 0.8780, Val Acc: 0.2878
Epoch 55/100, Loss: 0.6188, Acc: 0.6695, Val Loss: 0.8946, Val Acc: 0.2661
Epoch 56/100, Loss: 0.6189, Acc: 0.6715, Val Loss: 0.8798, Val Acc: 0.2923
Epoch 57/100, Loss: 0.6188, Acc: 0.6690, Val Loss: 0.8827, Val Acc: 0.2815
Epoch 58/100, Loss: 0.6182, Acc: 0.6695, Val Loss: 0.8941, Val Acc: 0.2697
Epoch 59/100, Loss: 0.6183, Acc: 0.6688, Val Loss: 0.8757, Val Acc: 0.3059
Epoch 60/100, Loss: 0.6176, Acc: 0.6696, Val Loss: 0.8698, Val Acc: 0.3070
Epoch 61/100, Loss: 0.6176, Acc: 0.6700, Val Loss: 0.8791, Val Acc: 0.3011
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6173, Acc: 0.6706, Val Loss: 0.8882, Val Acc: 0.2878
Epoch 63/100, Loss: 0.6171, Acc: 0.6697, Val Loss: 0.8870, Val Acc: 0.2889
Epoch 64/100, Loss: 0.6169, Acc: 0.6707, Val Loss: 0.8869, Val Acc: 0.2878
Epoch 65/100, Loss: 0.6168, Acc: 0.6717, Val Loss: 0.8906, Val Acc: 0.2830
Epoch 66/100, Loss: 0.6167, Acc: 0.6710, Val Loss: 0.8911, Val Acc: 0.2815
Epoch 67/100, Loss: 0.6165, Acc: 0.6725, Val Loss: 0.8800, Val Acc: 0.3011
Epoch 68/100, Loss: 0.6166, Acc: 0.6712, Val Loss: 0.8930, Val Acc: 0.2827
Epoch 69/100, Loss: 0.6165, Acc: 0.6721, Val Loss: 0.8842, Val Acc: 0.2930
Epoch 70/100, Loss: 0.6164, Acc: 0.6713, Val Loss: 0.8946, Val Acc: 0.2808
Epoch 71/100, Loss: 0.6166, Acc: 0.6719, Val Loss: 0.8903, Val Acc: 0.2886
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6161, Acc: 0.6717, Val Loss: 0.8845, Val Acc: 0.2959
Epoch 73/100, Loss: 0.6161, Acc: 0.6708, Val Loss: 0.8883, Val Acc: 0.2904
Epoch 74/100, Loss: 0.6160, Acc: 0.6717, Val Loss: 0.8851, Val Acc: 0.2948
Epoch 75/100, Loss: 0.6160, Acc: 0.6709, Val Loss: 0.8929, Val Acc: 0.2819
Epoch 76/100, Loss: 0.6159, Acc: 0.6714, Val Loss: 0.8896, Val Acc: 0.2893
Epoch 77/100, Loss: 0.6159, Acc: 0.6736, Val Loss: 0.8840, Val Acc: 0.2963
Epoch 78/100, Loss: 0.6158, Acc: 0.6724, Val Loss: 0.8961, Val Acc: 0.2793
Epoch 79/100, Loss: 0.6158, Acc: 0.6713, Val Loss: 0.8946, Val Acc: 0.2823
Epoch 80/100, Loss: 0.6157, Acc: 0.6731, Val Loss: 0.8850, Val Acc: 0.2970
Epoch 81/100, Loss: 0.6158, Acc: 0.6717, Val Loss: 0.8831, Val Acc: 0.3015
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6157, Acc: 0.6715, Val Loss: 0.8911, Val Acc: 0.2886
Epoch 83/100, Loss: 0.6156, Acc: 0.6707, Val Loss: 0.8939, Val Acc: 0.2845
Epoch 84/100, Loss: 0.6155, Acc: 0.6713, Val Loss: 0.8918, Val Acc: 0.2893
Epoch 85/100, Loss: 0.6153, Acc: 0.6719, Val Loss: 0.8946, Val Acc: 0.2937
Epoch 86/100, Loss: 0.6151, Acc: 0.6733, Val Loss: 0.8960, Val Acc: 0.2919
Epoch 87/100, Loss: 0.6150, Acc: 0.6728, Val Loss: 0.8970, Val Acc: 0.2893
Epoch 88/100, Loss: 0.6150, Acc: 0.6712, Val Loss: 0.8993, Val Acc: 0.2856
Epoch 89/100, Loss: 0.6148, Acc: 0.6710, Val Loss: 0.9031, Val Acc: 0.2812
Epoch 90/100, Loss: 0.6147, Acc: 0.6718, Val Loss: 0.8962, Val Acc: 0.2948
Epoch 91/100, Loss: 0.6148, Acc: 0.6720, Val Loss: 0.9038, Val Acc: 0.2793
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6146, Acc: 0.6721, Val Loss: 0.9060, Val Acc: 0.2760
Epoch 93/100, Loss: 0.6143, Acc: 0.6720, Val Loss: 0.8871, Val Acc: 0.3033
Epoch 94/100, Loss: 0.6144, Acc: 0.6731, Val Loss: 0.8902, Val Acc: 0.2974
Epoch 95/100, Loss: 0.6143, Acc: 0.6732, Val Loss: 0.8938, Val Acc: 0.2889
Epoch 96/100, Loss: 0.6142, Acc: 0.6724, Val Loss: 0.8925, Val Acc: 0.2919
Epoch 97/100, Loss: 0.6141, Acc: 0.6730, Val Loss: 0.8891, Val Acc: 0.2952
Epoch 98/100, Loss: 0.6141, Acc: 0.6741, Val Loss: 0.8905, Val Acc: 0.2952
Epoch 99/100, Loss: 0.6139, Acc: 0.6737, Val Loss: 0.8877, Val Acc: 0.3011
Epoch 100/100, Loss: 0.6141, Acc: 0.6723, Val Loss: 0.8942, Val Acc: 0.2878

##############################
Resultados para principal:  032  --- grupo:  ['067', '124', '010', '009', '118', '032']  --- window & package numer:  11 
 {'training': [0.6141408995849448, 0.6723091076356946, 0.636950146627566, 0.8, 0.7092244897959183], 'validate': [0.8941653169864832, 0.2878228782287823, 0.3620361560418649, 0.5637037037037037, 0.44090382387022015], 'test': [0.6868486753049886, 0.5156342182890855, 0.5072463768115942, 0.9940828402366864, 0.6717313074770092]}

##############################
Resultados para window:  11 
 {'067:124:010:009:118:032': {'training': [0.4822398564523804, 0.7648574057037718, 0.8, 0.7057090239410682, 0.7499021526418786], 'validate': [0.5282553243775701, 0.7505535055350554, 0.7047387606318347, 0.8592592592592593, 0.774365821094793], 'test': [0.561646118057224, 0.7064896755162242, 0.8485456369107321, 0.5005917159763313, 0.6296985485671753]}, '124:067:010:009:118:032': {'training': [0.2890300487693341, 0.8863845446182153, 0.8605810555269039, 0.921915285451197, 0.8901929403396461], 'validate': [0.6066685814497083, 0.7121771217712177, 0.6595744680851063, 0.8725925925925926, 0.7512755102040817], 'test': [0.7280068122693952, 0.6286135693215339, 0.5823461979365686, 0.901775147928994, 0.7076851636870212]}, '010:067:124:009:118:032': {'training': [0.45033955724829366, 0.7845446182152714, 0.7127894156560088, 0.9524861878453039, 0.8153870408324136], 'validate': [0.8407598772021228, 0.6627306273062731, 0.6778140293637847, 0.6155555555555555, 0.6451863354037267], 'test': [0.6343440199798008, 0.6669616519174041, 0.6288470372071658, 0.8100591715976332, 0.7080424101370572]}, '009:067:124:010:118:032': {'training': [0.0841597903893426, 0.965869365225391, 0.956506045840101, 0.9760589318600368, 0.966183574879227], 'validate': [0.06494159046506379, 0.9804428044280443, 0.9800148038490007, 0.9807407407407407, 0.9803776379118845], 'test': [0.1162783509946235, 0.95929203539823, 0.9813895781637717, 0.936094674556213, 0.9582071471835252]}, '118:067:124:010:009:032': {'training': [0.5924551367101696, 0.6750689972401104, 0.6246388232203836, 0.8758747697974217, 0.7292241643667586], 'validate': [0.5378969322110332, 0.7686346863468635, 0.7753236862147753, 0.7540740740740741, 0.7645512579797221], 'test': [0.6099510760802143, 0.6675516224188791, 0.6108704214257582, 0.9177514792899408, 0.7335067391818397]}, '032:067:124:010:009:118': {'training': [0.6141408995849448, 0.6723091076356946, 0.636950146627566, 0.8, 0.7092244897959183], 'validate': [0.8941653169864832, 0.2878228782287823, 0.3620361560418649, 0.5637037037037037, 0.44090382387022015], 'test': [0.6868486753049886, 0.5156342182890855, 0.5072463768115942, 0.9940828402366864, 0.6717313074770092]}}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  095  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  095  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6924, Acc: 0.5259, Val Loss: 0.6945, Val Acc: 0.4896
Mejor modelo guardado con Val Loss: 0.6945
Epoch 2/100, Loss: 0.6908, Acc: 0.5335, Val Loss: 0.6954, Val Acc: 0.4752
Epoch 3/100, Loss: 0.6883, Acc: 0.5621, Val Loss: 0.6948, Val Acc: 0.4919
Epoch 4/100, Loss: 0.6838, Acc: 0.5886, Val Loss: 0.6960, Val Acc: 0.5030
Epoch 5/100, Loss: 0.6814, Acc: 0.5864, Val Loss: 0.6962, Val Acc: 0.5026
Epoch 6/100, Loss: 0.6777, Acc: 0.5979, Val Loss: 0.6960, Val Acc: 0.5152
Epoch 7/100, Loss: 0.6755, Acc: 0.6002, Val Loss: 0.6960, Val Acc: 0.5237
Epoch 8/100, Loss: 0.6753, Acc: 0.5959, Val Loss: 0.7035, Val Acc: 0.5093
Epoch 9/100, Loss: 0.6698, Acc: 0.6075, Val Loss: 0.7012, Val Acc: 0.5189
Epoch 10/100, Loss: 0.6695, Acc: 0.6067, Val Loss: 0.6973, Val Acc: 0.5193
Epoch 11/100, Loss: 0.6713, Acc: 0.5991, Val Loss: 0.6969, Val Acc: 0.5219
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6652, Acc: 0.6108, Val Loss: 0.6972, Val Acc: 0.5252
Epoch 13/100, Loss: 0.6651, Acc: 0.6119, Val Loss: 0.6968, Val Acc: 0.5241
Epoch 14/100, Loss: 0.6636, Acc: 0.6135, Val Loss: 0.7006, Val Acc: 0.5226
Epoch 15/100, Loss: 0.6639, Acc: 0.6134, Val Loss: 0.6978, Val Acc: 0.5256
Epoch 16/100, Loss: 0.6629, Acc: 0.6107, Val Loss: 0.7007, Val Acc: 0.5211
Epoch 17/100, Loss: 0.6605, Acc: 0.6180, Val Loss: 0.7034, Val Acc: 0.5226
Epoch 18/100, Loss: 0.6628, Acc: 0.6124, Val Loss: 0.7020, Val Acc: 0.5200
Epoch 19/100, Loss: 0.6615, Acc: 0.6134, Val Loss: 0.7029, Val Acc: 0.5241
Epoch 20/100, Loss: 0.6600, Acc: 0.6143, Val Loss: 0.6990, Val Acc: 0.5285
Epoch 21/100, Loss: 0.6596, Acc: 0.6163, Val Loss: 0.7003, Val Acc: 0.5289
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6580, Acc: 0.6235, Val Loss: 0.7026, Val Acc: 0.5307
Epoch 23/100, Loss: 0.6583, Acc: 0.6181, Val Loss: 0.7011, Val Acc: 0.5270
Epoch 24/100, Loss: 0.6589, Acc: 0.6171, Val Loss: 0.7019, Val Acc: 0.5289
Epoch 25/100, Loss: 0.6578, Acc: 0.6188, Val Loss: 0.7018, Val Acc: 0.5304
Epoch 26/100, Loss: 0.6577, Acc: 0.6199, Val Loss: 0.7030, Val Acc: 0.5278
Epoch 27/100, Loss: 0.6569, Acc: 0.6218, Val Loss: 0.7028, Val Acc: 0.5281
Epoch 28/100, Loss: 0.6566, Acc: 0.6201, Val Loss: 0.7037, Val Acc: 0.5300
Epoch 29/100, Loss: 0.6572, Acc: 0.6203, Val Loss: 0.7025, Val Acc: 0.5285
Epoch 30/100, Loss: 0.6578, Acc: 0.6169, Val Loss: 0.7028, Val Acc: 0.5289
Epoch 31/100, Loss: 0.6575, Acc: 0.6178, Val Loss: 0.7029, Val Acc: 0.5293
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6567, Acc: 0.6200, Val Loss: 0.7026, Val Acc: 0.5304
Epoch 33/100, Loss: 0.6566, Acc: 0.6191, Val Loss: 0.7031, Val Acc: 0.5307
Epoch 34/100, Loss: 0.6560, Acc: 0.6206, Val Loss: 0.7031, Val Acc: 0.5293
Epoch 35/100, Loss: 0.6562, Acc: 0.6216, Val Loss: 0.7030, Val Acc: 0.5307
Epoch 36/100, Loss: 0.6560, Acc: 0.6224, Val Loss: 0.7033, Val Acc: 0.5304
Epoch 37/100, Loss: 0.6560, Acc: 0.6188, Val Loss: 0.7031, Val Acc: 0.5293
Epoch 38/100, Loss: 0.6562, Acc: 0.6206, Val Loss: 0.7034, Val Acc: 0.5293
Epoch 39/100, Loss: 0.6557, Acc: 0.6199, Val Loss: 0.7030, Val Acc: 0.5319
Epoch 40/100, Loss: 0.6562, Acc: 0.6193, Val Loss: 0.7034, Val Acc: 0.5304
Epoch 41/100, Loss: 0.6560, Acc: 0.6192, Val Loss: 0.7031, Val Acc: 0.5293
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6551, Acc: 0.6200, Val Loss: 0.7030, Val Acc: 0.5296
Epoch 43/100, Loss: 0.6552, Acc: 0.6201, Val Loss: 0.7032, Val Acc: 0.5311
Epoch 44/100, Loss: 0.6554, Acc: 0.6195, Val Loss: 0.7033, Val Acc: 0.5300
Epoch 45/100, Loss: 0.6549, Acc: 0.6215, Val Loss: 0.7043, Val Acc: 0.5252
Epoch 46/100, Loss: 0.6554, Acc: 0.6199, Val Loss: 0.7036, Val Acc: 0.5311
Epoch 47/100, Loss: 0.6555, Acc: 0.6201, Val Loss: 0.7037, Val Acc: 0.5300
Epoch 48/100, Loss: 0.6533, Acc: 0.6216, Val Loss: 0.7031, Val Acc: 0.5333
Epoch 49/100, Loss: 0.6515, Acc: 0.6247, Val Loss: 0.7031, Val Acc: 0.5333
Epoch 50/100, Loss: 0.6503, Acc: 0.6234, Val Loss: 0.7060, Val Acc: 0.5326
Epoch 51/100, Loss: 0.6484, Acc: 0.6251, Val Loss: 0.7050, Val Acc: 0.5348
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6474, Acc: 0.6280, Val Loss: 0.7043, Val Acc: 0.5322
Epoch 53/100, Loss: 0.6468, Acc: 0.6270, Val Loss: 0.7047, Val Acc: 0.5333
Epoch 54/100, Loss: 0.6465, Acc: 0.6274, Val Loss: 0.7040, Val Acc: 0.5296
Epoch 55/100, Loss: 0.6458, Acc: 0.6275, Val Loss: 0.7039, Val Acc: 0.5330
Epoch 56/100, Loss: 0.6456, Acc: 0.6269, Val Loss: 0.7035, Val Acc: 0.5348
Epoch 57/100, Loss: 0.6451, Acc: 0.6279, Val Loss: 0.7037, Val Acc: 0.5330
Epoch 58/100, Loss: 0.6447, Acc: 0.6277, Val Loss: 0.7034, Val Acc: 0.5304
Epoch 59/100, Loss: 0.6442, Acc: 0.6281, Val Loss: 0.7035, Val Acc: 0.5337
Epoch 60/100, Loss: 0.6438, Acc: 0.6285, Val Loss: 0.7029, Val Acc: 0.5348
Epoch 61/100, Loss: 0.6433, Acc: 0.6285, Val Loss: 0.7034, Val Acc: 0.5363
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6433, Acc: 0.6291, Val Loss: 0.7026, Val Acc: 0.5356
Epoch 63/100, Loss: 0.6428, Acc: 0.6289, Val Loss: 0.7026, Val Acc: 0.5341
Epoch 64/100, Loss: 0.6426, Acc: 0.6277, Val Loss: 0.7023, Val Acc: 0.5326
Epoch 65/100, Loss: 0.6425, Acc: 0.6296, Val Loss: 0.7023, Val Acc: 0.5341
Epoch 66/100, Loss: 0.6422, Acc: 0.6287, Val Loss: 0.7024, Val Acc: 0.5341
Epoch 67/100, Loss: 0.6420, Acc: 0.6308, Val Loss: 0.7024, Val Acc: 0.5359
Epoch 68/100, Loss: 0.6417, Acc: 0.6293, Val Loss: 0.7020, Val Acc: 0.5356
Epoch 69/100, Loss: 0.6415, Acc: 0.6305, Val Loss: 0.7023, Val Acc: 0.5352
Epoch 70/100, Loss: 0.6414, Acc: 0.6306, Val Loss: 0.7020, Val Acc: 0.5337
Epoch 71/100, Loss: 0.6412, Acc: 0.6304, Val Loss: 0.7020, Val Acc: 0.5356
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6409, Acc: 0.6301, Val Loss: 0.7018, Val Acc: 0.5341
Epoch 73/100, Loss: 0.6408, Acc: 0.6314, Val Loss: 0.7019, Val Acc: 0.5348
Epoch 74/100, Loss: 0.6407, Acc: 0.6295, Val Loss: 0.7018, Val Acc: 0.5367
Epoch 75/100, Loss: 0.6405, Acc: 0.6302, Val Loss: 0.7018, Val Acc: 0.5352
Epoch 76/100, Loss: 0.6404, Acc: 0.6311, Val Loss: 0.7018, Val Acc: 0.5337
Epoch 77/100, Loss: 0.6403, Acc: 0.6309, Val Loss: 0.7019, Val Acc: 0.5348
Epoch 78/100, Loss: 0.6401, Acc: 0.6319, Val Loss: 0.7016, Val Acc: 0.5352
Epoch 79/100, Loss: 0.6401, Acc: 0.6315, Val Loss: 0.7016, Val Acc: 0.5337
Epoch 80/100, Loss: 0.6399, Acc: 0.6325, Val Loss: 0.7019, Val Acc: 0.5359
Epoch 81/100, Loss: 0.6397, Acc: 0.6310, Val Loss: 0.7016, Val Acc: 0.5356
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6396, Acc: 0.6310, Val Loss: 0.7016, Val Acc: 0.5359
Epoch 83/100, Loss: 0.6394, Acc: 0.6318, Val Loss: 0.7015, Val Acc: 0.5367
Epoch 84/100, Loss: 0.6393, Acc: 0.6317, Val Loss: 0.7015, Val Acc: 0.5352
Epoch 85/100, Loss: 0.6393, Acc: 0.6312, Val Loss: 0.7014, Val Acc: 0.5359
Epoch 86/100, Loss: 0.6390, Acc: 0.6310, Val Loss: 0.7014, Val Acc: 0.5359
Epoch 87/100, Loss: 0.6389, Acc: 0.6323, Val Loss: 0.7014, Val Acc: 0.5363
Epoch 88/100, Loss: 0.6388, Acc: 0.6329, Val Loss: 0.7013, Val Acc: 0.5359
Epoch 89/100, Loss: 0.6386, Acc: 0.6331, Val Loss: 0.7013, Val Acc: 0.5356
Epoch 90/100, Loss: 0.6384, Acc: 0.6312, Val Loss: 0.7014, Val Acc: 0.5348
Epoch 91/100, Loss: 0.6383, Acc: 0.6311, Val Loss: 0.7013, Val Acc: 0.5348
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6383, Acc: 0.6325, Val Loss: 0.7012, Val Acc: 0.5356
Epoch 93/100, Loss: 0.6381, Acc: 0.6326, Val Loss: 0.7012, Val Acc: 0.5367
Epoch 94/100, Loss: 0.6379, Acc: 0.6330, Val Loss: 0.7011, Val Acc: 0.5359
Epoch 95/100, Loss: 0.6378, Acc: 0.6313, Val Loss: 0.7010, Val Acc: 0.5363
Epoch 96/100, Loss: 0.6377, Acc: 0.6322, Val Loss: 0.7011, Val Acc: 0.5356
Epoch 97/100, Loss: 0.6376, Acc: 0.6333, Val Loss: 0.7011, Val Acc: 0.5356
Epoch 98/100, Loss: 0.6374, Acc: 0.6331, Val Loss: 0.7008, Val Acc: 0.5356
Epoch 99/100, Loss: 0.6372, Acc: 0.6326, Val Loss: 0.7007, Val Acc: 0.5374
Epoch 100/100, Loss: 0.6371, Acc: 0.6326, Val Loss: 0.7007, Val Acc: 0.5381

##############################
Resultados para principal:  095  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21 
 {'training': [0.6370506663129255, 0.6325966850828729, 0.6084977238239757, 0.7398523985239852, 0.6677768526228143], 'validate': [0.7006737458151441, 0.5381481481481482, 0.5253682487725041, 0.7186567164179104, 0.6069965332492909], 'test': [0.690195233192084, 0.5701183431952662, 0.5438393202008498, 0.8380952380952381, 0.6596392597798079]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  065  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  065  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6882, Acc: 0.5482, Val Loss: 0.6812, Val Acc: 0.6370
Mejor modelo guardado con Val Loss: 0.6812
Epoch 2/100, Loss: 0.6839, Acc: 0.5722, Val Loss: 0.6691, Val Acc: 0.6578
Mejor modelo guardado con Val Loss: 0.6691
Epoch 3/100, Loss: 0.6801, Acc: 0.5873, Val Loss: 0.6828, Val Acc: 0.6015
Epoch 4/100, Loss: 0.6852, Acc: 0.5680, Val Loss: 0.6751, Val Acc: 0.6211
Epoch 5/100, Loss: 0.6868, Acc: 0.5491, Val Loss: 0.6716, Val Acc: 0.6381
Epoch 6/100, Loss: 0.6809, Acc: 0.5796, Val Loss: 0.6735, Val Acc: 0.6078
Epoch 7/100, Loss: 0.6805, Acc: 0.5770, Val Loss: 0.6647, Val Acc: 0.6385
Mejor modelo guardado con Val Loss: 0.6647
Epoch 8/100, Loss: 0.6823, Acc: 0.5693, Val Loss: 0.6740, Val Acc: 0.5933
Epoch 9/100, Loss: 0.6764, Acc: 0.5865, Val Loss: 0.6619, Val Acc: 0.6481
Mejor modelo guardado con Val Loss: 0.6619
Epoch 10/100, Loss: 0.6772, Acc: 0.5841, Val Loss: 0.6677, Val Acc: 0.6096
Epoch 11/100, Loss: 0.6758, Acc: 0.5872, Val Loss: 0.6586, Val Acc: 0.6415
Mejor modelo guardado con Val Loss: 0.6586
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6739, Acc: 0.5917, Val Loss: 0.6593, Val Acc: 0.6444
Epoch 13/100, Loss: 0.6720, Acc: 0.5966, Val Loss: 0.6591, Val Acc: 0.6367
Epoch 14/100, Loss: 0.6735, Acc: 0.5908, Val Loss: 0.6612, Val Acc: 0.6226
Epoch 15/100, Loss: 0.6724, Acc: 0.5959, Val Loss: 0.6559, Val Acc: 0.6533
Mejor modelo guardado con Val Loss: 0.6559
Epoch 16/100, Loss: 0.6714, Acc: 0.5957, Val Loss: 0.6585, Val Acc: 0.6307
Epoch 17/100, Loss: 0.6707, Acc: 0.6000, Val Loss: 0.6554, Val Acc: 0.6444
Mejor modelo guardado con Val Loss: 0.6554
Epoch 18/100, Loss: 0.6710, Acc: 0.5974, Val Loss: 0.6537, Val Acc: 0.6463
Mejor modelo guardado con Val Loss: 0.6537
Epoch 19/100, Loss: 0.6703, Acc: 0.5985, Val Loss: 0.6577, Val Acc: 0.6270
Epoch 20/100, Loss: 0.6712, Acc: 0.5948, Val Loss: 0.6534, Val Acc: 0.6459
Mejor modelo guardado con Val Loss: 0.6534
Epoch 21/100, Loss: 0.6698, Acc: 0.6004, Val Loss: 0.6553, Val Acc: 0.6363
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6683, Acc: 0.6031, Val Loss: 0.6533, Val Acc: 0.6452
Mejor modelo guardado con Val Loss: 0.6533
Epoch 23/100, Loss: 0.6688, Acc: 0.6001, Val Loss: 0.6536, Val Acc: 0.6433
Epoch 24/100, Loss: 0.6684, Acc: 0.6013, Val Loss: 0.6553, Val Acc: 0.6348
Epoch 25/100, Loss: 0.6684, Acc: 0.5992, Val Loss: 0.6512, Val Acc: 0.6470
Mejor modelo guardado con Val Loss: 0.6512
Epoch 26/100, Loss: 0.6690, Acc: 0.6022, Val Loss: 0.6555, Val Acc: 0.6304
Epoch 27/100, Loss: 0.6675, Acc: 0.6053, Val Loss: 0.6513, Val Acc: 0.6489
Epoch 28/100, Loss: 0.6678, Acc: 0.6040, Val Loss: 0.6528, Val Acc: 0.6396
Epoch 29/100, Loss: 0.6689, Acc: 0.6006, Val Loss: 0.6526, Val Acc: 0.6411
Epoch 30/100, Loss: 0.6680, Acc: 0.6020, Val Loss: 0.6539, Val Acc: 0.6396
Epoch 31/100, Loss: 0.6682, Acc: 0.6026, Val Loss: 0.6501, Val Acc: 0.6515
Mejor modelo guardado con Val Loss: 0.6501
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6673, Acc: 0.6028, Val Loss: 0.6529, Val Acc: 0.6381
Epoch 33/100, Loss: 0.6674, Acc: 0.6052, Val Loss: 0.6510, Val Acc: 0.6474
Epoch 34/100, Loss: 0.6671, Acc: 0.6055, Val Loss: 0.6506, Val Acc: 0.6504
Epoch 35/100, Loss: 0.6673, Acc: 0.6041, Val Loss: 0.6503, Val Acc: 0.6500
Epoch 36/100, Loss: 0.6673, Acc: 0.6039, Val Loss: 0.6519, Val Acc: 0.6422
Epoch 37/100, Loss: 0.6669, Acc: 0.6045, Val Loss: 0.6502, Val Acc: 0.6500
Epoch 38/100, Loss: 0.6671, Acc: 0.6052, Val Loss: 0.6504, Val Acc: 0.6500
Epoch 39/100, Loss: 0.6670, Acc: 0.6041, Val Loss: 0.6529, Val Acc: 0.6407
Epoch 40/100, Loss: 0.6665, Acc: 0.6079, Val Loss: 0.6546, Val Acc: 0.6356
Epoch 41/100, Loss: 0.6671, Acc: 0.6047, Val Loss: 0.6501, Val Acc: 0.6467
Mejor modelo guardado con Val Loss: 0.6501
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6650, Acc: 0.6063, Val Loss: 0.6468, Val Acc: 0.6511
Mejor modelo guardado con Val Loss: 0.6468
Epoch 43/100, Loss: 0.6647, Acc: 0.6074, Val Loss: 0.6464, Val Acc: 0.6504
Mejor modelo guardado con Val Loss: 0.6464
Epoch 44/100, Loss: 0.6643, Acc: 0.6086, Val Loss: 0.6464, Val Acc: 0.6500
Epoch 45/100, Loss: 0.6643, Acc: 0.6079, Val Loss: 0.6449, Val Acc: 0.6511
Mejor modelo guardado con Val Loss: 0.6449
Epoch 46/100, Loss: 0.6635, Acc: 0.6070, Val Loss: 0.6461, Val Acc: 0.6444
Epoch 47/100, Loss: 0.6632, Acc: 0.6086, Val Loss: 0.6453, Val Acc: 0.6500
Epoch 48/100, Loss: 0.6628, Acc: 0.6097, Val Loss: 0.6464, Val Acc: 0.6426
Epoch 49/100, Loss: 0.6627, Acc: 0.6076, Val Loss: 0.6433, Val Acc: 0.6530
Mejor modelo guardado con Val Loss: 0.6433
Epoch 50/100, Loss: 0.6540, Acc: 0.6129, Val Loss: 0.6314, Val Acc: 0.6537
Mejor modelo guardado con Val Loss: 0.6314
Epoch 51/100, Loss: 0.6509, Acc: 0.6177, Val Loss: 0.6303, Val Acc: 0.6585
Mejor modelo guardado con Val Loss: 0.6303
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6495, Acc: 0.6187, Val Loss: 0.6312, Val Acc: 0.6530
Epoch 53/100, Loss: 0.6489, Acc: 0.6183, Val Loss: 0.6279, Val Acc: 0.6533
Mejor modelo guardado con Val Loss: 0.6279
Epoch 54/100, Loss: 0.6482, Acc: 0.6190, Val Loss: 0.6267, Val Acc: 0.6585
Mejor modelo guardado con Val Loss: 0.6267
Epoch 55/100, Loss: 0.6478, Acc: 0.6188, Val Loss: 0.6275, Val Acc: 0.6537
Epoch 56/100, Loss: 0.6473, Acc: 0.6184, Val Loss: 0.6281, Val Acc: 0.6537
Epoch 57/100, Loss: 0.6471, Acc: 0.6184, Val Loss: 0.6266, Val Acc: 0.6541
Mejor modelo guardado con Val Loss: 0.6266
Epoch 58/100, Loss: 0.6466, Acc: 0.6203, Val Loss: 0.6262, Val Acc: 0.6552
Mejor modelo guardado con Val Loss: 0.6262
Epoch 59/100, Loss: 0.6463, Acc: 0.6200, Val Loss: 0.6255, Val Acc: 0.6574
Mejor modelo guardado con Val Loss: 0.6255
Epoch 60/100, Loss: 0.6458, Acc: 0.6208, Val Loss: 0.6253, Val Acc: 0.6589
Mejor modelo guardado con Val Loss: 0.6253
Epoch 61/100, Loss: 0.6455, Acc: 0.6207, Val Loss: 0.6252, Val Acc: 0.6563
Mejor modelo guardado con Val Loss: 0.6252
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6452, Acc: 0.6217, Val Loss: 0.6253, Val Acc: 0.6567
Epoch 63/100, Loss: 0.6450, Acc: 0.6215, Val Loss: 0.6253, Val Acc: 0.6556
Epoch 64/100, Loss: 0.6448, Acc: 0.6219, Val Loss: 0.6256, Val Acc: 0.6574
Epoch 65/100, Loss: 0.6446, Acc: 0.6215, Val Loss: 0.6249, Val Acc: 0.6567
Mejor modelo guardado con Val Loss: 0.6249
Epoch 66/100, Loss: 0.6444, Acc: 0.6227, Val Loss: 0.6246, Val Acc: 0.6563
Mejor modelo guardado con Val Loss: 0.6246
Epoch 67/100, Loss: 0.6442, Acc: 0.6214, Val Loss: 0.6240, Val Acc: 0.6596
Mejor modelo guardado con Val Loss: 0.6240
Epoch 68/100, Loss: 0.6442, Acc: 0.6223, Val Loss: 0.6239, Val Acc: 0.6585
Mejor modelo guardado con Val Loss: 0.6239
Epoch 69/100, Loss: 0.6439, Acc: 0.6228, Val Loss: 0.6240, Val Acc: 0.6578
Epoch 70/100, Loss: 0.6437, Acc: 0.6220, Val Loss: 0.6237, Val Acc: 0.6570
Mejor modelo guardado con Val Loss: 0.6237
Epoch 71/100, Loss: 0.6436, Acc: 0.6216, Val Loss: 0.6236, Val Acc: 0.6581
Mejor modelo guardado con Val Loss: 0.6236
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6434, Acc: 0.6232, Val Loss: 0.6236, Val Acc: 0.6593
Mejor modelo guardado con Val Loss: 0.6236
Epoch 73/100, Loss: 0.6433, Acc: 0.6224, Val Loss: 0.6240, Val Acc: 0.6578
Epoch 74/100, Loss: 0.6432, Acc: 0.6228, Val Loss: 0.6234, Val Acc: 0.6578
Mejor modelo guardado con Val Loss: 0.6234
Epoch 75/100, Loss: 0.6430, Acc: 0.6227, Val Loss: 0.6234, Val Acc: 0.6593
Mejor modelo guardado con Val Loss: 0.6234
Epoch 76/100, Loss: 0.6429, Acc: 0.6208, Val Loss: 0.6233, Val Acc: 0.6593
Mejor modelo guardado con Val Loss: 0.6233
Epoch 77/100, Loss: 0.6428, Acc: 0.6227, Val Loss: 0.6233, Val Acc: 0.6581
Epoch 78/100, Loss: 0.6426, Acc: 0.6231, Val Loss: 0.6230, Val Acc: 0.6604
Mejor modelo guardado con Val Loss: 0.6230
Epoch 79/100, Loss: 0.6426, Acc: 0.6230, Val Loss: 0.6237, Val Acc: 0.6593
Epoch 80/100, Loss: 0.6425, Acc: 0.6222, Val Loss: 0.6241, Val Acc: 0.6600
Epoch 81/100, Loss: 0.6422, Acc: 0.6225, Val Loss: 0.6243, Val Acc: 0.6611
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6421, Acc: 0.6223, Val Loss: 0.6242, Val Acc: 0.6596
Epoch 83/100, Loss: 0.6420, Acc: 0.6222, Val Loss: 0.6242, Val Acc: 0.6600
Epoch 84/100, Loss: 0.6419, Acc: 0.6227, Val Loss: 0.6238, Val Acc: 0.6600
Epoch 85/100, Loss: 0.6417, Acc: 0.6231, Val Loss: 0.6240, Val Acc: 0.6607
Epoch 86/100, Loss: 0.6416, Acc: 0.6235, Val Loss: 0.6240, Val Acc: 0.6626
Epoch 87/100, Loss: 0.6415, Acc: 0.6227, Val Loss: 0.6240, Val Acc: 0.6630
Epoch 88/100, Loss: 0.6414, Acc: 0.6241, Val Loss: 0.6237, Val Acc: 0.6607
Epoch 89/100, Loss: 0.6412, Acc: 0.6241, Val Loss: 0.6235, Val Acc: 0.6607
Epoch 90/100, Loss: 0.6411, Acc: 0.6232, Val Loss: 0.6234, Val Acc: 0.6619
Epoch 91/100, Loss: 0.6410, Acc: 0.6247, Val Loss: 0.6231, Val Acc: 0.6604
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6408, Acc: 0.6234, Val Loss: 0.6235, Val Acc: 0.6622
Epoch 93/100, Loss: 0.6408, Acc: 0.6242, Val Loss: 0.6229, Val Acc: 0.6607
Mejor modelo guardado con Val Loss: 0.6229
Epoch 94/100, Loss: 0.6406, Acc: 0.6246, Val Loss: 0.6228, Val Acc: 0.6622
Mejor modelo guardado con Val Loss: 0.6228
Epoch 95/100, Loss: 0.6405, Acc: 0.6247, Val Loss: 0.6228, Val Acc: 0.6630
Mejor modelo guardado con Val Loss: 0.6228
Epoch 96/100, Loss: 0.6404, Acc: 0.6246, Val Loss: 0.6230, Val Acc: 0.6622
Epoch 97/100, Loss: 0.6402, Acc: 0.6237, Val Loss: 0.6224, Val Acc: 0.6641
Mejor modelo guardado con Val Loss: 0.6224
Epoch 98/100, Loss: 0.6400, Acc: 0.6231, Val Loss: 0.6228, Val Acc: 0.6626
Epoch 99/100, Loss: 0.6399, Acc: 0.6221, Val Loss: 0.6220, Val Acc: 0.6633
Mejor modelo guardado con Val Loss: 0.6220
Epoch 100/100, Loss: 0.6398, Acc: 0.6246, Val Loss: 0.6219, Val Acc: 0.6630
Mejor modelo guardado con Val Loss: 0.6219

##############################
Resultados para principal:  065  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21 
 {'training': [0.6398268149922127, 0.624585635359116, 0.6306674450282156, 0.597970479704797, 0.6138838905199356], 'validate': [0.6219034208807834, 0.662962962962963, 0.6725521669341894, 0.6253731343283582, 0.6481051817478731], 'test': [0.6276996709265799, 0.6319526627218935, 0.6713836477987422, 0.5083333333333333, 0.5785907859078591]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  013  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  013  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6792, Acc: 0.5926, Val Loss: 0.6604, Val Acc: 0.6393
Mejor modelo guardado con Val Loss: 0.6604
Epoch 2/100, Loss: 0.6725, Acc: 0.6001, Val Loss: 0.6461, Val Acc: 0.6900
Mejor modelo guardado con Val Loss: 0.6461
Epoch 3/100, Loss: 0.6615, Acc: 0.6192, Val Loss: 0.6171, Val Acc: 0.7070
Mejor modelo guardado con Val Loss: 0.6171
Epoch 4/100, Loss: 0.6544, Acc: 0.6231, Val Loss: 0.6096, Val Acc: 0.6893
Mejor modelo guardado con Val Loss: 0.6096
Epoch 5/100, Loss: 0.6475, Acc: 0.6299, Val Loss: 0.6169, Val Acc: 0.6504
Epoch 6/100, Loss: 0.6455, Acc: 0.6261, Val Loss: 0.6356, Val Acc: 0.6489
Epoch 7/100, Loss: 0.6464, Acc: 0.6251, Val Loss: 0.6821, Val Acc: 0.5926
Epoch 8/100, Loss: 0.6465, Acc: 0.6294, Val Loss: 0.6461, Val Acc: 0.6496
Epoch 9/100, Loss: 0.6355, Acc: 0.6390, Val Loss: 0.6271, Val Acc: 0.6644
Epoch 10/100, Loss: 0.6326, Acc: 0.6445, Val Loss: 0.6076, Val Acc: 0.6681
Mejor modelo guardado con Val Loss: 0.6076
Epoch 11/100, Loss: 0.6410, Acc: 0.6332, Val Loss: 0.6052, Val Acc: 0.6941
Mejor modelo guardado con Val Loss: 0.6052
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6295, Acc: 0.6484, Val Loss: 0.6193, Val Acc: 0.6370
Epoch 13/100, Loss: 0.6258, Acc: 0.6527, Val Loss: 0.6059, Val Acc: 0.6589
Epoch 14/100, Loss: 0.6253, Acc: 0.6518, Val Loss: 0.6017, Val Acc: 0.6511
Mejor modelo guardado con Val Loss: 0.6017
Epoch 15/100, Loss: 0.6235, Acc: 0.6565, Val Loss: 0.5924, Val Acc: 0.6604
Mejor modelo guardado con Val Loss: 0.5924
Epoch 16/100, Loss: 0.6250, Acc: 0.6502, Val Loss: 0.6252, Val Acc: 0.6630
Epoch 17/100, Loss: 0.6229, Acc: 0.6537, Val Loss: 0.5883, Val Acc: 0.6744
Mejor modelo guardado con Val Loss: 0.5883
Epoch 18/100, Loss: 0.6241, Acc: 0.6541, Val Loss: 0.6024, Val Acc: 0.6837
Epoch 19/100, Loss: 0.6209, Acc: 0.6595, Val Loss: 0.6063, Val Acc: 0.6596
Epoch 20/100, Loss: 0.6210, Acc: 0.6541, Val Loss: 0.6213, Val Acc: 0.6163
Epoch 21/100, Loss: 0.6205, Acc: 0.6599, Val Loss: 0.6271, Val Acc: 0.6426
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6184, Acc: 0.6588, Val Loss: 0.6165, Val Acc: 0.6389
Epoch 23/100, Loss: 0.6163, Acc: 0.6665, Val Loss: 0.6235, Val Acc: 0.6533
Epoch 24/100, Loss: 0.6159, Acc: 0.6646, Val Loss: 0.6084, Val Acc: 0.6337
Epoch 25/100, Loss: 0.6150, Acc: 0.6632, Val Loss: 0.6419, Val Acc: 0.6293
Epoch 26/100, Loss: 0.6142, Acc: 0.6671, Val Loss: 0.6247, Val Acc: 0.6589
Epoch 27/100, Loss: 0.6146, Acc: 0.6653, Val Loss: 0.6238, Val Acc: 0.6337
Epoch 28/100, Loss: 0.6142, Acc: 0.6680, Val Loss: 0.6222, Val Acc: 0.6500
Epoch 29/100, Loss: 0.6134, Acc: 0.6683, Val Loss: 0.6035, Val Acc: 0.6448
Epoch 30/100, Loss: 0.6133, Acc: 0.6686, Val Loss: 0.6220, Val Acc: 0.6363
Epoch 31/100, Loss: 0.6146, Acc: 0.6646, Val Loss: 0.5937, Val Acc: 0.6500
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6103, Acc: 0.6714, Val Loss: 0.6008, Val Acc: 0.6426
Epoch 33/100, Loss: 0.6106, Acc: 0.6705, Val Loss: 0.6016, Val Acc: 0.6504
Epoch 34/100, Loss: 0.6107, Acc: 0.6709, Val Loss: 0.6094, Val Acc: 0.6448
Epoch 35/100, Loss: 0.6110, Acc: 0.6707, Val Loss: 0.6106, Val Acc: 0.6563
Epoch 36/100, Loss: 0.6100, Acc: 0.6737, Val Loss: 0.6055, Val Acc: 0.6641
Epoch 37/100, Loss: 0.6103, Acc: 0.6722, Val Loss: 0.6399, Val Acc: 0.6285
Epoch 38/100, Loss: 0.6033, Acc: 0.6754, Val Loss: 0.6293, Val Acc: 0.6463
Epoch 39/100, Loss: 0.6009, Acc: 0.6805, Val Loss: 0.6229, Val Acc: 0.6296
Epoch 40/100, Loss: 0.5996, Acc: 0.6808, Val Loss: 0.6236, Val Acc: 0.6422
Epoch 41/100, Loss: 0.5990, Acc: 0.6825, Val Loss: 0.6553, Val Acc: 0.6248
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5972, Acc: 0.6852, Val Loss: 0.6613, Val Acc: 0.6326
Epoch 43/100, Loss: 0.5962, Acc: 0.6855, Val Loss: 0.6469, Val Acc: 0.6185
Epoch 44/100, Loss: 0.5964, Acc: 0.6845, Val Loss: 0.6573, Val Acc: 0.6270
Epoch 45/100, Loss: 0.5952, Acc: 0.6879, Val Loss: 0.6616, Val Acc: 0.6215
Epoch 46/100, Loss: 0.5951, Acc: 0.6860, Val Loss: 0.6551, Val Acc: 0.6293
Epoch 47/100, Loss: 0.5944, Acc: 0.6875, Val Loss: 0.6470, Val Acc: 0.6367
Epoch 48/100, Loss: 0.5938, Acc: 0.6881, Val Loss: 0.6561, Val Acc: 0.6341
Epoch 49/100, Loss: 0.5933, Acc: 0.6895, Val Loss: 0.6363, Val Acc: 0.6348
Epoch 50/100, Loss: 0.5933, Acc: 0.6892, Val Loss: 0.6350, Val Acc: 0.6433
Epoch 51/100, Loss: 0.5926, Acc: 0.6899, Val Loss: 0.6542, Val Acc: 0.6341
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5923, Acc: 0.6899, Val Loss: 0.6541, Val Acc: 0.6311
Epoch 53/100, Loss: 0.5915, Acc: 0.6893, Val Loss: 0.6555, Val Acc: 0.6333
Epoch 54/100, Loss: 0.5916, Acc: 0.6896, Val Loss: 0.6572, Val Acc: 0.6319
Epoch 55/100, Loss: 0.5912, Acc: 0.6906, Val Loss: 0.6521, Val Acc: 0.6285
Epoch 56/100, Loss: 0.5909, Acc: 0.6907, Val Loss: 0.6628, Val Acc: 0.6289
Epoch 57/100, Loss: 0.5910, Acc: 0.6913, Val Loss: 0.6606, Val Acc: 0.6285
Epoch 58/100, Loss: 0.5908, Acc: 0.6907, Val Loss: 0.6542, Val Acc: 0.6322
Epoch 59/100, Loss: 0.5904, Acc: 0.6924, Val Loss: 0.6552, Val Acc: 0.6330
Epoch 60/100, Loss: 0.5903, Acc: 0.6915, Val Loss: 0.6527, Val Acc: 0.6330
Epoch 61/100, Loss: 0.5899, Acc: 0.6924, Val Loss: 0.6608, Val Acc: 0.6274
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5896, Acc: 0.6920, Val Loss: 0.6568, Val Acc: 0.6296
Epoch 63/100, Loss: 0.5894, Acc: 0.6913, Val Loss: 0.6535, Val Acc: 0.6307
Epoch 64/100, Loss: 0.5894, Acc: 0.6926, Val Loss: 0.6524, Val Acc: 0.6337
Epoch 65/100, Loss: 0.5893, Acc: 0.6917, Val Loss: 0.6539, Val Acc: 0.6311
Epoch 66/100, Loss: 0.5892, Acc: 0.6919, Val Loss: 0.6652, Val Acc: 0.6293
Epoch 67/100, Loss: 0.5890, Acc: 0.6923, Val Loss: 0.6587, Val Acc: 0.6270
Epoch 68/100, Loss: 0.5889, Acc: 0.6929, Val Loss: 0.6526, Val Acc: 0.6333
Epoch 69/100, Loss: 0.5889, Acc: 0.6913, Val Loss: 0.6625, Val Acc: 0.6263
Epoch 70/100, Loss: 0.5885, Acc: 0.6926, Val Loss: 0.6649, Val Acc: 0.6267
Epoch 71/100, Loss: 0.5885, Acc: 0.6918, Val Loss: 0.6656, Val Acc: 0.6274
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5882, Acc: 0.6913, Val Loss: 0.6613, Val Acc: 0.6281
Epoch 73/100, Loss: 0.5881, Acc: 0.6946, Val Loss: 0.6589, Val Acc: 0.6315
Epoch 74/100, Loss: 0.5881, Acc: 0.6929, Val Loss: 0.6622, Val Acc: 0.6270
Epoch 75/100, Loss: 0.5880, Acc: 0.6934, Val Loss: 0.6602, Val Acc: 0.6307
Epoch 76/100, Loss: 0.5880, Acc: 0.6927, Val Loss: 0.6604, Val Acc: 0.6289
Epoch 77/100, Loss: 0.5878, Acc: 0.6928, Val Loss: 0.6658, Val Acc: 0.6256
Epoch 78/100, Loss: 0.5878, Acc: 0.6919, Val Loss: 0.6621, Val Acc: 0.6274
Epoch 79/100, Loss: 0.5877, Acc: 0.6928, Val Loss: 0.6633, Val Acc: 0.6259
Epoch 80/100, Loss: 0.5876, Acc: 0.6929, Val Loss: 0.6612, Val Acc: 0.6296
Epoch 81/100, Loss: 0.5874, Acc: 0.6938, Val Loss: 0.6665, Val Acc: 0.6256
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5874, Acc: 0.6947, Val Loss: 0.6657, Val Acc: 0.6244
Epoch 83/100, Loss: 0.5873, Acc: 0.6935, Val Loss: 0.6629, Val Acc: 0.6259
Epoch 84/100, Loss: 0.5873, Acc: 0.6942, Val Loss: 0.6597, Val Acc: 0.6296
Epoch 85/100, Loss: 0.5873, Acc: 0.6933, Val Loss: 0.6600, Val Acc: 0.6285
Epoch 86/100, Loss: 0.5873, Acc: 0.6946, Val Loss: 0.6650, Val Acc: 0.6248
Epoch 87/100, Loss: 0.5871, Acc: 0.6930, Val Loss: 0.6643, Val Acc: 0.6256
Epoch 88/100, Loss: 0.5870, Acc: 0.6933, Val Loss: 0.6677, Val Acc: 0.6248
Epoch 89/100, Loss: 0.5871, Acc: 0.6939, Val Loss: 0.6636, Val Acc: 0.6248
Epoch 90/100, Loss: 0.5868, Acc: 0.6943, Val Loss: 0.6601, Val Acc: 0.6289
Epoch 91/100, Loss: 0.5868, Acc: 0.6938, Val Loss: 0.6662, Val Acc: 0.6248
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5868, Acc: 0.6943, Val Loss: 0.6622, Val Acc: 0.6263
Epoch 93/100, Loss: 0.5866, Acc: 0.6936, Val Loss: 0.6637, Val Acc: 0.6256
Epoch 94/100, Loss: 0.5865, Acc: 0.6939, Val Loss: 0.6743, Val Acc: 0.6270
Epoch 95/100, Loss: 0.5866, Acc: 0.6942, Val Loss: 0.6643, Val Acc: 0.6252
Epoch 96/100, Loss: 0.5864, Acc: 0.6940, Val Loss: 0.6637, Val Acc: 0.6270
Epoch 97/100, Loss: 0.5863, Acc: 0.6952, Val Loss: 0.6575, Val Acc: 0.6333
Epoch 98/100, Loss: 0.5864, Acc: 0.6943, Val Loss: 0.6688, Val Acc: 0.6244
Epoch 99/100, Loss: 0.5863, Acc: 0.6946, Val Loss: 0.6707, Val Acc: 0.6244
Epoch 100/100, Loss: 0.5862, Acc: 0.6947, Val Loss: 0.6677, Val Acc: 0.6233

##############################
Resultados para principal:  013  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21 
 {'training': [0.5861661572702243, 0.6946593001841621, 0.724115892628888, 0.6271217712177122, 0.6721376310065256], 'validate': [0.6676719252799832, 0.6233333333333333, 0.5782840523509453, 0.8902985074626866, 0.7011460476050544], 'test': [0.7790839570873188, 0.4908284023668639, 0.48416988416988416, 0.3732142857142857, 0.4215126050420168]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  063  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  063  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6938, Acc: 0.5004, Val Loss: 0.6928, Val Acc: 0.5037
Mejor modelo guardado con Val Loss: 0.6928
Epoch 2/100, Loss: 0.6936, Acc: 0.4887, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 3/100, Loss: 0.6937, Acc: 0.4967, Val Loss: 0.6928, Val Acc: 0.5037
Epoch 4/100, Loss: 0.6934, Acc: 0.5031, Val Loss: 0.6933, Val Acc: 0.4963
Epoch 5/100, Loss: 0.6934, Acc: 0.5001, Val Loss: 0.6934, Val Acc: 0.4963
Epoch 6/100, Loss: 0.6936, Acc: 0.4893, Val Loss: 0.6928, Val Acc: 0.5037
Mejor modelo guardado con Val Loss: 0.6928
Epoch 7/100, Loss: 0.6936, Acc: 0.4973, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 8/100, Loss: 0.6936, Acc: 0.4952, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 9/100, Loss: 0.6937, Acc: 0.5010, Val Loss: 0.6941, Val Acc: 0.4963
Epoch 10/100, Loss: 0.6933, Acc: 0.5020, Val Loss: 0.6947, Val Acc: 0.4963
Epoch 11/100, Loss: 0.6934, Acc: 0.4975, Val Loss: 0.6928, Val Acc: 0.5037
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6932, Acc: 0.5103, Val Loss: 0.6938, Val Acc: 0.4963
Epoch 13/100, Loss: 0.6933, Acc: 0.4956, Val Loss: 0.6929, Val Acc: 0.5037
Epoch 14/100, Loss: 0.6933, Acc: 0.4987, Val Loss: 0.6933, Val Acc: 0.4963
Epoch 15/100, Loss: 0.6933, Acc: 0.4972, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 16/100, Loss: 0.6934, Acc: 0.4940, Val Loss: 0.6936, Val Acc: 0.4963
Epoch 17/100, Loss: 0.6933, Acc: 0.4969, Val Loss: 0.6938, Val Acc: 0.4963
Epoch 18/100, Loss: 0.6933, Acc: 0.4994, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 19/100, Loss: 0.6932, Acc: 0.5059, Val Loss: 0.6928, Val Acc: 0.5037
Mejor modelo guardado con Val Loss: 0.6928
Epoch 20/100, Loss: 0.6934, Acc: 0.4882, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 21/100, Loss: 0.6934, Acc: 0.4963, Val Loss: 0.6929, Val Acc: 0.5037
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4963, Val Loss: 0.6933, Val Acc: 0.4963
Epoch 23/100, Loss: 0.6932, Acc: 0.4939, Val Loss: 0.6934, Val Acc: 0.4963
Epoch 24/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6929, Val Acc: 0.5037
Epoch 25/100, Loss: 0.6933, Acc: 0.4972, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 26/100, Loss: 0.6933, Acc: 0.4865, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 27/100, Loss: 0.6932, Acc: 0.5029, Val Loss: 0.6934, Val Acc: 0.4963
Epoch 28/100, Loss: 0.6933, Acc: 0.4899, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 29/100, Loss: 0.6933, Acc: 0.4948, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 30/100, Loss: 0.6932, Acc: 0.5007, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 31/100, Loss: 0.6932, Acc: 0.4948, Val Loss: 0.6930, Val Acc: 0.5037
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6932, Acc: 0.4978, Val Loss: 0.6929, Val Acc: 0.5037
Epoch 33/100, Loss: 0.6932, Acc: 0.4969, Val Loss: 0.6931, Val Acc: 0.4963
Epoch 34/100, Loss: 0.6932, Acc: 0.4899, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 35/100, Loss: 0.6932, Acc: 0.5013, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 36/100, Loss: 0.6932, Acc: 0.4954, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 37/100, Loss: 0.6932, Acc: 0.4919, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 38/100, Loss: 0.6932, Acc: 0.4974, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 39/100, Loss: 0.6932, Acc: 0.4988, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 40/100, Loss: 0.6932, Acc: 0.4901, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 41/100, Loss: 0.6932, Acc: 0.4915, Val Loss: 0.6931, Val Acc: 0.5037
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 43/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 44/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 45/100, Loss: 0.6932, Acc: 0.4996, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 46/100, Loss: 0.6932, Acc: 0.4963, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 47/100, Loss: 0.6932, Acc: 0.4948, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 48/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 49/100, Loss: 0.6932, Acc: 0.4978, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 50/100, Loss: 0.6932, Acc: 0.4991, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 51/100, Loss: 0.6932, Acc: 0.4877, Val Loss: 0.6932, Val Acc: 0.4963
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6932, Acc: 0.5007, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 53/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 54/100, Loss: 0.6932, Acc: 0.4917, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 55/100, Loss: 0.6932, Acc: 0.4977, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 56/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 57/100, Loss: 0.6932, Acc: 0.4950, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 58/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 59/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 60/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 61/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 63/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 64/100, Loss: 0.6932, Acc: 0.4947, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 65/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 66/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 67/100, Loss: 0.6931, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 68/100, Loss: 0.6931, Acc: 0.4985, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 69/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 70/100, Loss: 0.6931, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 71/100, Loss: 0.6931, Acc: 0.5008, Val Loss: 0.6931, Val Acc: 0.5037
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6931, Acc: 0.5015, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 73/100, Loss: 0.6931, Acc: 0.5022, Val Loss: 0.6931, Val Acc: 0.5056
Epoch 74/100, Loss: 0.6930, Acc: 0.5091, Val Loss: 0.6929, Val Acc: 0.5300
Epoch 75/100, Loss: 0.6927, Acc: 0.5289, Val Loss: 0.6917, Val Acc: 0.5856
Mejor modelo guardado con Val Loss: 0.6917
Epoch 76/100, Loss: 0.6922, Acc: 0.5329, Val Loss: 0.6904, Val Acc: 0.6159
Mejor modelo guardado con Val Loss: 0.6904
Epoch 77/100, Loss: 0.6921, Acc: 0.5333, Val Loss: 0.6901, Val Acc: 0.6170
Mejor modelo guardado con Val Loss: 0.6901
Epoch 78/100, Loss: 0.6920, Acc: 0.5338, Val Loss: 0.6899, Val Acc: 0.6059
Mejor modelo guardado con Val Loss: 0.6899
Epoch 79/100, Loss: 0.6920, Acc: 0.5349, Val Loss: 0.6898, Val Acc: 0.6037
Mejor modelo guardado con Val Loss: 0.6898
Epoch 80/100, Loss: 0.6919, Acc: 0.5330, Val Loss: 0.6897, Val Acc: 0.6033
Mejor modelo guardado con Val Loss: 0.6897
Epoch 81/100, Loss: 0.6919, Acc: 0.5339, Val Loss: 0.6896, Val Acc: 0.6041
Mejor modelo guardado con Val Loss: 0.6896
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6919, Acc: 0.5348, Val Loss: 0.6895, Val Acc: 0.6048
Mejor modelo guardado con Val Loss: 0.6895
Epoch 83/100, Loss: 0.6919, Acc: 0.5347, Val Loss: 0.6894, Val Acc: 0.6037
Mejor modelo guardado con Val Loss: 0.6894
Epoch 84/100, Loss: 0.6919, Acc: 0.5345, Val Loss: 0.6893, Val Acc: 0.6041
Mejor modelo guardado con Val Loss: 0.6893
Epoch 85/100, Loss: 0.6918, Acc: 0.5344, Val Loss: 0.6893, Val Acc: 0.5996
Mejor modelo guardado con Val Loss: 0.6893
Epoch 86/100, Loss: 0.6918, Acc: 0.5347, Val Loss: 0.6891, Val Acc: 0.6007
Mejor modelo guardado con Val Loss: 0.6891
Epoch 87/100, Loss: 0.6918, Acc: 0.5339, Val Loss: 0.6891, Val Acc: 0.6019
Mejor modelo guardado con Val Loss: 0.6891
Epoch 88/100, Loss: 0.6918, Acc: 0.5326, Val Loss: 0.6891, Val Acc: 0.6026
Mejor modelo guardado con Val Loss: 0.6891
Epoch 89/100, Loss: 0.6918, Acc: 0.5329, Val Loss: 0.6890, Val Acc: 0.6033
Mejor modelo guardado con Val Loss: 0.6890
Epoch 90/100, Loss: 0.6917, Acc: 0.5330, Val Loss: 0.6889, Val Acc: 0.6052
Mejor modelo guardado con Val Loss: 0.6889
Epoch 91/100, Loss: 0.6917, Acc: 0.5332, Val Loss: 0.6888, Val Acc: 0.6056
Mejor modelo guardado con Val Loss: 0.6888
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6917, Acc: 0.5336, Val Loss: 0.6887, Val Acc: 0.6048
Mejor modelo guardado con Val Loss: 0.6887
Epoch 93/100, Loss: 0.6917, Acc: 0.5336, Val Loss: 0.6886, Val Acc: 0.6037
Mejor modelo guardado con Val Loss: 0.6886
Epoch 94/100, Loss: 0.6917, Acc: 0.5320, Val Loss: 0.6886, Val Acc: 0.6037
Mejor modelo guardado con Val Loss: 0.6886
Epoch 95/100, Loss: 0.6916, Acc: 0.5338, Val Loss: 0.6885, Val Acc: 0.6030
Mejor modelo guardado con Val Loss: 0.6885
Epoch 96/100, Loss: 0.6916, Acc: 0.5334, Val Loss: 0.6884, Val Acc: 0.6044
Mejor modelo guardado con Val Loss: 0.6884
Epoch 97/100, Loss: 0.6915, Acc: 0.5344, Val Loss: 0.6884, Val Acc: 0.6033
Mejor modelo guardado con Val Loss: 0.6884
Epoch 98/100, Loss: 0.6914, Acc: 0.5366, Val Loss: 0.6881, Val Acc: 0.6096
Mejor modelo guardado con Val Loss: 0.6881
Epoch 99/100, Loss: 0.6912, Acc: 0.5390, Val Loss: 0.6879, Val Acc: 0.6063
Mejor modelo guardado con Val Loss: 0.6879
Epoch 100/100, Loss: 0.6910, Acc: 0.5397, Val Loss: 0.6875, Val Acc: 0.6059
Mejor modelo guardado con Val Loss: 0.6875

##############################
Resultados para principal:  063  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21 
 {'training': [0.6910329643753572, 0.5396869244935544, 0.5427237669981734, 0.4933579335793358, 0.5168647917270707], 'validate': [0.687497521555701, 0.605925925925926, 0.6304347826086957, 0.49776119402985075, 0.5562969140950792], 'test': [0.6908805572761679, 0.5343195266272189, 0.5322777101096224, 0.5202380952380953, 0.5261890427453342]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  070  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  070  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6886, Acc: 0.5466, Val Loss: 0.6954, Val Acc: 0.4663
Mejor modelo guardado con Val Loss: 0.6954
Epoch 2/100, Loss: 0.6901, Acc: 0.5417, Val Loss: 0.6987, Val Acc: 0.4726
Epoch 3/100, Loss: 0.6909, Acc: 0.5439, Val Loss: 0.6929, Val Acc: 0.5037
Mejor modelo guardado con Val Loss: 0.6929
Epoch 4/100, Loss: 0.6937, Acc: 0.4901, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 5/100, Loss: 0.6934, Acc: 0.5062, Val Loss: 0.6928, Val Acc: 0.5037
Mejor modelo guardado con Val Loss: 0.6928
Epoch 6/100, Loss: 0.6935, Acc: 0.4984, Val Loss: 0.6929, Val Acc: 0.5033
Epoch 7/100, Loss: 0.6935, Acc: 0.4959, Val Loss: 0.6928, Val Acc: 0.5037
Epoch 8/100, Loss: 0.6934, Acc: 0.5035, Val Loss: 0.6932, Val Acc: 0.4959
Epoch 9/100, Loss: 0.6935, Acc: 0.4884, Val Loss: 0.6928, Val Acc: 0.5037
Epoch 10/100, Loss: 0.6934, Acc: 0.4972, Val Loss: 0.6932, Val Acc: 0.4956
Epoch 11/100, Loss: 0.6935, Acc: 0.5026, Val Loss: 0.6930, Val Acc: 0.5037
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6934, Acc: 0.5063, Val Loss: 0.6929, Val Acc: 0.5037
Epoch 13/100, Loss: 0.6933, Acc: 0.4979, Val Loss: 0.6932, Val Acc: 0.4952
Epoch 14/100, Loss: 0.6934, Acc: 0.4977, Val Loss: 0.6929, Val Acc: 0.5037
Epoch 15/100, Loss: 0.6932, Acc: 0.5002, Val Loss: 0.6935, Val Acc: 0.4963
Epoch 16/100, Loss: 0.6934, Acc: 0.4939, Val Loss: 0.6928, Val Acc: 0.5037
Epoch 17/100, Loss: 0.6934, Acc: 0.4920, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 18/100, Loss: 0.6929, Acc: 0.5010, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 19/100, Loss: 0.6934, Acc: 0.4980, Val Loss: 0.6936, Val Acc: 0.4963
Epoch 20/100, Loss: 0.6932, Acc: 0.4979, Val Loss: 0.6933, Val Acc: 0.4963
Epoch 21/100, Loss: 0.6934, Acc: 0.4967, Val Loss: 0.6941, Val Acc: 0.4963
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4972, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 23/100, Loss: 0.6932, Acc: 0.4983, Val Loss: 0.6932, Val Acc: 0.4959
Epoch 24/100, Loss: 0.6933, Acc: 0.4915, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 25/100, Loss: 0.6933, Acc: 0.4921, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 26/100, Loss: 0.6933, Acc: 0.5014, Val Loss: 0.6932, Val Acc: 0.4959
Epoch 27/100, Loss: 0.6934, Acc: 0.5010, Val Loss: 0.6929, Val Acc: 0.5037
Epoch 28/100, Loss: 0.6932, Acc: 0.4985, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 29/100, Loss: 0.6931, Acc: 0.4982, Val Loss: 0.7027, Val Acc: 0.5037
Epoch 30/100, Loss: 0.6890, Acc: 0.5518, Val Loss: 0.7028, Val Acc: 0.4159
Epoch 31/100, Loss: 0.6881, Acc: 0.5606, Val Loss: 0.7028, Val Acc: 0.4115
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6868, Acc: 0.5716, Val Loss: 0.7031, Val Acc: 0.4130
Epoch 33/100, Loss: 0.6865, Acc: 0.5734, Val Loss: 0.7042, Val Acc: 0.4096
Epoch 34/100, Loss: 0.6863, Acc: 0.5739, Val Loss: 0.7056, Val Acc: 0.4063
Epoch 35/100, Loss: 0.6861, Acc: 0.5727, Val Loss: 0.7069, Val Acc: 0.3993
Epoch 36/100, Loss: 0.6856, Acc: 0.5731, Val Loss: 0.7059, Val Acc: 0.4067
Epoch 37/100, Loss: 0.6847, Acc: 0.5738, Val Loss: 0.7125, Val Acc: 0.3956
Epoch 38/100, Loss: 0.6841, Acc: 0.5748, Val Loss: 0.7114, Val Acc: 0.3981
Epoch 39/100, Loss: 0.6836, Acc: 0.5767, Val Loss: 0.7135, Val Acc: 0.3956
Epoch 40/100, Loss: 0.6834, Acc: 0.5771, Val Loss: 0.7151, Val Acc: 0.3959
Epoch 41/100, Loss: 0.6829, Acc: 0.5772, Val Loss: 0.7129, Val Acc: 0.3996
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6826, Acc: 0.5786, Val Loss: 0.7157, Val Acc: 0.3967
Epoch 43/100, Loss: 0.6825, Acc: 0.5791, Val Loss: 0.7166, Val Acc: 0.3963
Epoch 44/100, Loss: 0.6824, Acc: 0.5785, Val Loss: 0.7149, Val Acc: 0.4004
Epoch 45/100, Loss: 0.6822, Acc: 0.5782, Val Loss: 0.7146, Val Acc: 0.4026
Epoch 46/100, Loss: 0.6819, Acc: 0.5784, Val Loss: 0.7161, Val Acc: 0.4000
Epoch 47/100, Loss: 0.6818, Acc: 0.5773, Val Loss: 0.7180, Val Acc: 0.3956
Epoch 48/100, Loss: 0.6816, Acc: 0.5778, Val Loss: 0.7187, Val Acc: 0.3952
Epoch 49/100, Loss: 0.6815, Acc: 0.5807, Val Loss: 0.7188, Val Acc: 0.3959
Epoch 50/100, Loss: 0.6810, Acc: 0.5824, Val Loss: 0.7232, Val Acc: 0.3952
Epoch 51/100, Loss: 0.6804, Acc: 0.5798, Val Loss: 0.7241, Val Acc: 0.3922
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6802, Acc: 0.5771, Val Loss: 0.7239, Val Acc: 0.3937
Epoch 53/100, Loss: 0.6801, Acc: 0.5803, Val Loss: 0.7252, Val Acc: 0.3919
Epoch 54/100, Loss: 0.6799, Acc: 0.5785, Val Loss: 0.7241, Val Acc: 0.3941
Epoch 55/100, Loss: 0.6799, Acc: 0.5789, Val Loss: 0.7259, Val Acc: 0.3893
Epoch 56/100, Loss: 0.6797, Acc: 0.5806, Val Loss: 0.7272, Val Acc: 0.3944
Epoch 57/100, Loss: 0.6798, Acc: 0.5811, Val Loss: 0.7254, Val Acc: 0.3930
Epoch 58/100, Loss: 0.6796, Acc: 0.5799, Val Loss: 0.7261, Val Acc: 0.3915
Epoch 59/100, Loss: 0.6797, Acc: 0.5795, Val Loss: 0.7265, Val Acc: 0.3937
Epoch 60/100, Loss: 0.6795, Acc: 0.5824, Val Loss: 0.7252, Val Acc: 0.3967
Epoch 61/100, Loss: 0.6794, Acc: 0.5809, Val Loss: 0.7274, Val Acc: 0.3907
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6793, Acc: 0.5806, Val Loss: 0.7275, Val Acc: 0.3904
Epoch 63/100, Loss: 0.6793, Acc: 0.5802, Val Loss: 0.7281, Val Acc: 0.3893
Epoch 64/100, Loss: 0.6792, Acc: 0.5818, Val Loss: 0.7278, Val Acc: 0.3919
Epoch 65/100, Loss: 0.6791, Acc: 0.5809, Val Loss: 0.7274, Val Acc: 0.3937
Epoch 66/100, Loss: 0.6791, Acc: 0.5801, Val Loss: 0.7279, Val Acc: 0.3926
Epoch 67/100, Loss: 0.6790, Acc: 0.5818, Val Loss: 0.7273, Val Acc: 0.3948
Epoch 68/100, Loss: 0.6789, Acc: 0.5807, Val Loss: 0.7273, Val Acc: 0.3959
Epoch 69/100, Loss: 0.6788, Acc: 0.5799, Val Loss: 0.7274, Val Acc: 0.3944
Epoch 70/100, Loss: 0.6787, Acc: 0.5797, Val Loss: 0.7283, Val Acc: 0.3933
Epoch 71/100, Loss: 0.6787, Acc: 0.5808, Val Loss: 0.7279, Val Acc: 0.3937
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6786, Acc: 0.5795, Val Loss: 0.7281, Val Acc: 0.3933
Epoch 73/100, Loss: 0.6786, Acc: 0.5802, Val Loss: 0.7281, Val Acc: 0.3944
Epoch 74/100, Loss: 0.6785, Acc: 0.5804, Val Loss: 0.7286, Val Acc: 0.3922
Epoch 75/100, Loss: 0.6785, Acc: 0.5812, Val Loss: 0.7283, Val Acc: 0.3937
Epoch 76/100, Loss: 0.6784, Acc: 0.5806, Val Loss: 0.7285, Val Acc: 0.3933
Epoch 77/100, Loss: 0.6784, Acc: 0.5805, Val Loss: 0.7286, Val Acc: 0.3933
Epoch 78/100, Loss: 0.6783, Acc: 0.5820, Val Loss: 0.7283, Val Acc: 0.3933
Epoch 79/100, Loss: 0.6783, Acc: 0.5810, Val Loss: 0.7284, Val Acc: 0.3948
Epoch 80/100, Loss: 0.6782, Acc: 0.5822, Val Loss: 0.7281, Val Acc: 0.3970
Epoch 81/100, Loss: 0.6782, Acc: 0.5808, Val Loss: 0.7284, Val Acc: 0.3974
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6782, Acc: 0.5800, Val Loss: 0.7284, Val Acc: 0.3970
Epoch 83/100, Loss: 0.6781, Acc: 0.5808, Val Loss: 0.7291, Val Acc: 0.3959
Epoch 84/100, Loss: 0.6781, Acc: 0.5810, Val Loss: 0.7289, Val Acc: 0.3937
Epoch 85/100, Loss: 0.6780, Acc: 0.5804, Val Loss: 0.7288, Val Acc: 0.3959
Epoch 86/100, Loss: 0.6780, Acc: 0.5808, Val Loss: 0.7290, Val Acc: 0.3941
Epoch 87/100, Loss: 0.6779, Acc: 0.5808, Val Loss: 0.7287, Val Acc: 0.3978
Epoch 88/100, Loss: 0.6779, Acc: 0.5815, Val Loss: 0.7290, Val Acc: 0.3956
Epoch 89/100, Loss: 0.6779, Acc: 0.5813, Val Loss: 0.7288, Val Acc: 0.3970
Epoch 90/100, Loss: 0.6778, Acc: 0.5817, Val Loss: 0.7291, Val Acc: 0.3952
Epoch 91/100, Loss: 0.6778, Acc: 0.5805, Val Loss: 0.7291, Val Acc: 0.3981
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6778, Acc: 0.5802, Val Loss: 0.7292, Val Acc: 0.3959
Epoch 93/100, Loss: 0.6777, Acc: 0.5804, Val Loss: 0.7288, Val Acc: 0.3989
Epoch 94/100, Loss: 0.6777, Acc: 0.5822, Val Loss: 0.7290, Val Acc: 0.3978
Epoch 95/100, Loss: 0.6777, Acc: 0.5811, Val Loss: 0.7291, Val Acc: 0.3974
Epoch 96/100, Loss: 0.6776, Acc: 0.5830, Val Loss: 0.7292, Val Acc: 0.3974
Epoch 97/100, Loss: 0.6776, Acc: 0.5818, Val Loss: 0.7292, Val Acc: 0.3974
Epoch 98/100, Loss: 0.6775, Acc: 0.5821, Val Loss: 0.7292, Val Acc: 0.3985
Epoch 99/100, Loss: 0.6775, Acc: 0.5813, Val Loss: 0.7292, Val Acc: 0.3989
Epoch 100/100, Loss: 0.6775, Acc: 0.5812, Val Loss: 0.7292, Val Acc: 0.3989

##############################
Resultados para principal:  070  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21 
 {'training': [0.6774972825638717, 0.5812154696132596, 0.5813129429317418, 0.5750922509225093, 0.5781858653311074], 'validate': [0.7291857350704282, 0.3988888888888889, 0.3867093674939952, 0.3604477611940298, 0.373117033603708], 'test': [0.6933085873441877, 0.5029585798816568, 0.0, 0.0, 0.0]}

######################################## 
########################################
Grupo en indetificación:  ['095', '065', '013', '063', '070', '040']  --- principal:  040  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  040  --- group:  ['095', '065', '013', '063', '070', '040']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6697, Acc: 0.6161, Val Loss: 0.6439, Val Acc: 0.6704
Mejor modelo guardado con Val Loss: 0.6439
Epoch 2/100, Loss: 0.6464, Acc: 0.6543, Val Loss: 0.6370, Val Acc: 0.6544
Mejor modelo guardado con Val Loss: 0.6370
Epoch 3/100, Loss: 0.6180, Acc: 0.6719, Val Loss: 0.6158, Val Acc: 0.6730
Mejor modelo guardado con Val Loss: 0.6158
Epoch 4/100, Loss: 0.6187, Acc: 0.6681, Val Loss: 0.6228, Val Acc: 0.6715
Epoch 5/100, Loss: 0.6134, Acc: 0.6781, Val Loss: 0.5883, Val Acc: 0.7304
Mejor modelo guardado con Val Loss: 0.5883
Epoch 6/100, Loss: 0.5853, Acc: 0.7029, Val Loss: 0.5825, Val Acc: 0.7067
Mejor modelo guardado con Val Loss: 0.5825
Epoch 7/100, Loss: 0.5738, Acc: 0.7098, Val Loss: 0.5740, Val Acc: 0.7219
Mejor modelo guardado con Val Loss: 0.5740
Epoch 8/100, Loss: 0.5932, Acc: 0.6895, Val Loss: 0.6576, Val Acc: 0.6548
Epoch 9/100, Loss: 0.6039, Acc: 0.6746, Val Loss: 0.5633, Val Acc: 0.7352
Mejor modelo guardado con Val Loss: 0.5633
Epoch 10/100, Loss: 0.5870, Acc: 0.6936, Val Loss: 0.5642, Val Acc: 0.7348
Epoch 11/100, Loss: 0.5928, Acc: 0.6916, Val Loss: 0.5703, Val Acc: 0.7119
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.5767, Acc: 0.7198, Val Loss: 0.5679, Val Acc: 0.7485
Epoch 13/100, Loss: 0.5713, Acc: 0.7171, Val Loss: 0.5537, Val Acc: 0.7411
Mejor modelo guardado con Val Loss: 0.5537
Epoch 14/100, Loss: 0.5662, Acc: 0.7150, Val Loss: 0.5495, Val Acc: 0.7222
Mejor modelo guardado con Val Loss: 0.5495
Epoch 15/100, Loss: 0.5633, Acc: 0.7168, Val Loss: 0.5681, Val Acc: 0.7341
Epoch 16/100, Loss: 0.5640, Acc: 0.7199, Val Loss: 0.5755, Val Acc: 0.7163
Epoch 17/100, Loss: 0.5610, Acc: 0.7226, Val Loss: 0.5509, Val Acc: 0.7189
Epoch 18/100, Loss: 0.5559, Acc: 0.7222, Val Loss: 0.5656, Val Acc: 0.7322
Epoch 19/100, Loss: 0.5583, Acc: 0.7239, Val Loss: 0.5593, Val Acc: 0.7348
Epoch 20/100, Loss: 0.5543, Acc: 0.7302, Val Loss: 0.5805, Val Acc: 0.7211
Epoch 21/100, Loss: 0.5526, Acc: 0.7326, Val Loss: 0.5366, Val Acc: 0.7478
Mejor modelo guardado con Val Loss: 0.5366
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5460, Acc: 0.7377, Val Loss: 0.5326, Val Acc: 0.7500
Mejor modelo guardado con Val Loss: 0.5326
Epoch 23/100, Loss: 0.5447, Acc: 0.7389, Val Loss: 0.5425, Val Acc: 0.7393
Epoch 24/100, Loss: 0.5431, Acc: 0.7381, Val Loss: 0.5340, Val Acc: 0.7500
Epoch 25/100, Loss: 0.5425, Acc: 0.7379, Val Loss: 0.5545, Val Acc: 0.7278
Epoch 26/100, Loss: 0.5436, Acc: 0.7387, Val Loss: 0.5330, Val Acc: 0.7463
Epoch 27/100, Loss: 0.5434, Acc: 0.7377, Val Loss: 0.5306, Val Acc: 0.7548
Mejor modelo guardado con Val Loss: 0.5306
Epoch 28/100, Loss: 0.5411, Acc: 0.7376, Val Loss: 0.5277, Val Acc: 0.7452
Mejor modelo guardado con Val Loss: 0.5277
Epoch 29/100, Loss: 0.5414, Acc: 0.7358, Val Loss: 0.5444, Val Acc: 0.7448
Epoch 30/100, Loss: 0.5402, Acc: 0.7396, Val Loss: 0.5497, Val Acc: 0.7452
Epoch 31/100, Loss: 0.5401, Acc: 0.7396, Val Loss: 0.5286, Val Acc: 0.7504
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5361, Acc: 0.7439, Val Loss: 0.5329, Val Acc: 0.7496
Epoch 33/100, Loss: 0.5346, Acc: 0.7448, Val Loss: 0.5377, Val Acc: 0.7478
Epoch 34/100, Loss: 0.5338, Acc: 0.7483, Val Loss: 0.5266, Val Acc: 0.7519
Mejor modelo guardado con Val Loss: 0.5266
Epoch 35/100, Loss: 0.5360, Acc: 0.7456, Val Loss: 0.5305, Val Acc: 0.7570
Epoch 36/100, Loss: 0.5351, Acc: 0.7492, Val Loss: 0.5302, Val Acc: 0.7533
Epoch 37/100, Loss: 0.5343, Acc: 0.7483, Val Loss: 0.5254, Val Acc: 0.7574
Mejor modelo guardado con Val Loss: 0.5254
Epoch 38/100, Loss: 0.5328, Acc: 0.7492, Val Loss: 0.5315, Val Acc: 0.7526
Epoch 39/100, Loss: 0.5333, Acc: 0.7486, Val Loss: 0.5318, Val Acc: 0.7489
Epoch 40/100, Loss: 0.5346, Acc: 0.7465, Val Loss: 0.5380, Val Acc: 0.7500
Epoch 41/100, Loss: 0.5332, Acc: 0.7465, Val Loss: 0.5367, Val Acc: 0.7478
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5315, Acc: 0.7500, Val Loss: 0.5280, Val Acc: 0.7541
Epoch 43/100, Loss: 0.5311, Acc: 0.7498, Val Loss: 0.5255, Val Acc: 0.7559
Epoch 44/100, Loss: 0.5312, Acc: 0.7490, Val Loss: 0.5282, Val Acc: 0.7537
Epoch 45/100, Loss: 0.5304, Acc: 0.7490, Val Loss: 0.5357, Val Acc: 0.7470
Epoch 46/100, Loss: 0.5310, Acc: 0.7504, Val Loss: 0.5347, Val Acc: 0.7459
Epoch 47/100, Loss: 0.5306, Acc: 0.7517, Val Loss: 0.5258, Val Acc: 0.7522
Epoch 48/100, Loss: 0.5303, Acc: 0.7503, Val Loss: 0.5284, Val Acc: 0.7533
Epoch 49/100, Loss: 0.5296, Acc: 0.7516, Val Loss: 0.5245, Val Acc: 0.7548
Mejor modelo guardado con Val Loss: 0.5245
Epoch 50/100, Loss: 0.5296, Acc: 0.7516, Val Loss: 0.5285, Val Acc: 0.7522
Epoch 51/100, Loss: 0.5289, Acc: 0.7515, Val Loss: 0.5276, Val Acc: 0.7533
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5285, Acc: 0.7519, Val Loss: 0.5308, Val Acc: 0.7493
Epoch 53/100, Loss: 0.5286, Acc: 0.7526, Val Loss: 0.5285, Val Acc: 0.7515
Epoch 54/100, Loss: 0.5282, Acc: 0.7525, Val Loss: 0.5359, Val Acc: 0.7467
Epoch 55/100, Loss: 0.5282, Acc: 0.7531, Val Loss: 0.5279, Val Acc: 0.7544
Epoch 56/100, Loss: 0.5276, Acc: 0.7532, Val Loss: 0.5280, Val Acc: 0.7544
Epoch 57/100, Loss: 0.5260, Acc: 0.7546, Val Loss: 0.5259, Val Acc: 0.7559
Epoch 58/100, Loss: 0.5262, Acc: 0.7551, Val Loss: 0.5269, Val Acc: 0.7556
Epoch 59/100, Loss: 0.5254, Acc: 0.7549, Val Loss: 0.5317, Val Acc: 0.7519
Epoch 60/100, Loss: 0.5253, Acc: 0.7543, Val Loss: 0.5243, Val Acc: 0.7541
Mejor modelo guardado con Val Loss: 0.5243
Epoch 61/100, Loss: 0.5255, Acc: 0.7565, Val Loss: 0.5273, Val Acc: 0.7563
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5248, Acc: 0.7567, Val Loss: 0.5284, Val Acc: 0.7548
Epoch 63/100, Loss: 0.5247, Acc: 0.7552, Val Loss: 0.5299, Val Acc: 0.7522
Epoch 64/100, Loss: 0.5247, Acc: 0.7563, Val Loss: 0.5274, Val Acc: 0.7556
Epoch 65/100, Loss: 0.5245, Acc: 0.7545, Val Loss: 0.5259, Val Acc: 0.7533
Epoch 66/100, Loss: 0.5245, Acc: 0.7563, Val Loss: 0.5279, Val Acc: 0.7556
Epoch 67/100, Loss: 0.5243, Acc: 0.7557, Val Loss: 0.5305, Val Acc: 0.7504
Epoch 68/100, Loss: 0.5242, Acc: 0.7564, Val Loss: 0.5279, Val Acc: 0.7563
Epoch 69/100, Loss: 0.5237, Acc: 0.7570, Val Loss: 0.5297, Val Acc: 0.7515
Epoch 70/100, Loss: 0.5233, Acc: 0.7558, Val Loss: 0.5284, Val Acc: 0.7541
Epoch 71/100, Loss: 0.5235, Acc: 0.7544, Val Loss: 0.5274, Val Acc: 0.7567
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5232, Acc: 0.7539, Val Loss: 0.5289, Val Acc: 0.7544
Epoch 73/100, Loss: 0.5232, Acc: 0.7565, Val Loss: 0.5284, Val Acc: 0.7585
Epoch 74/100, Loss: 0.5230, Acc: 0.7558, Val Loss: 0.5286, Val Acc: 0.7541
Epoch 75/100, Loss: 0.5230, Acc: 0.7554, Val Loss: 0.5279, Val Acc: 0.7581
Epoch 76/100, Loss: 0.5230, Acc: 0.7564, Val Loss: 0.5279, Val Acc: 0.7585
Epoch 77/100, Loss: 0.5226, Acc: 0.7569, Val Loss: 0.5302, Val Acc: 0.7515
Epoch 78/100, Loss: 0.5228, Acc: 0.7554, Val Loss: 0.5287, Val Acc: 0.7548
Epoch 79/100, Loss: 0.5228, Acc: 0.7553, Val Loss: 0.5280, Val Acc: 0.7544
Epoch 80/100, Loss: 0.5227, Acc: 0.7558, Val Loss: 0.5297, Val Acc: 0.7522
Epoch 81/100, Loss: 0.5226, Acc: 0.7555, Val Loss: 0.5298, Val Acc: 0.7526
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5227, Acc: 0.7556, Val Loss: 0.5268, Val Acc: 0.7585
Epoch 83/100, Loss: 0.5224, Acc: 0.7558, Val Loss: 0.5263, Val Acc: 0.7567
Epoch 84/100, Loss: 0.5225, Acc: 0.7561, Val Loss: 0.5284, Val Acc: 0.7533
Epoch 85/100, Loss: 0.5224, Acc: 0.7563, Val Loss: 0.5280, Val Acc: 0.7548
Epoch 86/100, Loss: 0.5224, Acc: 0.7559, Val Loss: 0.5271, Val Acc: 0.7585
Epoch 87/100, Loss: 0.5223, Acc: 0.7567, Val Loss: 0.5283, Val Acc: 0.7567
Epoch 88/100, Loss: 0.5221, Acc: 0.7554, Val Loss: 0.5280, Val Acc: 0.7585
Epoch 89/100, Loss: 0.5219, Acc: 0.7572, Val Loss: 0.5307, Val Acc: 0.7522
Epoch 90/100, Loss: 0.5203, Acc: 0.7562, Val Loss: 0.5153, Val Acc: 0.7633
Mejor modelo guardado con Val Loss: 0.5153
Epoch 91/100, Loss: 0.5149, Acc: 0.7561, Val Loss: 0.5083, Val Acc: 0.7656
Mejor modelo guardado con Val Loss: 0.5083
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5134, Acc: 0.7571, Val Loss: 0.5091, Val Acc: 0.7670
Epoch 93/100, Loss: 0.5125, Acc: 0.7578, Val Loss: 0.5069, Val Acc: 0.7663
Mejor modelo guardado con Val Loss: 0.5069
Epoch 94/100, Loss: 0.5124, Acc: 0.7564, Val Loss: 0.5070, Val Acc: 0.7652
Epoch 95/100, Loss: 0.5121, Acc: 0.7573, Val Loss: 0.5088, Val Acc: 0.7648
Epoch 96/100, Loss: 0.5121, Acc: 0.7566, Val Loss: 0.5091, Val Acc: 0.7641
Epoch 97/100, Loss: 0.5120, Acc: 0.7568, Val Loss: 0.5079, Val Acc: 0.7663
Epoch 98/100, Loss: 0.5118, Acc: 0.7564, Val Loss: 0.5096, Val Acc: 0.7633
Epoch 99/100, Loss: 0.5112, Acc: 0.7575, Val Loss: 0.5126, Val Acc: 0.7630
Epoch 100/100, Loss: 0.5114, Acc: 0.7587, Val Loss: 0.5099, Val Acc: 0.7619

##############################
Resultados para principal:  040  --- grupo:  ['095', '065', '013', '063', '070', '040']  --- window & package numer:  21 
 {'training': [0.5113758617123627, 0.7586556169429097, 0.752480606169944, 0.7695571955719557, 0.7609231049895102], 'validate': [0.5099260207525519, 0.7618518518518519, 0.7662337662337663, 0.7485074626865672, 0.757266893167233], 'test': [0.6631770998520671, 0.643491124260355, 0.611975483262612, 0.7726190476190476, 0.682978163641147]}

##############################
Resultados para window:  21 
 {'095:065:013:063:070:040': {'training': [0.6370506663129255, 0.6325966850828729, 0.6084977238239757, 0.7398523985239852, 0.6677768526228143], 'validate': [0.7006737458151441, 0.5381481481481482, 0.5253682487725041, 0.7186567164179104, 0.6069965332492909], 'test': [0.690195233192084, 0.5701183431952662, 0.5438393202008498, 0.8380952380952381, 0.6596392597798079]}, '065:095:013:063:070:040': {'training': [0.6398268149922127, 0.624585635359116, 0.6306674450282156, 0.597970479704797, 0.6138838905199356], 'validate': [0.6219034208807834, 0.662962962962963, 0.6725521669341894, 0.6253731343283582, 0.6481051817478731], 'test': [0.6276996709265799, 0.6319526627218935, 0.6713836477987422, 0.5083333333333333, 0.5785907859078591]}, '013:095:065:063:070:040': {'training': [0.5861661572702243, 0.6946593001841621, 0.724115892628888, 0.6271217712177122, 0.6721376310065256], 'validate': [0.6676719252799832, 0.6233333333333333, 0.5782840523509453, 0.8902985074626866, 0.7011460476050544], 'test': [0.7790839570873188, 0.4908284023668639, 0.48416988416988416, 0.3732142857142857, 0.4215126050420168]}, '063:095:065:013:070:040': {'training': [0.6910329643753572, 0.5396869244935544, 0.5427237669981734, 0.4933579335793358, 0.5168647917270707], 'validate': [0.687497521555701, 0.605925925925926, 0.6304347826086957, 0.49776119402985075, 0.5562969140950792], 'test': [0.6908805572761679, 0.5343195266272189, 0.5322777101096224, 0.5202380952380953, 0.5261890427453342]}, '070:095:065:013:063:040': {'training': [0.6774972825638717, 0.5812154696132596, 0.5813129429317418, 0.5750922509225093, 0.5781858653311074], 'validate': [0.7291857350704282, 0.3988888888888889, 0.3867093674939952, 0.3604477611940298, 0.373117033603708], 'test': [0.6933085873441877, 0.5029585798816568, 0.0, 0.0, 0.0]}, '040:095:065:013:063:070': {'training': [0.5113758617123627, 0.7586556169429097, 0.752480606169944, 0.7695571955719557, 0.7609231049895102], 'validate': [0.5099260207525519, 0.7618518518518519, 0.7662337662337663, 0.7485074626865672, 0.757266893167233], 'test': [0.6631770998520671, 0.643491124260355, 0.611975483262612, 0.7726190476190476, 0.682978163641147]}}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  102  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  102  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6015, Acc: 0.7289, Val Loss: 0.3788, Val Acc: 0.9867
Mejor modelo guardado con Val Loss: 0.3788
Epoch 2/100, Loss: 0.5271, Acc: 0.7600, Val Loss: 0.2530, Val Acc: 0.9670
Mejor modelo guardado con Val Loss: 0.2530
Epoch 3/100, Loss: 0.4975, Acc: 0.7680, Val Loss: 0.2075, Val Acc: 0.9737
Mejor modelo guardado con Val Loss: 0.2075
Epoch 4/100, Loss: 0.4753, Acc: 0.7819, Val Loss: 0.1883, Val Acc: 0.9733
Mejor modelo guardado con Val Loss: 0.1883
Epoch 5/100, Loss: 0.4603, Acc: 0.7855, Val Loss: 0.1813, Val Acc: 0.9663
Mejor modelo guardado con Val Loss: 0.1813
Epoch 6/100, Loss: 0.4582, Acc: 0.7825, Val Loss: 0.2385, Val Acc: 0.9444
Epoch 7/100, Loss: 0.4564, Acc: 0.7870, Val Loss: 0.1855, Val Acc: 0.9578
Epoch 8/100, Loss: 0.4397, Acc: 0.7978, Val Loss: 0.2073, Val Acc: 0.9341
Epoch 9/100, Loss: 0.4379, Acc: 0.7981, Val Loss: 0.1402, Val Acc: 0.9648
Mejor modelo guardado con Val Loss: 0.1402
Epoch 10/100, Loss: 0.4332, Acc: 0.7967, Val Loss: 0.1380, Val Acc: 0.9693
Mejor modelo guardado con Val Loss: 0.1380
Epoch 11/100, Loss: 0.4282, Acc: 0.8006, Val Loss: 0.1702, Val Acc: 0.9485
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4090, Acc: 0.8109, Val Loss: 0.1576, Val Acc: 0.9630
Epoch 13/100, Loss: 0.4065, Acc: 0.8128, Val Loss: 0.1375, Val Acc: 0.9785
Mejor modelo guardado con Val Loss: 0.1375
Epoch 14/100, Loss: 0.4000, Acc: 0.8131, Val Loss: 0.1384, Val Acc: 0.9637
Epoch 15/100, Loss: 0.3994, Acc: 0.8130, Val Loss: 0.1335, Val Acc: 0.9715
Mejor modelo guardado con Val Loss: 0.1335
Epoch 16/100, Loss: 0.3904, Acc: 0.8192, Val Loss: 0.1286, Val Acc: 0.9737
Mejor modelo guardado con Val Loss: 0.1286
Epoch 17/100, Loss: 0.3913, Acc: 0.8166, Val Loss: 0.1280, Val Acc: 0.9659
Mejor modelo guardado con Val Loss: 0.1280
Epoch 18/100, Loss: 0.3884, Acc: 0.8164, Val Loss: 0.1457, Val Acc: 0.9511
Epoch 19/100, Loss: 0.3839, Acc: 0.8242, Val Loss: 0.1392, Val Acc: 0.9585
Epoch 20/100, Loss: 0.3852, Acc: 0.8244, Val Loss: 0.1414, Val Acc: 0.9556
Epoch 21/100, Loss: 0.3808, Acc: 0.8196, Val Loss: 0.1382, Val Acc: 0.9626
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.3713, Acc: 0.8252, Val Loss: 0.1393, Val Acc: 0.9581
Epoch 23/100, Loss: 0.3685, Acc: 0.8253, Val Loss: 0.1286, Val Acc: 0.9670
Epoch 24/100, Loss: 0.3673, Acc: 0.8287, Val Loss: 0.1283, Val Acc: 0.9622
Epoch 25/100, Loss: 0.3653, Acc: 0.8286, Val Loss: 0.1266, Val Acc: 0.9585
Mejor modelo guardado con Val Loss: 0.1266
Epoch 26/100, Loss: 0.3664, Acc: 0.8282, Val Loss: 0.1240, Val Acc: 0.9681
Mejor modelo guardado con Val Loss: 0.1240
Epoch 27/100, Loss: 0.3595, Acc: 0.8320, Val Loss: 0.1484, Val Acc: 0.9422
Epoch 28/100, Loss: 0.3603, Acc: 0.8291, Val Loss: 0.1196, Val Acc: 0.9659
Mejor modelo guardado con Val Loss: 0.1196
Epoch 29/100, Loss: 0.3574, Acc: 0.8320, Val Loss: 0.1433, Val Acc: 0.9444
Epoch 30/100, Loss: 0.3573, Acc: 0.8362, Val Loss: 0.1220, Val Acc: 0.9656
Epoch 31/100, Loss: 0.3555, Acc: 0.8337, Val Loss: 0.1340, Val Acc: 0.9463
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.3506, Acc: 0.8390, Val Loss: 0.1253, Val Acc: 0.9533
Epoch 33/100, Loss: 0.3477, Acc: 0.8374, Val Loss: 0.1396, Val Acc: 0.9463
Epoch 34/100, Loss: 0.3472, Acc: 0.8376, Val Loss: 0.1172, Val Acc: 0.9663
Mejor modelo guardado con Val Loss: 0.1172
Epoch 35/100, Loss: 0.3476, Acc: 0.8381, Val Loss: 0.1136, Val Acc: 0.9637
Mejor modelo guardado con Val Loss: 0.1136
Epoch 36/100, Loss: 0.3453, Acc: 0.8390, Val Loss: 0.1173, Val Acc: 0.9644
Epoch 37/100, Loss: 0.3448, Acc: 0.8375, Val Loss: 0.1240, Val Acc: 0.9537
Epoch 38/100, Loss: 0.3432, Acc: 0.8395, Val Loss: 0.1348, Val Acc: 0.9493
Epoch 39/100, Loss: 0.3453, Acc: 0.8393, Val Loss: 0.1195, Val Acc: 0.9578
Epoch 40/100, Loss: 0.3427, Acc: 0.8391, Val Loss: 0.1387, Val Acc: 0.9456
Epoch 41/100, Loss: 0.3413, Acc: 0.8396, Val Loss: 0.1223, Val Acc: 0.9522
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.3385, Acc: 0.8406, Val Loss: 0.1140, Val Acc: 0.9678
Epoch 43/100, Loss: 0.3374, Acc: 0.8424, Val Loss: 0.1180, Val Acc: 0.9604
Epoch 44/100, Loss: 0.3371, Acc: 0.8435, Val Loss: 0.1187, Val Acc: 0.9600
Epoch 45/100, Loss: 0.3378, Acc: 0.8411, Val Loss: 0.1169, Val Acc: 0.9593
Epoch 46/100, Loss: 0.3358, Acc: 0.8438, Val Loss: 0.1232, Val Acc: 0.9533
Epoch 47/100, Loss: 0.3366, Acc: 0.8414, Val Loss: 0.1171, Val Acc: 0.9604
Epoch 48/100, Loss: 0.3352, Acc: 0.8448, Val Loss: 0.1220, Val Acc: 0.9530
Epoch 49/100, Loss: 0.3347, Acc: 0.8436, Val Loss: 0.1163, Val Acc: 0.9622
Epoch 50/100, Loss: 0.3347, Acc: 0.8420, Val Loss: 0.1170, Val Acc: 0.9596
Epoch 51/100, Loss: 0.3335, Acc: 0.8436, Val Loss: 0.1189, Val Acc: 0.9593
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.3324, Acc: 0.8452, Val Loss: 0.1142, Val Acc: 0.9600
Epoch 53/100, Loss: 0.3328, Acc: 0.8448, Val Loss: 0.1128, Val Acc: 0.9622
Mejor modelo guardado con Val Loss: 0.1128
Epoch 54/100, Loss: 0.3322, Acc: 0.8457, Val Loss: 0.1191, Val Acc: 0.9574
Epoch 55/100, Loss: 0.3314, Acc: 0.8445, Val Loss: 0.1197, Val Acc: 0.9559
Epoch 56/100, Loss: 0.3315, Acc: 0.8464, Val Loss: 0.1162, Val Acc: 0.9633
Epoch 57/100, Loss: 0.3312, Acc: 0.8448, Val Loss: 0.1182, Val Acc: 0.9589
Epoch 58/100, Loss: 0.3308, Acc: 0.8441, Val Loss: 0.1161, Val Acc: 0.9581
Epoch 59/100, Loss: 0.3305, Acc: 0.8445, Val Loss: 0.1219, Val Acc: 0.9519
Epoch 60/100, Loss: 0.3297, Acc: 0.8438, Val Loss: 0.1150, Val Acc: 0.9596
Epoch 61/100, Loss: 0.3303, Acc: 0.8449, Val Loss: 0.1173, Val Acc: 0.9611
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.3292, Acc: 0.8466, Val Loss: 0.1229, Val Acc: 0.9533
Epoch 63/100, Loss: 0.3292, Acc: 0.8456, Val Loss: 0.1181, Val Acc: 0.9559
Epoch 64/100, Loss: 0.3295, Acc: 0.8449, Val Loss: 0.1152, Val Acc: 0.9611
Epoch 65/100, Loss: 0.3291, Acc: 0.8460, Val Loss: 0.1161, Val Acc: 0.9607
Epoch 66/100, Loss: 0.3289, Acc: 0.8459, Val Loss: 0.1168, Val Acc: 0.9589
Epoch 67/100, Loss: 0.3286, Acc: 0.8462, Val Loss: 0.1150, Val Acc: 0.9615
Epoch 68/100, Loss: 0.3285, Acc: 0.8459, Val Loss: 0.1146, Val Acc: 0.9622
Epoch 69/100, Loss: 0.3280, Acc: 0.8471, Val Loss: 0.1171, Val Acc: 0.9596
Epoch 70/100, Loss: 0.3276, Acc: 0.8487, Val Loss: 0.1197, Val Acc: 0.9563
Epoch 71/100, Loss: 0.3278, Acc: 0.8474, Val Loss: 0.1201, Val Acc: 0.9567
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.3269, Acc: 0.8483, Val Loss: 0.1163, Val Acc: 0.9611
Epoch 73/100, Loss: 0.3271, Acc: 0.8478, Val Loss: 0.1193, Val Acc: 0.9578
Epoch 74/100, Loss: 0.3269, Acc: 0.8474, Val Loss: 0.1183, Val Acc: 0.9589
Epoch 75/100, Loss: 0.3270, Acc: 0.8480, Val Loss: 0.1161, Val Acc: 0.9611
Epoch 76/100, Loss: 0.3266, Acc: 0.8485, Val Loss: 0.1216, Val Acc: 0.9556
Epoch 77/100, Loss: 0.3266, Acc: 0.8483, Val Loss: 0.1213, Val Acc: 0.9559
Epoch 78/100, Loss: 0.3265, Acc: 0.8485, Val Loss: 0.1174, Val Acc: 0.9600
Epoch 79/100, Loss: 0.3263, Acc: 0.8514, Val Loss: 0.1154, Val Acc: 0.9611
Epoch 80/100, Loss: 0.3260, Acc: 0.8492, Val Loss: 0.1194, Val Acc: 0.9570
Epoch 81/100, Loss: 0.3262, Acc: 0.8485, Val Loss: 0.1168, Val Acc: 0.9607
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.3260, Acc: 0.8486, Val Loss: 0.1172, Val Acc: 0.9607
Epoch 83/100, Loss: 0.3258, Acc: 0.8504, Val Loss: 0.1158, Val Acc: 0.9611
Epoch 84/100, Loss: 0.3258, Acc: 0.8492, Val Loss: 0.1163, Val Acc: 0.9607
Epoch 85/100, Loss: 0.3257, Acc: 0.8479, Val Loss: 0.1180, Val Acc: 0.9589
Epoch 86/100, Loss: 0.3256, Acc: 0.8495, Val Loss: 0.1153, Val Acc: 0.9611
Epoch 87/100, Loss: 0.3256, Acc: 0.8488, Val Loss: 0.1168, Val Acc: 0.9604
Epoch 88/100, Loss: 0.3254, Acc: 0.8486, Val Loss: 0.1190, Val Acc: 0.9585
Epoch 89/100, Loss: 0.3252, Acc: 0.8484, Val Loss: 0.1171, Val Acc: 0.9596
Epoch 90/100, Loss: 0.3253, Acc: 0.8494, Val Loss: 0.1178, Val Acc: 0.9585
Epoch 91/100, Loss: 0.3251, Acc: 0.8486, Val Loss: 0.1154, Val Acc: 0.9611
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.3251, Acc: 0.8499, Val Loss: 0.1172, Val Acc: 0.9589
Epoch 93/100, Loss: 0.3250, Acc: 0.8493, Val Loss: 0.1188, Val Acc: 0.9589
Epoch 94/100, Loss: 0.3249, Acc: 0.8507, Val Loss: 0.1192, Val Acc: 0.9570
Epoch 95/100, Loss: 0.3249, Acc: 0.8499, Val Loss: 0.1202, Val Acc: 0.9563
Epoch 96/100, Loss: 0.3247, Acc: 0.8496, Val Loss: 0.1168, Val Acc: 0.9596
Epoch 97/100, Loss: 0.3246, Acc: 0.8503, Val Loss: 0.1205, Val Acc: 0.9556
Epoch 98/100, Loss: 0.3244, Acc: 0.8506, Val Loss: 0.1175, Val Acc: 0.9589
Epoch 99/100, Loss: 0.3243, Acc: 0.8492, Val Loss: 0.1167, Val Acc: 0.9593
Epoch 100/100, Loss: 0.3242, Acc: 0.8495, Val Loss: 0.1176, Val Acc: 0.9581

##############################
Resultados para principal:  102  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21 
 {'training': [0.32415425803779896, 0.8495395948434622, 0.8560948081264108, 0.8396678966789668, 0.8478017883755589], 'validate': [0.11756837833672762, 0.9581481481481482, 0.9849802371541502, 0.9298507462686567, 0.9566218809980807], 'test': [0.6190017694431655, 0.7014792899408284, 0.6783625730994152, 0.7595238095238095, 0.7166526256669475]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  020  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  020  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6408, Acc: 0.6845, Val Loss: 0.7557, Val Acc: 0.3737
Mejor modelo guardado con Val Loss: 0.7557
Epoch 2/100, Loss: 0.5900, Acc: 0.7060, Val Loss: 0.7880, Val Acc: 0.4256
Epoch 3/100, Loss: 0.5660, Acc: 0.7212, Val Loss: 0.8353, Val Acc: 0.4378
Epoch 4/100, Loss: 0.5400, Acc: 0.7362, Val Loss: 0.8698, Val Acc: 0.4289
Epoch 5/100, Loss: 0.5304, Acc: 0.7447, Val Loss: 0.8343, Val Acc: 0.4593
Epoch 6/100, Loss: 0.5245, Acc: 0.7525, Val Loss: 0.9132, Val Acc: 0.4581
Epoch 7/100, Loss: 0.5149, Acc: 0.7542, Val Loss: 0.8952, Val Acc: 0.4541
Epoch 8/100, Loss: 0.5069, Acc: 0.7588, Val Loss: 0.9188, Val Acc: 0.4511
Epoch 9/100, Loss: 0.5009, Acc: 0.7643, Val Loss: 0.9289, Val Acc: 0.4426
Epoch 10/100, Loss: 0.4935, Acc: 0.7680, Val Loss: 0.9222, Val Acc: 0.4230
Epoch 11/100, Loss: 0.4919, Acc: 0.7711, Val Loss: 0.9790, Val Acc: 0.4344
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4816, Acc: 0.7786, Val Loss: 0.9293, Val Acc: 0.4737
Epoch 13/100, Loss: 0.4810, Acc: 0.7773, Val Loss: 0.9456, Val Acc: 0.4559
Epoch 14/100, Loss: 0.4780, Acc: 0.7809, Val Loss: 0.9315, Val Acc: 0.4622
Epoch 15/100, Loss: 0.4777, Acc: 0.7804, Val Loss: 0.9316, Val Acc: 0.4563
Epoch 16/100, Loss: 0.4754, Acc: 0.7857, Val Loss: 0.9383, Val Acc: 0.4752
Epoch 17/100, Loss: 0.4730, Acc: 0.7856, Val Loss: 0.9128, Val Acc: 0.4785
Epoch 18/100, Loss: 0.4758, Acc: 0.7825, Val Loss: 0.9384, Val Acc: 0.4611
Epoch 19/100, Loss: 0.4702, Acc: 0.7863, Val Loss: 0.9259, Val Acc: 0.4541
Epoch 20/100, Loss: 0.4656, Acc: 0.7910, Val Loss: 0.9295, Val Acc: 0.4711
Epoch 21/100, Loss: 0.4633, Acc: 0.7929, Val Loss: 0.9319, Val Acc: 0.4715
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4611, Acc: 0.7935, Val Loss: 0.9386, Val Acc: 0.4615
Epoch 23/100, Loss: 0.4583, Acc: 0.7972, Val Loss: 0.9439, Val Acc: 0.4526
Epoch 24/100, Loss: 0.4606, Acc: 0.7933, Val Loss: 0.9310, Val Acc: 0.4722
Epoch 25/100, Loss: 0.4578, Acc: 0.7959, Val Loss: 0.9311, Val Acc: 0.4707
Epoch 26/100, Loss: 0.4579, Acc: 0.7952, Val Loss: 0.9539, Val Acc: 0.4478
Epoch 27/100, Loss: 0.4581, Acc: 0.7943, Val Loss: 0.9470, Val Acc: 0.4600
Epoch 28/100, Loss: 0.4536, Acc: 0.7989, Val Loss: 0.9576, Val Acc: 0.4504
Epoch 29/100, Loss: 0.4550, Acc: 0.7979, Val Loss: 0.9576, Val Acc: 0.4444
Epoch 30/100, Loss: 0.4551, Acc: 0.7993, Val Loss: 0.9319, Val Acc: 0.4759
Epoch 31/100, Loss: 0.4467, Acc: 0.8004, Val Loss: 0.9603, Val Acc: 0.4659
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4356, Acc: 0.8054, Val Loss: 0.9524, Val Acc: 0.4693
Epoch 33/100, Loss: 0.4339, Acc: 0.8069, Val Loss: 0.9686, Val Acc: 0.4663
Epoch 34/100, Loss: 0.4330, Acc: 0.8067, Val Loss: 0.9712, Val Acc: 0.4537
Epoch 35/100, Loss: 0.4326, Acc: 0.8083, Val Loss: 0.9663, Val Acc: 0.4615
Epoch 36/100, Loss: 0.4318, Acc: 0.8067, Val Loss: 0.9695, Val Acc: 0.4656
Epoch 37/100, Loss: 0.4316, Acc: 0.8083, Val Loss: 0.9756, Val Acc: 0.4574
Epoch 38/100, Loss: 0.4314, Acc: 0.8084, Val Loss: 0.9641, Val Acc: 0.4711
Epoch 39/100, Loss: 0.4321, Acc: 0.8054, Val Loss: 0.9668, Val Acc: 0.4704
Epoch 40/100, Loss: 0.4300, Acc: 0.8078, Val Loss: 0.9716, Val Acc: 0.4678
Epoch 41/100, Loss: 0.4302, Acc: 0.8093, Val Loss: 0.9864, Val Acc: 0.4611
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4277, Acc: 0.8109, Val Loss: 0.9818, Val Acc: 0.4611
Epoch 43/100, Loss: 0.4268, Acc: 0.8101, Val Loss: 0.9859, Val Acc: 0.4559
Epoch 44/100, Loss: 0.4265, Acc: 0.8118, Val Loss: 0.9926, Val Acc: 0.4448
Epoch 45/100, Loss: 0.4269, Acc: 0.8091, Val Loss: 0.9951, Val Acc: 0.4459
Epoch 46/100, Loss: 0.4262, Acc: 0.8117, Val Loss: 0.9895, Val Acc: 0.4548
Epoch 47/100, Loss: 0.4267, Acc: 0.8098, Val Loss: 0.9890, Val Acc: 0.4519
Epoch 48/100, Loss: 0.4256, Acc: 0.8119, Val Loss: 0.9798, Val Acc: 0.4659
Epoch 49/100, Loss: 0.4255, Acc: 0.8116, Val Loss: 0.9842, Val Acc: 0.4604
Epoch 50/100, Loss: 0.4250, Acc: 0.8120, Val Loss: 0.9792, Val Acc: 0.4685
Epoch 51/100, Loss: 0.4248, Acc: 0.8114, Val Loss: 0.9854, Val Acc: 0.4596
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4239, Acc: 0.8120, Val Loss: 0.9861, Val Acc: 0.4622
Epoch 53/100, Loss: 0.4239, Acc: 0.8117, Val Loss: 0.9886, Val Acc: 0.4581
Epoch 54/100, Loss: 0.4233, Acc: 0.8127, Val Loss: 0.9813, Val Acc: 0.4652
Epoch 55/100, Loss: 0.4235, Acc: 0.8122, Val Loss: 0.9806, Val Acc: 0.4667
Epoch 56/100, Loss: 0.4236, Acc: 0.8116, Val Loss: 0.9810, Val Acc: 0.4670
Epoch 57/100, Loss: 0.4234, Acc: 0.8134, Val Loss: 0.9898, Val Acc: 0.4593
Epoch 58/100, Loss: 0.4228, Acc: 0.8134, Val Loss: 0.9875, Val Acc: 0.4641
Epoch 59/100, Loss: 0.4228, Acc: 0.8121, Val Loss: 0.9912, Val Acc: 0.4615
Epoch 60/100, Loss: 0.4228, Acc: 0.8137, Val Loss: 0.9908, Val Acc: 0.4611
Epoch 61/100, Loss: 0.4227, Acc: 0.8131, Val Loss: 0.9838, Val Acc: 0.4659
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4222, Acc: 0.8139, Val Loss: 0.9872, Val Acc: 0.4641
Epoch 63/100, Loss: 0.4219, Acc: 0.8132, Val Loss: 0.9876, Val Acc: 0.4659
Epoch 64/100, Loss: 0.4223, Acc: 0.8132, Val Loss: 0.9888, Val Acc: 0.4637
Epoch 65/100, Loss: 0.4219, Acc: 0.8141, Val Loss: 0.9871, Val Acc: 0.4644
Epoch 66/100, Loss: 0.4218, Acc: 0.8132, Val Loss: 0.9919, Val Acc: 0.4611
Epoch 67/100, Loss: 0.4219, Acc: 0.8134, Val Loss: 0.9915, Val Acc: 0.4611
Epoch 68/100, Loss: 0.4217, Acc: 0.8127, Val Loss: 0.9925, Val Acc: 0.4604
Epoch 69/100, Loss: 0.4216, Acc: 0.8145, Val Loss: 0.9884, Val Acc: 0.4641
Epoch 70/100, Loss: 0.4216, Acc: 0.8127, Val Loss: 0.9934, Val Acc: 0.4600
Epoch 71/100, Loss: 0.4214, Acc: 0.8139, Val Loss: 0.9889, Val Acc: 0.4641
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4213, Acc: 0.8149, Val Loss: 0.9920, Val Acc: 0.4607
Epoch 73/100, Loss: 0.4212, Acc: 0.8148, Val Loss: 0.9943, Val Acc: 0.4581
Epoch 74/100, Loss: 0.4211, Acc: 0.8149, Val Loss: 0.9903, Val Acc: 0.4622
Epoch 75/100, Loss: 0.4210, Acc: 0.8139, Val Loss: 0.9920, Val Acc: 0.4607
Epoch 76/100, Loss: 0.4210, Acc: 0.8145, Val Loss: 0.9933, Val Acc: 0.4604
Epoch 77/100, Loss: 0.4210, Acc: 0.8135, Val Loss: 0.9929, Val Acc: 0.4607
Epoch 78/100, Loss: 0.4210, Acc: 0.8151, Val Loss: 0.9931, Val Acc: 0.4607
Epoch 79/100, Loss: 0.4210, Acc: 0.8156, Val Loss: 0.9896, Val Acc: 0.4641
Epoch 80/100, Loss: 0.4208, Acc: 0.8151, Val Loss: 0.9911, Val Acc: 0.4626
Epoch 81/100, Loss: 0.4209, Acc: 0.8150, Val Loss: 0.9918, Val Acc: 0.4615
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4209, Acc: 0.8134, Val Loss: 0.9944, Val Acc: 0.4607
Epoch 83/100, Loss: 0.4207, Acc: 0.8150, Val Loss: 0.9923, Val Acc: 0.4619
Epoch 84/100, Loss: 0.4206, Acc: 0.8146, Val Loss: 0.9905, Val Acc: 0.4644
Epoch 85/100, Loss: 0.4207, Acc: 0.8150, Val Loss: 0.9928, Val Acc: 0.4619
Epoch 86/100, Loss: 0.4207, Acc: 0.8145, Val Loss: 0.9929, Val Acc: 0.4622
Epoch 87/100, Loss: 0.4206, Acc: 0.8145, Val Loss: 0.9907, Val Acc: 0.4637
Epoch 88/100, Loss: 0.4206, Acc: 0.8143, Val Loss: 0.9944, Val Acc: 0.4604
Epoch 89/100, Loss: 0.4204, Acc: 0.8153, Val Loss: 0.9948, Val Acc: 0.4611
Epoch 90/100, Loss: 0.4207, Acc: 0.8153, Val Loss: 0.9915, Val Acc: 0.4637
Epoch 91/100, Loss: 0.4205, Acc: 0.8140, Val Loss: 0.9945, Val Acc: 0.4604
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4202, Acc: 0.8146, Val Loss: 0.9939, Val Acc: 0.4611
Epoch 93/100, Loss: 0.4202, Acc: 0.8145, Val Loss: 0.9942, Val Acc: 0.4607
Epoch 94/100, Loss: 0.4203, Acc: 0.8147, Val Loss: 0.9917, Val Acc: 0.4633
Epoch 95/100, Loss: 0.4202, Acc: 0.8143, Val Loss: 0.9948, Val Acc: 0.4607
Epoch 96/100, Loss: 0.4203, Acc: 0.8137, Val Loss: 0.9936, Val Acc: 0.4615
Epoch 97/100, Loss: 0.4199, Acc: 0.8133, Val Loss: 1.0048, Val Acc: 0.4548
Epoch 98/100, Loss: 0.4184, Acc: 0.8153, Val Loss: 1.0050, Val Acc: 0.4552
Epoch 99/100, Loss: 0.4181, Acc: 0.8149, Val Loss: 1.0002, Val Acc: 0.4596
Epoch 100/100, Loss: 0.4182, Acc: 0.8146, Val Loss: 1.0047, Val Acc: 0.4552

##############################
Resultados para principal:  020  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21 
 {'training': [0.4182391260210322, 0.8146408839779006, 0.7706976005085016, 0.8948339483394834, 0.8281396738666439], 'validate': [1.0046862727680872, 0.4551851851851852, 0.47468109779667567, 0.9164179104477612, 0.6254138018843901], 'test': [0.644538606675166, 0.6174556213017751, 0.7300832342449465, 0.36547619047619045, 0.48710829036096787]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  125  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  125  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6930, Acc: 0.5035, Val Loss: 0.6935, Val Acc: 0.4970
Mejor modelo guardado con Val Loss: 0.6935
Epoch 2/100, Loss: 0.6934, Acc: 0.4952, Val Loss: 0.6927, Val Acc: 0.5037
Mejor modelo guardado con Val Loss: 0.6927
Epoch 3/100, Loss: 0.6932, Acc: 0.5016, Val Loss: 0.6935, Val Acc: 0.5037
Epoch 4/100, Loss: 0.6934, Acc: 0.4979, Val Loss: 0.6932, Val Acc: 0.5037
Epoch 5/100, Loss: 0.6939, Acc: 0.4930, Val Loss: 0.6941, Val Acc: 0.4963
Epoch 6/100, Loss: 0.6937, Acc: 0.4945, Val Loss: 0.6933, Val Acc: 0.4963
Epoch 7/100, Loss: 0.6935, Acc: 0.4967, Val Loss: 0.6929, Val Acc: 0.5037
Epoch 8/100, Loss: 0.6933, Acc: 0.4993, Val Loss: 0.6940, Val Acc: 0.4963
Epoch 9/100, Loss: 0.6933, Acc: 0.4980, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 10/100, Loss: 0.6935, Acc: 0.4882, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 11/100, Loss: 0.6934, Acc: 0.4989, Val Loss: 0.6928, Val Acc: 0.5037
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6933, Acc: 0.4974, Val Loss: 0.6936, Val Acc: 0.4963
Epoch 13/100, Loss: 0.6932, Acc: 0.4958, Val Loss: 0.6935, Val Acc: 0.4963
Epoch 14/100, Loss: 0.6931, Acc: 0.5053, Val Loss: 0.6928, Val Acc: 0.5037
Epoch 15/100, Loss: 0.6933, Acc: 0.5031, Val Loss: 0.6938, Val Acc: 0.4963
Epoch 16/100, Loss: 0.6933, Acc: 0.4923, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 17/100, Loss: 0.6932, Acc: 0.4959, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 18/100, Loss: 0.6933, Acc: 0.4940, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 19/100, Loss: 0.6933, Acc: 0.4947, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 20/100, Loss: 0.6934, Acc: 0.4928, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 21/100, Loss: 0.6933, Acc: 0.4985, Val Loss: 0.6928, Val Acc: 0.5037
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6933, Acc: 0.4971, Val Loss: 0.6929, Val Acc: 0.5037
Epoch 23/100, Loss: 0.6932, Acc: 0.4987, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 24/100, Loss: 0.6932, Acc: 0.4888, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 25/100, Loss: 0.6932, Acc: 0.4956, Val Loss: 0.6930, Val Acc: 0.5037
Epoch 26/100, Loss: 0.6932, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 27/100, Loss: 0.6933, Acc: 0.4998, Val Loss: 0.6933, Val Acc: 0.4963
Epoch 28/100, Loss: 0.6933, Acc: 0.4932, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 29/100, Loss: 0.6933, Acc: 0.5009, Val Loss: 0.6931, Val Acc: 0.5037
Epoch 30/100, Loss: 0.6932, Acc: 0.4917, Val Loss: 0.6932, Val Acc: 0.4963
Epoch 31/100, Loss: 0.6932, Acc: 0.4998, Val Loss: 0.6931, Val Acc: 0.5037
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6930, Acc: 0.5042, Val Loss: 0.6928, Val Acc: 0.5037
Epoch 33/100, Loss: 0.6918, Acc: 0.5322, Val Loss: 0.6927, Val Acc: 0.5148
Epoch 34/100, Loss: 0.6912, Acc: 0.5615, Val Loss: 0.6927, Val Acc: 0.5119
Epoch 35/100, Loss: 0.6907, Acc: 0.5649, Val Loss: 0.6927, Val Acc: 0.5230
Mejor modelo guardado con Val Loss: 0.6927
Epoch 36/100, Loss: 0.6900, Acc: 0.5631, Val Loss: 0.6932, Val Acc: 0.5133
Epoch 37/100, Loss: 0.6891, Acc: 0.5666, Val Loss: 0.6925, Val Acc: 0.5233
Mejor modelo guardado con Val Loss: 0.6925
Epoch 38/100, Loss: 0.6885, Acc: 0.5671, Val Loss: 0.6925, Val Acc: 0.5207
Mejor modelo guardado con Val Loss: 0.6925
Epoch 39/100, Loss: 0.6881, Acc: 0.5669, Val Loss: 0.6926, Val Acc: 0.5219
Epoch 40/100, Loss: 0.6874, Acc: 0.5738, Val Loss: 0.6924, Val Acc: 0.5233
Mejor modelo guardado con Val Loss: 0.6924
Epoch 41/100, Loss: 0.6871, Acc: 0.5736, Val Loss: 0.6925, Val Acc: 0.5226
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6867, Acc: 0.5745, Val Loss: 0.6924, Val Acc: 0.5193
Mejor modelo guardado con Val Loss: 0.6924
Epoch 43/100, Loss: 0.6866, Acc: 0.5736, Val Loss: 0.6923, Val Acc: 0.5185
Mejor modelo guardado con Val Loss: 0.6923
Epoch 44/100, Loss: 0.6862, Acc: 0.5777, Val Loss: 0.6922, Val Acc: 0.5167
Mejor modelo guardado con Val Loss: 0.6922
Epoch 45/100, Loss: 0.6863, Acc: 0.5736, Val Loss: 0.6923, Val Acc: 0.5237
Epoch 46/100, Loss: 0.6860, Acc: 0.5759, Val Loss: 0.6923, Val Acc: 0.5211
Epoch 47/100, Loss: 0.6858, Acc: 0.5776, Val Loss: 0.6922, Val Acc: 0.5189
Mejor modelo guardado con Val Loss: 0.6922
Epoch 48/100, Loss: 0.6857, Acc: 0.5762, Val Loss: 0.6922, Val Acc: 0.5230
Mejor modelo guardado con Val Loss: 0.6922
Epoch 49/100, Loss: 0.6855, Acc: 0.5787, Val Loss: 0.6921, Val Acc: 0.5193
Mejor modelo guardado con Val Loss: 0.6921
Epoch 50/100, Loss: 0.6853, Acc: 0.5761, Val Loss: 0.6921, Val Acc: 0.5215
Mejor modelo guardado con Val Loss: 0.6921
Epoch 51/100, Loss: 0.6852, Acc: 0.5800, Val Loss: 0.6922, Val Acc: 0.5237
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6851, Acc: 0.5784, Val Loss: 0.6922, Val Acc: 0.5211
Epoch 53/100, Loss: 0.6849, Acc: 0.5794, Val Loss: 0.6922, Val Acc: 0.5226
Epoch 54/100, Loss: 0.6848, Acc: 0.5807, Val Loss: 0.6921, Val Acc: 0.5241
Epoch 55/100, Loss: 0.6847, Acc: 0.5787, Val Loss: 0.6921, Val Acc: 0.5204
Mejor modelo guardado con Val Loss: 0.6921
Epoch 56/100, Loss: 0.6847, Acc: 0.5784, Val Loss: 0.6921, Val Acc: 0.5204
Mejor modelo guardado con Val Loss: 0.6921
Epoch 57/100, Loss: 0.6845, Acc: 0.5777, Val Loss: 0.6920, Val Acc: 0.5193
Mejor modelo guardado con Val Loss: 0.6920
Epoch 58/100, Loss: 0.6843, Acc: 0.5775, Val Loss: 0.6919, Val Acc: 0.5196
Mejor modelo guardado con Val Loss: 0.6919
Epoch 59/100, Loss: 0.6842, Acc: 0.5819, Val Loss: 0.6920, Val Acc: 0.5222
Epoch 60/100, Loss: 0.6841, Acc: 0.5807, Val Loss: 0.6919, Val Acc: 0.5185
Mejor modelo guardado con Val Loss: 0.6919
Epoch 61/100, Loss: 0.6839, Acc: 0.5802, Val Loss: 0.6917, Val Acc: 0.5196
Mejor modelo guardado con Val Loss: 0.6917
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6834, Acc: 0.5839, Val Loss: 0.6927, Val Acc: 0.5185
Epoch 63/100, Loss: 0.6833, Acc: 0.5788, Val Loss: 0.6925, Val Acc: 0.5196
Epoch 64/100, Loss: 0.6831, Acc: 0.5804, Val Loss: 0.6925, Val Acc: 0.5274
Epoch 65/100, Loss: 0.6831, Acc: 0.5795, Val Loss: 0.6926, Val Acc: 0.5274
Epoch 66/100, Loss: 0.6830, Acc: 0.5823, Val Loss: 0.6926, Val Acc: 0.5267
Epoch 67/100, Loss: 0.6830, Acc: 0.5809, Val Loss: 0.6927, Val Acc: 0.5296
Epoch 68/100, Loss: 0.6829, Acc: 0.5808, Val Loss: 0.6926, Val Acc: 0.5281
Epoch 69/100, Loss: 0.6828, Acc: 0.5798, Val Loss: 0.6927, Val Acc: 0.5281
Epoch 70/100, Loss: 0.6828, Acc: 0.5785, Val Loss: 0.6927, Val Acc: 0.5293
Epoch 71/100, Loss: 0.6828, Acc: 0.5799, Val Loss: 0.6927, Val Acc: 0.5296
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6826, Acc: 0.5793, Val Loss: 0.6928, Val Acc: 0.5293
Epoch 73/100, Loss: 0.6826, Acc: 0.5798, Val Loss: 0.6928, Val Acc: 0.5307
Epoch 74/100, Loss: 0.6826, Acc: 0.5804, Val Loss: 0.6928, Val Acc: 0.5270
Epoch 75/100, Loss: 0.6826, Acc: 0.5805, Val Loss: 0.6928, Val Acc: 0.5300
Epoch 76/100, Loss: 0.6826, Acc: 0.5802, Val Loss: 0.6928, Val Acc: 0.5296
Epoch 77/100, Loss: 0.6825, Acc: 0.5808, Val Loss: 0.6928, Val Acc: 0.5307
Epoch 78/100, Loss: 0.6825, Acc: 0.5802, Val Loss: 0.6928, Val Acc: 0.5307
Epoch 79/100, Loss: 0.6824, Acc: 0.5813, Val Loss: 0.6928, Val Acc: 0.5319
Epoch 80/100, Loss: 0.6824, Acc: 0.5800, Val Loss: 0.6929, Val Acc: 0.5322
Epoch 81/100, Loss: 0.6824, Acc: 0.5797, Val Loss: 0.6929, Val Acc: 0.5330
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6823, Acc: 0.5819, Val Loss: 0.6929, Val Acc: 0.5267
Epoch 83/100, Loss: 0.6823, Acc: 0.5807, Val Loss: 0.6929, Val Acc: 0.5322
Epoch 84/100, Loss: 0.6823, Acc: 0.5809, Val Loss: 0.6929, Val Acc: 0.5311
Epoch 85/100, Loss: 0.6823, Acc: 0.5805, Val Loss: 0.6929, Val Acc: 0.5278
Epoch 86/100, Loss: 0.6822, Acc: 0.5825, Val Loss: 0.6929, Val Acc: 0.5296
Epoch 87/100, Loss: 0.6822, Acc: 0.5806, Val Loss: 0.6929, Val Acc: 0.5322
Epoch 88/100, Loss: 0.6822, Acc: 0.5810, Val Loss: 0.6928, Val Acc: 0.5267
Epoch 89/100, Loss: 0.6821, Acc: 0.5811, Val Loss: 0.6929, Val Acc: 0.5300
Epoch 90/100, Loss: 0.6821, Acc: 0.5820, Val Loss: 0.6929, Val Acc: 0.5278
Epoch 91/100, Loss: 0.6821, Acc: 0.5797, Val Loss: 0.6929, Val Acc: 0.5322
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6820, Acc: 0.5819, Val Loss: 0.6930, Val Acc: 0.5333
Epoch 93/100, Loss: 0.6820, Acc: 0.5824, Val Loss: 0.6929, Val Acc: 0.5326
Epoch 94/100, Loss: 0.6820, Acc: 0.5812, Val Loss: 0.6929, Val Acc: 0.5322
Epoch 95/100, Loss: 0.6819, Acc: 0.5815, Val Loss: 0.6930, Val Acc: 0.5330
Epoch 96/100, Loss: 0.6819, Acc: 0.5805, Val Loss: 0.6930, Val Acc: 0.5326
Epoch 97/100, Loss: 0.6820, Acc: 0.5817, Val Loss: 0.6930, Val Acc: 0.5322
Epoch 98/100, Loss: 0.6819, Acc: 0.5810, Val Loss: 0.6929, Val Acc: 0.5319
Epoch 99/100, Loss: 0.6819, Acc: 0.5807, Val Loss: 0.6929, Val Acc: 0.5322
Epoch 100/100, Loss: 0.6818, Acc: 0.5813, Val Loss: 0.6929, Val Acc: 0.5289

##############################
Resultados para principal:  125  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21 
 {'training': [0.6817929769308747, 0.5813075506445672, 0.5777936196756371, 0.5981549815498155, 0.5877980237512465], 'validate': [0.6928516155065492, 0.5288888888888889, 0.5227272727272727, 0.5835820895522388, 0.5514809590973202], 'test': [0.6883430559680147, 0.5535502958579882, 0.5503237198351971, 0.5565476190476191, 0.5534181710565256]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  011  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  011  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6893, Acc: 0.5226, Val Loss: 0.6840, Val Acc: 0.6033
Mejor modelo guardado con Val Loss: 0.6840
Epoch 2/100, Loss: 0.6880, Acc: 0.5461, Val Loss: 0.6799, Val Acc: 0.5915
Mejor modelo guardado con Val Loss: 0.6799
Epoch 3/100, Loss: 0.6871, Acc: 0.5542, Val Loss: 0.6738, Val Acc: 0.7033
Mejor modelo guardado con Val Loss: 0.6738
Epoch 4/100, Loss: 0.6865, Acc: 0.5465, Val Loss: 0.6803, Val Acc: 0.6293
Epoch 5/100, Loss: 0.6879, Acc: 0.5448, Val Loss: 0.6757, Val Acc: 0.7422
Epoch 6/100, Loss: 0.6852, Acc: 0.5626, Val Loss: 0.6781, Val Acc: 0.6170
Epoch 7/100, Loss: 0.6840, Acc: 0.5682, Val Loss: 0.6824, Val Acc: 0.5889
Epoch 8/100, Loss: 0.6868, Acc: 0.5387, Val Loss: 0.6802, Val Acc: 0.5904
Epoch 9/100, Loss: 0.6851, Acc: 0.5576, Val Loss: 0.6527, Val Acc: 0.7289
Mejor modelo guardado con Val Loss: 0.6527
Epoch 10/100, Loss: 0.6830, Acc: 0.5680, Val Loss: 0.6585, Val Acc: 0.6889
Epoch 11/100, Loss: 0.6817, Acc: 0.5693, Val Loss: 0.6484, Val Acc: 0.7222
Mejor modelo guardado con Val Loss: 0.6484
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6795, Acc: 0.5760, Val Loss: 0.6479, Val Acc: 0.7181
Mejor modelo guardado con Val Loss: 0.6479
Epoch 13/100, Loss: 0.6785, Acc: 0.5809, Val Loss: 0.6570, Val Acc: 0.6789
Epoch 14/100, Loss: 0.6784, Acc: 0.5778, Val Loss: 0.6564, Val Acc: 0.6807
Epoch 15/100, Loss: 0.6789, Acc: 0.5775, Val Loss: 0.6420, Val Acc: 0.7256
Mejor modelo guardado con Val Loss: 0.6420
Epoch 16/100, Loss: 0.6779, Acc: 0.5799, Val Loss: 0.6417, Val Acc: 0.7196
Mejor modelo guardado con Val Loss: 0.6417
Epoch 17/100, Loss: 0.6775, Acc: 0.5795, Val Loss: 0.6425, Val Acc: 0.7144
Epoch 18/100, Loss: 0.6775, Acc: 0.5781, Val Loss: 0.6610, Val Acc: 0.6415
Epoch 19/100, Loss: 0.6763, Acc: 0.5835, Val Loss: 0.6439, Val Acc: 0.6981
Epoch 20/100, Loss: 0.6764, Acc: 0.5767, Val Loss: 0.6557, Val Acc: 0.6604
Epoch 21/100, Loss: 0.6761, Acc: 0.5809, Val Loss: 0.6478, Val Acc: 0.6826
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6754, Acc: 0.5821, Val Loss: 0.6499, Val Acc: 0.6748
Epoch 23/100, Loss: 0.6750, Acc: 0.5825, Val Loss: 0.6536, Val Acc: 0.6581
Epoch 24/100, Loss: 0.6748, Acc: 0.5828, Val Loss: 0.6433, Val Acc: 0.6915
Epoch 25/100, Loss: 0.6748, Acc: 0.5818, Val Loss: 0.6437, Val Acc: 0.6907
Epoch 26/100, Loss: 0.6746, Acc: 0.5826, Val Loss: 0.6503, Val Acc: 0.6681
Epoch 27/100, Loss: 0.6744, Acc: 0.5828, Val Loss: 0.6539, Val Acc: 0.6548
Epoch 28/100, Loss: 0.6749, Acc: 0.5793, Val Loss: 0.6432, Val Acc: 0.6889
Epoch 29/100, Loss: 0.6743, Acc: 0.5822, Val Loss: 0.6452, Val Acc: 0.6804
Epoch 30/100, Loss: 0.6739, Acc: 0.5820, Val Loss: 0.6522, Val Acc: 0.6559
Epoch 31/100, Loss: 0.6737, Acc: 0.5849, Val Loss: 0.6461, Val Acc: 0.6756
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.6734, Acc: 0.5855, Val Loss: 0.6408, Val Acc: 0.6911
Mejor modelo guardado con Val Loss: 0.6408
Epoch 33/100, Loss: 0.6733, Acc: 0.5836, Val Loss: 0.6408, Val Acc: 0.6904
Epoch 34/100, Loss: 0.6732, Acc: 0.5851, Val Loss: 0.6437, Val Acc: 0.6800
Epoch 35/100, Loss: 0.6732, Acc: 0.5860, Val Loss: 0.6413, Val Acc: 0.6889
Epoch 36/100, Loss: 0.6731, Acc: 0.5852, Val Loss: 0.6418, Val Acc: 0.6863
Epoch 37/100, Loss: 0.6731, Acc: 0.5853, Val Loss: 0.6485, Val Acc: 0.6652
Epoch 38/100, Loss: 0.6730, Acc: 0.5836, Val Loss: 0.6426, Val Acc: 0.6822
Epoch 39/100, Loss: 0.6727, Acc: 0.5865, Val Loss: 0.6347, Val Acc: 0.7037
Mejor modelo guardado con Val Loss: 0.6347
Epoch 40/100, Loss: 0.6730, Acc: 0.5836, Val Loss: 0.6505, Val Acc: 0.6556
Epoch 41/100, Loss: 0.6729, Acc: 0.5868, Val Loss: 0.6441, Val Acc: 0.6733
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.6726, Acc: 0.5846, Val Loss: 0.6410, Val Acc: 0.6863
Epoch 43/100, Loss: 0.6726, Acc: 0.5831, Val Loss: 0.6388, Val Acc: 0.6930
Epoch 44/100, Loss: 0.6729, Acc: 0.5831, Val Loss: 0.6442, Val Acc: 0.6733
Epoch 45/100, Loss: 0.6725, Acc: 0.5847, Val Loss: 0.6385, Val Acc: 0.6930
Epoch 46/100, Loss: 0.6727, Acc: 0.5834, Val Loss: 0.6439, Val Acc: 0.6741
Epoch 47/100, Loss: 0.6723, Acc: 0.5867, Val Loss: 0.6494, Val Acc: 0.6559
Epoch 48/100, Loss: 0.6725, Acc: 0.5851, Val Loss: 0.6466, Val Acc: 0.6704
Epoch 49/100, Loss: 0.6722, Acc: 0.5846, Val Loss: 0.6471, Val Acc: 0.6656
Epoch 50/100, Loss: 0.6722, Acc: 0.5849, Val Loss: 0.6501, Val Acc: 0.6604
Epoch 51/100, Loss: 0.6720, Acc: 0.5866, Val Loss: 0.6475, Val Acc: 0.6685
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.6718, Acc: 0.5850, Val Loss: 0.6443, Val Acc: 0.6785
Epoch 53/100, Loss: 0.6716, Acc: 0.5850, Val Loss: 0.6483, Val Acc: 0.6678
Epoch 54/100, Loss: 0.6715, Acc: 0.5858, Val Loss: 0.6491, Val Acc: 0.6622
Epoch 55/100, Loss: 0.6715, Acc: 0.5842, Val Loss: 0.6459, Val Acc: 0.6737
Epoch 56/100, Loss: 0.6711, Acc: 0.5840, Val Loss: 0.6489, Val Acc: 0.6674
Epoch 57/100, Loss: 0.6708, Acc: 0.5853, Val Loss: 0.6488, Val Acc: 0.6670
Epoch 58/100, Loss: 0.6706, Acc: 0.5850, Val Loss: 0.6498, Val Acc: 0.6663
Epoch 59/100, Loss: 0.6703, Acc: 0.5856, Val Loss: 0.6469, Val Acc: 0.6752
Epoch 60/100, Loss: 0.6702, Acc: 0.5846, Val Loss: 0.6490, Val Acc: 0.6663
Epoch 61/100, Loss: 0.6700, Acc: 0.5843, Val Loss: 0.6474, Val Acc: 0.6730
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.6698, Acc: 0.5851, Val Loss: 0.6474, Val Acc: 0.6744
Epoch 63/100, Loss: 0.6697, Acc: 0.5858, Val Loss: 0.6489, Val Acc: 0.6704
Epoch 64/100, Loss: 0.6696, Acc: 0.5857, Val Loss: 0.6492, Val Acc: 0.6700
Epoch 65/100, Loss: 0.6695, Acc: 0.5849, Val Loss: 0.6488, Val Acc: 0.6719
Epoch 66/100, Loss: 0.6694, Acc: 0.5855, Val Loss: 0.6486, Val Acc: 0.6715
Epoch 67/100, Loss: 0.6693, Acc: 0.5851, Val Loss: 0.6499, Val Acc: 0.6704
Epoch 68/100, Loss: 0.6692, Acc: 0.5846, Val Loss: 0.6501, Val Acc: 0.6670
Epoch 69/100, Loss: 0.6692, Acc: 0.5854, Val Loss: 0.6512, Val Acc: 0.6637
Epoch 70/100, Loss: 0.6690, Acc: 0.5849, Val Loss: 0.6507, Val Acc: 0.6667
Epoch 71/100, Loss: 0.6690, Acc: 0.5846, Val Loss: 0.6504, Val Acc: 0.6704
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.6688, Acc: 0.5854, Val Loss: 0.6513, Val Acc: 0.6667
Epoch 73/100, Loss: 0.6688, Acc: 0.5844, Val Loss: 0.6494, Val Acc: 0.6726
Epoch 74/100, Loss: 0.6687, Acc: 0.5850, Val Loss: 0.6508, Val Acc: 0.6707
Epoch 75/100, Loss: 0.6687, Acc: 0.5853, Val Loss: 0.6497, Val Acc: 0.6726
Epoch 76/100, Loss: 0.6686, Acc: 0.5854, Val Loss: 0.6499, Val Acc: 0.6707
Epoch 77/100, Loss: 0.6685, Acc: 0.5845, Val Loss: 0.6511, Val Acc: 0.6681
Epoch 78/100, Loss: 0.6685, Acc: 0.5853, Val Loss: 0.6517, Val Acc: 0.6681
Epoch 79/100, Loss: 0.6684, Acc: 0.5855, Val Loss: 0.6507, Val Acc: 0.6700
Epoch 80/100, Loss: 0.6683, Acc: 0.5849, Val Loss: 0.6513, Val Acc: 0.6696
Epoch 81/100, Loss: 0.6683, Acc: 0.5856, Val Loss: 0.6512, Val Acc: 0.6711
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.6682, Acc: 0.5851, Val Loss: 0.6508, Val Acc: 0.6700
Epoch 83/100, Loss: 0.6681, Acc: 0.5854, Val Loss: 0.6498, Val Acc: 0.6711
Epoch 84/100, Loss: 0.6681, Acc: 0.5855, Val Loss: 0.6512, Val Acc: 0.6707
Epoch 85/100, Loss: 0.6680, Acc: 0.5853, Val Loss: 0.6509, Val Acc: 0.6704
Epoch 86/100, Loss: 0.6680, Acc: 0.5851, Val Loss: 0.6508, Val Acc: 0.6722
Epoch 87/100, Loss: 0.6679, Acc: 0.5851, Val Loss: 0.6511, Val Acc: 0.6700
Epoch 88/100, Loss: 0.6678, Acc: 0.5851, Val Loss: 0.6508, Val Acc: 0.6722
Epoch 89/100, Loss: 0.6678, Acc: 0.5851, Val Loss: 0.6514, Val Acc: 0.6722
Epoch 90/100, Loss: 0.6677, Acc: 0.5848, Val Loss: 0.6517, Val Acc: 0.6696
Epoch 91/100, Loss: 0.6676, Acc: 0.5854, Val Loss: 0.6509, Val Acc: 0.6715
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.6676, Acc: 0.5848, Val Loss: 0.6520, Val Acc: 0.6707
Epoch 93/100, Loss: 0.6675, Acc: 0.5855, Val Loss: 0.6513, Val Acc: 0.6719
Epoch 94/100, Loss: 0.6674, Acc: 0.5849, Val Loss: 0.6509, Val Acc: 0.6715
Epoch 95/100, Loss: 0.6674, Acc: 0.5847, Val Loss: 0.6515, Val Acc: 0.6707
Epoch 96/100, Loss: 0.6673, Acc: 0.5850, Val Loss: 0.6520, Val Acc: 0.6707
Epoch 97/100, Loss: 0.6672, Acc: 0.5860, Val Loss: 0.6516, Val Acc: 0.6674
Epoch 98/100, Loss: 0.6672, Acc: 0.5850, Val Loss: 0.6521, Val Acc: 0.6704
Epoch 99/100, Loss: 0.6671, Acc: 0.5846, Val Loss: 0.6526, Val Acc: 0.6667
Epoch 100/100, Loss: 0.6670, Acc: 0.5881, Val Loss: 0.6534, Val Acc: 0.6670

##############################
Resultados para principal:  011  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21 
 {'training': [0.6670277285751497, 0.588121546961326, 0.5596573012473227, 0.8195571955719557, 0.6651194130418507], 'validate': [0.6533729600351911, 0.667037037037037, 0.6104156234351528, 0.9097014925373135, 0.7305963440215762], 'test': [0.7245230517297421, 0.4150887573964497, 0.4489515297353042, 0.7773809523809524, 0.5691871867509262]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  021  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  021  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6319, Acc: 0.6774, Val Loss: 0.5924, Val Acc: 0.6319
Mejor modelo guardado con Val Loss: 0.5924
Epoch 2/100, Loss: 0.5870, Acc: 0.7120, Val Loss: 0.4537, Val Acc: 0.9100
Mejor modelo guardado con Val Loss: 0.4537
Epoch 3/100, Loss: 0.5592, Acc: 0.7272, Val Loss: 0.4328, Val Acc: 0.8856
Mejor modelo guardado con Val Loss: 0.4328
Epoch 4/100, Loss: 0.5423, Acc: 0.7329, Val Loss: 0.3760, Val Acc: 0.9248
Mejor modelo guardado con Val Loss: 0.3760
Epoch 5/100, Loss: 0.5333, Acc: 0.7338, Val Loss: 0.4078, Val Acc: 0.8963
Epoch 6/100, Loss: 0.5316, Acc: 0.7364, Val Loss: 0.3568, Val Acc: 0.9285
Mejor modelo guardado con Val Loss: 0.3568
Epoch 7/100, Loss: 0.5234, Acc: 0.7400, Val Loss: 0.3336, Val Acc: 0.9263
Mejor modelo guardado con Val Loss: 0.3336
Epoch 8/100, Loss: 0.5202, Acc: 0.7425, Val Loss: 0.3320, Val Acc: 0.9341
Mejor modelo guardado con Val Loss: 0.3320
Epoch 9/100, Loss: 0.5095, Acc: 0.7562, Val Loss: 0.3244, Val Acc: 0.9267
Mejor modelo guardado con Val Loss: 0.3244
Epoch 10/100, Loss: 0.5114, Acc: 0.7466, Val Loss: 0.2980, Val Acc: 0.9422
Mejor modelo guardado con Val Loss: 0.2980
Epoch 11/100, Loss: 0.5147, Acc: 0.7451, Val Loss: 0.3266, Val Acc: 0.9200
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.4928, Acc: 0.7581, Val Loss: 0.3352, Val Acc: 0.9248
Epoch 13/100, Loss: 0.4925, Acc: 0.7604, Val Loss: 0.2820, Val Acc: 0.9356
Mejor modelo guardado con Val Loss: 0.2820
Epoch 14/100, Loss: 0.4859, Acc: 0.7647, Val Loss: 0.2966, Val Acc: 0.8959
Epoch 15/100, Loss: 0.4873, Acc: 0.7605, Val Loss: 0.3268, Val Acc: 0.8967
Epoch 16/100, Loss: 0.4837, Acc: 0.7618, Val Loss: 0.3098, Val Acc: 0.9130
Epoch 17/100, Loss: 0.4806, Acc: 0.7654, Val Loss: 0.3406, Val Acc: 0.8800
Epoch 18/100, Loss: 0.4773, Acc: 0.7658, Val Loss: 0.3121, Val Acc: 0.8944
Epoch 19/100, Loss: 0.4803, Acc: 0.7640, Val Loss: 0.3013, Val Acc: 0.9181
Epoch 20/100, Loss: 0.4789, Acc: 0.7650, Val Loss: 0.3099, Val Acc: 0.9056
Epoch 21/100, Loss: 0.4760, Acc: 0.7696, Val Loss: 0.3088, Val Acc: 0.8926
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.4670, Acc: 0.7688, Val Loss: 0.2834, Val Acc: 0.9048
Epoch 23/100, Loss: 0.4663, Acc: 0.7692, Val Loss: 0.3068, Val Acc: 0.8985
Epoch 24/100, Loss: 0.4655, Acc: 0.7726, Val Loss: 0.3234, Val Acc: 0.8781
Epoch 25/100, Loss: 0.4657, Acc: 0.7704, Val Loss: 0.3180, Val Acc: 0.8893
Epoch 26/100, Loss: 0.4649, Acc: 0.7733, Val Loss: 0.3300, Val Acc: 0.8933
Epoch 27/100, Loss: 0.4636, Acc: 0.7728, Val Loss: 0.3258, Val Acc: 0.8841
Epoch 28/100, Loss: 0.4632, Acc: 0.7733, Val Loss: 0.3395, Val Acc: 0.8811
Epoch 29/100, Loss: 0.4618, Acc: 0.7701, Val Loss: 0.3125, Val Acc: 0.8859
Epoch 30/100, Loss: 0.4607, Acc: 0.7723, Val Loss: 0.3116, Val Acc: 0.8752
Epoch 31/100, Loss: 0.4610, Acc: 0.7753, Val Loss: 0.3274, Val Acc: 0.8737
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.4586, Acc: 0.7749, Val Loss: 0.3076, Val Acc: 0.8844
Epoch 33/100, Loss: 0.4578, Acc: 0.7744, Val Loss: 0.3109, Val Acc: 0.8752
Epoch 34/100, Loss: 0.4578, Acc: 0.7776, Val Loss: 0.3043, Val Acc: 0.8881
Epoch 35/100, Loss: 0.4556, Acc: 0.7741, Val Loss: 0.3068, Val Acc: 0.8719
Epoch 36/100, Loss: 0.4554, Acc: 0.7766, Val Loss: 0.3197, Val Acc: 0.8733
Epoch 37/100, Loss: 0.4529, Acc: 0.7775, Val Loss: 0.3167, Val Acc: 0.8689
Epoch 38/100, Loss: 0.4540, Acc: 0.7784, Val Loss: 0.2875, Val Acc: 0.8919
Epoch 39/100, Loss: 0.4529, Acc: 0.7763, Val Loss: 0.2863, Val Acc: 0.8985
Epoch 40/100, Loss: 0.4514, Acc: 0.7795, Val Loss: 0.3051, Val Acc: 0.8833
Epoch 41/100, Loss: 0.4529, Acc: 0.7776, Val Loss: 0.2862, Val Acc: 0.8978
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.4488, Acc: 0.7785, Val Loss: 0.2927, Val Acc: 0.8874
Epoch 43/100, Loss: 0.4492, Acc: 0.7784, Val Loss: 0.2848, Val Acc: 0.8870
Epoch 44/100, Loss: 0.4488, Acc: 0.7787, Val Loss: 0.2865, Val Acc: 0.8893
Epoch 45/100, Loss: 0.4483, Acc: 0.7791, Val Loss: 0.2911, Val Acc: 0.8948
Epoch 46/100, Loss: 0.4478, Acc: 0.7789, Val Loss: 0.2905, Val Acc: 0.8896
Epoch 47/100, Loss: 0.4477, Acc: 0.7804, Val Loss: 0.2862, Val Acc: 0.8900
Epoch 48/100, Loss: 0.4481, Acc: 0.7797, Val Loss: 0.2973, Val Acc: 0.8822
Epoch 49/100, Loss: 0.4481, Acc: 0.7808, Val Loss: 0.2973, Val Acc: 0.8770
Epoch 50/100, Loss: 0.4475, Acc: 0.7800, Val Loss: 0.3058, Val Acc: 0.8685
Epoch 51/100, Loss: 0.4473, Acc: 0.7814, Val Loss: 0.3011, Val Acc: 0.8752
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.4461, Acc: 0.7810, Val Loss: 0.3050, Val Acc: 0.8730
Epoch 53/100, Loss: 0.4456, Acc: 0.7817, Val Loss: 0.3053, Val Acc: 0.8689
Epoch 54/100, Loss: 0.4460, Acc: 0.7819, Val Loss: 0.2872, Val Acc: 0.8815
Epoch 55/100, Loss: 0.4461, Acc: 0.7810, Val Loss: 0.2977, Val Acc: 0.8774
Epoch 56/100, Loss: 0.4460, Acc: 0.7798, Val Loss: 0.2934, Val Acc: 0.8804
Epoch 57/100, Loss: 0.4464, Acc: 0.7806, Val Loss: 0.2943, Val Acc: 0.8767
Epoch 58/100, Loss: 0.4454, Acc: 0.7813, Val Loss: 0.3043, Val Acc: 0.8707
Epoch 59/100, Loss: 0.4453, Acc: 0.7824, Val Loss: 0.2841, Val Acc: 0.8956
Epoch 60/100, Loss: 0.4458, Acc: 0.7821, Val Loss: 0.2878, Val Acc: 0.8915
Epoch 61/100, Loss: 0.4455, Acc: 0.7809, Val Loss: 0.3038, Val Acc: 0.8744
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.4448, Acc: 0.7818, Val Loss: 0.3061, Val Acc: 0.8693
Epoch 63/100, Loss: 0.4445, Acc: 0.7833, Val Loss: 0.3015, Val Acc: 0.8759
Epoch 64/100, Loss: 0.4450, Acc: 0.7811, Val Loss: 0.2915, Val Acc: 0.8863
Epoch 65/100, Loss: 0.4440, Acc: 0.7831, Val Loss: 0.2909, Val Acc: 0.8826
Epoch 66/100, Loss: 0.4442, Acc: 0.7827, Val Loss: 0.2851, Val Acc: 0.8915
Epoch 67/100, Loss: 0.4440, Acc: 0.7832, Val Loss: 0.2886, Val Acc: 0.8848
Epoch 68/100, Loss: 0.4439, Acc: 0.7823, Val Loss: 0.2895, Val Acc: 0.8856
Epoch 69/100, Loss: 0.4438, Acc: 0.7816, Val Loss: 0.3019, Val Acc: 0.8693
Epoch 70/100, Loss: 0.4441, Acc: 0.7825, Val Loss: 0.2913, Val Acc: 0.8841
Epoch 71/100, Loss: 0.4437, Acc: 0.7835, Val Loss: 0.2894, Val Acc: 0.8893
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.4436, Acc: 0.7821, Val Loss: 0.2883, Val Acc: 0.8881
Epoch 73/100, Loss: 0.4436, Acc: 0.7841, Val Loss: 0.2894, Val Acc: 0.8856
Epoch 74/100, Loss: 0.4436, Acc: 0.7815, Val Loss: 0.2897, Val Acc: 0.8852
Epoch 75/100, Loss: 0.4434, Acc: 0.7827, Val Loss: 0.2924, Val Acc: 0.8841
Epoch 76/100, Loss: 0.4434, Acc: 0.7824, Val Loss: 0.2889, Val Acc: 0.8878
Epoch 77/100, Loss: 0.4433, Acc: 0.7839, Val Loss: 0.2892, Val Acc: 0.8889
Epoch 78/100, Loss: 0.4433, Acc: 0.7831, Val Loss: 0.2917, Val Acc: 0.8833
Epoch 79/100, Loss: 0.4433, Acc: 0.7829, Val Loss: 0.2892, Val Acc: 0.8852
Epoch 80/100, Loss: 0.4432, Acc: 0.7835, Val Loss: 0.2891, Val Acc: 0.8848
Epoch 81/100, Loss: 0.4432, Acc: 0.7826, Val Loss: 0.2893, Val Acc: 0.8841
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.4432, Acc: 0.7821, Val Loss: 0.2908, Val Acc: 0.8833
Epoch 83/100, Loss: 0.4432, Acc: 0.7832, Val Loss: 0.2898, Val Acc: 0.8848
Epoch 84/100, Loss: 0.4430, Acc: 0.7845, Val Loss: 0.2873, Val Acc: 0.8878
Epoch 85/100, Loss: 0.4433, Acc: 0.7822, Val Loss: 0.2892, Val Acc: 0.8863
Epoch 86/100, Loss: 0.4431, Acc: 0.7830, Val Loss: 0.2895, Val Acc: 0.8856
Epoch 87/100, Loss: 0.4430, Acc: 0.7833, Val Loss: 0.2890, Val Acc: 0.8863
Epoch 88/100, Loss: 0.4431, Acc: 0.7820, Val Loss: 0.2917, Val Acc: 0.8826
Epoch 89/100, Loss: 0.4429, Acc: 0.7830, Val Loss: 0.2895, Val Acc: 0.8852
Epoch 90/100, Loss: 0.4428, Acc: 0.7830, Val Loss: 0.2897, Val Acc: 0.8863
Epoch 91/100, Loss: 0.4429, Acc: 0.7841, Val Loss: 0.2926, Val Acc: 0.8811
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.4428, Acc: 0.7830, Val Loss: 0.2885, Val Acc: 0.8863
Epoch 93/100, Loss: 0.4430, Acc: 0.7837, Val Loss: 0.2908, Val Acc: 0.8837
Epoch 94/100, Loss: 0.4427, Acc: 0.7826, Val Loss: 0.2913, Val Acc: 0.8833
Epoch 95/100, Loss: 0.4426, Acc: 0.7836, Val Loss: 0.2893, Val Acc: 0.8848
Epoch 96/100, Loss: 0.4428, Acc: 0.7837, Val Loss: 0.2880, Val Acc: 0.8863
Epoch 97/100, Loss: 0.4428, Acc: 0.7833, Val Loss: 0.2900, Val Acc: 0.8837
Epoch 98/100, Loss: 0.4427, Acc: 0.7827, Val Loss: 0.2873, Val Acc: 0.8863
Epoch 99/100, Loss: 0.4426, Acc: 0.7834, Val Loss: 0.2904, Val Acc: 0.8841
Epoch 100/100, Loss: 0.4423, Acc: 0.7833, Val Loss: 0.2879, Val Acc: 0.8863

##############################
Resultados para principal:  021  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21 
 {'training': [0.44232466052908925, 0.7833333333333333, 0.7893942253255332, 0.7717712177121772, 0.7804832540348913], 'validate': [0.2879472828881685, 0.8862962962962962, 0.8686652391149179, 0.9082089552238806, 0.8879970813571689], 'test': [0.34727789419439603, 0.8588757396449704, 0.8893203883495145, 0.8178571428571428, 0.8520930232558139]}

######################################## 
########################################
Grupo en indetificación:  ['102', '020', '125', '011', '021', '008']  --- principal:  008  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  008  --- group:  ['102', '020', '125', '011', '021', '008']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6826, Acc: 0.5829, Val Loss: 0.6892, Val Acc: 0.5452
Mejor modelo guardado con Val Loss: 0.6892
Epoch 2/100, Loss: 0.6724, Acc: 0.6229, Val Loss: 0.6846, Val Acc: 0.5444
Mejor modelo guardado con Val Loss: 0.6846
Epoch 3/100, Loss: 0.6598, Acc: 0.6413, Val Loss: 0.6982, Val Acc: 0.5096
Epoch 4/100, Loss: 0.6516, Acc: 0.6469, Val Loss: 0.6830, Val Acc: 0.5530
Mejor modelo guardado con Val Loss: 0.6830
Epoch 5/100, Loss: 0.6434, Acc: 0.6581, Val Loss: 0.6864, Val Acc: 0.5448
Epoch 6/100, Loss: 0.6324, Acc: 0.6702, Val Loss: 0.6846, Val Acc: 0.5663
Epoch 7/100, Loss: 0.6320, Acc: 0.6628, Val Loss: 0.7074, Val Acc: 0.4830
Epoch 8/100, Loss: 0.6253, Acc: 0.6737, Val Loss: 0.7057, Val Acc: 0.5167
Epoch 9/100, Loss: 0.6248, Acc: 0.6685, Val Loss: 0.6750, Val Acc: 0.5856
Mejor modelo guardado con Val Loss: 0.6750
Epoch 10/100, Loss: 0.6208, Acc: 0.6731, Val Loss: 0.7172, Val Acc: 0.5085
Epoch 11/100, Loss: 0.6160, Acc: 0.6798, Val Loss: 0.7139, Val Acc: 0.5030
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6108, Acc: 0.6861, Val Loss: 0.7659, Val Acc: 0.4600
Epoch 13/100, Loss: 0.6065, Acc: 0.6897, Val Loss: 0.7276, Val Acc: 0.5407
Epoch 14/100, Loss: 0.6037, Acc: 0.6942, Val Loss: 0.7406, Val Acc: 0.5015
Epoch 15/100, Loss: 0.6056, Acc: 0.6922, Val Loss: 0.7501, Val Acc: 0.4922
Epoch 16/100, Loss: 0.6049, Acc: 0.6898, Val Loss: 0.7480, Val Acc: 0.5148
Epoch 17/100, Loss: 0.6027, Acc: 0.6907, Val Loss: 0.7574, Val Acc: 0.4911
Epoch 18/100, Loss: 0.6026, Acc: 0.6906, Val Loss: 0.7581, Val Acc: 0.4819
Epoch 19/100, Loss: 0.6021, Acc: 0.6893, Val Loss: 0.7547, Val Acc: 0.5089
Epoch 20/100, Loss: 0.5997, Acc: 0.6917, Val Loss: 0.7580, Val Acc: 0.5037
Epoch 21/100, Loss: 0.5996, Acc: 0.6924, Val Loss: 0.7384, Val Acc: 0.4948
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.5974, Acc: 0.6948, Val Loss: 0.7688, Val Acc: 0.4956
Epoch 23/100, Loss: 0.5947, Acc: 0.6963, Val Loss: 0.7683, Val Acc: 0.4889
Epoch 24/100, Loss: 0.5955, Acc: 0.6958, Val Loss: 0.7877, Val Acc: 0.4719
Epoch 25/100, Loss: 0.5954, Acc: 0.6998, Val Loss: 0.7980, Val Acc: 0.4567
Epoch 26/100, Loss: 0.5943, Acc: 0.6961, Val Loss: 0.7855, Val Acc: 0.4641
Epoch 27/100, Loss: 0.5930, Acc: 0.6974, Val Loss: 0.7936, Val Acc: 0.4637
Epoch 28/100, Loss: 0.5933, Acc: 0.6970, Val Loss: 0.8085, Val Acc: 0.4493
Epoch 29/100, Loss: 0.5921, Acc: 0.6996, Val Loss: 0.7814, Val Acc: 0.4900
Epoch 30/100, Loss: 0.5914, Acc: 0.7015, Val Loss: 0.7847, Val Acc: 0.4896
Epoch 31/100, Loss: 0.5919, Acc: 0.7005, Val Loss: 0.7787, Val Acc: 0.4837
Learning rate reduced from 0.000250 to 0.000125
Epoch 32/100, Loss: 0.5913, Acc: 0.7013, Val Loss: 0.7788, Val Acc: 0.4885
Epoch 33/100, Loss: 0.5903, Acc: 0.6986, Val Loss: 0.7648, Val Acc: 0.5159
Epoch 34/100, Loss: 0.5906, Acc: 0.6974, Val Loss: 0.7955, Val Acc: 0.4722
Epoch 35/100, Loss: 0.5894, Acc: 0.6987, Val Loss: 0.7683, Val Acc: 0.5104
Epoch 36/100, Loss: 0.5895, Acc: 0.6995, Val Loss: 0.7855, Val Acc: 0.4815
Epoch 37/100, Loss: 0.5893, Acc: 0.6971, Val Loss: 0.7741, Val Acc: 0.5056
Epoch 38/100, Loss: 0.5893, Acc: 0.7006, Val Loss: 0.7857, Val Acc: 0.5000
Epoch 39/100, Loss: 0.5890, Acc: 0.7006, Val Loss: 0.7941, Val Acc: 0.4796
Epoch 40/100, Loss: 0.5888, Acc: 0.6990, Val Loss: 0.7964, Val Acc: 0.4796
Epoch 41/100, Loss: 0.5896, Acc: 0.6991, Val Loss: 0.7915, Val Acc: 0.4859
Learning rate reduced from 0.000125 to 0.000063
Epoch 42/100, Loss: 0.5878, Acc: 0.7013, Val Loss: 0.7882, Val Acc: 0.4863
Epoch 43/100, Loss: 0.5869, Acc: 0.7013, Val Loss: 0.7745, Val Acc: 0.5022
Epoch 44/100, Loss: 0.5871, Acc: 0.7019, Val Loss: 0.7894, Val Acc: 0.4874
Epoch 45/100, Loss: 0.5868, Acc: 0.7017, Val Loss: 0.7735, Val Acc: 0.5041
Epoch 46/100, Loss: 0.5869, Acc: 0.7020, Val Loss: 0.7860, Val Acc: 0.5048
Epoch 47/100, Loss: 0.5868, Acc: 0.7019, Val Loss: 0.8008, Val Acc: 0.4781
Epoch 48/100, Loss: 0.5868, Acc: 0.7016, Val Loss: 0.7926, Val Acc: 0.4789
Epoch 49/100, Loss: 0.5867, Acc: 0.7027, Val Loss: 0.7897, Val Acc: 0.4911
Epoch 50/100, Loss: 0.5866, Acc: 0.7019, Val Loss: 0.7825, Val Acc: 0.5022
Epoch 51/100, Loss: 0.5859, Acc: 0.7036, Val Loss: 0.7853, Val Acc: 0.5093
Learning rate reduced from 0.000063 to 0.000031
Epoch 52/100, Loss: 0.5857, Acc: 0.7031, Val Loss: 0.7878, Val Acc: 0.4963
Epoch 53/100, Loss: 0.5854, Acc: 0.7008, Val Loss: 0.7902, Val Acc: 0.4859
Epoch 54/100, Loss: 0.5855, Acc: 0.7025, Val Loss: 0.7831, Val Acc: 0.5019
Epoch 55/100, Loss: 0.5850, Acc: 0.7014, Val Loss: 0.7843, Val Acc: 0.4915
Epoch 56/100, Loss: 0.5850, Acc: 0.7020, Val Loss: 0.7789, Val Acc: 0.5111
Epoch 57/100, Loss: 0.5853, Acc: 0.7017, Val Loss: 0.7841, Val Acc: 0.4978
Epoch 58/100, Loss: 0.5848, Acc: 0.7022, Val Loss: 0.7893, Val Acc: 0.4937
Epoch 59/100, Loss: 0.5847, Acc: 0.7037, Val Loss: 0.7892, Val Acc: 0.4930
Epoch 60/100, Loss: 0.5845, Acc: 0.7031, Val Loss: 0.7844, Val Acc: 0.5033
Epoch 61/100, Loss: 0.5845, Acc: 0.7027, Val Loss: 0.7862, Val Acc: 0.4944
Learning rate reduced from 0.000031 to 0.000016
Epoch 62/100, Loss: 0.5841, Acc: 0.7032, Val Loss: 0.7882, Val Acc: 0.4944
Epoch 63/100, Loss: 0.5840, Acc: 0.7033, Val Loss: 0.7861, Val Acc: 0.4974
Epoch 64/100, Loss: 0.5840, Acc: 0.7029, Val Loss: 0.7879, Val Acc: 0.4941
Epoch 65/100, Loss: 0.5840, Acc: 0.7037, Val Loss: 0.7875, Val Acc: 0.4959
Epoch 66/100, Loss: 0.5839, Acc: 0.7023, Val Loss: 0.7911, Val Acc: 0.4919
Epoch 67/100, Loss: 0.5839, Acc: 0.7034, Val Loss: 0.7913, Val Acc: 0.4881
Epoch 68/100, Loss: 0.5839, Acc: 0.7030, Val Loss: 0.7873, Val Acc: 0.4985
Epoch 69/100, Loss: 0.5839, Acc: 0.7033, Val Loss: 0.7891, Val Acc: 0.4941
Epoch 70/100, Loss: 0.5839, Acc: 0.7032, Val Loss: 0.7897, Val Acc: 0.4948
Epoch 71/100, Loss: 0.5838, Acc: 0.7023, Val Loss: 0.7874, Val Acc: 0.4948
Learning rate reduced from 0.000016 to 0.000010
Epoch 72/100, Loss: 0.5836, Acc: 0.7034, Val Loss: 0.7883, Val Acc: 0.4952
Epoch 73/100, Loss: 0.5835, Acc: 0.7031, Val Loss: 0.7880, Val Acc: 0.4956
Epoch 74/100, Loss: 0.5835, Acc: 0.7040, Val Loss: 0.7894, Val Acc: 0.4956
Epoch 75/100, Loss: 0.5835, Acc: 0.7039, Val Loss: 0.7887, Val Acc: 0.4959
Epoch 76/100, Loss: 0.5834, Acc: 0.7031, Val Loss: 0.7886, Val Acc: 0.4956
Epoch 77/100, Loss: 0.5834, Acc: 0.7030, Val Loss: 0.7904, Val Acc: 0.4941
Epoch 78/100, Loss: 0.5834, Acc: 0.7032, Val Loss: 0.7893, Val Acc: 0.4948
Epoch 79/100, Loss: 0.5834, Acc: 0.7033, Val Loss: 0.7881, Val Acc: 0.4948
Epoch 80/100, Loss: 0.5833, Acc: 0.7039, Val Loss: 0.7892, Val Acc: 0.4956
Epoch 81/100, Loss: 0.5832, Acc: 0.7035, Val Loss: 0.7886, Val Acc: 0.4959
Learning rate reduced from 0.000010 to 0.000010
Epoch 82/100, Loss: 0.5832, Acc: 0.7034, Val Loss: 0.7894, Val Acc: 0.4952
Epoch 83/100, Loss: 0.5832, Acc: 0.7022, Val Loss: 0.7900, Val Acc: 0.4948
Epoch 84/100, Loss: 0.5830, Acc: 0.7028, Val Loss: 0.7886, Val Acc: 0.4967
Epoch 85/100, Loss: 0.5825, Acc: 0.7030, Val Loss: 0.7906, Val Acc: 0.4933
Epoch 86/100, Loss: 0.5825, Acc: 0.7039, Val Loss: 0.7902, Val Acc: 0.4959
Epoch 87/100, Loss: 0.5823, Acc: 0.7030, Val Loss: 0.7900, Val Acc: 0.4933
Epoch 88/100, Loss: 0.5822, Acc: 0.7040, Val Loss: 0.7896, Val Acc: 0.4937
Epoch 89/100, Loss: 0.5821, Acc: 0.7039, Val Loss: 0.7897, Val Acc: 0.4952
Epoch 90/100, Loss: 0.5821, Acc: 0.7033, Val Loss: 0.7891, Val Acc: 0.4944
Epoch 91/100, Loss: 0.5821, Acc: 0.7049, Val Loss: 0.7889, Val Acc: 0.4978
Learning rate reduced from 0.000010 to 0.000010
Epoch 92/100, Loss: 0.5820, Acc: 0.7038, Val Loss: 0.7922, Val Acc: 0.4915
Epoch 93/100, Loss: 0.5819, Acc: 0.7046, Val Loss: 0.7893, Val Acc: 0.4985
Epoch 94/100, Loss: 0.5819, Acc: 0.7038, Val Loss: 0.7908, Val Acc: 0.4933
Epoch 95/100, Loss: 0.5818, Acc: 0.7034, Val Loss: 0.7890, Val Acc: 0.4956
Epoch 96/100, Loss: 0.5817, Acc: 0.7046, Val Loss: 0.7894, Val Acc: 0.4956
Epoch 97/100, Loss: 0.5817, Acc: 0.7046, Val Loss: 0.7909, Val Acc: 0.4948
Epoch 98/100, Loss: 0.5817, Acc: 0.7037, Val Loss: 0.7900, Val Acc: 0.4952
Epoch 99/100, Loss: 0.5815, Acc: 0.7039, Val Loss: 0.7903, Val Acc: 0.4926
Epoch 100/100, Loss: 0.5816, Acc: 0.7038, Val Loss: 0.7895, Val Acc: 0.4948

##############################
Resultados para principal:  008  --- grupo:  ['102', '020', '125', '011', '021', '008']  --- window & package numer:  21 
 {'training': [0.5815960939966732, 0.7037753222836096, 0.6802487317951236, 0.7669741697416974, 0.7210129216893592], 'validate': [0.7894848647505738, 0.4948148148148148, 0.4903536977491961, 0.4552238805970149, 0.47213622291021673], 'test': [0.5027147767678747, 0.8384615384615385, 0.8810483870967742, 0.7803571428571429, 0.8276515151515151]}

##############################
Resultados para window:  21 
 {'102:020:125:011:021:008': {'training': [0.32415425803779896, 0.8495395948434622, 0.8560948081264108, 0.8396678966789668, 0.8478017883755589], 'validate': [0.11756837833672762, 0.9581481481481482, 0.9849802371541502, 0.9298507462686567, 0.9566218809980807], 'test': [0.6190017694431655, 0.7014792899408284, 0.6783625730994152, 0.7595238095238095, 0.7166526256669475]}, '020:102:125:011:021:008': {'training': [0.4182391260210322, 0.8146408839779006, 0.7706976005085016, 0.8948339483394834, 0.8281396738666439], 'validate': [1.0046862727680872, 0.4551851851851852, 0.47468109779667567, 0.9164179104477612, 0.6254138018843901], 'test': [0.644538606675166, 0.6174556213017751, 0.7300832342449465, 0.36547619047619045, 0.48710829036096787]}, '125:102:020:011:021:008': {'training': [0.6817929769308747, 0.5813075506445672, 0.5777936196756371, 0.5981549815498155, 0.5877980237512465], 'validate': [0.6928516155065492, 0.5288888888888889, 0.5227272727272727, 0.5835820895522388, 0.5514809590973202], 'test': [0.6883430559680147, 0.5535502958579882, 0.5503237198351971, 0.5565476190476191, 0.5534181710565256]}, '011:102:020:125:021:008': {'training': [0.6670277285751497, 0.588121546961326, 0.5596573012473227, 0.8195571955719557, 0.6651194130418507], 'validate': [0.6533729600351911, 0.667037037037037, 0.6104156234351528, 0.9097014925373135, 0.7305963440215762], 'test': [0.7245230517297421, 0.4150887573964497, 0.4489515297353042, 0.7773809523809524, 0.5691871867509262]}, '021:102:020:125:011:008': {'training': [0.44232466052908925, 0.7833333333333333, 0.7893942253255332, 0.7717712177121772, 0.7804832540348913], 'validate': [0.2879472828881685, 0.8862962962962962, 0.8686652391149179, 0.9082089552238806, 0.8879970813571689], 'test': [0.34727789419439603, 0.8588757396449704, 0.8893203883495145, 0.8178571428571428, 0.8520930232558139]}, '008:102:020:125:011:021': {'training': [0.5815960939966732, 0.7037753222836096, 0.6802487317951236, 0.7669741697416974, 0.7210129216893592], 'validate': [0.7894848647505738, 0.4948148148148148, 0.4903536977491961, 0.4552238805970149, 0.47213622291021673], 'test': [0.5027147767678747, 0.8384615384615385, 0.8810483870967742, 0.7803571428571429, 0.8276515151515151]}}

######################################## 
########################################
Grupo en indetificación:  ['036', '024', '100', '090', '091', '019']  --- principal:  036  --- window & package numer:  21

generando data de principal y secundarios...

generando data para training, validación y test...

generando de labels para training, validación y test...
Datos generados exitosamente. Generando etiquetas...
##################################### principal:  036  --- group:  ['036', '024', '100', '090', '091', '019']  --- window:  21
################# principal
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
################# secundario
shape train:  (5440, 52)
shape val:  (1360, 52)
shape test:  (1700, 52)
shape train label:  (5440,)
shape val label:  (1360,)
shape test label:  (1700,)
#####################################


########################################
identification model:  1 
principal:  036  --- grupo:  ['036', '024', '100', '090', '091', '019']  --- window & package numer:  21
comenzando modelo LSTM
Epoch 1/100, Loss: 0.6878, Acc: 0.5559, Val Loss: 0.6912, Val Acc: 0.5304
Mejor modelo guardado con Val Loss: 0.6912
Epoch 2/100, Loss: 0.6841, Acc: 0.5759, Val Loss: 0.6888, Val Acc: 0.5570
Mejor modelo guardado con Val Loss: 0.6888
Epoch 3/100, Loss: 0.6811, Acc: 0.5808, Val Loss: 0.6836, Val Acc: 0.5793
Mejor modelo guardado con Val Loss: 0.6836
Epoch 4/100, Loss: 0.6759, Acc: 0.5899, Val Loss: 0.6834, Val Acc: 0.5715
Mejor modelo guardado con Val Loss: 0.6834
Epoch 5/100, Loss: 0.6750, Acc: 0.5894, Val Loss: 0.6925, Val Acc: 0.5304
Epoch 6/100, Loss: 0.6705, Acc: 0.5962, Val Loss: 0.6984, Val Acc: 0.5126
Epoch 7/100, Loss: 0.6697, Acc: 0.5914, Val Loss: 0.6969, Val Acc: 0.5307
Epoch 8/100, Loss: 0.6660, Acc: 0.6022, Val Loss: 0.6833, Val Acc: 0.5689
Mejor modelo guardado con Val Loss: 0.6833
Epoch 9/100, Loss: 0.6688, Acc: 0.5938, Val Loss: 0.6840, Val Acc: 0.5759
Epoch 10/100, Loss: 0.6669, Acc: 0.5948, Val Loss: 0.6834, Val Acc: 0.5859
Epoch 11/100, Loss: 0.6643, Acc: 0.6005, Val Loss: 0.6926, Val Acc: 0.5407
Learning rate reduced from 0.001000 to 0.000500
Epoch 12/100, Loss: 0.6625, Acc: 0.6078, Val Loss: 0.6996, Val Acc: 0.5259
Epoch 13/100, Loss: 0.6603, Acc: 0.6058, Val Loss: 0.6957, Val Acc: 0.5433
Epoch 14/100, Loss: 0.6608, Acc: 0.6093, Val Loss: 0.6967, Val Acc: 0.5404
Epoch 15/100, Loss: 0.6610, Acc: 0.6080, Val Loss: 0.6969, Val Acc: 0.5378
Epoch 16/100, Loss: 0.6609, Acc: 0.6067, Val Loss: 0.6984, Val Acc: 0.5374
Epoch 17/100, Loss: 0.6603, Acc: 0.6087, Val Loss: 0.6963, Val Acc: 0.5422
Epoch 18/100, Loss: 0.6593, Acc: 0.6100, Val Loss: 0.7011, Val Acc: 0.5263
Epoch 19/100, Loss: 0.6587, Acc: 0.6098, Val Loss: 0.7104, Val Acc: 0.5115
Epoch 20/100, Loss: 0.6601, Acc: 0.6066, Val Loss: 0.6983, Val Acc: 0.5378
Epoch 21/100, Loss: 0.6585, Acc: 0.6086, Val Loss: 0.7053, Val Acc: 0.5230
Learning rate reduced from 0.000500 to 0.000250
Epoch 22/100, Loss: 0.6594, Acc: 0.6074, Val Loss: 0.7038, Val Acc: 0.5252
Epoch 23/100, Loss: 0.6575, Acc: 0.6113, Val Loss: 0.7058, Val Acc: 0.5159
Epoch 24/100, Loss: 0.6576, Acc: 0.6099, Val Loss: 0.7011, Val Acc: 0.5381
Epoch 25/100, Loss: 0.6567, Acc: 0.6106, Val Loss: 0.6998, Val Acc: 0.5359
Epoch 26/100, Loss: 0.6577, Acc: 0.6122, Val Loss: 0.7001, Val Acc: 0.5381
Epoch 27/100, Loss: 0.6563, Acc: 0.6149, Val Loss: 0.7017, Val Acc: 0.5370
Epoch 28/100, Loss: 0.6570, Acc: 0.6115, Val Loss: 0.7044, Val Acc: 0.5263
Epoch 29/100, Loss: 0.6573, Acc: 0.6133, Val Loss: 0.7037, Val Acc: 0.5244
Epoch 30/100, Loss: 0.6566, Acc: 0.6137, Val Loss: 0.7081, Val Acc: 0.5141
Epoch 31/100, Loss: 0.6572, Acc: 0.6096, Val Loss: 0.6995, Val Acc: 0.5381